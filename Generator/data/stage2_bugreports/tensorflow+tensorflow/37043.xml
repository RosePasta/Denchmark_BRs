<bug id='37043' author='TCBocean' open_date='2020-02-25T10:03:09Z' closed_time='2020-03-07T00:58:25Z'>
	<summary>An error is reported when the nested tf.keras.Model subclass model is converted to a tflite file</summary>
	<description>
My environment:
tensorflow-gpu 2.1
windows 10
python 3.7
tensorflow is installed using pip
The following is a simple demo I wrote to illustrate this problem.：
`
import tensorflow as tf
&lt;denchmark-code&gt;@tf.function
def Hswish(x):
    return x * tf.nn.relu6(x + 3) / 6

tf.keras.utils.get_custom_objects().update({'custom_activation': tf.keras.layers.Activation(Hswish)})

class Conv2d_BN(tf.keras.Model):
    def __init__(self, filters, kernel_size, strides, padding, is_use_bias=True, name=None):
        super(Conv2d_BN, self).__init__(name=name)
        self.conv2d_bn = tf.keras.Sequential([tf.keras.layers.Conv2D(filters, kernel_size, strides=strides,
                                                               padding=padding, use_bias=is_use_bias, kernel_initializer=tf.ones),
                                              tf.keras.layers.BatchNormalization()], name="conv2d_bn")

    def call(self, inputs):
        return self.conv2d_bn(inputs)

class test_model2(tf.keras.Model):
    def __init__(self, layer_name, layer_filters, name="test_model2"):
        super(test_model2, self).__init__(name=name)
        self.convs = []
        for n, f in zip(layer_name, layer_filters):
            if "2" in n:
                continue
            self.convs.append(Conv2d_BN(filters=f, kernel_size=1, strides=(1,1), padding="valid", is_use_bias=False,
                                        name=self.name + n + "/conv1"))
        self.empty_layer = None

    @tf.function
    def call(self, inputs):
        output1 = inputs[0]
        for c_layer in self.convs:
            output1 = c_layer(output1)

        output2 = inputs[1]
        for c_layer in self.convs:
            output2 = c_layer(output2)
        if self.empty_layer is None:
            print("None")
        return output1, output2


layer_name = ["layer1", "layer2", "layer3", "layer4", "layer5"]
layer_filters = [3, 4, 5, 6, 7]
model = test_model2(layer_name, layer_filters)
test_input1 = tf.ones((1, 2, 2, 1))
test_input2 = tf.zeros((1, 2, 2, 1))
input_list = [test_input1, test_input2]
test_output1, test_output2 = model(input_list)
print(test_output1)
print(test_output2)

model._set_inputs(input_list)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open("./save4/converted_model.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

`
The following is the error message：
C:\software\Anaconda3\envs\TF2_1_GPU\python.exe C:/Users/stars_ocean/Desktop/TensorFlow_test_folder/new_tf_模型保存_进阶4.py
2020-02-25 17:50:15.295174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-02-25 17:50:17.612336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-02-25 17:50:18.876900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2020-02-25 17:50:18.877178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-02-25 17:50:18.886768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-02-25 17:50:18.893842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-02-25 17:50:18.898386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-02-25 17:50:18.905867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-02-25 17:50:18.911441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-02-25 17:50:18.924981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-25 17:50:18.925736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-02-25 17:50:18.926051: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-02-25 17:50:18.926915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2020-02-25 17:50:18.927189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-02-25 17:50:18.927331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-02-25 17:50:18.927466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-02-25 17:50:18.927601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-02-25 17:50:18.927736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-02-25 17:50:18.927875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-02-25 17:50:18.928013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-25 17:50:18.928571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-02-25 17:50:19.461309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-25 17:50:19.461461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-02-25 17:50:19.461550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-02-25 17:50:19.462190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2985 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
None
None
2020-02-25 17:50:20.090133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-25 17:50:20.855562: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-02-25 17:50:20.874969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
tf.Tensor(
[[[[89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]
[89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]]
&lt;denchmark-code&gt;  [[89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]
   [89.82026 89.82026 89.82026 89.82026 89.82026 89.82026 89.82026]]]], shape=(1, 2, 2, 7), dtype=float32)
tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 0.]
   [0. 0. 0. 0. 0. 0. 0.]]

  [[0. 0. 0. 0. 0. 0. 0.]
   [0. 0. 0. 0. 0. 0. 0.]]]], shape=(1, 2, 2, 7), dtype=float32)
None
2020-02-25 17:50:21.348618: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2020-02-25 17:50:21.348841: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-25 17:50:21.350171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2020-02-25 17:50:21.350427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-02-25 17:50:21.350557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-02-25 17:50:21.350687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-02-25 17:50:21.350815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-02-25 17:50:21.350943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-02-25 17:50:21.351072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-02-25 17:50:21.351205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-25 17:50:21.351611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-02-25 17:50:21.351751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-25 17:50:21.351889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-02-25 17:50:21.351976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-02-25 17:50:21.352364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2985 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-02-25 17:50:21.378422: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-02-25 17:50:21.378569: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 182 nodes (156), 365 edges (338), time = 7.223ms.
2020-02-25 17:50:21.378731: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 182 nodes (0), 365 edges (0), time = 3.522ms.
2020-02-25 17:50:21.378885: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_1_true_940
2020-02-25 17:50:21.379063: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.379206: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.379345: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_false_829
2020-02-25 17:50:21.379524: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.379663: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.379799: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_1_false_811
2020-02-25 17:50:21.379978: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.380119: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.380258: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_false_764
2020-02-25 17:50:21.380435: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.380575: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.380712: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_false_894
2020-02-25 17:50:21.380889: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.381028: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.381166: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_1_false_746
2020-02-25 17:50:21.381344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.381482: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.381624: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_1_false_674
2020-02-25 17:50:21.381805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.381943: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.382079: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_true_763
2020-02-25 17:50:21.391040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.391189: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.391329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_true_893
2020-02-25 17:50:21.391507: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.391679: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.391817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_true_550
2020-02-25 17:50:21.391994: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.392136: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.392274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_true_828
2020-02-25 17:50:21.392453: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.392591: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.392729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_1_true_1005
2020-02-25 17:50:21.392910: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.393057: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.393200: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_true_478
2020-02-25 17:50:21.393374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.393512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.393649: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_1_false_530
2020-02-25 17:50:21.393827: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.393965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.394105: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_1_conv2d_bn_batch_normalization_cond_1_true_810
2020-02-25 17:50:21.394282: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.394423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.394562: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_false_479
2020-02-25 17:50:21.394740: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.406638: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.406786: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_1_false_602
2020-02-25 17:50:21.406966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.407107: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.407247: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_1_true_673
2020-02-25 17:50:21.407427: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.407565: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.407703: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_1_conv2d_bn_batch_normalization_2_cond_1_false_941
2020-02-25 17:50:21.407884: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.408027: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.408166: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_true_958
2020-02-25 17:50:21.408344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.408489: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.408634: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_false_695
2020-02-25 17:50:21.408870: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.409096: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.409238: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_true_694
2020-02-25 17:50:21.409416: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.409558: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.409696: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer1_conv1_conv2d_bn_batch_normalization_cond_1_true_529
2020-02-25 17:50:21.409874: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.410015: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.410154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_1_false_1006
2020-02-25 17:50:21.410340: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.410486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.422249: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_conv2d_bn_batch_normalization_3_cond_1_true_745
2020-02-25 17:50:21.422437: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.422581: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.422722: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_1_false_876
2020-02-25 17:50:21.422905: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.423048: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.423187: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_true_622
2020-02-25 17:50:21.423366: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.423508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.423646: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer5_conv1_1_conv2d_bn_batch_normalization_3_cond_false_959
2020-02-25 17:50:21.423825: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.423965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.424103: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_false_551
2020-02-25 17:50:21.424283: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.424425: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.424567: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_conv2d_bn_batch_normalization_1_cond_1_true_601
2020-02-25 17:50:21.424745: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.424886: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.425024: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer3_conv1_1_conv2d_bn_batch_normalization_1_cond_1_true_875
2020-02-25 17:50:21.425204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-25 17:50:21.425344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.425487: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: test_model2layer4_conv1_conv2d_bn_batch_normalization_2_cond_false_623
2020-02-25 17:50:21.425668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-25 17:50:21.425810: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
Traceback (most recent call last):
  File "C:/Users/stars_ocean/Desktop/TensorFlow_test_folder/new_tf_模型保存_进阶4.py", line 57, in &lt;module&gt;
	tflite_model = converter.convert()
  File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\lite\python\lite.py", line 423, in convert
	self._funcs[0], lower_control_flow=False)
  File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\convert_to_constants.py", line 437, in convert_variables_to_constants_v2
	tensor_data = _get_tensor_data(func)
  File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\convert_to_constants.py", line 209, in _get_tensor_data
	data = val_tensor.numpy()
AttributeError: 'Tensor' object has no attribute 'numpy'

Process finished with exit code 1
&lt;/denchmark-code&gt;

After debugging, it was found that the problem is that the val_tensor variable at line 209 of convert_to_constants.py is keras_learning_phase, it is not a tensor, so there is no numpy () method.
So in this case, if you want to nest the Model and save it as a tflite file, what should you do?
	</description>
	<comments>
		<comment id='1' author='TCBocean' date='2020-02-26T00:51:39Z'>
		In addition, I saved the model in SaveModel format and I got the following error:
&lt;denchmark-code&gt;If using Keras pass *_constraint arguments to layers.
Traceback (most recent call last):
  File "C:/Users/stars_ocean/Desktop/TensorFlow_test_folder/new_tf_模型保存_进阶4.py", line 57, in &lt;module&gt;
    tf.saved_model.save(model, "./save4")
  File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\saved_model\save.py", line 909, in save
    meta_graph_def, saveable_view, signatures, options.namespace_whitelist)
  File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\saved_model\save.py", line 553, in _fill_meta_graph_def
    object_map, resource_map, asset_info = saveable_view.map_resources()
  File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\saved_model\save.py", line 285, in map_resources
    "supported.").format(concrete_function.name, capture))
ValueError: Attempted to save a function b'__inference__wrapped_model_797' which references a symbolic Tensor Tensor("keras_learning_phase:0", shape=(), dtype=bool) that is not a simple constant. This is not supported.
&lt;/denchmark-code&gt;

So is it not supported to save nested custom keras models?
		</comment>
		<comment id='2' author='TCBocean' date='2020-02-26T02:52:47Z'>
		I seem to find the problem, the main problem is reflected in the BN layer. I deleted the BN layer and was able to save the model correctly.
&lt;denchmark-code&gt;import tensorflow as tf


class Conv2d_BN(tf.keras.layers.Layer):
    def __init__(self, filters, kernel_size, strides, padding, is_use_bias=True, name=None):
        super(Conv2d_BN, self).__init__(name=name)
        self.conv2d = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides,
                                             padding=padding, use_bias=is_use_bias, kernel_initializer=tf.ones)
        # self.bn = tf.keras.layers.BatchNormalization(name=name+"/bn")

    @tf.function
    def call(self, inputs):
        output = self.conv2d(inputs)
        # output = self.bn(output)
        return output


class test_model2(tf.keras.Model):
    def __init__(self, layer_name, layer_filters, name="test_model2"):
        super(test_model2, self).__init__(name=name)
        self.convs = []
        for n, f in zip(layer_name, layer_filters):
            if "2" in n:
                continue
            self.convs.append(Conv2d_BN(filters=f, kernel_size=1, strides=(1,1), padding="valid", is_use_bias=False,
                                        name=self.name + "/" + n + "/conv1"))
        self.empty_layer = None

    @tf.function
    def call(self, inputs):
        output1 = inputs[0]
        for c_layer in self.convs:
            output1 = c_layer(output1)

        output2 = inputs[1]
        for c_layer in self.convs:
            output2 = c_layer(output2)
        if self.empty_layer is None:
            print("None")
        return output1, output2


layer_name = ["layer1", "layer2", "layer3", "layer4", "layer5"]
layer_filters = [3, 4, 5, 6, 7]
model = test_model2(layer_name, layer_filters)
test_input1 = tf.ones((1, 2, 2, 1))
test_input2 = tf.zeros((1, 2, 2, 1))
input_list = [test_input1, test_input2]
# tf.keras.backend.set_learning_phase(True)
test_output1, test_output2 = model(input_list)
print(test_output1)
print(test_output2)
model._set_inputs(input_list)

# tf.saved_model.save(model, "./save4")


converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open("./save4/converted_model.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

In addition, I also found that the keras_learning_phase variable also seems to come from the BN layer. As long as I set tf.keras.backend.set_learning_phase (True) or set it to False can avoid this error. But then another error occurred.
&lt;denchmark-code&gt;import tensorflow as tf


class Conv2d_BN(tf.keras.layers.Layer):
    def __init__(self, filters, kernel_size, strides, padding, is_use_bias=True, name=None):
        super(Conv2d_BN, self).__init__(name=name)
        self.conv2d = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides,
                                             padding=padding, use_bias=is_use_bias, kernel_initializer=tf.ones)
        self.bn = tf.keras.layers.BatchNormalization(name=name+"/bn")

    @tf.function
    def call(self, inputs):
        output = self.conv2d(inputs)
        output = self.bn(output)
        return output


class test_model2(tf.keras.Model):
    def __init__(self, layer_name, layer_filters, name="test_model2"):
        super(test_model2, self).__init__(name=name)
        self.convs = []
        for n, f in zip(layer_name, layer_filters):
            if "2" in n:
                continue
            self.convs.append(Conv2d_BN(filters=f, kernel_size=1, strides=(1,1), padding="valid", is_use_bias=False,
                                        name=self.name + "/" + n + "/conv1"))
        self.empty_layer = None

    @tf.function
    def call(self, inputs):
        output1 = inputs[0]
        for c_layer in self.convs:
            output1 = c_layer(output1)

        output2 = inputs[1]
        for c_layer in self.convs:
            output2 = c_layer(output2)
        if self.empty_layer is None:
            print("None")
        return output1, output2


layer_name = ["layer1", "layer2", "layer3", "layer4", "layer5"]
layer_filters = [3, 4, 5, 6, 7]
model = test_model2(layer_name, layer_filters)
test_input1 = tf.ones((1, 2, 2, 1))
test_input2 = tf.zeros((1, 2, 2, 1))
input_list = [test_input1, test_input2]
tf.keras.backend.set_learning_phase(True)
test_output1, test_output2 = model(input_list)
print(test_output1)
print(test_output2)
model._set_inputs(input_list)

# tf.saved_model.save(model, "./save4")


converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open("./save4/converted_model.tflite", "wb").write(tflite_model)

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\lite\python\lite.py", line 423, in convert
   self._funcs[0], lower_control_flow=False)
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\convert_to_constants.py", line 622, in convert_variables_to_constants_v2
   converted_input_indices)
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\convert_to_constants.py", line 398, in _construct_concrete_function
   new_output_names)
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\eager\wrap_function.py", line 631, in function_from_graph_def
   wrapped_import = wrap_function(_imports_graph_def, [])
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\eager\wrap_function.py", line 609, in wrap_function
   collections={}),
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\func_graph.py", line 978, in func_graph_from_py_func
   func_outputs = python_func(*func_args, **func_kwargs)
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\eager\wrap_function.py", line 85, in __call__
   return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\eager\wrap_function.py", line 91, in wrapped
   return fn(*args, **kwargs)
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\eager\wrap_function.py", line 629, in _imports_graph_def
   importer.import_graph_def(graph_def, name="")
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\util\deprecation.py", line 507, in new_func
   return func(*args, **kwargs)
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\importer.py", line 405, in import_graph_def
   producer_op_list=producer_op_list)
 File "C:\software\Anaconda3\envs\TF2_1_GPU\lib\site-packages\tensorflow_core\python\framework\importer.py", line 501, in _import_graph_def_internal
   raise ValueError(str(e))
ValueError: Input 1 of node test_model2/StatefulPartitionedCall/test_model2/layer1/conv1/StatefulPartitionedCall/test_model2/layer1/conv1/bn/cond was passed resource from Func/test_model2/StatefulPartitionedCall/test_model2/layer1/conv1/StatefulPartitionedCall/input/_29:0 incompatible with expected float.

Process finished with exit code 1

&lt;/denchmark-code&gt;

This error still comes from the BN layer. What is the correct way to use the BN layer? How can I properly save to tflite format?
		</comment>
		<comment id='3' author='TCBocean' date='2020-02-26T03:19:17Z'>
		I tried to convert the model to SaveModel format, and then converted to tflite format also had the same error.
		</comment>
		<comment id='4' author='TCBocean' date='2020-02-26T09:47:40Z'>
		I tried to write a simple BN layer by myself without any parameters such as renorm, virtual_batch_size. My BN layer only uses fused, and changed tf_utils.smart_cond to if ... else. It can be converted to tflite format normally, so I guess tflite and tf.keras.layers.BatchNormalization are not compatible.
The following is the BN layer code I wrote. I have only briefly tested that its output is normal. I have not tested whether it performs normally during training.
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.python.keras import initializers
from tensorflow.python.keras import regularizers
from tensorflow.python.keras import constraints
from tensorflow.python.framework import dtypes
from tensorflow.python.keras import backend as K
from tensorflow.python.ops import variables as tf_variables
from tensorflow.python.keras.engine.input_spec import InputSpec
from tensorflow.python.keras.utils import tf_utils


class BatchNorm(tf.keras.layers.Layer):
    def __init__(self,
                 axis=-1,
                 momentum=0.99,
                 epsilon=1e-3,
                 center=True,
                 scale=True,
                 beta_initializer='zeros',
                 gamma_initializer='ones',
                 moving_mean_initializer='zeros',
                 moving_variance_initializer='ones',
                 beta_regularizer=None,
                 gamma_regularizer=None,
                 beta_constraint=None,
                 gamma_constraint=None,
                 trainable=True,
                 virtual_batch_size=None,
                 name=None,
                 **kwargs):
        super(BatchNorm, self).__init__(
            name=name, **kwargs)
        if isinstance(axis, list):
            self.axis = axis[:]
        elif isinstance(axis, int):
            self.axis = axis
        else:
            raise TypeError('axis must be int or list, type given: %s'
                            % type(axis))
        self.momentum = momentum
        self.epsilon = epsilon
        self.center = center
        self.scale = scale
        self.beta_initializer = initializers.get(beta_initializer)
        self.gamma_initializer = initializers.get(gamma_initializer)
        self.moving_mean_initializer = initializers.get(moving_mean_initializer)
        self.moving_variance_initializer = initializers.get(
            moving_variance_initializer)
        self.beta_regularizer = regularizers.get(beta_regularizer)
        self.gamma_regularizer = regularizers.get(gamma_regularizer)
        self.beta_constraint = constraints.get(beta_constraint)
        self.gamma_constraint = constraints.get(gamma_constraint)
        self.virtual_batch_size = virtual_batch_size

        self.fused = True
        self._bessels_correction_test_only = True
        self._trainable_var = None
        self.trainable = trainable

    def build(self, input_shape):
        if not input_shape.ndims:
            raise ValueError('Input has undefined rank:', input_shape)
        ndims = len(input_shape)

        # Convert axis to list and resolve negatives
        if isinstance(self.axis, int):
            self.axis = [self.axis]

        for idx, x in enumerate(self.axis):
            if x &lt; 0:
                self.axis[idx] = ndims + x

        # Validate axes
        for x in self.axis:
            if x &lt; 0 or x &gt;= ndims:
                raise ValueError('Invalid axis: %d' % x)
        if len(self.axis) != len(set(self.axis)):
            raise ValueError('Duplicate axis: %s' % self.axis)

        if self.virtual_batch_size is not None:
            if self.virtual_batch_size &lt;= 0:
                raise ValueError('virtual_batch_size must be a positive integer that '
                                 'divides the true batch size of the input Tensor')
            # If using virtual batches, the first dimension must be the batch
            # dimension and cannot be the batch norm axis
            if 0 in self.axis:
                raise ValueError('When using virtual_batch_size, the batch dimension '
                                 'must be 0 and thus axis cannot include 0')

        if self.fused:
            if self.axis == [1]:
                self._data_format = 'NCHW'
            elif self.axis == [3]:
                self._data_format = 'NHWC'
            else:
                raise ValueError('Unsupported axis, fused batch norm only supports '
                                 'axis == [1] or axis == [3]')

        axis_to_dim = {x: input_shape.dims[x].value for x in self.axis}
        for x in axis_to_dim:
            if axis_to_dim[x] is None:
                raise ValueError('Input has undefined `axis` dimension. Input shape: ',
                                 input_shape)
        self.input_spec = InputSpec(ndim=ndims, axes=axis_to_dim)

        if len(axis_to_dim) == 1 and self.virtual_batch_size is None:
            # Single axis batch norm (most common/default use-case)
            param_shape = (list(axis_to_dim.values())[0],)
        else:
            # Parameter shape is the original shape but with 1 in all non-axis dims
            param_shape = [axis_to_dim[i] if i in axis_to_dim else 1 for i in range(ndims)]
            if self.virtual_batch_size is not None:
                # When using virtual batches, add an extra dim at index 1
                param_shape.insert(1, 1)
                for idx, x in enumerate(self.axis):
                    self.axis[idx] = x + 1  # Account for added dimension

        if self.scale:
            self.gamma = self.add_weight(
                name='gamma',
                shape=param_shape,
                dtype=self._param_dtype,
                initializer=self.gamma_initializer,
                regularizer=self.gamma_regularizer,
                constraint=self.gamma_constraint,
                trainable=True,
                experimental_autocast=False)
        else:
            self.gamma = None
            if self.fused:
                self._gamma_const = K.constant(1.0, dtype=self._param_dtype, shape=param_shape)

        if self.center:
            self.beta = self.add_weight(
                name='beta',
                shape=param_shape,
                dtype=self._param_dtype,
                initializer=self.beta_initializer,
                regularizer=self.beta_regularizer,
                constraint=self.beta_constraint,
                trainable=True,
                experimental_autocast=False)
        else:
            self.beta = None
            if self.fused:
                self._beta_const = K.constant(0.0, dtype=self._param_dtype, shape=param_shape)

        # Disable variable partitioning when creating the moving mean and variance
        self.moving_mean = self.add_weight(
            name='moving_mean',
            shape=param_shape,
            dtype=self._param_dtype,
            initializer=self.moving_mean_initializer,
            synchronization=tf_variables.VariableSynchronization.ON_READ,
            trainable=False,
            aggregation=tf_variables.VariableAggregation.MEAN,
            experimental_autocast=False)

        self.moving_variance = self.add_weight(
            name='moving_variance',
            shape=param_shape,
            dtype=self._param_dtype,
            initializer=self.moving_variance_initializer,
            synchronization=tf_variables.VariableSynchronization.ON_READ,
            trainable=False,
            aggregation=tf_variables.VariableAggregation.MEAN,
            experimental_autocast=False)
        self.built = True

    def call(self, inputs, training=None):
        training = self._get_training_value(training)
        if self.fused:
            outputs = self._fused_batch_norm(inputs, training=training)
            return outputs

    def _get_training_value(self, training=None):
        if training is None:
            training = K.learning_phase()

        if isinstance(training, int):
            training = bool(training)
        return training

    def _fused_batch_norm(self, inputs, training):
        """Returns the output of fused batch norm."""
        beta = self.beta if self.center else self._beta_const
        gamma = self.gamma if self.scale else self._gamma_const

        inputs_size = None

        def _fused_batch_norm_training():
            return tf.compat.v1.nn.fused_batch_norm(
                inputs,
                gamma,
                beta,
                epsilon=self.epsilon,
                data_format=self._data_format)

        def _fused_batch_norm_inference():
            return tf.compat.v1.nn.fused_batch_norm(
                inputs,
                gamma,
                beta,
                mean=self.moving_mean,
                variance=self.moving_variance,
                epsilon=self.epsilon,
                is_training=False,
                data_format=self._data_format)

        if training:
            output, mean, variance = _fused_batch_norm_training()
        else:
            output, mean, variance = _fused_batch_norm_inference()

        training_value = tf_utils.constant_value(training)
        if training_value is None:
            if training:
                momentum = self.momentum
            else:
                momentum = 1.0
        else:
            momentum = tf.convert_to_tensor(self.momentum)
        if training_value or training_value is None:
            def mean_update():
                return self._assign_moving_average(self.moving_mean, mean, momentum,
                                                   inputs_size)

            def variance_update():
                return self._assign_moving_average(self.moving_variance, variance,
                                                   momentum, inputs_size)

            self.add_update(mean_update)
            self.add_update(variance_update)

        return output

    def _assign_moving_average(self, variable, value, momentum, inputs_size):
        decay = tf.convert_to_tensor(1.0 - momentum, name='decay')
        if decay.dtype != variable.dtype.base_dtype:
            decay = tf.cast(decay, variable.dtype.base_dtype)
        update_delta = (variable - tf.cast(value, variable.dtype)) * decay
        return tf.compat.v1.assign_sub(variable, update_delta)

    @property
    def _param_dtype(self):
        # Raise parameters of fp16 batch norm to fp32
        if self.dtype == dtypes.float16 or self.dtype == dtypes.bfloat16:
            return dtypes.float32
        else:
            return self.dtype or dtypes.float32
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='TCBocean' date='2020-02-28T10:07:10Z'>
		I added my custom BN layer to MobileNetV3 and trained with ImageNet. I found that my custom BN layer did not seem to affect the convergence performance of the model.
However, the original bug has not been resolved, so I do not intend to close this issue.
		</comment>
		<comment id='6' author='TCBocean' date='2020-03-05T20:58:22Z'>
		&lt;denchmark-link:https://github.com/TCBocean&gt;@TCBocean&lt;/denchmark-link&gt;
 You have described multiple issues here. Can you please separate the issues so that it will be easy for the community to follow your issue?  It will be easy for us to resolve issues faster if they are focused on one topic in each post.
Also, in each of the post, provide standalone code and also full error trace. Adding links to colab would be very helpful (but not required). Also, check with recently , some of the issue related to  were resolved in the . Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/7390fea36d8257122a97a3036a99adc6/untitled861.ipynb&gt;gist here&lt;/denchmark-link&gt;
 for the last-but-one-code that works without any error. Thanks!
		</comment>
		<comment id='7' author='TCBocean' date='2020-03-07T00:58:25Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Thanks for your advice.
		</comment>
		<comment id='8' author='TCBocean' date='2020-03-07T00:58:27Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37043&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37043&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>