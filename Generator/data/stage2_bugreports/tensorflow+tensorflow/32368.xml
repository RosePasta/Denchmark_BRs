<bug id='32368' author='nguerinjr' open_date='2019-09-09T21:18:53Z' closed_time='2019-10-01T17:05:54Z'>
	<summary>Problem in tensorboard callback</summary>
	<description>
-&gt; tf-nightly-gpu-2.0-preview==2.0.0.dev20190909
-&gt; Python 3.7.4 (default, Jul  9 2019, 03:52:42)  [GCC 5.4.0 20160609] on linux
-&gt; Ubuntu 16.04 LTS
-&gt; Geforce GTX 1080 Ti
I have an autoencoder with Tensorboard callback and tf.datasets (whose code I've omitted here, since the iteration on the patches are working)
tensorboard = tf.keras.callbacks.TensorBoard(log_dir=str(output_folder / 'logs'), histogram_freq=1, write_graph=True, update_freq=500)
checkpoints = tf.keras.callbacks.ModelCheckpoint(str(output_folder / 'checkpoints'/ 'val_loss{val_loss:.3g}-epoch{epoch:02d}-loss{loss:.3g}'), verbose=1, save_best_only=True, mode='min', monitor='val_loss', save_freq='epoch')

train_iter = create_db_loader(get_file_paths(g_dict['run_glob']), g_dict['train'])
valid_iter = create_db_loader(get_file_paths(g_dict['val_glob']), 0)

autoencoder.fit(x=train_iter, y=None, validation_data=valid_iter, epochs=g_dict['epochs'], steps_per_epoch=g_dict['steps_per_epoch'], validation_steps=g_dict['validation_steps'], validation_freq=1, callbacks=[tensorboard, checkpoints])
Apparently, everything runs ok
Train for 1000 steps, validate for 100 steps
Epoch 1/10
2019-09-09 17:33:56.224374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-09-09 17:33:56.979317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-09-09 17:33:57.194187: I tensorflow/core/profiler/lib/profiler_session.cc:206] Profiler session started.
2019-09-09 17:33:57.194313: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.0'; dlerror: libcupti.so.10.0: cannot open shared object file: No such file or directory
2019-09-09 17:33:57.194322: W tensorflow/core/profiler/lib/profiler_session.cc:214] Encountered error while starting profiler: Unavailable: CUPTI error: CUPTI could not be loaded or symbol could not be found.
   1/1000 [..............................] - ETA: 27:33 - loss: 0.21982019-09-09 17:33:57.202954: I tensorflow/core/platform/default/device_tracer.cc:590] Collecting 0 kernel records, 0 memcpy records.
2019-09-09 17:33:57.203136: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.
 993/1000 [============================&gt;.] - ETA: 0s - loss: 0.0086
Epoch 00001: loss improved from inf to 0.00862, saving model to ../output/run0/checkpoints/val_loss0.00754-epoch01-loss0.00862
2019-09-09 17:34:04.410966: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /home/nguerinjr/Documents/deep_coding_project/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1782: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
1000/1000 [==============================] - 9s 9ms/step - loss: 0.0086 - val_loss: 0.0075
Epoch 2/10
 998/1000 [============================&gt;.] - ETA: 0s - loss: 0.0077
Epoch 00002: loss improved from 0.00862 to 0.00767, saving model to ../output/run0/checkpoints/val_loss0.00718-epoch02-loss0.00767
1000/1000 [==============================] - 8s 8ms/step - loss: 0.0077 - val_loss: 0.0072
Epoch 3/10
 993/1000 [============================&gt;.] - ETA: 0s - loss: 0.0065
Epoch 00003: loss improved from 0.00767 to 0.00646, saving model to ../output/run0/checkpoints/val_loss0.00623-epoch03-loss0.00646
1000/1000 [==============================] - 8s 8ms/step - loss: 0.0065 - val_loss: 0.0062
Epoch 4/10
 995/1000 [============================&gt;.] - ETA: 0s - loss: 0.0052
Epoch 00004: loss improved from 0.00646 to 0.00524, saving model to ../output/run0/checkpoints/val_loss0.00642-epoch04-loss0.00524
1000/1000 [==============================] - 8s 8ms/step - loss: 0.0052 - val_loss: 0.0064
Epoch 5/10
 993/1000 [============================&gt;.] - ETA: 0s - loss: 0.0062
Epoch 00005: loss did not improve from 0.00524
1000/1000 [==============================] - 7s 7ms/step - loss: 0.0061 - val_loss: 0.0056
Epoch 6/10
 992/1000 [============================&gt;.] - ETA: 0s - loss: 0.4702
Epoch 00006: loss did not improve from 0.00524
1000/1000 [==============================] - 7s 7ms/step - loss: 0.4728 - val_loss: 0.7266
Epoch 7/10
 999/1000 [============================&gt;.] - ETA: 0s - loss: 0.7511
Epoch 00007: loss did not improve from 0.00524
1000/1000 [==============================] - 7s 7ms/step - loss: 0.7511 - val_loss: 0.7195
Epoch 8/10
 994/1000 [============================&gt;.] - ETA: 0s - loss: 0.7476
Epoch 00008: loss did not improve from 0.00524
1000/1000 [==============================] - 7s 7ms/step - loss: 0.7476 - val_loss: 0.7171
Epoch 9/10
 994/1000 [============================&gt;.] - ETA: 0s - loss: 0.7546
Epoch 00009: loss did not improve from 0.00524
1000/1000 [==============================] - 7s 7ms/step - loss: 0.7517 - val_loss: 0.2810
Epoch 10/10
 998/1000 [============================&gt;.] - ETA: 0s - loss: 0.2786
Epoch 00010: loss did not improve from 0.00524
1000/1000 [==============================] - 7s 7ms/step - loss: 0.2786 - val_loss: 0.2764
However, tensorboard simply doesn't show the activations:
&lt;denchmark-link:https://user-images.githubusercontent.com/35977339/64565143-80d3e100-d329-11e9-83d4-bb4bf323f16f.png&gt;&lt;/denchmark-link&gt;

write_images=True is not working either.
So, is there anything wrong with this piece of code? Or is it a bug?
Another thing: why isn't there a write_grads option in 2.0? I've seen a message in 1.x saying it's not supported with eager execution enabled. Is there a special reason for this removal?
I was trying to use as much functionalities as I could from keras default routines, for fast prototyping. Being capable of printing the gradients is a good thing, specially using the fit method.
It seems I'll have to implement a manual iteration loop.
	</description>
	<comments>
		<comment id='1' author='nguerinjr' date='2019-09-16T16:40:58Z'>
		&lt;denchmark-link:https://github.com/nguerinjr&gt;@nguerinjr&lt;/denchmark-link&gt;
 Can you please share a github gist of this issue. Thanks!
		</comment>
		<comment id='2' author='nguerinjr' date='2019-10-01T17:05:54Z'>
		Closing this issue as it has been inactive for more than 15 days. Please add additional comments and we can open the issue again. Thanks!
		</comment>
		<comment id='3' author='nguerinjr' date='2019-10-01T17:05:56Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=32368&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=32368&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>