<bug id='30951' author='Binpord' open_date='2019-07-23T10:38:46Z' closed_time='2020-02-28T18:59:35Z'>
	<summary>Missing input after saving/loading Keras Model</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 1.12.0
Python version: 2.7.12
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.0
GPU model and memory: GeForce FTX 1080

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 

I am using &lt;denchmark-link:https://keras.io/getting-started/functional-api-guide/&gt;keras functional API&lt;/denchmark-link&gt;
 to create a model. During training it has 2 inputs - one is actual input and second one is ground truth mask, I am applying using  layer (see code example). When saving the model (not the weights) (via  callback or manually) and loading it via  I get model without second input.
Describe the expected behavior
Model has both inputs after loading.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow import keras
import numpy as np


input_size = 30
output_size = 10

inp = keras.layers.Input((input_size,))
mask = keras.layers.Input((output_size,), dtype=tf.bool)

x = keras.layers.Dense(output_size)(inp)
x = keras.layers.Lambda(lambda x: x, mask=mask)(x)

model = keras.models.Model(inputs=[inp, mask], outputs=[x])
model.compile(loss='mean_squared_error', optimizer='sgd')

print('Model inputs: {}'.format(model.inputs)) # Prints: "Model inputs: [&lt;tf.Tensor 'input_1:0' shape=(?, 30) dtype=float32&gt;, &lt;tf.Tensor 'input_2:0' shape=(?, 10) dtype=bool&gt;]"

batch_size = 20
x_train = np.random.rand(batch_size, input_size)
y_train = np.random.rand(batch_size, output_size)
y_train_mask = np.random.rand(batch_size, output_size)
y_train_mask = y_train_mask &gt; .5

model.fit([x_train, y_train_mask], y_train)

checkpoint = './model.h5'
model.save(checkpoint)

model = keras.models.load_model(checkpoint)
print('Model inputs: {}'.format(model.inputs)) # Prints: "Model inputs: [&lt;tf.Tensor 'input_1_1:0' shape=(?, 30) dtype=float32&gt;]"
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='Binpord' date='2019-07-24T09:06:37Z'>
		I was able to reproduce the issue with TF version 1.12.
Please find Colab &lt;denchmark-link:https://colab.research.google.com/gist/oanush/8ef6232c7efe46a022abc644180188c5/30951.ipynb&gt;Gist&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='Binpord' date='2019-07-29T17:04:10Z'>
		Another thing to consider: running the exact code snippet with TF version 1.14 (built from source, git tag 1.14 with Bazel 0.25.2 on Mac OS, running with miniconda python 3.7.3) I get an unhandled exception in compile method:
&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0729 19:48:53.413664 4525299136 deprecation.py:506] From /Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Traceback (most recent call last):
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1864, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 10 for 'loss/lambda_loss/weighted_loss/Squeeze' (op: 'Squeeze') with input shapes: [?,10].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "example.py", line 16, in &lt;module&gt;
    model.compile(loss='mean_squared_error', optimizer='sgd')
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 337, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 1710, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 1774, in _prepare_total_loss
    reduction=losses_utils.ReductionV2.NONE)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py", line 199, in compute_weighted_loss
    losses, None, sample_weight)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py", line 101, in squeeze_or_expand_dimensions
    sample_weight = array_ops.squeeze(sample_weight, [-1])
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 180, in wrapper
    return target(*args, **kwargs)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 3162, in squeeze
    return gen_array_ops.squeeze(input, axis, name)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py", line 9666, in squeeze
    "Squeeze", input=input, squeeze_dims=axis, name=name)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py", line 788, in _apply_op_helper
    op_def=op_def)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 3616, in create_op
    op_def=op_def)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 2027, in __init__
    control_input_ops)
  File "/Users/binpord/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1867, in _create_c_op
    raise ValueError(str(e))
ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for 'loss/lambda_loss/weighted_loss/Squeeze' (op: 'Squeeze') with input shapes: [?,10].
&lt;/denchmark-code&gt;

This means, that I am doing something wrong. I tried debugging the issue, but got completely confused with all the abstraction levels. What I succeeded in grasping is, compile calls losses_utils.compute_weighted_loss function, which tries to equalise losses and sample_weight dimensions. Ok, the fact that output mask ends up in something called sample_weight seems already weird enough to me. Moreover, it completely fails, as losses has shape of (None, 1) (the mean squared error loss) and the sample_weight has shape of (None, 10), hence cannot be squashed.
How I see it, output mask should work this way: NN predicts some tensor (vector of 10 elements in the snippet) and mask should point to elements in this vector, which should be excluded from loss computation. However, this seems not to be the case. What am I doing wrong?
In actual use case, I am interested in, I try to predict some 2D image-like tensor and I would like to mask loss in some areas, where prediction is meaningless and, hence, should not affect training. Maybe I should use some other mechanism instead of Lambda layer mask?
		</comment>
		<comment id='3' author='Binpord' date='2020-02-28T18:59:35Z'>
		&lt;denchmark-link:https://github.com/Binpord&gt;@Binpord&lt;/denchmark-link&gt;
 Thanks for the issue!
There seem to be some errors with how the Model was constructed, this worked for me though:
import tensorflow as tf
from tensorflow import keras
import numpy as np


input_size = 30
output_size = 10

inp = keras.layers.Input((input_size,))
mask = keras.layers.Input((output_size,), dtype=tf.bool)
x = keras.layers.Dense(output_size)(inp)
x = x * tf.cast(mask, dtype=tf.float32)

model = keras.models.Model(inputs=[inp, mask], outputs=x)
model.compile(loss='mean_squared_error', optimizer='sgd')

print('Model inputs: {}'.format(model.inputs)) # Prints: "Model inputs: [&lt;tf.Tensor 'input_1:0' shape=(?, 30) dtype=float32&gt;, &lt;tf.Tensor 'input_2:0' shape=(?, 10) dtype=bool&gt;]"

batch_size = 20
x_train = np.random.rand(batch_size, input_size)
y_train = np.random.rand(batch_size, output_size)
y_train_mask = np.random.rand(batch_size, output_size)
y_train_mask = y_train_mask &gt; .5

model.fit([x_train, y_train_mask], y_train)

checkpoint = './model.h5'
model.save(checkpoint)

model = keras.models.load_model(checkpoint)
print('Model inputs: {}'.format(model.inputs))
Closing as I think the issue was in the model construction
		</comment>
		<comment id='4' author='Binpord' date='2020-02-28T18:59:36Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30951&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30951&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>