<bug id='6039' author='flash1293' open_date='2016-12-02T09:35:24Z' closed_time='2017-02-13T17:58:23Z'>
	<summary>Precision of reduce_sum operation</summary>
	<description>
There seems to be a numerical precision problem with the reduce_sum operation, see the example provided below. Even though everything is set to float32 as datatype tensorflow produces a much more imprecise result than numpy (whose result is numerically exact).
Is this intended? It seems strange that tensorflow makes such serious numerical errors. Am I doing something wrong?
&lt;denchmark-h:h3&gt;What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?&lt;/denchmark-h&gt;

nothing there to my knowledge
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: Mac OSX 10.12.1
Tensorflow 0.11.0 CPU
&lt;denchmark-link:https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl&gt;https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl&lt;/denchmark-link&gt;

could be reproduced in docker-container tensorflow/tensorflow:0.12.0-rc0 in a virtualbox linux vm
&lt;denchmark-h:h3&gt;If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)&lt;/denchmark-h&gt;

import tensorflow as tf
import numpy as np

data = tf.constant(1.23456, shape=[250,250], dtype=tf.float32)
sum = tf.reduce_sum(data)
sess = tf.Session()
sess.run(sum) #77151.477

data2 = np.full([250, 250], np.float32(1.23456), dtype=np.float32)
np.sum(data2) #77160
&lt;denchmark-link:https://gist.github.com/flash1293/84c2719dd646c0314ec0f4ea05df117a&gt;https://gist.github.com/flash1293/84c2719dd646c0314ec0f4ea05df117a&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;What other attempted solutions have you tried?&lt;/denchmark-h&gt;




&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;




	</description>
	<comments>
		<comment id='1' author='flash1293' date='2016-12-02T19:17:21Z'>
		I believe numpy implements a better (as in more numerically accurate) algorithm for sum as per this: &lt;denchmark-link:https://github.com/numpy/numpy/pull/3685&gt;numpy/numpy#3685&lt;/denchmark-link&gt;

I would prefer not to say that numpy's result is exact however.  Exactness when dealing with floating point is very hard :)
The gpu version of tensorflow sum should be just as numerically stable.  The CPU version unfortunately is implemented in the naive way with a single accumulator.  I'll let Benoit comment on the likelihood of this improving.  A quick hack might be to use a 64-bit accumulator even if the input is 32-bit.
		</comment>
		<comment id='2' author='flash1293' date='2016-12-02T19:56:49Z'>
		Thanks for the insight - &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/2625&gt;#2625&lt;/denchmark-link&gt;
 is related to this.
By exact I meant exact in the provided example.
		</comment>
		<comment id='3' author='flash1293' date='2016-12-03T22:38:44Z'>
		Same as &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/5527&gt;#5527&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='4' author='flash1293' date='2016-12-05T05:55:32Z'>
		&lt;denchmark-link:https://github.com/ppwwyyxx&gt;@ppwwyyxx&lt;/denchmark-link&gt;
 yes, this is the same problem.
		</comment>
		<comment id='5' author='flash1293' date='2017-02-13T17:58:23Z'>
		Closing this issue as it is a dupe  of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/5527&gt;#5527&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>