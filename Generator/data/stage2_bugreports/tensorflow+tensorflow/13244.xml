<bug id='13244' author='sushanthku' open_date='2017-09-22T19:30:17Z' closed_time='2018-01-04T01:59:19Z'>
	<summary>BUG:Memory leak in tf.string_split</summary>
	<description>
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1325612/profile_9734.0066.txt&gt;profile_9734.0066.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1325613/profile_9734.0100.txt&gt;profile_9734.0100.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1325611/profile_9734.0150.txt&gt;profile_9734.0150.txt&lt;/denchmark-link&gt;

Please go to Stack Overflow for help and support:
&lt;denchmark-link:https://stackoverflow.com/questions/tagged/tensorflow&gt;https://stackoverflow.com/questions/tagged/tensorflow&lt;/denchmark-link&gt;

If you open a GitHub issue, here is our policy:

It must be a bug or a feature request.
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.

Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Centos Linux version 3.10.0-229.4.2.el7.x86_64 (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) )
TensorFlow installed from (source or binary): pip install tensorflow
TensorFlow version (use command below): tensorflow==1.3.0
Python version: Python 2.7.5
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A (CPU only)
GPU model and memory: N/A
Exact command to reproduce:

You can collect some of this information using our environment capture script:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&lt;/denchmark-link&gt;

You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I am seeing noticeably large memory usage when I use tf.string_split  within the map function of a dataset API.  I have attached a sample code below. I tried to do a heap analysis and I see std::basic_string::_Rep::_S_create constantly growing in size and not freeing up its memory.
If i remove the tf.string_split and just return the line as is, there is no memory held over. This issue is a blocker for us to scale up the tensorflow pipeline to large datasets.
I have attached three output files of pprof over time .
6447.1  96.8%  96.8%   6447.1  96.8% std::basic_string::_Rep::_S_create
  9765.5  96.5%  96.5%   9765.5  96.5% std::basic_string::_Rep::_S_create
 14704.7  95.5%  95.5%  14704.7  95.5% std::basic_string::_Rep::_S_create
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf

def mapper(line):
    line = tf.identity(line)
    tokens = tf.string_split(line, delimiter='\t')
    return tokens.indices

def run():
    filenames = "sample.txt"
    # Cluster spec
    cluster = tf.train.ClusterSpec({
        "worker": ["localhost:2223"]
    })
    server = tf.train.Server(cluster, job_name="worker", task_index=0)

    dataset = tf.contrib.data.TextLineDataset(filenames)
    dataset = dataset.batch(1000)
    dataset = dataset.map(mapper, 8).repeat()
    iterator = dataset.make_one_shot_iterator()
    next_element = iterator.get_next()

    with tf.Session(target=server.target) as session:
        while True:
            try:
                session.run(next_element)
            except tf.errors.OutOfRangeError:
                break
run()
&lt;/denchmark-code&gt;

#You can run this script by
LD_PRELOAD=/usr/lib64/libtcmalloc.so.4 HEAPPROFILE=/tmp/profile nohup python -u bug.py &gt; output.log &amp;
	</description>
	<comments>
		<comment id='1' author='sushanthku' date='2017-09-29T03:14:52Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
, do you have any insight into this. Does the dataset pipeline hold string data in some special way?
		</comment>
		<comment id='2' author='sushanthku' date='2017-09-29T03:26:12Z'>
		The dataset pipeline doesn't do anything special with strings, and relies on tensorflow::Tensor refcounting to release the data.
&lt;denchmark-link:https://github.com/sushanthku&gt;@sushanthku&lt;/denchmark-link&gt;
 Can you try making a  string from a representative line in your file, and running  on that constant in a loop to see if the memory growth is similar?
		</comment>
		<comment id='3' author='sushanthku' date='2017-12-20T01:12:45Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue? Please update the label and/or status accordingly.
		</comment>
		<comment id='4' author='sushanthku' date='2018-01-03T19:15:47Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue? Please update the label and/or status accordingly.
		</comment>
		<comment id='5' author='sushanthku' date='2018-01-04T01:59:19Z'>
		Closing due to lack of activity. &lt;denchmark-link:https://github.com/sushanthku&gt;@sushanthku&lt;/denchmark-link&gt;
 Feel free to reopen if you can pare this down to a self-contained reproduction.
		</comment>
	</comments>
</bug>