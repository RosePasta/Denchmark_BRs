<bug id='36804' author='huanyingjun' open_date='2020-02-17T01:34:07Z' closed_time='2020-02-25T20:50:04Z'>
	<summary>TFlite got error output when enable hexagon delegate</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): - OS Platform and Distribution (
Linux Ubuntu 16.04): - Mobile device (OPPO reno ace) if
the issue happens on mobile device: - TensorFlow installed from (source or
binary): - TensorFlow version (use command below): - Python version: - Bazel
version (if compiling from source): - GCC/Compiler version (if compiling from
source): - CUDA/cuDNN version: - GPU model and memory:
You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 

I use this model for testing: &lt;denchmark-link:https://storage.googleapis.com/mirror.tensorflow.org/storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip&gt;https://storage.googleapis.com/mirror.tensorflow.org/storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip&lt;/denchmark-link&gt;

I set all input values as 1(just for tesing), then print the first 50 values of output[0], see below picture, on the left is the values when running on CPU, on the right is the values when enable hexagon delegate,
&lt;denchmark-link:https://user-images.githubusercontent.com/29744812/74617424-eee9c300-5167-11ea-9061-53225444a7b7.png&gt;&lt;/denchmark-link&gt;

CPU and DSP got diffrent output
Describe the expected behavior
CPU and DSP should get the same output values
Code to reproduce the issue Provide a reproducible test case that is the
bare minimum necessary to generate the problem.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='huanyingjun' date='2020-02-17T05:11:16Z'>
		&lt;denchmark-link:https://github.com/huanyingjun&gt;@huanyingjun&lt;/denchmark-link&gt;
 Please provide us with simple executable stand alone code[along with the tensorflow version] so we could replicate the issue in our environment.
		</comment>
		<comment id='2' author='huanyingjun' date='2020-02-17T10:37:15Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

tensorflow is at commit ID: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/a00bd4687adac4d5f1880595262276e656375322&gt;a00bd46&lt;/denchmark-link&gt;
, Date:   Sun Feb 16 15:18:17 2020 -0800
I use tflite benchmark_model for testing, just modify a few lines:
benchmark_tflite_model.cc
line 478  PrepareInputData ：
&lt;denchmark-code&gt;} else if (t-&gt;type == kTfLiteUInt8) {
int low = 1;//has_value_range ? low_range : 0;
int high = 1;//has_value_range ? high_range : 254;
&lt;/denchmark-code&gt;

and line 656, modify "RunImpl" as below:
&lt;denchmark-code&gt;TfLiteStatus BenchmarkTfLiteModel::RunImpl() { 
	TfLiteStatus ret = interpreter_-&gt;Invoke(); 
	auto interpreter_outputs = interpreter_-&gt;outputs();
	TfLiteTensor* t = interpreter_-&gt;tensor(interpreter_outputs[0]);
	float* out_ptr = t-&gt;data.f;
	printf("==================\n");
	for (int i = 0; i &lt; 50; i++)
	{
		if (i % 10 == 0 &amp;&amp; i) printf("\n");
		printf("%f ", out_ptr[i]);
	}
	printf("\n==================\n");
	return ret;
}
&lt;/denchmark-code&gt;

then run benchmark with CPU and DSP， you can get the output value.
		</comment>
		<comment id='3' author='huanyingjun' date='2020-02-17T11:39:07Z'>
		And I also test with mobilenet-v2 ( &lt;denchmark-link:https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz&gt;https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz&lt;/denchmark-link&gt;
 )
Also set input values as 1 just for testing, modify below codes:
benchmark_tflite_model.cc
line 478 PrepareInputData ：
&lt;denchmark-code&gt;} else if (t-&gt;type == kTfLiteUInt8) {
int low = 1;//has_value_range ? low_range : 0;
int high = 1;//has_value_range ? high_range : 254;
&lt;/denchmark-code&gt;

and line 656, modify "RunImpl" as below:
&lt;denchmark-code&gt;TfLiteStatus BenchmarkTfLiteModel::RunImpl() { 
	TfLiteStatus ret = interpreter_-&gt;Invoke(); 

	auto interpreter_outputs = interpreter_-&gt;outputs();
	TfLiteTensor* t = interpreter_-&gt;tensor(interpreter_outputs[0]);
	uint8_t* out_ptr = t-&gt;data.uint8;
	printf("==================\n");
	for (int i = 0; i &lt; 50; i++)
	{
		if (i % 10 == 0 &amp;&amp; i)  printf("\n");
		printf("%f ", (out_ptr[i] - t-&gt;params.zero_point) * t-&gt;params.scale);
	}
	printf("\n==================\n");
	
	return ret;
}
&lt;/denchmark-code&gt;

CPU and DSP got different output values
&lt;denchmark-link:https://user-images.githubusercontent.com/29744812/74650556-f6878700-51bc-11ea-90b4-ab6645328c35.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='huanyingjun' date='2020-02-18T06:48:47Z'>
		&lt;denchmark-link:https://github.com/huanyingjun&gt;@huanyingjun&lt;/denchmark-link&gt;
 Can you please share the tensorflow version used, it helps us resolve the issue
		</comment>
		<comment id='5' author='huanyingjun' date='2020-02-18T08:12:24Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

tensorflow is at commit ID: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/a00bd4687adac4d5f1880595262276e656375322&gt;a00bd46&lt;/denchmark-link&gt;
, Date: Sun Feb 16 15:18:17 2020 -0800
		</comment>
		<comment id='6' author='huanyingjun' date='2020-02-21T00:48:22Z'>
		Hey &lt;denchmark-link:https://github.com/huanyingjun&gt;@huanyingjun&lt;/denchmark-link&gt;
, the output-pointer casting in your MobileNetv2 example (where you use ) is the correct, but the SSD one is wrong - I assume you fixed it later.
It might also be good to generate random data instead of using all 1s (but then you will need to run both settings with the same).
Minimal, equal activations (such as 1) amplify the small differences in execution on DSP &amp; CPU - they are never the exact same.
Also, may you try our &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/inference_diff&gt;inference_diff&lt;/denchmark-link&gt;
 tool which was specifically built for this kind of testing? It runs both settings (CPU/delegate) with the same random data and returns errors between each output tensor. If these are high for you, we need to debug.
		</comment>
		<comment id='7' author='huanyingjun' date='2020-02-21T03:04:12Z'>
		&lt;denchmark-link:https://github.com/srjoglekar246&gt;@srjoglekar246&lt;/denchmark-link&gt;

hello, I tried inference_diff with 3 models, below is the result:
mobilenet_v1_1.0_224_quant.tflite (&lt;denchmark-link:https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224_quant.tgz&gt;https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224_quant.tgz&lt;/denchmark-link&gt;
)
&lt;denchmark-code&gt;output_errors {
      max_value: 0.0659340695
      min_value: 0.00799200777
      avg_value: 0.026453545093536378
      std_deviation: 0.0120730288
    }
&lt;/denchmark-code&gt;

mobilenet_v2_1.0_224_quant.tflite ( &lt;denchmark-link:https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz&gt;https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz&lt;/denchmark-link&gt;
 )
&lt;denchmark-code&gt;output_errors {
      max_value: 5.48851156
      min_value: 5.13486528
      avg_value: 5.251767578125
      std_deviation: 0.0698218346
    }
&lt;/denchmark-code&gt;

detect.tflite (&lt;denchmark-link:https://storage.googleapis.com/mirror.tensorflow.org/storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip&gt;https://storage.googleapis.com/mirror.tensorflow.org/storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip&lt;/denchmark-link&gt;
)
&lt;denchmark-code&gt;output_errors {
      max_value: 0.433035672
      min_value: 0.255494833
      avg_value: 0.33961360931396484
      std_deviation: 0.0411406
    }
    output_errors {
      max_value: 37.4
      min_value: 7.9
      avg_value: 20.665998535156248
      std_deviation: 6.46516037
    }
    output_errors {
      max_value: 0.707812488
      min_value: 0.662890613
      avg_value: 0.68922660827636717
      std_deviation: 0.00848944299
    }
    output_errors {
      max_value: 0
      min_value: 0
      avg_value: 0
      std_deviation: 0
    }
&lt;/denchmark-code&gt;

seems mobilenet-v1 is correct.
but for mobilenet-v2 and  SSD, the  avg_value is high
mobilenet-v2:  (avg_value: 5.251767578125),
SSD:  (avg_value: 20.665998535156248)
Could you please help check this ?
		</comment>
		<comment id='8' author='huanyingjun' date='2020-02-21T09:07:42Z'>
		&lt;denchmark-link:https://github.com/huanyingjun&gt;@huanyingjun&lt;/denchmark-link&gt;
 Hi, I have been trying to use Hexagon Delegate with QCS605 and I'm getting the same results for SSD MobileNet as described here &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/36927&gt;#36927&lt;/denchmark-link&gt;
 . It now seems like a similar issue.
Is it possible to get access to previous versions of libraries?
		</comment>
		<comment id='9' author='huanyingjun' date='2020-02-21T16:25:04Z'>
		I can reproduce this issue. Lemme debug and send a fix :-)
		</comment>
		<comment id='10' author='huanyingjun' date='2020-02-22T10:11:16Z'>
		&lt;denchmark-link:https://github.com/srjoglekar246&gt;@srjoglekar246&lt;/denchmark-link&gt;

Thanks for your kindly response, I have an other question, Could you please share me how to build libhexagon_nn_skel.so for tflite?
TFLite hexagon delegate is based on hexagon nnlib, I can get nnlib source code from &lt;denchmark-link:https://source.codeaurora.org/quic/hexagon_nn/nnlib&gt;https://source.codeaurora.org/quic/hexagon_nn/nnlib&lt;/denchmark-link&gt;
, and I can build ibhexagon_nn_skel.so according to "README.HOW_TO_BUILD" in nnlib, but my build libhexagon_nn_skel.so can not be used for tflite, report some error. Does tflite modify the nnlib code ? how to build libhexagon_nn_skel.so using the nnlib source code ?
		</comment>
		<comment id='11' author='huanyingjun' date='2020-02-24T17:02:42Z'>
		Short answer is, you cannot (unless you have Qualcomm's dev board).
Only Qualcomm can build &amp; sign a binary that runs on non-debug devices in the wild.
		</comment>
		<comment id='12' author='huanyingjun' date='2020-02-25T20:50:04Z'>
		The fix for this should be in by now. We were handling Convolution with an activation (RELU6) incorrectly, hence the issue with SSD MobileNet.
About the outputs from the  tool &amp; your own scripting:
I see diffs for MobileNetV2 &amp; the int vector of SSD still, but when I checked with our &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks&gt;classification &amp; object detection tooling&lt;/denchmark-link&gt;
, the models got correct accuracy with the ImageNet/COCO datasets.
From what I understand, randomized inputs are hard to interpret like actual data (eg images), since constant values or gaussian distributions don't entail typical model behavior. For example, the NMS post-processing that SSD does causes large deviations for random inputs, since there is sorting going on under-the-hood.
The way we typically use the diff tool is take a 'snapshot' of the output errors when we know the model is behaving correctly with the delegate, and then debug if the errors suddenly diverge. For example, the SSD model - with the fix, its avg diff for output tensor#1 is 8 with low std_deviation, while the one we saw before that is ~20 with a high std_deviation.
		</comment>
		<comment id='13' author='huanyingjun' date='2020-02-25T20:50:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36804&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36804&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='huanyingjun' date='2020-02-26T18:03:01Z'>
		&lt;denchmark-link:https://github.com/srjoglekar246&gt;@srjoglekar246&lt;/denchmark-link&gt;
 so where the bug was exactly and what should I update? Cheers!
		</comment>
		<comment id='15' author='huanyingjun' date='2020-02-26T18:24:50Z'>
		The bug was in the TensorFlow code, so you just need to use the latest nightly/master version. If you are using Android, the &lt;denchmark-link:https://www.tensorflow.org/lite/performance/hexagon_delegate#step_1_edit_appbuildgradle_to_use_the_nightly_hexagon_delegate_aar_2&gt;nightly AAR&lt;/denchmark-link&gt;
 should work. Or if you are using the benchmark tool, BUILD from master :-)
		</comment>
		<comment id='16' author='huanyingjun' date='2020-02-26T18:26:29Z'>
		&lt;denchmark-link:https://github.com/srjoglekar246&gt;@srjoglekar246&lt;/denchmark-link&gt;
 Thank you :))
		</comment>
	</comments>
</bug>