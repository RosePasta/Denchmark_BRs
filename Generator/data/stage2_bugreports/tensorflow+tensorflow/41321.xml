<bug id='41321' author='faruknane' open_date='2020-07-12T12:02:31Z' closed_time='2020-07-27T10:30:13Z'>
	<summary>using 3.2GB ram for the simplest mnist model</summary>
	<description>
I create the simplest model, but it uses so much ram. Can you help this issue?
System information

Cuda 10.1
Gtx 1050 ti
Windows 10 platform
Tensorflow-gpu 2.2.0
keras 2.4.3

Describe the current behavior
Using ~3.2GB Video Ram
Describe the expected behavior
Using ~300MB Video Ram
Code
&lt;denchmark-code&gt;import numpy as np
import matplotlib
import matplotlib.pyplot as plt

import keras
from keras.datasets import mnist
from keras.models import Sequential, load_model
from keras.layers.core import Dense, Dropout, Activation, Flatten 
from keras.utils import np_utils
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization

# The first time you run this might be a bit slow, since the
# mnist package has to download and cache the data.
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = np.array(x_train, dtype=np.float32)
x_test = np.array(x_test, dtype=np.float32)

x_train /= 255
x_test /= 255
y_train = np_utils.to_categorical(y_train, 10)
y_test = np_utils.to_categorical(y_test, 10)

x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))

print(x_train.shape) # (60000, 28, 28)
print(y_train.shape) # (60000,)

model = Sequential()
#model.add(Conv2D(32, kernel_size=(3, 3), padding='valid', activation='relu', kernel_initializer='he_normal', input_shape=(28,28, 1)))
#model.add(MaxPool2D((2, 2)))
#model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal'))
#model.add(MaxPool2D((2, 2)))
#model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal'))
#model.add(MaxPool2D((2, 2)))
#model.add(Conv2D(256, kernel_size=(1, 1), activation='relu', kernel_initializer='he_normal'))
model.add(Flatten())
model.add(Dense(30, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(Dense(10, activation='softmax'))
#model.summary()
model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/37745467/87245731-7229ef00-c450-11ea-9bcf-cd5703acfbb3.png&gt;&lt;/denchmark-link&gt;

//EDIT: More info
I had cuda 10.2 installed in my computer. I installed keras and tensorflow. It didn't work at the beginning because tf needs CUDA 10.1. Then I tried to uninstall cuda, reinstalling cuda 10.1. It failed couple times etc. Finally I was able to install cuda 10.1 and tensorflow. I don't know if this is related with the current memory issue.
	</description>
	<comments>
		<comment id='1' author='faruknane' date='2020-07-15T11:30:57Z'>
		&lt;denchmark-link:https://github.com/faruknane&gt;@faruknane&lt;/denchmark-link&gt;

Please confirm if &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/8546222f759b6adbb288517166584d17/untitled279.ipynb&gt;this gist&lt;/denchmark-link&gt;
 confirms your issue.
		</comment>
		<comment id='2' author='faruknane' date='2020-07-15T13:22:58Z'>
		Yes, exactly &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/37745467/87550154-6b50e580-c6b7-11ea-917a-827c4c00bf67.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='faruknane' date='2020-07-15T19:47:14Z'>
		I tried your example in google colab and I see 1.27 gb ram usage.
&lt;denchmark-link:https://user-images.githubusercontent.com/42785357/87588831-2a49d880-c699-11ea-9df9-25a650446240.png&gt;&lt;/denchmark-link&gt;

You may try again by closing all the applications and rebooting your system.
		</comment>
		<comment id='4' author='faruknane' date='2020-07-16T10:38:38Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 I have cudnn64_7.dll and Cuda 10.1 installed. I don't know what's wrong. But I think it's decreasing the performance. On my PC, it uses 3.2 gib GPU ram. It's not about the apps that are running. When I restart the kernel of the notebook, GPU memory is 77mb. When I run the notebook, the memory usage is 3.2gib.
I only did install TensorFlow-GPU and Keras packages. Do you have any idea what the issue is about?
&lt;denchmark-link:https://user-images.githubusercontent.com/37745467/87661730-c8a56f00-c769-11ea-9e8a-df502ce6ca1f.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/37745467/87661794-ea9ef180-c769-11ea-96e1-52608589d59f.png&gt;&lt;/denchmark-link&gt;

Do I have to install tensorflow package?
		</comment>
		<comment id='5' author='faruknane' date='2020-07-19T10:51:17Z'>
		At least can you guide me on how to remove all and reinstall them proper and successfully?
		</comment>
		<comment id='6' author='faruknane' date='2020-07-21T06:52:41Z'>
		I see you are using anaconda to install TF.
For installing TF with conda you may raise a request on &lt;denchmark-link:https://github.com/ContinuumIO/anaconda-issues/issues&gt;https://github.com/ContinuumIO/anaconda-issues/issues&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='faruknane' date='2020-07-27T10:30:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41321&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41321&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>