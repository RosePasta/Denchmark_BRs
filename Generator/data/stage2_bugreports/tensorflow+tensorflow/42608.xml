<bug id='42608' author='ChaseLewis' open_date='2020-08-24T02:26:53Z' closed_time='2020-09-09T17:16:26Z'>
	<summary>CUDA_ERROR_LAUNCH_FAILED - possible memory issue</summary>
	<description>
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I have modified an example keras project (https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py) by just removing the dataset size loaded.


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 Pro


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A


TensorFlow installed from (source or binary):
tensorflow-gpu installed through pip


TensorFlow version (use command below):
Git Version: v2.3.0-rc2-23-gb36436b087
Version: 2.3.0


Python version:
3.8.5 64-bit


Bazel version (if compiling from source):
N/A


GCC/Compiler version (if compiling from source):
N/A


CUDA/cuDNN version:
CUDA: 10.1
cuDNN: 7.6


GPU model and memory:
GPU: GTX 1080 Ti
Memory: 11GB (9.5 GB effective from log)


-System Memory:
32GB

Using the script here (&lt;denchmark-link:https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py&gt;https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py&lt;/denchmark-link&gt;
) to start learning a bit about LSTM's and Sequence2Sequence learning. The result is when training starts I have ~16 GB allocated by CPU side over the epoch it gradually raises itself until it nearly maxes out the system memory. Sometimes I can complete a few epochs but eventually I get the following error:
"CUDNN_STATUS_INTERNAL_ERROR
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1892): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data-&gt;opaque(), output_h_desc.handle(), output_h_data-&gt;opaque(), output_c_desc.handle(), output_c_data-&gt;opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2020-08-23 21:11:43.812986: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure"
My assumption is this has to do something with the memory allocation going a bit crazy and eventually triggering an OOM under the hood, but I'm not 100% sure how to get anymore data to help determine what is going on.
I have tested it at 100k items and everything works as expected, but not 124k. My assumption is something is moving everything over to the GPU and thus crazy allocations are happening once the entire dataset won't fit into GPU memory.
If there is something dumb I didn't do to prevent the memory from scaling crazy I apologize, but hadn't got an answer on stackoverflow so figured asking here might be better.
Describe the expected behavior
I would expect the memory usage to scale only on batch_size, not total dataset size. I would expect if I can complete an epoch once I should be be able to complete the remaining ones without an error. I have built a generator to see if maybe the issue was all the memory being allocated, but that also didn't fix the issue. I could see adding more memory but seems like the issue is more that memory use scales by total dataset size. When doing image training I haven't ever seen anything like that, only with this LSTM network.

&lt;denchmark-link:https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py&gt;https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py&lt;/denchmark-link&gt;

Run this script but set the total size to 124000.
Output
(.venv) PS C:\Dev\CompressedMemory&gt;  cd 'c:\Dev\CompressedMemory'; &amp; 'c:\Dev\CompressedMemory.venv\Scripts\python.exe' 'c:\Users\ChaseRLewis.vscode\extensions\ms-python.python-2020.8.103604\pythonFiles\lib\python\debugpy\launcher' '50370' '--' 'c:\Dev\CompressedMemory\train.py'
2020-08-23 20:59:49.133632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
v2.3.0-rc2-23-gb36436b087
2.3.0
Number of samples: 124325
Number of unique input tokens: 91
Number of unique output tokens: 114
2020-08-23 21:08:54.280683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-08-23 21:08:54.314777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-08-23 21:08:54.322233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-23 21:08:54.355314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-23 21:08:54.386173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-23 21:08:54.398183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-23 21:08:54.419257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-23 21:08:54.439330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-23 21:08:54.550070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-23 21:08:54.554182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-23 21:08:54.567696: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-23 21:08:54.662347: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b911c0e2b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-23 21:08:54.667058: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-23 21:08:54.671211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-08-23 21:08:54.686125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-08-23 21:08:54.699127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-23 21:08:54.702580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-08-23 21:08:54.716295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-08-23 21:08:54.719900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-08-23 21:08:54.733723: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-08-23 21:08:54.737621: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-08-23 21:08:54.749712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-23 21:08:55.792500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-23 21:08:55.796084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-08-23 21:08:55.798310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-08-23 21:08:55.801223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9525 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
2020-08-23 21:08:55.821954: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b938950590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-23 21:08:55.832406: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
Epoch 1/300
2020-08-23 21:09:07.991819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-08-23 21:09:08.422643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
3108/3108 [==============================] - ETA: 0s - loss: 0.21842020-08-23 21:11:43.812127: E tensorflow/stream_executor/dnn.cc:616] CUDNN_STATUS_INTERNAL_ERROR
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1892): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data-&gt;opaque(), output_h_desc.handle(), output_h_data-&gt;opaque(), output_c_desc.handle(), output_c_data-&gt;opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2020-08-23 21:11:43.812986: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-08-23 21:11:43.839269: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 114, 256, 1, 280, 32, 256]
2020-08-23 21:11:43.853074: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:220] Unexpected Event status: 1
	</description>
	<comments>
		<comment id='1' author='ChaseLewis' date='2020-08-24T02:39:23Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42608&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42608&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='ChaseLewis' date='2020-08-26T10:45:56Z'>
		I am also experiencing the same issue, however, I am a beginner with TensorFlow so it's likely my code's fault.
My system also uses a GTX 1080 Ti.
I have tried a couple configurations according to &lt;denchmark-link:https://www.tensorflow.org/install/source_windows&gt;this&lt;/denchmark-link&gt;
:



Version
Python version
Compiler
Build tools
cuDNN
CUDA




tensorflow_gpu-2.3.0
3.8
MSVC 2019
Bazel 3.1.0
7.4
10.1


tensorflow_gpu-2.1.0
3.7
MSVC 2019
Bazel 0.27.1-0.29.1
7.4
10.1



I have written custom code, use Win10 Home x64, IntelliJ IDE.
		</comment>
		<comment id='3' author='ChaseLewis' date='2020-08-26T15:51:40Z'>
		&lt;denchmark-link:https://github.com/ChaseLewis&gt;@ChaseLewis&lt;/denchmark-link&gt;

Could you please provide the complete code to reproduce the issue reported here?
Also, please take a look at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/35950#issuecomment-577427083&gt;this comment&lt;/denchmark-link&gt;
 from a similar issue and let us know if it helps.
Also refer to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/41169#issuecomment-673346093&gt;link&lt;/denchmark-link&gt;
,&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33848#issuecomment-558839064&gt;link1&lt;/denchmark-link&gt;
,  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34695&gt;#34695&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/37932&gt;#37932&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/39264&gt;#39264&lt;/denchmark-link&gt;

Thanks!
		</comment>
		<comment id='4' author='ChaseLewis' date='2020-09-02T16:22:16Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='5' author='ChaseLewis' date='2020-09-09T17:16:25Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='6' author='ChaseLewis' date='2020-09-09T17:16:27Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42608&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42608&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>