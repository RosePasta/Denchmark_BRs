<bug id='42281' author='DNXie' open_date='2020-08-12T20:06:58Z' closed_time='2020-10-27T00:19:52Z'>
	<summary>tf.nn.ctc_beam_search_decoder crashes(bad_alloc) when top_paths is large</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below):2.1.0
Python version:3.7.6
Bazel version (if compiling from source):N/A
GCC/Compiler version (if compiling from source):N/A
CUDA/cuDNN version:N/A
GPU model and memory:N/A

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
tf.nn.ctc_beam_search_decoder crashes(bad_alloc) when top_paths is extremely large
Describe the expected behavior
Expect no crashes
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
import tensorflow as tf
tf.nn.ctc_beam_search_decoder(inputs=tf.ones((1,1,1)), sequence_length=[1], top_paths=1000000000000)
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
  what():  std::bad_alloc
Aborted (core dumped)
	</description>
	<comments>
		<comment id='1' author='DNXie' date='2020-08-13T06:08:12Z'>
		I have tried in colab with TF version 2.1,2.3,nightly versions() and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/2969447f67d86720918d264620763d03/untitled247.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='DNXie' date='2020-08-18T16:56:59Z'>
		Depending on the version of TF i use, I get different errors.
Internally; I get the error
ValueError: Attr top_paths has value 1000000000000 out of range for an int32
using python3.6; which I think is the real expected error.
In OSS ipython3 I get the error:
MemoryError: std::bad_alloc
at the line
&lt;denchmark-code&gt;--&gt; 118   _result = _execute.execute(b"CTCBeamSearchDecoder", top_paths + top_paths +
    119                              top_paths + 1, inputs=_inputs_flat, attrs=_attrs,
    120                              ctx=ctx, name=name)
&lt;/denchmark-code&gt;

(eager execution)
		</comment>
		<comment id='3' author='DNXie' date='2020-08-18T16:58:03Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 who should take this over?  looks like an error in attr size validation?  or perhaps we're allowing an int64 through when it should be an int32; and then differences in tcmalloc vs. some other malloc externally?
		</comment>
		<comment id='4' author='DNXie' date='2020-08-18T16:58:53Z'>
		The internal error is correctly identified here, I think:
&lt;denchmark-code&gt;.../tensorflow/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)
   2003         op_def = self._graph._get_op_def(node_def.op)
   2004       self._c_op = _create_c_op(self._graph, node_def, inputs,
-&gt; 2005                                 control_input_ops, op_def)
   2006       name = compat.as_str(node_def.name)
   2007     # pylint: enable=protected-access

.../tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)
   1843   except errors.InvalidArgumentError as e:
   1844     # Convert to ValueError for backwards compatibility.
-&gt; 1845     raise ValueError(str(e))
   1846 
   1847   return c_op

ValueError: Attr top_paths has value 1000000000000 out of range for an int32
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='DNXie' date='2020-08-18T16:59:32Z'>
		&lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
 can you help triage this? The error seems to be in the TF C API layer.
		</comment>
		<comment id='6' author='DNXie' date='2020-10-27T00:19:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42281&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42281&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>