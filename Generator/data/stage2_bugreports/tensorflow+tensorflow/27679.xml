<bug id='27679' author='eldar' open_date='2019-04-09T11:37:54Z' closed_time='2019-12-07T12:24:00Z'>
	<summary>Passing a dictionary of tensors to py_function</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9.0
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0 alpha
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

tf.data.Dataset supports dictionary as a valid type of its elements, which is convenient when your data source have multiple tensors and you want to assign a name to each of them. However if I want to manipulate these tensors by mapping the dataset to a tf.py_function, it complains that the dictionary is not compatible with the Tensor, even though its values are Tensors.
import numpy as np
import tensorflow as tf


def make_dictionary(inp):
    out = {}
    out["image1"] = inp[0]
    out["image2"] = inp[1]
    out["image3"] = inp[2]
    return out


def process_data(data):
    print("image1", data["image1"])
    print("image2", data["image2"])
    print("image3", data["image3"])
    return 0.0


dataset = tf.data.Dataset.from_tensor_slices(np.arange(10))

dataset = tf.data.Dataset.zip((dataset, dataset, dataset))
dataset = dataset.map(lambda *stuff: make_dictionary(stuff))
# now each element in dataset is a dictionary
# processing the dictionary however is not supported by py_function:

dataset = dataset.map(
      lambda data: tf.py_function(
          process_data, [data], tf.float32))

for image in dataset.take(4):
    print(image)
The error I get is:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 559, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 559, in &lt;listcomp&gt;
    str_values = [compat.as_bytes(x) for x in proto_values]
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/util/compat.py", line 61, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got {'image1': &lt;tf.Tensor 'args_0:0' shape=() dtype=int64&gt;, 'image2': &lt;tf.Tensor 'args_1:0' shape=() dtype=int64&gt;, 'image3': &lt;tf.Tensor 'args_2:0' shape=() dtype=int64&gt;}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 471, in _apply_op_helper
    as_ref=input_arg.is_ref)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1251, in internal_convert_n_to_tensor
    ctx=ctx))
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1186, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 304, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 245, in constant
    allow_broadcast=True)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
    allow_broadcast=allow_broadcast))
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 563, in make_tensor_proto
    "supported type." % (type(values), values))
TypeError: Failed to convert object of type &lt;class 'dict'&gt; to Tensor. Contents: {'image1': &lt;tf.Tensor 'args_0:0' shape=() dtype=int64&gt;, 'image2': &lt;tf.Tensor 'args_1:0' shape=() dtype=int64&gt;, 'image3': &lt;tf.Tensor 'args_2:0' shape=() dtype=int64&gt;}. Consider casting elements to a supported type.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "tmp.py", line 28, in &lt;module&gt;
    lambda data: tf.py_function(
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 1012, in map
    return MapDataset(self, map_func, preserve_cardinality=True)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 2986, in __init__
    use_legacy_function=use_legacy_function)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 2388, in __init__
    self._function = wrapper_fn._get_concrete_function_internal()
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1319, in _get_concrete_function_internal
    *args, **kwargs)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1313, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1580, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1512, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 694, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 2381, in wrapper_fn
    ret = _wrapper_helper(*args)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 2326, in _wrapper_helper
    ret = func(*nested_args)
  File "tmp.py", line 29, in &lt;lambda&gt;
    process_data, [data], tf.float32))
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py", line 389, in eager_py_func
    return _internal_py_func(func=func, inp=inp, Tout=Tout, eager=True, name=name)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py", line 278, in _internal_py_func
    input=inp, token=token, Tout=Tout, name=name)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/ops/gen_script_ops.py", line 74, in eager_py_func
    "EagerPyFunc", input=input, token=token, Tout=Tout, name=name)
  File "/BS/eldar-3dshape/work/apps/miniconda3/envs/py36_tf20/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 502, in _apply_op_helper
    "%s that are invalid. Tensors: %s" % (prefix, values))
TypeError: Tensors in list passed to 'input' of 'EagerPyFunc' Op have types [&lt;NOT CONVERTIBLE TO TENSOR&gt;] that are invalid. Tensors: [{'image1': &lt;tf.Tensor 'args_0:0' shape=() dtype=int64&gt;, 'image2': &lt;tf.Tensor 'args_1:0' shape=() dtype=int64&gt;, 'image3': &lt;tf.Tensor 'args_2:0' shape=() dtype=int64&gt;}]
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='eldar' date='2019-08-02T15:16:34Z'>
		Any updates on this?
		</comment>
		<comment id='2' author='eldar' date='2019-08-02T17:36:55Z'>
		This is a limitation of py_function which only supports a list of Tensor inputs and I don't need see a straightforward way to extend its implementation to support dictionaries.
FWIW, you could deconstruct the dictionary structure ahead of invoking the py_function:
&lt;denchmark-code&gt;import tensorflow as tf

tf.enable_v2_behavior()

def deconstruct(x):
  return x['a'], x['b']

def process(*args):
  a, b = args
  return a + b

dataset = tf.data.Dataset.from_tensors({'a': 1, 'b': 2})
dataset = dataset.map(deconstruct)
dataset = dataset.map(lambda *args: tf.py_function(process, args, tf.int32))

for elem in dataset:
  print(elem.numpy())
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='eldar' date='2019-08-02T17:36:57Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27679&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27679&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='eldar' date='2019-08-02T18:08:06Z'>
		In a related feature request (Support Sparse Tensors in py_function, &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30069&gt;#30069&lt;/denchmark-link&gt;
), &lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 noted:

I think now that we have compositetensor and typespec it should be straightforward to implement sparsetensor support in py_function by treating all composites generically.

Could the same mechanism provide a path to implementing dictionary handling by py_function?
		</comment>
		<comment id='5' author='eldar' date='2019-08-02T18:24:34Z'>
		Not until:
a) CompositeTensor inputs are supported to py_function
b) a subclass of CompositeTensor exists that can represent a dictionary
		</comment>
		<comment id='6' author='eldar' date='2019-08-19T13:11:05Z'>
		Most APIs that support composite tensors also support nested structures (as defined by &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/nest&gt;tf.nest&lt;/denchmark-link&gt;
.  In particular, the tf.nest functions include an "expand_composites" argument that tells tf.nest that it should treat composite tensors as nested structures.
Therefore, we don't need a CompositeTensor for dictionaries -- we can just use dictionaries as is.  But what we do ned is to extend py_function to use tf.nest to do appropriate flattening and repacking of tensors at the input &amp; output boundaries.  (Using "expand_composites=True" will ensure that this supports both "normal" nested structures and composite tensors.)
		</comment>
		<comment id='7' author='eldar' date='2019-08-19T13:34:32Z'>
		Here's an example showing how the existing py_function could be wrapped to handle nested structures, including "normal" nested structures like dictionaries or tuples and also composite tensors:
&lt;denchmark-code&gt;def new_py_function(func, inp, Tout, name=None):
  def wrapped_func(*flat_inp):
    reconstructed_inp = tf.nest.pack_sequence_as(inp, flat_inp,
                                                 expand_composites=True)
    out = func(*reconstructed_inp)
    return tf.nest.flatten(out, expand_composites=True)
  flat_Tout = tf.nest.flatten(Tout, expand_composites=True)
  flat_out = tf.py_function(
      func=wrapped_func, 
      inp=tf.nest.flatten(inp, expand_composites=True),
      Tout=[_tensor_spec_to_dtype(v) for v in flat_Tout],
      name=name)
  spec_out = tf.nest.map_structure(_dtype_to_tensor_spec, Tout, 
                                   expand_composites=True)
  out = tf.nest.pack_sequence_as(spec_out, flat_out, expand_composites=True)
  return out

def _dtype_to_tensor_spec(v):
  return tf.TensorSpec(None, v) if isinstance(v, tf.dtypes.DType) else v

def _tensor_spec_to_dtype(v):
  return v.dtype if isinstance(v, tf.TensorSpec) else v
&lt;/denchmark-code&gt;

(Warning: I tested this out on your example, but haven't done thorough testing, so there might be a bug or two in this code; but it should give you the basic idea of what needs to be done.)
		</comment>
		<comment id='8' author='eldar' date='2019-10-01T21:59:42Z'>
		&lt;denchmark-link:https://github.com/eldar&gt;@eldar&lt;/denchmark-link&gt;
 Is this still an issue for you? did you try the suggestions from &lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/edloper&gt;@edloper&lt;/denchmark-link&gt;
 .
Can you try recently released  and let us know whether the issue persists with the latest version? Thanks!
		</comment>
		<comment id='9' author='eldar' date='2019-10-03T19:02:38Z'>
		I just tested it using v2.0, and it still isn't possible to supply dictionaries to a py_function as inputs. Attempting to do so still results in:

TypeError: Tensors in list passed to 'input' of 'EagerPyFunc' Op have types [] that are invalid.

&lt;denchmark-link:https://github.com/edloper&gt;@edloper&lt;/denchmark-link&gt;
's workaround seems like it may work (at least for the simple case that I have tried it with so far), but I still believe that  itself should be modified to be able to accept (and return, for that matter) dictionaries and other composite tensors.
		</comment>
		<comment id='10' author='eldar' date='2019-10-03T19:32:41Z'>
		&lt;denchmark-link:https://github.com/novog&gt;@novog&lt;/denchmark-link&gt;
 If you're interested in submitting a pull request that updates  to support nested structures, it looks like you could probably fold the suggestions I made above into &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/script_ops.py#L251&gt;_internal_py_func&lt;/denchmark-link&gt;
.  (You'd need to add tests etc. as well.)
		</comment>
		<comment id='11' author='eldar' date='2019-10-08T14:38:08Z'>
		&lt;denchmark-link:https://github.com/edloper&gt;@edloper&lt;/denchmark-link&gt;
 Thanks again.
Your example code looks like it might be able to handle nested return types, but I can't make it work with a function that returns a Dict[str, tf.Tensor]. Should this work, and if so, what should be specified for Tout?
		</comment>
		<comment id='12' author='eldar' date='2019-10-08T15:17:20Z'>
		You can use something like: Tout={"foo": tf.int32, "bar": tf.float32}.
Note that you'll need to know the keys of the dict and the types of the tensor values statically.  In particular, if we're in graph mode, then we need to know what this structure looks like statically, so we can create the output tensors.  If the size/set of keys in the dict can change each time the python function is called, then there's no sensible way to hook it up to the output.
In the general case, you can use nested structure in your output, but only if the "structure" part of that nested structure is fixed and known in advance.
		</comment>
		<comment id='13' author='eldar' date='2019-12-07T12:24:02Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27679&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27679&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='eldar' date='2019-12-07T12:24:10Z'>
		We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!
		</comment>
		<comment id='15' author='eldar' date='2019-12-14T20:57:57Z'>
		So, I created a patch thanks to &lt;denchmark-link:https://github.com/edloper&gt;@edloper&lt;/denchmark-link&gt;
 suggestion &lt;denchmark-link:https://github.com/minhtriet/tensorflow/blob/master/tensorflow/python/ops/script_ops.py#L373&gt;here&lt;/denchmark-link&gt;
. That is the only change
&lt;denchmark-code&gt;2019-12-14 21:35:12.013946: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at iterator_ops.cc:929 : Invalid argument: {{function_node __inference_Dataset_map_&lt;lambda&gt;_19}} 0-th value returned by pyfunc_0 is double, but expects float
	 [[{{node PyFuncStateless}}]]
Traceback (most recent call last):
  File "C:\Users\cool\Miniconda3\envs\tf_contrib_conda\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py", line 666, in next
    return self._next_internal()
  File "C:\Users\cool\Miniconda3\envs\tf_contrib_conda\lib\site-packages\tensorflow_core\python\data\ops\iterator_ops.py", line 651, in _next_internal
    output_shapes=self._flat_output_shapes)
  File "C:\Users\cool\Miniconda3\envs\tf_contrib_conda\lib\site-packages\tensorflow_core\python\ops\gen_dataset_ops.py", line 2672, in iterator_get_next_sync
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File "&lt;string&gt;", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __inference_Dataset_map_&lt;lambda&gt;_19}} 0-th value returned by pyfunc_0 is double, but expects float
	 [[{{node PyFuncStateless}}]] [Op:IteratorGetNextSync]
&lt;/denchmark-code&gt;

pyfunc_0 returns a double, but expects float, but I cannot debug this function. Could someone give me a pointer? Thank you
		</comment>
		<comment id='16' author='eldar' date='2019-12-16T17:44:50Z'>
		Add a tf.cast?
		</comment>
		<comment id='17' author='eldar' date='2020-04-03T21:38:05Z'>
		Hello &lt;denchmark-link:https://github.com/edloper&gt;@edloper&lt;/denchmark-link&gt;
,
I did like you pointed out in a similar case:
Tout={"input_ids": tf.int32, "attention_mask": tf.int32}, {"input_ids": tf.int32, "attention_mask": tf.int32}
But I got the following error:
ValueError: Attempt to convert a value 
({
'input_ids': [101, 13366, 2131, 1035, 6819, 2094, 1035, 2013, 1035, 24471, 2140, 1006, 24471, 2140, 1007, 102], 
'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}) 
with an unsupported type (&lt;class 'dict'&gt;) to a Tensor.
Any suggestion?
		</comment>
		<comment id='18' author='eldar' date='2020-04-30T15:14:45Z'>
		&lt;denchmark-link:https://github.com/jeromerg&gt;@jeromerg&lt;/denchmark-link&gt;
 This issue was about passing values in &amp; out of , and not about .  Passing nested dictionaries, namedtules, lists, and tuples of tensors in &amp; out of  should work fine.
		</comment>
		<comment id='19' author='eldar' date='2020-04-30T15:21:30Z'>
		&lt;denchmark-link:https://github.com/Ceceu&gt;@Ceceu&lt;/denchmark-link&gt;
 The following works fine for me, using the  defined above:
&lt;denchmark-code&gt;def my_function(x):
  return ({"input_ids": x, "atention_mask": x},
          {"input_ids": x, "atention_mask": x})
  
new_py_function(my_function, [tf.constant([5, 6, 7])], Tout=(
    {"input_ids": tf.int32, "attention_mask": tf.int32},
    {"input_ids": tf.int32, "attention_mask": tf.int32}))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='20' author='eldar' date='2020-05-07T11:20:39Z'>
		&lt;denchmark-link:https://github.com/edloper&gt;@edloper&lt;/denchmark-link&gt;
 Thanks a lot for your new_py_function, which is very very useful to work with dicts !!
It should definitely be integrated in Tensorflow !
For those who would like another example, I used it with map to pass input and output dicts, add new data to the output dict and return the 2 dicts, like this :
def my_py_func_adding_data(self, dicts):
	dict_inputs, dict_outputs = dicts
	new_data = some_function(dict_outputs["output1"].numpy())
	dict_outputs["output2"] = new_data
	return dict_inputs, dict_outputs

ds = ds.map(lambda dict_in, dict_out: new_py_function(my_py_func_adding_data,
                                                      inp=[(dict_in, dict_out)], 
						      Tout=({"img": tf.float32}, {"output1": tf.float32, "output2": tf.float32})))
And it worked like a charm :)
		</comment>
		<comment id='21' author='eldar' date='2020-08-03T12:12:01Z'>
		&lt;denchmark-code&gt;def tf_parser_func(img_id):
    (dict1, dict2) = tf.py_function(
        func = self.parser_func, 
        inp = [img_id],
        Tout = ({'input_1':tf.float32}, {'classification':tf.float32,'regression':tf.float32})
    )
    return dict1, dict2

def parser_func(img_id):
    if type(img_id) != int:
        img_id = int(img_id.numpy())
        assert type(img_id) == int 
    
    image = load_image(img_id) # get image based img_id
    annos = load_annotations(img_id) # get annos based img_id

    inputs, cls_targets, reg_targets = compute_inputs_targets(image, annos) # generate inputs and labels

    return ({'input_1':inputs}, {'classification':cls_targets,'regression':reg_targets})

def get_dataset(imgae_ids):
    dataset = tf.data.Dataset.from_tensor_slices(image_ids) # create dataset from a list
    dataset = dataset.map(tf_parser_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    dataset = dataset.batch(1, drop_remainder=True).repeat(1)
    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return dataset
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/ismael-elatifi&gt;@ismael-elatifi&lt;/denchmark-link&gt;
  And could you help me find out where is wrong in above code? The dataset that I want to make is create a input and two ouput, and I want make every output has a name so I can pass this dataset into keras model.fit func.
		</comment>
	</comments>
</bug>