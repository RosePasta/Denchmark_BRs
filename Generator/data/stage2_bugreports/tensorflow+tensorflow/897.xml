<bug id='897' author='ppwwyyxx' open_date='2016-01-26T22:53:00Z' closed_time='2016-02-02T00:52:26Z'>
	<summary>gradient of tf.floor</summary>
	<description>
import numpy as np
import tensorflow as tf
f = np.array([3.8], dtype='float32')
vif = tf.placeholder(tf.float32, shape=[1])

#out = vif + tf.cast(tf.cast(vif, tf.int32), tf.float32)
out = vif + tf.floor(vif)
grad = tf.gradients(tf.reduce_sum(out), vif)

sess = tf.Session()
sess.run(tf.initialize_all_variables())
print sess.run(grad, feed_dict={vif: f})  # print 2

import theano
import theano.tensor as T
vif = T.fvector()
out = vif + T.floor(vif)
grad = T.grad(out.sum(), vif)
func = theano.function([vif], grad)
print func(f) # print 1
It looks like the gradient of tf.floor(x) w.r.t x is 1. But I'm expecting it to be 0, as in theano.
Right now I could use a double casting as a work around, but why is it different?
	</description>
	<comments>
		<comment id='1' author='ppwwyyxx' date='2016-01-28T17:31:38Z'>
		Yes, the gradient of floor is always zero.
		</comment>
		<comment id='2' author='ppwwyyxx' date='2016-01-28T17:31:50Z'>
		Well, almost always.
		</comment>
		<comment id='3' author='ppwwyyxx' date='2016-01-31T16:04:59Z'>
		Should it be as simple as changing:
@ops.RegisterGradient("Floor")
def _FloorGrad(_, grad):
  return grad  # return 0
in python/ops/math_grad.py?
		</comment>
		<comment id='4' author='ppwwyyxx' date='2016-02-01T15:57:28Z'>
		Yes, changing it to return [None] would be the fix.
		</comment>
		<comment id='5' author='ppwwyyxx' date='2016-02-01T16:13:45Z'>
		Thanks. Could you explain why None is preferred over 0 ?
I observed that the gradient of tf.cast(tf.cast(vif, tf.int32), tf.float32) is also None, that's why I added   vif in the example code.
		</comment>
		<comment id='6' author='ppwwyyxx' date='2016-02-01T16:23:18Z'>
		 will be treated by the gradient code as "no connection", which is mathematically equivalent to zero but faster since it will never construct large zero matrices.  There's some related discussion here: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/783&gt;#783&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>