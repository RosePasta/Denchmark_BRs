<bug id='24660' author='egyptdj' open_date='2019-01-02T06:20:36Z' closed_time='2019-12-28T02:03:27Z'>
	<summary>cuDNN launch failure when implementing custom kernel_regularizer function within [tf.layers] module</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO
TensorFlow installed from (source or binary): SOURCE (pip)
TensorFlow version (use command below): tensorflow-gpu API r1.12
Python version: 2.7.12
Bazel version (if compiling from source): not compiled with bazel
GCC/Compiler version (if compiling from source): gcc 5.4.0 20160609
CUDA/cuDNN version: CUDA 9.0.176 (wth patch 9.0.176.1 and 9.0.176.2), cuDNN version 7.21
GPU model and memory: two NVIDIA GeForce GTX 1080ti s, 11171mb memory each

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
I implemented a spectral normalization regularizer that can be passed as the [kernel_regularizer] argument in the [tf.layers] module. This implementation causes three problems which are not expected.

Slows down the first epoch of the training process by around ten-fold.
Training process gets slower after every epoch by around 1.5 times. (No new ops are being added in the graph and this was made sure by using finalize() method of the graph within the session.)
Eventually crashes after a few epochs and throws the following InternalError

Caused by op u'GRAN_model/encoder_models/encoder_real/encoder/encoder_conv_3/Conv2D', defined at:
File "main.py", line 70, in 
gran.initialize()
File "main.py", line 33, in initialize
config=self.config)
File "/home/bispl/github/generative_recon/network.py", line 32, in build_network
self.graph.build_model(model=self.model)
File "/home/bispl/github/generative_recon/graph.py", line 45, in build_model
self.model.build_model(image_input=self.image_input, bold_input=self.bold_input, unpaired_image_input=self.unpaired_image_input, training=self.training)
File "/home/bispl/github/generative_recon/model.py", line 38, in build_model
self.encoder_real_model_output = self.encoder.build_model(image_input=self.image_input, bold_input=self.bold_input, model_scope='encoder_real', reuse=False)
File "/home/bispl/github/generative_recon/model_components.py", line 37, in build_model
_x = tf.layers.conv2d(inputs=_x, filters=256, kernel_size=[7,7], kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, kernel_constraint=self.co
nstraint, strides=1, padding='SAME', name=self.scope+'_conv_3')
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/convolutional.py", line 417, in conv2d
return layer.apply(inputs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 817, in apply
return self.call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py", line 374, in call
outputs = super(Layer, self).call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 757, in call
outputs = self.call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/convolutional.py", line 194, in call
outputs = self._convolution_op(inputs, self.kernel)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 868, in call
return self.conv_op(inp, filter)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 520, in call
return self.call(inp, filter)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 204, in call
name=self.name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py", line 957, in conv2d
data_format=data_format, dilations=dilations, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
return func(*args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 3274, in create_op
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1770, in init
self._traceback = tf_stack.extract_stack()
InternalError (see above for traceback): cuDNN launch failure : input shape([16,128,24,32]) filter shape([7,7,128,256])
[[node GRAN_model/encoder_models/encoder_real/encoder/encoder_conv_3/Conv2D (defined at /home/bispl/github/generative_recon/model_components.py:37)  = Conv2D[T
=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:
0"](GRAN_model/encoder_models/encoder_real/encoder/encoder_maxpool_0/MaxPool, encoder/encoder_conv_3/kernel/read)]]
[[{{node GRAN_graph_metrics/generator_real_loss/update_op/_215}} = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", s
end_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_23669_GRAN_graph_metrics/generator_real_loss/update_op", tensor_
type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]
Describe the expected behavior
The expected behavior are

Training process gets slower by at most two-fold using this implementation
Does not further slow down after every epoch
No error thrown.

Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Implementation of the spectral normalization function to be passed to kernel_regularizer argument of the tf.layers module (e.g. tf.layers.conv2d)

&lt;denchmark-code&gt;def spectral_normalization(kernel):
    with tf.variable_scope("spectral_normalization", reuse=tf.AUTO_REUSE):
        print (kernel)
        w = kernel
        _w = tf.reshape(w, [-1, w.shape[-1]], name="reshape_weight_to_2d")

        u_tilde = tf.get_local_variable(name="u_tilde", shape=[1, w.shape[-1].value], initializer=tf.initializers.truncated_normal)
        _u_tilde = tf.identity(u_tilde, name="u_tilde_update")
        for i in range(1):
            _v_tilde = tf.nn.l2_normalize(tf.matmul(_u_tilde, _w, transpose_b=True), name="v_tilde_update_{}".format(i))
            _u_tilde = tf.nn.l2_normalize(tf.matmul(_v_tilde, _w), name="u_tilde_update_{}".format(i))

        update_u_tilde = u_tilde.assign(_u_tilde)
        sigma_w = tf.squeeze(tf.matmul(tf.matmul(_v_tilde, _w), _u_tilde, transpose_b=True), name='sigma_w')
        _w_sn = _w / sigma_w
        w_sn = tf.reshape(_w_sn, w.shape, name="reshape_weight_to_original")
        kernel_spectral_normalized = tf.identity(w_sn, name="kernel_spectral_normalized")
        with tf.control_dependencies([update_u_tilde]):
            apply_regularization = kernel.assign(kernel_spectral_normalized, name="apply_regularization")
            tf.add_to_collection(name="SPECTRAL_NORMALIZATION", value=apply_regularization)

&lt;/denchmark-code&gt;


the function is passed to a layer in [tf.layers] module

conv_layer = tf.layers.conv2d(inputs=input,  filters=128, kernel_regularizer=spectral_normalization) 

run the regularizer after each update

&lt;denchmark-code&gt;weight_regularization_op = tf.get_collection("SPECTRAL_NORMALIZATION")
.
.
.
with tf.Session() as sess:
    for _ in range(num_epoch):
        sess.run(train_op)
        sess.run(weight_regularization_op)

&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
2018-12-31 17:47:41.987355: E tensorflow/stream_executor/cuda/cuda_dnn.cc:82] CUDNN_STATUS_EXECUTION_FAILED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(2531): 'cudnnConvolutionForward( cudnn.handle(), alpha, input_nd.handle(), input_data.opaque(), filter.handle(), filter_d
ata.opaque(), conv.handle(), ToConvForwardAlgo(algo_desc), scratch.opaque(), scratch.size(), beta, output_nd.handle(), output_data-&gt;opaque())'
Traceback (most recent call last):
File "main.py", line 72, in 
gran.train()
File "main.py", line 43, in train
save_epoch=self.base_option['save_epoch'])
File "/home/bispl/github/generative_recon/network.py", line 51, in train
self.session.train_graph(savedir=savedir, save_epoch=save_epoch)
File "/home/bispl/github/generative_recon/session.py", line 112, in train_graph
feed_dict={self.graph.image_input: train_image_input, self.graph.bold_input: train_bold_input, self.graph.unpaired_image_input: train_unpaired_image_input, self.gra
ph.training: True, self.graph.generator_learning_rate: self.generator_learning_rate})
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 929, in run
run_metadata_ptr)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1152, in _run
feed_dict_tensor, options, run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1328, in _do_run
run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1348, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: cuDNN launch failure : input shape([16,128,24,32]) filter shape([7,7,128,256])
[[node GRAN_model/encoder_models/encoder_real/encoder/encoder_conv_3/Conv2D (defined at /home/bispl/github/generative_recon/model_components.py:37)  = Conv2D[T
=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:
0"](GRAN_model/encoder_models/encoder_real/encoder/encoder_maxpool_0/MaxPool, encoder/encoder_conv_3/kernel/read)]]
[[{{node GRAN_graph_metrics/generator_real_loss/update_op/_215}} = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", s
end_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_23669_GRAN_graph_metrics/generator_real_loss/update_op", tensor_
type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]
Caused by op u'GRAN_model/encoder_models/encoder_real/encoder/encoder_conv_3/Conv2D', defined at:
File "main.py", line 70, in 
gran.initialize()
File "main.py", line 33, in initialize
config=self.config)
File "/home/bispl/github/generative_recon/network.py", line 32, in build_network
self.graph.build_model(model=self.model)
File "/home/bispl/github/generative_recon/graph.py", line 45, in build_model
self.model.build_model(image_input=self.image_input, bold_input=self.bold_input, unpaired_image_input=self.unpaired_image_input, training=self.training)
File "/home/bispl/github/generative_recon/model.py", line 38, in build_model
self.encoder_real_model_output = self.encoder.build_model(image_input=self.image_input, bold_input=self.bold_input, model_scope='encoder_real', reuse=False)
File "/home/bispl/github/generative_recon/model_components.py", line 37, in build_model
_x = tf.layers.conv2d(inputs=_x, filters=256, kernel_size=[7,7], kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, kernel_constraint=self.co
nstraint, strides=1, padding='SAME', name=self.scope+'_conv_3')
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/convolutional.py", line 417, in conv2d
return layer.apply(inputs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 817, in apply
return self.call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py", line 374, in call
outputs = super(Layer, self).call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 757, in call
outputs = self.call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/convolutional.py", line 194, in call
outputs = self._convolution_op(inputs, self.kernel)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 868, in call
return self.conv_op(inp, filter)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 520, in call
return self.call(inp, filter)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 204, in call
name=self.name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py", line 957, in conv2d
data_format=data_format, dilations=dilations, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
return func(*args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 3274, in create_op
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1770, in init
self._traceback = tf_stack.extract_stack()
InternalError (see above for traceback): cuDNN launch failure : input shape([16,128,24,32]) filter shape([7,7,128,256])
[[node GRAN_model/encoder_models/encoder_real/encoder/encoder_conv_3/Conv2D (defined at /home/bispl/github/generative_recon/model_components.py:37)  = Conv2D[T
=DT_FLOAT, data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:
0"](GRAN_model/encoder_models/encoder_real/encoder/encoder_maxpool_0/MaxPool, encoder/encoder_conv_3/kernel/read)]]
[[{{node GRAN_graph_metrics/generator_real_loss/update_op/_215}} = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", s
end_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_23669_GRAN_graph_metrics/generator_real_loss/update_op", tensor_
type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]
	</description>
	<comments>
		<comment id='1' author='egyptdj' date='2019-01-07T23:59:57Z'>
		Hello &lt;denchmark-link:https://github.com/egyptdj&gt;@egyptdj&lt;/denchmark-link&gt;
 , Thank you for the detailed issue template response. Can we please try to step back to gcc 4.8 ? Please let us know how the runs on (1), (2) &amp; (3) transpire. Thanks.
		</comment>
		<comment id='2' author='egyptdj' date='2019-01-08T02:43:10Z'>
		Hello &lt;denchmark-link:https://github.com/msymp&gt;@msymp&lt;/denchmark-link&gt;
 ,
Thank you for your help.
I removed and re-compiled the tensorflow-gpu with gcc --version 4.8.5.
It still seems that the same problem occurs when running (1), (2), and (3), but at a different layer. (I did not change the layer numbers or capacity, i.e. same network.). The time for running the network was almost the same as before.
I will attach the new error message at the bottom of this comment.
Please let me know if I need to check anything further.
Thanks.
=================================================
2019-01-08 11:07:37.148026: E tensorflow/stream_executor/cuda/cuda_dnn.cc:82] CUDNN_STATUS_EXECUTION_FAILED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(3197): 'cudnnConvolutionBackwardData(cudnn.handle(), alpha, filter.handle(), filter_data.opaque(), out_back_nd.handle(), backward_output_data.opaque()
, conv.handle(), ToConvBackwardDataAlgo(algo_desc), scratch.opaque(), scratch.size(), beta, in_back_nd.handle(), backward_input_data-&gt;opaque())'
2019-01-08 11:07:37.218704: I tensorflow/stream_executor/stream.cc:5049] [stream=0x7fc2252e23d0,impl=0x7fc2252e2470] did not memzero GPU location; source: 0x7fc21d7f8dc0
Traceback (most recent call last):
File "main.py", line 43, in train
save_epoch=self.base_option['save_epoch'])
File "/home/bispl/github/generative_recon/network.py", line 51, in train
self.session.train_graph(savedir=savedir, save_epoch=save_epoch)
File "/home/bispl/github/generative_recon/session.py", line 112, in train_graph
feed_dict={self.graph.image_input: train_image_input, self.graph.bold_input: train_bold_input, self.graph.unpaired_image_input: train_unpaired_image_input, self.graph.training: True, self.graph
.generator_learning_rate: self.generator_learning_rate})
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 929, in run
run_metadata_ptr)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1152, in _run
feed_dict_tensor, options, run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1328, in _do_run
run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1348, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: cuDNN Backward Data function launch failure : input shape([16,256,12,16]) filter shape([7,7,256,256])
[[node GRAN_graph_op/gradients_2/GRAN_model/generator_models/generator_noise/generator/generator_conv_2/Conv2D_grad/Conv2DBackpropInput (defined at /home/bispl/github/generative_recon/grap
h.py:163)  = Conv2DBackpropInput[T=DT_FLOAT, ...dependency"], data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/j
ob:localhost/replica:0/task:0/device:GPU:0"](GRAN_graph_op/gradients_2/GRAN_model/generator_models/generator_noise/generator/generator_conv_2/Conv2D_grad/ShapeN, generator/generator_conv_2/kernel/r
ead, GRAN_graph_op/gradients_2/AddN_53, ^GRAN_graph_op/gradients_2/GRAN_model/generator_models/generator_noise/generator/generator_conv_2/BiasAdd_grad/tuple/group_deps)]]
[[{{node GRAN_graph_metrics/ssim/update_op/_221}} = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/
device:GPU:0", send_device_incarnation=1, tensor_name="edge_23675_GRAN_graph_metrics/ssim/update_op", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]
Caused by op u'GRAN_graph_op/gradients_2/GRAN_model/generator_models/generator_noise/generator/generator_conv_2/Conv2D_grad/Conv2DBackpropInput', defined at:
File "main.py", line 70, in 
gran.initialize()
File "main.py", line 33, in initialize
config=self.config)
File "/home/bispl/github/generative_recon/network.py", line 33, in build_network
self.graph.build_graph()
File "/home/bispl/github/generative_recon/graph.py", line 163, in build_graph
self.generator_train = tf.train.AdamOptimizer(learning_rate=self.generator_learning_rate, beta1=0.5, name='generator_optimizer').minimize(self.generator_weighted_loss, var_list=self.generator_v
ariables, name='generator_train')
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py", line 400, in minimize
grad_loss=grad_loss)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py", line 519, in compute_gradients
colocate_gradients_with_ops=colocate_gradients_with_ops)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 630, in gradients
gate_gradients, aggregation_method, stop_gradients)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 814, in _GradientsHelper
lambda: grad_fn(op, *out_grads))
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 408, in _MaybeCompile
return grad_fn()  # Exit early
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 814, in 
lambda: grad_fn(op, *out_grads))
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_grad.py", line 517, in _Conv2DGrad
data_format=data_format),
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py", line 1229, in conv2d_backprop_input
dilations=dilations, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
return func(*args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 3274, in create_op
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1770, in init
self._traceback = tf_stack.extract_stack()
...which was originally created as op u'GRAN_model/generator_models/generator_noise/generator/generator_conv_2/Conv2D', defined at:
File "main.py", line 70, in 
gran.initialize()
[elided 0 identical lines from previous traceback]
File "main.py", line 33, in initialize
config=self.config)
File "/home/bispl/github/generative_recon/network.py", line 32, in build_network
self.graph.build_model(model=self.model)
File "/home/bispl/github/generative_recon/graph.py", line 45, in build_model
self.model.build_model(image_input=self.image_input, bold_input=self.bold_input, unpaired_image_input=self.unpaired_image_input, training=self.training)
File "/home/bispl/github/generative_recon/model.py", line 33, in build_model
self.generator_model_output = self.generator.build_model(image_input=self.image_input, bold_input=self.noise_bold_input, model_scope='generator_noise', reuse=False)
File "/home/bispl/github/generative_recon/model_components.py", line 169, in build_model
_y = tf.layers.conv2d(inputs=_y, filters=256, kernel_size=[7,7], kernel_initializer=self.initializer, kernel_regularizer=self.regularizer, kernel_constraint=self.constraint, strides=1, padding='SAME', name=self.scope+'_conv_2')
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/convolutional.py", line 417, in conv2d
return layer.apply(inputs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 817, in apply
return self.call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py", line 374, in call
outputs = super(Layer, self).call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 757, in call
outputs = self.call(inputs, *args, **kwargs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/convolutional.py", line 194, in call
outputs = self._convolution_op(inputs, self.kernel)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 868, in call
return self.conv_op(inp, filter)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 520, in call
return self.call(inp, filter)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 204, in call
name=self.name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py", line 957, in conv2d
data_format=data_format, dilations=dilations, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
op_def=op_def)
InternalError (see above for traceback): cuDNN Backward Data function launch failure : input shape([16,256,12,16]) filter shape([7,7,256,256])
[[node GRAN_graph_op/gradients_2/GRAN_model/generator_models/generator_noise/generator/generator_conv_2/Conv2D_grad/Conv2DBackpropInput (defined at /home/bispl/github/generative_recon/graph.py:163)  = Conv2DBackpropInput[T=DT_FLOAT, ...dependency"], data_format="NCHW", dilations=[1, 1, 1, 1], padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](GRAN_graph_op/gradients_2/GRAN_model/generator_models/generator_noise/generator/generator_conv_2/Conv2D_grad/ShapeN, generator/generator_conv_2/kernel/read, GRAN_graph_op/gradients_2/AddN_53, ^GRAN_graph_op/gradients_2/GRAN_model/generator_models/generator_noise/generator/generator_conv_2/BiasAdd_grad/tuple/group_deps)]]
[[{{node GRAN_graph_metrics/ssim/update_op/_221}} = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_23675_GRAN_graph_metrics/ssim/update_op", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]
		</comment>
		<comment id='3' author='egyptdj' date='2019-01-08T20:37:55Z'>
		Hello &lt;denchmark-link:https://github.com/azaks2&gt;@azaks2&lt;/denchmark-link&gt;
  &amp; &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 , this user has written a custom regularizer (spectral normalization) that is passed to the tf.layers module, and the behavior is as follows: there is a significant slowdown in the first epoch, and further slowdown in successive epochs, and finally aborts with an error after several epochs. Can you please advise. Thanks.
		</comment>
		<comment id='4' author='egyptdj' date='2019-03-07T07:22:02Z'>
		Hello, &lt;denchmark-link:https://github.com/azaks2&gt;@azaks2&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 . Is this issue on the fix by Tensorflowers or is it still pending? Sorry to make a rush, but if this issue is something that is not to be solved (or which takes a long time to solve), then I need to work on another implementation approach of the algorithm. Thanks.
		</comment>
		<comment id='5' author='egyptdj' date='2019-03-17T16:32:23Z'>
		CC &lt;denchmark-link:https://github.com/tatianashp&gt;@tatianashp&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='egyptdj' date='2019-04-02T23:56:17Z'>
		I do not know what spectral_normalization is, and am not sure why it's crashing But, a kernel_regularizer is supposed to be a callable that takes in a variable, and returns a regularization loss. A  Instead of doing
&lt;denchmark-code&gt;conv_layer = tf.layers.conv2d(inputs=input, filters=128, kernel_regularizer=spectral_normalization)
&lt;/denchmark-code&gt;

Try doing something like
&lt;denchmark-code&gt;conv_layer = tf.layers.Conv2D(filters=128)
output = conv_layer(input)
weight_regularization_op = spectral_normalization(conv_layer.kernel)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='egyptdj' date='2019-12-28T02:03:27Z'>
		Closing the issue since there hasn't been an update since Apr 3.  Please reopen if this is still relevant.
		</comment>
		<comment id='8' author='egyptdj' date='2019-12-28T02:03:29Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24660&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24660&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='egyptdj' date='2020-09-10T17:57:57Z'>
		even i had the same issue which resolve by installing the right version of cudatoolkit
		</comment>
	</comments>
</bug>