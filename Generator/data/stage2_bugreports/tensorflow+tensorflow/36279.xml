<bug id='36279' author='PavelKovalets' open_date='2020-01-28T09:24:28Z' closed_time='2020-03-07T01:14:10Z'>
	<summary>Dimension is expanded for Keras scalar input in eager mode</summary>
	<description>
System information

Have I written custom code: YES
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
Python version: Python 3.7.3
CUDA/cuDNN version: CUDA v10.1 / cuDNN 7.6.4
GPU model and memory: NVIDIA GeForce GTX 1060 with Max-Q Design 6 GB

Describe the current behavior
If input layer for keras model is scalar and model is executing eagerly model.compile(run_eagerly=True) then

The shape of the input tensor is expanded up to 1 dimension (TensorShape([16, 1]) instead of TensorShape([16]) including the batch dimension if batch size is 16.
Warning is shown WARNING:tensorflow:Model was constructed with shape Tensor("the_input:0", shape=(16,), dtype=float32) for input (16,), but it was re-called on a Tensor with incompatible shape (16, 1).

If run_eagerly=False then the shape is as expected.
This is pretty critical in our case because we use scalar input for  argument of &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss&gt;tf.nn.ctc_loss&lt;/denchmark-link&gt;
 which requires tensor of shape  and fails with really vague error if shape is 
Describe the expected behavior
The shape should be kept as specified - TensorShape([16]) - and no warning is shown.
Code to reproduce the issue
import tensorflow as tf
import numpy as np
import sys


batch_size = 16
input_batch = np.ones((batch_size,)).astype(np.float32)


class TestSequence(tf.keras.utils.Sequence):
    def __len__(self):
        return 1

    def __getitem__(self, idx):
        return input_batch, input_batch

# Dummy layer to show the tensor shape
class PrintLayer(tf.keras.layers.Layer):
    def call(self, inputs):
        tf.print(inputs.shape, output_stream=sys.stderr)
        return inputs


# The result is the same if shape=() is used to specify scalar input
input_layer = tf.keras.layers.Input(
    name='the_input', batch_shape=(batch_size,), dtype='float32')
x = PrintLayer()(input_layer)
output_layer = tf.keras.layers.ReLU()(x)
model = tf.keras.models.Model(inputs=[input_layer], outputs=[output_layer])

# If run_eagerly=False then the shapes are correct
model.compile(loss='mse', run_eagerly=True)

model.fit(TestSequence(), epochs=3)
Other info / logs
I've tracked the source of this change up to the following line (callstack below)
&lt;denchmark-code&gt;standardize_single_array, training_utils.py:454
&lt;listcomp&gt;, training_utils.py:529
standardize_input_data, training_utils.py:529
_standardize_tensors, training.py:2410
_standardize_user_data, training.py:2383
train_on_batch, training_v2_utils.py:416
wrapper, api.py:258
_call_for_each_replica, distribute_lib.py:2164
call_for_each_replica, distribute_lib.py:1819
experimental_run_v2, distribute_lib.py:763
distributed_function, training_v2_utils.py:85
execution_function, training_v2_utils.py:98
run_one_epoch, training_v2.py:128
fit, training_v2.py:342
fit, training.py:819
&lt;/denchmark-code&gt;

Seems like the expected shapes are not passed if the eager mode is on (see &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L2391&gt;this line&lt;/denchmark-link&gt;
) and hence the error.
Here is a &lt;denchmark-link:https://gist.github.com/PavelKovalets/2e0bb75fe234d355773f291dd8c4bdb3&gt;link to gist in colab&lt;/denchmark-link&gt;
.
	</description>
	<comments>
		<comment id='1' author='PavelKovalets' date='2020-01-30T10:05:15Z'>
		i am able to replicate the issue, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/f954acee0b06d7b1dbdaabc751ea69a0/untitled11.ipynb&gt;gist&lt;/denchmark-link&gt;
 here.
		</comment>
		<comment id='2' author='PavelKovalets' date='2020-02-05T22:35:05Z'>
		&lt;denchmark-link:https://github.com/PavelKovalets&gt;@PavelKovalets&lt;/denchmark-link&gt;
 This is expected behavior in both Tensorflow Keras and Keras and is being clearly mentioned &lt;denchmark-link:https://github.com/keras-team/keras/issues/12058#issuecomment-455453006&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='PavelKovalets' date='2020-02-07T17:25:23Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 as for me it is quite strange that the behaviour differs when eager is turned on and off. So if the expected behaviour is to always expand dims of a scalar input, why the shape is not changed if I run it with  - it is ? Shouldn't it be consistent?
And by the way does it mean that it is not possible to have scalar input? If so (which is at least seems like an artificial limitation), then maybe it should be mentioned somewhere in documentation and in the &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/14384&gt;related issue&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='PavelKovalets' date='2020-03-07T01:14:09Z'>
		&lt;denchmark-link:https://github.com/PavelKovalets&gt;@PavelKovalets&lt;/denchmark-link&gt;
 Thanks for the issue! This is fixed in the latest nightly 
		</comment>
		<comment id='5' author='PavelKovalets' date='2020-03-07T01:14:11Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36279&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36279&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>