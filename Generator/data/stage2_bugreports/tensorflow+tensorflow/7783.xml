<bug id='7783' author='untom' open_date='2017-02-22T16:32:30Z' closed_time='2017-02-27T02:00:01Z'>
	<summary>Segfault in runtime executor due to variable overflow</summary>
	<description>
I'm running Tensorflow 1.0, and I'm encountering a segfault in tensorflow, with the following output:
&lt;denchmark-code&gt; F tensorflow/core/common_runtime/executor.cc:484] Check failed: e-&gt;src_output() &lt; 32768 (38774 vs. 32768)
 Aborted (core dumped)
&lt;/denchmark-code&gt;

My program loads a fairly large sparse matrix (1879549 samples, 556926 features, 0.000038 of the entries in the matrix are nonzero) into memory. I then create a tf.SparseTensor out of it:
&lt;denchmark-code&gt;# x_indices and x.data are the data for the sparse matrix in the correct format
x_ind = tf.Variable(initial_value=x_indices.astype(np.int64), trainable=False)
x_val = tf.Variable(initial_value=x.data, dtype=tf.float32, trainable=False)
return tf.SparseTensor(x_ind, x_val, dense_shape=x_sparse.shape)
&lt;/denchmark-code&gt;

I then split this SparseTensor into minibatch-sized splits. I have several queue-runners feed that feed a Queue by taking a minibatch, transforming it to dense and putting it into the queue.
In code, the process looks like this (where self._input_x_sp is the SparseTensor):
&lt;denchmark-code&gt;    self.x_shape = self._input_x_sp.get_shape().as_list()
    self.y_shape = self._input_y.get_shape().as_list()
    n_batches = self.x_shape[0] // self.batch_size
    self._x_split = tf.sparse_split(sp_input=self._input_x_sp, num_split=n_batches, axis=0)
    self._y_split = tf.split(self._input_y, num_or_size_splits=n_batches, axis=0, name="y_batch")

    #   ...  creating a Queue

    # build a list of all possible enqueue OPs.
    # We need to do this here while we're still single-threaded, as the
    # Graph creation is not thread-safe
    # Later in the different threads we can just run the OPs
    self._op_list = []
    for i in range(n_batches):
        x_batch = tf.sparse_tensor_to_dense(self._x_split[i], name="x_batch")
        y_batch = self._y_split[i]
        self._op_list.append(self._queue.enqueue_many([x_batch, y_batch]))
&lt;/denchmark-code&gt;

The queue-runners randomly pick an operation from self._op_list and execute it, in a loop.
I am confident that my code is not to blame, as the program runs just fine on smaller input sizes (a sparse matrix of 206208 samples and 133515 features of which 0.000135 nonzero entries), but encounters the segfault on the larger matrix.
Looking at the TF code where the error is generated (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/core/common_runtime/executor.cc#L484&gt;here&lt;/denchmark-link&gt;
) it seems like the cause is a variable in tensorflow that is an unsigned short when it probably should be something larger than that.
	</description>
	<comments>
		<comment id='1' author='untom' date='2017-02-22T21:58:00Z'>
		Thanks for making a detailed analysis of the problem.
		</comment>
		<comment id='2' author='untom' date='2017-02-23T09:07:47Z'>
		You're welcome. I updated my post to remove some duplicated code, and corrected the link to the runtime-executor. If you need any further details let me know.
		</comment>
		<comment id='3' author='untom' date='2017-02-25T05:29:26Z'>
		Should be fixed in the next push.
		</comment>
	</comments>
</bug>