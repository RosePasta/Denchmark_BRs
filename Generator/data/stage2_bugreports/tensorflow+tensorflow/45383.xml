<bug id='45383' author='Bchi1994' open_date='2020-12-03T20:38:52Z' closed_time='2020-12-22T23:33:52Z'>
	<summary>RTX 3070 - CUBLAS_STATUS_ALLOC_FAILED</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom Code
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/A
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): tf-nightly 2.5.0-dev20201203
Python version: 3.8
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 11.1 / 8.0.4.30
GPU model and memory: RTX 3070

&lt;denchmark-code&gt;import warnings
from distutils.version import LooseVersion
import warnings
import tensorflow as tf

# Check TensorFlow Version
assert LooseVersion(tf.__version__) &gt;= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)
print('TensorFlow Version: {}'.format(tf.__version__))

# Check for a GPU
if not tf.test.gpu_device_name():
    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')
else:
    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))
    
    import numpy
import csv

filename = "jokes_plain_tweet_data.txt"
raw_text = open(filename).read()
raw_text = raw_text.lower()

# strip unwanted characters
raw_text = raw_text.replace('"', '')
raw_text = raw_text.replace('\n', '')
raw_text = raw_text.replace('#', '')

# create mapping of unique chars to integers
chars = sorted(list(set(raw_text)))
char_to_int = dict((c, i) for i, c in enumerate(chars))
print(char_to_int)

n_chars = len(raw_text)
n_vocab = len(chars)

# prepare the dataset of input to output pairs encoded as integers
seq_length = 140

dataX = []
dataY = []

# creates a sequence of 100 characters, output contains the corrosponding character that follows.
# window of 'seq_length' that increments across each character.

for i in range(0, n_chars - seq_length, 1):
    seq_in = raw_text[i:(i + seq_length)]
    seq_out = raw_text[i + seq_length]
    
    #append to training data
    dataX.append([char_to_int[char] for char in seq_in])
    dataY.append(char_to_int[seq_out])
    
    
n_patterns = len(dataX)
print("Total Patterns: ", n_patterns)


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Embedding
from tensorflow.keras.layers import Flatten
from tensorflow.keras.callbacks import ModelCheckpoint
from keras.utils import np_utils

physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)

# reshape X to be [samples, time steps, features]
#X = numpy.reshape(dataX, (n_patterns, seq_length, 1))
X = numpy.reshape(dataX, (n_patterns, seq_length, 1))

# normalize
X = X / float(n_vocab)

# one hot encode the output variable
y = np_utils.to_categorical(dataY)

# define the LSTM model
model = Sequential()
model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))
model.add(Dropout(0.25))
model.add(LSTM(128))
model.add(Dropout(0.25))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')

# define the checkpoint
filepath="weights\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
callbacks_list = [checkpoint]

history = model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)



&lt;/denchmark-code&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/66197527/101088390-7de59180-3568-11eb-8c73-cc0d47f1b296.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/66197527/101091615-41686480-356d-11eb-957f-ddfc5d3c22ef.png&gt;&lt;/denchmark-link&gt;

files for code here:
&lt;denchmark-link:https://ea4269d4-d326-4ad3-8762-3cd36a7b1e50.filesusr.com/archives/d9662a_32aa1694580b4fd698345293e04104b2.rar?dn=tensorflow-gpu-tutorial.rar&gt;https://ea4269d4-d326-4ad3-8762-3cd36a7b1e50.filesusr.com/archives/d9662a_32aa1694580b4fd698345293e04104b2.rar?dn=tensorflow-gpu-tutorial.rar&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Bchi1994' date='2020-12-03T21:38:09Z'>
		Based on testing and other models, I believe the bug is in the utils. Any models importing utils cannot run correctly. Any help on this would be greatly appreciated! Code without utils will run.
		</comment>
		<comment id='2' author='Bchi1994' date='2020-12-04T04:41:53Z'>
		&lt;denchmark-link:https://github.com/Bchi1994&gt;@Bchi1994&lt;/denchmark-link&gt;

Can you please try with CUDA 11.0? TF 2.4 (and nightly) is built and tested against CUDA 11.0, not 11.1.
Also the code shared is not in format for us to replicate, if possible please share a colab gist with error reported.
		</comment>
		<comment id='3' author='Bchi1994' date='2020-12-11T05:27:51Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='4' author='Bchi1994' date='2020-12-15T22:57:46Z'>
		Seems to be a recurring issue that is happening with a lot of Ampere Cards. You need to enable memory growth at the start of the script, just after importing tensorflow to stop it from running out of memory.
&lt;denchmark-code&gt;physical_devices = tf.config.list_physical_devices('GPU')
try:
  tf.config.experimental.set_memory_growth(physical_devices[0], True)
except RuntimeError as e:
  print(e)
&lt;/denchmark-code&gt;

You can also skip this step by having the TF_FORCE_GPU_ALLOW_GROWTH environment variable set to TRUE
		</comment>
		<comment id='5' author='Bchi1994' date='2020-12-22T23:33:51Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='6' author='Bchi1994' date='2020-12-22T23:33:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45383&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45383&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>