<bug id='34704' author='pingsutw' open_date='2019-11-29T12:14:08Z' closed_time='2019-12-02T23:54:17Z'>
	<summary>Program aborted after use tf.io.gfile.makedirs</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
TensorFlow installed from (source or binary): pip install tensorflow==1.14.0
TensorFlow version (use command below): 1.14.0
Python version: 3.6.8

&lt;denchmark-code&gt;LSB Version:	:core-4.1-amd64:core-4.1-noarch
Distributor ID:	CentOS
Description:	CentOS Linux release 7.6.1810 (Core) 
Release:	7.6.1810
Codename:	Core
&lt;/denchmark-code&gt;


I follow this &lt;denchmark-link:https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/hadoop.md&gt;link&lt;/denchmark-link&gt;
 to set up Hadoop environment
After execute below snippet of code, my terminal aborted
Describe the expected behavior
should create test directory in hdfs file system
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
tf.io.gfile.makedirs("hdfs://kevin0:8020/user/root/test")
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;FileSystem: loadFileSystems failed error:
(unable to get root cause for java.lang.NoClassDefFoundError)
(unable to get stack trace for java.lang.NoClassDefFoundError)
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00007f6be49c64f1, pid=61570, tid=0x00007f6ca07c0740
#
# JRE version: Java(TM) SE Runtime Environment (8.0_221-b11) (build 1.8.0_221-b11)
# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.221-b11 mixed mode linux-amd64 compressed oops)
# Problematic frame:
# C  [libhdfs.so+0xa4f1]
#
# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again
#
# An error report file with more information is saved as:
# /root/hs_err_pid61570.log
#
# If you would like to submit a bug report, please visit:
#   http://bugreport.java.com/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='pingsutw' date='2019-12-02T19:07:14Z'>
		I resolve this issue, my latest Hadoop compile from source code that don't have libhdfs in lib/native, I download Hadoop-3.2.1, it works for me
		</comment>
		<comment id='2' author='pingsutw' date='2019-12-02T23:54:16Z'>
		Thanks for sharing the solution. Closing this issue.
		</comment>
		<comment id='3' author='pingsutw' date='2019-12-02T23:54:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34704&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34704&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>