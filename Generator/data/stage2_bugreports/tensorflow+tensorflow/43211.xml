<bug id='43211' author='dikshantjn' open_date='2020-09-14T14:53:06Z' closed_time='2020-09-14T19:09:53Z'>
	<summary>Converter Error : for converting saved-model to tflite</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): pip install tensorflow
TensorFlow version (or github SHA if from source): 2.3.0 , also installed tf-nightly

Command used to run the converter or code if youâ€™re using the Python API
If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;# Copy and paste here the exact command
&lt;/denchmark-code&gt;

import tensorflow as tf
saved_model_dir = 'C:\Users\diksh\Desktop\Fine_Tuned_Model\saved_model'
model = tf.saved_model.load(saved_model_dir)
model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[0].set_shape([1, 256, 256, 3])
tf.saved_model.save(model, "saved_model_updated", signatures=model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY])
&lt;denchmark-h:h1&gt;Convert&lt;/denchmark-h&gt;

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_updated', signature_keys=['serving_default'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
&lt;denchmark-h:h2&gt;TFLite Interpreter to check input shape&lt;/denchmark-h&gt;

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()
&lt;denchmark-h:h1&gt;Get input and output tensors.&lt;/denchmark-h&gt;

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
&lt;denchmark-h:h1&gt;Test the model on random input data.&lt;/denchmark-h&gt;

input_shape = input_details[0]['shape']
print(input_shape)
The output from the converter invocation
Exception                                 Traceback (most recent call last)
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
198                                                  debug_info_str,
--&gt; 199                                                  enable_mlir_converter)
200       return model_str
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
37       debug_info_str,
---&gt; 38       enable_mlir_converter)
39
Exception: :0: error: loc("Func/StatefulPartitionedCall/input/_0"): requires all operands and results to have compatible element types
:0: note: loc("Func/StatefulPartitionedCall/input/_0"): see current operation: %1 = "tf.Identity"(%arg0) {_class = ["loc:@Func/StatefulPartitionedCall/StatefulPartitionedCall/input/_702"], device = ""} : (tensor&lt;1x256x256x3x!tf.quint8&gt;) -&gt; tensor&lt;1x256x256x3xui8&gt;
During handling of the above exception, another exception occurred:
ConverterError                            Traceback (most recent call last)
 in 
11 converter.optimizations = [tf.lite.Optimize.DEFAULT]
12 converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
---&gt; 13 tflite_model = converter.convert()
14
15 ## TFLite Interpreter to check input shape
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\lite.py in convert(self)
1074         Invalid quantization parameters.
1075     """
-&gt; 1076     return super(TFLiteConverterV2, self).convert()
1077
1078
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\lite.py in convert(self)
898
899     return super(TFLiteFrozenGraphConverterV2,
--&gt; 900                  self).convert(graph_def, input_tensors, output_tensors)
901
902
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\lite.py in convert(self, graph_def, input_tensors, output_tensors)
631         input_tensors=input_tensors,
632         output_tensors=output_tensors,
--&gt; 633         **converter_kwargs)
634
635     calibrate_and_quantize, flags = quant_mode.quantizer_flags(
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
572       input_data.SerializeToString(),
573       debug_info_str=debug_info_str,
--&gt; 574       enable_mlir_converter=enable_mlir_converter)
575   return data
576
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
200       return model_str
201     except Exception as e:
--&gt; 202       raise ConverterError(str(e))
203
204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:
ConverterError: :0: error: loc("Func/StatefulPartitionedCall/input/_0"): requires all operands and results to have compatible element types
:0: note: loc("Func/StatefulPartitionedCall/input/_0"): see current operation: %1 = "tf.Identity"(%arg0) {_class = ["loc:@Func/StatefulPartitionedCall/StatefulPartitionedCall/input/_702"], device = ""} : (tensor&lt;1x256x256x3x!tf.quint8&gt;) -&gt; tensor&lt;1x256x256x3xui8&gt;
&lt;denchmark-code&gt;# Copy and paste the output here.
&lt;/denchmark-code&gt;

Also, please include a link to the saved model or GraphDef
&lt;denchmark-code&gt;# Put link here or attach to the issue.
&lt;/denchmark-code&gt;

Failure details
If the conversion is successful, but the generated model is wrong,
state what is wrong:

Producing wrong results and/or decrease in accuracy
Producing correct results, but the model is slower than expected (model generated from old converter)

RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.
Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='dikshantjn' date='2020-09-14T15:03:57Z'>
		Please could you share a very, very minimal but complete standalone or colab example that we could copy, past and run to reproduce your issue?
		</comment>
		<comment id='2' author='dikshantjn' date='2020-09-14T15:16:11Z'>
		Here is the link with the jupyter notebooks and saved model data
&lt;denchmark-link:https://drive.google.com/drive/folders/1MCvDti2ygukqw6fGE18WpnFOSzR_AanF?usp=sharing&gt;https://drive.google.com/drive/folders/1MCvDti2ygukqw6fGE18WpnFOSzR_AanF?usp=sharing&lt;/denchmark-link&gt;

Im working on a team where i have been requested to convert the saved_model to a tflite.
The "FLIR_retraining.ipynb" is the file to retrain the model.
and the "TFLite_converter.ipynb" is a shorter version that I have been trying to use for the conversion.
Thank you.
		</comment>
		<comment id='3' author='dikshantjn' date='2020-09-14T16:34:41Z'>
		&lt;denchmark-link:https://github.com/dikshantjn&gt;@dikshantjn&lt;/denchmark-link&gt;
,
I was able to reproduce the error with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/ced1f50c56218d3da7c401a91bb5acbc/43211.ipynb&gt;TF v2.3&lt;/denchmark-link&gt;
.
However, with the latest &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/3c9f9d7540e521fa298398a6e5538bee/43211-tf-nightly.ipynb&gt;TF-nightly&lt;/denchmark-link&gt;
 I was able to run the code without any issues. Please find the attached gist. Thanks!
		</comment>
		<comment id='4' author='dikshantjn' date='2020-09-14T16:46:09Z'>
		I'm still getting the same error:
":0: error: loc("Func/StatefulPartitionedCall/input/_0"): requires all operands and results to have compatible element types
:0: note: loc("Func/StatefulPartitionedCall/input/_0"): see current operation: %1 = "tf.Identity"(%arg0) {_class = ["loc:@Func/StatefulPartitionedCall/StatefulPartitionedCall/input/_702"], device = ""} : (tensor&lt;1x256x256x3x!tf.quint8&gt;) -&gt; tensor&lt;1x256x256x3xui8&gt;"
		</comment>
		<comment id='5' author='dikshantjn' date='2020-09-14T17:40:29Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;

Thank you .... I was able to convert the model to tflite in colab, previously I was trying it on my windows PC
I am now trying to save it on my drive using :
tflite_file = 'Fine_Tuned_Model/head_detector.tflite'
open(tflite_file, "wb").write(tflite_model)
But it is not generating any files
Please help
		</comment>
		<comment id='6' author='dikshantjn' date='2020-09-14T19:09:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43211&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43211&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='dikshantjn' date='2020-09-16T15:31:53Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 here is the colab
&lt;denchmark-link:https://colab.research.google.com/drive/1_9l_DcyNuVV1NxU3PsmSMjWeI9nTEwNS?usp=sharing&gt;https://colab.research.google.com/drive/1_9l_DcyNuVV1NxU3PsmSMjWeI9nTEwNS?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='dikshantjn' date='2020-11-17T18:20:09Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 .... with the latest version of tf-nightly, the  order of output tensors changes. If you could help me understand that and what is the meaning of each of them
		</comment>
		<comment id='9' author='dikshantjn' date='2020-11-23T05:53:11Z'>
		&lt;denchmark-link:https://github.com/dikshantjn&gt;@dikshantjn&lt;/denchmark-link&gt;
,
Could you please submit a new issue from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new/choose&gt;this link&lt;/denchmark-link&gt;
 and fill in the template, so that we can track the issue there. Thanks!
		</comment>
		<comment id='10' author='dikshantjn' date='2020-11-26T11:37:11Z'>
		
@amahendrakar .... with the latest version of tf-nightly, the order of output tensors changes. If you could help me understand that and what is the meaning of each of them

I faced this issue too. Had to debug the shape of each output to get it to work.
Regardless, it worked. Not with the current tf-nightly build but with the one used in the gist posted by &lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/3c9f9d7540e521fa298398a6e5538bee/43211-tf-nightly.ipynb&gt;in this link&lt;/denchmark-link&gt;

i.e. instead of !pip install tf-nightly, i used !pip install tf-nightly==2.4.0.dev20200914
		</comment>
	</comments>
</bug>