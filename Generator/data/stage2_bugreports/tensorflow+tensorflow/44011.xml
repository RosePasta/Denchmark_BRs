<bug id='44011' author='dhruvin2910' open_date='2020-10-14T12:46:16Z' closed_time='2020-12-16T01:00:18Z'>
	<summary>ops defined inside tf.while_loop's cond/body or tf.cond's true_fn/false_fn functions ignore their enclosed tf.device if the tf.while_loop/tf.cond itself is inside a tf.device</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
Python version: Python 3.7.8
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
tf.print doesn't print on specified device (using tf.device) if it is inside a for loop in graph mode.
Initially I though it's an autograph issue. But if you trace the graph and inspect it in tensorboard (color by device), the graph does have that PrintV2 placed where it's supposed to.
Now, I'm not sure why it's happening.
I'm yet to verify if this happens across all the ops, or just the tf.print.
Waiting for the team to let me know what to check next.
Describe the expected behavior
tf.print should print on specified device (using tf.device). Everything works fine if I'm using tf.while_loop instead.
Can be seen from sample code.
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
THIS SNIPPET IS NOT CORRECT ANYMORE, PLEASE READ A COUPLE OF COMMENTS BELOW.
import tensorflow as tf

# assume there's a tf.distribute.Server running on rpi.local:2222
tf.config.experimental_connect_to_cluster(
    tf.train.ClusterSpec({'worker': ['dhruvins-macbook-air.local:2222', 'rpi.local:2222']}),
    job_name='worker',
    task_index=0
)

laptop = '/job:worker/task:0'
rpi = '/job:worker/task:1'


@tf.function
def test_for():
    with tf.device(rpi):
        for i in tf.range(3):
            tf.print('rpi', 'for', i)
            with tf.device(laptop):
                tf.print('laptop', 'for', i)


@tf.function
def test_while():
    def cond(i):
        return i &lt; 3

    def body(i):
        with tf.device(rpi):
            tf.print('rpi', 'while', i)
            with tf.device(laptop):
                tf.print('laptop', 'while', i)
        return [i + 1]

    tf.while_loop(cond, body, [0], parallel_iterations=1)


test_for()
test_while()
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='dhruvin2910' date='2020-10-19T15:26:21Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

I ran this code on nightly, the code keep running and does not produce any output, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/cdad7be80aca26f332c5e366cfbced34/untitled445.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='dhruvin2910' date='2020-10-19T17:52:37Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 One will need to modify their colab code a bit to point to existing (running) (s).
The reason why it's stuck is because it's unable to connect to rpi.local:2222 while running inside colab's container.
The sample code I provided requires at least two tensorflow servers. On same machine, or on different ones (i.e. my case).
 Here's the &lt;denchmark-link:https://colab.research.google.com/gist/dhruvin2910/d8b0765a28b8182303105b29dd57262c/untitled445.ipynb&gt;reproducible version&lt;/denchmark-link&gt;
. Let me know if this suffices.
		</comment>
		<comment id='3' author='dhruvin2910' date='2020-10-20T12:41:03Z'>
		&lt;denchmark-link:https://github.com/dhruvin2910&gt;@dhruvin2910&lt;/denchmark-link&gt;
 there is a notable difference between the two snippets of code: In the autograph case, the  is places outside the loop. In the tf.while_loop case, the  is placed inside the loop. So to make them equivalent, you'd need to either write:
&lt;denchmark-code&gt;for i in tf.range(3):
    with tf.device(rpi):
&lt;/denchmark-code&gt;

or
&lt;denchmark-code&gt;with tf.device(rpi):
    def cond(i):
        ...
    def body(i):
        ...

    tf.while_loop(...)
&lt;/denchmark-code&gt;

And I believe that highlights the bug: if we place a tf.device outside a tf.while_loop, its body does not respect it. Things work as expected when the tf.device is placed inside the loop body. Could you verify that in your setup?
At any rate, this looks like a placement bug in TensorFlow.
		</comment>
		<comment id='4' author='dhruvin2910' date='2020-10-20T12:46:39Z'>
		&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
 You sure this is intended for me? Did you mean to tag dhruvin2910 and accidentally selected me in dropdown somehow? Because although I have contributed to tensorflow in past, I don't think I have touched this part of the code.
Just realized I am logged into this from my work account (JayNakrani) and my personal account (dhananjay92) was tagged
		</comment>
		<comment id='5' author='dhruvin2910' date='2020-10-20T12:49:55Z'>
		&lt;denchmark-link:https://github.com/JayNakrani&gt;@JayNakrani&lt;/denchmark-link&gt;
 sorry about that. I meant to tag &lt;denchmark-link:https://github.com/dhruvin2910&gt;@dhruvin2910&lt;/denchmark-link&gt;
. Not sure how the autocomplete filled your tag.
		</comment>
		<comment id='6' author='dhruvin2910' date='2020-10-20T14:00:18Z'>
		
there is a notable difference between the two snippets of code: In the autograph case, the tf.device is places outside the loop. In the tf.while_loop case, the tf.device is placed inside the loop. So to make them equivalent, you'd need to either write: ...

&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
 Yes, I intended to provide what you just suggested. The problem originated from a bit involving code. Somehow, I missed wrapping the  with  instead, while I was simplifying it to reproduce this issue.

And I believe that highlights the bug: if we place a tf.device outside a tf.while_loop, its body does not respect it. Things work as expected when the tf.device is placed inside the loop body. Could you verify that in your setup?

Yes. &lt;denchmark-link:https://colab.research.google.com/gist/dhruvin2910/d8b0765a28b8182303105b29dd57262c/untitled445.ipynb#scrollTo=vFcc6P_S_ebz&gt;Updated Colab&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='dhruvin2910' date='2020-10-21T03:23:47Z'>
		As I mentioned earlier, the graph seems to have PrintV2 placed on expected device.
I'm unable to upload the logs properly to tensorboard.dev, so here's a screenshot (blue ones are on rpi and green ones are on my macbook):
&lt;denchmark-link:https://user-images.githubusercontent.com/9679326/96669104-27d2db00-137a-11eb-8dc9-63eeaae26a48.png&gt;&lt;/denchmark-link&gt;


At any rate, this looks like a placement bug in TensorFlow.

Yes, I think the problem lies in the execution of the graph.
		</comment>
		<comment id='8' author='dhruvin2910' date='2020-10-21T06:49:10Z'>
		I tested if all ops are misplaced or not with this code.
I don't really know a proper way to find it out. But here's an experiment (and assumptions) to test it:

A very long while loop may be substituted for a long running task (with parallel iterations set to 1)


With proper control_dependencies set, one can measure computation time of a set of ops.
If two devices have different compute power, one can guess the device placement by the amount of time taken, faster task would mean it was placed on the device with better compute.




Since both long running tasks are assigned to different devices, they should run concurrently.
One can guess the device placement is wrong if they are run in sequence. Can be guessed from total time, or from print statements.



def task(n):
    with tf.name_scope('task'):
        return tf.while_loop(lambda i: i &lt; n, lambda i: i + 1, [0], parallel_iterations=1)[0]


def timed(f, *args):
    with tf.name_scope('timed'):
        start = tf.timestamp(name='start')
        with tf.control_dependencies([start]):
            r = f(*args)
        with tf.control_dependencies([r]):
            end = tf.timestamp(name='end')
        return tf.subtract(end, start, name='time'), r


@tf.function
def test_while():
    with tf.device(rpi):
        def cond(i):
            return i &lt; 1

        def body(i):
            t, n = timed(task, 100_000)
            tf.print('rpi', 'while', t, n)
            with tf.device(laptop):
                t, n = timed(task, 100_000)
                tf.print('laptop', 'while', t, n)
            return [i + 1]

        tf.while_loop(cond, body, [0], parallel_iterations=1)
Observations:

The tasks are running in sequence, so there's something more to this story.
I have a rasppberry pi running at 700MHz and a MacBook Air running at 1.8GHz. The tasks take roughly the same time (6s), and the total time was around 12s. Again there's something missing.

&lt;denchmark-code&gt;rpi while 6.2778100967407227 100000
laptop while 6.16434907913208 100000
&lt;/denchmark-code&gt;

Note:
Since I may have made mistakes in my assumptions or the code, I don't think the experiment is conclusive.
I think it may still help further investigation.
		</comment>
		<comment id='9' author='dhruvin2910' date='2020-10-21T07:11:30Z'>
		Just discovered tf.debugging.set_log_device_placement(True), and I can confirm that the device placement is indeed incorrect.
&lt;denchmark-code&gt;...
while/body/_1/while/PrintV2: (PrintV2): /job:worker/replica:0/task:1/device:CPU:0
...
while/body/_1/while/PrintV2_1: (PrintV2): /job:worker/replica:0/task:1/device:CPU:0
...
&lt;/denchmark-code&gt;

Both of these are placed on task:1 (aka rpi).
Also, not just the tf.print, but all the ops in the loop (edit: both cond and body) are are placed incorrectly. Tested with tf.random.uniform.
		</comment>
		<comment id='10' author='dhruvin2910' date='2020-10-21T08:22:38Z'>
		tf.cond and if ...: else: ... (with autograph) both have same problem.
@tf.function
def test_cond():
    with tf.device(rpi):
        def true_fn():
            tf.print('rpi')
            with tf.device(laptop):
                tf.print('laptop')

        def false_fn():
            tf.print('rpi')
            with tf.device(laptop):
                tf.print('laptop')

        tf.cond(tf.greater_equal(tf.random.uniform(()), 0.5), true_fn, false_fn)


@tf.function
def test_if():
    with tf.device(rpi):
        if tf.greater_equal(tf.random.uniform(()), 0.5):
            tf.print('rpi')
            with tf.device(laptop):
                tf.print('laptop')
        else:
            tf.print('rpi')
            with tf.device(laptop):
                tf.print('laptop')
No tf.print (or any other op placed via tf.device) will be placed on laptop
		</comment>
		<comment id='11' author='dhruvin2910' date='2020-10-21T09:02:29Z'>
		After a lot of experiments, here's a concise example of what is working and what is not.
import tensorflow as tf

# assume there's a tf.distribute.Server running on rpi.local:2222
tf.config.experimental_connect_to_cluster(
    tf.train.ClusterSpec({'worker': ['dhruvins-macbook-air.local:2222', 'rpi.local:2222']}),
    job_name='worker',
    task_index=0
)

laptop = '/job:worker/task:0'
rpi = '/job:worker/task:1'


@tf.function
def works():
    def true_fn():
        # this tf.device will be respected
        with tf.device(laptop):
            tf.print('expected on', 'laptop')

    def false_fn():
        # this tf.device will be respected
        with tf.device(rpi):
            tf.print('expected on', 'rpi')

    tf.cond(tf.constant(True), true_fn, false_fn)


@tf.function
def does_not_work():
    # we enclose everything inside a tf.device
    with tf.device(rpi):
        def true_fn():
            # this tf.device will be ignored
            with tf.device(laptop):
                tf.print('expected on', 'laptop')

        def false_fn():
            # this tf.device will be ignored
            with tf.device(rpi):
                tf.print('expected on', 'rpi')

        # tf.cond is in tf.device now
        tf.cond(tf.constant(True), true_fn, false_fn)


works()
does_not_work()
Both calls must print 'expected on laptop' on laptop.
But the second call (aka does_not_work) prints on rpi instead.
&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
 can you verify this?
		</comment>
		<comment id='12' author='dhruvin2910' date='2020-10-21T12:21:01Z'>
		Thanks for the detailed investigation. We're having a closer look at the cause.
Just to double check, in the last snippet you meant tf.device(laptop), right (since the outer device is already rpi)?
		</comment>
		<comment id='13' author='dhruvin2910' date='2020-10-21T14:59:19Z'>
		
Just to double check, in the last snippet you meant tf.device(laptop), right (since the outer device is already rpi)?

works used to flip a coin and printed on a device at random, but to make the code deterministic, I set the condition as True. So in the example false_fn is never evaluated and any of rpi or laptop would work.
I tried to demonstrate that if you take a correctly behaving tf.cond code (works in our example), and wrap it with a tf.device, the ops inside true_fn and false_fn don't get distributed the way they were originally.
All the ops are placed where tf.cond is placed.
		</comment>
		<comment id='14' author='dhruvin2910' date='2020-10-22T00:56:12Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/d3698cdfd94c858092ebbb9af7ab0815e9bc78c1&gt;d3698cd&lt;/denchmark-link&gt;
 should fix the  scope inheritance issue. It also has a test that ops don't always follow cond placement (even if there's a device scope around the cond).
Please give it a try and re-open if something's still broken.
		</comment>
		<comment id='15' author='dhruvin2910' date='2020-10-22T00:56:14Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44011&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44011&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='dhruvin2910' date='2020-10-22T04:33:08Z'>
		Thank you so much &lt;denchmark-link:https://github.com/allenlavoie&gt;@allenlavoie&lt;/denchmark-link&gt;
. I'll see if the issue is fixed in the nightly (when the commit gets in nightly) and let you know.
For my future reference, &lt;denchmark-link:https://colab.research.google.com/gist/dhruvin2910/d8b0765a28b8182303105b29dd57262c/untitled445.ipynb#scrollTo=vFcc6P_S_ebz&gt;colab&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='dhruvin2910' date='2020-10-25T03:36:56Z'>
		&lt;denchmark-link:https://github.com/allenlavoie&gt;@allenlavoie&lt;/denchmark-link&gt;
 I think the commit you added must have arrived in nightly.
I have been trying to see if the issue is still there or not for 3 days, and the problem persists.
See the colab above.
PS: I'm unable to reopen this issue. &lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
 can you still reproduce the issue?
		</comment>
		<comment id='18' author='dhruvin2910' date='2020-10-27T15:00:09Z'>
		&lt;denchmark-link:https://github.com/dhruvin2910&gt;@dhruvin2910&lt;/denchmark-link&gt;
 I'm not sure if the issue can be accurately reproduced in the colab setup. IIUC, the colab doesn't see the output from any of the two cluster workers. At the same time, I suspect w1_proc will capture outputs from both workers.
Looking at the op placement: print(test_while.get_concrete_function().graph.as_graph_def()), if we search for op: "PrintV2", I can see that the two Print ops are placed one on worker/task:0 and worker/task:1, as expected.
I don't know if it's possible to configure a cluster that includes the current colab process. &lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='19' author='dhruvin2910' date='2020-10-27T17:34:45Z'>
		
I'm not sure if the issue can be accurately reproduced in the colab setup. IIUC, the colab doesn't see the output from any of the two cluster workers. At the same time, I suspect w1_proc will capture outputs from both workers.

&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
 I tried a simple  code (example below) and the workers (in the same colab) had correct outputs.
@tf.function
def test():
    with tf.device(w0):
      tf.print("This is a test print. Should be done on w0")
    with tf.device(w1):
      tf.print("This is a test print. Should be done on w1")

Looking at the op placement: print(test_while.get_concrete_function().graph.as_graph_def()), if we search for op: "PrintV2", I can see that the two Print ops are placed one on worker/task:0 and worker/task:1, as expected.

I mentioned exactly this in my previous &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/44011#issuecomment-713271763&gt;#44011 (comment)&lt;/denchmark-link&gt;
. Ops in the graph have proper device assigned, but the ops are placed incorrectly at runtime. See this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/44011#issuecomment-713360321&gt;#44011 (comment)&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='20' author='dhruvin2910' date='2020-10-27T17:50:30Z'>
		Thanks, and sorry I missed those bits. I concur, there is a bug still present in the placement logic. I suggest updating the test colab to make that clearer:
&lt;denchmark-code&gt;@tf.function
def test_while():
    with tf.device(w0):
      tf.print('w0', 'control test')
    with tf.device(w1):
      ...
&lt;/denchmark-code&gt;

		</comment>
		<comment id='21' author='dhruvin2910' date='2020-12-16T00:58:06Z'>
		The second issue looks like it was related to function inlining (when inlining, the function's placement partially overrode the body's placement; conds were inlined as two functions). I have a change that should go through soon for that.
Thank you for the report.
		</comment>
		<comment id='22' author='dhruvin2910' date='2020-12-16T01:00:19Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44011&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44011&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='23' author='dhruvin2910' date='2020-12-19T11:01:08Z'>
		The issue seems to be fixed in 2.4 . Thanks &lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/allenlavoie&gt;@allenlavoie&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>