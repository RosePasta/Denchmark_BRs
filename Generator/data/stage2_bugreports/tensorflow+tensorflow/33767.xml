<bug id='33767' author='olk' open_date='2019-10-27T22:08:50Z' closed_time='2019-11-08T14:01:59Z'>
	<summary>AutoGraph: Error transforming entity / AssertionError: Bad argument number for Name: 3, expecting 4</summary>
	<description>
System information

OS Platform and Distribution: Arch Linux, 5.3.7-arch1-1-ARCH
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0
Kerasversion (use command below): 2.2.4-tf
Python version: 3.7.4
CUDA/cuDNN version: CUDA 10.1.243 / cuDNN 7.6.2.24
GPU model and memory: 2x GTX 1080 Ti 11GB"`

various errors/warnings as: "Entity &lt;function Function._initialize_uninitialized_variables..initialize_variables at 0x7f0f2846c320&gt; could not be transformed and will be executed as-is"

2019-10-27 22:54:04,017 - INFO - Error transforming entity &lt;function Function._initialize_uninitialized_variables..initialize_variables at 0x7f0f2846c320&gt;
Traceback (most recent call last):
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py", line 506, in converted_call
converted_f = conversion.convert(target_entity, program_ctx)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 322, in convert
free_nonglobal_var_names)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 240, in _convert_with_cache
entity, program_ctx)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 469, in convert_entity_to_ast
nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 669, in convert_func_to_ast
node = node_to_graph(node, context)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 698, in node_to_graph
node = converter.standard_analysis(node, context, is_initial=True)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py", line 383, in standard_analysis
node = qual_names.resolve(node)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/qual_names.py", line 254, in resolve
return QnResolver().visit(node)
File "/usr/lib/python3.7/ast.py", line 262, in visit
return visitor(node)
File "/usr/lib/python3.7/ast.py", line 317, in generic_visit
value = self.visit(value)
File "/usr/lib/python3.7/ast.py", line 262, in visit
return visitor(node)
File "/usr/lib/python3.7/ast.py", line 317, in generic_visit
value = self.visit(value)
File "/usr/lib/python3.7/ast.py", line 262, in visit
return visitor(node)
File "/usr/lib/python3.7/ast.py", line 326, in generic_visit
new_node = self.visit(old_value)
File "/usr/lib/python3.7/ast.py", line 262, in visit
return visitor(node)
File "/usr/lib/python3.7/ast.py", line 317, in generic_visit
value = self.visit(value)
File "/usr/lib/python3.7/ast.py", line 262, in visit
return visitor(node)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/qual_names.py", line 236, in visit_Subscript
if isinstance(s.value, gast.Num):
AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity &lt;function Function._initialize_uninitialized_variables..initialize_variables at 0x7f0f2846c320&gt; could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'
2019-10-27 22:54:04,017 - WARNING - Entity &lt;function Function._initialize_uninitialized_variables..initialize_variables at 0x7f0f2846c320&gt; could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'
2019-10-27 22:54:06.670890: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_gru_10450_11011' and '__inference___backward_cudnn_gru_with_fallback_9300_9441_specialized_for_StatefulPartitionedCall_1_at___inference_distributed_function_12398' both implement 'gru_ee50c0e8-e326-45b7-b98e-88e06e2f6f01' but their signatures do not match.


2019-10-27 22:54:01,401 - INFO - Error transforming entity &lt;bound method Output.call of &lt;model.Output object at 0x7f0f3c96aa90&gt;&gt;
Traceback (most recent call last):
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py", line 506, in converted_call
converted_f = conversion.convert(target_entity, program_ctx)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 322, in convert
free_nonglobal_var_names)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 240, in convert_with_cache
entity, program_ctx)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 471, in convert_entity_to_ast
nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 669, in convert_func_to_ast
node = node_to_graph(node, context)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 699, in node_to_graph
node = converter.apply(node, context, function_scopes)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py", line 409, in apply_
node = converter_module.transform(node, context)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py", line 120, in transform
return FunctionBodyTransformer(ctx).visit(node)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py", line 346, in visit
return super(Base, self).visit(node)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py", line 480, in visit
result = super(Base, self).visit(node)
File "/usr/lib/python3.7/ast.py", line 262, in visit
return visitor(node)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py", line 87, in visit_FunctionDef
node = self.generic_visit(node)
File "/usr/lib/python3.7/ast.py", line 317, in generic_visit
value = self.visit(value)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/core/converter.py", line 346, in visit
return super(Base, self).visit(node)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/transformer.py", line 480, in visit
result = super(Base, self).visit(node)
File "/usr/lib/python3.7/ast.py", line 262, in visit
return visitor(node)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py", line 44, in visit_Return
value=node.value)
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/templates.py", line 261, in replace
replacements[k] = _convert_to_ast(replacements[k])
File "/usr/lib/python3.7/site-packages/tensorflow_core/python/autograph/pyct/templates.py", line 223, in _convert_to_ast
return gast.Name(id=n, ctx=None, annotation=None)
File "/usr/lib/python3.7/site-packages/gast/gast.py", line 19, in create_node
format(Name, nbparam, len(Fields))
AssertionError: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:Entity &lt;bound method Output.call of &lt;model.Output object at 0x7f0f3c96aa90&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
2019-10-27 22:54:01,401 - WARNING - Entity &lt;bound method Output.call of &lt;model.Output object at 0x7f0f3c96aa90&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:5783: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version

	</description>
	<comments>
		<comment id='1' author='olk' date='2019-10-29T10:39:05Z'>
		&lt;denchmark-link:https://github.com/olk&gt;@olk&lt;/denchmark-link&gt;
 ,
Can you share a simple and standalone code to reproduce the issue reported?Thanks!
		</comment>
		<comment id='2' author='olk' date='2019-10-29T12:40:51Z'>
		&lt;denchmark-link:https://github.com/oanush&gt;@oanush&lt;/denchmark-link&gt;
 it's not so easy to produce standalone code - I could give you the link to the git repo (contains Makefiles to generate the data and to train the model) alternatively I could post the model code.
It is the same code that causes issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33809&gt;#33809&lt;/denchmark-link&gt;
 '' - maybe both issues are related.
		</comment>
		<comment id='3' author='olk' date='2019-10-29T12:48:51Z'>
		
Model:

&lt;denchmark-code&gt;class FeatureExtraction(Layer):
    def __init__(self, conv_filters, pool_size, name='feature-extraction', **kwargs):
        super(FeatureExtraction, self).__init__(name=name, **kwargs)
        self.conv1 = Conv2D(filters=conv_filters, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer='he_normal', name='conv1')
        self.conv2 = Conv2D(filters=conv_filters, kernel_size=(3, 3), padding='same', activation='relu', kernel_initializer='he_normal', name='conv2')
        self.max1 = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')
        self.max2 = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')

    def call(self, inputs):
        x = self.conv1(inputs)
        x = self.max1(x)
        x = self.conv2(x)
        return self.max2(x)

    def get_config(self):
        return super(FeatureExtraction, self).get_config()


class FeatureReduction(Layer):
    def __init__(self, img_w, img_h, pool_size, conv_filters, name='feature-reduction', **kwargs):
        super(FeatureReduction, self).__init__(name=name, **kwargs)
        target_shape = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)
        self.reshape = Reshape(target_shape=target_shape, name='reshape')
        self.dense = Dense(32, activation='relu', name='dense')

    def call(self, inputs):
        x = self.reshape(inputs)
        return self.dense(x)

    def get_config(self):
        return super(FeatureReduction, self).get_config()


class SequentialLearner(Layer):
    def __init__(self, name='sequential-learner', **kwargs):
        super(SequentialLearner, self).__init__(name=name, **kwargs)
        self.gru_1a = GRU(512, return_sequences=True, kernel_initializer='he_normal', name='gru_1a')
        self.gru_1b = GRU(512, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru_1b')
        self.gru_2a = GRU(512, return_sequences=True, kernel_initializer='he_normal', name='gru_2a')
        self.gru_2b = GRU(512, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru_2b')

    def call(self, inputs):
        x_1a = self.gru_1a(inputs)
        x_1b = self.gru_1b(inputs)
        x = add([x_1a, x_1b])
        x_2a = self.gru_2a(x)
        x_2b = self.gru_2b(x)
        return concatenate([x_2a, x_2b])

    def get_config(self):
        return super(SequentialLearner, self).get_config()


class Output(Layer):
    def __init__(self, output_size, name='output', **kwargs):
        super(Output, self).__init__(name=name, **kwargs)
        self.dense = Dense(output_size, kernel_initializer='he_normal', name='dense')
        self.softmax = Activation('softmax', name='softmax')

    def call(self, inputs):
        x = self.dense(inputs)
        return self.softmax(x)

    def get_config(self):
        return super(Output, self).get_config()


class OCRNet(Model):
    def __init__(self, output_size, img_w, img_h, max_text_len, name='OCRNet', **kwargs):
        # parameters
        conv_filters = 16
        pool_size = 2
        # define layers
        feature_extraction = FeatureExtraction(conv_filters=conv_filters, pool_size=pool_size)
        sequential_learner = SequentialLearner()
        feature_reduction = FeatureReduction(img_w=img_w, img_h=img_h, pool_size=pool_size, conv_filters=conv_filters)
        output = Output(output_size)
        # NHWC == channels_last NCHW == channels_first
        # initialize input shape
        if 'channels_first' == K.image_data_format():
            input_shape = (1, img_w, img_h)
        else:
            input_shape = (img_w, img_h, 1)
        # input
        inputs = Input(name='the_input', shape=input_shape, dtype='float32')
        labels = Input(name='the_labels', shape=[max_text_len], dtype='float32')
        input_length = Input(name='input_length', shape=[1], dtype='int64')
        label_length = Input(name='label_length', shape=[1], dtype='int64')
        # call layers
        x = feature_extraction(inputs)
        x = feature_reduction(x)
        x = sequential_learner(x)
        predictions = output(x)
        # Keras doesn't currently support loss funcs with extra parameters
        # so CTC loss is implemented in a lambda layer
        loss_out = Lambda(self._ctc_lambda_func, output_shape=(1,), name='ctc')([predictions, labels, input_length, label_length])
        super(OCRNet, self).__init__(
                inputs=[inputs, labels, input_length, label_length], outputs=loss_out,
                name=name, **kwargs)

        # ctc decoder
        flattened_input_length = K.reshape(input_length, (-1,))
        top_k_decoded, _ = K.ctc_decode(predictions, flattened_input_length)
        self.decoder = K.function([inputs, flattened_input_length], [top_k_decoded[0]])

    # loss and train functions, network architecture
    def _ctc_lambda_func(self, args):
        predictions, labels, input_length, label_length = args
        # the 2 is critical here since the first couple outputs of the RNN
        # tend to be garbage
        predictions = predictions[:, 2:, :]
        return K.ctc_batch_cost(labels, predictions, input_length, label_length)
&lt;/denchmark-code&gt;


training (stripped):

&lt;denchmark-code&gt;    ...
    strategy = tf.distribute.MirroredStrategy() if 1 &lt; ngpus else tf.distribute.OneDeviceStrategy(device="/gpu:1")
    batch_size = batch_size * strategy.num_replicas_in_sync
   ...
    with strategy.scope():
        model = OCRNet(train_gen.output_size, img_w, img_h, max_text_len)
        model.summary()
        adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
        model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=adam, metrics=['accuracy'])
    callbacks = []
    start = time.perf_counter()
    model.fit(
            train_gen,
            validation_data=val_gen,
            epochs=epochs,
            shuffle=False,
            use_multiprocessing=True,
            workers=6,
            callbacks=callbacks)
    elapsed = time.perf_counter() - start
    logger.info('elapsed: {:0.3f}'.format(elapsed))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='olk' date='2019-11-08T14:01:58Z'>
		Hi, this issue should go away if you downgrade gast to 0.2.2 (pip install gast==0.2.2).
The dependencies in TF 2.0 pull the latest version of gast, which breaks compatibility at 0.3. This should be fixed in 2.1 which pins to this older version.
Please reopen the issue if downgrading didn't work.
		</comment>
		<comment id='5' author='olk' date='2019-11-08T14:02:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33767&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33767&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='olk' date='2019-11-10T07:51:16Z'>
		Thanks a lot ！

Hi, this issue should go away if you downgrade gast to 0.2.2 (pip install gast==0.2.2).
The dependencies in TF 2.0 pull the latest version of gast, which breaks compatibility at 0.3. This should be fixed in 2.1 which pins to this older version.
Please reopen the issue if downgrading didn't work.

		</comment>
	</comments>
</bug>