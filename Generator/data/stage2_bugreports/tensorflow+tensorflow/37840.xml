<bug id='37840' author='jliebers' open_date='2020-03-23T20:42:32Z' closed_time='2020-04-01T17:36:29Z'>
	<summary>validation_split-Parameter in model.fit() leads to severe crashes due to enormous stacktrace</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: No
TensorFlow installed from (source or binary): Installed from Pypi (Python Packaging Index), Version 2.1.0
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
Python version: 3.7.6
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: nvcc -V: release 10.1, V10.1.105
GPU model and memory: GTX 1060, 6 GB

Describe the current behavior
I created the following model and I am using it in a jupyter notebook to learn some data:
&lt;denchmark-code&gt;model = Sequential()
model.add(LSTM(100, input_shape=input_shape, return_sequences=True))
model.add(LSTM(100, return_sequences=True))
model.add(LSTM(100))
model.add(Dense(number_of_classes, activation='softmax'))

model.compile(optimizer=Adam(lr=0.001),
              loss='categorical_crossentropy', 
              metrics=['acc'])

history = model.fit(x=[MODEL_DATA['DATA_TRAIN_PADDED_NORMALIZED']],
                    y=[MODEL_DATA['DATA_LABELS_OHC']],
                    validation_split=0.2,
                    epochs=500,
                    verbose=1)
&lt;/denchmark-code&gt;

When I imported all layers from the keras-package, the code works successfully on the CPU. Yet I would like to use the GPU-accelerated LSTMs (formerly known as CuDNNLSTM, but they are merged in TF 2.1 into LSTM).
To train my model, I am using a jupyter notebook. Sadly, once I changed my imports from the old keras-packages to tensorflow.keras and thus to the GPU-accelerated LSTMs, I suffered from sudden major crashes. And by "major" I mean a crashing jupyter-server that crashes my Firefox as well. When using pycharm with the jupyter notebook plugin, pycharm crashes too.
So I wondered why I had those massive problems across different processes on my machines that occured when I executed tensorflow and my notebook.
As it turns out, I could trace the problem to the following line [0]. It appears that as part of raising the ValueError, x is returned in its constructor in the str.format()-call. Here, x is my complete training data set. This resulted in a dump of 262 MB of text into stderr as part of the stacktrace that then lead to the consequences (crashing jupyter server, crashing browser via websocket-connection to localhost). I found that out by piping the stream to a file, as the exception's message has a len() of 275168064 characters!
Next, I wondered if the bug is still present in the newest version of tensorflow. I could see in git that the corresponding lines of code do not exist anymore when installing tf-nightly (version: v1.12.1-27849-g9278bbfc24 2.2.0-dev20200323 ) as the whole file, training_v2.py, does not exist anymore. Subsequently, I re-ran my code with the current tf-nightly from PyPI. First, I got this error [1], as I did not provide a numpy array.
After changing my model.fit() to the following:
&lt;denchmark-code&gt;history = model.fit(x=np.array([MODEL_DATA['DATA_TRAIN_PADDED_NORMALIZED']]),
                    y=np.array([MODEL_DATA['DATA_LABELS_OHC']]),
                    validation_split=0.2,
                    epochs=500,
                    verbose=1)
&lt;/denchmark-code&gt;

... I ran into the following error [2]:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "C:\Users\Joo\AppData\Local\Programs\Python\Python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "C:\[...]\venv\lib\site-packages\tensorflow\python\ops\variable_scope.py", line 2805, in variable_creator_scope
    yield
  File "C:\[...]\venv\lib\site-packages\tensorflow\python\keras\engine\training.py", line 854, in fit
    epoch_logs = copy.copy(logs)
UnboundLocalError: local variable 'logs' referenced before assignment
&lt;/denchmark-code&gt;

It appears, that logs does not exist here [2].
Not using validation_split as part of model.fit() solved all my problems for tf 2.1.0, but I had to find it out the hard way. üôÅ  Moreover, I could not resolve the problem for tf-nightly at all, even when omitting the parameter as other exceptions popped up.
Thanks in advance for checking the code and improving tensorflow.
[0] 


tensorflow/tensorflow/python/keras/engine/training_v2.py


         Line 539
      in
      f270180






 raise ValueError( 





[1] 


tensorflow/tensorflow/python/keras/engine/data_adapter.py


         Line 1386
      in
      e7bbb42






 raise ValueError( 





[2] 


tensorflow/tensorflow/python/keras/engine/training.py


         Line 857
      in
      c45d13f






 epoch_logs = copy.copy(logs) 





Describe the expected behavior
I would expect an exception that does not return over 260 MB of text as part of the stack trace. The important part of the stack trace (in the beginning of the message) is also not shown (i. e., that validation_split cannot be used), as the 260 MB of x overfill the non-infinite buffer of my IDE in a split second, thus omitting the whole stack trace with my training data.
	</description>
	<comments>
		<comment id='1' author='jliebers' date='2020-03-24T05:44:38Z'>
		&lt;denchmark-link:https://github.com/jliebers&gt;@jliebers&lt;/denchmark-link&gt;

please provide us with complete simple stand alone code for us to replicate the issue faced by you in our local, &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/f99a24679f147526f8466432751ad3f4/untitled106.ipynb&gt;gist of code shared is&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='jliebers' date='2020-03-24T11:32:05Z'>
		Hi &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 ,
thank you for your quick response. üôÇ üöÄ
Please check out this gist: &lt;denchmark-link:https://gist.github.com/jliebers/b9a285ac97607916a10cb091b860fa48&gt;https://gist.github.com/jliebers/b9a285ac97607916a10cb091b860fa48&lt;/denchmark-link&gt;

For the tf-nightly problem, please check the output from above. As described it justs ends in a local variable not being assigned without any large problems.
For the  problem, that resulted in major crashes of jupyter and my browser, please check this gist: &lt;denchmark-link:https://gist.github.com/jliebers/42a3d787aea2595219e48e2abea6c7cf&gt;https://gist.github.com/jliebers/42a3d787aea2595219e48e2abea6c7cf&lt;/denchmark-link&gt;

(Please note the empty output of the last cell. Apparently colab does not execute it at all, but it causes major crashes on my offline-setup with jupyter and firefox)
By moving my code into this example that can be reproduced I found some obvious flaws which on the other hand still should not cause such massive problems. I think the biggest problem is that I did not use numpy but sticked to the standard iterable data structures of python.
To be fair, in my real project I stick to numpy, but since my real notebook became huge I apparently altered some types by mistake in the middle of it, resulting in standard python data structures. (i.e., DATA_NORMALIZED being a list of lists of tuples and LABELS_OHC being a list of lists).
&lt;denchmark-link:https://user-images.githubusercontent.com/24356915/77411807-47daf580-6dbd-11ea-9087-aa7b657e2e0c.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/24356915/77411760-34c82580-6dbd-11ea-9421-d7225af645c2.png&gt;&lt;/denchmark-link&gt;

Thank you in advance for your consideration.
		</comment>
		<comment id='3' author='jliebers' date='2020-03-26T03:07:12Z'>
		I guess this is training issue rather than a LSTM issue, the training logic has been updated recently. Adding &lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='jliebers' date='2020-03-26T08:35:04Z'>
		Hi &lt;denchmark-link:https://github.com/qlzh727&gt;@qlzh727&lt;/denchmark-link&gt;
 ,
thank you and thank you all for your consideration. üôÇ üëç
I just would quickly like to clarify, that the main reason for me to open this issue is, that the raised Exception in tf-2.1.0 contains a string which includes the whole training x (262 MB of text data), thus leading to crashes and such. The tf-nightly issue is of course also a problem but from my perspective way less severe.
Thank you and thank you all for the good work!
		</comment>
		<comment id='5' author='jliebers' date='2020-03-31T04:50:01Z'>
		Thanks  for the report. Will submit the fix very soon.
		</comment>
		<comment id='6' author='jliebers' date='2020-04-01T17:36:28Z'>
		Should be fixed now. Btw, your code is not providing a correct input data to the model. The np.array([list]) will make the a numpy array with shape [1, ?, ?], and instead, you should do np.array(list).
		</comment>
		<comment id='7' author='jliebers' date='2020-04-01T17:36:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37840&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37840&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>