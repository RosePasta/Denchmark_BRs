<bug id='33962' author='netw0rkf10w' open_date='2019-11-04T08:48:08Z' closed_time='2020-01-20T14:13:29Z'>
	<summary>AutoGraph unexpected indent in tf-nightly-gpu-2.1.0.dev20191103</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tf-nightly-gpu-2.1.0.dev20191103
Python version: 3.5.2
CUDA/cuDNN version: 10.0/7.1
GPU model and memory: GTX 1080 Ti

Describe the current behavior
After upgrading to tf-nightly-gpu-2.1.0.dev20191103 from tensorflow-gpu-2.0.0, I obtained this error when running my code:
&lt;denchmark-code&gt;WARNING:tensorflow:AutoGraph could not transform &lt;bound method CRFLayer.mean_field of &lt;models.crf_layer.CRFLayer object at 0x7f6124237b00&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: unexpected indent (&lt;unknown&gt;, line 36)
&lt;/denchmark-code&gt;

I did export AUTOGRAPH_VERBOSITY=10 but did not observe any other types of output other than the above. It says unexpected indent so I guess something changed in the parsing of Python code when building the graph? The problem does not occur on tensorflow-gpu-2.0.0 (I installed tf-nightly-gpu-2.1.0.dev20191103 because I need to be able to load_weights(pretrained_weights, by_name=True, skip_mismatch=True), which is not available in 2.0.0. There is another bug with this function that I will report in a separate issue.)
Describe the expected behavior
Like in TF 2.0.0: no AutoGraph warning.
Code to reproduce the issue
Unfortunately my code has a lot of dependencies and I was unable to create a minimal reproducible example. But from the warning message I guess it's easy enough to check in the source code.
	</description>
	<comments>
		<comment id='1' author='netw0rkf10w' date='2019-11-05T05:37:52Z'>
		&lt;denchmark-link:https://github.com/netw0rkf10w&gt;@netw0rkf10w&lt;/denchmark-link&gt;
 ,
Will you be able to provide Colab link with code you are trying to execute ?Thanks!
		</comment>
		<comment id='2' author='netw0rkf10w' date='2019-11-05T15:46:08Z'>
		Hi &lt;denchmark-link:https://github.com/oanush&gt;@oanush&lt;/denchmark-link&gt;
. Unfortunately this code has a custom TF op in C++ that needs to be compiled. I'm not sure it's possible to do that in Colab. Let me know if sharing a zip file of source code is ok.
		</comment>
		<comment id='3' author='netw0rkf10w' date='2019-11-06T21:54:28Z'>
		&lt;denchmark-link:https://github.com/netw0rkf10w&gt;@netw0rkf10w&lt;/denchmark-link&gt;
 Please share the zip file of source code. Thanks!
		</comment>
		<comment id='4' author='netw0rkf10w' date='2019-11-19T22:49:44Z'>
		&lt;denchmark-link:https://github.com/netw0rkf10w&gt;@netw0rkf10w&lt;/denchmark-link&gt;
 Can you please share the source code?
		</comment>
		<comment id='5' author='netw0rkf10w' date='2019-11-21T14:03:11Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 Sorry for the delay, I have been overwhelmed over the last days. I'm preparing the code.
		</comment>
		<comment id='6' author='netw0rkf10w' date='2019-12-09T22:45:04Z'>
		Closing this issue as it has been inactive for more than 2 weeks. Please add additional comments and we can open this issue again. Thanks!
		</comment>
		<comment id='7' author='netw0rkf10w' date='2019-12-09T22:45:13Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33962&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33962&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='netw0rkf10w' date='2019-12-19T07:11:12Z'>
		We have observed similar issues with TF 2.1-rc0. Cannot share source code, but hopefully I could get a minimal reproducible case later on.
&lt;denchmark-code&gt;WARNING:tensorflow:AutoGraph could not transform &lt;bound method TransformerDecoder._transform of &lt;bytedseq.decoders.transformer_decoder.TransformerDecoder object at 0x7f727cc9e390&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: unexpected indent (&lt;unknown&gt;, line 31)
W1219 06:50:06.045258 140133751701632 ag_logging.py:146] AutoGraph could not transform &lt;bound method TransformerDecoder._transform of &lt;bytedseq.decoders.transformer_decoder.TransformerDecoder object at 0x7f727cc9e390&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: unexpected indent (&lt;unknown&gt;, line 31)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='netw0rkf10w' date='2019-12-19T07:13:35Z'>
		Gently ping &lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
; does this look familiar to you?
		</comment>
		<comment id='10' author='netw0rkf10w' date='2019-12-19T15:04:36Z'>
		These unexpected indent errors are new to me, but it looks like a regression. Setting AUTOGRAPH_VERBOSITY=10 should have given you a whole lot of extra logging. Since autograph outputs to the abseil logger, try adding this somewhere early in your code:
&lt;denchmark-code&gt;from absl import logging
logging.set_verbosity(logging.INFO)
&lt;/denchmark-code&gt;

In the mean time, could you visually inspect the source code of one of the functions that it complains about? Like e.g. TransformerDecoder._transform - does it contain any thing out of the ordinary, like mixing tabs with spaces, backslash \ continuations or anything like that?
As a side note, to get a minimal repro, could you also try the following command: tf.autograph.to_code(TransformerDecoder._transform). It should allow us to test things outside of your main program, even with unbound variables or missing arguments.
		</comment>
		<comment id='11' author='netw0rkf10w' date='2020-01-13T21:47:36Z'>
		Also having this problem on a fairly innocuous piece of code:
&lt;denchmark-code&gt;
def reverse_edges(edges):
    """
    Reverse edges to point from left_node -&gt; right_node to
    right_node -&gt; left_node

    :param edges: dict(('layer', 'idx')), edges

    :return reversed_edges: dict(('layer', idx')), reversed edges
    """
    llayer = edges['layer'][0, 0]
    rlayer = edges['layer'][0, 1]
    reversed_edges = {
            'layer': tf.constant([[rlayer, llayer]]),
            'idx': reverse_edge_idxs(edges['idx']),
            }
    return reversed_edges

def key_to_layers(key):
    """
    Decodes a key into layer numbers.

    :param key: str, node or edge key

    :return llayer: str, left or sender layer number
    :return rlayer: str, right or receiver layer number
    """
    if '_to_' in key:
        llayer, _, rlayer = key.split('_')
    else:
        llayer = rlayer = key.split('_')[-1]
    return llayer, rlayer

def build_edges(edges, load_reverse_edges = False)
    # Reverse edges do not have to be loaded but can be constructed
    # This is the line that causes the autograph issue
    if not load_reverse_edges:
        for k in list(edges.keys()):
            llayer, rlayer = key_to_layers(k)
            if llayer != rlayer:
                edges[connect_key(rlayer, llayer)] = gbuild.reverse_edges(edges[k])
                edges.pop(k)
&lt;/denchmark-code&gt;

where edges is a dictionary containing tensors as values. Not a complete example, but maybe might help isolating the issue?
		</comment>
		<comment id='12' author='netw0rkf10w' date='2020-01-13T22:36:35Z'>
		&lt;denchmark-link:https://github.com/mjlbach&gt;@mjlbach&lt;/denchmark-link&gt;
 I tried your code by passing them directly to autograph, e.g. . I'm not seeing any errors in Python 3.7; I'll try with 3.5 shortly.
If you have the chance, could you try the same test on the function mentioned in the warning message?
		</comment>
		<comment id='13' author='netw0rkf10w' date='2020-01-13T23:42:51Z'>
		Ok, the two errors are:
&lt;denchmark-code&gt;WARNING:tensorflow:AutoGraph could not transform &lt;bound method ParticleGraphConstructorFromRecords.construct_hierarchy_from_records of &lt;boxphysics.model.fromrecords.BoxGraphConstructorFromRecords object at 0x7fbbf055fd68&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: unexpected indent (&lt;unknown&gt;, line 91)
WARNING:tensorflow:AutoGraph could not transform &lt;bound method ParticleGraphConstructorFromRecords.remove_invalid_parts_by_nodes of &lt;boxphysics.model.fromrecords.BoxGraphConstructorFromRecords object at 0x7fbbf055fd68&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: expected an indented block (&lt;unknown&gt;, line 27)
&lt;/denchmark-code&gt;

If I try to run autograph_to_code on the first one, I get:
&lt;denchmark-code&gt;*** IndentationError: unexpected indent
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 831, in to_code
    experimental_optional_features=experimental_optional_features))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 658, in to_graph
    return conversion.convert(entity, program_ctx)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py", line 359, in convert
    free_nonglobal_var_names)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py", line 274, in _convert_with_cache
    entity, program_ctx)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py", line 508, in convert_entity_to_ast
    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py", line 668, in convert_func_to_ast
    node, source = parser.parse_entity(f, future_features=future_features)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py", line 209, in parse_entity
    return _attempt_to_parse_normal_source(source, future_features)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py", line 113, in _attempt_to_parse_normal_source
    return parse(source, preamble_len=len(future_features)), source
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py", line 226, in parse
    module_node = gast.parse(src)
  File "/usr/local/lib/python3.6/dist-packages/gast/gast.py", line 295, in parse
    return ast_to_gast(_ast.parse(*args, **kwargs))
  File "/usr/lib/python3.6/ast.py", line 35, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File "&lt;unknown&gt;", line 91
    if not load_reverse_edges:
&lt;/denchmark-code&gt;

The relevant block of code is :
&lt;denchmark-code&gt;    def construct_hierarchy_from_records(self,
            particles,
            edges,
            node_feat_keys = ['pos', 'mass', 'vel', 'force', 'next_vel',
                'material', 'undeform', 'obj_id', 'mask'],
            is_time_consistent = True,
            load_reverse_edges = False,
            ):
        """
        Constructs a hierarchical graph of colored nodes and edges from tfrecords
        inputs.

        :param particles: dict, particles
        :param edges: dict, colored edges
        :param node_feat_keys: list(str), node feature keys to be added to nodes
        :param is_time_consistent: bool, if true it is assumed that the graph does
                not change over time
        :param load_reverse_edges: bool, if true reverse edges are loaded from files
                instead of being constructed

        :return graph: dict, graph of colored nodes and edges
        """
        # IMPORTANT: TO_PARENT AND TO_CHILD EDGES MUST BE SORTED!!! ASC AND DESC!!!

        # If edges are same across time remove time dimension
        if is_time_consistent:
            for k in edges:
                edges[k] = edges[k][:, 0]
        else:
            raise NotImplementedError('Edges must be consistent across time!')

        # Convert to edge format
        for k in edges:
            if 'inner' in k or 'outer' in k:
                llayer = rlayer = k.split('_')[-1]
            elif 'to' in k:
                llayer, _, rlayer = k.split('_')
            else:
                raise KeyError('Unknown Edge Key "%s"' % k)
            edges[k] = {
                    'layer': np.array([[int(name_key(llayer)), int(name_key(rlayer))]]),
                    'idx': edges[k],
                    }

        # Reverse edges do not have to be loaded but can be constructed
        if not load_reverse_edges:
            for k in list(edges.keys()):
                llayer, rlayer = key_to_layers(k)
                if llayer &gt; rlayer:
                    edges.pop(k)


        # Determine number of nodes per layer
        num_nodes = gbuild.get_num_nodes_per_layer(edges)
        num_nodes[name_key(0)] = tf.shape(particles['mass'])[2]

        # Convert to batch unique idxs
        for k in edges:
            llayer, rlayer = key_to_layers(k)
            lnum_node = num_nodes[llayer]
            rnum_node = num_nodes[rlayer]
            edges[k]['idx'] = gbuild.batch_edge_idxs(edges[k]['idx'], lnum_node, rnum_node)

        # Fold time dimension of particles into state dimension
        batch_dim, node_dim = particles['mass'][:, -1].shape.as_list()[0:2]
        leaf_nodes = {}

        for k in node_feat_keys:
            leaf_nodes[k] = tf.reshape(tf.transpose(particles[k], [0, 2, 1, 3]),
                    [batch_dim, node_dim, -1])
            leaf_nodes[k] = tf.reshape(leaf_nodes[k], [-1, leaf_nodes[k].shape[-1]])

        leaf_nodes['num_children'] = tf.zeros_like(leaf_nodes['mask'])

        nodes = {
                name_key(0): leaf_nodes
                }
        dims = {
                name_key(0): [batch_dim, node_dim]
                }
        valid = {
                name_key(0): tf.reshape(nodes[name_key(0)]['mask'][:, 0] * \
                tf.minimum(nodes[name_key(0)]['obj_id'][:, 0], 1), shape = [-1, 1])
                }

        # Remove invalid nodes and remap edges
        nodes, edges = self.remove_invalid_parts_by_nodes(nodes, edges, layer = name_key(0))
        edges = self.remap_edges_continuous(edges, num_nodes)

        # Construct reverse edges if needed
        if not load_reverse_edges:
            for k in list(edges.keys()):
                llayer, rlayer = key_to_layers(k)
                if llayer != rlayer:
                    edges[connect_key(rlayer, llayer)] = gbuild.reverse_edges(edges[k])

        # Construct higher level nodes
        for layer in range(1, len(num_nodes)):
            layer_nodes = nodes[name_key(0)]
            lindex = edges[connect_key(layer, 0)]['idx'][:, 1:2]
            rindex = edges[connect_key(layer, 0)]['idx'][:, 0]

            parent_nodes = {}
            for k in layer_nodes:
                parent_nodes[k] = tf.math.unsorted_segment_mean(
                        tf.gather_nd(layer_nodes[k], lindex),
                        rindex, gutils.len_index(rindex))

            # Correct mass and avoid zero division
            num_children = tf.math.unsorted_segment_sum(
                    tf.gather_nd(tf.ones(tf.shape(layer_nodes['mass']),
                        dtype = layer_nodes['mass'].dtype), lindex),
                    rindex, gutils.len_index(rindex))
            # TODO Check if works???
            parent_nodes['mass'] /= num_children + \
                    tf.cast(tf.equal(num_children, 0), parent_nodes['mass'].dtype)
            parent_nodes['num_children'] = num_children

            nodes[name_key(layer)] = parent_nodes

        # Convert nodes and edges to graph
        for layer in nodes:
            nodes[layer] = nodes[layer]

        for edge_type in edges:
            edges[edge_type] = edges[edge_type]

        for layer in nodes:
            if layer == name_key(0):
                continue
            dims[layer] = [batch_dim, num_nodes[layer]]

        for layer in nodes:
            if layer == name_key(0):
                continue
            valid[layer] = tf.reshape([nodes[layer]['mask'][:, 0] * \
                    tf.minimum(nodes[layer]['obj_id'][:, 0], 1)], shape = [-1, 1])

        # New graph construction
        graph = {}
        graph['nodes'] = nodes
        graph['edges'] = edges
        graph['dims'] = dims
        graph['valid'] = valid

        return graph
&lt;/denchmark-code&gt;

On the second:
&lt;denchmark-code&gt;*** IndentationError: expected an indented block
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 831, in to_code
    experimental_optional_features=experimental_optional_features))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py", line 658, in to_graph
    return conversion.convert(entity, program_ctx)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py", line 359, in convert
    free_nonglobal_var_names)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py", line 274, in _convert_with_cache
    entity, program_ctx)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py", line 508, in convert_entity_to_ast
    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py", line 668, in convert_func_to_ast
    node, source = parser.parse_entity(f, future_features=future_features)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py", line 209, in parse_entity
    return _attempt_to_parse_normal_source(source, future_features)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py", line 113, in _attempt_to_parse_normal_source
    return parse(source, preamble_len=len(future_features)), source
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py", line 226, in parse
    module_node = gast.parse(src)
  File "/usr/local/lib/python3.6/dist-packages/gast/gast.py", line 295, in parse
    return ast_to_gast(_ast.parse(*args, **kwargs))
  File "/usr/lib/python3.6/ast.py", line 35, in parse
    return compile(source, filename, mode, PyCF_ONLY_AST)
  File "&lt;unknown&gt;", line 27
    llayer, rlayer = key_to_layers(k)
&lt;/denchmark-code&gt;

The relevant block of code is:
&lt;denchmark-code&gt;
    def remove_invalid_parts_by_nodes(self,
            nodes,
            edges,
            layer = name_key(0)
            ):
        """
        Removes invalid nodes and adjusts edges to point to the correct node indices
        after removal for the specified layer.

        :param nodes: dict, colored nodes
        :param edges: dict, colored edges
        :param layer: str, name key of layer

        :return nodes: dict, valid colored nodes
        :return edges: dict, remapped colored edges
        """
        valid_idxs = tf.where(nodes[layer]['mask'][:, 0] * \
                nodes[layer]['obj_id'][:, 0])
        mapping = tf.scatter_nd(
                indices = valid_idxs,
                updates = tf.range(tf.shape(valid_idxs)[0]),
                shape = tf.cast(tf.shape(nodes[layer]['mask'])[0:1], tf.int64),
                )

        for k in edges:
            #test
            llayer, rlayer = key_to_layers(k)

            if llayer != layer and rlayer != layer:
                continue

            lidxs = edges[k]['idx'][:, 0:1]
            ridxs = edges[k]['idx'][:, 1:2]

            if llayer == layer:
                lidxs = gbuild.remap_edge_idxs(lidxs, mapping)

            if rlayer == layer:
                ridxs = gbuild.remap_edge_idxs(ridxs, mapping)

            edges[k]['idx'] = tf.concat([lidxs, ridxs], axis = -1)

        for k in nodes[layer]:
            nodes[layer][k] = tf.gather_nd(nodes[layer][k], valid_idxs)

        return nodes, edges
&lt;/denchmark-code&gt;

		</comment>
		<comment id='14' author='netw0rkf10w' date='2020-01-17T21:38:49Z'>
		Thank you, and sorry for the delay. It looks like the warning is caused by the same bug as &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/35765&gt;#35765&lt;/denchmark-link&gt;
. Removing the backslash continuations worked in my tests. Until that's fixed, any of these workarounds should silence the warning:

removing the backslash continuations
decorating the function with @tf.autograph.experimental.do_not_convert, since it doesn't contain data-dependent control flow

Note that you can use parentheses to break expressions on multiple lines, as alternative to backslash continuations.
		</comment>
		<comment id='15' author='netw0rkf10w' date='2020-01-17T21:43:08Z'>
		
Thank you, and sorry for the delay. It looks like the warning is caused by the same bug as #35765. Removing the backslash continuations worked in my tests. Until that's fixed, any of these workarounds should silence the warning:
* removing the backslash continuations

* decorating the function with @tf.autograph.experimental.do_not_convert, since it doesn't contain data-dependent control flow

Note that you can use parentheses to break expressions on multiple lines, as alternative to backslash continuations.

Thank you!
		</comment>
		<comment id='16' author='netw0rkf10w' date='2020-01-20T14:13:29Z'>
		Backslash continuations should now be properly supported; the fix is in tf-nightly and will be available in TF 2.2.
		</comment>
		<comment id='17' author='netw0rkf10w' date='2020-01-20T14:13:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33962&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33962&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>