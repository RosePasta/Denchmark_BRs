<bug id='8845' author='IgorX2' open_date='2017-03-30T16:02:24Z' closed_time='2017-04-04T15:39:39Z'>
	<summary>Tensorboard not showing data on Windows</summary>
	<description>
I have a simple example of a MNIST classifier that works well for the dataset. However, Tensorboard is unable to read the data from the saved logs. I have inspected the data using tensorboard --inspect --logdir... and the files seem to be in order.
I have tested this and a much simpler model on a different machine, and got the same results. Tensorboard runs and the interface is accessible, but no data is shown (I tested with Google Chrome and Edge).
The code is as follows:
&lt;denchmark-code&gt;from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)

import tensorflow as tf
sess = tf.InteractiveSession()

with tf.name_scope('input'):
    x = tf.placeholder(tf.float32, shape=[None, 784])
    y_ = tf.placeholder(tf.float32, shape=[None, 10])

def variable_summaries(var):
  with tf.name_scope('summaries'):
    mean = tf.reduce_mean(var)
    tf.summary.scalar('mean', mean)
    with tf.name_scope('stddev'):
      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))
    tf.summary.scalar('stddev', stddev)
    tf.summary.scalar('max', tf.reduce_max(var))
    tf.summary.scalar('min', tf.reduce_min(var))
    tf.summary.histogram('histogram', var)

def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1, name='weights')
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape, name='bias')
  return tf.Variable(initial)

def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name='conv')

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool')

with tf.name_scope('conv1'):
    W_conv1 = weight_variable([5, 5, 1, 32])
    b_conv1 = bias_variable([32])
    variable_summaries(W_conv1)
    variable_summaries(b_conv1)

    x_image = tf.reshape(x, [-1, 28, 28, 1], name='reshape')
    tf.summary.image('image', x_image, 3)

    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name='relu')
    h_pool1 = max_pool_2x2(h_conv1)
    variable_summaries(h_conv1)
    variable_summaries(h_pool1)

with tf.name_scope('conv2x'):
    W_conv2x = weight_variable([5, 5, 32, 64])
    b_conv2x = bias_variable([64])
    variable_summaries(W_conv2x)
    variable_summaries(b_conv2x)

    h_conv2x = tf.nn.relu(conv2d(h_pool1, W_conv2x) + b_conv2x, name='relu')
    h_pool2x = max_pool_2x2(h_conv2x)
    variable_summaries(h_conv2x)
    variable_summaries(h_pool2x)

with tf.name_scope('conv2y'):
    W_conv2y = weight_variable([3, 3, 32, 64])
    b_conv2y = bias_variable([64])
    variable_summaries(W_conv2y)
    variable_summaries(b_conv2y)

    h_conv2y = tf.nn.relu(conv2d(h_pool1, W_conv2y) + b_conv2y, name='relu')
    h_pool2y = max_pool_2x2(h_conv2x)
    variable_summaries(h_conv2y)
    variable_summaries(h_pool2y)

with tf.name_scope('concat'):
    h_pool2 = tf.concat([h_pool2x, h_pool2y], 3)
    variable_summaries(h_pool2)

with tf.name_scope('fc1'):
    W_fc1 = weight_variable([7 * 7 * (64*2), 1024])
    b_fc1 = bias_variable([1024])
    variable_summaries(W_fc1)
    variable_summaries(b_fc1)

    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * (64*2)])
    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name='relu')
    variable_summaries(h_pool2_flat)
    variable_summaries(h_fc1)

keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name='dropout')
variable_summaries(h_fc1_drop)

with tf.name_scope('fc2'):
    W_fc2 = weight_variable([1024, 10])
    b_fc2 = bias_variable([10])
    variable_summaries(W_fc2)
    variable_summaries(b_fc2)

    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2
    variable_summaries(y_conv)

learning_rate = tf.placeholder(tf.float32, shape=[])
tf.summary.scalar('learning_rate', learning_rate)

with tf.name_scope('loss'):
    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv)
    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)
    variable_summaries(cross_entropy)

correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')
tf.summary.scalar('accuracy', accuracy)

merged = tf.summary.merge_all()
train_writer = tf.summary.FileWriter('summaries/train', sess.graph)
test_writer = tf.summary.FileWriter('summaries/test', sess.graph)

tf.global_variables_initializer().run()

for i in range(101):
  batch = mnist.train.next_batch(100)
  summary, _, acc = sess.run([merged, train_step, accuracy], feed_dict={x:batch[0], y_: batch[1], learning_rate:0.02, keep_prob: 0.5})
  train_writer.add_summary(summary, i)
  #train_writer.add_graph(sess.graph, i)
  print("step %d, training accuracy %g" % (i, acc))
  if i % 100 == 0:
    #This is just a test model, the accuracy is not important
    batch = mnist.test.next_batch(100)
    summary, acc = sess.run([merged, accuracy], feed_dict={x:batch[0], y_: batch[1], learning_rate:0, keep_prob: 1.0})
    test_writer.add_summary(summary, i)
    print("step %d, test accuracy %g" % (i, acc))

train_writer.close()
test_writer.close()
&lt;/denchmark-code&gt;

The logs are provided below.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/883033/summaries.zip&gt;summaries.zip&lt;/denchmark-link&gt;

System information:
Windows 10
CUDA 8.0, cuDNN 5.0
Tensorflow 1.0.1
Python 3.5 64-bit
	</description>
	<comments>
		<comment id='1' author='IgorX2' date='2017-03-30T19:16:15Z'>
		Please include all the information required by the issue template.
		</comment>
		<comment id='2' author='IgorX2' date='2017-03-31T14:24:23Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
: I updated the issue description.
		</comment>
		<comment id='3' author='IgorX2' date='2017-04-01T21:20:03Z'>
		I've verified that the train summary loads in tensorboard on Mac OS X. I don't have a windows machine to test. &lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 can you let us know if Windows tensorboard is expected to work?
		</comment>
		<comment id='4' author='IgorX2' date='2017-04-03T10:25:23Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/IgorX2&gt;@IgorX2&lt;/denchmark-link&gt;
 I have managed to run your script and appear to be getting full Tensorboard functionality in in Windows. Your code appears to be coded fine.
Can I please ask you for the following to help troubleshoot this.

What command did you run for Tensorboard.
Where on your disk do your summaries go? Are they in a folder called summaries below where your code is being executed or are they in a folder called summaries at root?
Do you get anything in the graphs section?
Can you please try a different directory, perhaps at root (i.e. C;/summaries) and try to fetch the logs from there?

This sounds like it could be a permissions error as I am unable to reproduce your error but instead get your full Tensorboard results. If not then perhaps it is in an error within your installation? I am happy to help you troubleshoot this.
		</comment>
		<comment id='5' author='IgorX2' date='2017-04-03T15:15:21Z'>
		&lt;denchmark-link:https://github.com/jubjamie&gt;@jubjamie&lt;/denchmark-link&gt;
 Thanks for looking into this! Were you also running with version 1.0.1?
&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/IgorX2&gt;@IgorX2&lt;/denchmark-link&gt;
 TensorBoard is expected to work on Windows, although there are some wrinkles around (e.g.) TensorBoard options that are colon-delimited and get confused by Windows paths. Seeing the full command, as &lt;denchmark-link:https://github.com/jubjamie&gt;@jubjamie&lt;/denchmark-link&gt;
 suggests, would help to diagnose this.
		</comment>
		<comment id='6' author='IgorX2' date='2017-04-03T16:10:19Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 Yes 1.0.1, I have a feeling that this is either permissions related or, more likely, to do with the actual file locations vs. whats typed in i.e. summaries/train =/= /summaries/train
I see little other reason for Tensorboard to not show the data apart from a corrupt installation. &lt;denchmark-link:https://github.com/IgorX2&gt;@IgorX2&lt;/denchmark-link&gt;
 May I suggest that you see if you can copy &amp; paste a Tensorboard tutorial and see if that works and make sure that you are able to read files correctly.
		</comment>
		<comment id='7' author='IgorX2' date='2017-04-04T08:53:17Z'>
		I managed to get it working, but I still believe there is a bug.
Here is what I tried:

Place the files in the project directory
Place the files in the root of D:
Place the files in the root of D: and use / instead of \ in path
Place the files in the root of C: (this is the only one that worked)

Also, using tensorboard --inspect ... on all three locations found the files and listed their contents.
		</comment>
		<comment id='8' author='IgorX2' date='2017-04-04T15:39:39Z'>
		Thanks for  confirming this. The underlying problem is the same as &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7856&gt;#7856&lt;/denchmark-link&gt;
, which arises because TensorBoard uses a  to separate the run name from the log directory in its command-line flags, which is fine on Linux but on Windows it clashes with the use of  in the drive name. I suggested a workaround on the thread for &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7856&gt;#7856&lt;/denchmark-link&gt;
, and I'd encourage you to comment there if you have further problems with this.
/cc &lt;denchmark-link:https://github.com/dandelionmane&gt;@dandelionmane&lt;/denchmark-link&gt;
 FYI.
		</comment>
	</comments>
</bug>