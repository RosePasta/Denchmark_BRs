<bug id='36508' author='ARozental' open_date='2020-02-06T11:27:23Z' closed_time='2020-03-20T20:31:24Z'>
	<summary>keras LSTM Fail to find the dnn implementation</summary>
	<description>
System information

CUDA/cuDNN version: 10.1
GPU model and memory: GeForce RTX 2080
TF 2.1.0:

uncommenting the LSTM layer will yield the following error:
&lt;denchmark-code&gt;UnknownError:  [_Derived_]  Fail to find the dnn implementation.
	 [[{{node CudnnRNN}}]]
	 [[sequential_6/bidirectional_2/backward_lstm_3/StatefulPartitionedCall]]
	 [[Reshape_11/_38]] [Op:__inference_distributed_function_39046]
&lt;/denchmark-code&gt;

working code:
&lt;denchmark-code&gt;model = tf.keras.Sequential([
    tf.keras.layers.Embedding(encoder.vocab_size, 64),
    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',
              optimizer=tf.keras.optimizers.Adam(1e-4),
              metrics=['accuracy'])
history = model.fit(train_dataset, epochs=10,
                    validation_data=test_dataset, 
                    validation_steps=30)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ARozental' date='2020-02-07T05:19:01Z'>
		&lt;denchmark-link:https://github.com/ARozental&gt;@ARozental&lt;/denchmark-link&gt;
  Could you please provide us with supporting files and complete stand alone code to replicate the issue in our environment.
		</comment>
		<comment id='2' author='ARozental' date='2020-02-09T12:34:29Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

the code is from one of the TF official tutorials and the working version is attached here, uncommenting the LSTM line will raise the error:
&lt;denchmark-code&gt;from __future__ import absolute_import, division, print_function, unicode_literals
import os
import tensorflow_datasets as tfds
import tensorflow as tf
from tensorflow.python.client import device_lib

dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,
                          as_supervised=True)
train_dataset, test_dataset = dataset['train'], dataset['test']

BUFFER_SIZE = 10000
BATCH_SIZE = 64

train_dataset = train_dataset.shuffle(BUFFER_SIZE)
train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)

test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)
encoder = info.features['text'].encoder


model = tf.keras.Sequential([
    tf.keras.layers.Embedding(encoder.vocab_size, 64),
    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',
              optimizer=tf.keras.optimizers.Adam(1e-4),
              metrics=['accuracy'])
history = model.fit(train_dataset, epochs=10,
                    validation_data=test_dataset, 
                    validation_steps=30)
&lt;/denchmark-code&gt;

Also, I use ubuntu 18.04.
Thanks.
		</comment>
		<comment id='3' author='ARozental' date='2020-02-10T09:52:22Z'>
		&lt;denchmark-link:https://github.com/alonRozental&gt;@alonRozental&lt;/denchmark-link&gt;
  I ran the code [on nightly] after un-commenting the LSTM line and did not face any issues, please find the gist &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/f1b1a090b3308b7ae5539594bf8bbddb/36508.ipynb&gt;here&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='ARozental' date='2020-02-10T10:16:17Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
  I'm running TF 2.1.0.
I don't think the problem exists in TF1 which is used in the notebook.
also making the following change makes the code work:
&lt;denchmark-code&gt;    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(64))),
&lt;/denchmark-code&gt;

I would think that those 2 lines should do the same thing (please correct me if I'm wrong) but it seems only the second line works.
		</comment>
		<comment id='5' author='ARozental' date='2020-02-11T09:46:40Z'>
		&lt;denchmark-link:https://github.com/ARozental&gt;@ARozental&lt;/denchmark-link&gt;
 I ran the code on nightly ['2.2.0-dev20200210'] and on tensorflow==2.1.0, un-commenting the LSTM line as requested by you and did not face any issues,  please find the gist of 2.1.0 &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/6e154d2e10a11bf658ce742182066fd1/latest.ipynb&gt;here&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='ARozental' date='2020-02-11T11:20:47Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 than I don't know how to replicate it on Colab, maybe it only occurs with specific hardware (ti 2080). In anyway, can you confirm that those 2 lines should do the exact same thing? if this is indeed the case we can look at the difference (that shouldn't exist) between the 2 implementations to find the bug.
		</comment>
		<comment id='7' author='ARozental' date='2020-02-11T20:32:51Z'>
		me too
&lt;denchmark-code&gt;tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-02-12 04:48:50.916938: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at cudnn_rnn_ops.cc:1510 : Unknown: Fail to find the dnn implementation.
2020-02-12 04:48:50.923690: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Fail to find the dnn implementation.
         [[{{node CudnnRNN}}]]
2020-02-12 04:48:50.931195: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: {{function_node __inference_cudnn_lstm_with_fallback_1954_specialized_for_sequential_1_lstm_StatefulPartitionedCall_at___inference_distributed_function_2139}} {{function_node __inference_cudnn_lstm_with_fallback_1954_specialized_for_sequential_1_lstm_StatefulPartitionedCall_at___inference_distributed_function_2139}} Fail to find the dnn implementation.
         [[{{node CudnnRNN}}]]
         [[sequential_1/lstm/StatefulPartitionedCall]]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='ARozental' date='2020-02-11T22:57:16Z'>
		&lt;denchmark-link:https://github.com/Lay4U&gt;@Lay4U&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ARozental&gt;@ARozental&lt;/denchmark-link&gt;
 Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
&lt;denchmark-code&gt;import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='ARozental' date='2020-02-16T07:10:44Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 It doesn't help
		</comment>
		<comment id='10' author='ARozental' date='2020-03-01T16:57:57Z'>
		I confirm that it does not help
		</comment>
		<comment id='11' author='ARozental' date='2020-03-02T06:12:40Z'>
		I confirm that it does not help
		</comment>
		<comment id='12' author='ARozental' date='2020-03-04T17:50:49Z'>
		
@Saduf2019 I'm running TF 2.1.0.
I don't think the problem exists in TF1 which is used in the notebook.
also making the following change makes the code work:
    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(64))),

I would think that those 2 lines should do the same thing (please correct me if I'm wrong) but it seems only the second line works.

Those two line will build different graph under the hood, but should produce same math result.
The first line will use cudnn kernel on GPU if GPU is available, whereas the second line will use generic kernel on GPU.
Adding @houtoms from Nvidia side. Is there any recent change to the kernel CudnnRNN?
		</comment>
		<comment id='13' author='ARozental' date='2020-03-04T17:59:12Z'>
		I wasn't able to produce this issue on a GPU colab as well. I think this somehow indicate its a environment issue, we probably should check the cuda kernel version.
		</comment>
		<comment id='14' author='ARozental' date='2020-03-05T21:29:16Z'>
		From the error log, the cuDNN didn't successfully create the handler. So, it seems not to be a CuDNN RNN issue. Can you try some convolution examples to see if the cuDNN is able to create handler? &lt;denchmark-link:https://github.com/ARozental&gt;@ARozental&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='ARozental' date='2020-03-20T20:31:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36508&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36508&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='ARozental' date='2020-03-29T19:31:28Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


this resolved the issue in my case.. Using:

CUDA 12.2
tf.version is 2.1.0
tf.keras.version is: 2.2.4-tf
Python 3.7.4
cuDNN v7.6.5 (November 18th, 2019), for CUDA 10.2

		</comment>
		<comment id='17' author='ARozental' date='2020-04-24T20:41:11Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


Ran into this same issue and this option also fixed it for me (fresh install of Anaconda 4.8.2, tensorflow-gpu 2.1.0 installed via Conda). Thanks!
		</comment>
		<comment id='18' author='ARozental' date='2020-04-27T01:12:07Z'>
		

@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


Ran into this same issue and this option also fixed it for me (fresh install of Anaconda 4.8.2, tensorflow-gpu 2.1.0 installed via Conda). Thanks!

Are you using windows or linux?
		</comment>
		<comment id='19' author='ARozental' date='2020-04-28T19:15:15Z'>
		&lt;denchmark-link:https://github.com/talhaanwarch&gt;@talhaanwarch&lt;/denchmark-link&gt;
 sorry, just noticed this question was to me. This is on Windows 10.
		</comment>
		<comment id='20' author='ARozental' date='2020-05-11T00:32:12Z'>
		I got the same problem, which is solved by this. Thanks a lot!

@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


		</comment>
		<comment id='21' author='ARozental' date='2020-05-14T03:17:01Z'>
		Just a heads up I had this error but I noticed in the output this error as well
&lt;denchmark-code&gt;Loaded runtime CuDNN library: 7.1.3 but source was compiled with: 7.6.4.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version.
&lt;/denchmark-code&gt;

Resolved by updating my conda env with
&lt;denchmark-code&gt;conda install -c anaconda cudnn
&lt;/denchmark-code&gt;

		</comment>
		<comment id='22' author='ARozental' date='2020-05-18T22:33:04Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


worked for me with
CUDA/cuDNN version: 10.1
GPU model and memory: GeForce RTX 2080 Ti
TF 2.1.0:
		</comment>
		<comment id='23' author='ARozental' date='2020-05-18T22:48:54Z'>
		I have similar issues. The memory_growth trick worked in the past but seems to have no effect now. GPU is detected and used, but the dnn implementation error is constant.
Fail to find the dnn implementation
Ubuntu 20.04 or 18.04
TF2.2 or 2.1
CUDA/cuDNN version: 10.2
GPU model and memory: GeForce RTX 2080 Super
I cannot get cuda 10.1 properly as the GPU guide on tensorflow website suggest.
Upon running it, one of the packages bumps the NVIDIA driver to 440 and subsequently cuda to 10.2
Was working until last week, so some tampering from my side must have helped break it. Now even with a clean install, drivers purge and re-install, etc, nothing works. :/
		</comment>
		<comment id='24' author='ARozental' date='2020-05-18T23:08:08Z'>
		
I have similar issues. The memory_growth trick worked in the past but seems to have no effect now. GPU is detected and used, but the dnn implementation error is constant.
Fail to find the dnn implementation
Ubuntu 20.04 or 18.04
TF2.2 or 2.1
CUDA/cuDNN version: 10.2
GPU model and memory: GeForce RTX 2080 Super
I cannot get cuda 10.1 properly as the GPU guide on tensorflow website suggest.
Upon running it, one of the packages bumps the NVIDIA driver to 440 and subsequently cuda to 10.2
Was working until last week, so some tampering from my side must have helped break it. Now even with a clean install, drivers purge and re-install, etc, nothing works. :/

I used the steps in the following link in order to get cuda version 10.1 (instead of 10.2) on my Ubuntu 18.04
&lt;denchmark-link:https://askubuntu.com/questions/1077061/how-do-i-install-nvidia-and-cuda-drivers-into-ubuntu&gt;https://askubuntu.com/questions/1077061/how-do-i-install-nvidia-and-cuda-drivers-into-ubuntu&lt;/denchmark-link&gt;

		</comment>
		<comment id='25' author='ARozental' date='2020-05-20T08:25:41Z'>
		I do have 10.1 installed and loaded but TF fails the same way.
Ironically, the line before failure is
&lt;denchmark-code&gt;Successfully opened dynamic library libcudnn.so.7
&lt;/denchmark-code&gt;

and the only error I get is when training, our old friend
&lt;denchmark-code&gt;tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at cudnn_rnn_ops.cc:1510 : Unknown: Fail to find the dnn implementation.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='26' author='ARozental' date='2020-05-20T14:33:49Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


Just wanted to response, to say thank you. That works for me, as well.
OS: Windows 10
CUDA/cuDNN: 10.1
GPU: GeForce RTX 2060 Super 8GB
TF: 2.2.0
		</comment>
		<comment id='27' author='ARozental' date='2020-06-03T06:36:19Z'>
		gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
tf.config.experimental.set_visible_devices(devices=gpus[1], device_type='GPU')
tf.config.experimental.set_memory_growth(device=gpus[1], enable=True)
above work for me.
		</comment>
		<comment id='28' author='ARozental' date='2020-06-06T11:08:49Z'>
		Ok I managed to make it work after fighting with CUDA 10.1 and 10.2 (10.2 works nice with 2.3 nightly) for a while, environments, OS and everything.
Narrowed it to a seeming harmless line
I was running tf.test.gpu_device_name() to check there was a GPU and print its name. That command when run at any time makes the model fail on train with the mentioned error: Unknown: Fail to find the dnn implementation
The  command that &lt;denchmark-link:https://github.com/shaoeChen&gt;@shaoeChen&lt;/denchmark-link&gt;
 mentioned didn't change anything for me so I removed it.
I managed to make it work more reliably running this right after importing tensorflow (and other libs, but I don't think it changes anything)
&lt;denchmark-code&gt;gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
tf.config.experimental.set_memory_growth(device=gpus[0], enable=True)
&lt;/denchmark-code&gt;

Is this a known bug or some unintended behaviour?
		</comment>
		<comment id='29' author='ARozental' date='2020-06-14T08:53:58Z'>
		
Just a heads up I had this error but I noticed in the output this error as well
Loaded runtime CuDNN library: 7.1.3 but source was compiled with: 7.6.4.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version.

Resolved by updating my conda env with
conda install -c anaconda cudnn


Yes, simply works! Thank you.
		</comment>
		<comment id='30' author='ARozental' date='2020-07-11T08:57:52Z'>
		Why this is closed? I got the same error in ubuntu 20.04 jupyterlab '2.1.5' tensorflow 2.2.0 (with GPU) CUDA Version 10.1.105 when building a model in jupyter-lab using a kernel having tensorflow 2.2.0
Only thing that helped is the workaround presented earlier:
&lt;denchmark-code&gt;from tensorflow.keras.layers import RNN, LSTMCell
def build_model(feature_count=feature_count, seq_len=seq_len):
    inputs = tensorflow.keras.Input(shape=(seq_len, feature_count))
    X = RNN(LSTMCell(units=seq_len), input_shape=(seq_len, feature_count), return_sequences=True, stateful=False)(inputs)

&lt;/denchmark-code&gt;

terveisin, Markus
		</comment>
		<comment id='31' author='ARozental' date='2020-07-14T23:04:07Z'>
		
@Lay4U @ARozental Please use the below code while importing TensorFlow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


Hello,
Thanks &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 
This solved my problem. My configuration is:
: Windows 10 x64
 : 3.6
 : 2.2.0
 : 10.1
 : 7.6.5
		</comment>
		<comment id='32' author='ARozental' date='2020-07-28T12:31:16Z'>
		
conda install -c anaconda cudnn


This worked for us when getting
&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.UnknownError:  [_Derived_]  Fail to find the dnn implementation.
&lt;/denchmark-code&gt;

Thanks &lt;denchmark-link:https://github.com/ElliotVilhelm&gt;@ElliotVilhelm&lt;/denchmark-link&gt;

		</comment>
		<comment id='33' author='ARozental' date='2020-08-21T07:22:14Z'>
		
gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
tf.config.experimental.set_visible_devices(devices=gpus[1], device_type='GPU')
tf.config.experimental.set_memory_growth(device=gpus[1], enable=True)
above work for me.

also worked for me (tf 2.3). Does this mean CUDA was not installed correctly or is this a tensorflow bug?
		</comment>
		<comment id='34' author='ARozental' date='2020-08-29T18:54:24Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


Worked for me. tks.
Running BiLSTM on TF2.1 with two 2080S
		</comment>
		<comment id='35' author='ARozental' date='2020-09-03T08:07:29Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


It solved my problem.   Using tf 2.2.0 with one 2070s.
		</comment>
		<comment id='36' author='ARozental' date='2020-10-14T04:57:08Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


It worked for me, running GRU using TF 2.3.0 with one 2060. Thanks!
		</comment>
		<comment id='37' author='ARozental' date='2020-10-15T05:07:23Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


This solves the problem for me as well.
OS: Ubuntu 18.04
Python : 3.6.9
TensorFlow-GPU : 2.3.0
Cuda : 10.1
Cudnn : 7.6.5
		</comment>
		<comment id='38' author='ARozental' date='2020-11-16T14:20:50Z'>
		thx, solved the problem:
linux mint 20
geforce RTX 2060
		</comment>
		<comment id='39' author='ARozental' date='2020-12-12T20:53:22Z'>
		I think a lot of the cuDNN related problems could be solved by adding these code.
&lt;denchmark-link:https://leimao.github.io/blog/TensorFlow-cuDNN-Failure/&gt;https://leimao.github.io/blog/TensorFlow-cuDNN-Failure/&lt;/denchmark-link&gt;

		</comment>
		<comment id='40' author='ARozental' date='2020-12-24T01:53:44Z'>
		
@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)


this solved it for me.  What does this do exactly?
		</comment>
	</comments>
</bug>