<bug id='41846' author='OmriTreidel' open_date='2020-07-29T03:27:44Z' closed_time='2020-10-03T00:31:10Z'>
	<summary>Missing "model" in visualize.py script: tflite model AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.4.0
Python version: 3.8.1
Bazel version (if compiling from source): 3.1.0
GCC/Compiler version (if compiling from source): (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA/cuDNN version: N/A
GPU model and memory: N/A

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)" v1.12.1-37714-gac84c5eb81 2.4.0

**I followed the &lt;denchmark-link:https://www.tensorflow.org/lite/guide/faq#how_do_i_inspect_a_tflite_file&gt;instructions&lt;/denchmark-link&gt;
 in order to inspect a tflite file. Compilation and installation of the python whl was successful. pip freeze shows
tensorflow @ file:///tmp/tensorflow_pkg/tensorflow-2.4.0-cp38-cp38-linux_x86_64.whl. Starting the python consul and importing tensorflow works as expected.
However, running
python visualize.py foo.tflite foo.html
results in a an error
Traceback (most recent call last):
File "visualize.py", line 517, in 
main(sys.argv)
File "visualize.py", line 513, in main
CreateHtmlFile(tflite_input, html_output)
File "visualize.py", line 429, in CreateHtmlFile
data = CreateDictFromFlatbuffer(file_data)
File "visualize.py", line 414, in CreateDictFromFlatbuffer
model_obj = schema_fb.Model.GetRootAsModel(buffer_data, 0)
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'
In addition,
bazel run //tensorflow/lite/tools:visualize model.tflite visualized_model.html
results in a similar error
INFO: Options provided by the client:
Inherited 'common' options: --isatty=1 --terminal_columns=153
INFO: Reading rc options for 'run' from /home/omri/src/tensorflow/.bazelrc:
Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'run' from /home/omri/src/tensorflow/.bazelrc:
Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'run' from /home/omri/src/tensorflow/.tf_configure.bazelrc:
Inherited 'build' options: --action_env PYTHON_BIN_PATH=/home/omri/.pyenv/versions/tf_src/bin/python3 --action_env PYTHON_LIB_PATH=/home/omri/.pyenv/versions/tf_src/lib/python3.8/site-packages --python_path=/home/omri/.pyenv/versions/tf_src/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /home/omri/src/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/omri/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/omri/src/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:linux in file /home/omri/src/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/omri/src/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/lite/tools:visualize (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
Target //tensorflow/lite/tools:visualize up-to-date:
bazel-bin/tensorflow/lite/tools/visualize
INFO: Elapsed time: 0.132s, Critical Path: 0.01s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
INFO: Running command line: bazel-bin/tensorflow/lite/tools/visualize /home/omri/Downloads/mobilenet_thin_openpose_opt_fullint_tf1.tflite /home/omri/DownINFO: Build completed successfully, 1 total action
Traceback (most recent call last):
File "/home/omri/.cache/bazel/_bazel_omri/a9e9b87cb64d67149db4f28645a2ba4b/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/visualize.runfiles/org_tensorflow/tensorflow/lite/tools/visualize.py", line 517, in 
main(sys.argv)
File "/home/omri/.cache/bazel/_bazel_omri/a9e9b87cb64d67149db4f28645a2ba4b/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/visualize.runfiles/org_tensorflow/tensorflow/lite/tools/visualize.py", line 513, in main
CreateHtmlFile(tflite_input, html_output)
File "/home/omri/.cache/bazel/_bazel_omri/a9e9b87cb64d67149db4f28645a2ba4b/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/visualize.runfiles/org_tensorflow/tensorflow/lite/tools/visualize.py", line 429, in CreateHtmlFile
data = CreateDictFromFlatbuffer(file_data)
File "/home/omri/.cache/bazel/_bazel_omri/a9e9b87cb64d67149db4f28645a2ba4b/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/visualize.runfiles/org_tensorflow/tensorflow/lite/tools/visualize.py", line 414, in CreateDictFromFlatbuffer
model_obj = schema_fb.Model.GetRootAsModel(buffer_data, 0)
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'
Finally, starting the python consul and trying to import Model from  'tensorflow.lite.python.schema_py_generated' results in the same error
~/src/tensorflow/tensorflow/lite/tools$ python
Python 3.8.1 (default, Mar  5 2020, 13:14:49)
[GCC 7.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.



from tensorflow.lite.python import schema_py_generated
schema_py_generated.Model
Traceback (most recent call last):
File "", line 1, in 
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'



**
The script should generate an HTML file
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='OmriTreidel' date='2020-07-30T14:39:03Z'>
		&lt;denchmark-link:https://github.com/OmriTreidel&gt;@OmriTreidel&lt;/denchmark-link&gt;

Please provide simple stand alone code to replicate the issue or if possible share colab gist with the error to analyse.
		</comment>
		<comment id='2' author='OmriTreidel' date='2020-07-31T04:47:49Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 The error can be reproduced by a single import 2 lines mentioned above
&lt;denchmark-code&gt;from tensorflow.lite.python import schema_py_generated
schema_py_generated.Model
&lt;/denchmark-code&gt;

or alternatively by using bazel run in the terminal
&lt;denchmark-code&gt;bazel run //tensorflow/lite/tools:visualize model.tflite visualized_model.html
&lt;/denchmark-code&gt;

both result in the same error
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'
What else should I provide ?
		</comment>
		<comment id='3' author='OmriTreidel' date='2020-08-13T08:36:40Z'>
		I am also facing the same issue. Any update on this ?
Kindly help &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='OmriTreidel' date='2020-08-14T00:56:23Z'>
		I can reproduce the issue. Investigating...
		</comment>
		<comment id='5' author='OmriTreidel' date='2020-08-26T23:00:19Z'>
		Seems this's because 'schema_py_generated.py' is empty. By changing 


tensorflow/third_party/flatbuffers/build_defs.bzl


         Line 373
      in
      9544dfa






 "sed 's/from flatbuffers.compat import import_numpy/import numpy as np' |" + 




 from

"sed 's/from flatbuffers.compat import import_numpy/import numpy as np' |" +

to

"sed 's/from flatbuffers.compat import import_numpy/import numpy as np/g' |" +

should fix the issue
		</comment>
		<comment id='6' author='OmriTreidel' date='2020-08-27T00:38:53Z'>
		&lt;denchmark-link:https://github.com/Fruiter&gt;@Fruiter&lt;/denchmark-link&gt;
 I have "AttributeError: module 'flatbuffers' has no attribute 'encode'" error with the change.
Am I missing something?
		</comment>
		<comment id='7' author='OmriTreidel' date='2020-08-27T07:25:17Z'>
		
@Fruiter I have "AttributeError: module 'flatbuffers' has no attribute 'encode'" error with the change.
Am I missing something?

Not sure. I tested by 'bazel build //tensorflow/lite/python:schema_py' then replaced the empty schema_py_generated.py. And I didn't test the 'visualize' use case. But I have tested with tflite model conversion logic which has the same error without the fix.
		</comment>
		<comment id='8' author='OmriTreidel' date='2020-09-10T18:22:38Z'>
		&lt;denchmark-link:https://github.com/lu-wang-g&gt;@lu-wang-g&lt;/denchmark-link&gt;
 can you advise?
		</comment>
		<comment id='9' author='OmriTreidel' date='2020-09-10T22:17:55Z'>
		It seems to be related to a recent change on FlatBuffer bazel rules. &lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
 could you please double check the case?
		</comment>
		<comment id='10' author='OmriTreidel' date='2020-09-11T23:41:46Z'>
		Looking into this now. I was able to reproduce the error. Will post an update when I find a fix.
		</comment>
		<comment id='11' author='OmriTreidel' date='2020-10-03T00:31:10Z'>
		Marking the issue as closed as it has been fixed. Feel free to re-open it if the issue is still unresolved.
		</comment>
		<comment id='12' author='OmriTreidel' date='2020-10-03T00:31:12Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41846&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41846&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='OmriTreidel' date='2020-11-10T12:41:19Z'>
		F:\anaconda3\Lib\site-packages\tensorflow\lite\pythonschema_py_generated.py      There is no code, it is empty.
how to solve this problemï¼Ÿ
		</comment>
		<comment id='14' author='OmriTreidel' date='2020-11-10T20:55:51Z'>
		&lt;denchmark-link:https://github.com/YANxu-666&gt;@YANxu-666&lt;/denchmark-link&gt;
 what TF version are you using? Could you installing and try again?
		</comment>
		<comment id='15' author='OmriTreidel' date='2020-11-15T12:21:24Z'>
		
@ YANxu-666æ‚¨ä½¿ç”¨çš„æ˜¯ä»€ä¹ˆTFç‰ˆæœ¬ï¼Ÿæ‚¨å¯ä»¥å®‰è£…å¹¶é‡tf-nightlyè¯•å—ï¼Ÿ

tensorflow2.4.0  .I am also facing the same issue. Any update on this ?
		</comment>
		<comment id='16' author='OmriTreidel' date='2020-11-15T12:21:31Z'>
		I am also facing the same issue. Any update on this ?
		</comment>
		<comment id='17' author='OmriTreidel' date='2020-11-16T10:31:45Z'>
		Ran into this issue on Windows (maybe that ^^ bazel find/sed script does not run on Windows?). Created a new virtualenv in WSL2 (Ubuntu 18.04) and installed the same requirements.txt including tf-nightly==2.5.0.dev20201115. There the schema_py_generated.py was not empty... Because I wanted to continue on Windows, I copied the generated code to the empty file in my Windows environment and now it works like a charm. Hope it helps you (to fix it ğŸ˜‰ )?
		</comment>
		<comment id='18' author='OmriTreidel' date='2020-11-16T12:47:50Z'>
		
åœ¨Windowsä¸Šé‡åˆ°æ­¤é—®é¢˜ï¼ˆä¹Ÿè®¸^^ bazelæŸ¥æ‰¾/ sedè„šæœ¬ä¸èƒ½åœ¨Windowsä¸Šè¿è¡Œï¼Ÿï¼‰ã€‚åœ¨WSL2ï¼ˆUbuntu 18.04ï¼‰ä¸­åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„virtualenvï¼Œå¹¶å®‰è£…äº†ç›¸åŒçš„requirements.txtï¼Œå…¶ä¸­åŒ…æ‹¬tf-nightly==2.5.0.dev20201115ã€‚é‚£é‡Œschema_py_generated.pyä¸æ˜¯ç©ºçš„â€¦â€¦å› ä¸ºæˆ‘æƒ³åœ¨Windowsä¸Šç»§ç»­ï¼Œæ‰€ä»¥æˆ‘å°†ç”Ÿæˆçš„ä»£ç å¤åˆ¶åˆ°Windowsç¯å¢ƒä¸­çš„ç©ºæ–‡ä»¶ä¸­ï¼Œç°åœ¨å®ƒå°±åƒä¸€ä¸ªè¶…çº§æŒ‰é’®ä¸€æ ·å·¥ä½œã€‚å¸Œæœ›å¯¹æ‚¨æœ‰å¸®åŠ©ï¼ˆä¿®å¤å®ƒï¼‰ğŸ˜‰ ï¼‰ï¼Ÿ
I am running on Windows,and I downloaded all the files in the tensorflow directory to my computer.I don't know which file directory the schema_py_generated.py is in.
Can you send me the code of schema_py_generated.py?
thanks

		</comment>
		<comment id='19' author='OmriTreidel' date='2020-11-16T14:10:13Z'>
		
åœ¨Windowsä¸Šé‡åˆ°æ­¤é—®é¢˜ï¼ˆä¹Ÿè®¸^^ bazelæŸ¥æ‰¾/ sedè„šæœ¬ä¸èƒ½åœ¨Windowsä¸Šè¿è¡Œï¼Ÿï¼‰ã€‚åœ¨WSL2ï¼ˆUbuntu 18.04ï¼‰ä¸­åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„virtualenvï¼Œå¹¶å®‰è£…äº†ç›¸åŒçš„requirements.txtï¼Œå…¶ä¸­åŒ…æ‹¬tf-nightly==2.5.0.dev20201115ã€‚é‚£é‡Œschema_py_generated.pyä¸æ˜¯ç©ºçš„â€¦â€¦å› ä¸ºæˆ‘æƒ³åœ¨Windowsä¸Šç»§ç»­ï¼Œæ‰€ä»¥æˆ‘å°†ç”Ÿæˆçš„ä»£ç å¤åˆ¶åˆ°Windowsç¯å¢ƒä¸­çš„ç©ºæ–‡ä»¶ä¸­ï¼Œç°åœ¨å®ƒå°±åƒä¸€ä¸ªè¶…çº§æŒ‰é’®ä¸€æ ·å·¥ä½œã€‚å¸Œæœ›å¯¹æ‚¨æœ‰å¸®åŠ©ï¼ˆä¿®å¤å®ƒï¼‰ğŸ˜‰ ï¼‰ï¼Ÿ
I found schema_py_generated.py but it is empty
Can you send me the code of schema_py_generated.py?
I really need it

		</comment>
		<comment id='20' author='OmriTreidel' date='2020-11-16T17:47:11Z'>
		&lt;denchmark-link:https://github.com/YANxu-666&gt;@YANxu-666&lt;/denchmark-link&gt;
 This issue should be fixed with the latest TF code (tf-nightly). Could you try with that let us know if it works?
Install it using pip as follows:
&lt;denchmark-code&gt;pip install tf-nightly
&lt;/denchmark-code&gt;

(you need to restart your runtime if you are using &lt;denchmark-link:https://colab.research.google.com&gt;https://colab.research.google.com&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='21' author='OmriTreidel' date='2020-11-20T09:38:05Z'>
		
Ran into this issue on Windows (maybe that ^^ bazel find/sed script does not run on Windows?). Created a new virtualenv in WSL2 (Ubuntu 18.04) and installed the same requirements.txt including tf-nightly==2.5.0.dev20201115. There the schema_py_generated.py was not empty... Because I wanted to continue on Windows, I copied the generated code to the empty file in my Windows environment and now it works like a charm. Hope it helps you (to fix it ğŸ˜‰ )?

On Windows, i still get empty scheme_py_generated.py
Tested it with clean pip installs of tf-nightly 2.5.0.dev20201116 and fresh released v2.4.0-rc2
		</comment>
		<comment id='22' author='OmriTreidel' date='2020-11-20T22:55:36Z'>
		&lt;denchmark-link:https://github.com/hhass&gt;@hhass&lt;/denchmark-link&gt;
 is it possible to post an end-to-end &lt;denchmark-link:https://colab.research.google.com&gt;https://colab.research.google.com&lt;/denchmark-link&gt;
 where I can reproduce this issue?
		</comment>
		<comment id='23' author='OmriTreidel' date='2020-12-02T21:39:18Z'>
		Hi! I am encountering the same problem, my version of tensorflow is : tf_nightly-2.5.0.dev20201202.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "C:\Program Files\JetBrains\PyCharm Community Edition 2020.1\plugins\python-ce\helpers\pydev\pydevd.py", line 1438, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "C:\Program Files\JetBrains\PyCharm Community Edition 2020.1\plugins\python-ce\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "C:/Users/brackman/Documents/Tensorflow/models/research/object_detection/ssd_mobilenet_quant/convertion.py", line 39, in &lt;module&gt;
    tflite_model = converter.convert()
  File "C:\Users\brackman\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\lite\python\lite.py", line 767, in convert
    result = _modify_model_io_type(result, **flags_modify_model_io_type)
  File "C:\Users\brackman\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\lite\python\util.py", line 853, in modify_model_io_type
    model_object = _convert_model_from_bytearray_to_object(model)
  File "C:\Users\brackman\Anaconda3\envs\tf-nightly\lib\site-packages\tensorflow\lite\python\util.py", line 579, in _convert_model_from_bytearray_to_object
    model_object = schema_fb.Model.GetRootAsModel(model_bytearray, 0)
AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'
&lt;/denchmark-code&gt;

I am trying to quantize the SSD_MobileNetV2. Let me know if you need my code for review. Thank you!
		</comment>
		<comment id='24' author='OmriTreidel' date='2020-12-02T21:48:11Z'>
		&lt;denchmark-link:https://github.com/ChowderII&gt;@ChowderII&lt;/denchmark-link&gt;
 Yes, please do post an end-to-end [colab notebook](&lt;denchmark-link:https://colab.research.google.com%5D&gt;https://colab.research.google.com]&lt;/denchmark-link&gt;
 so I can reproduce the issue for debugging.
		</comment>
		<comment id='25' author='OmriTreidel' date='2020-12-02T22:26:33Z'>
		&lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;

I am not sure how to upload my model there but I will give you the code that I ran. (The model is &lt;denchmark-link:http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz&gt;SSD_MobileNetV2_FPN_lite&lt;/denchmark-link&gt;
)
I don't know how to put my images and my model there but here is the &lt;denchmark-link:https://colab.research.google.com/drive/1T7anbKpXTxVc2h93e_eTSsG9MLdxHCr5?usp=sharing&gt;colab&lt;/denchmark-link&gt;

		</comment>
		<comment id='26' author='OmriTreidel' date='2020-12-03T03:13:02Z'>
		&lt;denchmark-link:https://github.com/ChowderII&gt;@ChowderII&lt;/denchmark-link&gt;
 If you can upload all your data (model and images) to GoogleDrive, mount it &amp; run your colab to verify the error,  and finally share that folder (ensure it has with read permissions for everyone), it would make it very easy for us to debug it.
Here's a Github issue where a user did this, and it enabled us to debug the issue quickly - &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/41840&gt;#41840&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>