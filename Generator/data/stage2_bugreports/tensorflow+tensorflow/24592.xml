<bug id='24592' author='traviskaufman' open_date='2018-12-27T03:32:39Z' closed_time='2019-02-22T21:49:07Z'>
	<summary>Estimators + tf.data iterators incompatible with eager execution enabled</summary>
	<description>

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Yes

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

MacOS Mojave version 10.14.2

Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

N/A

TensorFlow installed from (source or binary):

binary

TensorFlow version (use command below):

v1.12.0-rc2-3-ga6d8ffae09 1.12.0

Python version:

Python 3.6.0

Bazel version (if compiling from source):

N/A

GCC/Compiler version (if compiling from source):

N/A

CUDA/cuDNN version:

N/A

GPU model and memory:

N/A
Describe the current behavior
Say you train an estimator using &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate&gt;tf.estimator.train_and_evaluate&lt;/denchmark-link&gt;
. The  to your estimator returns a &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/data/Dataset&gt;tf.data.Dataset&lt;/denchmark-link&gt;
. you may want to write a small program to make predictions over a subset of data to sanity-check model training and gain more insight into how your estimator makes predictions, without having to go through the trouble of deploying your model. You may want to, for simplicity, use eager execution to do this. Something like:
import tensorflow as tf; tf.enable_eager_execution()

estimator = tf.estimator.Estimator(
        model.model_fn,
        warm_start_from=tf.train.latest_checkpoint(args.job_dir))
it = model_input_fn().make_one_shot_iterator()

batch = it.get_next() # Returns &lt;features&gt;, &lt;label&gt;
predictions = estimator.predict(lambda: tf.data.Dataset.from_tensor_slices(batch))
print('Prediction:', next(predictions))
print('Label:', batch[1])
This currently throws the following error:
&lt;denchmark-code&gt;RuntimeError: Attempting to capture an EagerTensor without building a function.
&lt;/denchmark-code&gt;

Describe the expected behavior
Ideally this would just work? Unless I'm missing something ðŸ˜„
Code to reproduce the issue

Train a toy estimator using tf.estimator.train_and_evaluate. Have its input function return a dataset.
Write a script similar to the one written above, which basically creates an estimator warm-started from the latest checkpoint in your training job, calls the input function to get the actual labels, then tries to compare that to prediction output from an estimator.

Other info / logs
The problem appears to be something that from_tensor_slices is doing. Relevant part of my traceback is below
&lt;denchmark-code&gt; File "WORKDIR/model_evaluation.py", line 61, in &lt;lambda&gt;
    predictions = estimator.predict(lambda: tf.data.Dataset.from_tensor_slices(batch))
  File "PYTHONDIR/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 289, in from_tensor_slices
    return TensorSliceDataset(tensors)
  File "PYTHONDIR/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 1565, in __init__
    for i, t in enumerate(nest.flatten(tensors))
  File "PYTHONDIR/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 1565, in &lt;listcomp&gt;
    for i, t in enumerate(nest.flatten(tensors))
  File "PYTHONDIR/site-packages/tensorflow/python/framework/ops.py", line 1050, in convert_to_tensor
    as_ref=False)
  File "PYTHONDIR/site-packages/tensorflow/python/framework/ops.py", line 1106, in internal_convert_to_tensor
    raise RuntimeError("Attempting to capture an EagerTensor without "
RuntimeError: Attempting to capture an EagerTensor without building a function.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='traviskaufman' date='2018-12-27T22:38:35Z'>
		&lt;denchmark-link:https://github.com/traviskaufman&gt;@traviskaufman&lt;/denchmark-link&gt;
 Would you mind to provide a full reproducible code sample that triggers the error? The code snippet you pasted may not be complete.
		</comment>
		<comment id='2' author='traviskaufman' date='2019-01-04T19:08:43Z'>
		I ran into the same issue. I think the problem is that predict() runs a new session, and in that context, accessing the EagerTensor is not supported. A workaround I found works is to convert the tensor into a numpy array and convert it with numpy_input_fn():
&lt;denchmark-code&gt;predictions = estimator.predict(tf.estimator.inputs.numpy_input_fn(
  {"foo": features["foo"].numpy()}, shuffle=False))
&lt;/denchmark-code&gt;

My first attempt was to pass the numpy array into Dataset.from_tensor_slices():
&lt;denchmark-code&gt;predictions = estimator.predict(
  lambda: tf.data.Dataset.from_tensor_slices({"x": features["foo"].numpy()}))
&lt;/denchmark-code&gt;

But that leads to an infinitely yielding predictions. I don't know why.
		</comment>
		<comment id='3' author='traviskaufman' date='2019-01-17T19:01:59Z'>
		The problem is in these lines:
&lt;denchmark-code&gt;it = model_input_fn().make_one_shot_iterator()

batch = it.get_next() # Returns &lt;features&gt;, &lt;label&gt;
predictions = estimator.predict(lambda: tf.data.Dataset.from_tensor_slices(batch))
&lt;/denchmark-code&gt;

If you really want to predict on this single batch, going through numpy is the way to go:
&lt;denchmark-code&gt;predictions = estimator.predict(lambda: tf.data.Dataset.from_tensor_slices(batch.numpy()))
&lt;/denchmark-code&gt;

but this is unusably slow so I think you want to do
&lt;denchmark-code&gt;predictions = estimator.predict(model_input_fn)
&lt;/denchmark-code&gt;

right?
		</comment>
		<comment id='4' author='traviskaufman' date='2019-06-15T21:38:50Z'>
		I have the same issue. If I load a dataset from tensorflow_datasets, then how should I define the input-function. Here is my code:
mnist, info = tfds.load('mnist', with_info=True)

ds_train_orig, ds_test = mnist['train'], mnist['test']

## Step 1: define the input-function
def train_input_fn(dataset, batch_size):
    dataset = dataset.map(lambda x:({'image-pixels':tf.reshape(x['image'], (-1,))}, 
                                    x['label']))
    return dataset.shuffle(1000).repeat().batch(batch_size)

## Step 2: define the feature_column:
image_feature_column = tf.feature_column.numeric_column(key='image-pixels',
                                                        shape=(28*28))

# image_feature_column
# NumericColumn(key='image-pixels', shape=(784,), default_value=None, dtype=tf.float32, normalizer_fn=None)


## Step 3:
dnn_classifier = tf.estimator.DNNClassifier(
    feature_columns=image_feature_column,
    hidden_units=[16, 16],
    n_classes=10)

## Step 4:
dnn_classifier.train(
    input_fn=lambda:train_input_fn(ds_train_orig, batch_size=32),
    #lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),
    steps=20)
But this gives me the same error as given in this thread:
&lt;denchmark-code&gt;RuntimeError: Attempting to capture an EagerTensor without building a function.
&lt;/denchmark-code&gt;

I tried to convert the data (step-1) to NumPy using the map() method like this:
def train_input_fn(dataset, batch_size):
    dataset = dataset.map(lambda x:({'features':x['image'].numpy().flatten()}, 
                                    x['label']))
    return dataset.shuffle(1000).repeat().batch(batch_size)
but it says that Tensor object does not have attribute numpy.
Is there any example to use a pre-existing dataset object to use with an estimator?
		</comment>
	</comments>
</bug>