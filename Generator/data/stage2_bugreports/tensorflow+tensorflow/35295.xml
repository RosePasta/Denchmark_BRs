<bug id='35295' author='yxchng' open_date='2019-12-20T03:11:02Z' closed_time='2019-12-23T19:23:39Z'>
	<summary>TF Lite GPU delegate gives fuse_auto_input failed error when running TF Lite model that uses only supported GPU operations.</summary>
	<description>
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N.A.


TensorFlow installed from (source or binary):
Source, 9a5b203


TensorFlow version (use command below):
2


Python version:
3.6.8


Bazel version (if compiling from source):
1.0.0


GCC/Compiler version (if compiling from source):
7.4.0


CUDA/cuDNN version:
10.0.130/7.4.2


GPU model and memory:
RTX 2080 Ti



TF Lite GPU delegate gives  error when running TF Lite model that only uses supported operations listed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/gpu&gt;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/gpu&lt;/denchmark-link&gt;
.
At first, I suspect that TF Lite GPU delegate expects a model that has no fused operators. Therefore, I tried to prevent TFLiteConverter from fusing operators by commenting the following lines in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/toco/toco_tooling.cc&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/toco/toco_tooling.cc&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;if (SupportsFusedActivationFunction(output_format)) {
  transformations.Add(new FuseActivationFunctions);
} else {
  transformations.Add(new UnfuseActivationFunctions);
}
&lt;/denchmark-code&gt;

However, it still gives the same error.
It only works when I add  to this file (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/gl_delegate.cc&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/gl_delegate.cc&lt;/denchmark-link&gt;
), which prevents TF Lite GPU delegate from trying to fuse operators.
Describe the expected behavior
TF Lite GPU delegate should be able to run TF Lite model without needing to modify TensorFlow source code.
Code to reproduce the issue

git pull https://github.com/google/mediapipe.git
Switch this model (https://drive.google.com/file/d/1LwNKYcf_sYDDWNWML-mNjxp8_j_2ofRe/view?usp=sharing) with the hair_segmentation.tflite model in MediaPipe
Run the hair segmentation pipeline by

&lt;denchmark-code&gt;bazel build -c opt --copt -DMESA_EGL_NO_X11_HEADERS mediapipe/examples/desktop/hair_segmentation:hair_segmentation_gpu
GLOG_logtostderr=1 bazel-bin/mediapipe/examples/desktop/hair_segmentation/hair_segmentation_gpu     --calculator_graph_config_file=mediapipe/graphs/hair_segmentation/hair_segmentation_mobile_gpu.pbtxt
&lt;/denchmark-code&gt;

Other info / logs

INFO: Created TensorFlow Lite delegate for GPU.
ERROR: TfLiteGpuDelegate Prepare: fuse_auto_input failed
ERROR: Node number 8 (TfLiteGpuDelegate) failed to prepare.
ERROR: Restored previous execution plan after delegate application failure.
E1220 10:32:56.170152  5452 demo_run_graph_main_gpu.cc:186] Failed to run the graph: Graph has errors:
Calculator::Open() for node "[TfLiteInferenceCalculator, TfLiteInferenceCalculator with output stream: segmentation_tensor]" failed: ; (interpreter_-&gt;ModifyGraphWithDelegate(delegate_))==(kTfLiteOk)e_calculator.cc:593)

	</description>
	<comments>
		<comment id='1' author='yxchng' date='2019-12-23T19:23:38Z'>
		&lt;denchmark-link:https://github.com/yxchng&gt;@yxchng&lt;/denchmark-link&gt;

hair_segmentation.tflite is a model that we know runs on mobile GPUs.

Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N.A.

with this + mesa, you're entering a domain we don't support =/
Note that fuse_auto_input doesn't mean the same thing as in what TOCO calls fusion, so you shouldn't worry about fixing TOCO; it's fusion for GPU kernels only.  And the fusion logic is not even the GPU land, but purely on the CPU land, so you might be able to pinpoint what's causing the failure.
		</comment>
		<comment id='2' author='yxchng' date='2019-12-23T19:23:40Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35295&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35295&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>