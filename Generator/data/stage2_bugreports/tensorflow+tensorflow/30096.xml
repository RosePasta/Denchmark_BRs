<bug id='30096' author='mahzoon' open_date='2019-06-24T17:56:20Z' closed_time='2019-08-09T22:10:13Z'>
	<summary>Keras load_model fails to load models with BatchNormalization layer when saved in non-eager mode</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below):
tf version = 2.0.0-dev20190622
tf git version = v1.12.1-4759-g9856697d8b
Python version: 3.6.4
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: NA
GPU model and memory: NA


This issue is very similar to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/3628&gt;#3628&lt;/denchmark-link&gt;
, but it only happens in non-eager mode in TF 2.0.
You can save a model (having batch norm layer) in  successfully. However, you cannot load the model in any mode.  Load model fails with:
&lt;denchmark-code&gt;ValueError: Node 'AssignMovingAvg/sub/x' expects to be colocated with unknown node 'bn_layer/moving_mean'
&lt;/denchmark-code&gt;

Seems like the model is not saved correctly.
Describe the expected behavior
Save model should produce a correct SavedModel in non-eager mode so that it can be loaded later.
Code to reproduce the issue
import tensorflow as tf

tf.compat.v1.disable_eager_execution()

## model architecture
input_layer = tf.keras.Input(shape=(28, 28, 1), name='image_input')
layer = tf.keras.layers.ZeroPadding2D(padding=(3, 3), name='initial_padding')(input_layer)
# add convolutional layer
layer = tf.keras.layers.Conv2D(
    filters=16,
    kernel_size=8,
    padding='same',
    name='conv_layer'
)(layer)
# batch normalization
layer = tf.keras.layers.BatchNormalization(axis=3, name='bn_layer')(layer)
# activation
layer = tf.keras.layers.Activation('relu', name='activation_layer')(layer)
# down sample
net = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(layer)
# flatten
net = tf.keras.layers.Flatten(name='flatten_layer')(net)
# dense layer with ReLU-activation.
net = tf.keras.layers.Dense(64, activation='relu', name='dense_layer')(net)
# dropout layer
net = tf.keras.layers.Dropout(0.2, name='dropout_layer')(net)
# last fully-connected / dense layer with softmax-activation so it can be used for classification.
output_layer = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(net)
# creating the model
model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='test1')

# loading data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
# add channel to x; also divide by 255 to normalize the data
x_train = x_train.reshape(60000, 28, 28, 1)#.astype('float32') / 255
x_test = x_test.reshape(10000, 28, 28, 1)#.astype('float32') / 255

# create the training dataset
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
# shuffle, batch and prefetch for optimizing io reads
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64).prefetch(1024)
# create the validation dataset.
val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
# batch and prefetch for optimizing io reads
val_dataset = val_dataset.batch(64).prefetch(1024)

# compile the model
model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='rmsprop',
    metrics=['accuracy']
)

# fit the model
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=2,
    steps_per_epoch=50
)

# the returned "history" object holds a record of the loss values and metric values during training
print('\nhistory dict:', history.history)

model.save('mnist_model')

del model
# recreate the exact same model purely from the file:
model = tf.keras.models.load_model('mnist_model')
Other info / logs
&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0624 13:37:50.545702 140736272085888 deprecation.py:506] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1624: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2019-06-24 13:37:51.383301: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-24 13:37:51.398677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90837c85b0 executing computations on platform Host. Devices:
2019-06-24 13:37:51.398709: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-06-24 13:37:51.728750: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0624 13:37:52.842435 140736272085888 deprecation.py:323] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:460: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Apply a constraint manually following the optimizer update step.
Train on 50 steps, validate on 157 steps
Epoch 1/2
50/50 [==============================] - 4s 73ms/step - loss: 1.8029 - accuracy: 0.5256 - val_loss: 0.5635 - val_accuracy: 0.8345
Epoch 2/2
50/50 [==============================] - 3s 58ms/step - loss: 0.6426 - accuracy: 0.7937 - val_loss: 0.4020 - val_accuracy: 0.8787

history dict: {'loss': [1.8028993177413941, 0.6426236051321029], 'accuracy': [0.525625, 0.79375], 'val_loss': [0.563538867861602, 0.40199054775249426], 'val_accuracy': [0.8345, 0.8787]}
2019-06-24 13:38:02.261349: W tensorflow/python/util/util.cc:268] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Traceback (most recent call last):
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py", line 427, in import_graph_def
    graph._c_graph, serialized, options)  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: Node 'AssignMovingAvg/sub/x' expects to be colocated with unknown node 'bn_layer/moving_mean'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "error_showcase_graph.py", line 71, in &lt;module&gt;
    model = tf.keras.models.load_model('mnist_model')
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 142, in load_model
    return saved_model_load.load(filepath, compile)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py", line 86, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py", line 506, in load_internal
    export_dir)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py", line 102, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py", line 111, in __init__
    meta_graph.graph_def.library))
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/function_deserialization.py", line 301, in load_function_def_library
    copy, copy_functions=False)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/framework/function_def_to_graph.py", line 64, in function_def_to_graph
    importer.import_graph_def(graph_def, name="")
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py", line 431, in import_graph_def
    raise ValueError(str(e))
ValueError: Node 'AssignMovingAvg/sub/x' expects to be colocated with unknown node 'bn_layer/moving_mean'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mahzoon' date='2019-06-25T10:14:41Z'>
		I have tried on Colab with TF version 2.0.0-dev20190622 and was able to reproduce it on only non eager mode.
		</comment>
		<comment id='2' author='mahzoon' date='2019-08-09T22:10:12Z'>
		Thanks for reporting this issue! This should now be fixed with this change: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/769900b011cf6a31f8e8f919e97b70900f9825d8#diff-5738cc9149537416bc9a07c7cfefae42&gt;769900b#diff-5738cc9149537416bc9a07c7cfefae42&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='mahzoon' date='2019-08-09T22:10:14Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30096&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30096&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='mahzoon' date='2019-08-15T01:00:47Z'>
		Thank you &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;

I confirm that the issue is resolved in the tf-nightly
		</comment>
	</comments>
</bug>