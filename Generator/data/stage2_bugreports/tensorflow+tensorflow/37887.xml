<bug id='37887' author='Hongtao-Niro' open_date='2020-03-25T04:06:11Z' closed_time='2020-03-30T02:45:40Z'>
	<summary>Wrong loss calculation with multi-output models when using model.fit.</summary>
	<description>
System information

Have I written custom code: Yes, though the code sample below is adapted from an official tensorflow tutorial with minimal changes.
OS Platform and Distribution: Ubuntu 18.04
TensorFlow installed from: official pip package, version 2.1.0
Python version: 3.6.9
CUDA/cuDNN version: CUDA 10.1, GTX 1070

Describe the current behavior
Consider the following mnist example
import numpy as np
import tensorflow as tf

inputs = tf.keras.Input(shape=(784,), name='digits')
x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)
x = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)
outputs = tf.keras.layers.Dense(10, name='predictions', activation='softmax')(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer=tf.keras.optimizers.SGD(),
    loss={"predictions": tf.keras.losses.SparseCategoricalCrossentropy()},
    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name="accuracy")],
)

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = x_train.reshape(60000, 784).astype('float32') / 255
x_test = x_test.reshape(10000, 784).astype('float32') / 255
y_train = y_train.astype('float32')
y_test = y_test.astype('float32')

x_val = x_train[-10000:]
y_val = y_train[-10000:]
x_train = x_train[:-10000]
y_train = y_train[:-10000]

train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=1024).repeat().batch(64)

val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_dataset = val_dataset.batch(64, drop_remainder=True)

test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_dataset = test_dataset.batch(64)

model.fit(train_dataset, epochs=3, steps_per_epoch=1000, validation_data=val_dataset)
The output is
Epoch 1/3
1000/1000 [==============================] - 4s 4ms/step - loss: 0.9192 - accuracy: 0.7615 - val_loss: 0.4060 - val_accuracy: 0.8914
Epoch 2/3
1000/1000 [==============================] - 3s 3ms/step - loss: 0.3786 - accuracy: 0.8939 - val_loss: 0.3147 - val_accuracy: 0.9127
Epoch 3/3
1000/1000 [==============================] - 3s 3ms/step - loss: 0.3211 - accuracy: 0.9080 - val_loss: 0.2796 - val_accuracy: 0.9196
This works just fine as the loss decreases and the accuracy increases.
However, if I simply add another dummy output to the model, the training will become erroneous. Let's just change the model definition line to model = tf.keras.Model(inputs=inputs, outputs=[x, outputs])
Now the output is:
WARNING:tensorflow:Output dense_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_2.
Epoch 1/3
WARNING:tensorflow:Gradients do not exist for variables ['predictions/kernel:0', 'predictions/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['predictions/kernel:0', 'predictions/bias:0'] when minimizing the loss.
1000/1000 [==============================] - 4s 4ms/step - loss: 5.7781 - predictions_loss: 5.7781 - predictions_accuracy: 0.1048 - val_loss: 5.5196 - val_predictions_loss: 5.5196 - val_predictions_accuracy: 0.1243
Epoch 2/3
1000/1000 [==============================] - 4s 4ms/step - loss: 5.3866 - predictions_loss: 5.3866 - predictions_accuracy: 0.1202 - val_loss: 5.2255 - val_predictions_loss: 5.2255 - val_predictions_accuracy: 0.0967
Epoch 3/3
1000/1000 [==============================] - 4s 4ms/step - loss: 5.1167 - predictions_loss: 5.1167 - predictions_accuracy: 0.0996 - val_loss: 5.1479 - val_predictions_loss: 5.1479 - val_predictions_accuracy: 0.0992
Basically the network is not trained at all because as the warning says: Gradients do not exist for variables ['predictions/kernel:0', 'predictions/bias:0'] when minimizing the loss.
Describe the expected behavior
The expect behavior is that by adding additional outputs to the model should not affect the training process in anyway. Note that in model.compile, I specified the loss function using a dictionary, so I don't need to modify the rest of the code after adding a dummy output.
	</description>
	<comments>
		<comment id='1' author='Hongtao-Niro' date='2020-03-25T04:20:23Z'>
		&lt;denchmark-h:h2&gt;Update&lt;/denchmark-h&gt;

I just found out that, if you alter the order of the outputs by doing model = tf.keras.Model(inputs=inputs, outputs=[outputs, x]), then the script works as expected. This means the first loss object you give will always be associated with the first output.
I would say this is still a bug because the purpose of passing a dictionary to loss is to make everything explicit, so I don't have to worry about the order. This should work like python kwargs.
		</comment>
		<comment id='2' author='Hongtao-Niro' date='2020-03-26T11:21:41Z'>
		&lt;denchmark-link:https://github.com/Hongtao-Niro&gt;@Hongtao-Niro&lt;/denchmark-link&gt;
,
I was able to reproduce the error with TF 2.1. However, the issue seems to be fixed in TF-nightly. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/bba34c53fef4e0fd34ab0210cf5bd87a/37887-tf-nightly.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='Hongtao-Niro' date='2020-03-30T02:45:40Z'>
		Thanks!
		</comment>
		<comment id='4' author='Hongtao-Niro' date='2020-03-30T02:45:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37887&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37887&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>