<bug id='8897' author='Androbin' open_date='2017-04-01T17:19:49Z' closed_time='2018-01-24T14:57:26Z'>
	<summary>outputs indifferent to input when applying `merge_duplicate_nodes`</summary>
	<description>
I think I might have located the root of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/8698&gt;#8698&lt;/denchmark-link&gt;

It seems that  is the reason that  malfunctions.
Whatever I do, whenever I apply a  somewhere during a graph transformation, the output becomes completely indifferent to the input.
(Unfortunately) I don't get any error messages concerning this...
	</description>
	<comments>
		<comment id='1' author='Androbin' date='2017-04-01T22:18:54Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 , could you please take a look. Thanks so much.
		</comment>
		<comment id='2' author='Androbin' date='2017-04-02T13:35:35Z'>
		Variants of this problem include constant values from some intermediate layer onwards.
So the input won't make it past there, which results in the overall output being constant.
		</comment>
		<comment id='3' author='Androbin' date='2017-04-08T18:45:44Z'>
		I should probably mention that it makes inference a lot faster ...
Unfortunately, faster doesn't always mean better ...
How could merge_duplicate_nodes possibly eliminate all of these computations?
		</comment>
		<comment id='4' author='Androbin' date='2017-04-18T22:35:32Z'>
		&lt;denchmark-link:https://github.com/Androbin&gt;@Androbin&lt;/denchmark-link&gt;
, could you confirm that replacing  with  in
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/a667a52ee909975389e48ffe30fb4ff9570635da/tensorflow/tools/graph_transforms/quantize_nodes.cc#L942&gt;quantize_nodes.cc line 942&lt;/denchmark-link&gt;
 causes the problem to go away?
		</comment>
		<comment id='5' author='Androbin' date='2017-04-18T22:38:35Z'>
		&lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;

I replaced  with  in , recompiled the  tool and reinserted the  transformation.
After doing so, I can confirm to get changing values during inference whereas previously, the output was indifferent to the input.
		</comment>
		<comment id='6' author='Androbin' date='2017-04-18T23:34:21Z'>
		As mentioned, this bug does step in place whenever merge_duplicate_nodes is used (not just with quantize_nodes).
		</comment>
		<comment id='7' author='Androbin' date='2017-04-19T15:32:56Z'>
		And I should probably mention that I am doing the inference on Android.
Unfortunately, I am currently unable to test this on Ubuntu because the original graph, from which the quantized version is derivated, is currently broken due to another issue.
		</comment>
		<comment id='8' author='Androbin' date='2017-04-19T21:50:10Z'>
		&lt;denchmark-link:https://github.com/Androbin&gt;@Androbin&lt;/denchmark-link&gt;

I found an issue with dequantization on Android and I'm wondering if building with

works for you. I'd appreciate if you would try it out. Thanks in advance!
		</comment>
		<comment id='9' author='Androbin' date='2017-04-19T23:50:02Z'>
		&lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;

Thanks for the hint!
Seems like I can't rely on  builds anymore...
		</comment>
		<comment id='10' author='Androbin' date='2017-04-20T16:14:08Z'>
		The following should work:
bazel build -c opt --copt="-DTENSORFLOW_DISABLE_META" //tensorflow/contrib/android:libtensorflow_inference.so --config=android_arm
But if you are OK waiting, we should have a fix for quantization in the nightly by the end of next week. I'm not sure it will fix this particular problem you are experiencing, though.
Meanwhile, could you perhaps provide steps for reproducing the failures you are seeing with merge_duplicate_nodes? Did you retrain an inception model?
		</comment>
		<comment id='11' author='Androbin' date='2017-04-20T16:24:43Z'>
		&lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;

Thanks, this should work now.
Happy to hear about a fix in sight.
In my particular case, I didn't use a prepared model but a custom one in the scope of a research project.
I can provide the structure of the graph, if this was helpful.
Anyway, currently any graph transform containing a merge_duplicate_nodes e.g. quantize_nodes causes this issue with my model.
		</comment>
		<comment id='12' author='Androbin' date='2017-04-20T17:45:08Z'>
		I'd be curious to know which nodes are removed when you run transform_graph with
--transforms='merge_duplicate_nodes'
from reading the code I understand only nodes that have the same op, inputs and attributes (by the way of a hash function) are removed.
		</comment>
		<comment id='13' author='Androbin' date='2017-04-20T17:49:16Z'>
		&lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;

I will inspect this and list anything unusual here!
		</comment>
		<comment id='14' author='Androbin' date='2017-04-20T18:42:38Z'>
		&lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;

Meanwhile, which ABI does  resolve to?

		</comment>
		<comment id='15' author='Androbin' date='2017-04-20T18:47:39Z'>
		armeabi-v7a (but I think any of the ones you mentioned should be fine)
		</comment>
		<comment id='16' author='Androbin' date='2017-06-08T21:10:50Z'>
		I tried recompiling and running computing a diff but since the output of transform_graph is binary, I wasn't able to extract, exactly which nodes are removed.
		</comment>
		<comment id='17' author='Androbin' date='2017-07-03T07:09:22Z'>
		&lt;denchmark-link:https://github.com/Androbin&gt;@Androbin&lt;/denchmark-link&gt;
 Did the new bazel build for  work for you?
Edit: building with --copt="-DTENSORFLOW_DISABLE_META"  solved the problem for me.
		</comment>
		<comment id='18' author='Androbin' date='2017-07-05T12:16:52Z'>
		&lt;denchmark-link:https://github.com/kwotsin&gt;@kwotsin&lt;/denchmark-link&gt;
 I will recompile, retrain and requantize and comment the results as soon as I have them.
		</comment>
		<comment id='19' author='Androbin' date='2017-07-05T19:11:48Z'>
		Might take time though, there are currently issues with building the inference library &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/11182&gt;#11182&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='20' author='Androbin' date='2017-12-22T07:46:13Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='21' author='Androbin' date='2018-01-05T19:12:42Z'>
		Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='22' author='Androbin' date='2018-01-23T23:13:45Z'>
		A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.
		</comment>
	</comments>
</bug>