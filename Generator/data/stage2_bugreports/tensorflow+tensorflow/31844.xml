<bug id='31844' author='maneshsyno' open_date='2019-08-21T15:00:00Z' closed_time='2019-08-23T11:10:48Z'>
	<summary>Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.</summary>
	<description>
System information

Windows 10:
TensorFlow installed using PIP:
TensorFlow version 1.14:

Provide the text output from tflite_convert
&lt;denchmark-code&gt;Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.

&lt;/denchmark-code&gt;

Also, please include a link to a GraphDef or the model if possible.
ssd_mobilenet_v1_coco
Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Using following code to convert the graph file to tflite:
import tensorflow as tf
graph_def_file = "C:/tensorflow1/models/research/object_detection/inference_graph/tflite_graph.pb"
input_arrays = ["normalized_input_image_tensor"]
input_shaps = {"normalized_input_image_tensor":[1, 300, 300, 3]}
output_arrays = ['TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3']
#output_shaps = {"raw_outputs/box_encodings":[1, 10, 4]}
converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shaps)
tflite_model = converter.convert()
open("detact.tflite", "wb").write(tflite_model)
	</description>
	<comments>
		<comment id='1' author='maneshsyno' date='2019-08-22T20:38:13Z'>
		The 'TFLite_Detection_PostProcess' is a custom operator that you need explicitly register, otherwise the interpreter can't find the kernel of this op. You can register by setting converter.allow_custom_ops = true.
		</comment>
		<comment id='2' author='maneshsyno' date='2019-08-23T10:12:39Z'>
		
The 'TFLite_Detection_PostProcess' is a custom operator that you need explicitly register, otherwise the interpreter can't find the kernel of this op. You can register by setting converter.allow_custom_ops = true.

Thanks it worked for me.
		</comment>
		<comment id='3' author='maneshsyno' date='2019-08-23T11:10:48Z'>
		I am closing this issue since it looks to be fixed. Thanks!
		</comment>
		<comment id='4' author='maneshsyno' date='2019-08-23T11:10:49Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31844&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31844&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>