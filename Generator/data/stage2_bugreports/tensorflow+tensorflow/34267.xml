<bug id='34267' author='ChaiKnight' open_date='2019-11-14T09:35:38Z' closed_time='2020-01-14T12:39:01Z'>
	<summary>Invoking Interpreter from C API fails with exit code 1</summary>
	<description>
Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 and Android 9
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy S10
TensorFlow installed from (source or binary): Little bit of both
TensorFlow version: 1.14, 1.15, 2.0
Python version: 3.6
Installed using virtualenv? pip? conda?: Pip and source
Bazel version (if compiling from source): 26.1, 29.1
GCC/Compiler version (if compiling from source): 7.4
CUDA/cuDNN version: 10.1, 7
GPU model and memory: 1050ti and whatever is in my phone

Describe the problem
When I build the tflite C api (currently on 1.14 after testing tf-nightly 1.15 and 2.0 (which I found out is not ready yet?)), I get a variety of weird errors. I have a simple tflite SSD model provided from the tf model zoo, which takes a 300x300x3 float32 input and outputs the usual 4 arrays of the detection_postprocess node provided by the tflite team.
When I feed it a float array like in the Unity example, it crashes. I can either feed it a byte array or trick it into accepting the actual float array by dividing the input_data_size argument by 4, since it believes the TFL_TensorByteSize is 270000 when it should be 1080000.
Either way, when I call TFL_InterpreterInvoke, it crashes, and I haven't been able to follow the C api code to figure out why.
Provide the exact sequence of commands / steps that you executed before running into the problem
First:
&lt;denchmark-code&gt;GCHandle tensorDataHandle = GCHandle.Alloc(inputTensorData, GCHandleType.Pinned);
        IntPtr tensorDataPtr = tensorDataHandle.AddrOfPinnedObject();
        IntPtr tensor = TFL_InterpreterGetInputTensor(interpreter, inputTensorIndex);

        int tensorByteSize = TFL_TensorByteSize(tensor);
        int inputDimsSize = Buffer.ByteLength(inputTensorData);

        Debug.Log(tensorByteSize + " | " + inputDimsSize);
        
        ThrowIfError(TFL_TensorCopyFromBuffer(
            tensor, tensorDataPtr, Buffer.ByteLength(inputTensorData)));
&lt;/denchmark-code&gt;

This works with a byte array or a float array with the third argument like Buffer.ByteLength(inputTensorData) / 4
Then
&lt;denchmark-code&gt;ThrowIfError(TFL_InterpreterInvoke(interpreter));
&lt;/denchmark-code&gt;

But since both of the input methods are actually wrong, it of course crashes with error code 1.
Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
I am able to load the model using the python tf.lite.Interpreter like so:
&lt;denchmark-code&gt;model = tf.compat.v2.lite.Interpreter("/path/detecter.tflite")
&lt;/denchmark-code&gt;

All of the following calls, until model.invoke, work fine too. However, I can only model.invoke if the set_tensor call before uses a copy of x, otherwise it complains about references to internal data:
&lt;denchmark-code&gt;RuntimeError: There is at least 1 reference to internal data
      in the interpreter in the form of a numpy array or slice. Be sure to
      only hold the function returned from tensor() if you are using raw
      data access.
&lt;/denchmark-code&gt;

So to summarize; this works:
&lt;denchmark-code&gt;x = np.random.normal(size=(1,300,300,3))
print(x)
model.set_tensor(tensor_index=175,value=np.copy(x))
model.invoke()
&lt;/denchmark-code&gt;

But this does not:
&lt;denchmark-code&gt;x = np.random.normal(size=(1,300,300,3))
print(x)
model.set_tensor(tensor_index=175,value=x)
model.invoke()
&lt;/denchmark-code&gt;

Does TFL_TensorCopyFromBuffer not take ownership of the copy and fear breaking it?
Regardless, I can't seem to find any information about this and can't find the documentation to follow it myself, so any help is appreciated.
PS. When is the 2.0 C API ready to roll out? The new converter and tf2.0 control flow ops are very appealing.
	</description>
	<comments>
		<comment id='1' author='ChaiKnight' date='2019-11-14T10:31:51Z'>
		A few quick updates:
I tried a similar trick with cloning the input array in my script, but to no avail. Using a cloned Array for input did not help.
I also tested a similar network that I've called detect_new. This network shows the correct input dimensions (byte size 1080000) and will run, but crashes out of Unity entirely when invoked without any error codes.
		</comment>
		<comment id='2' author='ChaiKnight' date='2019-11-15T16:58:45Z'>
		Just to be clear, is this crashing both on device (Android) and in the Unity Editor (on Linux)? Or with just one?
Would you mind sharing the exact model that fails? Also, are there any other failure logs in the editor log or device log that are relevant?
		</comment>
		<comment id='3' author='ChaiKnight' date='2020-01-14T12:39:03Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34267&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34267&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='ChaiKnight' date='2020-01-14T12:39:15Z'>
		We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!
		</comment>
	</comments>
</bug>