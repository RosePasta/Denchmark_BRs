<bug id='24507' author='fgr1986' open_date='2018-12-21T14:15:02Z' closed_time='2019-01-29T05:30:54Z'>
	<summary>Estimator inputs are not quantized using create_training_graph/create_eval_graph</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04 Ubuntu
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 1.12
Python version: 3.6
Bazel version (if compiling from source): No
GCC/Compiler version (if compiling from source): No
CUDA/cuDNN version: No
GPU model and memory: No

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
Estimator inputs are not quantized using create_training_graph/create_eval_graph as this layer has no activation.
From &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/quantize/python/quantize.py&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/quantize/python/quantize.py&lt;/denchmark-link&gt;

Though
&lt;denchmark-code&gt;# Activations that are supported by the quantization rewrite.
_ACTIVATION_TYPES = {'Relu', 'Relu6', 'Identity'}
&lt;/denchmark-code&gt;

The valid activations are only Relu*
&lt;denchmark-code&gt;_RELU_TYPES = {'Relu', 'Relu6'}
...
_PASS_THROUGH_OP = {'Reshape', 'Identity', 'BatchToSpaceND', 'SpaceToBatchND'}
_VALID_ACTIVATION_OP = {'Relu', 'Relu6'}
&lt;/denchmark-code&gt;

Thus, having something as
&lt;denchmark-code&gt;input = tf.identity(input, name='q_input')
...
does not produce the expected result.

The alternative is using a manual layer as FakeQuantOp, but in this case max/min should be provided.
It would be required that create_training_graph/create_eval_graph automatically quantize the input as any other activation.

Thanks
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='fgr1986' date='2019-01-29T05:30:54Z'>
		Currently the tooling doesn't quantize inputs by design. This is because the rewriter targets image models with the expectation that inputs during inference are values from 0 to 255. You can then map these values to the float values used as inputs during training, for instance in the range [0.0f, 1.0f], using the mean_value and std_value flags.
mean_value = the uint8 value that maps to floating point 0.
std_value = (uint8 range) / (float input range).
We understand that the current rewriter tool is brittle and we are actively working on more robust tooling to replace it.
		</comment>
		<comment id='2' author='fgr1986' date='2019-01-29T11:10:03Z'>
		Hi &lt;denchmark-link:https://github.com/suharshs&gt;@suharshs&lt;/denchmark-link&gt;
 could it be possible to get a bit more information on that new tool?
I have just send you an email to the mail account you have on your profile, subject referring this github issue.
Thank you very much for your time
		</comment>
	</comments>
</bug>