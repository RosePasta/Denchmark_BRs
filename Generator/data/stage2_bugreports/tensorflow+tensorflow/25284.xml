<bug id='25284' author='xhyandwyy' open_date='2019-01-29T15:14:34Z' closed_time='2019-02-22T23:08:01Z'>
	<summary>TensorFlow1.11 estimator train_and_evaluate distributed（MirroredStrategy）， the sum eval metric （false_negatives，false_positives，true_negatives， true_positives  ）at different GPUs is wrong</summary>
	<description>
The test set is 1000
when I use one GPU，the sum of test set is true, 1000
INFO:tensorflow:Saving dict for global step 102: eval_accuracy = 0.762, eval_loss = 0.5891396, false_negatives = 27.0, false_positives = 211.0, global_step = 102, loss = 0.5891396, negative_f1_score = 0.715311, negative_precision = 0.9171779, negative_recall = 0.5862745, positive_f1_score = 0.7955326, positive_precision = 0.6869436, positive_recall = 0.94489795, true_negatives = 299.0, true_positives = 463.0
when I use two GPU，the sum of test set is wrong, 992
INFO:tensorflow:Saving dict for global step 102: eval_accuracy = 0.68245965, eval_loss = 0.6352085, false_negatives = 134.0, false_positives = 181.0, global_step = 102, loss = 0.6352085, negative_f1_score = 0.6764509, negative_precision = 0.70869565, negative_recall = 0.64299804, positive_f1_score = 0.6902654, positive_precision = 0.6597744, positive_recall = 0.7237113, true_negatives = 326.0, true_positives = 351.0
when I use three GPU，the sum of test set is wrong, 984
INFO:tensorflow:Saving dict for global step 102: eval_accuracy = 0.8231707, eval_loss = 0.40057757, false_negatives = 99.0, false_positives = 75.0, global_step = 102, loss = 0.40057757, negative_f1_score = 0.83139527, negative_precision = 0.8125, negative_recall = 0.85119045, positive_f1_score = 0.81410253, positive_precision = 0.8355263, positive_recall = 0.79375, true_negatives = 429.0, true_positives = 381.0
	</description>
	<comments>
		<comment id='1' author='xhyandwyy' date='2019-01-30T03:52:52Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/contrib/distribute/python/values.py#L1130&gt;https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/contrib/distribute/python/values.py#L1130&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;      # TODO(priyag): If dropping remainder is not appropriate, find another
      # approach to distributing the dataset when not possible to divide evenly.
      # Possibly not an issue when we start using PartitionedDataset.
      self._dataset = dataset.batch(len(devices), drop_remainder=True)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='xhyandwyy' date='2019-02-15T01:10:16Z'>
		&lt;denchmark-link:https://github.com/xhyandwyy&gt;@xhyandwyy&lt;/denchmark-link&gt;
 Could you provide a code to reproduce the bug? Thanks!
		</comment>
		<comment id='3' author='xhyandwyy' date='2019-02-22T23:08:01Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
	</comments>
</bug>