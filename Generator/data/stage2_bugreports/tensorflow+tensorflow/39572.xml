<bug id='39572' author='ghost(ghost)' open_date='2020-05-15T09:00:32Z' closed_time='2020-11-06T12:42:46Z'>
	<summary>The New Converter of Tensorflow 2.2.0 generate incorrect model output</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows/ubuntu
TensorFlow installed from (source or binary): pip
TensorFlow version (or github SHA if from source): 2.2.0

Command used to run the converter or code if youâ€™re using the Python API
https://colab.research.google.com/drive/1uMiHGTFrj7R_rFcGJoje3Yfbap0sC9H-?usp=sharing
import tensorflow as tf
import numpy as np
np.set_printoptions(suppress=True)

length = 66

a = tf.constant(
    np.random.rand(length,length).astype(np.float32),
    shape=[length, length])

c = [ tf.constant(
    np.random.rand(length).astype(np.float32),
    shape=[ length]) for i in range(0,3)]


@tf.function
def func2(x ,c1, c2):
    return  tf.multiply(x, c2) + c2

@tf.function
def func(x):
    return  func2(tf.nn.bias_add(tf.matmul(x,a) , c[0] ), c[1],  c[2])
     


input =  np.random.rand(1,length).astype(np.float32)
original_output = func(input).numpy()

print("Orginal:")
print(original_output)


def save_and_test(experimental_new_converter , filename):

    lite = tf.lite.TFLiteConverter.from_concrete_functions([func.get_concrete_function(x = tf.TensorSpec(shape=[None,length], dtype=tf.float32) )])
    lite.experimental_new_converter  = experimental_new_converter
    open(filename,"wb").write(lite.convert())

    interpreter = tf.lite.Interpreter(model_path=filename)
    interpreter.allocate_tensors()
    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input)
    interpreter.invoke()

    print(filename, ":")
    output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])
    print(output)
    print(filename, " sum of absolute difference: ", np.sum(np.absolute(original_output - output)))


save_and_test(True, "mlir")
save_and_test(False, "toco")
The output from the converter invocation
&lt;denchmark-code&gt;Orginal:
[[ 6.9496317   7.9791102   0.23810546  1.6724037   9.687994   11.553456
   0.60509163  8.606714   17.731003    2.52809    16.075905    0.50299734
   6.119868   12.388639    8.383967   11.989329    7.3116794   8.7486725
   9.714089   12.450738    1.4212162   7.567941   14.836599    5.73806
   8.028838    2.5774102   7.9609547  19.35534    11.474097    1.2807347
   5.075203   17.249842    3.0866256  17.775652    7.390017   15.896519
  16.136719    6.5862875  12.216141    0.33137095 18.97356     1.9778614
   5.3641543   1.9284656   1.8500257  16.767817   12.7209     14.047361
   7.367909    3.1752422   5.949711   15.742522    2.2939441  16.137108
   1.6687201  13.069997    8.666047   16.782955    1.3117387   6.3798137
   6.557558   15.286772    7.5772853   9.168247    3.2267199   1.5568383 ]]

mlir :
[[ 8.160242   9.0523     7.3261642  8.867854   7.860682   8.722304
   7.2230916  8.622743   9.271859   7.7777925  9.489797   7.390472
   8.524878   9.906944   8.355099   8.330111   8.341421   8.271743
   8.937096   8.515015   7.225615   9.190289   8.9844675  8.162167
   8.694139   6.9362564  9.618863  10.1376915  8.462459   8.29322
   8.158456   8.796178   8.039083   9.774652   8.209907   9.378836
  10.289057   7.984726   8.897137   9.119129   9.802201   8.349303
   6.498592   8.638722   8.569397   9.730883   8.358421   9.018978
   8.4079275  6.496749   8.111706   8.541293   9.513434   9.01988
   7.2715945  8.307488   8.566431   9.748925   8.775068   7.9520493
   7.9917192  9.261906   7.9303417  9.471784   9.427535   7.840794 ]]
mlir  sum of absolute difference:  284.37515

toco :
[[ 6.9496307   7.9791093   0.23810542  1.6724037   9.687995   11.553459
   0.6050917   8.606714   17.731003    2.5280902  16.075907    0.50299734
   6.1198673  12.388639    8.383966   11.98933     7.311679    8.748673
   9.714088   12.450737    1.4212162   7.567941   14.836597    5.73806
   8.028838    2.5774097   7.960953   19.355337   11.474101    1.2807347
   5.075203   17.24984     3.086626   17.775652    7.390019   15.896517
  16.13672     6.586289   12.216139    0.33137095 18.973562    1.9778614
   5.364155    1.9284654   1.8500254  16.767818   12.7209015  14.047361
   7.367908    3.1752434   5.94971    15.74252     2.2939441  16.137106
   1.6687204  13.069999    8.666047   16.782953    1.3117385   6.379814
   6.557558   15.286772    7.577286    9.168246    3.2267199   1.5568382 ]]
toco  sum of absolute difference:  5.4582953e-05
&lt;/denchmark-code&gt;

Failure details
The conversion is successful, but the generated model is wrong,
The result running with the model is much different from the original result.
	</description>
	<comments>
		<comment id='1' author='ghost(ghost)' date='2020-05-15T12:17:59Z'>
		Was able to reproduce the issue with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/97a184c5b298585bd18887b72e57c3e1/39572.ipynb&gt;TF v2.2&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/6a8783e3a871557adffddc2899e76661/39572-tf-nightly.ipynb&gt;TF-nightly&lt;/denchmark-link&gt;
. Please find the attached gist. Thanks!
		</comment>
		<comment id='2' author='ghost(ghost)' date='2020-05-15T13:21:27Z'>
		Looks like the fusion in MLIR is broken. I can reproduce this with the following minimal function as well:
length = 66
a = tf.random.uniform([length, length], dtype=tf.float32)
c = tf.random.uniform([length], dtype=tf.float32)

@tf.function
def func(x):
    return tf.matmul(x, a) * c
The weights in the generated flatbuffer are definitely different.
		</comment>
		<comment id='3' author='ghost(ghost)' date='2020-05-15T15:17:38Z'>
		It looks like this is not a new issue. I can reproduce this in v2.1.0 as well.
		</comment>
		<comment id='4' author='ghost(ghost)' date='2020-05-15T15:48:08Z'>
		


tensorflow/tensorflow/compiler/mlir/lite/transforms/optimize.cc


        Lines 361 to 368
      in
      020a88a






 if (!IsBroadcastableElementsAttrAndType(cst.getType(), filter.getType())) { 



 auto original_shape = cst.getType().getShape(); 



   llvm::SmallVector&lt;int64_t, 4&gt; normalized_shape(original_shape.begin(), 



                                                  original_shape.end()); 



   normalized_shape.push_back(1); 



 auto new_cst = cst.reshape(RankedTensorType::get( 



       normalized_shape, cst.getType().getElementType())); 



   Type new_type = new_cst.getType(); 





These lines are skipped if the filter is square matrix.
		</comment>
		<comment id='5' author='ghost(ghost)' date='2020-05-18T10:52:29Z'>
		Hi &lt;denchmark-link:https://github.com/liufengdb&gt;@liufengdb&lt;/denchmark-link&gt;
,
Do you think you can take a look?
		</comment>
		<comment id='6' author='ghost(ghost)' date='2020-05-19T06:43:30Z'>
		lgeiger, I'm a little bit confused by your example. The patterns used for tf.matmul(x, a) * c in your example is different from the issue description, right?
		</comment>
		<comment id='7' author='ghost(ghost)' date='2020-05-19T10:21:03Z'>
		
lgeiger, I'm a little bit confused by your example. The patterns used for tf.matmul(x, a) * c in your example is different from the issue description, right?

&lt;denchmark-link:https://github.com/liufengdb&gt;@liufengdb&lt;/denchmark-link&gt;
 Thanks for checking it out. Yes, the example is different on purpose since it uses a subset of the ops of the original example and I thought it might be helpful for debugging to have a smaller graph that reproduces the same issue. Please let me know if the two examples are not related, I am happy to open up a new issue for it.
		</comment>
		<comment id='8' author='ghost(ghost)' date='2020-05-21T06:09:24Z'>
		


tensorflow/tensorflow/compiler/mlir/lite/tests/optimize.mlir


        Lines 252 to 264
      in
      ed0eb69






 func @fuseMulIntoFullyConnectedNoBias(%arg0: tensor&lt;4x2xf32&gt;, %arg1: none) -&gt; tensor&lt;4x2xf32&gt; { 



 %cst0 = constant dense&lt;[[1.0, 2.0], [3.0, 4.0]]&gt; : tensor&lt;2x2xf32&gt; 



 %cst2 = constant dense&lt;[1.0, 2.0]&gt; : tensor&lt;2xf32&gt; 



 



 %0 = "tfl.fully_connected"(%arg0, %cst0, %arg1) {fused_activation_function = "NONE", keep_num_dims = false, weights_format = "DEFAULT"} : (tensor&lt;4x2xf32&gt;, tensor&lt;2x2xf32&gt;, none) -&gt; tensor&lt;4x2xf32&gt; 



 %1 = "tfl.mul"(%0, %cst2) {fused_activation_function = "RELU6"} : (tensor&lt;4x2xf32&gt;, tensor&lt;2xf32&gt;) -&gt; tensor&lt;4x2xf32&gt; 



 



 return %1 : tensor&lt;4x2xf32&gt; 



 



 // CHECK:  %[[CONSTANT:.*]] = constant dense&lt;{{\[\[}}1.000000e+00, 4.000000e+00], [3.000000e+00, 8.000000e+00]]&gt; : tensor&lt;2x2xf32&gt; 



 // CHECK:  %[[RES:.*]] = "tfl.fully_connected"(%arg0, %[[CONSTANT]], %arg1) {fused_activation_function = "RELU6", keep_num_dims = false, weights_format = "DEFAULT"} : (tensor&lt;4x2xf32&gt;, tensor&lt;2x2xf32&gt;, none) -&gt; tensor&lt;4x2xf32&gt; 



 // CHECK:  return %[[RES]] : tensor&lt;4x2xf32&gt; 



 } 





The test is invalid too.
&lt;denchmark-code&gt;cst0 = [[1.0, 2.0],
        [3.0, 4.0]]

cst1 = [1.0, 2.0]

arg0 = [x, y]

%0 = tfl.fully_connected(arg0, cst0) = tf.matmul(arg0, tf.transpose(cst0)) = [1.0x + 2.0y, 3.0x + 4.0y]

%1 = tfl.mul(%0, cst1) = [1.0x + 2.0y, 6.0x + 8.0y] = tf.matmul(arg0, [[1.0, 6.0], [2.0, 8.0]]) = tf.matmul(arg0, tf.transpose([[1.0, 2.0], [6.0, 8.0]]))

%[[CONSTANT]] = [[1.0, 2.0], [6.0, 8.0]]  !=  [[1.0, 4.0], [3.0, 8.0]]  


&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='ghost(ghost)' date='2020-07-09T13:25:04Z'>
		Are there any updates on this? It looks like the related PR is stale &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/40013&gt;#40013&lt;/denchmark-link&gt;
 but it would be great if this issue would be fixed.
		</comment>
		<comment id='10' author='ghost(ghost)' date='2020-08-11T08:35:08Z'>
		I submitted &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/41790&gt;#41790&lt;/denchmark-link&gt;
 a few weeks ago to fix this, any chance someone could review it?
		</comment>
		<comment id='11' author='ghost(ghost)' date='2020-09-22T08:05:06Z'>
		This is still a major issue and a fix is available at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/41790&gt;#41790&lt;/denchmark-link&gt;
, it would be great if this could still make it into the 2.4 release.
		</comment>
		<comment id='12' author='ghost(ghost)' date='2020-10-14T19:47:00Z'>
		I can still reproduce this in the latest tf-nightly: &lt;denchmark-link:https://colab.research.google.com/drive/1kcw_zhk_7wj8zOVf3VH1V-2GjN0eFQJF?usp=sharing&gt;https://colab.research.google.com/drive/1kcw_zhk_7wj8zOVf3VH1V-2GjN0eFQJF?usp=sharing&lt;/denchmark-link&gt;

Any news on when &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/41790&gt;#41790&lt;/denchmark-link&gt;
 could get a review?
		</comment>
		<comment id='13' author='ghost(ghost)' date='2020-11-06T12:42:48Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39572&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39572&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>