<bug id='25472' author='ZhiqingXiao' open_date='2019-02-03T13:17:51Z' closed_time='2019-07-19T22:02:50Z'>
	<summary>tf2.0 - tf.keras.optimizers.Optimizer.get_updates() does not work</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0-dev20190203
Python version: 3.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
When keras optimizer's get_updates() function is called, it raises error "RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
Describe the expected behavior
I expect it returns correct operators that can be used to build keras function that changes weights.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;from tensorflow import keras
model = keras.Sequential()
model.add(keras.layers.Dense(1, input_shape=(1,)))
model.compile(optimizer='adam', loss='mse')
loss = keras.losses.mse(model.input, model.output)
updates = model.optimizer.get_updates(params=model.trainable_weights, loss=loss)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Traceback:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-4-f4bb57df0d91&gt; in &lt;module&gt;()
      5 loss = keras.losses.mse(model.input, model.output)
      6 model.optimizer.get_updates(
----&gt; 7         params=model.trainable_weights, loss=loss)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in get_updates(self, loss, params)
    440 
    441   def get_updates(self, loss, params):
--&gt; 442     grads = self.get_gradients(loss, params)
    443     grads_and_vars = list(zip(grads, params))
    444     self._assert_valid_dtypes([

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in get_gradients(self, loss, params)
    353     """
    354     loss = self._scale_loss(loss)
--&gt; 355     grads = gradients.gradients(loss, params)
    356     if None in grads:
    357       raise ValueError("An operation has `None` for gradient. "

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py in gradients(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)
    156         ys, xs, grad_ys, name, colocate_gradients_with_ops,
    157         gate_gradients, aggregation_method, stop_gradients,
--&gt; 158         unconnected_gradients)
    159   # pylint: enable=protected-access
    160 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    545   """Implementation of gradients()."""
    546   if context.executing_eagerly():
--&gt; 547     raise RuntimeError("tf.gradients is not supported when eager execution "
    548                        "is enabled. Use tf.GradientTape instead.")
    549   if src_graph is None:

RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ZhiqingXiao' date='2019-07-19T22:02:50Z'>
		This is fixed TF 2.0 nightly '2.0.0-dev20190718'
Thanks!
		</comment>
		<comment id='2' author='ZhiqingXiao' date='2019-07-19T22:02:51Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=25472&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=25472&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>