<bug id='43386' author='cgreening' open_date='2020-09-20T17:45:02Z' closed_time='2020-09-20T21:15:27Z'>
	<summary>tf.lite.Optimize.DEFAULT - Hybrid models are not supported on TFLite Micro.</summary>
	<description>
@tensorflow/micro
System information

Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.6
TensorFlow installed from (source or binary): 2.3.0
Tensorflow version (commit SHA if source):
Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32

Describe the problem
I'm trying to convert a model for tflite, but keep hitting:
"Hybrid models are not supported on TFLite Micro."
Please provide the exact sequence of commands/steps when you ran into the problem
Here is my model:
&lt;denchmark-code&gt;model = Sequential([
    Conv2D(4, 3, 
           padding='same',
           activation='relu',
           input_shape=(IMG_WIDTH, IMG_HEIGHT, 1),
           name='conv_layer1'),
    MaxPooling2D(name='max_pooling1'),
    Conv2D(4, 3, 
           padding='same',
           activation='relu',
           name='conv_layer2'),
    MaxPooling2D(name='max_pooling2', pool_size=(2,2)),
    Flatten(),
    Dense(
        20,
        activation='relu',
        name='hidden_layer'
    ),
    Dense(1, activation='sigmoid', name='output')
])
&lt;/denchmark-code&gt;

And here is the code I am using to convert the mode:
&lt;denchmark-code&gt;converter = tf.lite.TFLiteConverter.from_saved_model("checkpoint.model")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
model = converter.convert()
open("converted_model.tflite", "wb").write(model)
&lt;/denchmark-code&gt;

I have also tried tf.lite.Optimize.OPTIMIZE_FOR_SIZE which has the same issue. Removing all optimisations lets me
Is there any way to avoid triggering this error with my model? Ideally, I would like to optimize my model to make it smaller.
	</description>
	<comments>
		<comment id='1' author='cgreening' date='2020-09-20T19:49:04Z'>
		See here:
&lt;denchmark-link:https://www.tensorflow.org/lite/performance/post_training_quantization&gt;https://www.tensorflow.org/lite/performance/post_training_quantization&lt;/denchmark-link&gt;

Go for full integer quantization. The default optimization leaves part of the operations as floating point (hence hybrid) and mixing isn't supported in micro.
		</comment>
		<comment id='2' author='cgreening' date='2020-09-20T21:15:27Z'>
		&lt;denchmark-link:https://github.com/yair-ehrenwald&gt;@yair-ehrenwald&lt;/denchmark-link&gt;

Great! Setting a value for the representative_dataset seems to fix it.
Thanks for the quick response.
		</comment>
	</comments>
</bug>