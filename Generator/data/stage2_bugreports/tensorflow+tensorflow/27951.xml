<bug id='27951' author='neodelphis' open_date='2019-04-18T10:32:26Z' closed_time='2019-04-26T21:07:03Z'>
	<summary>tf.nn.batch_normalization unexpected behavior</summary>
	<description>
tf.VERSION :  1.13.0-rc2
OS              : MacOS Mojave 10.14.4 on MacBook Pro (13-inch, 2017)
I encountered a problem trying to implement tf.nn.batch_normalization working on the mnist digits dataset.
For testing purposes, I implemented a very simple network
L1 : 100 neurons fully connected layer + Batch norm + Sigmoid
L2:   10 neurons fully connected layer + softmax
When I use tf.nn.batch_normalization
Ybn1   = tf.nn.batch_normalization(Yl1, m1, v1, O1, S1, 1e-5) it leads to divergence:
&lt;denchmark-link:https://user-images.githubusercontent.com/44782534/56353537-df10f380-61d1-11e9-9060-749a04f55cb4.png&gt;&lt;/denchmark-link&gt;

If I do the math by myself it does converge:
Yhat1 = (Yl1 - m1) / tf.sqrt(v1 + 1e-5)
 Ybn1  = S1 * Yhat1 + O1
&lt;denchmark-link:https://user-images.githubusercontent.com/44782534/56353771-6eb6a200-61d2-11e9-9d4f-08a6096091ea.png&gt;&lt;/denchmark-link&gt;

If I implement the content of batch_normalization function within my code, it does not work either.
inv = math_ops.rsqrt(v1 + 1e-5)
inv *= S1
Ybn1 =  Yl1 * math_ops.cast(inv, Yl1.dtype) + math_ops.cast(O1 - m1 * inv, Yl1.dtype)
but if I combine the 2 last lines it works correctly:
inv = math_ops.rsqrt(v1 + 1e-5)
Ybn1 =  (Yl1 - m1) * inv * S1+ O1
I have certainly done something wrong, but I cannot figure out what, and if it is a real bug I just wanted to let you know.
Here is the entire code if you want to reproduce the issue:
&lt;denchmark-link:https://github.com/neodelphis/tensorflow-without-a-phd-french/blob/master/mnist_test.ipynb&gt;https://github.com/neodelphis/tensorflow-without-a-phd-french/blob/master/mnist_test.ipynb&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='neodelphis' date='2019-04-26T21:07:03Z'>
		This question is better asked on &lt;denchmark-link:http://stackoverflow.com/questions/tagged/tensorflow&gt;StackOverflow&lt;/denchmark-link&gt;
 since it is not clear that this is an issue with TensorFlow. There is also a larger community that reads questions there. I would, however, recommend that you try to use , as keras layers are the recommended API moving forward.
If you think we've misinterpreted a bug, or if you're able to narrow the cause of the errant behavior down and determine that it is indeed an issue with TensorFlow, please comment again with a clear explanation as to why.Thanks!
		</comment>
		<comment id='2' author='neodelphis' date='2019-04-26T21:07:05Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27951&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27951&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>