<bug id='24566' author='sergeigofman' open_date='2018-12-25T19:47:14Z' closed_time='2019-06-03T06:06:55Z'>
	<summary>leaky_relu - buggy when alpha &amp;gt; 1 or alpha &amp;lt; 0</summary>
	<description>
tf.nn.leaky_relu() is implemented as math_ops.maximum(alpha * features, features, name=name). This won't work if alpha &gt; 1 or alpha &lt; 0. Although this is not expected, there is nothing that prevents users from setting alpha parameter as such.
A better implementation could be nn.relu(features) - alpha*nn.relu(-features) which won't suffer from the above issue.
	</description>
	<comments>
		<comment id='1' author='sergeigofman' date='2019-01-29T07:39:07Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
  Hiï¼ŒI want to know when this problem will be solved. Thank you
		</comment>
		<comment id='2' author='sergeigofman' date='2019-06-03T06:06:56Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=24566&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=24566&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>