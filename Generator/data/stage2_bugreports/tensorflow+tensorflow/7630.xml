<bug id='7630' author='cancan101' open_date='2017-02-17T19:19:31Z' closed_time='2017-06-16T19:02:59Z'>
	<summary>Poor Constant Propagation</summary>
	<description>
Running on the 1.0.0 Docker image.
Compare this:
&lt;denchmark-code&gt;tensor_util.constant_value_as_shape(ops.convert_to_tensor((tf.constant(15),16)))
&gt; TensorShape([Dimension(15), Dimension(16)])
&lt;/denchmark-code&gt;

to:
&lt;denchmark-code&gt;tensor_util.constant_value_as_shape(ops.convert_to_tensor((tf.constant(15) * 1,16)))
&gt; TensorShape([Dimension(None), Dimension(16)])
&lt;/denchmark-code&gt;

It seems to me that constant propagation should happen in the latter. This leads to size information being lost in certain cases such as image upsampling / downsampling where constant size is multiplied and then fed to something like resize_images.
	</description>
	<comments>
		<comment id='1' author='cancan101' date='2017-02-18T19:02:26Z'>
		I vaguely remember similar issues being fixed by modifying tensor_util.constant_value function. One possibility is that it works for tf.constant(15), but gives up when it sees a tf.mul
		</comment>
		<comment id='2' author='cancan101' date='2017-02-18T22:00:44Z'>
		Should be solvable by adding a case to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/a0d784bdd31b27e013a7eac58a86ba62e86db299/tensorflow/python/framework/tensor_util.py#L577&gt;_ConstantValue&lt;/denchmark-link&gt;
 (this can be used for any binary operator). This is rough solution, might not handle various tensor types quite right:
  elif tensor.op.type == "Mul":
    left = constant_value(tensor.op.inputs[0])
    if left is None:
      return None
    right = constant_value(tensor.op.inputs[1])
    if right is None:
      return None
    return left * right
		</comment>
		<comment id='3' author='cancan101' date='2017-02-18T22:22:42Z'>
		I think ideally, XLA and other more general optimization efforts will handle some of this better constant folding. CCing &lt;denchmark-link:https://github.com/prb12&gt;@prb12&lt;/denchmark-link&gt;
 for comment. I'd hate to have to put special cases like that in every Tensor, especially since that optimization would only benefit the python bindings and not any other languages.
		</comment>
		<comment id='4' author='cancan101' date='2017-02-18T22:30:40Z'>
		The issue that I am dealing with is on the Python side, where the shape information gets lost when calling resize_images with something like 2x the current size, etc.
		</comment>
		<comment id='5' author='cancan101' date='2017-02-19T04:46:18Z'>
		Sorry for the confusion. Yes, it looks like it would be good to propagate these cases into constantvalue, especially if they are happening in common functions. Could you please provide a PR. You might consider it checking for all binary operators that it can be done on in a generic way.
		</comment>
		<comment id='6' author='cancan101' date='2017-02-19T05:20:45Z'>
		If you do this in python, you might also want to implement the same logic in this C++ function: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/shape_refiner.cc#L356&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/shape_refiner.cc#L356&lt;/denchmark-link&gt;
 (with tests) -- it's possible in C++ the else clause already handles this case, whereas in python it doesn't, but it would be good to make sure they are consistent.
		</comment>
		<comment id='7' author='cancan101' date='2017-06-16T19:02:59Z'>
		Unfortunately the  fix proposed by &lt;denchmark-link:https://github.com/cancan101&gt;@cancan101&lt;/denchmark-link&gt;
 makes  linear time in the size of the whole graph in the worse case.  Therefore, I don't think we can support it in that form.  I'll close this issue as now as out of reach of simple contributions (and for lack of activity).
		</comment>
	</comments>
</bug>