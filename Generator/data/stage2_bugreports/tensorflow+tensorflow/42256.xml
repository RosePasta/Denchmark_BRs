<bug id='42256' author='zldrobit' open_date='2020-08-12T08:24:30Z' closed_time='2020-09-14T16:41:19Z'>
	<summary>How to avoid AddV2 op in TFLite model?</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): pip/binary
TensorFlow version (or github SHA if from source):
2.3.0
tflite 2.3.0 aar

Command used to run the converter or code if youâ€™re using the Python API
If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;import tensorflow as tf                                                 
if not tf.__version__.startswith('1'):                                  
    import tensorflow.compat.v1 as tf                                   
tf.disable_v2_behavior()                                                
# Path to the frozen graph file                                         
graph_def_file = 'weights/yolov5s.pb'                                   
# A list of the names of the model's input tensors                      
input_arrays = ['images']                                               
# A list of the names of the model's output tensors                     
output_arrays = ['Concat_442']                                          
# Load and convert the frozen graph                                     
converter = tf.lite.TFLiteConverter.from_frozen_graph(                  
    graph_def_file, input_arrays, output_arrays)                        
# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
#                                        tf.lite.OpsSet.SELECT_TF_OPS]  
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
converter.allow_custom_ops = True                                     
# converter.experimental_new_converter = False                            
tflite_model = converter.convert()                                      
# Write the converted model to disk                                     
open("weights/yolov5s.tflite", "wb").write(tflite_model)                
&lt;/denchmark-code&gt;

The output from the converter invocation
&lt;denchmark-code&gt;# Copy and paste the output here.
&lt;/denchmark-code&gt;

Also, please include a link to the saved model or GraphDef
&lt;denchmark-code&gt;# Put link here or attach to the issue.
&lt;/denchmark-code&gt;

Failure details
I try to convert a Tensorflow GraphDef model to TFLite model, and I want to void AddV2 op.
If I use tf.lite.OpsSet.SELECT_TF_OPS option, FlexAddV2 will be generated instead of AddV2, which I would like to avoid too.
AddV2 is unsupported in tflite 2.3.0 aar.
FlexAddV2 is supported by flex delegate, but cannot work on Android Emulator (Pixel 2 API 24) .
The last thing I tried is substituting 'AddV2' with 'Add' manually in pbtxt format (AddV2 is in the original GraphDef ).
After I convert the processed GraphDef with tflite converter, the 'AddV2' ops emerge again.
PS:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33393&gt;#33393&lt;/denchmark-link&gt;
 says that TensorFlow 1.15 can resolve this problem.
	</description>
	<comments>
		<comment id='1' author='zldrobit' date='2020-08-12T08:36:06Z'>
		&lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;

Please share complete information for us to replicate the issue faced, i ran the code shared and face a different issue, &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/f43423fa38f09670c520cd8ac731758c/untitled365.ipynb&gt;gist&lt;/denchmark-link&gt;
 for the same.
		</comment>
		<comment id='2' author='zldrobit' date='2020-08-12T08:54:45Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 I have uploaded the model to &lt;denchmark-link:https://drive.google.com/file/d/1Z4jJ6DwP_A1o2fyN8oSMhEz6quRJ42Jf/view?usp=sharing&gt;https://drive.google.com/file/d/1Z4jJ6DwP_A1o2fyN8oSMhEz6quRJ42Jf/view?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='zldrobit' date='2020-08-12T11:24:52Z'>
		&lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;

I tried to access the link shared it says no preview available.
		</comment>
		<comment id='4' author='zldrobit' date='2020-08-13T00:09:29Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 you can click  to download the file directly.
		</comment>
		<comment id='5' author='zldrobit' date='2020-08-20T04:20:10Z'>
		hi &lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;

i have a same issue~~
and then test &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33393&gt;#33393&lt;/denchmark-link&gt;
 tensorflow 1.15.0 but have a trouble .
tensorflow-addons hope tensorflow1.15.0 to tensorflow 2.x
under is command line log
'''
ImportError: This version of TensorFlow Addons requires TensorFlow version &gt;= 2; Detected an installation of version 1.15.0. Please upgrade TensorFlow to proceed.
'''
ps . i install tensorflow-addons 0.5.0
		</comment>
		<comment id='6' author='zldrobit' date='2020-08-20T05:16:00Z'>
		&lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;

I ran the code on 2.3, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/9133c142c3231beb79c2ed6a86ae5330/untitled379.ipynb&gt;gist here&lt;/denchmark-link&gt;
, whereas in nightly i face an issue, &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/4d5120b5e5fc76c7329592bbeb4c89e7/untitled379.ipynb&gt;gist for nightly&lt;/denchmark-link&gt;
.
&lt;denchmark-link:https://github.com/dan0978520303&gt;@dan0978520303&lt;/denchmark-link&gt;

Can you please try with later versions of tf and let us know if you still face any issues.
		</comment>
		<comment id='7' author='zldrobit' date='2020-08-20T06:45:04Z'>
		
@dan0978520303
Can you please try with later versions of tf and let us know if you still face any issues.

tf2.3 can work in my converter (pb -&gt; tflite) but the graph appear AddV2 (have same trouble with author)
i still find version (tf, onnx-tf, ... ) such that AddV2 becoming Add
appreciation any advice !!!
		</comment>
		<comment id='8' author='zldrobit' date='2020-08-20T07:13:48Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 , I notice that you changed
 to .
It won't work if you use .
&lt;denchmark-link:https://github.com/dan0978520303&gt;@dan0978520303&lt;/denchmark-link&gt;
, I find that TF v2.1.1 works in converting tf.AddV2 to tfl add.
I conjuecture that something is wrong with v2.3.0 MLIR TFLite converter.
		</comment>
		<comment id='9' author='zldrobit' date='2020-08-20T07:26:25Z'>
		
@dan0978520303, I find that TF v2.1.1 works in converting tf.AddV2 to tfl add.
I conjuecture that something is wrong with v2.3.0 MLIR TFLite converter.

hi! thank you replication~
But i run the tf2.1.1 still appear familiar situation (attr.value_case() == AttrValue::kType (1 vs. 6)) ps : tf2.3 , it can work
Can i see your environment (pb to tflite file )?
thx very much~~~
I stuck over 5 days =(
		</comment>
		<comment id='10' author='zldrobit' date='2020-08-20T08:35:21Z'>
		&lt;denchmark-link:https://github.com/dan0978520303&gt;@dan0978520303&lt;/denchmark-link&gt;
  Of course.
It's just the &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/42256#issue-677499982&gt;first thread&lt;/denchmark-link&gt;
 I wrote in this issue .
It seems you are using the  TOCO converter, while the key is to turn the experimental converter switch :
&lt;denchmark-code&gt;converter.experimental_new_converter = True
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='zldrobit' date='2020-08-20T09:04:40Z'>
		
@dan0978520303 Of course.
It's just the first thread I wrote in this issue .
It seems you are using the OLD TOCO converter, while the key is to turn the experimental converter switch ON:
converter.experimental_new_converter = True


thx~~~
I add this '''converter.experimental_new_converter = True ''' to avoid  AttrValue::kType (1 vs. 6) problem =)
But i encounter this error
'tfl.padv2' op failed to verify that operand 0's rank equals operand 1's size
Could you encounter this error ?
thx one more again !!!
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

updated,
Finally, tf 2.2.0 is work !!!
		</comment>
		<comment id='12' author='zldrobit' date='2020-08-20T12:23:23Z'>
		
@zldrobit

I ran the same code shared by you in the issue template where "converter.allow_custom_ops = True " is true and did not face any issues, as shared above with you.
Can you try the same, also with 2.2 and let us know if you still facing the issue.
		</comment>
		<comment id='13' author='zldrobit' date='2020-08-21T00:30:44Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 I can convert the model using either v2.1.1 or v2.2.
		</comment>
		<comment id='14' author='zldrobit' date='2020-08-24T03:13:28Z'>
		hi! &lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;

Do you encounter an error : RuntimeError: Inputs and outputs not all float|uint8|int16 types.Node number 91 (ADD) failed to invoke. ?
I run this test to try if the tflite file can work on the android ~
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/39790&gt;#39790&lt;/denchmark-link&gt;
 this not work for me.
In Netron , I find the Add node is int64 after pb to tflite converter.
But i don't any idea to fix int64 to int32.
this is my code :
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

import tensorflow as tf
import numpy as np
interpreter = tf.lite.Interpreter(model_path="0824.tflite")
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

thanks any advices ~~~
		</comment>
		<comment id='15' author='zldrobit' date='2020-08-24T15:24:22Z'>
		&lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;

Is this still an issue.
		</comment>
		<comment id='16' author='zldrobit' date='2020-08-25T00:27:45Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 It's not an issue for me now. I had a workaround to convert a model using TF v2.1.1/v2.2, and infer the model with TF v2.3.
&lt;denchmark-link:https://github.com/dan0978520303&gt;@dan0978520303&lt;/denchmark-link&gt;
 Have you tried to use the new experimental converter
?
		</comment>
		<comment id='17' author='zldrobit' date='2020-08-25T02:17:17Z'>
		
@dan0978520303 Have you tried to use the new experimental converter
converter.experimental_new_converter = False?

hi ! &lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;

thank your replication~
I have tried to change "converter.experimental_new_converter = False" and "converter using TF v2.1.1/v2.2 and infer TF v2.3".
Above, not work =(
Another way is inference in tf-nightly 2.4.0.dev20200824 but still error is :
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

RuntimeError: tensorflow/lite/kernels/add.cc:373 Type INT64 is unsupported by op Add.Node number 91 (ADD) failed to invoke.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

It still not work ~
		</comment>
		<comment id='18' author='zldrobit' date='2020-08-25T05:24:23Z'>
		&lt;denchmark-link:https://github.com/dan0978520303&gt;@dan0978520303&lt;/denchmark-link&gt;

Please provide complete stand alone(indented) code with system details or if possible share colab gist with error faced.
		</comment>
		<comment id='19' author='zldrobit' date='2020-08-25T06:14:48Z'>
		
@dan0978520303
Please provide complete stand alone(indented) code with system details or if possible share colab gist with error faced.

Hi &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

here is my code :
&lt;denchmark-link:https://colab.research.google.com/gist/dan0978520303/27c8e30a194a3195d343ae5023f8bfb6/question.ipynb&gt;https://colab.research.google.com/gist/dan0978520303/27c8e30a194a3195d343ae5023f8bfb6/question.ipynb&lt;/denchmark-link&gt;

ps:

my env is conda

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

onnx 1.6.0
tensorflow 2.2.0 (converter)
tf-nightly 2.4.0.dev20200824 (inference)
tensorflow-addons 0.11.1
pytorch 1.4.0
python  3.7.7
onnx-tf 1.6.0 (pip install git+&lt;denchmark-link:https://github.com/onnx/onnx-tensorflow.git&gt;https://github.com/onnx/onnx-tensorflow.git&lt;/denchmark-link&gt;
)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;


my unet  model is from  :

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/switchablenorms/CelebAMask-HQ/tree/master/face_parsing&gt;https://github.com/switchablenorms/CelebAMask-HQ/tree/master/face_parsing&lt;/denchmark-link&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

I really appreciate any advice !!!
		</comment>
		<comment id='20' author='zldrobit' date='2020-08-26T16:11:31Z'>
		&lt;denchmark-link:https://github.com/dan0978520303&gt;@dan0978520303&lt;/denchmark-link&gt;

I am unable to replicate your code, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/e5b7df3c91c19673a8b30d88685bc2c2/untitled395.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='21' author='zldrobit' date='2020-08-27T02:30:28Z'>
		
@dan0978520303
I am unable to replicate your code, please find the gist here.

hi &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

My onnx model is too complex and then simplify the onnx model by onnx-simplifier.
It can work for me~
Hope this can help  =)
		</comment>
		<comment id='22' author='zldrobit' date='2020-08-27T04:50:03Z'>
		&lt;denchmark-link:https://github.com/dan0978520303&gt;@dan0978520303&lt;/denchmark-link&gt;

Can you please provide a colab gist with the error reported, Can you please create a new issue with these details as the issue reported by user is resolved.
		</comment>
		<comment id='23' author='zldrobit' date='2020-08-28T02:37:46Z'>
		
@dan0978520303
Can you please provide a colab gist with the error reported, Can you please create a new issue with these details as the issue reported by user is resolved.

OK~
Let me list my process to open new issue.
Because i first use github, my report maybe not good~
		</comment>
		<comment id='24' author='zldrobit' date='2020-08-28T04:23:46Z'>
		&lt;denchmark-link:https://github.com/dan0978520303&gt;@dan0978520303&lt;/denchmark-link&gt;

Please submit the new issue from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new/choose&gt;this link&lt;/denchmark-link&gt;
 and fill in the issue template, so that we can track the issue there. Thanks!
		</comment>
		<comment id='25' author='zldrobit' date='2020-09-07T16:16:23Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='26' author='zldrobit' date='2020-09-14T16:41:11Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='27' author='zldrobit' date='2020-09-14T16:41:28Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42256&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42256&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>