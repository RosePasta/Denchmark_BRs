<bug id='27845' author='proteneer' open_date='2019-04-15T02:59:25Z' closed_time='2019-04-22T18:24:17Z'>
	<summary>Wrong derivatives for complex second order derivatives.</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tensorflow==1.12.0
Python version: 3.6.8

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
Derivatives of non-holomorphic functions are incorrect when compared both against AD and finite differences.
Describe the expected behavior
Derivatives of non-holomorphic functions should becorrect.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import numpy as onp
import autograd as ag
import autograd.numpy as anp
import numpy as onp
import tensorflow as tf

inp = anp.array(2.0)

print("input", inp)

def ag_fn(x):
    real = anp.cos(x+2)
    imag = anp.sin(x-1)
    return anp.abs(real+1j*imag)

ag_hess = ag.hessian(ag_fn)

print("ag val:", ag_fn(inp))
print("ag hess:", ag_hess(inp))

def tf_fn(x):
    real = tf.cos(x+2)
    imag = tf.sin(x-1)
    return tf.abs(tf.complex(real, imag))

# tf_inp = tf.convert_to_tensor(inp)
tf_inp = tf.placeholder(shape=tuple(), dtype=onp.float64)

out_op = tf_fn(tf_inp)

tf_grad = tf.gradients(out_op, tf_inp)[0]
tf_hess = tf.hessians(out_op, tf_inp)[0]

sess = tf.Session()
delta = 1e-7

_, d0, tf_ad = sess.run([out_op, tf_grad, tf_hess], feed_dict={tf_inp: inp})
_, d1, _ = sess.run([out_op, tf_grad, tf_hess], feed_dict={tf_inp: inp+delta})

print("tf_numerical derivative:", (d1-d0)/delta)
print("tf_autodiff derivative:", tf_ad)
&lt;denchmark-code&gt;input 2.0
ag val: 1.0655155566059393
ag hess: -0.25533014019223726
2019-04-14 22:55:43.481283: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
tf_numerical derivative: -0.25533013481293665
tf_autodiff derivative: -1.0655155566059389
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Additional information: &lt;denchmark-link:https://github.com/google/jax/issues/603&gt;google/jax#603&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='proteneer' date='2019-04-15T14:54:51Z'>
		Ran this on tensorflow==2.0.0-dev20190327 and I get the same incorrect output.
		</comment>
		<comment id='2' author='proteneer' date='2019-04-20T00:09:11Z'>
		Thanks for the minimal code snippet to reproduce the issue. I was able to reproduce the behavior in TF 1.13 and latest nightly build.
		</comment>
		<comment id='3' author='proteneer' date='2019-04-22T16:13:23Z'>
		Thanks for filing the issue!
If I replace tf.abs on your example with a manual implementation (tf.sqrt(real(x)*real(x) + imag(x)*imag(x))) the values are identical, so I think this is a problem with the gradient for the ComplexAbs op.
		</comment>
		<comment id='4' author='proteneer' date='2019-04-22T18:24:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27845&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27845&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='proteneer' date='2019-04-24T15:25:52Z'>
		Thanks for fixing this guys!
		</comment>
	</comments>
</bug>