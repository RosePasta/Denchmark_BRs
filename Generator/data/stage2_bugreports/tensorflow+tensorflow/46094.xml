<bug id='46094' author='omerbrandis' open_date='2020-12-31T12:56:07Z' closed_time='2021-01-22T06:37:26Z'>
	<summary>cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory</summary>
	<description>
hello,
I'm trying to run inference on a tensorrt converted graph (tf-trt) and received the error in the title.
I've followed instructions for "TF-TRT 2.0 Workflow With A SavedModel" at &lt;denchmark-link:https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html&gt;https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html&lt;/denchmark-link&gt;
.
but i'm afraid i have not been able to reach the part of the code the performs the inference, I get the OOM error a after loading the saved model , during preparation of the input data.
I'm running tensorflow 2.0.0 (eager execution). on ubuntu 16.04, cuda 10.0, geforce gtx 1050 ( 4gb ram )
here is my conversion code
from tensorflow.python.compiler.tensorrt import trt_convert as trt
ConvParams = trt.DEFAULT_TRT_CONVERSION_PARAMS
ConvParams = ConvParams._replace(max_workspace_size_bytes=110241024*1024)
ConvParams = ConvParams._replace(precision_mode="FP32")
ConvParams = ConvParams._replace(max_batch_size=1)
converter = trt.TrtGraphConverterV2(input_saved_model_dir=args.InputToConvert, conversion_params=ConvParams)
TensorRT_graph = converter.convert()
print('convert completed, building')
def my_input_fn():
import numpy as np
Inp1 = np.random.normal(size=(1,250, 250, 3)).astype(np.uint8)
yield [Inp1]
converter.build(input_fn=my_input_fn)
print('build completed, saveing results to {}'.format(args.Output))
converter.save(args.Output)
the conversion process generates warnings but succeeds.
in another program/script/"execution session" I perform the following:
load the saved model using the following code
saved_model_loaded = tf.saved_model.load('my saved model directory name',tags=[tf.compat.v1.saved_model.tag_constants.SERVING])
graph_func = saved_model_loaded.signatures[tf.compat.v1.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2
frozen_func = convert_variables_to_constants_v2(graph_func)
print('created concreate function')
try to load an image for inference
ReadFile = tf.io.read_file('/home/omerbrandis/ffrobotics/AppleMask/mask_rcnn/test_images/img3095_RECT2_2.jpg')
print('after read file')
DecodedImg = tf.io.decode_jpeg(ReadFile)
print('after decode ')
image_expanded = tf.expand_dims(DecodedImg, axis=0)
print('read file')
at runtime the code does not reach "read file" , only "after decode" is written.
if i comment out the first section of the program that deals with reading the graph , the part that reads the file works without any problem.
as stated before, i have 4GB of ram on my gpu , and the conversion process should have limited the graphs usage to 1gb thus the OOM error is surprising. ( the image is only 210X210 pixels).
please advise
Omer.
	</description>
	<comments>
		<comment id='1' author='omerbrandis' date='2021-01-08T05:25:06Z'>
		&lt;denchmark-link:https://github.com/omerbrandis&gt;@omerbrandis&lt;/denchmark-link&gt;

Can you please try in latest stable TF version 2.4 and see if you are facing the same issue?.There are lot of performance improvements in latest releases.
If you are facing issue still please share the colab link or simple standalone code with proper indentation and supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='2' author='omerbrandis' date='2021-01-15T06:03:29Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='3' author='omerbrandis' date='2021-01-22T06:37:24Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='4' author='omerbrandis' date='2021-01-22T06:37:29Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46094&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46094&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>