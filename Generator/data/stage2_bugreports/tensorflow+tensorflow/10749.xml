<bug id='10749' author='Sushobhan04' open_date='2017-06-16T00:45:28Z' closed_time='2018-06-25T18:59:45Z'>
	<summary>Numpy.fft.fft2() gives different result than tf.fft2d()</summary>
	<description>
as mentioned in the issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/6401&gt;#6401&lt;/denchmark-link&gt;
, the tf.fft2d() gives different result compared to np.fft.fft2(). Is there a reason for this ?
Note : numpy gives proper fourier transform after np.fft.fftshift(), and I have taken care of that in my code.
The differences are not visible here, but the mean squared error is significant.
&lt;denchmark-link:https://user-images.githubusercontent.com/18488880/27207200-84637a88-5202-11e7-9d49-d22cf9a8057d.png&gt;&lt;/denchmark-link&gt;
&lt;denchmark-link:https://user-images.githubusercontent.com/18488880/27207198-8462f2b6-5202-11e7-88c2-7114b36c696a.png&gt;&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://user-images.githubusercontent.com/18488880/27207199-8462fe50-5202-11e7-8d7b-bca01bba063b.png&gt;&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://user-images.githubusercontent.com/18488880/27207631-f2a41284-5205-11e7-91a6-336d75755787.png&gt;&lt;/denchmark-link&gt;

Second image is the fft using tensorflow, and third one is using numpy. You can see the difference in the corners. The fourth image is the difference between the two images times 10.
(tf has some features while numpy does not)
I am working on an application which uses fft in backpropagation and thus it is of absolute importance that the fft in numpy are same as fft by tf.
My question is - Why is there a difference and how can I get the same fft as numpy ?
	</description>
	<comments>
		<comment id='1' author='Sushobhan04' date='2017-06-16T02:51:15Z'>
		I am not sure if this is related to this issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/10735&gt;#10735&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='Sushobhan04' date='2017-06-16T15:55:45Z'>
		Can you give any indication about the relative error between the two versions? How much did you magnify the difference image?
		</comment>
		<comment id='3' author='Sushobhan04' date='2017-06-19T00:34:17Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 Hey, sorry for late response. I magnified the difference by a factor of 10.
I realized that numpy uses float64 whereas tf uses float32. I could not find a way to use float64 in tf (creates a complex128, which is not supported by tf.fft2d). Could this be a possible problem ?
The difference kind of seems huge to consider floating point accuracy as the reason.
		</comment>
		<comment id='4' author='Sushobhan04' date='2017-06-19T16:28:16Z'>
		We use cuFFT to compute fft's, so it is a property of the cufft. You could look at its documentation to see if it has any insight (or google for cufft vs fftw). Also, you could see whether numpy.fft when run with floats matches better.
		</comment>
		<comment id='5' author='Sushobhan04' date='2017-09-12T19:15:08Z'>
		This is still an issue. I am not sure how much it will matter in the long run if we are training a network around it anyway..., but it is quite shocking that the error is so high. This also makes debugging hard, because TF's FFT is undoubtedly not doing what we think it should be. Perhaps cuFFT's algorithm is not numerically stable? The error is there even for 1D, but it is much much smaller. This makes me think that the 2D implementation is not optimal, with a lot of fill in or non-optimal number of operations. If someone can point me to the code, maybe we can debug / suggest a fix without changing too much.
Some python code to verify error using complex64 for both numpy and tf (i.e. based on float32):
&lt;denchmark-code&gt;## DEFINE FFTs
fft1D_np = np.fft.fft
fft1D_tf = tf.fft
ifft1D_np = np.fft.ifft
ifft1D_tf = tf.ifft
fft2D_np = np.fft.fft2
fft2D_tf = tf.fft2d
ifft2D_np = np.fft.ifft2
ifft2D_tf = tf.ifft2d
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;  ## TEST 2D FFT
   np.random.seed(13)
   M = np.random.random([1,2,2]).astype(np.complex64)
   M_tf = tf.placeholder(dtype=M.dtype, shape=[None,*M.shape[1:]], name='M_tf')
   eval_dict = {M_tf: M}
   sess, gsaver = nn_utils.init_network()
   Mhat = fft2D_np(M) 
   Mhat_tf = fft2D_tf(M_tf)
   Mhat_tfeval = Mhat_tf.eval(feed_dict=eval_dict)
   e = Mhat - Mhat_tfeval
   err = np.linalg.norm(e.reshape([-1,1]))
   assert( np.isclose(err, 0.0) )
&lt;/denchmark-code&gt;

Doing some prints in my session:
&lt;denchmark-code&gt;&gt;&gt;&gt; M
array([[[ 0.77770239+0.j,  0.23754121+0.j],
        [ 0.82427853+0.j,  0.96574920+0.j]]], dtype=complex64)
&gt;&gt;&gt; Mhat
array([[[ 2.80527139+0.j,  0.39869052+0.j],
        [-0.77478409+0.j,  0.68163186+0.j]]], dtype=complex64)
&gt;&gt;&gt; Mhat_tfeval
array([[[ 2.80527139+0.j,  0.39869046+0.j],
        [-0.77478415+0.j,  0.68163186+0.j]]], dtype=complex64)
&gt;&gt;&gt; e
array([[[  0.00000000e+00+0.j,   5.96046448e-08+0.j],
        [  5.96046448e-08+0.j,   0.00000000e+00+0.j]]], dtype=complex64)
&gt;&gt;&gt; err
8.4293696e-08
&gt;&gt;&gt; np.isclose(err, 0.0)
False
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='Sushobhan04' date='2017-10-02T01:27:43Z'>
		&lt;denchmark-link:https://github.com/sirgogo&gt;@sirgogo&lt;/denchmark-link&gt;
, can you please post the source to  and  in your example?
Are your ops running on GPU or CPU?
(have you verified that with tf.ConfigProto(log_device_placement=True)?)
FWIW, NumPy is the oracle used for all of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/fft_ops_test.py&gt;the FFT unit tests&lt;/denchmark-link&gt;
.  The tolerance on those checks is  at the moment, which is pretty high, but it's because we're using a one-size-fits all bound against Eigen's TensorFFT (CPU), and cuFFT (GPU). Please also note that the FFT unit tests include gradient tests, that verify the numerical gradient matches the symbolic gradient.
Due to differences in the floating point hardware across your CPU and GPU, the results between NumPy and cuFFT will differ by some amount for an identical sequence of floating point operations. Additionally, NumPy uses fftpack for its FFTs -- so whether your ops are running on CPU or GPU, it's a different FFT implementation from TensorFlow's. That's not to say there isn't a bug in TensorFlow's invocation of these FFT implementations or the implementations themselves!
Here are code pointers:

Eigen TensorFFT
TensorFlow FFT kernels. Used to invoke either Eigen TensorFFT or cuFFT.
cuFFT documentation
StreamExecutor invocation of cuFFT
TensorFlow FFT gradient definitions

What is your expectation here?  e.g. would you be happy if np.isclose returned True in your example? That would imply you need something like rtol=1e-5, atol=1e-8 ?
		</comment>
		<comment id='7' author='Sushobhan04' date='2017-10-11T18:29:50Z'>
		&lt;denchmark-link:https://github.com/rryan&gt;@rryan&lt;/denchmark-link&gt;
, thank you for the info and links! I will take a look shortly. Sorry for the  delay, I was out of town, server went down, etc etc.
You can run the example with the following simple definitions: I have updated that post with this
&lt;denchmark-code&gt;fft1D_np = np.fft.fft
fft1D_tf = tf.fft
ifft1D_np = np.fft.ifft
ifft1D_tf = tf.ifft
fft2D_np = np.fft.fft2
fft2D_tf = tf.fft2d
ifft2D_np = np.fft.ifft2
ifft2D_tf = tf.ifft2d
&lt;/denchmark-code&gt;

I am running with tensorflow-GPU. This is the only way I was able to get any of the tf.fft-like functions to work. It complains if you are using the CPU-only version (at least for 2D). Is this sufficient to assume the ops are running on the GPU? I can try the log_device_placement setting.
Yes, I would expect that the maximum relative error needs to be lower. That would probably make me / most folks happy. Thanks for your insight into this. Just to clarify, you are saying this is an issue with Eigen's TensorFFT / cuFFT, and not something that would be fixed by compiling from source?
		</comment>
		<comment id='8' author='Sushobhan04' date='2017-12-09T17:30:32Z'>
		Hi,
using tensorflow to do some signal processing and the fft problem has appeared. I did some tests and hope they are helpful. I also created a repository with the example signal where the fft really goes wrong using the cpu, error after fft is &gt;1e+14. With a gpu it looks good.
Code:
(&lt;denchmark-link:https://github.com/rassibassi/fftTensorflow&gt;https://github.com/rassibassi/fftTensorflow&lt;/denchmark-link&gt;
)
import tensorflow as tf
import scipy.io
import numpy as np

print('tf:',tf.__version__)
print('scipy:',scipy.__version__)
print('np:',np.__version__)

# numpy fft
signal = scipy.io.loadmat('signal.mat')['signal']
signal_f = np.fft.fft(signal)

# tf fft
tf_signal = tf.placeholder(shape=signal.shape,dtype=tf.complex64)
tf_signal_f = tf.fft(tf_signal)
session = tf.InteractiveSession()
out_signal_f, out_signal = session.run([tf_signal_f,tf_signal], feed_dict={tf_signal:signal})

errorBefore = np.mean(np.power(np.abs(out_signal-signal),2))
errorAfter = np.mean(np.power(np.abs(out_signal_f-signal_f),2))
print('Error before fft:',errorBefore)
print('Error after fft:',errorAfter)
unix ubuntu cpu:
&lt;denchmark-code&gt;tf: 1.4.0
scipy: 0.19.1
np: 1.13.1
Error before fft: 6.43755807539e-22
Error after fft: 4.21685308781e+14
&lt;/denchmark-code&gt;

scientific linux hpc-cluster cpu:
&lt;denchmark-code&gt;tf: 1.3.0
scipy: 0.17.1
np: 1.11.0
Error before fft: 6.43755807539e-22
Error after fft: 4.21685308781e+14
&lt;/denchmark-code&gt;

scientific linux hpc-cluster gpu (Tesla K80) with cudnn/v5.1:
&lt;denchmark-code&gt;('tf:', '1.0.1')
('scipy:', '0.18.1')
('np:', '1.11.2')
('Error before fft:', 6.4375580753914162e-22)
('Error after fft:', 2.8628744462657876e-15)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='Sushobhan04' date='2017-12-09T19:07:13Z'>
		Thanks very much for the helpful repro &lt;denchmark-link:https://github.com/Rassibassi&gt;@Rassibassi&lt;/denchmark-link&gt;
! I can also reproduce the issue.
This suggests an issue with Eigen TensorFFT or the TensorFlow plumbing that uses it. Interestingly, if I trim your 66528 tensor to length 65536 (power of 2) the results match numpy to 1e-8, but I get high error at length 65535. I get similar results when I trim the input tensor to length 32768/32767, but not when I trim to 16384/16383. Maybe suggests something is overflowing? We'll take a look.
cc: &lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;('tf:', '1.4.1')
('scipy:', '1.0.0')
('np:', '1.13.3')
('signal=', (1, 65536))
('Error before fft:', 6.4749546908751922e-22)
('Error after fft:', 1.0376122868548086e-08)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;('tf:', '1.4.1')
('scipy:', '1.0.0')
('np:', '1.13.3')
('signal=', (1, 65535))
('Error before fft:', 6.4750239427498006e-22)
('Error after fft:', 55656499607300.164)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;('tf:', '1.4.1')
('scipy:', '1.0.0')
('np:', '1.13.3')
('signal=', (1, 32768))
('Error before fft:', 6.1796690528036584e-22)
('Error after fft:', 7.996054658436124e-10)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;('tf:', '1.4.1')
('scipy:', '1.0.0')
('np:', '1.13.3')
('signal=', (1, 32767))
('Error before fft:', 6.1793787363606864e-22)
('Error after fft:', 1754207811720195.0)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;('tf:', '1.4.1')
('scipy:', '1.0.0')
('np:', '1.13.3')
('signal=', (1, 16384))
('Error before fft:', 6.0547451539629847e-22)
('Error after fft:', 1.1566757798862581e-10)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;('tf:', '1.4.1')
('scipy:', '1.0.0')
('np:', '1.13.3')
('signal=', (1, 16383))
('Error before fft:', 6.055074302285619e-22)
('Error after fft:', 8.9115448530747228e-06)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='Sushobhan04' date='2017-12-30T17:26:27Z'>
		Hi,
I've gotten high errors also running one dimensional tf.rfft() on CPU over large signals (&gt;280000 samples). On the other hand, after trimming the tensor length to the next power of two the results are quite better (in terms of error), as pointed out by &lt;denchmark-link:https://github.com/rryan&gt;@rryan&lt;/denchmark-link&gt;
 .
		</comment>
		<comment id='11' author='Sushobhan04' date='2017-12-30T21:24:21Z'>
		We think we tracked the issue (or part of the issue) down to this code in Eigen that computes twiddle factors for non-power-of-2 FFTs via Bluestein's algorithm.
&lt;denchmark-link:https://bitbucket.org/eigen/eigen/src/034b6c3e101792a3cc3ccabd9bfaddcabe85bb58/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h?at=default&amp;fileviewer=file-view-default#TensorFFT.h-230:249&gt;https://bitbucket.org/eigen/eigen/src/034b6c3e101792a3cc3ccabd9bfaddcabe85bb58/unsupported/Eigen/CXX11/src/Tensor/TensorFFT.h?at=default&amp;fileviewer=file-view-default#TensorFFT.h-230:249&lt;/denchmark-link&gt;

We'll submit a fix to Eigen, then update the version of Eigen that TensorFlow uses.
		</comment>
		<comment id='12' author='Sushobhan04' date='2017-12-31T16:05:48Z'>
		&lt;denchmark-link:https://bitbucket.org/eigen/eigen/pull-requests/356/disable-use-of-recurrence-for-computing&gt;https://bitbucket.org/eigen/eigen/pull-requests/356/disable-use-of-recurrence-for-computing&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='Sushobhan04' date='2017-12-31T16:07:09Z'>
		I'm not sure if this is the same issue &lt;denchmark-link:https://github.com/Sushobhan04&gt;@Sushobhan04&lt;/denchmark-link&gt;
 is seeing though (the subject of this issue).
&lt;denchmark-link:https://github.com/Sushobhan04&gt;@Sushobhan04&lt;/denchmark-link&gt;
, are you using power of 2 transforms?
		</comment>
		<comment id='14' author='Sushobhan04' date='2018-01-15T18:59:39Z'>
		Nagging Awaiting Response: It has been 14 days with no activityand the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='15' author='Sushobhan04' date='2018-01-19T01:57:59Z'>
		As of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/67ff23036e093343a7ea02e17f36f2b02eaae740&gt;67ff230&lt;/denchmark-link&gt;
 the fix in &lt;denchmark-link:https://bitbucket.org/eigen/eigen/pull-requests/356/disable-use-of-recurrence-for-computing&gt;https://bitbucket.org/eigen/eigen/pull-requests/356/disable-use-of-recurrence-for-computing&lt;/denchmark-link&gt;
 has been applied to TensorFlow.
		</comment>
		<comment id='16' author='Sushobhan04' date='2018-01-31T05:51:31Z'>
		Hej!
Thanks for fixing the issue. It seems like there is still an issue with the CPU FFT. It's more subtle, but after calling  several times the error becomes apparent. Take a look at the following script.
I updated &lt;denchmark-link:https://github.com/rassibassi/fftTensorflow&gt;https://github.com/rassibassi/fftTensorflow&lt;/denchmark-link&gt;
 with the new script in :
import tensorflow as tf
import scipy.io
import numpy as np

print('tf',tf.__version__)
print('scipy',scipy.__version__)
print('numpy',np.__version__)

def error(matlab,tf):
    error = np.mean(np.square(np.abs(matlab-np.array(tf))))
    return error
def relError(matlab,tf):
    error = np.mean(np.square(np.abs(matlab-np.array(tf)))/np.square(np.abs(matlab)))
    return error
def tf_i_fft(var,i=1):
    for _ in range(i):
        var = tf.ifft(tf.fft(var))
    return var
def np_i_fft(var,i=1):
    for _ in range(i):
        var = np.fft.ifft(np.fft.fft(var))
    return var    

def runTF(signal):
    x = tf.placeholder(dtype=tf.complex64,shape=signal.shape)
    out1 = tf_i_fft(x,1)
    out20 = tf_i_fft(x,20)
    out200 = tf_i_fft(x,200)
    with tf.Session() as sess:
        o1,o20,o200 = sess.run([out1,out20,out200],feed_dict={x:signal})
        print("relError():")
        for x in [o1,o20,o200]:
            print(relError(signal, x))
        print("error():")
        for x in [o1,o20,o200]:
            print(error(signal, x))
        
def runNP(signal):
    print("relError():")
    for i in [1,20,200]:
        print(relError(signal, np_i_fft(signal,i)))
    print("error():")
    for i in [1,20,200]:
        print(relError(signal, np_i_fft(signal,i)))

signal = np.random.normal(size=2**14)+1j*np.random.normal(size=2**14)
print("TF error:")
runTF(signal)
print("NP error:")
runNP(signal)

signal = np.random.normal(size=2**16)+1j*np.random.normal(size=2**16)
print("TF error:")
runTF(signal)
print("NP error:")
runNP(signal)
Output CPU:
&lt;denchmark-code&gt;tf 1.4.0
scipy 0.19.1
numpy 1.13.1

TF error:
relError():
5.59392525962e-08
2.2448001263e-05
0.00232261390227
error():
2.67353836243e-08
1.07318864944e-05
0.00110999929123
NP error:
relError():
3.1608419451e-30
4.11521670168e-28
3.64023186949e-26
error():
3.1608419451e-30
4.11521670168e-28
3.64023186949e-26

TF error:
relError():
1.07720386138e-06
0.000440561647239
0.0554315680362
error():
6.64006775289e-07
0.000269907188294
0.0315664672648
NP error:
relError():
6.42319902792e-30
7.48332641966e-28
4.85939408462e-26
error():
6.42319902792e-30
7.48332641966e-28
4.85939408462e-26
&lt;/denchmark-code&gt;

Output GPU:
&lt;denchmark-code&gt;tf 1.4.0
scipy 0.19.1
numpy 1.13.1

TF error:
relError():
2.51723807688e-11
2.20787161855e-09
1.39922980127e-07
error():
1.26221058554e-13
2.72995514739e-11
2.5727280163e-09
NP error:
relError():
4.08902237726e-29
6.82474569015e-27
8.05050948207e-25
error():
4.08902237726e-29
6.82474569015e-27
8.05050948207e-25

TF error:
relError():
1.00672471898e-11
1.62742361807e-10
2.14752586388e-08
error():
1.2714050306e-13
2.48766311645e-11
2.29909628833e-09
NP error:
relError():
9.99902717965e-29
1.10272520665e-26
2.09878555167e-24
error():
9.99902717965e-29
1.10272520665e-26
2.09878555167e-24
&lt;/denchmark-code&gt;

		</comment>
		<comment id='17' author='Sushobhan04' date='2018-02-14T13:23:24Z'>
		Nagging Awaiting Response: It has been 14 days with no activityand the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='18' author='Sushobhan04' date='2018-03-03T07:57:54Z'>
		Nagging Awaiting Response: It has been 14 days with no activityand the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='19' author='Sushobhan04' date='2018-03-17T15:00:04Z'>
		Nagging Awaiting Response: It has been 14 days with no activityand the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='20' author='Sushobhan04' date='2018-04-01T12:32:13Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='21' author='Sushobhan04' date='2018-04-10T19:09:22Z'>
		&lt;denchmark-link:https://github.com/Rassibassi&gt;@Rassibassi&lt;/denchmark-link&gt;
, I'm working on adding complex128 support to the FFT ops, and I ran your code snippet on CPU with the new complex128 support. It looks like a good bit of the difference comes down to floating point precision, but there is still a difference in magnitude of error between our Eigen CPU kernels and NumPy's FFTPACK-based implementation:
&lt;denchmark-code&gt;('tf', '1.7.0-rc1')
('scipy', '1.0.0')
('numpy', '1.13.3')

TF complex64 error:
relError():
5.69994795505e-08
2.28822314134e-05
0.00236386710254
error():
2.67673230982e-08
1.07452364853e-05
0.00111161453476

TF complex128 error:
relError():
2.03202621417e-25
8.12885273597e-23
8.1293612227e-21
error():
8.45195242854e-26
3.3806405275e-23
3.38062769196e-21

NP error:
relError():
1.46110214039e-30
2.56749381389e-28
2.15249955484e-26
error():
1.46110214039e-30
2.56749381389e-28
2.15249955484e-26

TF complex64 error:
relError():
2.80140031472e-06
0.00114172830632
0.137244893593
error():
6.57350034283e-07
0.000267167590172
0.0312076844667

TF complex128 error:
relError():
5.34248829151e-24
2.136542245e-21
2.1367747769e-19
error():
7.49076129451e-25
2.9962948344e-22
2.99628924207e-20

NP error:
relError():
1.32333991018e-29
4.18679573526e-27
3.71090920591e-25
error():
1.32333991018e-29
4.18679573526e-27
3.71090920591e-25
&lt;/denchmark-code&gt;

		</comment>
		<comment id='22' author='Sushobhan04' date='2018-04-10T19:41:07Z'>
		&lt;denchmark-link:https://github.com/sirgogo&gt;@sirgogo&lt;/denchmark-link&gt;
, running your code snippet using complex128 FFTs the error is . Under complex64 the error is .
		</comment>
		<comment id='23' author='Sushobhan04' date='2018-04-10T22:24:57Z'>
		&lt;denchmark-link:https://github.com/rryan&gt;@rryan&lt;/denchmark-link&gt;
 Thanks, this sounds promising.
One thing I was wondering (perhaps unrelated to this issue), is some of us are seeing different results on TF-CPU vs TF-GPU computation, even for networks with only simple operations like Add, Multiply, MatMul, reduce_sum, reduce_max, etc. I need to come up with a good set of tests to expose this, but do you have any insight on why this might be the case?
		</comment>
		<comment id='24' author='Sushobhan04' date='2018-04-10T23:19:33Z'>
		Different results make sense, since the computation is being run by different hardware implementations of IEEE-754. Also, the implementation of reductions across CPU and GPU can be quite different. I've heard that Eigen on CPU can produce non-deterministic results when computing e.g. reductions using a thread pool.
One way to eliminate Eigen CPU non-determinism as a factor in testing is to set &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L273&gt;intra_op_parallelism_threads&lt;/denchmark-link&gt;
 to 1 in your ConfigProto.
Differences can also arise from software bugs though, so please do file issues, ideally with reproducible test cases, for places where you think the difference might be a bug.
		</comment>
		<comment id='25' author='Sushobhan04' date='2018-04-15T10:18:14Z'>
		&lt;denchmark-link:https://github.com/rryan&gt;@rryan&lt;/denchmark-link&gt;
 Thanks! Looking forward to complex128 FFT functionality! :)
what about running the examples with complex128 on a GPU?
		</comment>
		<comment id='26' author='Sushobhan04' date='2018-04-24T20:07:38Z'>
		&lt;denchmark-link:https://github.com/Sushobhan04&gt;@Sushobhan04&lt;/denchmark-link&gt;
 Hi!
According to the second that you have made, you used fftshift in tensorflow. Am I right?
Can you, please, share tensorflow implementation of fftshift?
		</comment>
		<comment id='27' author='Sushobhan04' date='2018-05-04T21:12:38Z'>
		I added complex128 FFT support for CPU and GPU in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/8f0a90b711480c12716d1a3b1094cc8b34939f2d&gt;8f0a90b&lt;/denchmark-link&gt;
. It'll be part of TensorFlow 1.9.
RFFT/IRFFT support is on the way but a little more complicated, so I split it into a separate commit.
		</comment>
		<comment id='28' author='Sushobhan04' date='2018-05-27T03:05:39Z'>
		It has been 21 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='29' author='Sushobhan04' date='2018-06-10T18:38:15Z'>
		It has been 36 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='30' author='Sushobhan04' date='2018-06-25T19:04:47Z'>
		We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!
		</comment>
		<comment id='31' author='Sushobhan04' date='2018-09-17T12:20:52Z'>
		hello, how to use tf.fft3d on rgb image, can you make a example? thank you very much.
		</comment>
		<comment id='32' author='Sushobhan04' date='2019-04-26T17:45:21Z'>
		I am finding the 2dfft produces nonsensical results on complex data.  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/28192&gt;#28192&lt;/denchmark-link&gt;

		</comment>
		<comment id='33' author='Sushobhan04' date='2019-04-28T03:47:56Z'>
		&lt;denchmark-link:https://github.com/isaacgerg&gt;@isaacgerg&lt;/denchmark-link&gt;
, commented on your issue. It looks like you were feeding a , tensor to , so your FFT was over  instead of  as you intended.
		</comment>
		<comment id='34' author='Sushobhan04' date='2019-05-17T17:47:43Z'>
		&lt;denchmark-link:https://github.com/rryan&gt;@rryan&lt;/denchmark-link&gt;
 Is the equivalent fix (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/8f0a90b711480c12716d1a3b1094cc8b34939f2d&gt;8f0a90b&lt;/denchmark-link&gt;
)  for RFFT in the works? Until then I'm just truncating the output of the complex FFT but would be nice to have.
		</comment>
		<comment id='35' author='Sushobhan04' date='2019-09-13T17:34:26Z'>
		&lt;denchmark-link:https://github.com/PCerles&gt;@PCerles&lt;/denchmark-link&gt;
 RFFT complex128 support has been merged now. Sorry for the long delay! &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/4a3cbea5f3d1f79eb2ff6bb2c64875e951ca3ce2&gt;4a3cbea&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>