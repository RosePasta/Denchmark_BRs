<bug id='34299' author='huanyingjun' open_date='2019-11-15T03:02:21Z' closed_time='2019-11-17T19:03:10Z'>
	<summary>How to use Per-channel quantize in TFLiteï¼Ÿ</summary>
	<description>
Hello
from the tflite conv.cc , I can see that now tflite supports Per-channel quantize , is there any guide or doc how to use per-channel quantize when convert tf model to tflite?
	</description>
	<comments>
		<comment id='1' author='huanyingjun' date='2019-11-16T20:56:42Z'>
		hi,
&lt;denchmark-link:https://github.com/KhronosGroup/NNEF-Tools/issues/40&gt;KhronosGroup/NNEF-Tools#40&lt;/denchmark-link&gt;

&lt;denchmark-link:https://www.tensorflow.org/lite/performance/post_training_quantization&gt;https://www.tensorflow.org/lite/performance/post_training_quantization&lt;/denchmark-link&gt;

CHECK THESE LINKS UPDATE ME
		</comment>
		<comment id='2' author='huanyingjun' date='2019-11-17T19:03:10Z'>
		When you use post-training integer quantization, per-channel quantization is enabled by default. Please follow instructions here:
&lt;denchmark-link:https://medium.com/tensorflow/tensorflow-model-optimization-toolkit-post-training-integer-quantization-b4964a1ea9ba&gt;https://medium.com/tensorflow/tensorflow-model-optimization-toolkit-post-training-integer-quantization-b4964a1ea9ba&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='huanyingjun' date='2020-03-31T10:27:30Z'>
		&lt;denchmark-link:https://github.com/liyunlu0618&gt;@liyunlu0618&lt;/denchmark-link&gt;
 Do you know how to specify for using per-layer quantization instead in tflite?  I searched in many tutorials and documents, no luck however.
		</comment>
		<comment id='4' author='huanyingjun' date='2020-03-31T16:30:20Z'>
		Currently if you use post-training integer quantization it's per-channel by default. There's no way to configure that to use per-layer quant. The legacy quantization-aware training (QAT) used per-layer quantization but we're deprecating that. The upcoming QAT will also use per-channel.
		</comment>
		<comment id='5' author='huanyingjun' date='2020-06-26T20:45:59Z'>
		Hey &lt;denchmark-link:https://github.com/liyunlu0618&gt;@liyunlu0618&lt;/denchmark-link&gt;
  , sorry to bring up this issue again (since been closed for a while), but I"m just looking for some answer and hopefully you can provide me some. To my understanding, right now TF QAT for Conv2D is still supporting per-axis quantization, I'm wondering if we can pass in some custom configuration for quantizing to make it per-tensor quantization instead? If it's possible, I'm wondering if you can provide me some examples/ resources to do so.
		</comment>
		<comment id='6' author='huanyingjun' date='2020-08-07T11:32:13Z'>
		Hello guys,
I'm facing a similar issue of not-having per-layer quantization available - is it somehow enforce this feature (per-layer-quantization)?
As &lt;denchmark-link:https://github.com/liyunlu0618&gt;@liyunlu0618&lt;/denchmark-link&gt;
 mentioned this feature ((per-layer-quantization)) will be removed but is it somehow possible to have this feature - if so, how?
Thank you.
Peter
		</comment>
	</comments>
</bug>