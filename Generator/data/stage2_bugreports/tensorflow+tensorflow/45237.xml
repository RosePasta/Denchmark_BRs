<bug id='45237' author='kafan1986' open_date='2020-11-28T00:05:37Z' closed_time='2020-12-17T13:20:19Z'>
	<summary>Enabling XNNPACK changes the output.</summary>
	<description>
System information

OS Platform and Distribution: Android
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: All android
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): v2.3
Python version: N/A
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
Running a computer vision model for emotion detection. The output is as expected when XNN is disabled but if I enable tfliteOptions.setUseXNNPACK(true) then the output is incorrect and totally different.
Describe the expected behavior
Output should be same for both XNN enabled and non-XNN option.
I have attached inference class files and model files below.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/5609851/Archive.zip&gt;ClassFiles.zip&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/5609852/emotion_fp16t.tflite.zip&gt;emotion_fp16t.tflite.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='kafan1986' date='2020-11-30T12:46:20Z'>
		Having the same issue with XNNPACK. If running delegate with XNNPACK the result is totally different from the disabled one. (TF2 version 2.3.1)
		</comment>
		<comment id='2' author='kafan1986' date='2020-12-06T09:49:23Z'>
		&lt;denchmark-link:https://github.com/Maratyszcza&gt;@Maratyszcza&lt;/denchmark-link&gt;
 could you take a look at this issue?
		</comment>
		<comment id='3' author='kafan1986' date='2020-12-06T10:30:28Z'>
		&lt;denchmark-link:https://github.com/kafan1986&gt;@kafan1986&lt;/denchmark-link&gt;
 Does it reproduce if you build TFLite from the master branch? There was a bug with asymetric padding a while ago that was fixed in &lt;denchmark-link:https://github.com/google/XNNPACK/commit/facecc526bf35d09ac3319f44072d640101b2b70&gt;google/XNNPACK@facecc5&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='kafan1986' date='2020-12-06T12:00:41Z'>
		&lt;denchmark-link:https://github.com/Maratyszcza&gt;@Maratyszcza&lt;/denchmark-link&gt;
 I have tested with 0.0.0-nightly build of tflite and the output is same for both version. But the performance seems to be remain same for both with XNN module true and false, whereas earlier the XNN true would significantly run the inference faster although the output was wrong.
		</comment>
		<comment id='5' author='kafan1986' date='2020-12-06T13:54:41Z'>
		AFAIK the nightly build of TFLite enables XNNPACK by default (&lt;denchmark-link:https://github.com/multiverse-tf&gt;@multiverse-tf&lt;/denchmark-link&gt;
 to confirm), that is why you don't see any difference from explicitly enabling it. I checked that your model does get fully delegated to XNNPACK.
		</comment>
		<comment id='6' author='kafan1986' date='2020-12-06T15:25:40Z'>
		&lt;denchmark-link:https://github.com/Maratyszcza&gt;@Maratyszcza&lt;/denchmark-link&gt;
 But I was explicitly disabling the XNNPACK by passing false to setXNNPACK.
		</comment>
		<comment id='7' author='kafan1986' date='2020-12-07T10:58:49Z'>
		It is possible that this is not sufficient to disable XNNPACK. You may profile the binary, and if it spends much time in xnn_* functions, XNNPACK is being used.
		</comment>
		<comment id='8' author='kafan1986' date='2020-12-17T13:20:19Z'>
		Works OK with tensorflow lite 2.4.0
		</comment>
		<comment id='9' author='kafan1986' date='2020-12-17T13:20:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45237&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45237&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>