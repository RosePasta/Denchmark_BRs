<bug id='27255' author='botev' open_date='2019-03-28T17:20:40Z' closed_time='2019-04-08T20:04:20Z'>
	<summary>Issues with @tf.function and abstracted classes</summary>
	<description>
System information

Have I written custom code: YES
OS Platform and Distribution: Ubuntu 18.04
Mobile device: NO
TensorFlow installed from (source or binary): PyPI
TensorFlow version (use command below): 2.0.0-alpha0
Python version: 3.6.4
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: NA
GPU model and memory: NA

Describe the current behavior
When using @tf.function on a function that involves abstract classes (e.g. for instance layers or other NN abstractions) Tensorflow fails with the error:
&lt;denchmark-code&gt;2019-03-28 19:44:23.869165: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-28 19:44:23.901972: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2693750000 Hz
2019-03-28 19:44:23.902265: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x555bfd2f8e40 executing computations on platform Host. Devices:
2019-03-28 19:44:23.902288: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
Traceback (most recent call last):
  File "/home/alex/work/python/simple-kf/tf_git/example.py", line 87, in &lt;module&gt;
    main()
  File "/home/alex/work/python/simple-kf/tf_git/example.py", line 81, in main
    loss = train_one_step(params, data)
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 426, in __call__
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 370, in _initialize
    *args, **kwds))
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1313, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1580, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1512, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 694, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 317, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 686, in wrapper
    ), args, kwargs)
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 392, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/tmp/tmpc8qghhfj.py", line 6, in tf__train_one_step
    logits, extra = ag__.converted_call(model, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (variables, batch), {'return_inputs': False, 'return_outputs': False})
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 392, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/tmp/tmp2wyz0_pd.py", line 5, in tf____call__
    result, extra = ag__.converted_call('__call__', super(ParametricFunction, self), ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (params, inputs), dict(kwargs, **{'return_inputs': return_inputs, 'return_outputs': return_outputs}))
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 392, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/tmp/tmpn16v62zu.py", line 6, in tf____call__
    retval_ = ag__.converted_call('call', self, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_2, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (params, inputs), dict(kwargs, **{'return_inputs': return_inputs, 'return_outputs': return_outputs}))
  File "/opt/miniconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 392, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/tmp/tmp43quxi5v.py", line 3, in tf__call
    raise ag__.converted_call(NotImplementedError, None, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(tf.function, defun, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_1, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_2, ag__.convert, ag__.do_not_convert, ag__.converted_call, defun_3, ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), ('call not implemented for {}.'.format(self.__dict__),), {})
NotImplementedError: call not implemented for {'_name': None, 'initializers': None, 'out_dim': 784}.
&lt;/denchmark-code&gt;

Describe the expected behaviour
To work as though if it was run without @tf.function (e.g. in Eager Mode).
Code to reproduce the issue
&lt;denchmark-code&gt;from abc import abstractmethod
import tensorflow as tf
import logging


class Function(object):
    def __init__(self, name=None):
        self._name = name

    def call(self, params, inputs, **kwargs):
        raise NotImplementedError("call not implemented for {}.".format(self.__dict__))

    def __call__(self, params, inputs, return_inputs=False, return_outputs=False, **kwargs):
        return self.call(params, inputs,
                         return_inputs=return_inputs,
                         return_outputs=return_outputs,
                         **kwargs)


def expand_bias_to(bias, shape):
    return tf.reshape(bias, [1] * (len(shape) - len(bias.shape)) + bias.shape.as_list())


def call_or_get(maybe_callable, *args, **kwargs):
    if callable(maybe_callable):
        return maybe_callable(*args, **kwargs)
    else:
        return maybe_callable


class ParametricFunction(Function):
    def __init__(self, initializers, name=None):
        super(ParametricFunction, self).__init__(name=name)
        self.initializers = initializers

    def __call__(self, params, inputs, return_inputs=False, return_outputs=False, **kwargs):
        result, extra = super(ParametricFunction, self). \
            __call__(params, inputs,
                     return_inputs=return_inputs,
                     return_outputs=return_outputs,
                     **kwargs)
        return result, extra

    @abstractmethod
    def call(self, params, inputs, **kwargs):
        raise NotImplementedError()


class Affine(ParametricFunction):
    def __init__(self, out_dim,
                 name=None):
        super(Affine, self).__init__(initializers=None, name=name)
        self.out_dim = out_dim

    def call(self, params, inputs, **kwargs):
        if len(params) == 2:
            w, b = params
            b = expand_bias_to(b, inputs.shape)
        else:
            w, b = params[0], 0
        return tf.matmul(inputs, w) + b, None


# !!! IF THIS IS COMMENTED OUT IT WORKS !!!
@tf.function
def train_one_step(variables, batch):
    model = Affine(784)
    logits, extra = model(variables, batch, return_inputs=False, return_outputs=False)
    loss_value = tf.reduce_mean(logits ** 2)
    return loss_value


def main():
    batch_size = 100
    tf.get_logger().setLevel(logging.WARNING)
    params = (tf.Variable(initial_value=tf.random.normal([784, 784]), name="W"),
              tf.Variable(initial_value=tf.zeros([784]), name="b"))
    data = tf.random.normal([batch_size, 784])

    for epoch in range(10):
        loss = train_one_step(params, data)
        epoch += 1
        print("Epoch {}, loss: {:0.3f}".format(epoch, loss))


if __name__ == '__main__':
    main()
&lt;/denchmark-code&gt;

Other info / logs
This seems to stem somehow from the inheritance of abstract methods.
	</description>
	<comments>
		<comment id='1' author='botev' date='2019-03-28T22:55:32Z'>
		It seems that the error stems from the using calls of the type:
&lt;denchmark-code&gt;def method(self, ...):
    super(Class, self).method()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='botev' date='2019-04-08T18:38:53Z'>
		I can confirm that error trace with TF2.0.0-alpha0. When I ran with tf-nightly, the error is as follows.
TypeError                                 Traceback (most recent call last)
 in ()
84
85 if name == 'main':
---&gt; 86     main()
 in main()
80         loss = train_one_step(params, data)
81         epoch += 1
---&gt; 82         print("Epoch {}, loss: {:0.3f}".format(epoch, loss))
83
84
TypeError: unsupported format string passed to Tensor.format
		</comment>
		<comment id='3' author='botev' date='2019-04-08T20:04:20Z'>
		I just ran this in a colab with version 2.0.0-dev20190405 and it runs without an error, so I think this has been fixed.
		</comment>
		<comment id='4' author='botev' date='2019-04-08T20:04:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27255&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27255&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>