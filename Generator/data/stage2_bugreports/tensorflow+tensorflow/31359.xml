<bug id='31359' author='jiarenyf' open_date='2019-08-06T07:48:20Z' closed_time='2019-08-30T01:42:24Z'>
	<summary>tflite output different result with pbfile when using only one convolutional layer ?</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): In a Ubuntu18.04 docker container.
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip install tensorflow==1.14
TensorFlow version (use command below): tf-cpu==1.14.0
Python version: python3.6.8
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: No.
GPU model and memory: No.

Describe the current behavior
tflite output different result with pbfile when using only one convolutional layer ?
Describe the expected behavior
tflite should output the same result with pbfile when using only one convolutional layer.
Code to reproduce the issue
&lt;denchmark-code&gt;import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import warnings
warnings.filterwarnings(action='ignore', category=FutureWarning)

######################################################################

import numpy as np
import tensorflow as tf
from tensorflow.python.tools.freeze_graph import freeze_graph

CONFIG = tf.compat.v1.ConfigProto()
CONFIG.gpu_options.allow_growth = True

######################################################################

inputs_debug = ["inpT"]
outputs_debug = ["outT"]
shape_debug = (1, 32, 240, 1)
dtype_debug = np.float32
pbPath_debug = './debug/fuck.pb'
litePath_debug = './debug/fuck.lite'
checkpoint_debug = './debug/fuck.ckpt'

######################################################################

def convert(pbPath, litePath, inputs, outputs):
    from_frozen_graph = tf.lite.TFLiteConverter.from_frozen_graph
    converter = from_frozen_graph(pbPath, inputs, outputs)

    tflite_model = converter.convert()
    open(litePath, "wb").write(tflite_model)

######################################################################

def generate_data(shape, dtype=np.float32):
    data = np.array(np.random.randint(0, 255, shape), dtype=dtype)
    if dtype == np.float32: data = (data - 127.0) / 128.0

    return [data]

######################################################################

def get_tf_engine(pbPath, inpNs, outNs):
    inpNs = [inpN + ":0" for inpN in inpNs]
    outNs = [outN + ":0" for outN in outNs]

    graph = tf.compat.v1.Graph()
    with graph.as_default():
        f = tf.io.gfile.GFile(pbPath, "rb")
        graphDef = tf.compat.v1.GraphDef()
        graphDef.ParseFromString(f.read())

        Ts = tf.import_graph_def(
            graphDef, name='',
            return_elements=inpNs + outNs,
        )
        inpT, outT = Ts[:len(inpNs)], Ts[len(inpNs):]
        session = tf.compat.v1.Session(config=CONFIG)

    def get_tf_target(data):
        return session.run(
            outT,
            {iT: d for (iT, d) in zip(inpT, data)}
        )

    return get_tf_target

######################################################################

def get_lite_engine(litePath):
    interpreter = tf.lite.Interpreter(litePath)
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    outputs_details = interpreter.get_output_details()

    def get_lite_output(data):
        for (input_detail, d) in zip(input_details, data):
            interpreter.set_tensor(input_detail['index'], d)
        interpreter.invoke()

        return [
            interpreter.get_tensor(outputs_detail['index'])
            for outputs_detail in outputs_details
        ]

    return get_lite_output

######################################################################

if __name__ == '__main__':
    if not os.path.exists(checkpoint_debug+".meta"):
        with tf.compat.v1.Graph().as_default():
            inpT = tf.compat.v1.placeholder(
                dtype_debug, shape_debug, inputs_debug[0])

            x = inpT
            x = tf.layers.conv2d(x, 64, (3,3), (1,1), 'same', dilation_rate=(1,1))

            outT = tf.identity(x, outputs_debug[0])

            saver = tf.compat.v1.train.Saver()
            with tf.compat.v1.Session(config=CONFIG) as session:
                session.run(tf.compat.v1.global_variables_initializer())

                saver.save(session, checkpoint_debug)

    if not os.path.exists(pbPath_debug):
        freeze_graph(
            input_graph=None,
            input_saver=None,
            input_binary=True,
            input_checkpoint=checkpoint_debug,
            output_node_names=','.join(outputs_debug),
            restore_op_name=None,
            filename_tensor_name=None,
            output_graph=pbPath_debug,
            clear_devices=True,
            initializer_nodes=None,
            variable_names_whitelist="",
            variable_names_blacklist="",
            input_meta_graph=checkpoint_debug+".meta",
            input_saved_model_dir=None,
        )

    if not os.path.exists(litePath_debug):
        convert(pbPath_debug, litePath_debug, inputs_debug, outputs_debug)

    get_tf_target = get_tf_engine(
        pbPath_debug, inputs_debug, outputs_debug)
    get_lite_output = get_lite_engine(litePath_debug)

    for i in range(10):
        data = generate_data(shape_debug, dtype_debug)

        targets = get_tf_target(data)
        outputs = get_lite_output(data)

        for (target, output) in zip(targets, outputs):
            print(target.shape, output.shape, end='\t')
            print(np.allclose(target, output, 1e-5, 1e-8), end='\n')

&lt;/denchmark-code&gt;

I use the code above to generate a pb file with only one convolutional layer, and convert it to a tflite file. And the output of the pb and tflite files are different as following. I wonder why ?
&lt;denchmark-code&gt;INFO: Initialized TensorFlow Lite runtime.
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False
(1, 32, 240, 64) (1, 32, 240, 64)       False

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='jiarenyf' date='2019-08-06T08:00:19Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;

Do you know what's the problem, thank you ?
		</comment>
		<comment id='2' author='jiarenyf' date='2019-08-06T08:59:10Z'>
		I found that when installing tensorflow using 'pip install tensorflow==1.14.0', the problem occurs; when installing by building from source and 'pip install tensorflow-1.14.1-cp36-cp36m-linux_x86_64.whl', the problem disappear.
I wonder this is a problem in tf==1.14.0 and has been fixed in tf==1.14.1 ?
		</comment>
		<comment id='3' author='jiarenyf' date='2019-08-06T09:15:03Z'>
		I found another question:
Adding one layer to the network makes the result different between pb file and lite file...
&lt;denchmark-code&gt;x = tf.layers.conv2d(x, 64, (3,3), (1,1), 'same', dilation_rate=(1,1))
x = tf.layers.conv2d(x, 64, (3,3), (1,1), 'same', dilation_rate=(1,1)) # Adding one convolutional layer.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='jiarenyf' date='2019-08-07T01:16:56Z'>
		&lt;denchmark-link:https://github.com/tensorflowbutler&gt;@tensorflowbutler&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='jiarenyf' date='2019-08-08T02:36:20Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 I found that using , the output of tensorflow with  is the same with the output of tflite using the .lite file converted from .pb file.
However, tensorflow==1.14.0 and tensorflow==1.14.1 both output wrong results.
And, in tensorflow==1.13.2, the output of .pb file is not the same as that of .lite file when using dilation, no matter whether the w and h is the same in the dilation rate.
		</comment>
		<comment id='6' author='jiarenyf' date='2019-08-09T01:39:51Z'>
		The diff is loss in accuracy. For example it is passing with
print(np.allclose(target, output, 1e-5, 1e-7))
Will look when this small diff started showing.
		</comment>
		<comment id='7' author='jiarenyf' date='2019-08-09T02:10:22Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 I wonder why converting from  to  would introduce loss in accuracy ?
And I found the loss is small in the first several layers, but is huge in the last several layers, and causing the model with tflie output wrong result !
I think that converting pb to tflite both with float32 data type should not introduce error or loss in accuracy.
		</comment>
		<comment id='8' author='jiarenyf' date='2019-08-21T15:57:35Z'>
		&lt;denchmark-link:https://github.com/jiarenyf&gt;@jiarenyf&lt;/denchmark-link&gt;
 This might be an error in the C++ code.
		</comment>
		<comment id='9' author='jiarenyf' date='2019-08-30T01:42:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31359&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31359&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>