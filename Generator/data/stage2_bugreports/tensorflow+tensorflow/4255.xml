<bug id='4255' author='clo-dan' open_date='2016-09-07T17:54:34Z' closed_time='2017-03-09T18:22:44Z'>
	<summary>iOS memory warnings</summary>
	<description>
I tried posting this to SO first and it's been there a week with no activity: &lt;denchmark-link:https://stackoverflow.com/questions/39255211/tensorflow-ios-memory-warnings&gt;https://stackoverflow.com/questions/39255211/tensorflow-ios-memory-warnings&lt;/denchmark-link&gt;

We are building an iOS app to perform image classification using the TensorFlow library.
Using our machine learning model (91MB, 400 classes) and the TensorFlow 'simple' example, we get memory warnings on any iOS device with 1GB of RAM. 2GB models do not experience any warnings, while &lt; 1GB models completely run out of memory and crash the app.
We are using the latest TensorFlow code from the master branch that includes &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/459c2fed498530b794c4871892fd68d1e6834ac6&gt;this iOS memory performance commit&lt;/denchmark-link&gt;
, which we thought might help but didn't.
We have also tried setting various GPU options on our TF session object, including set_allow_growth(true) and set_per_process_gpu_memory_fraction().
Our only changes to the TF 'simple' example code is a wanted_width and wanted_height of 299, and an input_mean and input_std of 128.
Any thoughts? Is our model simply too big?
	</description>
	<comments>
		<comment id='1' author='clo-dan' date='2016-09-08T06:28:44Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 might have some ideas.
		</comment>
		<comment id='2' author='clo-dan' date='2016-09-08T16:00:16Z'>
		I am working on an approach that uses memory mapping to avoid this problem. It works by mmap-ing the weight parameters of large files into read-only pages that don't count towards the memory limits on iOS. You can see the work-in-progress here:
&lt;denchmark-link:https://github.com/petewarden/tensorflow/blob/master/tensorflow/contrib/ios_examples/camera/tensorflow_utils.mm#L162&gt;https://github.com/petewarden/tensorflow/blob/master/tensorflow/contrib/ios_examples/camera/tensorflow_utils.mm#L162&lt;/denchmark-link&gt;

I'll be finishing this off and writing proper documentation, but for now take a look at how we use that function, and here's how you create a memory-mappable file from the standard Inception v3 model:
&lt;denchmark-code&gt;bazel build tensorflow/contrib/util:convert_graphdef_memmapped_format &amp;&amp; \
bazel-bin/tensorflow/contrib/util/convert_graphdef_memmapped_format \
--in_graph=tensorflow/contrib/ios_examples/camera/data/tensorflow_inception_graph.pb \
--out_graph=tensorflow/contrib/ios_examples/camera/inception_mmap.pb
&lt;/denchmark-code&gt;

Does that help?
		</comment>
		<comment id='3' author='clo-dan' date='2016-09-08T16:42:09Z'>
		Yes, that seems like it should help us. Thanks Pete.
		</comment>
		<comment id='4' author='clo-dan' date='2016-09-29T20:05:22Z'>
		Just wanted to give an update on this. We mmapped our model as Pete showed above (FYI, this took quite awhile on a modern MacBook Pro) and implemented the changes from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/4457&gt;#4457&lt;/denchmark-link&gt;
 in our code.
Result is no more memory warnings on 1GB iOS devices plus a much faster classification (2-3 seconds, down from several). Still need to test a 512MB device but I think we'll be OK.
		</comment>
		<comment id='5' author='clo-dan' date='2017-01-12T11:00:43Z'>
		Just mmapped a quantized and unquantized graph, both resulting in a broken graph

8bit quantized graph says 0 nodes converted, and can't load resulting pb graph (error Out of range: Read less bytes than requested)
unquantized graph says 16 nodes converted but prints error Session was not created with a graph before Run() when calling Run()

		</comment>
		<comment id='6' author='clo-dan' date='2017-01-24T22:55:02Z'>
		&lt;denchmark-link:https://github.com/eaigner&gt;@eaigner&lt;/denchmark-link&gt;
 do you have info? The second problem looks like you just have to create a default session.
		</comment>
		<comment id='7' author='clo-dan' date='2017-01-25T07:30:57Z'>
		The code is the same that works with the unmapped graph. A Session is definitely created (just no valid one).
		</comment>
		<comment id='8' author='clo-dan' date='2017-01-25T20:15:21Z'>
		I see. Is this iOS only or does it fail on linux too? If so, do you have a simple repro script?
		</comment>
		<comment id='9' author='clo-dan' date='2017-03-09T18:22:44Z'>
		Closing due to lack of response.  Please reopen if necessary.
		</comment>
		<comment id='10' author='clo-dan' date='2017-05-24T16:04:09Z'>
		Follow-up question: is it possible to mmap a quantized graph? I've been trying and encountering the same issue that &lt;denchmark-link:https://github.com/eaigner&gt;@eaigner&lt;/denchmark-link&gt;
 was encountering above. Without quantization, my graph is huge but runs into memory issues on IOS. With quantization, it's small and I think it will work but I cannot mmap now.
		</comment>
	</comments>
</bug>