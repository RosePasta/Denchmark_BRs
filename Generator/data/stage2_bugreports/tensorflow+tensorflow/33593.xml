<bug id='33593' author='bj1123' open_date='2019-10-22T05:25:36Z' closed_time='2019-12-27T18:54:14Z'>
	<summary>distributed training with MirroredStrategy crashes when input shapes are variable</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip binary
TensorFlow version (use command below): tf2.0.0
Python version: 3.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: cuda 10.0 cudnn 7.6.4
GPU model and memory: rtx titan / 24gb

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
Tensorflow raise error (ValueError: When input_signature is provided, all inputs to the Python function must be convertible to tensors:) when checking input signature of a tf.function if input shape is variable in a distributed training environment. The training works without any error when I train it with single GPU or input with fixed shape, or I delete a path to cuda from my environment path.
Describe the expected behavior
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow.keras as keras
import random
import os
os.environ["CUDA_VISIBLE_DEVICES"]="2,3"
class Model(keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.emb = keras.layers.Embedding(51,100)
        self.layer = keras.layers.Dense(51)
    def call(self,x):
        x = self.emb(x)
        x = self.layer(x)
        return x
@tf.function(input_signature=(tf.TensorSpec(shape=[None, None], dtype=tf.int64),
                              tf.TensorSpec(shape=[None, None], dtype=tf.int64)))
def multi_gpu_step(x,y):
    def example_update_step(x, y):
        with tf.GradientTape() as tape:
            y_ = model(x)
            batch_loss = keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_, from_logits=True)`
            losses = batch_loss / strategy.num_replicas_in_sync
        step_grad = tape.gradient(losses, model.trainable_variables)
        optimizer.apply_gradients(zip(step_grad, model.trainable_variables))
        return tf.reduce_mean(batch_loss,1)
    example_loss = strategy.experimental_run_v2(
        example_update_step, args=(x, y))
    losses_sum = strategy.reduce(
        tf.distribute.ReduceOp.SUM, example_loss, axis=0)
    return losses_sum


strategy = tf.distribute.MirroredStrategy()

data = [[i for i in range(random.randint(10,50))] for j in range(400)]


def iterator():
    for i in range(len(data)):
        yield data[i], data[i]


with strategy.scope():
    model = Model()
    optimizer = keras.optimizers.Adam()

dataset = tf.data.Dataset.from_generator(iterator, output_types=(tf.int64, tf.int64))
batchfier = dataset.padded_batch(4, padded_shapes=([None], [None]))
batchfier = strategy.experimental_distribute_dataset(batchfier)

for x,y in batchfier:
    l = multi_gpu_step(x,y)
&lt;/denchmark-code&gt;

Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Other info / logs
&lt;denchmark-code&gt;2019-10-22 14:21:01.879166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-22 14:21:02.010621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:b2:00.0
2019-10-22 14:21:02.011936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:db:00.0
2019-10-22 14:21:02.012174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 14:21:02.013811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 14:21:02.015315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 14:21:02.015650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 14:21:02.017535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 14:21:02.019038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 14:21:02.023539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 14:21:02.028529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-10-22 14:21:02.028935: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-10-22 14:21:02.058997: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2019-10-22 14:21:02.062760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d0eb1f8ad0 executing computations on platform Host. Devices:
2019-10-22 14:21:02.062799: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-10-22 14:21:02.415212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d0eb25ba20 executing computations on platform CUDA. Devices:
2019-10-22 14:21:02.415251: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN RTX, Compute Capability 7.5
2019-10-22 14:21:02.415260: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN RTX, Compute Capability 7.5
2019-10-22 14:21:02.417153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:b2:00.0
2019-10-22 14:21:02.418575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:db:00.0
2019-10-22 14:21:02.418622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 14:21:02.418637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 14:21:02.418652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 14:21:02.418667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 14:21:02.418682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 14:21:02.418697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 14:21:02.418714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 14:21:02.424652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-10-22 14:21:02.424697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 14:21:02.428615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 14:21:02.428630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 
2019-10-22 14:21:02.428636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N 
2019-10-22 14:21:02.428641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N 
2019-10-22 14:21:02.432235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22846 MB memory) -&gt; physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:b2:00.0, compute capability: 7.5)
2019-10-22 14:21:02.434469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22846 MB memory) -&gt; physical GPU (device: 1, name: TITAN RTX, pci bus id: 0000:db:00.0, compute capability: 7.5)
2019-10-22 14:21:02.445038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:b2:00.0
2019-10-22 14:21:02.448745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: TITAN RTX major: 7 minor: 5 memoryClockRate(GHz): 1.77
pciBusID: 0000:db:00.0
2019-10-22 14:21:02.448816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 14:21:02.448856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 14:21:02.448907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 14:21:02.448953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 14:21:02.449004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 14:21:02.449045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 14:21:02.449095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-22 14:21:02.459964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2019-10-22 14:21:02.460089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 14:21:02.460116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 
2019-10-22 14:21:02.460136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N 
2019-10-22 14:21:02.460156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N 
2019-10-22 14:21:02.466303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 22846 MB memory) -&gt; physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:b2:00.0, compute capability: 7.5)
2019-10-22 14:21:02.468400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 22846 MB memory) -&gt; physical GPU (device: 1, name: TITAN RTX, pci bus id: 0000:db:00.0, compute capability: 7.5)
WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices
Traceback (most recent call last):
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1704, in _convert_inputs_to_signature
    value, dtype_hint=spec.dtype)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py", line 1184, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py", line 1242, in convert_to_tensor_v2
    as_ref=False)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py", line 1296, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py", line 286, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py", line 227, in constant
    allow_broadcast=True)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py", line 235, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py", line 96, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: Attempt to convert a value (PerReplica:{
  0 /job:localhost/replica:0/task:0/device:GPU:0: &lt;tf.Tensor: id=145, shape=(2, 49), dtype=int64, numpy=
array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0],
       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
        48]])&gt;,
  1 /job:localhost/replica:0/task:0/device:GPU:1: &lt;tf.Tensor: id=148, shape=(2, 27), dtype=int64, numpy=
array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
        16, 17, 18,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,
        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]])&gt;
}) with an unsupported type (&lt;class 'tensorflow.python.distribute.values.PerReplica'&gt;) to a Tensor.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/bj1123/pycharms/GPT2/multi_test_variable.py", line 54, in &lt;module&gt;
    l = multi_gpu_step(x,y)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 457, in __call__
    result = self._call(*args, **kwds)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1822, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2107, in _maybe_define_function
    *args, **kwargs)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1650, in canonicalize_function_inputs
    self._flat_input_signature)
  File "/home/bj1123/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1710, in _convert_inputs_to_signature
    format_error_message(inputs, input_signature))
ValueError: When input_signature is provided, all inputs to the Python function must be convertible to tensors:
  inputs: (
    PerReplica:{
  0 /job:localhost/replica:0/task:0/device:GPU:0: tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0]
 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
  48]], shape=(2, 49), dtype=int64),
  1 /job:localhost/replica:0/task:0/device:GPU:1: tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18  0  0  0  0  0
   0  0  0]
 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26]], shape=(2, 27), dtype=int64)
},
    PerReplica:{
  0 /job:localhost/replica:0/task:0/device:GPU:0: tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
   0]
 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
  48]], shape=(2, 49), dtype=int64),
  1 /job:localhost/replica:0/task:0/device:GPU:1: tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18  0  0  0  0  0
   0  0  0]
 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
  24 25 26]], shape=(2, 27), dtype=int64)
})
  input_signature: (
    TensorSpec(shape=(None, None), dtype=tf.int64, name=None),
    TensorSpec(shape=(None, None), dtype=tf.int64, name=None))

Process finished with exit code 1
&lt;/denchmark-code&gt;

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='bj1123' date='2019-10-22T05:28:54Z'>
		when I change inputs to be a fixed shape
with
strategy = tf.distribute.MirroredStrategy()
x = tf.random.uniform((800,50),maxval=50,dtype=tf.int64)
y = tf.random.uniform((800,50),maxval=50,dtype=tf.int64)
dataset = tf.data.Dataset.from_tensor_slices((x,y))
batchfier = dataset.batch(4)
it works perfectly
In addition, I tried setting experimental_relax_shapes to true, but it didn't work.
Not passing input_signature argument, which means just decorating codes only with @tf.function did not raise error, but it significantly slowed down the training speed.
		</comment>
		<comment id='2' author='bj1123' date='2019-12-27T18:54:14Z'>
		This issue has now been fixed and an example has been provided in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29911&gt;#29911&lt;/denchmark-link&gt;
 for how to use the element_spec property of distributed datasets/iterators to specify the input_signature. Please reopen this issue as needed. Thanks!
		</comment>
		<comment id='3' author='bj1123' date='2019-12-27T18:54:16Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33593&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33593&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>