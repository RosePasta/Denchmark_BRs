<bug id='31999' author='cadama' open_date='2019-08-27T08:02:17Z' closed_time='2019-08-29T14:09:20Z'>
	<summary>SparseTensor stopped working on tf.keras when moving from 2.0.0-beta1 to 2.0.0-rc0</summary>
	<description>
I just moved from 2.0.0-beta1 to 2.0.0-rc0 and some code for handling sparse categorical variable stopped working for me.
Here is some minimal code to reproduce the issue.
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

class SparseSlice(tf.keras.layers.Layer):
    def __init__(self, feature_column):
        super(SparseSlice, self).__init__()
        self.fc = feature_column

    def build(self, input_shape):

        self.kernel = self.add_weight('{}_kernel'.format(self.fc.name), shape=(self.fc.num_buckets, ), dtype=tf.float32)

    def call(self, input):
        ids = self.fc._transform_input_tensor(input)
        return tf.expand_dims(tf.gather(self.kernel, ids.values), axis=1)


batch_size = 10
c = 'smth'
col = tf.feature_column.categorical_column_with_hash_bucket(c, 10000, dtype=tf.int64)
example_spec = tf.feature_column.make_parse_example_spec([col])

inputs = tf.keras.layers.Input(name=c, shape=(None, ), batch_size=batch_size, sparse=True, dtype=tf.int64)
sparse_out = SparseSlice(col)(inputs)
output = tf.keras.layers.Dense(1, activation='sigmoid')(sparse_out)

model = tf.keras.Model(inputs, output)

model.compile(optimizer='adam',
              loss='mse')


features = {c: tf.sparse.SparseTensor(indices=[[i, 0] for i in range(batch_size)], values=np.random.randint(0, 1000, (batch_size, )).tolist(), dense_shape=(batch_size, 1))}
ys = tf.constant(np.random.rand(batch_size).tolist(), dtype=tf.float32)

dataset = tf.data.Dataset.from_tensor_slices((features, ys)).batch(batch_size)

model.fit(x=dataset,
          epochs=1
          )
&lt;/denchmark-code&gt;

on 2.0.0-rc0 I am getting the following error
&lt;denchmark-code&gt;ValueError: The two structures don't have the same nested structure.
First structure: type=SparseTensorSpec str=SparseTensorSpec(TensorShape([None, 1]), tf.int32)
Second structure: type=SparseTensor str=SparseTensor(indices=Tensor("smth/indices:0", shape=(None, 2), dtype=int64), values=Tensor("smth/values:0", shape=(None,), dtype=int64), dense_shape=Tensor("smth/shape:0", shape=(2,), dtype=int64))
More specifically: Incompatible CompositeTensor TypeSpecs: type=SparseTensorSpec str=SparseTensorSpec(TensorShape([None, 1]), tf.int32) vs. type=SparseTensorSpec str=SparseTensorSpec(TensorShape([None, None]), tf.int64)
Entire first structure:
.
Entire second structure:
.
&lt;/denchmark-code&gt;

Whereas everything runs fine in 2.0.0-beta1
	</description>
	<comments>
		<comment id='1' author='cadama' date='2019-08-27T09:09:59Z'>
		Was able to reproduce the issue. Please find the associated colab link for &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/6408be4542eb305927594dd16573af92/untitled108.ipynb&gt;2.0.0-beta1&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/4f25ab88488a7854065c145c46780512/untitled109.ipynb&gt;2.0.0-rc0&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='cadama' date='2019-08-28T01:55:01Z'>
		Hi all,
The code above is hitting a datatype check.
More specifically: Incompatible CompositeTensor TypeSpecs: type=SparseTensorSpec str=SparseTensorSpec(TensorShape([None, 1]), tf.int32) vs. type=SparseTensorSpec str=SparseTensorSpec(TensorShape([None, None]), tf.int64)
I took a look at your code above (thanks so much for the repro colab, &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
!) and it looks like calling .tolist() on your np.random.randint array is causing the data to be cast to int32; this causes the input SparseTensor type to be tf.int32, which is not compatible with your specified input type of tf.int64.
To fix this particular error, you can either remove .tolist(), or change your Input dtype to tf.int32.
I will work with the internal team to try and make the reported error clearer. I apologize for the inconvenience and confusion this has caused!
		</comment>
		<comment id='3' author='cadama' date='2019-08-29T10:00:47Z'>
		Thanks for your answer &lt;denchmark-link:https://github.com/markomernick&gt;@markomernick&lt;/denchmark-link&gt;
. It works. I am still struggling a bit with these types of errors here and there. For example let's say I want to predict with exactly the model outlined above.
if I simply run:
&lt;denchmark-code&gt;model.predict({c: np.random.randint(0, 1000, (batch_size, 1))})
&lt;/denchmark-code&gt;

I incur into
&lt;denchmark-code&gt;ValueError: The two structures don't have the same nested structure.
First structure: type=TensorSpec str=TensorSpec(shape=(10, 1), dtype=tf.int64, name=None)
Second structure: type=SparseTensor str=SparseTensor(indices=Tensor("smth/indices_1:0", shape=(None, 2), dtype=int64), values=Tensor("smth/values_1:0", shape=(None,), dtype=int64), dense_shape=Tensor("smth/shape_1:0", shape=(2,), dtype=int64))
More specifically: Substructure "type=SparseTensor str=SparseTensor(indices=Tensor("smth/indices_1:0", shape=(None, 2), dtype=int64), values=Tensor("smth/values_1:0", shape=(None,), dtype=int64), dense_shape=Tensor("smth/shape_1:0", shape=(2,), dtype=int64))" is a sequence, while substructure "type=TensorSpec str=TensorSpec(shape=(10, 1), dtype=tf.int64, name=None)" is not
Entire first structure:
.
Entire second structure:
.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='cadama' date='2019-08-29T13:51:37Z'>
		Hi &lt;denchmark-link:https://github.com/cadama&gt;@cadama&lt;/denchmark-link&gt;
:
In that case, you're trying to pass a standard Tensor (First structure: type=TensorSpec str=TensorSpec(shape=(10, 1), dtype=tf.int64, name=None) into a Model that expects SparseTensors (Second structure: type=SparseTensor str=SparseTensor(indices=Tensor("smth/indices_1:0", shape=(None, 2), dtype=int64), values=Tensor("smth/values_1:0", shape=(None,), dtype=int64), dense_shape=Tensor("smth/shape_1:0", shape=(2,), dtype=int64))). This won't work, because the underlying Tensorflow for your model expects 3 placeholder tensors (for sparse indices, values, and shape). We can't sparsify your tensor automatically, either, since it's not clear what values to drop.
Again, I apologize for the lack of clarity in the error message - we're working on it.
		</comment>
		<comment id='5' author='cadama' date='2019-08-29T14:09:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31999&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31999&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>