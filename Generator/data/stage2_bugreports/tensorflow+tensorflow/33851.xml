<bug id='33851' author='zychen2016' open_date='2019-10-30T15:16:18Z' closed_time='2019-11-07T07:37:49Z'>
	<summary>TF lite Gpu delegate  E/libEGL: call to OpenGL ES API with no current context (logged once per thread)</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Fllow this document
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md
and using this project in android studio.
https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) : virtual device Pixel 2 in Android Studio
TensorFlow installed from (source or binary):java package
TensorFlow version (use command below):
org.tensorflow:tensorflow-lite:0.0.0-nightly
org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly
Python version:---
Bazel version (if compiling from source):---
GCC/Compiler version (if compiling from source):---
CUDA/cuDNN version:CUDA 10.0
GPU model and memory: gpu 1080

Describe the current behavior
My retrain ssd_mobilenet_v2 model with my  own datasets--called detect.tflite
Input shape
&lt;denchmark-code&gt;[{'name': 'normalized_input_image_tensor',
  'index': 308,
  'shape': array([  1, 300, 300,   3], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)}]

&lt;/denchmark-code&gt;

Output shape
&lt;denchmark-code&gt;[{'name': 'TFLite_Detection_PostProcess',
  'index': 300,
  'shape': array([ 1, 10,  4], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)},
 {'name': 'TFLite_Detection_PostProcess:1',
  'index': 301,
  'shape': array([ 1, 10], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)},
 {'name': 'TFLite_Detection_PostProcess:2',
  'index': 302,
  'shape': array([ 1, 10], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)},
 {'name': 'TFLite_Detection_PostProcess:3',
  'index': 303,
  'shape': array([1], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)}]

&lt;/denchmark-code&gt;

It could run object detect app using  https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection projects, Just modify path to tflite and labelmap.
However we want to Using Gpu delegate like  &lt;denchmark-link:https://www.tensorflow.org/lite/performance/gpu&gt;https://www.tensorflow.org/lite/performance/gpu&lt;/denchmark-link&gt;
.
so I just using mobile_ssd_v2_float_coco.tflite which download from &lt;denchmark-link:https://www.tensorflow.org/lite/performance/gpu&gt;https://www.tensorflow.org/lite/performance/gpu&lt;/denchmark-link&gt;
 .
&lt;denchmark-code&gt;input_details
[{'name': 'normalized_input_image_tensor',
  'index': 306,
  'shape': array([  1, 320, 320,   3], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)}]

output_details                                                                          

[{'name': 'raw_outputs/box_encodings',
  'index': 307,
  'shape': array([   1, 2034,    4], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)},
 {'name': 'raw_outputs/class_predictions',
  'index': 308,
  'shape': array([   1, 2034,   91], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0)}]

&lt;/denchmark-code&gt;

But report this error in Android Studio when using virtual devices pixel 2 to Debug.
&lt;denchmark-code&gt;E/libEGL: call to OpenGL ES API with no current context (logged once per thread)
E/AndroidRuntime: FATAL EXCEPTION: main
                  Process: org.tensorflow.lite.examples.detection, PID: 5063
                  java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: OpenCL library not loaded - dlopen failed: library "libOpenCL-pixel.so" not found
                  Falling back to OpenGL
                  TfLiteGpuDelegate Init: [GL_INVALID_ENUM]: An unacceptable value is specified for an enumerated argument.: glGetBufferParameteri64v in tensorflow/lite/delegates/gpu/gl/gl_buffer.cc:46
                  TfLiteGpuDelegate Prepare: delegate is not initialized
                  Node number 116 (TfLiteGpuDelegateV2) failed to prepare.

&lt;/denchmark-code&gt;

If I use my detect.tflite, error is
&lt;denchmark-code&gt;delegate:
                  CUSTOM TFLite_Detection_PostProcess: Operation is not supported.
                  First 114 operations will run on the GPU, and the remaining 1 on the CPU.
                  OpenCL library not loaded - dlopen failed: library "libOpenCL-pixel.so" not found
&lt;/denchmark-code&gt;

And I modify TFLiteObjectDetectionAPIModel.java to use Gpu Delegate:
&lt;denchmark-code&gt;  private ByteBuffer imgData;

  private Interpreter tfLite;
 + private static GpuDelegate delegate = new GpuDelegate();
 + private static  Interpreter.Options options = (new Interpreter.Options()).addDelegate(delegate);
  private TFLiteObjectDetectionAPIModel() {}

.....
.....
public static Classifier create(
...

+d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename),options);


&lt;/denchmark-code&gt;

Describe the expected behavior
1.Why the mobile_ssd_v2_float_coco.tflite input shape and output shape is different from the model  retrained using object detection api ?
2.The code  I modifyied  TFLiteObjectDetectionAPIModel.java to using Gpu delegate  is right?
	</description>
	<comments>
		<comment id='1' author='zychen2016' date='2019-11-04T23:12:17Z'>
		Hi,
I'm the assigned "tensorflower".  Sorry for the late response; I was out on a conference.

Unfortunately, I'm not familiar with the object detection API and cannot answer your first question.
It should be okay.  You can ignore the error messages CUSTOM ... is not supported. as it just a warning message.  It should be about the same for the OpenCL library not loaded... message as well.  It should fall back to OpenGL in that case.  In fact that's what the log in FATAL EXCEPTION... is describing.  Your program is probably failing because you are using a virtual device.  Emulators don't support compute shaders well, and can fail.  Can you check whether it fails on a real device?

		</comment>
		<comment id='2' author='zychen2016' date='2019-11-06T12:52:44Z'>
		
Hi,
I'm the assigned "tensorflower". Sorry for the late response; I was out on a conference.

Unfortunately, I'm not familiar with the object detection API and cannot answer your first question.
It should be okay.  You can ignore the error messages CUSTOM ... is not supported. as it just a warning message.  It should be about the same for the OpenCL library not loaded... message as well.  It should fall back to OpenGL in that case.  In fact that's what the log in FATAL EXCEPTION... is describing.  Your program is probably failing because you are using a virtual device.  Emulators don't support compute shaders well, and can fail.  Can you check whether it fails on a real device?


Thank you！On xiaomi 8 SE，Gpu delegate ~60ms!
But how to get tflite file Like mobile_ssd_v2_float_coco.tflite ？(mobile_ssd_v2_float_coco.tflite which download from &lt;denchmark-link:https://www.tensorflow.org/lite/performance/gpu&gt;https://www.tensorflow.org/lite/performance/gpu&lt;/denchmark-link&gt;
 .  &lt;denchmark-link:https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobile_ssd_v2_float_coco.tflite&gt;https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobile_ssd_v2_float_coco.tflite&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='3' author='zychen2016' date='2019-11-06T18:14:27Z'>
		Hm, I was not directly involved in creating that model file, so the correct answer would be "I don't know".  There are two possibilities:

Either the Python script was modified to match the dimensions,
Or the TOCO was invoked with the new input dimensions.

I don't think the person who prepared the TFLite file re-trained things with the 1st option.  I am guessing the 2nd option.
		</comment>
		<comment id='4' author='zychen2016' date='2019-11-07T07:37:38Z'>
		OK，Thank you very much!
		</comment>
		<comment id='5' author='zychen2016' date='2019-11-07T07:37:50Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33851&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33851&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='zychen2016' date='2020-06-13T23:57:02Z'>
		
OK，Thank you very much!

Hey, can you share that float model which you modified.
		</comment>
	</comments>
</bug>