<bug id='36424' author='jeisinge' open_date='2020-02-02T18:00:58Z' closed_time='2020-10-15T14:15:45Z'>
	<summary>TensorFlow Feature Columns Fail for Keras Model Functional API</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Databricks 6.3- Linux version 4.4.0-1100-aws (buildd@lgw01-amd64-030) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.12) ) #111-Ubuntu SMP Wed Dec 4 12:20:15 UTC 2019 (Ubuntu 4.4.0-1100.111-aws 4.4.203)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below):

&lt;denchmark-code&gt;2020-02-02 17:40:54.646833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-02-02 17:40:54.648818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
v2.1.0-rc2-17-ge5bf8de 2.1.0
&lt;/denchmark-code&gt;


Python version: 3.7.3
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source): GCC 7.3.0
CUDA/cuDNN version: 10.1
GPU model and memory: AWS p2.xlarge
Exact command to reproduce:

source_column = tf.feature_column.numeric_column("source_name")
categorical_column = tf.feature_column.bucketized_column(source_column, [0, 10, 100])
embedding_column = tf.feature_column.embedding_column(categorical_column, 7)
feature_columns = [ embedding_column ]

name_schema = tf.feature_column.make_parse_example_spec(feature_columns)
inputs = {
  name: keras.layers.Input(shape=schema.shape, name=name, dtype=schema.dtype)
  for name, schema in name_schema.items()
}

dense_features = keras.layers.DenseFeatures(feature_columns)
column_tensors = {}
dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;


Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I believe it should be possible to use Feature Columns with Keras Model Functional API.  Most feature columns work, however, it appears that some combinations of feature columns like the above embedding - bucketized - numeric columns fail.
It is not clear how to work around this error or apply the suggested wrapping.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;


Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

The above code fails with:
ValueError                                Traceback (most recent call last)
&lt;command-1166953&gt; in &lt;module&gt;
     12 dense_features = keras.layers.DenseFeatures(feature_columns)
     13 column_tensors = {}
---&gt; 14 dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    803               kwargs.pop('mask')
    804             inputs, outputs = self._set_connectivity_metadata_(
--&gt; 805                 inputs, outputs, args, kwargs)
    806           self._handle_activity_regularization(inputs, outputs)
    807           self._set_mask_metadata(inputs, outputs, input_masks)

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs)
   2012     # This updates the layer history of the output tensor(s).
   2013     self._add_inbound_node(
-&gt; 2014         input_tensors=inputs, output_tensors=outputs, arguments=arguments)
   2015     return inputs, outputs
   2016 

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _add_inbound_node(self, input_tensors, output_tensors, arguments)
   2042         input_tensors=input_tensors,
   2043         output_tensors=output_tensors,
-&gt; 2044         arguments=arguments)
   2045 
   2046     # Update tensor history metadata.

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/node.py in __init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)
    120       if base_layer_utils.needs_keras_history(
    121           tensor_argument, ignore_call_context=True):
--&gt; 122         base_layer_utils.create_keras_history(tensor_argument)
    123 
    124     # Add nodes to all layers involved.

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in create_keras_history(tensors)
    185     keras_tensors: The Tensors found that came from a Keras Layer.
    186   """
--&gt; 187   _, created_layers = _create_keras_history_helper(tensors, set(), [])
    188   return created_layers
    189 

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    221             'Sparse ops are not supported with functional models with built-in '
    222             'layer wrapping. Please wrap the sparse ops in a Lambda layer like'
--&gt; 223             ': \n{lambda_example}\n'.format(lambda_example=lambda_example))
    224 
    225       # Recursively set `_keras_history`.

ValueError: Sparse ops are not supported with functional models with built-in layer wrapping. Please wrap the sparse ops in a Lambda layer like: 

        weights_mult = lambda x: tf.sparse.sparse_dense_matmul(x, weights)
        output = tf.keras.layers.Lambda(weights_mult)(input)
	</description>
	<comments>
		<comment id='1' author='jeisinge' date='2020-02-02T21:37:58Z'>
		On Tensorflow 1.15, I get the following error:
ValueError                                Traceback (most recent call last)
&lt;command-1167185&gt; in &lt;module&gt;
     12 dense_features = keras.layers.DenseFeatures(feature_columns)
     13 column_tensors = {}
---&gt; 14 dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    879               kwargs.pop('mask')
    880             inputs, outputs = self._set_connectivity_metadata_(
--&gt; 881                 inputs, outputs, args, kwargs)
    882           self._handle_activity_regularization(inputs, outputs)
    883           self._set_mask_metadata(inputs, outputs, input_masks)

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs)
   2041     # This updates the layer history of the output tensor(s).
   2042     self._add_inbound_node(
-&gt; 2043         input_tensors=inputs, output_tensors=outputs, arguments=arguments)
   2044     return inputs, outputs
   2045 

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _add_inbound_node(self, input_tensors, output_tensors, arguments)
   2071         input_tensors=input_tensors,
   2072         output_tensors=output_tensors,
-&gt; 2073         arguments=arguments)
   2074 
   2075     # Update tensor history metadata.

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/node.py in __init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)
    120       if base_layer_utils.needs_keras_history(
    121           tensor_argument, ignore_call_context=True):
--&gt; 122         base_layer_utils.create_keras_history(tensor_argument)
    123 
    124     # Add nodes to all layers involved.

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in create_keras_history(tensors)
    182     keras_tensors: The Tensors found that came from a Keras Layer.
    183   """
--&gt; 184   _, created_layers = _create_keras_history_helper(tensors, set(), [])
    185   return created_layers
    186 

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
--&gt; 231           layer_inputs, processed_ops, created_layers)
    232       name = op.name
    233       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    227           else:
    228             with ops.init_scope():
--&gt; 229               constants[i] = backend.function([], op_input)([])
    230       processed_ops, created_layers = _create_keras_history_helper(
    231           layer_inputs, processed_ops, created_layers)

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py in __call__(self, inputs)
   3642     return nest.pack_sequence_as(
   3643         self._outputs_structure,
-&gt; 3644         [x._numpy() for x in outputs],  # pylint: disable=protected-access
   3645         expand_composites=True)
   3646 

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py in &lt;listcomp&gt;(.0)
   3642     return nest.pack_sequence_as(
   3643         self._outputs_structure,
-&gt; 3644         [x._numpy() for x in outputs],  # pylint: disable=protected-access
   3645         expand_composites=True)
   3646 

ValueError: Cannot convert a Tensor of dtype resource to a NumPy array.
		</comment>
		<comment id='2' author='jeisinge' date='2020-02-02T21:46:24Z'>
		Creating the dense_tensor with tf.compat.v1.feature_column.input_layer fails later when used.
The following code runs successfully.
column_tensors = {}
dense_tensor = tf.compat.v1.feature_column.input_layer(
  inputs,
  feature_columns,
  cols_to_output_tensors=column_tensors
)
However, the same failure exists when the dense_tensor is used:
output_1 = keras.layers.Dense(64, activation='relu')(dense_tensor)
Can feature_columns be used with Keras models?
		</comment>
		<comment id='3' author='jeisinge' date='2020-02-03T08:38:22Z'>
		&lt;denchmark-link:https://github.com/jeisinge&gt;@jeisinge&lt;/denchmark-link&gt;
 Could you please refer tho this &lt;denchmark-link:https://github.com/tensorflow/docs/blob/b4d8d7096099c2b0a7df6a0564bf6eca8c96c4a0/site/en/tutorials/structured_data/feature_cols_keras.ipynb&gt;link&lt;/denchmark-link&gt;
 , in case you are still unable to resolve the issue,
Could you please provide us with simple standalone code to reproduce the issue in our environment, Thanks
		</comment>
		<comment id='4' author='jeisinge' date='2020-02-03T14:37:50Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 , I am a bit confused.  The referenced document is from 2018.  It refers to , which I don't think exists anymore.  A more recent document at &lt;denchmark-link:https://www.tensorflow.org/tutorials/structured_data/feature_columns#create_a_feature_layer&gt;https://www.tensorflow.org/tutorials/structured_data/feature_columns#create_a_feature_layer&lt;/denchmark-link&gt;
 refers to , which I use.
For standalone code, I created a Google Colab at &lt;denchmark-link:https://colab.research.google.com/drive/1DVfpU6EoEz5vkMqLxH7JTXHALpa3VoOs&gt;https://colab.research.google.com/drive/1DVfpU6EoEz5vkMqLxH7JTXHALpa3VoOs&lt;/denchmark-link&gt;
 .  Is that what you were looking for?
Also, I believe it is important to note that this doesn't work on TensorFlow 2 and TensorFlow 1.  I'll try to add the tag.
		</comment>
		<comment id='5' author='jeisinge' date='2020-02-07T22:25:51Z'>
		&lt;denchmark-link:https://github.com/jeisinge&gt;@jeisinge&lt;/denchmark-link&gt;
 I ran with  and it did throw only deprecation warning and clearly mentioned to use new  API. For example changing  to . Before that we need to import feature_column API as . Please check the &lt;denchmark-link:https://www.tensorflow.org/tutorials/structured_data/feature_columns&gt;tutorial&lt;/denchmark-link&gt;
 on TF website.
&lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/14728a5879f016c82e320b165ff64dc3/tensorflow-feature-columns-fail-for-keras-model-functional-api.ipynb&gt;Here&lt;/denchmark-link&gt;
 is gist for y/our reference. Thanks!
Please close the issue if it was resolved for you. Thanks!
		</comment>
		<comment id='6' author='jeisinge' date='2020-02-07T23:37:40Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 , I am not an expert in Python.  What is the difference between:
import tensorflow as tf

source_column = tf.feature_column.numeric_column("source_name")
...
and
from tensorflow import feature_column

source_column = feature_column.numeric_column("source_name")
...
?
Are you saying that this defect is fixed in the nightly build?  If so, were you able to reproduce in TF 2.1 or TF 1.15?
		</comment>
		<comment id='7' author='jeisinge' date='2020-02-07T23:47:10Z'>
		I attempted to install tf-nightly in the colab notebook with !pip install tf-nightly.  It also failed.
Also, I did try the from tensorflow import feature_column.  That failed as well.
		</comment>
		<comment id='8' author='jeisinge' date='2020-02-20T17:57:59Z'>
		&lt;denchmark-link:https://github.com/jeisinge&gt;@jeisinge&lt;/denchmark-link&gt;
 did you try running my colab gist? Thanks!
		</comment>
		<comment id='9' author='jeisinge' date='2020-02-21T02:36:22Z'>
		Yeah. It fails.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Feb 20, 2020, 11:58 AM Vishnuvardhan Janapati &lt; ***@***.***&gt; wrote:
 @jeisinge &lt;https://github.com/jeisinge&gt; did you try running my colab
 gist? Thanks!

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#36424?email_source=notifications&amp;email_token=ACDUX2IORQSOELGNCEBTPMTRD3AC5A5CNFSM4KO3C5K2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMPOARI#issuecomment-589226053&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/ACDUX2OEXALJPVVFT6WIYNDRD3AC5ANCNFSM4KO3C5KQ&gt;
 .



		</comment>
		<comment id='10' author='jeisinge' date='2020-02-21T17:48:35Z'>
		&lt;denchmark-link:https://github.com/jeisinge&gt;@jeisinge&lt;/denchmark-link&gt;
 It is strange. my Colab gist should run without an issue. Can you please share the error you are facing? Are you running my gist as it is or did you modify anything? Are you running it in Chrome or any other browser? Still not sure what is the root-cause. Thanks!
		</comment>
		<comment id='11' author='jeisinge' date='2020-02-21T22:02:38Z'>
		I reran the gist and it succeeded.  However, it appears to be on TF 1.15 due to a misspelling on install.   After upgrading to TF 2 or TF Nightly, it appears to fail on a rerun with the same error:
ValueError                                Traceback (most recent call last)

&lt;ipython-input-6-bed319bac6ce&gt; in &lt;module&gt;()
      1 dense_features = keras.layers.DenseFeatures(feature_columns)
      2 column_tensors = {}
----&gt; 3 dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)

10 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    220             'Sparse ops are not supported with functional models with built-in '
    221             'layer wrapping. Please wrap the sparse ops in a Lambda layer like'
--&gt; 222             ': \n{lambda_example}\n'.format(lambda_example=lambda_example))
    223 
    224       # Recursively set `_keras_history`.

ValueError: Sparse ops are not supported with functional models with built-in layer wrapping. Please wrap the sparse ops in a Lambda layer like: 

        weights_mult = lambda x: tf.sparse.sparse_dense_matmul(x, weights)
        output = tf.keras.layers.Lambda(weights_mult)(input)
This might be due to restarting the Python Interpereter.  I believe you can see the gist at &lt;denchmark-link:https://colab.research.google.com/gist/jeisinge/90718acccf943c16b61ec80a2ff3cb66/tensorflow-feature-columns-fail-for-keras-model-functional-api.ipynb&gt;https://colab.research.google.com/gist/jeisinge/90718acccf943c16b61ec80a2ff3cb66/tensorflow-feature-columns-fail-for-keras-model-functional-api.ipynb&lt;/denchmark-link&gt;
 .
In general, I had to run cell 1.  Click the Restart button that appears, rerun everything.
		</comment>
		<comment id='12' author='jeisinge' date='2020-10-15T10:44:05Z'>
		&lt;denchmark-link:https://github.com/jeisinge&gt;@jeisinge&lt;/denchmark-link&gt;
  Could you please check with tf-nightly version and let us know if the issue still persists.Thanks!
		</comment>
		<comment id='13' author='jeisinge' date='2020-10-15T14:15:45Z'>
		I just tested on TF 2.3 and TF Nightly.  TF 2.3 fails, but TF Nightly works.  Also, the resulting model can be serialized.  Thank you!
		</comment>
		<comment id='14' author='jeisinge' date='2020-10-15T14:15:47Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36424&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36424&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>