<bug id='27298' author='zzh8829' open_date='2019-03-29T17:44:21Z' closed_time='2020-04-10T04:19:46Z'>
	<summary>Tensorflow 2.0 tf.name_scope has no effect on weights created by keras functional api</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0-alpha0
Python version: 3.7.1

Describe the current behavior
tf.name_scope does not effect the name of weights created by keras.layers
output in tf 2.0.0-alpha0
&lt;denchmark-code&gt;dense/kernel:0
dense/bias:0
&lt;/denchmark-code&gt;

Describe the expected behavior
tf.name_scope is applied to wights created by keras.layers
output in tf 1.13.1 is the expected behavior
&lt;denchmark-code&gt;block/dense/kernel:0
block/dense/bias:0
&lt;/denchmark-code&gt;

Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
print(tf.__version__)

inputs = tf.keras.Input(shape=[2])
with tf.name_scope('block'):
    outputs = tf.keras.layers.Dense(10)(inputs)
model = tf.keras.Model(inputs, outputs)
for w in model.weights:
    print(w.name)
&lt;/denchmark-code&gt;

Other info / logs
I was able to reproduce the output of tf 1.13 in tf 2.0.0 by using the following code
&lt;denchmark-code&gt;from tensorflow.python.keras.backend import get_graph
with get_graph().as_default(), tf.name_scope('block'):
    outputs = tf.keras.layers.Dense(10)(inputs)
&lt;/denchmark-code&gt;

keras.layers is using the keras graph which overrides the name_scope generated by   tf.name_scope in the default graph
I think the problem is actually caused by tf.name_scope incorrectly set _has_symbolic_input_in_eager to False when we are building graph using the keras functional api. since the input here is keras.Input, the name_scope should be applied to keras graph instead of default graph
	</description>
	<comments>
		<comment id='1' author='zzh8829' date='2019-03-29T20:35:09Z'>
		In TF 2.0 the Eager Execution is set as Default, therefore in eager execetion the TF completely ignores the name_scope. I think this ops is particularly designed for Graphs.
Therefore you can do all the above things when Graphs are set as Default
with tf.Graph().as_default():  
  inputs = tf.keras.Input(shape=[2])
  with tf.name_scope('block'):
      outputs = tf.keras.layers.Dense(10)(inputs)
model = tf.keras.Model(inputs, outputs)
for w in model.weights:
    print(w.name)
		</comment>
		<comment id='2' author='zzh8829' date='2019-03-30T02:42:03Z'>
		I would disagree here, in a real eager execution scenario, keras layers does work with tf.name_scope.
&lt;denchmark-code&gt;inputs = np.random.random((1, 2))
with tf.name_scope('block'):
    dense = tf.keras.layers.Dense(10, input_shape=(2, ))
    outputs = dense(inputs)
for w in dense.weights:
    print(w.name)
&lt;/denchmark-code&gt;

output:
&lt;denchmark-code&gt;block/dense/kernel:0
block/dense/bias:0
&lt;/denchmark-code&gt;

I don't think keras should have inconsistent behavior when the input type change from numerical to symbolic.  tf.name_scope v1 used to take a variable parameter for this exact case, but it's removed in tf2.
In fact, an old &lt;denchmark-link:https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html&gt;keras tutorial&lt;/denchmark-link&gt;
 specifically mentioned tf.name_scope is compatible with the functional api which is no longer true in tf2.
I don't know if this is indeed the expected outcome, but this definitely needs more clarification since name_scope is pretty essential for building complex models.
		</comment>
		<comment id='3' author='zzh8829' date='2019-03-30T06:58:33Z'>
		Maybe you're right. Lets see what does the Member of Tensorflow have to say about this.
		</comment>
		<comment id='4' author='zzh8829' date='2019-04-02T09:52:43Z'>
		Please do not hesitate to add something to my Stackoverflow issue &lt;denchmark-link:https://stackoverflow.com/questions/55318952/tensorflow-2-0-how-to-group-graph-using-tf-keras-tf-name-scope-tf-variable-sco/55376814?noredirect=1#comment97651032_55376814&gt;TensorFlow 2.0: how to group graph using tf.keras? tf.name_scope/tf.variable_scope not used anymore?&lt;/denchmark-link&gt;

However, I also think this is actually a bug. tf.Variable works as intended:
&lt;denchmark-code&gt;In [3]: with tf.name_scope("foo"): 
   ...:     with tf.name_scope("bar"): 
   ...:         v = tf.Variable([0])

In [4]: v                                                                                                                                                                                                           
Out[4]: &lt;tf.Variable 'foo/bar/Variable:0' shape=(1,) dtype=int32, numpy=array([0], dtype=int32)&gt;
&lt;/denchmark-code&gt;

The variable is placed within the scope foo/bar.
Eager execution, as already demonstrated, also works using tf.keras.layers...
&lt;denchmark-code&gt;In [5]: inputs = np.random.rand(10,1) 
    ...: with tf.name_scope("foo"): 
    ...:     with tf.name_scope("bar"): 
    ...:         dense_layer = tf.keras.layers.Dense(1) 
    ...:         dense_output = dense_layer(inputs)

In [6]: dense_layer.weights                                                                                                                                                                                        
Out[6]:
[&lt;tf.Variable 'foo/bar/dense_1/kernel:0' shape=(1, 1) dtype=float64, numpy=array([[1.40278891]])&gt;,
 &lt;tf.Variable 'foo/bar/dense_1/bias:0' shape=(1,) dtype=float64, numpy=array([0.])&gt;]
&lt;/denchmark-code&gt;

...while simply building a model with tf.keras.layers completeley ignores tf.name_scope:
&lt;denchmark-code&gt;In [7]: with tf.name_scope("foo"): 
    ...:     with tf.name_scope("bar"): 
    ...:         inputs = tf.keras.Input(shape=(1,)) 
    ...:         dense_layer = tf.keras.layers.Dense(1)(inputs) 
    ...:         model = tf.keras.Model(inputs=inputs, outputs=dense_layer) 
    ...:         model.compile(optimizer=tf.optimizers.SGD(), loss=tf.losses.MeanSquaredError())

In [8]: for l in model.layers: 
    ...:     for w in l.weights: 
    ...:         print(w.name) 
    ...:                                                                                                                                                                                                            
Out[8]: 
dense_2/kernel:0
dense_2/bias:0
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='zzh8829' date='2019-04-03T00:29:21Z'>
		^ name_scope is definitely not working very nicely in tf2, throwing in some of my findings here.
In eager mode with symbolic input, tf.name_scope pushes scope into default context here 


tensorflow/tensorflow/python/framework/ops.py


         Line 6400
      in
      6a603d8






 if self._in_eager_mode: 





In keras, when layers gets call with symbolic input, it tries to build a graph and replace the current context with the keras graph here 


tensorflow/tensorflow/python/keras/engine/base_layer.py


         Line 580
      in
      6a603d8






 with graph.as_default(), ops.name_scope(self._name_scope()): 





However, if the input is numpy, __call__ follows this code path



tensorflow/tensorflow/python/keras/engine/base_layer.py


         Line 644
      in
      6a603d8






 # Eager execution on data tensors. 





which correctly inherits the parent tf.name_scope
The weirdness happens because tf.name_scope is not in the same graph as keras model. I think the best solution might be providing tf.name_scope an extra parameter (like it did before) to specify the input type. But if there is a more TFonic way to merge scopes without doing it explicitly that be great.
		</comment>
		<comment id='6' author='zzh8829' date='2019-07-15T09:47:35Z'>
		I'm seeing this too ... does anyone know in what direction this is moving?
		</comment>
		<comment id='7' author='zzh8829' date='2019-09-06T22:44:47Z'>
		I could reproduce the issue in . Please take a look at the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/d517caf07e65b06cb4209c55e1de0025/tf27298.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='8' author='zzh8829' date='2019-10-18T19:26:36Z'>
		&lt;denchmark-link:https://github.com/zzh8829&gt;@zzh8829&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/rchao&gt;@rchao&lt;/denchmark-link&gt;
 are there any updates? Any plans to fix the  integration?
		</comment>
		<comment id='9' author='zzh8829' date='2019-11-12T20:34:38Z'>
		I found the name scope worked correctly if I additionally wrapped the with tf.name_scope(... with with tensorflow.python.keras.backend.get_graph().as_default():. This was sort of mirroring this line:



tensorflow/tensorflow/python/keras/engine/base_layer.py


         Line 580
      in
      6a603d8






 with graph.as_default(), ops.name_scope(self._name_scope()): 





My guess was that the name scopes were specific to eager mode vs graph-based mode, and the normal Keras model construction forced the graph based mode - so you want to specify the name scope in graph mode. This is a very vague guess, and I don't know if this causes other issues.
Using the normal tensorflow.keras.backend also didn't work - I had to use tensorflow.python.keras.backend.
		</comment>
		<comment id='10' author='zzh8829' date='2019-12-19T11:10:37Z'>
		I find similar problem, and here is one solution for name_scope control with Sequential rather than tf.name_scope for tf 2.0 kerasï¼š
import tensorflow as tf
print(tf.__version__)

inputs = tf.keras.Input(shape=[2,10])
dense = tf.keras.layers.Dense(10)
seq = tf.keras.Sequential(name='block')
seq.add(dense)
outputs = seq(inputs)
model = tf.keras.Model(inputs, outputs)
for w in model.weights:
    print(w.name)

2.0.0
block/dense/kernel:0
block/dense/bias:0
		</comment>
		<comment id='11' author='zzh8829' date='2020-01-04T00:56:25Z'>
		It works as expected inside the 'build' phase. You're in a functional graph and name_space stack there.
		</comment>
		<comment id='12' author='zzh8829' date='2020-02-29T22:22:00Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/zzh8829&gt;@zzh8829&lt;/denchmark-link&gt;
 any updates? &lt;denchmark-link:https://github.com/rchao&gt;@rchao&lt;/denchmark-link&gt;
 does not seem to be active in this issue.
		</comment>
		<comment id='13' author='zzh8829' date='2020-04-02T18:33:30Z'>
		&lt;denchmark-link:https://github.com/zzh8829&gt;@zzh8829&lt;/denchmark-link&gt;
 I think this was resolved in recent . I could not reproduce with . &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/1ece1f2942cfb0aadbd5a72e693e867d/untitled56.ipynb&gt;Here&lt;/denchmark-link&gt;
 is the colab gist for your reference.
Please verify once and if this was resolved for you then close the issue. Thanks!
		</comment>
		<comment id='14' author='zzh8829' date='2020-04-08T01:00:21Z'>
		&lt;denchmark-link:https://github.com/zzh8829&gt;@zzh8829&lt;/denchmark-link&gt;
 Can you verify once and close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='15' author='zzh8829' date='2020-04-10T04:19:46Z'>
		&lt;denchmark-link:https://github.com/zzh8829&gt;@zzh8829&lt;/denchmark-link&gt;
 I am closing this issue as this was resolved in recent . Please feel free to reopen if this issue was not resolved for you. Thanks!
		</comment>
		<comment id='16' author='zzh8829' date='2020-04-10T04:19:48Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27298&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27298&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='zzh8829' date='2020-04-22T15:21:53Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 this issue not resolved in , including latest nightly.
Please see this gist &lt;denchmark-link:https://gist.github.com/Daniel451/03d173825235369be46b27e06e5e109a&gt;https://gist.github.com/Daniel451/03d173825235369be46b27e06e5e109a&lt;/denchmark-link&gt;

		</comment>
		<comment id='18' author='zzh8829' date='2020-04-22T17:41:32Z'>
		&lt;denchmark-link:https://github.com/Daniel451&gt;@Daniel451&lt;/denchmark-link&gt;
 Can you please open a new issue with your standalone code. I think the second example in your code uses graph context and providing scope name works well as shown below. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/79327bcdc98a09d3f72afcec18d076c7/untitled109.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
&lt;denchmark-code&gt;with tf.name_scope("foo2"): 
     with tf.name_scope("block1") as scope: 
         inputs = tf.keras.Input(shape=(1,)) 
         dense_layer = tf.keras.layers.Dense(1,name=scope)(inputs) 
         model = tf.keras.Model(inputs=inputs, outputs=dense_layer) 
         model.compile(optimizer=tf.optimizers.SGD(), loss=tf.losses.MeanSquaredError())

for l in model.layers:
  print(l.name)
  for w in l.weights: 
    print(w.name)
&lt;/denchmark-code&gt;

Output is
&lt;denchmark-code&gt;input_2
foo2/block1/
foo2/block1/kernel:0
foo2/block1/bias:0
&lt;/denchmark-code&gt;

Please open a new issue for further question on this issue. Thanks!
		</comment>
		<comment id='19' author='zzh8829' date='2020-05-15T20:02:47Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 I can't help but notice that the  is a no-op in that example.  The following gives the same output:
&lt;denchmark-code&gt;scope = 'foo2/block1'
inputs = tf.keras.Input(shape=(1,)) 
dense_layer = tf.keras.layers.Dense(1,name=scope)(inputs) 
model = tf.keras.Model(inputs=inputs, outputs=dense_layer) 
model.compile(optimizer=tf.optimizers.SGD(), loss=tf.losses.MeanSquaredError())

for l in model.layers:
	print(l.name)
	for w in l.weights: 
	print(w.name)
&lt;/denchmark-code&gt;

What we want is for tf.name_scope to work, not a tutorial on how to work around it by manually calculating values for name=
		</comment>
		<comment id='20' author='zzh8829' date='2020-11-11T22:41:18Z'>
		How is this still not resolved in tf 2.3.0?
		</comment>
		<comment id='21' author='zzh8829' date='2020-11-11T23:20:23Z'>
		&lt;denchmark-link:https://github.com/tgsmith61591&gt;@tgsmith61591&lt;/denchmark-link&gt;
 I have been able to use it since tf 2.1
Have you put it under a  block? Like
&lt;denchmark-code&gt;class Douche(tf.keras.Model):
    def __init__(self,out_labels):
        self.shitty = tf.keras.layers.Dense(4)
        self.wok = tf.keras.layers.Dense(out_labels)
    def call(x):
        with tf.name_scope("Turd"):
            x = self.shitty(x)
        with tf.name_scope("Sandwich"):
            x = self.wok(x)
        return x
&lt;/denchmark-code&gt;

		</comment>
		<comment id='22' author='zzh8829' date='2020-11-12T00:09:59Z'>
		&lt;denchmark-link:https://github.com/nicolasshu&gt;@nicolasshu&lt;/denchmark-link&gt;
 this is  what this issue is about. The problem persists during graph mode / when constructing the model.
Your example is just another variation of &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 demonstration that given an actual call / eager mode  is inferred correctly. However, as &lt;denchmark-link:https://github.com/phsyron&gt;@phsyron&lt;/denchmark-link&gt;
 already stated, the issue persists for graph mode / model construction -&gt; your example only works, because you subclass  and infer  in , i.e.  runtime with actual inputs  given. We were talking about correctly inferring  during model construction and only once as well as a correct inferring during graph mode.
		</comment>
		<comment id='23' author='zzh8829' date='2020-11-12T00:11:18Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 I actually lost track of this issue, but it still persists. If opening a new issue is necessary I'll do this and supply a standalone Gist soon. Thank you for your help &amp; time.
		</comment>
		<comment id='24' author='zzh8829' date='2020-11-12T01:52:25Z'>
		&lt;denchmark-link:https://github.com/Daniel451&gt;@Daniel451&lt;/denchmark-link&gt;
 If you don't mind, please open a new issue as there are many comments above to follow the actual problem. In the new issue, you can refer this issue for further details. Thanks!
		</comment>
	</comments>
</bug>