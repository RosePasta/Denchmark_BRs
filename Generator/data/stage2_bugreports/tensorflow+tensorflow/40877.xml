<bug id='40877' author='summa-code' open_date='2020-06-28T06:44:39Z' closed_time='2020-07-02T16:58:32Z'>
	<summary>Check failed: cudnnSetRNNMatrixMathType(rnn_desc.get(), math_type) == CUDNN_STATUS_SUCCESS (3 vs. 0)</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): SOURCE
TensorFlow version (use command below): LATEST FROM GIT
Python version: 3.8.1
Bazel version (if compiling from source): 3.1.0
GCC/Compiler version (if compiling from source): 9.3.0
CUDA/cuDNN version: 11 / 8.0.1
GPU model and memory: GeForce RTX 2070

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
Errors out with this line when i ran a sequential model
F tensorflow/stream_executor/cuda/cuda_dnn.cc:1186] Check failed: cudnnSetRNNMatrixMathType(rnn_desc.get(), math_type) == CUDNN_STATUS_SUCCESS (3 vs. 0)
Standalone code to reproduce the issue
model = keras.Sequential()
model.add(
keras.layers.Bidirectional(
keras.layers.LSTM(
units=128,
input_shape=(X_train.shape[1], X_train.shape[2])
)
)
)
model.add(keras.layers.Dropout(rate=0.2))
model.add(keras.layers.Dense(units=1))
model.compile(loss='mean_squared_error', optimizer='adam')
Error happens at this line,
history = model.fit(
X_train, y_train,
epochs=30,
batch_size=32,
validation_split=0.1,
shuffle=False
)
	</description>
	<comments>
		<comment id='1' author='summa-code' date='2020-06-29T14:42:43Z'>
		&lt;denchmark-link:https://github.com/summa-code&gt;@summa-code&lt;/denchmark-link&gt;
,
On running the code I am facing an error stating .
In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!
		</comment>
		<comment id='2' author='summa-code' date='2020-06-29T18:23:58Z'>
		Here is the code in GIT,
&lt;denchmark-link:https://github.com/curiousily/Deep-Learning-For-Hackers&gt;https://github.com/curiousily/Deep-Learning-For-Hackers&lt;/denchmark-link&gt;

I have used the 12th example for Time series prediction.
I built a code on 22nd, and that works. The codes that i pulled after 22nd seems to throw this issue. Related to LSTM/RNN ?
		</comment>
		<comment id='3' author='summa-code' date='2020-06-30T18:23:11Z'>
		&lt;denchmark-link:https://github.com/summa-code&gt;@summa-code&lt;/denchmark-link&gt;
,
I was able to run the code without any issues with TF v2.2 and TF-nightly. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/1480936b3b43c78426a7aae0c6755778/40877-tf-nightly.ipynb&gt;here&lt;/denchmark-link&gt;
.
Could you please check if you are facing the same issue in a virtual environment? Thanks!
		</comment>
		<comment id='4' author='summa-code' date='2020-06-30T18:26:50Z'>
		Also, please take a look the &lt;denchmark-link:https://www.tensorflow.org/install/source#gpu&gt;tested build configuration&lt;/denchmark-link&gt;
 and check if you are running the compatible CUDA and cuDNN versions. Thanks!
		</comment>
		<comment id='5' author='summa-code' date='2020-07-01T05:42:54Z'>
		
Also, please take a look the tested build configuration and check if you are running the compatible CUDA and cuDNN versions. Thanks!

+1, please report your CUDA and cuDNN versions.  We have observed this error internally with CUDA11+cuDNN8, and are currently investigating it.  CC &lt;denchmark-link:https://github.com/chsigg&gt;@chsigg&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='summa-code' date='2020-07-01T14:59:03Z'>
		I have the same problem. I use LSTM layer. On CPU all working fine.
root@RedShark:/var/www# python3 -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"
2020-07-01 17:53:54.907427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
v1.12.1-35611-gcd0a2e6c1f 2.4.0
		</comment>
		<comment id='7' author='summa-code' date='2020-07-02T16:58:32Z'>
		cudnnSetRNNDescriptor_v6 has been deprecated in cuDNN 8, and cudnnSetRNNMatrixMathType returns an error.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/28766652e6db8020881b55b1ebe77b05b2ac994a&gt;2876665&lt;/denchmark-link&gt;
 switched to cudnnSetRNNDescriptor_v8.
I'm closing this isssue as I think it has been resolved. Please reopen if you still see the issue. Thanks!
		</comment>
		<comment id='8' author='summa-code' date='2020-07-02T16:58:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40877&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40877&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='summa-code' date='2020-07-02T21:03:37Z'>
		The previously described error no longer occurs. No less, when trying to use the LSTM layer, another error appeared
&lt;denchmark-code&gt;UnknownError                              Traceback (most recent call last)
&lt;ipython-input-24-66b029fffc15&gt; in &lt;module&gt;
      1 # train
----&gt; 2 hist = textClassifier.train(X_train[:10000], y_train[:10000])
      3 hist

&lt;ipython-input-21-d0b8fb2d36c8&gt; in train(self, X, y, w2v_model, verbose, X2)
    308 
    309     def train(self, X, y, w2v_model=None, verbose=0, X2=None):
--&gt; 310         self.fit(X, y, w2v_model, verbose, X2)
    311         return self.hist
    312 

&lt;ipython-input-21-d0b8fb2d36c8&gt; in fit(self, X, y, w2v_model, verbose, X2)
    301                                   epochs           = self.epochs,
    302                                   batch_size       = self.batch_size,
--&gt; 303                                   shuffle          = False)
    304 
    305         self.model      = model

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--&gt; 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1097                 batch_size=batch_size):
   1098               callbacks.on_train_batch_begin(step)
-&gt; 1099               tmp_logs = train_function(iterator)
   1100               if data_handler.should_sync:
   1101                 context.async_wait()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = "nonXla"
--&gt; 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    838         # Lifting succeeded, so variables are initialized and we can run the
    839         # stateless function.
--&gt; 840         return self._stateless_fn(*args, **kwds)
    841     else:
    842       canon_args, canon_kwds = \

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2842     with self._lock:
   2843       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-&gt; 2844     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2845 
   2846   @property

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1845                            resource_variable_ops.BaseResourceVariable))],
   1846         captured_inputs=self.captured_inputs,
-&gt; 1847         cancellation_manager=cancellation_manager)
   1848 
   1849   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1921       # No tape is watching; skip to running the function.
   1922       return self._build_call_outputs(self._inference_function.call(
-&gt; 1923           ctx, args, cancellation_manager=cancellation_manager))
   1924     forward_backward = self._select_forward_and_backward_functions(
   1925         args,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    548               inputs=args,
    549               attrs=attrs,
--&gt; 550               ctx=ctx)
    551         else:
    552           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---&gt; 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

UnknownError:    CUDNN_STATUS_BAD_PARAM
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1130): 'cudnnSetRNNDescriptor_v8( rnn_desc.get(), rnn_algo, rnn_mode, bias_mode, direction_mode, input_mode, data_type, compute_type, math_type, input_size, hidden_size, cell_size, num_layers, dropout_desc.handle(), aux_flags)'
	 [[{{node CudnnRNN}}]]
	 [[functional_3/bidirectional_1/forward_lstm_1/PartitionedCall]] [Op:__inference_train_function_13519]

Function call stack:
train_function -&gt; train_function -&gt; train_function
&lt;/denchmark-code&gt;

root@RedShark:/usr# python3 -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"
2020-07-03 00:10:58.059582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
v1.12.1-35676-g89798077df 2.4.0
If I turn off cuda ( os.environ['CUDA_VISIBLE_DEVICES'] = '' ), everything works fine on cpu.
		</comment>
		<comment id='10' author='summa-code' date='2020-07-03T05:38:00Z'>
		
No less, when trying to use the LSTM layer, another error appeared

&lt;denchmark-link:https://github.com/ApelSYN&gt;@ApelSYN&lt;/denchmark-link&gt;
,
Could you please submit a new issue from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new/choose&gt;this link&lt;/denchmark-link&gt;
 and fill in the template, so that we can track the issue there. Thanks!
		</comment>
	</comments>
</bug>