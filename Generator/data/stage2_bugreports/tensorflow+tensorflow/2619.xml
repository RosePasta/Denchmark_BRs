<bug id='2619' author='beopst' open_date='2016-06-02T07:59:37Z' closed_time='2016-06-15T05:52:24Z'>
	<summary>tf.image.decode_png returns wrong values for uint16 images</summary>
	<description>
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: Ubuntu 14.04
Installed version of CUDA and cuDNN: CUDA 7.5, cuDNN R4
If installed from sources, provide the commit hash: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/d8eb4bb6470d4cb3d0f67f2111a39fa50f1c28e5&gt;d8eb4bb&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;

Please see the below code. After saving numpy array as uint16 png image, I loaded it using tf.image.decode_png. It returns different values from the original array.
import numpy as np
import tensorflow as tf
from skimage import io

original = np.array([[1,4096],[15000,30000]],dtype=np.uint16)
io.imsave('test.png',original)

sk_im = io.imread('test.png')

image = tf.image.decode_png(tf.read_file('test.png'),dtype=tf.uint16)
sess = tf.Session()
tf_im = sess.run(image)

print sk_im
print tf_im
Results are
&lt;denchmark-code&gt;sk_im = [[1, 4096], [15000, 30000]] #same as original
tf_im[:,:,0] = [[256, 16], [38970, 12405]]
&lt;/denchmark-code&gt;

I checked the function works properly in case of uint8 png image.
	</description>
	<comments>
		<comment id='1' author='beopst' date='2016-06-02T16:44:22Z'>
		What architecture are you running on (little endian or big endian)?
		</comment>
		<comment id='2' author='beopst' date='2016-06-03T01:57:03Z'>
		It is little endian (x86 processors).

$ lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                12
On-line CPU(s) list:   0-11
Thread(s) per core:    2
Core(s) per socket:    6
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 63
Stepping:              2
CPU MHz:               2599.968
BogoMIPS:              4797.20
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              15360K
NUMA node0 CPU(s):     0-11

		</comment>
		<comment id='3' author='beopst' date='2016-06-07T10:35:19Z'>
		As a workaround, the values can be fixed by swapping the bytes via integer-operations
&lt;denchmark-code&gt;# Decode image
image = tf.image.decode_png(png, dtype=tf.uint16)
image = tf.reshape(image, [depth, height, width])

# Swap Bytes 
tensor256 = tf.fill(image.get_shape(), 256)
image_div = tf.div(tf.cast(image, tf.int32), tensor256)
image_mod = tf.mod(tf.cast(image, tf.int32), tensor256)
image = tf.add(tf.mul(image_mod, tensor256), image_div)
&lt;/denchmark-code&gt;

This is obviously a dirty hack and would break correct values on systems where the decode function works correctly
		</comment>
		<comment id='4' author='beopst' date='2016-06-11T00:07:44Z'>
		&lt;denchmark-link:https://github.com/dave-andersen&gt;@dave-andersen&lt;/denchmark-link&gt;
 Could you take a look since you touched the png reading most recently? :)
		</comment>
		<comment id='5' author='beopst' date='2016-06-14T22:02:36Z'>
		Urgh.  I'm concerned that we're not properly setting the IS_LITTLE_ENDIAN flag in the OSS build:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&amp;q=IS_LITTLE_ENDIAN&gt;https://github.com/tensorflow/tensorflow/search?utf8=%E2%9C%93&amp;q=IS_LITTLE_ENDIAN&lt;/denchmark-link&gt;

I'll take this on.  &lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
 - do you know off the top of your head if we have an existing flag for little endian I can repurpose here?  (I'll dig, just trying to be lazy. :)
		</comment>
		<comment id='6' author='beopst' date='2016-06-14T22:12:05Z'>
		&lt;denchmark-link:https://github.com/dave-andersen&gt;@dave-andersen&lt;/denchmark-link&gt;
 I don't remember, nor do I envy you this task. :)
		</comment>
		<comment id='7' author='beopst' date='2016-06-14T22:15:05Z'>
		I'm, um, just going to use the existing flag and assume it's someone else's responsibility to make the flag work. :)
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/host_info.h#L25&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/host_info.h#L25&lt;/denchmark-link&gt;

(static const bool kLittleEndian = true; )
		</comment>
		<comment id='8' author='beopst' date='2016-06-14T22:20:04Z'>
		Actually, I'm not sure that flag is the issue.  &lt;denchmark-link:https://github.com/beopst&gt;@beopst&lt;/denchmark-link&gt;
 Are you on a little endian machine?
		</comment>
		<comment id='9' author='beopst' date='2016-06-14T22:22:48Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
 - the issue is that we don't use that flag in the PNG decoder, we use the IS_LITTLE_ENDIAN flag, which is only defined by some transitively included google-internal header.
The second part of the issue is that we don't have any tests for the png decode op that would catch this on jenkins.
Fixing.
		</comment>
		<comment id='10' author='beopst' date='2016-06-15T01:14:37Z'>
		Fix submitted, should hit github at next sync.  Will let the fix close it.
&lt;denchmark-link:https://github.com/beopst&gt;@beopst&lt;/denchmark-link&gt;
 - huge thanks for providing an easy way to reproduce with your bug report!
		</comment>
	</comments>
</bug>