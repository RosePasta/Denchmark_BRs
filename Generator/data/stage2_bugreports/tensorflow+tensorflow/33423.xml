<bug id='33423' author='Yuvaraj8blr' open_date='2019-10-16T12:11:15Z' closed_time='2019-10-21T20:56:00Z'>
	<summary>"Tensor.op is meaningless when eager execution is enabled",  when using tf.compat.v1 RNN cells</summary>
	<description>
System information

Have I written custom code : Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): openSUSE Leap 15.0
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from : binary
TensorFlow version: v2.0.0-rc2-26-g64c3d38( 2.0.0)
Python version: Python 3.6
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: CUDA Version 10.2
GPU model and memory: GeForce RTX 2080


[The final goal is convert the saved_model to .tflite to port to an Android device. My model must use LSTM layers. My references are from : &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/lstm/g3doc/README.md&gt;Tensorflow Lite Experimental Examples&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://www.tensorflow.org/lite/convert/rnn&gt;Supported functions to convert RNNs&lt;/denchmark-link&gt;
 ]
I have used a single BasicLSTMCell with Static RNN with compat.v1.*.
MNIST dataset is used to provide a stand-alone code example.
Describe the expected behavior
operations in compat.V1 for RNNs for TF2.0 should be supported for eager execution.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras import Sequential
from tensorflow.keras import layers
from tensorflow.keras.layers import LSTM, Dense, Input, Layer


(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))

n_hidden = 8
time_steps = x_train.shape[1]
n_input = x_train.shape[2]
n_classes = 10
batch_size  = 20

loss_object = tf.keras.losses.CategoricalCrossentropy()
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)

train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')

val_loss = tf.keras.metrics.Mean(name='val_loss')
val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')


@tf.function
def train_step(model, features, labels):
    with tf.GradientTape() as tape:
        predictions = model(features)
        loss = loss_object(labels, predictions)

    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    train_loss(loss)
    train_accuracy(labels, predictions)


weights = {
    'out': tf.Variable(tf.random.normal([n_hidden, n_classes]), trainable = True, dtype='float32')
}
biases = {
    'out': tf.Variable(tf.random.normal([n_classes]), trainable = True, dtype='float32')
}


class CompatV1LSTM(tf.keras.layers.Layer):
    def __init__(self, n_hidden = 8):
        super(CompatV1LSTM, self).__init__()
        print('Layer Init')

    def call(self, x):
        x = tf.dtypes.cast(x, tf.dtypes.float32, name='Converted_floats')
        _X = tf.unstack(x, time_steps, 1)

        print('Shape of x', x.shape)
        print('Shape of input after unstack',len(_X))
        print('Shape of first element', _X[0].shape)

        lstm_cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)
        output, state = tf.compat.v1.nn.static_rnn(cell=lstm_cell, inputs=_X, dtype=tf.float32)

        return tf.matmul(output[-1], weights['out']) + biases['out']

batch_dataset = train_dataset.batch(20)
x, y = next(iter(batch_dataset))
labels = tf.one_hot(y, depth = 10)

model = CompatV1LSTM()
print(model)
train_step(model, x, labels)
print(train_accuracy.result())
print(train_loss.result())
&lt;/denchmark-code&gt;

Other info / logs : Error log :
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "&lt;input&gt;", line 1, in &lt;module&gt;
  File "/opt/pycharm-community-2019.1.3/helpers/pydev/_pydev_bundle/pydev_umd.py", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File "/opt/pycharm-community-2019.1.3/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/localdata/d1300/HAR_RW_Linse10/Models/DeployModels/tflite2.py", line 123, in &lt;module&gt;
    train_step(model, x, labels)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 457, in __call__
    result = self._call(*args, **kwds)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1822, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 2150, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 2041, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 358, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in converted code:
    /localdata/d1300/HAR_RW_Linse10/Models/DeployModels/tflite2.py:31 train_step  *
        predictions = model(features)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:847 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    /localdata/d1300/HAR_RW_Linse10/Models/DeployModels/tflite2.py:118 call  *
        x = self.block_1(inputs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:847 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    /localdata/d1300/HAR_RW_Linse10/Models/DeployModels/tflite2.py:87 call  *
        output, state = tf.compat.v1.nn.static_rnn(cell=lstm_cell, inputs=_X, dtype=tf.float32)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:324 new_func
        return func(*args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn.py:1438 static_rnn
        (output, state) = call_cell()
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn.py:1425 &lt;lambda&gt;
        call_cell = lambda: cell(input_, state)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:386 __call__
        self, inputs, state, scope=scope, *args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/layers/base.py:548 __call__
        outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:817 __call__
        self._maybe_build(inputs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:2141 _maybe_build
        self.build(input_shapes)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py:306 wrapper
        output_shape = fn(instance, input_shape)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735 build
        shape=[input_depth + h_depth, 4 * self._num_units])
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:324 new_func
        return func(*args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:1702 add_variable
        return self.add_weight(*args, **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/layers/base.py:461 add_weight
        **kwargs)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:522 add_weight
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py:744 _add_variable_with_custom_getter
        **kwargs_for_getter)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:1504 get_variable
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:1247 get_variable
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:567 get_variable
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:519 _true_getter
        aggregation=aggregation)
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:861 _get_single_variable
        tb = var.op.traceback[::-1]
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:555 op
        return self._handle.op
    /home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1080 op
        "Tensor.op is meaningless when eager execution is enabled.")
    AttributeError: Tensor.op is meaningless when eager execution is enabled.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Yuvaraj8blr' date='2019-10-17T04:29:07Z'>
		I could reproduce the issue with TF 2.0.0 on colab. Please see the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/fd5270ec7c179952716861d70e75853e/untitled204.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='Yuvaraj8blr' date='2019-10-21T20:56:00Z'>
		The code is bit messy, but I think the error is caused by creating the lstm cell within the call body(), which is executed in the graph context(). The correct way to do it is create the cell at init(), and have a build() method, which build the weights for cell (it will run in eager context), and use the cell in the call() body, like below:
class CompatV1LSTM(tf.keras.layers.Layer):
  def __init__(self, n_hidden = 8):
    super(CompatV1LSTM, self).__init__()
    self.lstm_cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)
    print('Layer Init')

  def build(self, input_shape):
    self.lstm_cell.build(input_shape)


  def call(self, x):
    x = tf.dtypes.cast(x, tf.dtypes.float32, name='Converted_floats')
    _X = tf.unstack(x, time_steps, 1)

    print('Shape of x', x.shape)
    print('Shape of input after unstack',len(_X))
    print('Shape of first element', _X[0].shape)

    output, state = tf.compat.v1.nn.static_rnn(cell=self.lstm_cell,
                                               inputs=_X, dtype=tf.float32)

    return tf.matmul(output[-1], weights['out']) + biases['out']
		</comment>
		<comment id='3' author='Yuvaraj8blr' date='2019-10-21T20:56:01Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33423&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33423&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>