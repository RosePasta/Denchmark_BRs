<bug id='4981' author='jart' open_date='2016-10-15T05:02:59Z' closed_time='2016-10-15T06:45:51Z'>
	<summary>FastGFile ResourceExhaustedError</summary>
	<description>
In &lt;denchmark-link:https://github.com/tensorflow/models/commit/2390974a03a62b1388a004173477418db267074a&gt;tensorflow/models@2390974&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/cshallue&gt;@cshallue&lt;/denchmark-link&gt;
 changed some  calls to  because two RedHat users reported in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/4685&gt;#4685&lt;/denchmark-link&gt;
 that it causes ResourceExhaustedError even though resources don't appear to be exhausted.
We've also had the same issue reported in &lt;denchmark-link:https://github.com/tensorflow/models/issues/531&gt;tensorflow/models#531&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tensorflow/models/issues/489&gt;tensorflow/models#489&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/tensorflow/models/issues/480&gt;tensorflow/models#480&lt;/denchmark-link&gt;
 but we're still waiting to learn if they're using RedHat.
Assigning to &lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
 who has done work on this code in the past.
	</description>
	<comments>
		<comment id='1' author='jart' date='2016-10-15T05:15:49Z'>
		Yeah there was a memory leak by which file handles weren't being closed. Should have been fixed with &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/0f605abad3b30594416dc627860102e3382d6dea#diff-8dc0e318495c91370f8807ef81b589e0&gt;0f605ab#diff-8dc0e318495c91370f8807ef81b589e0&lt;/denchmark-link&gt;

Let me know if this is still an issue
		</comment>
		<comment id='2' author='jart' date='2016-10-17T18:10:13Z'>
		I meet the same issue, but in a different file
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/imagenet/classify_image.py#L141
This example only predict 1 image. if we change this example by using for loop to predict a large number images, it report the same ResourceExhaustedError error
		</comment>
		<comment id='3' author='jart' date='2016-10-17T20:34:28Z'>
		@civilmanxx are you building TensorFlow from source with Bazel at HEAD?
		</comment>
		<comment id='4' author='jart' date='2016-10-17T20:58:52Z'>
		yes, but my local code is not the latest version, which does not include a C++ fix (3 days ago? ) for this issue. Now I use open() instead of read() to avoid this issue.
If I get the lastest code, rebuild at local and use read() will be no issue anymore, is that right?
		</comment>
		<comment id='5' author='jart' date='2016-10-17T21:43:10Z'>
		As far as we know, the issue goes away if you sync to HEAD and build.
		</comment>
	</comments>
</bug>