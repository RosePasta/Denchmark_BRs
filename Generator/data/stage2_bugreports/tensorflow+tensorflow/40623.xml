<bug id='40623' author='Enumaris' open_date='2020-06-19T21:06:42Z' closed_time='2020-06-22T06:45:39Z'>
	<summary>ALBERT from TF Hub doesn't work with GradientTape</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9.12
TensorFlow installed from (source or binary): Automatic installation for GCP deep learning vm
TensorFlow version (use command below): 2.1.0
Tensorflow Hub version: 0.8.0
Python version: 3.7.6
CUDA/cuDNN version: 10.1
GPU model and memory: Nvidia V100

Describe the current behavior
I get an error when trying to run ALBERT from TF-Hub inside a tf.GradientTape() context. The error occurs at the "forward pass" before calling tape.gradient() . The error does not occur when the model call is placed outside of the tf.GradientTape() context.
Describe the expected behavior
No such error should occur and the model should run and gradients should be calculated properly.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow_hub as hub
from tensorflow import keras
import numpy as np

def get_model():
    global max_seq_length
    global batch_size
    input_word_ids = keras.layers.Input(batch_shape=(batch_size, max_seq_length, ), 
                                           dtype=tf.int32,
                                           name="input_word_ids")
    input_mask = keras.layers.Input(batch_shape=(batch_size, max_seq_length, ), 
                                       dtype=tf.int32,
                                       name="input_mask")
    segment_ids = keras.layers.Input(batch_shape=(batch_size, max_seq_length, ), 
                                        dtype=tf.int32,
                                        name="segment_ids")
    albert_layer = hub.KerasLayer("https://tfhub.dev/tensorflow/albert_en_base/1",
                                  trainable=True,
                                  name='albert_layer')
    pooled_output, sequence_output = albert_layer([input_word_ids, input_mask, segment_ids])
    output = keras.layers.Dense(2)(sequence_output)

    model = keras.Model(inputs=(input_word_ids, input_mask, segment_ids),
                        outputs=output)
    print(model.summary())
    return model


batch_size = 4
max_seq_length = 16
model = get_model()

input_ids = 5 * np.ones((4, 16), dtype=np.int32)
input_mask = np.ones((4, 16), dtype=np.int32)
segment_ids = np.zeros((4, 16), dtype=np.int32)

with tf.GradientTape(persistent=True) as tape:
    logits = model({
                  'input_word_ids' : input_ids,
                  'input_mask' : input_mask,
                  'segment_ids' : segment_ids
    })
    print(logits)
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "albert_gradient_tape_test.py", line 42, in &lt;module&gt;
    'segment_ids' : segment_ids
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 717, in call
    convert_kwargs_to_constants=base_layer_utils.call_context().saving)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 891, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py", line 822, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py", line 218, in call
    lambda: f(training=False))
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/smart_cond.py", line 56, in smart_cond
    return false_fn()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py", line 218, in &lt;lambda&gt;
    lambda: f(training=False))
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py", line 438, in _call_attribute
    return instance.__call__(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 568, in __call__
    result = self._call(*args, **kwds)
File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 606, in _call
    results = self._stateful_fn(*args, **kwds)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2362, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/function_deserialization.py", line 241, in restored_function_body
    return _call_concrete_function(function, inputs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/function_deserialization.py", line 72, in _call_concrete_function
    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py", line 99, in _call_flat
    cancellation_manager)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1697, in _call_flat
    forward_function, args_with_tangents = forward_backward.forward()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1423, in forward
    self._inference_args, self._input_tangents)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1185, in forward
    self._forward_and_backward_functions(inference_args, input_tangents))
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1379, in _forward_and_backward_functions
    outputs, inference_args, input_tangents)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 882, in _build_functions_for_outputs
    output)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/default_gradient.py", line 45, in shape_and_dtype
    "of a variable without handle data:\n%s" % str(t))
ValueError: Internal error: Tried to take gradients (or similar) of a variable without handle data:
Tensor("StatefulPartitionedCall:949", shape=(), dtype=resource)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Enumaris' date='2020-06-22T06:45:39Z'>
		&lt;denchmark-link:https://github.com/Enumaris&gt;@Enumaris&lt;/denchmark-link&gt;

Please post TF_Hub related issues in the &lt;denchmark-link:https://github.com/tensorflow/hub/issues&gt;Hub Repo&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='Enumaris' date='2020-06-22T06:45:41Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40623&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40623&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>