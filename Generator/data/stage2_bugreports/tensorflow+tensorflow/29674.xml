<bug id='29674' author='siavash-khodadadeh' open_date='2019-06-12T00:04:59Z' closed_time='2019-10-28T23:52:40Z'>
	<summary>Cannot find the placeholder op that is an input to ReadVariableOp in tf lite conversion.</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2 beta
Python version: 3.6.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: Cuda 10
GPU model and memory: Geforce GTX 1060

Describe the current behavior
I have a pretty complicated model with three different inputs  and I can save and load it with custom objects as a keras model with model.save() and model.load() methods. I want to convert it to  tf lite and I get this error:
ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp
Code to reproduce the issue
&lt;denchmark-code&gt;loss_function = get_loss_function()
    model = tf.keras.models.load_model(save_checkpoint_address, custom_objects={
        'customlayer': CustomLayer,
        'loss_function': loss_function
    })

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;2019-06-11 19:55:42.378746: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2019-06-11 19:55:42.378868: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2019-06-11 19:55:42.434841: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-06-11 19:55:42.434867: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 2213 nodes (393), 3499 edges (663), time = 18.406ms.
2019-06-11 19:55:42.434874: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.785ms.
Traceback (most recent call last):
  File "/home/siavash/programming/ximpa/carim_tensor/convert_to_tflite.py", line 32, in &lt;module&gt;
    convert_saved_model()
  File "/home/siavash/programming/ximpa/carim_tensor/convert_to_tflite.py", line 27, in convert_saved_model
    tflite_model = converter.convert()
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py", line 348, in convert
    self._funcs[0])
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py", line 166, in convert_variables_to_constants_v2
    raise ValueError("Cannot find the Placeholder op that is an input "
ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='siavash-khodadadeh' date='2019-06-17T15:41:56Z'>
		Can you rerun your code with TensorFlow 2.0.0-beta1? There was an issue with beta0 that was fixed in beta1. If that doesn't work, can you provide a reproducible example?
		</comment>
		<comment id='2' author='siavash-khodadadeh' date='2019-07-01T17:31:27Z'>
		I have tried using TensorFlow 2.0.0-beta1 and see the same issue. But I get the error only when trying to convert tf.keras.layers.GRU or tf.keras.layers.LSTM layers to TFLite. Is this an issue with tf.lite.TFLiteConverter.from_saved_model ?
		</comment>
		<comment id='3' author='siavash-khodadadeh' date='2019-07-08T21:23:54Z'>
		I see the same error when using tfjs-converter (tf_saved_model --&gt; tfjs_graph_model).
		</comment>
		<comment id='4' author='siavash-khodadadeh' date='2019-07-12T17:21:55Z'>
		There is currently limited support for LSTMs in TFLite. The documented path is available &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/lstm/g3doc/README.md&gt;here&lt;/denchmark-link&gt;
. We are working on improving our support of control flow based operations and models.
		</comment>
		<comment id='5' author='siavash-khodadadeh' date='2019-10-02T22:35:17Z'>
		&lt;denchmark-link:https://github.com/siavash-khodadadeh&gt;@siavash-khodadadeh&lt;/denchmark-link&gt;
 Is this still an issue? Can you check with  and let us know whether the issue persists with latest TF version. Can you please provide a simple standalone code to reproduce the issue? Thanks!
		</comment>
		<comment id='6' author='siavash-khodadadeh' date='2019-10-07T21:58:37Z'>
		I will try it and let you know. It might take a couple of days since I do not have access to that code now.
		</comment>
		<comment id='7' author='siavash-khodadadeh' date='2019-10-11T13:23:31Z'>
		
@siavash-khodadadeh Is this still an issue? Can you check with TF2.0 and let us know whether the issue persists with latest TF version. Can you please provide a simple standalone code to reproduce the issue? Thanks!

I am using a model with LSTM, After getting the 'Cannot find placeholder op' issue with TF2.0b1, I updated to TF2.0,
I get the following error :
&lt;denchmark-code&gt;
&gt;&gt;&gt; converter = tf.lite.TFLiteConverter.from_keras_model(model)
&gt;&gt;&gt; converter.convert()
2019-10-11 15:16:45.711540: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 1
2019-10-11 15:16:45.741723: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-11 15:16:45.750431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.62
pciBusID: 0000:04:00.0
2019-10-11 15:16:45.750588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-11 15:16:45.750616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-11 15:16:45.750637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-11 15:16:45.750657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-11 15:16:45.750675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-11 15:16:45.750694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-11 15:16:45.750712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-11 15:16:45.753898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-11 15:16:45.753997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-11 15:16:45.754011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-11 15:16:45.754020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-11 15:16:45.760720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4956 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:04:00.0, compute capability: 7.5)
2019-10-11 15:16:45.884323: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-10-11 15:16:45.884563: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 41 nodes (0), 47 edges (0), time = 23.098ms.
2019-10-11 15:16:45.884612: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 41 nodes (0), 47 edges (0), time = 18.946ms.
2019-10-11 15:16:45.884641: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: __forward_cudnn_lstm_with_fallback_23859
2019-10-11 15:16:45.884671: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-10-11 15:16:45.884701: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-10-11 15:16:45.884727: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: __inference_cudnn_lstm_with_fallback_23677
2019-10-11 15:16:45.884756: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2019-10-11 15:16:45.884785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-10-11 15:16:45.884824: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: while_body_23461
2019-10-11 15:16:45.884856: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2019-10-11 15:16:45.884883: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-10-11 15:16:45.884908: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: while_cond_23460
2019-10-11 15:16:45.884935: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2019-10-11 15:16:45.884963: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-10-11 15:16:45.884991: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: __inference___backward_cudnn_lstm_with_fallback_23678_23860
2019-10-11 15:16:45.885025: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2019-10-11 15:16:45.885057: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2019-10-11 15:16:45.885096: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: __inference_standard_lstm_23566_specialized_for_sequential_lstm1_StatefulPartitionedCall_at_graph_to_optimize
2019-10-11 15:16:45.885129: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 72 nodes (0), 102 edges (0), time = 9.739ms.
2019-10-11 15:16:45.885159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 72 nodes (0), 102 edges (0), time = 3.147ms.
2019-10-11 15:16:45.885189: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: __inference_standard_lstm_23566
2019-10-11 15:16:45.885218: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 76 nodes (0), 106 edges (0), time = 2.82ms.
2019-10-11 15:16:45.885248: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 76 nodes (0), 106 edges (0), time = 2.649ms.
Traceback (most recent call last):
  File "&lt;input&gt;", line 1, in &lt;module&gt;
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py", line 405, in convert
    self._funcs[0], lower_control_flow=False)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/convert_to_constants.py", line 414, in convert_variables_to_constants_v2
    function_data = _get_control_flow_function_data(node_defs, tensor_data)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/convert_to_constants.py", line 262, in _get_control_flow_function_data
    arg_types[idx] = get_resource_type(input_name)
  File "/home/d1300/no_backup/d1300/tfRC/lib/python3.6/site-packages/tensorflow_core/python/framework/convert_to_constants.py", line 228, in get_resource_type
    numpy_type = tensor_data[node_name]["data"].dtype
KeyError: 'kernel'

&lt;/denchmark-code&gt;

Here is now the model looks like :
&lt;denchmark-code&gt;def MyModel_keras():
    model = tf.keras.models.Sequential([
        tf.keras.layers.LSTM(conf.n_hidden_lstm, activation='tanh', return_sequences=False, name='lstm1'),
        tf.keras.layers.Dense(conf.n_dense_1, activation='relu', name='dense1'),
        tf.keras.layers.Dense(conf.num_output_classes, activation='softmax', name='dense2')
    ])
    return model
&lt;/denchmark-code&gt;

Is this issue specific to keras models with LSTMs?
Is there a workaround for this?
		</comment>
		<comment id='8' author='siavash-khodadadeh' date='2019-10-11T21:34:14Z'>
		&lt;denchmark-link:https://github.com/Yuvaraj8blr&gt;@Yuvaraj8blr&lt;/denchmark-link&gt;
 Please check the comment &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29674#issuecomment-510966279&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='9' author='siavash-khodadadeh' date='2019-10-14T12:07:58Z'>
		I'm using the TF 2.0 gpu version and still get this error with trt.TrtGraphConverterV2:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "optimize_graphv2.py", line 33, in &lt;module&gt;
    main(args)
  File "optimize_graphv2.py", line 22, in main
    converter.convert()
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py", line 960, in convert
    frozen_func = convert_to_constants.convert_variables_to_constants_v2(func)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/convert_to_constants.py", line 479, in convert_variables_to_constants_v2
    raise ValueError("Cannot find the Placeholder op that is an input "
ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.```

&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='siavash-khodadadeh' date='2019-10-14T15:47:16Z'>
		&lt;denchmark-link:https://github.com/PolinaDemochkina&gt;@PolinaDemochkina&lt;/denchmark-link&gt;
 Please provide a simple standalone code to reproduce the issue. Please check the &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29674#issuecomment-541231768&gt;link&lt;/denchmark-link&gt;
 before providing standalone code. Thanks!
		</comment>
		<comment id='11' author='siavash-khodadadeh' date='2019-10-15T08:15:53Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 I am not using TFLite, but I guess the issue has to do with the LSTM layer in my model. Tried to replace this layer with GRU, however, I got the same mistake. Does the optimizer not support any kind of recurrent layers?
Here's the code to reproduce the issue:
&lt;denchmark-code&gt;from tensorflow.keras import layers
from tensorflow.keras import optimizers
from tensorflow.keras.datasets import cifar100
import numpy as np
import tensorflow as tf
from tensorflow import keras
keras.backend.clear_session()
keras.backend.set_learning_phase(0)
from tensorflow.python.compiler.tensorrt import trt_convert as trt
import os

os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

(x_train, y_train), (x_test, y_test) = cifar100.load_data()
x_train = np.float32(x_train)[:64*(x_train.shape[0]//64)]
x_train /= 255.0
i_shape = x_train[0].shape

inputs = layers.Input(i_shape)
base_model = keras.models.Sequential([
    layers.Conv2D(128, 3, padding='same', strides=(2, 2)),
    layers.BatchNormalization(),
    layers.LeakyReLU(0.2),

    layers.Conv2D(256, 3, padding='same', strides=(2, 2)),
    layers.BatchNormalization(),
    layers.LeakyReLU(0.2),

    layers.Conv2D(512*100, 3, padding='same', strides=(2, 2)),
    layers.BatchNormalization(),
    layers.LeakyReLU(0.2),
    layers.Flatten(),
    layers.Dense(5*128),
    layers.Reshape((5, 128)),
    layers.LSTM(128),
    layers.Flatten(),
])(inputs)

prediction = layers.Dense(100, activation='softmax')(base_model)
model = keras.Model(inputs=inputs, outputs=prediction)
optimizer = optimizers.Adam(0.00001)
model.compile(optimizer, 'categorical_crossentropy', metrics=['accuracy'])
print(model.summary())
saved_model_dir = os.getcwd()
output_directory = os.getcwd()
tf.saved_model.save(model, saved_model_dir)

# graph quantization
loaded = tf.saved_model.load(saved_model_dir)

params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(
    precision_mode='FP16',
    is_dynamic_op=True,
    maximum_cached_engines=16)
converter = trt.TrtGraphConverterV2(
    input_saved_model_dir=saved_model_dir,
    input_saved_model_tags="serve",
    input_saved_model_signature_key="serving_default",
    conversion_params=params)
converter.convert()
saved_model_dir_trt = output_directory
converter.save(saved_model_dir_trt)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='siavash-khodadadeh' date='2019-10-15T16:13:46Z'>
		&lt;denchmark-link:https://github.com/PolinaDemochkina&gt;@PolinaDemochkina&lt;/denchmark-link&gt;
 Your issues is different from original issue (is with TF lite). Can you please post a new issue with details, platform, TF version and standalone code (as above). Thanks!
		</comment>
		<comment id='13' author='siavash-khodadadeh' date='2019-10-28T23:52:40Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='14' author='siavash-khodadadeh' date='2019-10-28T23:52:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29674&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29674&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='siavash-khodadadeh' date='2020-01-31T20:58:08Z'>
		Run on tensorflow 2.1.0
&lt;denchmark-code&gt;import tensorflow as tf

def build_model(vocab_size, embedding_dim, rnn_units, batch_size):
  model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim,
                              batch_input_shape=[batch_size, embedding_dim]),
    tf.keras.layers.LSTM(rnn_units,
                        return_sequences=True,
                        stateful=False,
                        recurrent_activation='sigmoid',
                        recurrent_initializer='glorot_uniform'),
    tf.keras.layers.Dense(vocab_size)
  ])
  return model

embedding_dim = 100
units = 256
vocab_size = 300
batch_size = 32

model = build_model(vocab_size, embedding_dim, units, batch_size)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

from tensorflow.python.keras.saving import saving_utils as _saving_utils
from tensorflow.python.framework import convert_to_constants as _convert_to_constants

tf.keras.backend.set_learning_phase(False)
func = _saving_utils.trace_model_call(model)
concrete_func = func.get_concrete_function()
frozen_func = _convert_to_constants.convert_variables_to_constants_v2(concrete_func)
&lt;/denchmark-code&gt;

This produces the same error
Can you reopen this issue?
		</comment>
		<comment id='16' author='siavash-khodadadeh' date='2020-01-31T21:01:21Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Can you reopen this issue?
		</comment>
		<comment id='17' author='siavash-khodadadeh' date='2020-01-31T21:24:51Z'>
		&lt;denchmark-link:https://github.com/jakesabathia2&gt;@jakesabathia2&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 Can you please open a new issue with more details on the issue. It will be easy for others to follow learn for your issue. Thanks!
		</comment>
		<comment id='18' author='siavash-khodadadeh' date='2020-01-31T23:08:31Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/36391&gt;#36391&lt;/denchmark-link&gt;

		</comment>
		<comment id='19' author='siavash-khodadadeh' date='2020-02-11T09:46:02Z'>
		I have similar issue with the model NOT using LSTMs - I posted it here: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/35987&gt;#35987&lt;/denchmark-link&gt;

(with latest tf-nightly and experimental converter turned on)
File "[...]/miniconda3/envs/tf-nightly-py3/lib/python3.7/site-packages/tensorflow_core/python/framework/convert_to_constants.py", line 526, in _convert_variables_to_constants_v2_impl raise ValueError("Cannot find the Placeholder op that is an input " ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.
		</comment>
	</comments>
</bug>