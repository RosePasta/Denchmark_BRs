<bug id='46092' author='kukdh1' open_date='2020-12-31T11:32:52Z' closed_time='2021-01-06T08:31:19Z'>
	<summary>Wrong output dimension calculation of StrideSlice operation on TensorFlow Lite.</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 8
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): Both pip and source build
TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
Python version: 3.6.8
Bazel version (if compiling from source): 3.7.1
GCC/Compiler version (if compiling from source): 8.3.1
CUDA/cuDNN version: CUDA 11.1 / cuDNN 8
GPU model and memory: RTX3090 24GB

Describe the current behavior
The StridedSlice operation on TensorFlow Lite calculates output dimension incorrectly.
I'm developing some custom operations for both TensorFlow and TensorFlow Lite.
While I debugging my custom operation, inference fails only on TensorFlow Lite.
I found that  operation of TensorFlow Lite calculates output dimension incorrectly.
I added some  function to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/lite/kernels/strided_slice.cc#L185&gt;tflite::ops::builtin::strided_slice::Eval&lt;/denchmark-link&gt;
:
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
  StridedSliceContext op_context(context, node);

  printf("**** [STRIDED_SLICE] Input [");
  for (int i = 0; i &lt; NumDimensions(op_context.input); i++) {
    printf("%d, ", SizeOfDimension(op_context.input, i));
  }
  printf("]\n**** [STRIDED_SLICE] Begin: ");
  for (int i = 0; i &lt; SizeOfDimension(op_context.begin, 0); i++) {
    printf("%d, ", GetTensorData&lt;int32_t&gt;(op_context.begin)[i]);
  }
  printf("\n**** [STRIDED_SLICE] End: ");
  for (int i = 0; i &lt; SizeOfDimension(op_context.end, 0); i++) {
    printf("%d, ", GetTensorData&lt;int32_t&gt;(op_context.end)[i]);
  }
  printf("\n**** [STRIDED_SLICE] Strides: ");
  for (int i = 0; i &lt; SizeOfDimension(op_context.strides, 0); i++) {
    printf("%d, ", GetTensorData&lt;int32_t&gt;(op_context.strides)[i]);
  }
  printf("\n");

  if (IsDynamicTensor(op_context.output)) {
    TF_LITE_ENSURE_OK(context, ResizeOutputTensor(context, &amp;op_context));
  }
  StridedSliceParams op_params = BuildStridedSliceParams(&amp;op_context);

  printf("**** [STRIDED_SLICE] Output [");
  for (int i = 0; i &lt; NumDimensions(op_context.output); i++) {
    printf("%d, ", SizeOfDimension(op_context.output, i));
  }
  printf("]\n");
And I got following logs:
&lt;denchmark-code&gt;**** [STRIDED_SLICE] Input [1656, 8, 32, ]
**** [STRIDED_SLICE] Begin: 0, 0, 0, 
**** [STRIDED_SLICE] End: 893, 
**** [STRIDED_SLICE] Strides: 1, 1, 1, 
**** [STRIDED_SLICE] Output [893, 8, 0, ]
&lt;/denchmark-code&gt;

Describe the expected behavior
After strided slicing, output dimension should be [893, 8, 32, ] in above example.

I wrote a smallest &lt;denchmark-link:https://github.com/kukdh1/tflite_buf_report/blob/master/test_strided_slice.py&gt;reproducible code&lt;/denchmark-link&gt;
.
The  keras layer creates read-only  with size of [128, 8, 32].
After ten s, I saved the model into tflite model file.
On TensorFlow (python, no code modification -- installed by pip tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl) it calculates output dimension correctly.
&lt;denchmark-code&gt;TEST: Input: [128, 8, 32] SiliceTo: 53 Output: (53, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 38 Output: (38, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 64 Output: (64, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 100 Output: (100, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 106 Output: (106, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 90 Output: (90, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 126 Output: (126, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 122 Output: (122, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 62 Output: (62, 8, 32)
TEST: Input: [128, 8, 32] SiliceTo: 99 Output: (99, 8, 32)
&lt;/denchmark-code&gt;

I checked the stored model with &lt;denchmark-link:https://netron.app/&gt;netron&lt;/denchmark-link&gt;
:
&lt;denchmark-link:https://user-images.githubusercontent.com/6904750/103407030-52be8400-4ba0-11eb-8344-2e2d1b85e0d2.png&gt;&lt;/denchmark-link&gt;

And it shows that  has input  of size  and output  has size .
To test on TensorFlow Lite, I wrote &lt;denchmark-link:https://github.com/kukdh1/tflite_buf_report/blob/master/strided_slice.cc&gt;simple inference code&lt;/denchmark-link&gt;
 with TensorFlow Lite C++ API.
It randomly selects input  (slice index) and print the output dimension.
I used the source code (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/582c8d236cb079023657287c318ff26adb239002&gt;582c8d2&lt;/denchmark-link&gt;
 == v2.4.0) with above   modification.
I built  with following command:

And the content of  is:
&lt;denchmark-code&gt;build --action_env PYTHON_BIN_PATH="/home/kukdh1/.virtualenvs/tf_develop/bin/python3"
build --action_env PYTHON_LIB_PATH="/home/kukdh1/.virtualenvs/tf_develop/lib/python3.6/site-packages"
build --python_path="/home/kukdh1/.virtualenvs/tf_develop/bin/python3"
build --config=xla
build --action_env CUDA_TOOLKIT_PATH="/usr/local/cuda-11.1"
build --action_env TF_CUDA_COMPUTE_CAPABILITIES="7.5,8.6"
build --action_env LD_LIBRARY_PATH="/usr/local/cuda-11.1/lib64:"
build --action_env GCC_HOST_COMPILER_PATH="/usr/bin/gcc"
build --config=cuda
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_env=LD_LIBRARY_PATH
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only
build --action_env TF_CONFIGURE_IOS="0"
&lt;/denchmark-code&gt;

I built test program with  (&lt;denchmark-link:https://github.com/kukdh1/tflite_buf_report/blob/master/CMakeLists.txt&gt;CMakeLists.txt&lt;/denchmark-link&gt;
)
When I ran the test program, I got following result:
&lt;denchmark-code&gt;$ CUDA_VISIBLE_DEVICES=-1 ./tflite-strided-slice strided_slice.tflite 
2020-12-31 19:47:18.088431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
**** [STRIDED_SLICE] Input [128, 8, 32, ]
**** [STRIDED_SLICE] Begin: 0, 0, 0, 
**** [STRIDED_SLICE] End: 103, 
**** [STRIDED_SLICE] Strides: 1, 1, 1, 
**** [STRIDED_SLICE] Output [103, 0, 32, ]
Input: 103
Output: [103 0 32 ]
########## PRINT INTERPRETER STATE BEGIN ##########
Interpreter has 6 tensors and 2 nodes
Inputs: 0
Outputs: 5

Tensor   0 input_1              kTfLiteInt32   kTfLiteCustom          4 bytes ( 0.0 MB) 
Tensor   1 simple_layer/ReadVariableOp/resource kTfLiteFloat32   kTfLiteMmapRo     131072 bytes ( 0.1 MB)  128 8 32
Tensor   2 simple_layer/strided_slice kTfLiteInt32   kTfLiteMmapRo         12 bytes ( 0.0 MB)  3
Tensor   3 simple_layer/strided_slice1 kTfLiteInt32   kTfLiteMmapRo         12 bytes ( 0.0 MB)  3
Tensor   4 simple_layer/strided_slice/stack_1 kTfLiteInt32  kTfLiteArenaRw          4 bytes ( 0.0 MB)  1
Tensor   5 Identity             kTfLiteFloat32  kTfLiteDynamic          0 bytes ( 0.0 MB)  103 0 32

Node   0 Operator Builtin Code  83 PACK
  Inputs: 0
  Outputs: 4
Node   1 Operator Builtin Code  45 STRIDED_SLICE
  Inputs: 1 2 4 3
  Outputs: 5
########### PRINT INTERPRETER STATE END ###########
&lt;/denchmark-code&gt;

The output Tensor has size of [103, 0, 32] not [103, 8, 32].
I think this is a bug on &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/lite/kernels/strided_slice.cc#L101&gt;tflite::ops::builtin::strided_slice::ResizeOutputTensor&lt;/denchmark-link&gt;
.
Please let me know if I did something wrong.

You can find all the code snippets I used to reproduce the problem at &lt;denchmark-link:https://github.com/kukdh1/tflite_buf_report&gt;here&lt;/denchmark-link&gt;
.
(Download all dependencies by running  at )
You can find tflite model too.
P.S. The dimension error is quite random. Sometimes it calculates correctly. Sometimes innermost (axis=2) dimension becomes zero. Sometimes middle (axis=1) dimension becoms zero, Sometimes both (axis=1, axis=2) dimensions become zero.
P.S. 2. I double checked with unmodified tensorflow source downloaded with:
wget https://github.com/tensorflow/tensorflow/archive/v2.4.0.tar.gz
on Ubuntu 18.04.5 (different machine) with GCC 7.5.0, bazel 3.7.2 and Python 3.6.9.
Same command used to build libtensorflowlite.so and .tf_configure.bazelrc is:
&lt;denchmark-code&gt;build --action_env PYTHON_BIN_PATH="/home/kukdh1/.virtualenvs/tensorflow/bin/python3"
build --action_env PYTHON_LIB_PATH="/home/kukdh1/.virtualenvs/tensorflow/lib/python3.6/site-packages"
build --python_path="/home/kukdh1/.virtualenvs/tensorflow/bin/python3"
build --config=xla
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
build --action_env TF_CONFIGURE_IOS="0"
&lt;/denchmark-code&gt;

The output on Ubuntu machine was (one example):
&lt;denchmark-code&gt;Input: 41
Output: [41 0 0 ]
########## PRINT INTERPRETER STATE BEGIN ##########
Interpreter has 6 tensors and 2 nodes
Inputs: 0
Outputs: 5

Tensor   0 input_1              kTfLiteInt32   kTfLiteCustom          4 bytes ( 0.0 MB)
Tensor   1 simple_layer/ReadVariableOp/resource kTfLiteFloat32   kTfLiteMmapRo     131072 bytes ( 0.1 MB)  128 8 32
Tensor   2 simple_layer/strided_slice kTfLiteInt32   kTfLiteMmapRo         12 bytes ( 0.0 MB)  3
Tensor   3 simple_layer/strided_slice1 kTfLiteInt32   kTfLiteMmapRo         12 bytes ( 0.0 MB)  3
Tensor   4 simple_layer/strided_slice/stack_1 kTfLiteInt32  kTfLiteArenaRw          4 bytes ( 0.0 MB)  1
Tensor   5 Identity             kTfLiteFloat32  kTfLiteDynamic          0 bytes ( 0.0 MB)  41 0 0

Node   0 Operator Builtin Code  83 PACK
  Inputs: 0
  Outputs: 4
Node   1 Operator Builtin Code  45 STRIDED_SLICE
  Inputs: 1 2 4 3
  Outputs: 5
########### PRINT INTERPRETER STATE END ###########
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='kukdh1' date='2021-01-02T05:29:20Z'>
		Hi,
I found the function BuildStridedSliceParams in tensorflow/lite/kernels/strided_slice.cc was the problem.
The following loop assumes the dimension of begin, end and strides are same, but in my case, dimension of begin and strides was 3 while dimension of end was 1.
  int begin_count = GetTensorShape(op_context-&gt;begin).Dims(0);
  for (int i = 0; i &lt; begin_count; ++i) {
    op_params.start_indices[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;begin)[i];
    op_params.stop_indices[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;end)[i];
    op_params.strides[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;strides)[i];
  }
So I changed the code to:
diff --git a/tensorflow/lite/kernels/strided_slice.cc b/tensorflow/lite/kernels/strided_slice.cc
index d10e99c1..26f3ab5c 100644
--- a/tensorflow/lite/kernels/strided_slice.cc
+++ b/tensorflow/lite/kernels/strided_slice.cc
@@ -78,19 +78,29 @@ StridedSliceParams BuildStridedSliceParams(StridedSliceContext* op_context) {
   op_params.shrink_axis_mask = op_context-&gt;params-&gt;shrink_axis_mask;
 
   int begin_count = GetTensorShape(op_context-&gt;begin).Dims(0);
-  for (int i = 0; i &lt; begin_count; ++i) {
-    op_params.start_indices[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;begin)[i];
-    op_params.stop_indices[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;end)[i];
-    op_params.strides[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;strides)[i];
-  }
+  int end_count = GetTensorShape(op_context-&gt;end).Dims(0);
+  int strides_count = GetTensorShape(op_context-&gt;strides).Dims(0);
+
+  for (int i = 0; i &lt; op_context-&gt;dims; ++i) {
+    if (i &lt; begin_count) {
+      op_params.start_indices[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;begin)[i];
+    } else {
+      op_params.start_indices[i] = 0;
+      op_params.begin_mask |= (1 &lt;&lt; i);
+    }
 
-  // If the length of begin and end smaller than number of input dims, set the
-  // mask bit of begin and end for that index.
-  for (int i = begin_count; i &lt; op_context-&gt;dims; ++i) {
-    op_params.start_indices[i] = op_params.stop_indices[i] = 0;
-    op_params.strides[i] = 1;
-    op_params.begin_mask |= (1 &lt;&lt; i);
-    op_params.end_mask |= (1 &lt;&lt; i);
+    if (i &lt; end_count) {
+      op_params.stop_indices[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;end)[i];
+    } else {
+      op_params.stop_indices[i] = 0;
+      op_params.end_mask |= (1 &lt;&lt; i);
+    }
+
+    if (i &lt; strides_count) {
+      op_params.strides[i] = GetTensorData&lt;int32_t&gt;(op_context-&gt;strides)[i];
+    } else {
+      op_params.strides[i] = 1;
+    }
   }
   return op_params;
 }
And it solves the problem.
(In below interpreter state, Tensor 2 == begin and Tensor 3 == strides has dimension of 3, but Tensor 4 == end has dimension of 1).
&lt;denchmark-code&gt;Input: 41
Output: [41 8 32 ]
########## PRINT INTERPRETER STATE BEGIN ##########
Interpreter has 6 tensors and 2 nodes
Inputs: 0
Outputs: 5

Tensor   0 input_1              kTfLiteInt32   kTfLiteCustom          4 bytes ( 0.0 MB) 
Tensor   1 simple_layer/ReadVariableOp/resource kTfLiteFloat32   kTfLiteMmapRo     131072 bytes ( 0.1 MB)  128 8 32
Tensor   2 simple_layer/strided_slice kTfLiteInt32   kTfLiteMmapRo         12 bytes ( 0.0 MB)  3
Tensor   3 simple_layer/strided_slice1 kTfLiteInt32   kTfLiteMmapRo         12 bytes ( 0.0 MB)  3
Tensor   4 simple_layer/strided_slice/stack_1 kTfLiteInt32  kTfLiteArenaRw          4 bytes ( 0.0 MB)  1
Tensor   5 Identity             kTfLiteFloat32  kTfLiteDynamic      41984 bytes ( 0.0 MB)  41 8 32

Node   0 Operator Builtin Code  83 PACK
  Inputs: 0
  Outputs: 4
Node   1 Operator Builtin Code  45 STRIDED_SLICE
  Inputs: 1 2 4 3
  Outputs: 5
########### PRINT INTERPRETER STATE END ###########
&lt;/denchmark-code&gt;

This patch solves the problem, but I'm not sure that fixing BuildStridedSliceParams function is correct solution.
Maybe, in conversion process, all three (begin, end and strides) tensors should not expanded or should be expanded.
(I used MLIR for the conversion)
Thanks.
		</comment>
		<comment id='2' author='kukdh1' date='2021-01-04T22:33:51Z'>
		Hi &lt;denchmark-link:https://github.com/kukdh1&gt;@kukdh1&lt;/denchmark-link&gt;
, conversion as well as output seem to be correct in tf-nightly. Can you try it on nightly version instead?
&lt;denchmark-link:https://colab.research.google.com/drive/1h8MnLZdmRePyHecXzJRRQfAw9-MRwPEA?usp=sharing&gt;https://colab.research.google.com/drive/1h8MnLZdmRePyHecXzJRRQfAw9-MRwPEA?usp=sharing&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/11615393/103586386-d5458d00-4e99-11eb-922a-2261aa38005b.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='kukdh1' date='2021-01-05T07:12:17Z'>
		Hi,
I just installed  and the converted result has correct input dimensions.
&lt;denchmark-link:https://user-images.githubusercontent.com/6904750/103616503-e95bbe00-4f6f-11eb-96f9-1a8601c7caad.png&gt;&lt;/denchmark-link&gt;

And I compiled  with master branch &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/bd68b49a9dd9067ead26b36b391a7ad4de7eee9f&gt;bd68b49&lt;/denchmark-link&gt;
 and it calculates output dimension as well.
&lt;denchmark-code&gt;Input: 103
Output: [103 8 32 ]
########## PRINT INTERPRETER STATE BEGIN ##########
Interpreter has 6 tensors and 2 nodes
Inputs: 0
Outputs: 5

Tensor   0 input_1              kTfLiteInt32   kTfLiteCustom          4 bytes ( 0.0 MB)
Tensor   1 simple_layer/ReadVariableOp/resource kTfLiteFloat32   kTfLiteMmapRo     131072 bytes ( 0.1 MB)  128 8 32
Tensor   2 simple_layer/strided_slice/stack kTfLiteInt32   kTfLiteMmapRo          4 bytes ( 0.0 MB)  1
Tensor   3 simple_layer/strided_slice/stack_2 kTfLiteInt32   kTfLiteMmapRo          4 bytes ( 0.0 MB)  1
Tensor   4 simple_layer/strided_slice/stack_1 kTfLiteInt32  kTfLiteArenaRw          4 bytes ( 0.0 MB)  1
Tensor   5 Identity             kTfLiteFloat32  kTfLiteDynamic     105472 bytes ( 0.1 MB)  103 8 32

Node   0 Operator Builtin Code  83 PACK
  Inputs: 0
  Outputs: 4
Node   1 Operator Builtin Code  45 STRIDED_SLICE
  Inputs: 1 2 4 3
  Outputs: 5
########### PRINT INTERPRETER STATE END ###########
&lt;/denchmark-code&gt;

I hope this will be fixed in v2.4.1.
Thanks.
		</comment>
		<comment id='4' author='kukdh1' date='2021-01-05T10:03:03Z'>
		&lt;denchmark-link:https://github.com/kukdh1&gt;@kukdh1&lt;/denchmark-link&gt;

Please move the issue to closed status if resolved.
		</comment>
		<comment id='5' author='kukdh1' date='2021-01-06T08:31:20Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46092&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46092&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>