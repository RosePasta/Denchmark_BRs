<bug id='30713' author='oliverdutton' open_date='2019-07-15T15:14:03Z' closed_time='2019-08-28T19:51:35Z'>
	<summary>Gradient tape with tf.math.reduce_euclidean_norm disconnects</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary (Conda)
TensorFlow version (use command below): 2.0.0b1
Python version: 3.7.3
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: N/A
GPU model and memory: N/A (Running on CPU)

Describe the current behavior
Using GradientTape to track the gradients using tf.math.reduce_euclidean_norm directly the gradient disconnects and returns 'None'.
Describe the expected behavior
I expect a gradient to be returned. If I decompose the function into the three constituent sequential operators (square the elements, sum them [reducing the dimension] and square rooting the resulting tensor) I get the gradient connecting up as expected.
Code to reproduce the issue
import tensorflow as tf
x = tf.constant([3.0,1.2,17,0])
''' Calculate euclidian distance of an nD vector by tf implementation'''
with tf.GradientTape() as t2:
t2.watch(x)
z2 = tf.math.reduce_euclidean_norm(x, axis = -1)
dz2_dx = t2.gradient(z2,x)
print("z: {}, \nGradients: {}".format(z2, dz2_dx))
''' Calculate euclidian distance of an nD vector by decomposed operations'''
with tf.GradientTape() as t:
t.watch(x)
x_sq = tf.math.square(x)
x_sum_sq = tf.math.reduce_sum(x_sq, axis = 0)
z = tf.math.sqrt(x_sum_sq)
dz_dx = t.gradient(z, x)
print("z: {}, \nGradients: {}".format(z, dz_dx))
Other info / logs
The example code gives:
z: 17.30433464050293,
Gradients: None
z: 17.30433464050293,
Gradients: [0.17336696 0.06934679 0.9824128  0.        ]
With the reduce_euclidean_distance() operator the gradient is dropped.
	</description>
	<comments>
		<comment id='1' author='oliverdutton' date='2019-07-16T11:03:46Z'>
		I have tried on colab with TF version 2.0 beta1 and was able to reproduce the issue.Thanks!
		</comment>
		<comment id='2' author='oliverdutton' date='2019-08-22T03:54:22Z'>
		FYI, It's just not implemented yet 


tensorflow/tensorflow/python/ops/math_grad.py


         Line 53
      in
      c9443f0






 # TODO(rmlarsen): Implement gradient. 





I think this could be confusing to users as it returns None without any explanation.  This is a simple example but for a complex real-world numerical script, it could take good amount of time figuring out which part was the problem.
Would it make sense to have a notion of "not implemented" which raises an exception or prints an error/warning message instead of current ops.NotDifferentiale?
		</comment>
		<comment id='3' author='oliverdutton' date='2019-08-22T15:44:42Z'>
		That is a very serious bug. ops.NotDifferentiable is to be used only on purpose when an operation is not differentiable at all; for operations which are differentiable you do get an exception if you neither register a gradient nor mark it as notdifferentiable.
However at this point removing this annotation would likely break existing code, so we should fix this by implementing the gradient. Can you take a stab at it, &lt;denchmark-link:https://github.com/kkimdev&gt;@kkimdev&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='4' author='oliverdutton' date='2019-08-22T16:08:08Z'>
		sg, started.
		</comment>
		<comment id='5' author='oliverdutton' date='2019-08-28T19:51:35Z'>
		Should be fixed on the master branch &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/f2d7bc27a00f2ee08335c00782f98af0d04a08e2&gt;f2d7bc2&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='oliverdutton' date='2019-08-28T19:51:36Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30713&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30713&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>