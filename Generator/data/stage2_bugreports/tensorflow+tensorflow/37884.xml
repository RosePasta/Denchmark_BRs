<bug id='37884' author='LAWSSSS' open_date='2020-03-25T02:05:46Z' closed_time='2020-06-04T08:34:27Z'>
	<summary>Try to convert a custom SSD_MobileNet model to tflite, but get the error: Check failed: dim_size &amp;gt;= 1 (0 vs. 1)</summary>
	<description>
System information:


Windows 10


Python 3.6.10


Tensorflow 2.0.0


&lt;denchmark-code&gt;import tensorflow as tf
# pb path
path = "C:/Users/LAWSSSS/Desktop/convert_pb_2_tflite/frozen_inference_graph-SteelRoll.pb"
# input and output
inputs = ["image_tensor"]
outputs = ["detection_boxes", "detection_classes", "detection_scores", "num_detections"]
# convert pb to tflite
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(path, inputs, outputs, input_shapes={"image_tensor":[1,640,360,3]})
converter.post_training_quantize = True
tflite_model = converter.convert()
# save
open("frozen_inference_graph-SteelRoll.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

However, when I run the above code, error messages will show up as the following:
&lt;denchmark-code&gt;2020-03-25 09:48:40.298641: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
C:\Users\LAWSSSS\.conda\envs\tfcpu\lib\site-packages\tensorflow_core\lite\python\lite.py:846: UserWarning: Property post_training_quantize is deprecated, please use optimizations=[Optimize.DEFAULT] instead.
  " instead." % name)
Traceback (most recent call last):
  File "C:/Users/LAWSSSS/Desktop/convert_pb_2_tflite/test.py", line 18, in &lt;module&gt;
    tflite_model = converter.convert()
  File "C:\Users\LAWSSSS\.conda\envs\tfcpu\lib\site-packages\tensorflow_core\lite\python\lite.py", line 983, in convert
    **converter_kwargs)
  File "C:\Users\LAWSSSS\.conda\envs\tfcpu\lib\site-packages\tensorflow_core\lite\python\convert.py", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "C:\Users\LAWSSSS\.conda\envs\tfcpu\lib\site-packages\tensorflow_core\lite\python\convert.py", line 200, in toco_convert_protos
    raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-03-25 09:48:42.916392: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.916652: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.916927: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2020-03-25 09:48:42.917171: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.917396: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.917617: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.917915: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.918138: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.918357: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.918575: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.918843: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.919088: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.919315: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2020-03-25 09:48:42.919565: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.919837: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.920075: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.920288: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2020-03-25 09:48:42.920582: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.920799: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.921020: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-03-25 09:48:42.921263: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.921479: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.921704: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-03-25 09:48:42.922236: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2020-03-25 09:48:42.922514: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2020-03-25 09:48:42.922751: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2020-03-25 09:48:42.923035: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2020-03-25 09:48:42.923274: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2020-03-25 09:48:42.923526: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2020-03-25 09:48:42.947959: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.948212: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.948444: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.948713: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.949022: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.949258: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.949485: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.949774: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.950029: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2020-03-25 09:48:42.950303: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2020-03-25 09:48:42.950636: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2020-03-25 09:48:42.950916: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3
2020-03-25 09:48:42.951170: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.951404: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.951638: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.951923: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.952150: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.952382: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.952614: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3
2020-03-25 09:48:42.952849: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.953080: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.953305: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.953526: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.953802: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.954023: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.954241: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.954527: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.954812: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond
2020-03-25 09:48:42.955065: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.955311: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.955544: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.955805: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2020-03-25 09:48:42.956042: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.956253: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.956469: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.956688: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2020-03-25 09:48:42.956921: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.957130: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.957348: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.957562: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2020-03-25 09:48:42.957856: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.958068: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.958285: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.958497: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3
2020-03-25 09:48:42.958953: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV3
2020-03-25 09:48:42.959338: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV3
2020-03-25 09:48:42.959836: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-03-25 09:48:42.960451: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-03-25 09:48:42.961178: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.961393: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.961612: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-03-25 09:48:42.961940: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.962246: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.962459: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-03-25 09:48:42.962731: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.962943: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.963160: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-03-25 09:48:42.963396: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter
2020-03-25 09:48:42.963608: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20
2020-03-25 09:48:42.963905: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-03-25 09:48:42.964158: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2020-03-25 09:48:42.964369: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2020-03-25 09:48:42.964578: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2020-03-25 09:48:42.964863: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit
2020-03-25 09:48:42.965125: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2020-03-25 09:48:42.965416: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2020-03-25 09:48:42.965733: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2020-03-25 09:48:42.965983: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2020-03-25 09:48:42.966222: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2020-03-25 09:48:42.966470: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2020-03-25 09:48:42.966816: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3
2020-03-25 09:48:42.967131: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3
2020-03-25 09:48:43.049924: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1791 operators, 3037 arrays (0 quantized)
2020-03-25 09:48:43.216798: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1770 operators, 2983 arrays (0 quantized)
2020-03-25 09:48:43.404253: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1770 operators, 2983 arrays (0 quantized)
2020-03-25 09:48:43.509305: F tensorflow/lite/toco/graph_transformations/resolve_constant_slice.cc:59] Check failed: dim_size &gt;= 1 (0 vs. 1)
Fatal Python error: Aborted
&lt;/denchmark-code&gt;

How do I solve Check failed: dim_size &gt;= 1 (0 vs. 1).?
Thanks in advance.
	</description>
	<comments>
		<comment id='1' author='LAWSSSS' date='2020-03-25T02:48:40Z'>
		Also, I notice that there are many "unsupported operation" showing up in the error message, do these faults have anything to do with my problem?
		</comment>
		<comment id='2' author='LAWSSSS' date='2020-03-26T09:14:27Z'>
		&lt;denchmark-link:https://github.com/LAWSSSS&gt;@LAWSSSS&lt;/denchmark-link&gt;

Please try including the code before tflite=converter.convert()
&lt;denchmark-code&gt;converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
&lt;/denchmark-code&gt;

For more information refer &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/35590&gt;#35590&lt;/denchmark-link&gt;

If the issue is still not resolved please provide us the complete code snippet used  along with supported files.Thanks!
		</comment>
		<comment id='3' author='LAWSSSS' date='2020-03-26T09:33:28Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 Thanks for the kind response. I added the code before . However, the same error still exists. Here is my complete code snippet:
&lt;denchmark-code&gt;import tensorflow as tf
# pb path
path = "C:/Users/LAWSSSS/Desktop/convert_pb_2_tflite/frozen_inference_graph-SteelRoll.pb"
# input and output
inputs = ["image_tensor"]
outputs = ["detection_boxes", "detection_classes", "detection_scores", "num_detections"]
# convert pb to tflite
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(path, inputs, outputs, input_shapes={"image_tensor":[1,640,360,3]})
converter.post_training_quantize = True

converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()
# save
open("frozen_inference_graph-SteelRoll.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

And here is my model file if you need to check out: &lt;denchmark-link:https://github.com/LAWSSSS/Frozen_Pb/blob/master/frozen_inference_graph-SteelRoll.pb&gt;frozen_model_file&lt;/denchmark-link&gt;
. I trained it with SSD MobileNet V2.
Thanks for your help in advance.
		</comment>
		<comment id='4' author='LAWSSSS' date='2020-03-31T17:09:49Z'>
		&lt;denchmark-link:https://github.com/LAWSSSS&gt;@LAWSSSS&lt;/denchmark-link&gt;
 I am not sure how you created the *.pb file. It is throwing data type mismatch error. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/0ecb928c2d2df120d05a82259c485049/untitled46.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Can you please let us know what steps you followed to create *.pb file? Thanks!
&lt;denchmark-code&gt;loc("Preprocessor/map/while/LoopCond"): error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit signless integer or 32-bit signless integer or 64-bit signless integer or TFLite quint8 type or 8-bit unsigned integer or complex type with 32-bit float elements values, but got 'tensor&lt;2x!tf.resource&lt;tensor&lt;*xf32&gt;&gt;&gt;'
loc("Preprocessor/map/while/LoopCond"): error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit signless integer or 32-bit signless integer or 64-bit signless integer or TFLite quint8 type or 8-bit unsigned integer or complex type with 32-bit float elements values, but got 'tensor&lt;2x!tf.resource&lt;tensor&lt;*xf32&gt;&gt;&gt;'
loc("Preprocessor/map/while/LoopCond"): error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit signless integer or 32-bit signless integer or 64-bit signless integer or TFLite quint8 type or 8-bit unsigned integer or complex type with 32-bit float elements values, but got 'tensor&lt;2x!tf.resource&lt;tensor&lt;*xi32&gt;&gt;&gt;'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='LAWSSSS' date='2020-04-08T00:29:14Z'>
		&lt;denchmark-link:https://github.com/LAWSSSS&gt;@LAWSSSS&lt;/denchmark-link&gt;
 Can you please take a look at my previous response? Thanks!
		</comment>
		<comment id='6' author='LAWSSSS' date='2020-04-08T01:21:54Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Sorry for the late response, and thanks for your kind help. I've been working on another project recently and forgot to check this issue. I use the following code 'export_inference_graph.py' to generate .pb file:
&lt;denchmark-code&gt;r"""Tool to export an object detection model for inference.

Prepares an object detection tensorflow graph for inference using model
configuration and a trained checkpoint. Outputs inference
graph, associated checkpoint files, a frozen inference graph and a
SavedModel (https://tensorflow.github.io/serving/serving_basic.html).

The inference graph contains one of three input nodes depending on the user
specified option.
  * `image_tensor`: Accepts a uint8 4-D tensor of shape [None, None, None, 3]
  * `encoded_image_string_tensor`: Accepts a 1-D string tensor of shape [None]
    containing encoded PNG or JPEG images. Image resolutions are expected to be
    the same if more than 1 image is provided.
  * `tf_example`: Accepts a 1-D string tensor of shape [None] containing
    serialized TFExample protos. Image resolutions are expected to be the same
    if more than 1 image is provided.

and the following output nodes returned by the model.postprocess(..):
  * `num_detections`: Outputs float32 tensors of the form [batch]
      that specifies the number of valid boxes per image in the batch.
  * `detection_boxes`: Outputs float32 tensors of the form
      [batch, num_boxes, 4] containing detected boxes.
  * `detection_scores`: Outputs float32 tensors of the form
      [batch, num_boxes] containing class scores for the detections.
  * `detection_classes`: Outputs float32 tensors of the form
      [batch, num_boxes] containing classes for the detections.
  * `detection_masks`: Outputs float32 tensors of the form
      [batch, num_boxes, mask_height, mask_width] containing predicted instance
      masks for each box if its present in the dictionary of postprocessed
      tensors returned by the model.

Notes:
 * This tool uses `use_moving_averages` from eval_config to decide which
   weights to freeze.

Example Usage:
--------------
python export_inference_graph \
    --input_type image_tensor \
    --pipeline_config_path path/to/ssd_inception_v2.config \
    --trained_checkpoint_prefix path/to/model.ckpt \
    --output_directory path/to/exported_model_directory

The expected output would be in the directory
path/to/exported_model_directory (which is created if it does not exist)
with contents:
 - inference_graph.pbtxt
 - model.ckpt.data-00000-of-00001
 - model.ckpt.info
 - model.ckpt.meta
 - frozen_inference_graph.pb
 + saved_model (a directory)

Config overrides (see the `config_override` flag) are text protobufs
(also of type pipeline_pb2.TrainEvalPipelineConfig) which are used to override
certain fields in the provided pipeline_config_path.  These are useful for
making small changes to the inference graph that differ from the training or
eval config.

Example Usage (in which we change the second stage post-processing score
threshold to be 0.5):

python export_inference_graph \
    --input_type image_tensor \
    --pipeline_config_path path/to/ssd_inception_v2.config \
    --trained_checkpoint_prefix path/to/model.ckpt \
    --output_directory path/to/exported_model_directory \
    --config_override " \
            model{ \
              faster_rcnn { \
                second_stage_post_processing { \
                  batch_non_max_suppression { \
                    score_threshold: 0.5 \
                  } \
                } \
              } \
            }"
"""
import tensorflow as tf
from google.protobuf import text_format
from object_detection import exporter
from object_detection.protos import pipeline_pb2

slim = tf.contrib.slim
flags = tf.app.flags

flags.DEFINE_string('input_type', 'image_tensor', 'Type of input node. Can be '
                    'one of [`image_tensor`, `encoded_image_string_tensor`, '
                    '`tf_example`]')
flags.DEFINE_string('input_shape', None,
                    'If input_type is `image_tensor`, this can explicitly set '
                    'the shape of this input tensor to a fixed size. The '
                    'dimensions are to be provided as a comma-separated list '
                    'of integers. A value of -1 can be used for unknown '
                    'dimensions. If not specified, for an `image_tensor, the '
                    'default shape will be partially specified as '
                    '`[None, None, None, 3]`.')
flags.DEFINE_string('pipeline_config_path', None,
                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '
                    'file.')
flags.DEFINE_string('trained_checkpoint_prefix', None,
                    'Path to trained checkpoint, typically of the form '
                    'path/to/model.ckpt')
flags.DEFINE_string('output_directory', None, 'Path to write outputs.')
flags.DEFINE_string('config_override', '',
                    'pipeline_pb2.TrainEvalPipelineConfig '
                    'text proto to override pipeline_config_path.')
flags.DEFINE_boolean('write_inference_graph', False,
                     'If true, writes inference graph to disk.')
tf.app.flags.mark_flag_as_required('pipeline_config_path')
tf.app.flags.mark_flag_as_required('trained_checkpoint_prefix')
tf.app.flags.mark_flag_as_required('output_directory')
FLAGS = flags.FLAGS


def main(_):
  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()
  with tf.gfile.GFile(FLAGS.pipeline_config_path, 'r') as f:
    text_format.Merge(f.read(), pipeline_config)
  text_format.Merge(FLAGS.config_override, pipeline_config)
  if FLAGS.input_shape:
    input_shape = [
        int(dim) if dim != '-1' else None
        for dim in FLAGS.input_shape.split(',')
    ]
  else:
    input_shape = None
  exporter.export_inference_graph(
      FLAGS.input_type, pipeline_config, FLAGS.trained_checkpoint_prefix,
      FLAGS.output_directory, input_shape=input_shape,
      write_inference_graph=FLAGS.write_inference_graph)


if __name__ == '__main__':
  tf.app.run()
&lt;/denchmark-code&gt;

I use the following command combined with the code:
python export_inference_graph.py --pipeline_config_path=./data/ssd_mobilenet_v2_coco.config --trained_checkpoint_prefix ./data/model.ckpt-19393 --output_directory ./data/exported_model_directory
		</comment>
		<comment id='7' author='LAWSSSS' date='2020-05-21T07:11:38Z'>
		&lt;denchmark-link:https://github.com/LAWSSSS&gt;@LAWSSSS&lt;/denchmark-link&gt;
 Sorry for the delay in my response. I ran your code with  and was able to convert the .pb to .tflite model. I added only one line as shown below

Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/f3f7e6034bb67815c186b67efedfd6db/untitled46.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Please verify once and close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='8' author='LAWSSSS' date='2020-05-28T08:10:42Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='9' author='LAWSSSS' date='2020-06-04T08:34:26Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='10' author='LAWSSSS' date='2020-06-04T08:34:28Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37884&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37884&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>