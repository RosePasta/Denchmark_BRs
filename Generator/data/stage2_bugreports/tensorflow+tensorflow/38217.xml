<bug id='38217' author='jackyesf' open_date='2020-04-04T12:43:55Z' closed_time='2020-04-18T09:40:07Z'>
	<summary>load_model cause memory leak.</summary>
	<description>
model = load_model('.\Models\LSTM-RAdam-batchsize50-Data5040\Algorithm-LSTM-RAdam-batchsize50-Data5040-0.h5')
if i use tensorflow2.0 will got this bug,and tensorflow2.1.0 no this bug.
save.py 146  2020-04-04 20:14:39.885989
hdf5_format.py 153  2020-04-04 20:14:39.886990
hdf5_format.py 159  2020-04-04 20:14:39.886990
model_config.py 54  2020-04-04 20:14:39.890988
hdf5_format.py 169  2020-04-04 20:14:45.900547
hdf5_format.py 172  2020-04-04 20:14:46.118488
optimizer_v2.py 253  2020-04-04 20:14:46.118488
hdf5_format.py 185  2020-04-04 20:14:48.779033
hdf5_format.py 193  2020-04-04 20:14:48.779033
traing.py 2094  2020-04-04 20:14:48.779033
traing.py 2112  2020-04-04 20:14:48.822994
traing.py 2116  2020-04-04 20:14:48.823996
optimizer_v2.py 501  2020-04-04 20:14:48.823996
optimizer_v2.py 390 2020-04-04 20:14:48.823996
optimizer_v2.py 393  2020-04-04 20:14:48.824993
gradients_impl.py 154  2020-04-04 20:14:48.824993
gradients_impl.py 156  2020-04-04 20:14:48.824993
gradients_util.py 504  2020-04-04 20:14:48.824993 513.27 MB   0
gradients_util.py 680  &lt;function _AddGrad at 0x0000024A9360BD90&gt;
_MaybeCompile 340  513.27 MB
_MaybeCompile 350  513.27 MB
_MaybeCompile 358  &lt;function _GradientsHelper.. at 0x0000024AA779C730&gt; 513.27 MB
gradients_util.py 682
gradients_util.py 711
...
...
gradients_util.py 711
gradients_util.py 680  &lt;function _IfGrad at 0x0000024A9609A488&gt;
_MaybeCompile 340  544.09 MB
_MaybeCompile 350  544.09 MB
_MaybeCompile 358  &lt;function _GradientsHelper.. at 0x0000024AAC1750D0&gt; 544.09 MB
gradients_util.py 504  2020-04-04 20:14:52.229995 571.5 MB   1
gradients_util.py 680  &lt;function _IdGrad at 0x0000024A935BCE18&gt;
_MaybeCompile 340  571.5 MB
...
...
gradients_util.py 680  &lt;function _IfGrad at 0x0000024A9609A488&gt;
_MaybeCompile 340  2058.01 MB
_MaybeCompile 350  2058.01 MB
_MaybeCompile 358  &lt;function _GradientsHelper.. at 0x0000024B0A7B08C8&gt; 2058.01 MB
gradients_util.py 504  2020-04-04 20:15:10.104159 2101.93 MB   84
gradients()--&gt;_GradientsHelper()--&gt;_MaybeCompile()--&gt;grad_fn()(_GradientsHelper)
	</description>
	<comments>
		<comment id='1' author='jackyesf' date='2020-04-06T07:23:00Z'>
		&lt;denchmark-link:https://github.com/jackyesf&gt;@jackyesf&lt;/denchmark-link&gt;
, Tensorflow 2.1 is latest stable release, which has new features and many fixes compared to Tf2.0. It would be good to use Tf 2.1. Thanks
		</comment>
		<comment id='2' author='jackyesf' date='2020-04-06T14:21:14Z'>
		I try to use Tf2.1 and got another bug.
the Tf got 5 batch data then start train,I don't know when why?the same soure code run in another computer with cpu don't have this problem.
history = model.fit(train_generator,
steps_per_epoch=5,&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/582&gt;#582&lt;/denchmark-link&gt;
,
epochs=2,
workers=0,
shuffle=False,
callbacks=callbacks_log,
max_queue_size=1,
use_multiprocessing=False)
2017-02-13 is open day
total_count: 50   Time:  0 : 0 : 24   ReadTime:  0.4885924999999993
date:   2020-04-06 20:08:05.283358
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.
0. 0.]
Train for 5 steps
Epoch 1/2
2017-02-14 is open day
total_count: 100   Time:  0 : 1 : 22   ReadTime:  0.146348500000002
date:   2020-04-06 20:09:03.293034
[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0.]
2017-02-15 is open day
total_count: 150   Time:  0 : 2 : 10   ReadTime:  0.17794280000001095
date:   2020-04-06 20:09:51.197738
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
0. 0.]
2017-02-16 is open day
total_count: 200   Time:  0 : 2 : 23   ReadTime:  0.1687238000000093
date:   2020-04-06 20:10:04.233256
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.

0.]

2017-02-17 is open day
total_count: 250   Time:  0 : 2 : 36   ReadTime:  0.14867739999999685
date:   2020-04-06 20:10:16.904404
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
0. 0.]
1/5 [=====&gt;........................] - ETA: 9:13 - loss:  0.0420
		</comment>
		<comment id='3' author='jackyesf' date='2020-04-08T08:00:19Z'>
		&lt;denchmark-link:https://github.com/jackyesf&gt;@jackyesf&lt;/denchmark-link&gt;
, Could you share the complete standalone code to analyze the issue. Thanks
		</comment>
		<comment id='4' author='jackyesf' date='2020-04-08T10:31:49Z'>
		It's too big to upload the code and data .
		</comment>
		<comment id='5' author='jackyesf' date='2020-04-14T06:26:25Z'>
		I tracing in traing the LSTM layers is tensorflow.python.keras.layers.recurrent_v2.LSTM
network.py,888  _run_internal_graph False &lt;tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x000001B05E6BC518&gt;
but after save the model and reload it ,I found the LSTM layers changed to ensorflow.python.keras.layers.recurrent.LSTM
model = tf.keras.models.load_model('.\Models\LSTM-RAdam-batchsize50\AlgorithmLSTM-RAdam-batchsize.h5',
custom_objects={'binary_focal_loss': binary_focal_loss,
'binary_focal_loss_fixed':binary_focal_loss_fixed})
history = model.fit(train_generator,
steps_per_epoch=1,&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/582&gt;#582&lt;/denchmark-link&gt;
,
epochs=2,
workers=0)
network.py,888  _run_internal_graph False &lt;tensorflow.python.keras.layers.recurrent.LSTM object at 0x000001CB28747F98&gt;
		</comment>
		<comment id='6' author='jackyesf' date='2020-04-14T08:51:32Z'>
		&lt;denchmark-link:https://www.tensorflow.org/guide/keras/save_and_serialize?hl=zh_cn#saving_subclassed_models&gt;https://www.tensorflow.org/guide/keras/save_and_serialize?hl=zh_cn#saving_subclassed_models&lt;/denchmark-link&gt;

Part II: Saving and Loading of Subclassed Models
model.save('path_to_my_model',save_format='tf')
even i follow the instructon on the guide ,still got the same problem
		</comment>
		<comment id='7' author='jackyesf' date='2020-04-18T09:40:07Z'>
		I found this bug fixed on tensorflow2.2.0rc3
		</comment>
		<comment id='8' author='jackyesf' date='2020-04-18T09:40:08Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38217&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38217&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>