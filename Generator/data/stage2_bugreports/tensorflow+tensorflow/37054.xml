<bug id='37054' author='muhammetfaik' open_date='2020-02-25T17:40:38Z' closed_time='2020-03-12T21:57:49Z'>
	<summary>TPU scope valuerror</summary>
	<description>
I want to run this code support TPU
It's my function and &lt;denchmark-link:https://colab.research.google.com/drive/1aysV-1Vur5Wp8BKD64bwWLNNue60MV2-&gt;colab:&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;def build_model(params_path = 'test/params', enc_lstm_units = 128, unroll = True, use_gru=False, optimizer='adam', display_summary=True):
    """
    Build keras model

    Parameters:

    params_path (str): Path for saving/loading the params.

    enc_lstm_units (int): Positive integer, dimensionality of the output space.

    unroll (bool): Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.

    use_gru (bool): GRU will be used instead of LSTM

    optimizer (str): optimizer to be used

    display_summary (bool): Set to true for verbose information.


    Returns:

    model (keras model): built model object.
    
    params (dict): Generated params (encoding, decoding dicts ..).

    """
    # generateing the encoding, decoding dicts
    params = build_params(params_path = params_path)

    input_encoding = params['input_encoding']
    input_decoding = params['input_decoding']
    input_dict_size = params['input_dict_size']
    output_encoding = params['output_encoding']
    output_decoding = params['output_decoding']
    output_dict_size = params['output_dict_size']
    max_input_length = params['max_input_length']
    max_output_length = params['max_output_length']


    if display_summary:
        print('Input encoding', input_encoding)
        print('Input decoding', input_decoding)
        print('Output encoding', output_encoding)
        print('Output decoding', output_decoding)


    # We need to define the max input lengths and max output lengths before training the model.
    # We pad the inputs and outputs to these max lengths
    encoder_input = Input(shape=(max_input_length,))
    decoder_input = Input(shape=(max_output_length,))

    # Need to make the number of hidden units configurable
    encoder = Embedding(input_dict_size, enc_lstm_units, input_length=max_input_length, mask_zero=True)(encoder_input)
    # using concat merge mode since in my experiments it g ave the best results same with unroll
    if not use_gru:
        encoder = Bidirectional(LSTM(enc_lstm_units, return_sequences=True, return_state=True, unroll=unroll), merge_mode='concat')(encoder)
        encoder_outs, forward_h, forward_c, backward_h, backward_c = encoder
        encoder_h = concatenate([forward_h, backward_h])
        encoder_c = concatenate([forward_c, backward_c])
    
    else:
        encoder = Bidirectional(GRU(enc_lstm_units, return_sequences=True, return_state=True, unroll=unroll), merge_mode='concat')(encoder)        
        encoder_outs, forward_h, backward_h= encoder
        encoder_h = concatenate([forward_h, backward_h])
    

    # using 2* enc_lstm_units because we are using concat merge mode
    # cannot use bidirectionals lstm for decoding (obviously!)
    
    decoder = Embedding(output_dict_size, 2 * enc_lstm_units, input_length=max_output_length, mask_zero=True)(decoder_input)

    if not use_gru:
        decoder = LSTM(2 * enc_lstm_units, return_sequences=True, unroll=unroll)(decoder, initial_state=[encoder_h, encoder_c])
    else:
        decoder = GRU(2 * enc_lstm_units, return_sequences=True, unroll=unroll)(decoder, initial_state=encoder_h)


    # luong attention
    attention = dot([decoder, encoder_outs], axes=[2, 2])
    attention = Activation('softmax', name='attention')(attention)

    context = dot([attention, encoder_outs], axes=[2,1])

    decoder_combined_context = concatenate([context, decoder])

    output = TimeDistributed(Dense(enc_lstm_units, activation="tanh"))(decoder_combined_context)
    output = TimeDistributed(Dense(output_dict_size, activation="softmax"))(output)

    model = Model(inputs=[encoder_input, decoder_input], outputs=[output])
    
    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
    tf.config.experimental_connect_to_cluster(resolver)
    tf.tpu.experimental.initialize_tpu_system(resolver)
    strategy = tf.distribute.experimental.TPUStrategy(resolver) 
    with strategy.scope():
      model = Model(inputs=[encoder_input, decoder_input], outputs=[output])
      model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

    if display_summary:
        model.summary()
    
    return model, params
&lt;/denchmark-code&gt;

Error:
&lt;denchmark-code&gt;ValueError                                Traceback (most recent call last)
&lt;ipython-input-6-66476e79d8c4&gt; in &lt;module&gt;()
    501     build_params(input_data = input_data, output_data = output_data, params_path = 'params', max_lenghts=(10, 10))
    502 
--&gt; 503     model, params = build_model(params_path='params')
    504 
    505     input_data, output_data = convert_training_data(input_data, output_data, params)

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    398                 'with strategy.scope():\n'
    399                 '  model=_create_model()\n'
--&gt; 400                 '  model.compile(...)'% (v, strategy))
    401 
    402   @trackable.no_automatic_dependency_tracking

ValueError: Variable (&lt;tf.Variable 'embedding_2_1/embeddings:0' shape=(39, 128) dtype=float32&gt;) was not created in the distribution strategy scope of (&lt;tensorflow.python.distribute.tpu_strategy.TPUStrategyV1 object at 0x7f9e623bef98&gt;). It is most likely due to not all layers or the model or optimizer being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.
with strategy.scope():
  model=_create_model()
  model.compile(...)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='muhammetfaik' date='2020-02-26T11:31:03Z'>
		Was able to reproduce the issue. Please find the Gist &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/86e9cfb03c7eba411b5b88b4011218f8/37054.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='muhammetfaik' date='2020-02-26T19:02:44Z'>
		&lt;denchmark-link:https://github.com/muhammetfaik&gt;@muhammetfaik&lt;/denchmark-link&gt;
  creation needs to be inside the . Please follow &lt;denchmark-link:https://www.tensorflow.org/guide/tpu&gt;the tutorial&lt;/denchmark-link&gt;
 on  and update your code. I have updated some parts but still some coding needs to be updated.
Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/b1b7e6f717f7b52fb1f86f829eee7c70/37054.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
Please post support related questions on stackoverflow. Thanks!
		</comment>
		<comment id='3' author='muhammetfaik' date='2020-03-12T18:31:09Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='4' author='muhammetfaik' date='2020-03-12T21:57:49Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='5' author='muhammetfaik' date='2020-03-12T21:57:51Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37054&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37054&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>