<bug id='3527' author='jparinita' open_date='2016-07-27T11:01:15Z' closed_time='2017-04-26T04:21:46Z'>
	<summary>//tensorflow/python:Sparse_split_op_test  is failing on Big Endian</summary>
	<description>
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: Ubuntu/Red Hat
Installed version of CUDA and cuDNN:  Not installed
The output from python -c "import tensorflow; print(tensorflow.__version__)". 0.8.0
If installed from source, provide

The commit hash (git rev-parse HEAD) [ 4b7bc31]
The output of bazel version 0.3.0

&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;


Run bazel test //tensorflow/python:Sparse_split_op_test

&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

It was observed that this particular test consists of row-wise and column-wise split of tensor.
Test is failing on execution of column wise tensor split in case of Big Endian.
Please check attached stack-trace.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/385847/sparse_split_test_log.txt&gt;sparse_split_test_log.txt&lt;/denchmark-link&gt;

I checked the test is passing in case of  Little Endian (Ubuntu, Red Hat)
	</description>
	<comments>
		<comment id='1' author='jparinita' date='2016-07-27T20:20:50Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
 this looks like a bug but the code author isn't in the tf org. Would you assign appropriately?
		</comment>
		<comment id='2' author='jparinita' date='2016-07-27T21:57:30Z'>
		&lt;denchmark-link:https://github.com/jparinita&gt;@jparinita&lt;/denchmark-link&gt;
 Is that the only test that fails?  I'm particularly curious whether any simpler tests exercising TensorShape might fail.
		</comment>
		<comment id='3' author='jparinita' date='2016-07-28T08:31:10Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;

There were many tests failing from //tensorflow/... test suite.
Looks like  tensorflow is not supporting Big Endian as of now.
We have made changes to source code to add big endian support ( changes for const bool kLittleEndian variable)
With code changes, most of the tests are passing like
&lt;denchmark-code&gt;//tensorflow/contrib/framework:ops_test 
//tensorflow/core:framework_op_kernel_test          
//tensorflow/core:util_sparse_sparse_tensor_test 
&lt;/denchmark-code&gt;

However, we still couldn't figure out why Sparse_split_op_test is failing.
		</comment>
		<comment id='4' author='jparinita' date='2016-07-29T15:54:03Z'>
		&lt;denchmark-link:https://github.com/jparinita&gt;@jparinita&lt;/denchmark-link&gt;
 That you for the fixes so far!  Would you be interested in sending them as a PR so I can see how TensorFlow is currently broken (and make it slightly less broken)?  My best guess is still that it's a bug in TensorShape, but I don't know where.
Note that TensorShape has been heavily optimized to avoid memory allocations, which involved quite a lot of case analysis.  It's possible that some of these cases are now correct in big endian and others are not.
		</comment>
		<comment id='5' author='jparinita' date='2016-08-03T09:50:28Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;

Could you please let us know the test "Sparse_split_op_test" which is failing can be ignored? Or is it used to test some complex functionality of TensorFlow?
About PR for Tensorflow,  I have built TensorFlow version 0.8.0 for big endian and also executed test cases for same version. I made few code changes related to big endian in the source code that I git cloned from tag 0.8.0.
Now, I am trying to build TensorFlow master on big endian and I am facing few build issues.
Issues like:

has a dependency on protobuf and need changes here.
Facing issue as 'Packet4f' does not name a type
This one is related to EIGEN_VECTORIZE_SSE2.

I haven't faced them on v0.8.0 before.
I am looking into above issues.
Once I could fix these issues and able to build master, I will create a PR .
		</comment>
		<comment id='6' author='jparinita' date='2016-08-03T14:38:31Z'>
		&lt;denchmark-link:https://github.com/jparinita&gt;@jparinita&lt;/denchmark-link&gt;
  mostly just tests that one op, but there's a good chance that the failure is in core functionality rather than that op so it's worth debugging.
		</comment>
		<comment id='7' author='jparinita' date='2016-08-09T23:32:54Z'>
		Removing my assignment since I can't debug this personally.  Still happy to help with advice and code reviews.
		</comment>
		<comment id='8' author='jparinita' date='2016-08-22T13:10:46Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;

Since TensorFlow v0.9.0 was released, I have built v0.9.0 on big endian platform and currently executing tests.
sparse_split_op_test is failing on v0.9.0 as well.  Additionally, there are few more test failures seen such as
&lt;denchmark-code&gt;//tensorflow/python:sparse_matmul_op_test
//tensorflow/python:string_to_hash_bucket_op_test
//tensorflow/python:conv_ops_test
//tensorflow/core/kernels:sparse_matmul_op_test_gpu
//tensorflow/python:determinant_op_test
&lt;/denchmark-code&gt;

I am debugging the code to find the root cause but no luck yet.
Above mentioned tests seem to be related to ops functionality (op_def_library.apply_op()).
Any suggestions would be helpful.
		</comment>
		<comment id='9' author='jparinita' date='2016-08-22T14:41:40Z'>
		&lt;denchmark-link:https://github.com/jparinita&gt;@jparinita&lt;/denchmark-link&gt;
 I'd still suggest preparing a pull request of your changes so far.  It's hard for me to help without some idea what kind of changes need to be made.
		</comment>
		<comment id='10' author='jparinita' date='2016-09-22T12:08:55Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;

We have created a PR  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/4508&gt;#4508&lt;/denchmark-link&gt;
 for TensorFlow with big endian changes.
Could you please have a look?
Any suggestions would be helpful to fix failing test cases mentioned above .
		</comment>
		<comment id='11' author='jparinita' date='2016-09-25T01:22:18Z'>
		Cc &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 for triage, since I'm OOO.
		</comment>
		<comment id='12' author='jparinita' date='2016-10-03T05:30:55Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
  Could you please have a look?
		</comment>
		<comment id='13' author='jparinita' date='2016-10-04T00:46:19Z'>
		I will look at this first thing tomorrow.
		</comment>
		<comment id='14' author='jparinita' date='2016-10-04T20:53:15Z'>
		I looked at the code you changed, and it seems plausible. I also Could you post the test logs from the failing tests. I checked your code, and it looks like what you are doing is plausible. Obvious ways to check for more areas that need changing is grepping for reinterpret_cast's and uses of unions. Also, you might want to try compiling with -fno-strict-aliasing to see if a you are hitting some strict aliasing problems.
I would like to help more, but I can't reproduce your big endian test, because I have no easy access to a   machine that is big endian. Do you know of an easy environment to build/run big endian code?
		</comment>
		<comment id='15' author='jparinita' date='2016-10-04T21:03:49Z'>
		More notes,
Also, in terms of looking at TensorShape which Geoffrey thought might be an issue. It looks like things would mostly be ok. One question is whether your architecture has alignment restrictions for uint16 for uint8 and uint32's. It looks like we aren't doing manipulations as anything but the word size and bytes, which probably is safe. You should insert
&lt;denchmark-code&gt;static_assert(sizeof(Rep16)==12, "rep16 not 12 bytes");
static_assert(sizeof(Rep32)==12, "rep32 not 12 bytes");
&lt;/denchmark-code&gt;

into TensorShape inside tensor_shape.h.
If you have valgrind, you might try running that to see if any buffers are being run-off.
		</comment>
		<comment id='16' author='jparinita' date='2016-10-05T12:32:17Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;

Thank you for your comments.
We are working on your suggestions for big endian.
Do you know of an easy environment to build/run big endian code?
==&gt; Will it be ok if we provide our big endian vm as an extension to TensorFlow CI?
		</comment>
		<comment id='17' author='jparinita' date='2016-10-05T17:51:07Z'>
		Can you describe the endian VM? How much slower is it than a native system? Is the emulator and software open source code? I'll look into how hard it would be to put that in our testing infrastructure. &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
  can also comment.
		</comment>
		<comment id='18' author='jparinita' date='2016-10-05T18:48:34Z'>
		For now, I think it is possible to hook it up to our test infra for daily tests.
But in the near future we will transfer management of our test infra, and in that case we will be quite limited.
		</comment>
		<comment id='19' author='jparinita' date='2016-10-07T12:37:43Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;

Can you please provide more details on how the current CI infrastructure is ?
Also, I need below details in order to setup the CI infrastructure on z Systems (big endian):

How frequent the CI runs on average?
What is the recommended H/W and configuration requirement?
Special S/W requirements (if any).

		</comment>
		<comment id='20' author='jparinita' date='2016-10-17T11:56:05Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 Could you please provide details on the current CI infrastructure ?
		</comment>
		<comment id='21' author='jparinita' date='2016-10-17T12:29:17Z'>
		We have attached test logs for the below failing tests:

//tensorflow/python:string_to_hash_bucket_op_test
//tensorflow/python:sparse_split_op_test

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/533415/string_to_hash_bucket_op_test.log.txt&gt;string_to_hash_bucket_op_test.log.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/533436/sparse_split_op_test.txt&gt;sparse_split_op_test.txt&lt;/denchmark-link&gt;

Could you please have a look at logs?
		</comment>
		<comment id='22' author='jparinita' date='2016-10-17T15:33:54Z'>
		About our CI:
Looking back at our future plans, we will be retiring our self maintained CI. Therefore, we ourselves would like to avoid adding more machines/setups to that to avoid making our final move more complicated.
Therefore, we decided against running a big endian machine/VM in our CI. I would be happy to help you if you wanted to setup a CI with your machines for this. And we will be happy to accept any patches you might provide.
Currently, our CI runs the scripts here:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build&gt;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build&lt;/denchmark-link&gt;

Which should work for you as well.
About the failure you are seeing, I would defer to someone else with more in-depth information about the ops.
		</comment>
		<comment id='23' author='jparinita' date='2016-10-18T12:59:24Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
  We will be glad, if any kind of assistance in maintaining the zSystem VM in the CI by our team can change your decision.
Please let us know.
		</comment>
		<comment id='24' author='jparinita' date='2016-10-18T13:01:27Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
  We have compiled TensorFlow with -fno-strict-aliasing flag and executed tests however we have observed same failures as before.
We have also checked if our architecture has alignment restrictions for uint8,  uint16 and/or uint32's by adding static_asserts as suggested. However, we didn't find such restrictions ( sizeof Rep16 and Rep32 are 12 bytes)
		</comment>
		<comment id='25' author='jparinita' date='2016-10-19T22:39:53Z'>
		Probably the next thing  I would try is debugging further. So the next step is to look at the failing tests in more detail. You can compile in debug mode both on your architecture and a supported architecture and use a debugger to step through the statements until you find a mismatch.
		</comment>
		<comment id='26' author='jparinita' date='2016-10-24T12:21:50Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 Thanks for your comments.
We have built TensorFlow using '-dbg' flag on s390x architecture.
We are trying to debug the failing test-case using gdb.
Is there any documentation available which we can refer for debugging?
		</comment>
		<comment id='27' author='jparinita' date='2016-11-15T10:36:34Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;

We are currently debugging   on s390x as well as x86 architecture.
We could see that the mismatch of values is happening in from  .
We could observe that the  op.outputs is populated after   is being called:
&lt;denchmark-code&gt;ret = Operation(node_def, self, inputs=inputs, output_types=dtypes,
                    control_inputs=control_inputs, input_types=input_types,
                    original_op=self._default_original_op, op_def=op_def)
    if compute_shapes:
      set_shapes_for_outputs(ret)
-------------&gt; **here,  ret.outputs[0].eval() gives NotFoundError**
    self._add_op(ret)
-------------&gt; **here,  p ret.outputs[0].eval() gives array([3, 5, 7]) ( expected output is array[4,2,8])**

    self._record_op_seen_by_control_dependencies(ret)
&lt;/denchmark-code&gt;

We tried debugging function _add_op() , however couldn't find where the op.outputs is getting populated.
Also, we could seeself.lock being used in this function. Is some other thread populating these values?
		</comment>
		<comment id='28' author='jparinita' date='2016-11-15T15:33:29Z'>
		&lt;denchmark-link:https://github.com/Nayana-ibm&gt;@Nayana-ibm&lt;/denchmark-link&gt;
 I don't know offhand, and my next step at this point would just be adding print statements until I did know.  I'm not sure what you mean by : Python graph construction is not thread safe, and is typically single threaded.
		</comment>
		<comment id='29' author='jparinita' date='2016-11-15T17:23:22Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
 We are using pdb to debug test case and tried to print the op.outputs[0].eval() . The mismatch we could observe after _add_op(self, op) is being called as below:
&lt;denchmark-code&gt;ret = Operation(node_def, self, inputs=inputs, output_types=dtypes,
                    control_inputs=control_inputs, input_types=input_types,
                    original_op=self._default_original_op, op_def=op_def)
    if compute_shapes:
      set_shapes_for_outputs(ret)
-------------&gt; **here,  ret.outputs[0].eval() gives NotFoundError**
    self._add_op(ret)
-------------&gt; **here,  p ret.outputs[0].eval() gives array([3, 5, 7]) ( expected output is array[4,2,8])**
&lt;/denchmark-code&gt;

About self.lock, this is used in the definition of _add_op function( filename: python/framework/ops.py):
&lt;denchmark-code&gt;
with self._lock:
      # pylint: disable=protected-access
      if op._id in self._nodes_by_id:
        raise ValueError("cannot add an op with id %d as it already "
                         "exists in the graph" % op._id)
      if op.name in self._nodes_by_name:
        raise ValueError("cannot add op with name %s as that name "
                         "is already used" % op.name)
      self._nodes_by_id[op._id] = op
      self._nodes_by_name[op.name] = op
self._version = max(self._version, op._id)
&lt;/denchmark-code&gt;

In self.lock is defined in def init(self) from Graph object as (filename: python/framework/ops.py):
&lt;denchmark-code&gt;self._lock = threading.Lock()
self._nodes_by_id = dict() # GUARDED_BY(self._lock)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='30' author='jparinita' date='2016-11-15T17:31:05Z'>
		Ah, maybe it is thread safe! :)  In any case, I would be surprised if the problem was at the Python level, but I don't think I'll be able to help much in debugging this remotely since I can't tinker.
		</comment>
		<comment id='31' author='jparinita' date='2016-12-01T12:26:33Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 Can you please have a look at this issue and share your views?
		</comment>
		<comment id='32' author='jparinita' date='2016-12-01T15:59:06Z'>
		&lt;denchmark-link:https://github.com/Nayana-ibm&gt;@Nayana-ibm&lt;/denchmark-link&gt;
 I agree with &lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
: The problem almost certainly isn't in Python (unless there's an endianness bug in the Python runtime itself), but is more likely to be in either the OpKernel for the op that is failing or its C++ shape function. I'd suggest using gdb to step through these functions and see where they go wrong.
		</comment>
		<comment id='33' author='jparinita' date='2017-02-01T11:31:47Z'>
		This test is now passing on big endian system. Fixed through PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/6686&gt;#6686&lt;/denchmark-link&gt;

		</comment>
		<comment id='34' author='jparinita' date='2017-02-01T11:32:57Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;

To extend my post on CI:
We would like to know that how TensorFlow CI can be extended to support z system.
Please let us know what support will be required from IBM side. We are aware on the H/w support.
We can provide s390x machines on which we will setup Jenkins slave node to build TensorFlow.
The present Jenkins master will manage this node and post the s390x build results to GitHub.
Please let us know your comments.
		</comment>
		<comment id='35' author='jparinita' date='2017-02-01T23:44:03Z'>
		&lt;denchmark-link:https://github.com/Nayana-ibm&gt;@Nayana-ibm&lt;/denchmark-link&gt;
 As far as support goes, I cannot really promise we can fully support ourselves as we do not have big endian machines. So we cannot give first class support for this platform.
But I can help setup our jenkins to run all TF tests on your machines periodically. When there are failures, most probably we will escalate the issues to you, if they seem to be specific to your machines, and we will be available to consult resolving issues. You will retain ownership of these machines. I will help you setup all our dependencies on them, and as long as your machine is healthy and up, our jenkins master will schedule tests on your machine.
How does this sound?
		</comment>
		<comment id='36' author='jparinita' date='2017-02-03T12:32:22Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;

This sounds good to us.
As per my understanding,  we will provide you a Jenkins slave node which will be added under your master. Correct? Also, wanted to know how the build results will be shared with us? through GitHub issue? Please let me know.
		</comment>
		<comment id='37' author='jparinita' date='2017-02-07T22:56:50Z'>
		Sorry for the delay, my inbox is going crazy these days.
Yes, you will have the machine maintained by you, and I will provide you instructions to setup the machine for tensorflow builds. The build results will be visible through ci.tensorflow.org. You will have access to all build logs through ci.tensorflow.org.
I can even set you up with access to start and stop the specific build for s390x.
		</comment>
		<comment id='38' author='jparinita' date='2017-02-09T10:45:30Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;

Thanks for your support.
Could you please let me know what's the recommended H/W configuration required? and
S/W requirements (if any).
		</comment>
		<comment id='39' author='jparinita' date='2017-02-14T18:44:26Z'>
		Sorry for the delay, looks like I wrote up the response but forgot to send.
For H/W requirements, completely up to you. Obviously, the beefier the machine is, the quicker code is tested. But I wont block code submissions on this so we can tolerate some delays here.
S/W requirements, you will need all TF dependencies on your machine installed. We usually run all our tests in a docker container, but in this case I dont think we need docker.
Our jenkins will simply execute:
&lt;denchmark-code&gt;git checkout &lt;commit&gt;
&lt;set some environment variables&gt;
yes "" | ./configure
bazel test tensorflow/...
&lt;/denchmark-code&gt;

		</comment>
		<comment id='40' author='jparinita' date='2017-02-17T15:02:51Z'>
		Thank you for your inputs.
We are setting up machine with all TF dependencies.
I could see Tensorflow supports Ubuntu 14.04 ( Ref: &lt;denchmark-link:https://www.tensorflow.org/install/install_linux&gt;https://www.tensorflow.org/install/install_linux&lt;/denchmark-link&gt;
)
however we are planning to build the TensorFlow on RHEL and Ubuntu on s390x platform.
		</comment>
		<comment id='41' author='jparinita' date='2017-02-22T05:43:38Z'>
		I just verified that with bazel I can build on CentOS 7 without any issues.
I expect a similar experience with RHEL.
However, we do not have official RedHat support, so we will possibly redirect Redhat specific build issues to you in this build.
		</comment>
		<comment id='42' author='jparinita' date='2017-03-21T12:46:20Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;

We have procured the s390x vms with Ubuntu 16.04 distribution.
Also, installed the dependencies like bazel, python-setuptools etc.
Please let me know the procedure to add those vm's under TensorFlow CI .
		</comment>
		<comment id='43' author='jparinita' date='2017-03-21T19:22:02Z'>
		Great!
Could you email me? my github username @ companyname is the address
We can continue the conversation there.
		</comment>
		<comment id='44' author='jparinita' date='2017-03-23T09:23:57Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;

Will you please email me on &lt;denchmark-link:mailto:nthorat@us.ibm.com&gt;nthorat@us.ibm.com&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='45' author='jparinita' date='2017-04-25T09:13:07Z'>
		Closing this issue as it was originally opened for test case failure.
Also, we have completed Tensorflow CI for s390x.
&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 Thank you for your help and support.
		</comment>
	</comments>
</bug>