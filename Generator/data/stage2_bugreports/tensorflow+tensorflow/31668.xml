<bug id='31668' author='geometrikal' open_date='2019-08-16T00:28:13Z' closed_time='2019-08-20T16:58:28Z'>
	<summary>Models with tf.keras.layers.BatchNormalisation layers give errors when frozen, or are frozen incorrectly and cannot be loaded</summary>
	<description>
This issue continues on from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31331&gt;#31331&lt;/denchmark-link&gt;
 with a more wide ranging scope
System information

Have I written custom code: Yes
OS Platform and Distribution: Windows 1903
TensorFlow installed from: pip
TensorFlow version: 1.13.1 / 1.14.0 / tf-nightly
Python version: 3.7.3
GPU model and memory: RTX 2080 Ti

Problem
Freezing a model with tf.keras.layers.BatchNormalization layers either gives an error, or does not freeze correctly and gives an error when loading, depending on the tensorflow version.
Method

Freezing: Save a model with tf.keras.layers.BatchNormalization layers using tf.saved_model.simple_save and then freeze it using tensorflow.python.tools.freeze_graph.freeze_graph.
Loading: Load the frozen model using tf.import_graph_def()

Results
1.13.1

Freezing: no error
Loading: ValueError: Input 0 of node batch_normalization/cond/ReadVariableOp/Switch was passed float from batch_normalization/gamma:0 incompatible with expected resource

1.14.0

Freezing: ValueError: Tensor name 'batch_normalization/cond/ReadVariableOp/Switch:1' is invalid.
Loading: n/a

tf-nightly  1.15.0-dev20190815

Freezing: no error
Loading: Node 'batch_normalization/cond/ReadVariableOp/Switch_3' has an _output_shapes attribute inconsistent with the GraphDef for output #0: Shapes must be equal rank, but are 1 and 0

Code to reproduce
Colab gist is here: &lt;denchmark-link:https://colab.research.google.com/gist/geometrikal/da64b13d8a579bc46c005e981d9bc051/tf_31331_freezing_savedmodel.ipynb&gt;https://colab.research.google.com/gist/geometrikal/da64b13d8a579bc46c005e981d9bc051/tf_31331_freezing_savedmodel.ipynb&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow.keras.backend as K
import os
import datetime
import shutil
from tensorflow.python.tools import freeze_graph
from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input, Activation, BatchNormalization, Lambda
from tensorflow.keras.models import Model
from tensorflow.python.platform import gfile

# Clear the session
K.clear_session()

# TF version
print("TF version is " + tf.__version__)

# Create model
print('# Creating model')
def create_model():
    inputs = Input(shape=(128, 128, 1))
    x = Conv2D(4, (3, 3))(inputs)
    x = BatchNormalization()(x)
    # x = Lambda((lambda x: tf.layers.batch_normalization(x)))(x)
    x = Activation('relu')(x)
    x = Flatten()(x)
    x = Dense(5, activation='softmax')(x)
    model = Model(inputs, x, name='test')
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

model = create_model()

# Remove old frozen graph directory
if os.path.exists('/content/frozen/'):
  shutil.rmtree('/content/frozen/')

# Create saved model
print('# Saving model')
save_dir = "/content/frozen/"
tf.saved_model.simple_save(K.get_session(),
                           save_dir,
                           inputs={"input": model.inputs[0]},
                           outputs={"output": model.outputs[0]})

# Freeze graph from saved model checkpoint
print('# Freezing graph')
freeze_graph.freeze_graph(None,
                          None,
                          None,
                          None,
                          model.outputs[0].op.name,
                          None,
                          None,
                          os.path.join(save_dir, "frozen_model.pb"),
                          False,
                          "",
                          input_saved_model_dir=save_dir)

# Try to load frozen graph
print('# Loading graph')
source = "/content/frozen/frozen_model.pb"
session = K.get_session()
with gfile.Open(source, 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    session.graph.as_default()
    tf.import_graph_def(graph_def, name='')
&lt;/denchmark-code&gt;

Workaround
Workaround is to save the weights, clear the session, , recreate the model, restore the weights, and then freeze. &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31331#issuecomment-518655879&gt;#31331 (comment)&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='geometrikal' date='2019-08-20T16:58:28Z'>
		This should work on the latest nightly. Please reopen if you still have issues with running the script provided above.
		</comment>
		<comment id='2' author='geometrikal' date='2019-08-20T16:58:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31668&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31668&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='geometrikal' date='2020-02-28T07:43:07Z'>
		This is happening in TF 2.x when using hub to transfer learn. I can't clear these layers when freezing either so I can't take the model outside of TF to say Open CV DNN.
		</comment>
	</comments>
</bug>