<bug id='37686' author='thamquocdung' open_date='2020-03-18T10:26:59Z' closed_time='2020-03-21T01:41:58Z'>
	<summary>The Problem with Distributed inference on multi-GPUs with tf.distribute.MirroredStrategy() strategy</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:
TensorFlow installed from (source or
binary): binary (install from pip)
TensorFlow version (use command below): 2.1.0
Python version: 3.6.8
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from
source):
CUDA/cuDNN version: Cuda Toolkit 10.1 / cuDNN 7.6.4
GPU model and memory: 2 Titan V

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 

I have tried to custom distributed inference on multi-GPUs (i.e 2 GPUs) follow the tutorial on page &lt;denchmark-link:https://www.tensorflow.org/tutorials/distribute/save_and_load&gt;https://www.tensorflow.org/tutorials/distribute/save_and_load&lt;/denchmark-link&gt;
 by using my model and  strategy. In particular when I ran my bellow code
&lt;denchmark-code&gt;# Here is my code

DEFAULT_FUNCTION_KEY = "serving_default"
data = tf.data.Dataset.from_tensor_slices(np.random.rand(32*100, 416, 416, 3).astype('float32')).batch(32)

# load model and do inference on 1 GPU
loaded = tf.saved_model.load('./model')
inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]

total_time = 0.0
for batch in data:
    begin = time.time()
    inference_func(batch)
    total_time += time.time() - begin
print('Total time on 1 GPU: ', total_time)

# load model and do inference in a distributed manner
mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():
    model = tf.saved_model.load('./model')
    inference_func = model.signatures[DEFAULT_FUNCTION_KEY]

    dist_predict_dataset = mirrored_strategy.experimental_distribute_dataset(data)

    total_time = 0.0
    for batch in dist_predict_dataset:
        begin = time.time()
        mirrored_strategy.run(inference_func, args=(batch,))
        total_time += time.time() - begin
    print('Total time on 2 GPUs: ', total_time)
&lt;/denchmark-code&gt;

*Note: The above code is customed from your bellow sample code in the tutorial
&lt;denchmark-code&gt;# Here is your sample code in the tutorial

DEFAULT_FUNCTION_KEY = "serving_default"
loaded = tf.saved_model.load(saved_model_path)
inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]

predict_dataset = eval_dataset.map(lambda image, label: image)
for batch in predict_dataset.take(1):
  print(inference_func(batch))

another_strategy = tf.distribute.MirroredStrategy()
with another_strategy.scope():
  loaded = tf.saved_model.load(saved_model_path)
  inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]

  dist_predict_dataset = another_strategy.experimental_distribute_dataset(
      predict_dataset)

  # Calling the function in a distributed manner
  for batch in dist_predict_dataset:
    another_strategy.run(inference_func,args=(batch,))
&lt;/denchmark-code&gt;

and compared the total inference time of the model between 1 GPU and 2 GPUs with the same inputs. Unfortunately, I realized that the performance on 2 GPUs is not faster than on 1 GPU (about total time as well as the time of an iterator). It seems that the inference process executed on 2 GPUs sequentially (not parallel as I expected).
Describe the expected behavior
Please let me know if there are any problems here and show me how to modify the code in order to run distributed inference on multi-GPUs parallel with the best performance. Thanks so much for your help

Files to reproduce the test case in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4348380/example.zip&gt;example.zip&lt;/denchmark-link&gt;

Other info / logs
	</description>
	<comments>
		<comment id='1' author='thamquocdung' date='2020-03-19T06:46:45Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
  I've read the original code at 
 and see .  It means threads are going to run sequentially here.
		</comment>
		<comment id='2' author='thamquocdung' date='2020-03-21T01:41:58Z'>
		It is true that the inference_func is running on each GPU sequentially in eager mode, and you should be able to see a warning like &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/mirrored_strategy.py#L755&gt;this&lt;/denchmark-link&gt;
.
To get things running in parallel, you can put the  method inside a tf.function, so that graph building is sequential, but execution is parallel. See this &lt;denchmark-link:https://www.tensorflow.org/tutorials/distribute/custom_training&gt;tutorial&lt;/denchmark-link&gt;
 for an example.
		</comment>
		<comment id='3' author='thamquocdung' date='2020-03-21T01:42:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37686&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37686&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>