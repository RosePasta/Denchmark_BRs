<bug id='39163' author='javidcf' open_date='2020-05-04T18:06:41Z' closed_time='2020-05-06T09:33:37Z'>
	<summary>Cannot make padded batches from dataset made from ragged tensor slices</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 2.2.0-rc4
Python version: 3.7.6
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: NA
GPU model and memory: NA

Describe the current behavior
I can create a dataset from a ragged tensor using &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices&gt;tf.data.Dataset.from_tensor_slices&lt;/denchmark-link&gt;
, but I cannot make a padded batch from it with &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch&gt;tf.data.Dataset.padded_batch&lt;/denchmark-link&gt;
.
Describe the expected behavior
If the API is meant to support ragged tensors, then the dataset should allow me to make a padded batch from the ragged tensor slices. Otherwise, the API could be restricted to disallow ragged tensors.
Standalone code to reproduce the issue
import tensorflow as tf
a = tf.ragged.stack([[1, 2], [3, 4, 5], [6], [7, 8, 9, 10]])
dataset = tf.data.Dataset.from_tensor_slices(a)
print(dataset)
# &lt;TensorSliceDataset shapes: (None,), types: tf.int32&gt;
for it in dataset:
    print(it.numpy())
# [1 2]
# [3 4 5]
# [6]
# [ 7  8  9 10]
batches = dataset.padded_batch(batch_size=2, padded_shapes=[5])
# TypeError: ('Padded batching of components of type ', &lt;class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec'&gt;, ' is not supported.')
Compare with a similar working example with a dataset taken from the documentation of &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator&gt;tf.data.Dataset.from_generator&lt;/denchmark-link&gt;
:
import tensorflow as tf
import itertools
def gen():
    for i in itertools.count(1):
        yield (i, [1] * i)
dataset = tf.data.Dataset.from_generator(gen, (tf.int64, tf.int64), (tf.TensorShape([]), tf.TensorShape([None])))
print(dataset)
# &lt;FlatMapDataset shapes: ((), (None,)), types: (tf.int64, tf.int64)&gt;
for it1, it2 in dataset.take(3):
    print(it1.numpy(), it2.numpy())
# 1 [1]
# 2 [1 1]
# 3 [1 1 1]
batches = dataset.padded_batch(batch_size=2, padded_shapes=([], [10]))
for it1, it2 in batches.take(3):
    print(it1.numpy(), it2.numpy())
# [1 2] [[1 0 0 0 0 0 0 0 0 0]
#  [1 1 0 0 0 0 0 0 0 0]]
# [3 4] [[1 1 1 0 0 0 0 0 0 0]
#  [1 1 1 1 0 0 0 0 0 0]]
# [5 6] [[1 1 1 1 1 0 0 0 0 0]
#  [1 1 1 1 1 1 0 0 0 0]]
Other info / logs NA
	</description>
	<comments>
		<comment id='1' author='javidcf' date='2020-05-05T11:11:46Z'>
		Was able to reproduce the issue with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/4cb13e191e75746af4cbd03f9fd266af/39163-2-1-0.ipynb&gt;TF v2.1&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/a8ff91eafb16f9d9f30b334d5674fed3/39163.ipynb&gt;TF v2.2.0rc4&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/a232ada6dacbb4850ddb40fd3643df5a/39163-tf-nightly.ipynb#scrollTo=JLIl0PO0fWGD&gt;TF-nightly&lt;/denchmark-link&gt;
. Please find the attached gist. Thanks!
		</comment>
		<comment id='2' author='javidcf' date='2020-05-05T19:19:15Z'>
		Padded batching of ragged tensors is currently not supported (and this is indicated by the error message you get).
&lt;denchmark-link:https://github.com/edloper&gt;@edloper&lt;/denchmark-link&gt;
 is there a better option for padded batching of RaggedTensors than converting them DenseTensors?
		</comment>
		<comment id='3' author='javidcf' date='2020-05-05T19:30:29Z'>
		For now, the best solution is to convert them to dense tensors.  In your example (where you have a single ragged dimension), you can do this with just:
dataset = tf.data.Dataset.from_tensor_slices(rt_with_one_ragged_dimension)
dataset = dataset.map(lambda x: x)  # convert ragged -&gt; uniform
If you had multiple ragged dimensions, then you'd need to use:
dataset = tf.data.Dataset.from_tensor_slices(rt_with_multiple_ragged_dimensions)
dataset = dataset.map(lambda x: x.to_tensor())  # convert ragged -&gt; uniform
In the future, it would be good to make this work without any need for the user to convert from ragged to uniform.  (In particular, PaddedBatchDataset could do the conversion itself, rather than raising an exception.)
		</comment>
		<comment id='4' author='javidcf' date='2020-05-06T09:33:37Z'>
		Thanks for the replies. I just thought it seemed strange to have two datasets with the same data behave differently depending on how they were created, but if this is currently expected behavior then there's no reason to have this as an open issue.
		</comment>
		<comment id='5' author='javidcf' date='2020-05-06T09:33:39Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39163&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39163&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>