<bug id='36209' author='monocongo' open_date='2020-01-25T21:25:42Z' closed_time='2020-02-13T22:38:34Z'>
	<summary>Segmentation fault when training DeepLab segmentation model</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): conda install tensorflow=1
TensorFlow version (use command below): 1.13.1
Python version: 3.6.7


I am trying to train the DeepLab model following the directions in this &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/pascal.md&gt;DeepLab example&lt;/denchmark-link&gt;
 using the following command:
&lt;denchmark-code&gt;$ python deeplab/train.py \
    --logtostderr \
    --training_number_of_steps=30000 \
    --train_split="train" \
    --model_variant="xception_65" \
    --atrous_rates=6 \
    --atrous_rates=12 \
    --atrous_rates=18 \
    --output_stride=16 \
    --decoder_output_stride=4 \
    --train_crop_size="513,513" \
    --train_batch_size=1 \
    --dataset="basins" \
    --tf_initial_checkpoint=/home/james/deeplab/pretrained/x65-b2u1s2p-d48-2-3x256-sc-cr300k_init.ckpt.data-00000-of-00001 \
    --train_logdir=./deeplab/datasets/basins/exp/train_on_train_set/train \
    --dataset_dir=./deeplab/datasets/basins
&lt;/denchmark-code&gt;

I get the following output/error:
&lt;denchmark-code&gt;&lt;thousands of useless/confusing warning messages&gt;
...
2020-01-25 16:03:48.084849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-01-25 16:03:48.086476: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559e7db9e710 executing computations on platform Host. Devices:
2020-01-25 16:03:48.086916: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Starting Session.
INFO:tensorflow:Saving checkpoint to path ./deeplab/datasets/basins/exp/train_on_train_set/train/model.ckpt
INFO:tensorflow:Starting Queues.
Segmentation fault (core dumped)
&lt;/denchmark-code&gt;

Describe the expected behavior
I am hoping that the model will train as advertised.
Code to reproduce the issue
Run a DeepLab model training as described in the DeepLab tutorial documentation referenced above.
BTW I have had this happen on two separate machines, both of which are running Ubuntu 18.04. One is a Dell laptop with CPU and the other is an AWS EC2 instance with T4 GPU. On the EC2 instance the TF version installed is 1.15.0 and I also tried using TensorFlow 2.0 but when I did that the code failed immediately with a message indicating that tf.contrib is no longer included in TensorFlow so my assumption is that this code has not been ported to work for TF2. Please advise if there is a known version of TF that this code works with, it appears to be broken in its current state using the versions of TF that I've tried.
Thanks in advance for any insight or suggestions. And/or if there is a more up-to-date semantic segmentation model from TensorFlow other than DeepLab then please point me in the right direction.
	</description>
	<comments>
		<comment id='1' author='monocongo' date='2020-01-25T22:46:06Z'>
		I have just confirmed that this also happens on an AWS EC2 instance (Ubuntu 18.04) with GPU using tensorflow-gpu version 1.15, here is the output from the training command above:
&lt;denchmark-code&gt;...
Thread 0x00007fe15eaa9740 (most recent call first):
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1443 in _call_tf_sessionrun
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1350 in _run_fn
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1365 in _do_call
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1359 in _do_run
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1180 in _run
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 956 in run
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py", line 490 in train_step
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py", line 775 in train
  File "deeplab/train.py", line 458 in main
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/absl/app.py", line 250 in _run_main
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/absl/app.py", line 299 in run
  File "/home/ubuntu/anaconda3/envs/deeplab/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py", line 40 in run
  File "deeplab/train.py", line 464 in &lt;module&gt;
Segmentation fault (core dumped)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='monocongo' date='2020-01-27T09:07:41Z'>
		As an alternative approach you could try Mask-RCNN &lt;denchmark-link:url&gt;https://github.com/matterport/Mask_RCNN&lt;/denchmark-link&gt;
  however i think maskrcnn is instance based.
		</comment>
		<comment id='3' author='monocongo' date='2020-01-27T13:20:42Z'>
		Thanks &lt;denchmark-link:https://github.com/shashank3110&gt;@shashank3110&lt;/denchmark-link&gt;
 . Unfortunately, I have already tried Mask R-CNN and had similar issues with that model (see &lt;denchmark-link:https://github.com/matterport/Mask_RCNN/issues/1961&gt;this&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/matterport/Mask_RCNN/pull/1896#issuecomment-578460832&gt;this&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='4' author='monocongo' date='2020-02-05T23:10:10Z'>
		&lt;denchmark-link:https://github.com/monocongo&gt;@monocongo&lt;/denchmark-link&gt;
 Please post this issue in &lt;denchmark-link:https://github.com/tensorflow/models/issues&gt;tensorflow/models&lt;/denchmark-link&gt;
 repo as this issue belongs to models repo and also you can get a faster response there. Thanks!
		</comment>
		<comment id='5' author='monocongo' date='2020-02-13T22:38:35Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36209&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36209&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='monocongo' date='2020-02-14T03:24:10Z'>
		Thanks for the good advice, &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;

As suggested this issue was raised on the tensorflow/models issues tracker (see &lt;denchmark-link:https://github.com/tensorflow/models/issues/8137&gt;8137&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='7' author='monocongo' date='2020-03-31T14:29:34Z'>
		Hi，I fix this issue!
I got exactly the same issue on cenos7 with tensorflow==1.15.0,  for me, it is only related with the dataset generation issues!
With cityscapes dataset, the generation of tfrecord following the tutorial doc would be
.
├── train-00002-of-00010.tfrecord
├── train-00003-of-00010.tfrecord
├── train-00004-of-00010.tfrecord
├── train-00005-of-00010.tfrecord
├── train-00006-of-00010.tfrecord
├── train-00007-of-00010.tfrecord
├── train-00008-of-00010.tfrecord
├── train-00009-of-00010.tfrecord
├── train-00000-of-00010.tfrecord
├── train-00001-of-00010.tfrecord
├── val-00000-of-00010.tfrecord
├── val-00001-of-00010.tfrecord
├── val-00002-of-00010.tfrecord
├── val-00003-of-00010.tfrecord
├── val-00004-of-00010.tfrecord
├── val-00005-of-00010.tfrecord
├── val-00006-of-00010.tfrecord
├── val-00007-of-00010.tfrecord
├── val-00008-of-00010.tfrecord
└── val-00009-of-00010.tfrecord
the shell commands for me (in the /reasearch folder),
python deeplab/train.py --dataset cityscapes \
--dataset_dir=deeplab/datasets/cityscapes/tfrecord/ \
--train_logdir deeplab/datasets/cityscapes/exp/train_on_train_set/train/ \
--train_split=train_fine --model_variant=mobilenet_v3_large_seg \
--train_crop_size=769,769 --training_number_of_steps=1000 \
--decoder_output_stride=8 --image_pyramid=1 \
--image_se_uses_qsigmoid=1 --decoder_output_is_logits=1 \
--decoder_filters=19 --decoder_use_sum_merge=1 \
--aspp_with_squeeze_and_excitation=1 --aspp_with_concat_projection=0 \
--aspp_convs_filters=128 \
--image_pooling_stride=4,5 --image_pooling_crop_size=769,769
I use pretrained weights from &lt;denchmark-link:https://github.com/tensorflow/models/issues/7911&gt;mobilenet_v3_large_seg&lt;/denchmark-link&gt;
,  since the &lt;denchmark-link:https://github.com/tensorflow/models/blob/1498d9419b799c3df61d8a8b63a879dcbca4504e/research/deeplab/datasets/data_generator.py&gt;L71-80 of script&lt;/denchmark-link&gt;
 tells me it should be  ，
_CITYSCAPES_INFORMATION = DatasetDescriptor(
    splits_to_sizes={'train_fine': 2975,
                     'train_coarse': 22973,
                     'trainval_fine': 3475,
                     'trainval_coarse': 23473,
                     'val_fine': 500,
                     'test_fine': 1525},
    num_classes=19,
    ignore_label=255,
)

(note that the parameter --train_split=train_fine)

BUT tfrecord  dataset I have all start with train-0000-...,  HERE IS THE  INCONSISTENCE !!!!
I change the name of tfrecord dataset to train_fine-00000-of-00010.tfrecord by hands,  all Segmented fault gone !!!
and the screen outputs show as expected:
......lalalalalallala........
nagement) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
I0331 21:53:58.600903 140616897775424 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0331 21:54:19.723121 140616897775424 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Starting Session.
I0331 21:54:25.378759 140616897775424 learning.py:754] Starting Session.
INFO:tensorflow:Saving checkpoint to path deeplab/datasets/cityscapes/exp/train_on_train_set/train/model.ckpt
I0331 21:54:25.692887 140594135426816 supervisor.py:1117] Saving checkpoint to path deeplab/datasets/cityscapes/exp/train_on_train_set/train/model.ckpt
INFO:tensorflow:Starting Queues.
I0331 21:54:25.693168 140616897775424 learning.py:768] Starting Queues.
2020-03-31 21:54:40.171982: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 23 of 100
2020-03-31 21:54:50.836214: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 33 of 100
INFO:tensorflow:global_step/sec: 0
I0331 21:54:54.143480 140594127034112 supervisor.py:1099] global_step/sec: 0
2020-03-31 21:55:02.310592: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 35 of 100
2020-03-31 21:55:15.670713: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 41 of 100
2020-03-31 21:55:27.116835: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 45 of 100
2020-03-31 21:55:30.685718: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 47 of 100
2020-03-31 21:55:43.929746: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 54 of 100
2020-03-31 21:55:55.429286: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 59 of 100
2020-03-31 21:55:58.944730: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 66 of 100
2020-03-31 21:56:10.205733: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 78 of 100
2020-03-31 21:56:25.282349: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 85 of 100
2020-03-31 21:56:31.110601: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 89 of 100
2020-03-31 21:56:41.034107: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 98 of 100
2020-03-31 21:56:41.034194: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:195] Shuffle buffer filled.
2020-03-31 21:56:55.479292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-31 21:59:02.041739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
INFO:tensorflow:Recording summary at step 0.
I0331 21:59:05.214339 140594118641408 supervisor.py:1050] Recording summary at step 0.
INFO:tensorflow:global step 10: loss = 3.5340 (2.648 sec/step)
I0331 21:59:49.024268 140616897775424 learning.py:507] global step 10: loss = 3.5340 (2.648 sec/step)
INFO:tensorflow:global step 20: loss = 3.2525 (8.487 sec/step)
I0331 22:00:49.050415 140616897775424 learning.py:507] global step 20: loss = 3.2525 (8.487 sec/step)
INFO:tensorflow:global step 30: loss = 3.2256 (8.564 sec/step)
I0331 22:02:40.427151 140616897775424 learning.py:507] global step 30: loss = 3.2256 (8.564 sec/step)
INFO:tensorflow:global step 40: loss = 3.2458 (12.522 sec/step)
I0331 22:04:02.487207 140616897775424 learning.py:507] global step 40: loss = 3.2458 (12.522 sec/step)
thanks for the link in &lt;denchmark-link:https://stackoverflow.com/questions/58938886/segmentation-fault-training-deeplab-with-cityscapes&gt;stackoverflow https://stackoverflow.com/questions/58938886/segmentation-fault-training-deeplab-with-cityscapes&lt;/denchmark-link&gt;

Cheers !
		</comment>
		<comment id='8' author='monocongo' date='2020-04-29T08:51:40Z'>
		Hi,
I just checked your solution &lt;denchmark-link:https://github.com/Papageno2&gt;@Papageno2&lt;/denchmark-link&gt;

1- I could make tfrecords successfuly
ls /hdd/Deeplab/models/research/deeplab/datasets/PQR/dataset/tfrecord/
train-00000-of-00004.tfrecord     trainval-00002-of-00004.tfrecord
train-00001-of-00004.tfrecord     trainval-00003-of-00004.tfrecord
train-00002-of-00004.tfrecord     val-00000-of-00004.tfrecord
train-00003-of-00004.tfrecord     val-00001-of-00004.tfrecord
trainval-00000-of-00004.tfrecord  val-00002-of-00004.tfrecord
trainval-00001-of-00004.tfrecord  val-00003-of-00004.tfrecord
2- I have two classes one background and other class, I edited data_generator.py L82-90 as the following
I have 176 samples as shown below
_PASCAL_VOC_SEG_INFORMATION = DatasetDescriptor(
splits_to_sizes={
'train': 150,
'train_aug': 100,
'trainval': 176,
'val': 26,
},
num_classes=2,
ignore_label=255,
3- I have a file called SegmentationClass contains the segmented images using LabelMe like this example
&lt;denchmark-link:https://user-images.githubusercontent.com/24913534/80576689-4cbf4480-8a0e-11ea-90eb-c116007a7b1f.png&gt;&lt;/denchmark-link&gt;

In JPEGImages I have png images like this
&lt;denchmark-link:https://user-images.githubusercontent.com/24913534/80576760-68c2e600-8a0e-11ea-8136-0e072b7b5f90.png&gt;&lt;/denchmark-link&gt;

in ImageSets/train.txt I have 150 items name of images without extension val.txt 26 item trainval.txt 150 items.
4- The tensorflow version is 1.14.0
5-When I run the local_test.sh it runs smoothly with no errors, just to check if the error from TF versions, but it seems not.
6-My images sizes are 512*512
Finally:
but When Im running the python train command I'm facing the Segmentation fault (core dumped)
python deeplab/train.py 
--logtostderr 
--training_number_of_steps=30000 
--train_split="train" 
--model_variant="xception_65" 
--atrous_rates=6 
--atrous_rates=12 
--atrous_rates=18 
--output_stride=16 
--decoder_output_stride=4 
--train_crop_size="513,513" 
--train_batch_size=1 
--dataset="pascal_voc_seg" 
--tf_initial_checkpoint=${hdd/Deeplab/models/research/deeplab/datasets/PQR/dataset/exp/train_on_tranval_set/init_modelsinit_models/deeplabv3_pascal_train_aug/model.ckpt} 
--train_logdir=${hdd/Deeplab/models/research/deeplab/datasets/PQR/dataset/exp/train_on_tranval_set/train/} 
--dataset_dir=${hdd/Deeplab/models/research/deeplab/datasets/PQR/dataset/tfrecord/} &gt; output.txt  2&gt;&amp;1
The error is still the same, here is the log file(part of it)
INFO:tensorflow:Running local_init_op.
I0429 10:23:24.512071 140539206354688 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0429 10:23:24.996261 140539206354688 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Starting Session.
I0429 10:23:26.720231 140539206354688 learning.py:754] Starting Session.
INFO:tensorflow:Starting Queues.
I0429 10:23:26.721034 140539206354688 learning.py:768] Starting Queues.
Fatal Python error: Segmentation fault
Thread 0x00007fd1d578c700 (most recent call first):
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1429 in _call_tf_sessionrun
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1341 in _run_fn
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1356 in _do_call
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1350 in _do_run
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1173 in _run
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 950 in run
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/learning.py", line 490 in train_step
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/learning.py", line 775 in train
File "deeplab/train.py", line 458 in main
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/absl/app.py", line 250 in _run_main
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/absl/app.py", line 299 in run
File "/home/jvipai/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/platform/app.py", line 40 in run
File "deeplab/train.py", line 464 in 
		</comment>
		<comment id='9' author='monocongo' date='2020-04-29T08:52:20Z'>
		the log for the error:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4550613/output.txt&gt;output.txt&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>