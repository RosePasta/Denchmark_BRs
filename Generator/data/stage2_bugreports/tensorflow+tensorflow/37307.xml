<bug id='37307' author='Krastanov' open_date='2020-03-04T18:35:16Z' closed_time='2020-05-06T02:47:41Z'>
	<summary>gradient of `einsum` is incorrect for complex numbers</summary>
	<description>
System information

Attached is a small script reproducing the problem
OS Platform and Distribution: Ubuntu 18.04 LTS
TensorFlow installed from pip
TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0
Python version: Python 3.7.5
Observed both on CPU and GPU

Describe the current behavior
The gradient of this tf.matmul expression with respect to p is computed correctly:
# `h` is an NxN complex128 matrix, `p` is float64 number, and `zero` is a float64 zero
def f(p,h):
    h1 = tf.complex(p,zero) * h
    return tf.abs(tf.reduce_sum(tf.matmul(h,h)))
But the value of the following tf.einsum expression is the same (and computed correctly), while the gradient with respect to p is wrong:
def f(p,h):
    h1 = tf.complex(p,zero) * h
    return tf.abs(tf.reduce_sum(tf.einsum('ab,bc-&gt;ac',h,h)))
The problem happens only when the matrices are complex.
Describe the expected behavior
The two functions should produce the same value (which is working fine), and their gradients with respect to p should be the same (which is not happening).
Standalone code to reproduce the issue
&lt;denchmark-link:https://colab.research.google.com/drive/1FdC-x5Q74NqoLiB6kR7Omtcb5npdrDtx&gt;https://colab.research.google.com/drive/1FdC-x5Q74NqoLiB6kR7Omtcb5npdrDtx&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Krastanov' date='2020-04-06T14:12:58Z'>
		I'm also experiencing this issue (even with tf-nightly '2.2.0-dev20200406').
Any ETA on a fix?
		</comment>
		<comment id='2' author='Krastanov' date='2020-04-06T15:51:02Z'>
		I'm also experiencing this issue, and would love to see it resolved:)
		</comment>
		<comment id='3' author='Krastanov' date='2020-04-10T08:53:44Z'>
		Same issue for me.
		</comment>
		<comment id='4' author='Krastanov' date='2020-04-29T09:45:52Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
  this issue has been blocking several research projects for weeks now, do you know if anyone is looking into a fix?
		</comment>
		<comment id='5' author='Krastanov' date='2020-04-29T13:34:44Z'>
		&lt;denchmark-link:https://github.com/ziofil&gt;@ziofil&lt;/denchmark-link&gt;
, FYI  calls can be replaced by calls to / and . It seems you use tensorflow in the same type of research work as me, and while it is a bit more clunky to write the code with  and  it ended working fine and unblocked my work (and this bug does not exist there).
Of course, this is no reason not to try to fix this bug.
		</comment>
		<comment id='6' author='Krastanov' date='2020-04-29T13:38:28Z'>
		Would another solution be to do the following?
from tensorflow.python.ops.special_math_ops import _einsum_v1 as einsum
It seems that TensorFlow 2.1 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/4eba4d514e24b6c1fdae69b40c2b958cc2a1cb42&gt;introduced a significant refactor of tf.einsum&lt;/denchmark-link&gt;
 to use the optimized einsum library, and that might be where the bug was introduced.  seems to be the original implementation.
		</comment>
		<comment id='7' author='Krastanov' date='2020-04-29T13:51:16Z'>
		For example:
from tensorflow.python.ops.special_math_ops import _einsum_v1

import tensorflow as tf


def f1(h):
    return tf.abs(tf.reduce_sum(tf.matmul(h,h)))

def f2(h):
    return tf.abs(tf.reduce_sum(tf.einsum('ab,bc-&gt;ac',h,h)))

def f3(h):
    return tf.abs(tf.reduce_sum(_einsum_v1('ab,bc-&gt;ac',h,h)))

tf.random.set_seed(1)
A = tf.Variable(tf.random.uniform(shape=[2, 2]))
B = tf.random.uniform(shape=[2, 2])

for f in (f1, f2, f3):
    with tf.GradientTape() as tape:
        C = tf.cast(A, dtype=tf.complex64) + tf.cast(B, dtype=tf.complex64)*1j
        loss = f(C)

    grad = tape.gradient(loss, A)
    print(grad)
This gives the output
tf.Tensor(
[[1.6376667 2.0820131]
 [2.087226  2.5315723]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[-2.0803595 -2.5244465]
 [-2.6582363 -3.1023233]], shape=(2, 2), dtype=float32)
tf.Tensor(
[[1.6376667 2.0820131]
 [2.087226  2.5315723]], shape=(2, 2), dtype=float32)
		</comment>
		<comment id='8' author='Krastanov' date='2020-04-29T15:44:46Z'>
		&lt;denchmark-link:https://github.com/bloops&gt;@bloops&lt;/denchmark-link&gt;
 are you aware of this issue?
		</comment>
		<comment id='9' author='Krastanov' date='2020-04-29T18:05:25Z'>
		Seems like a number of additional cases fail for complex numbers, which weren't noticed since gradient tests are performed only for float64.
		</comment>
		<comment id='10' author='Krastanov' date='2020-04-29T19:06:16Z'>
		I wasn't aware of this. I'll take a look...
		</comment>
		<comment id='11' author='Krastanov' date='2020-04-29T19:10:13Z'>
		I've tried adding complex tests, many are failing for complex: &lt;denchmark-link:https://github.com/Randl/tensorflow/commit/f6865e57c93a1d92df30aee4b3756b2979b9125c&gt;Randl@f6865e5&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='Krastanov' date='2020-04-29T21:28:55Z'>
		
Seems like a number of additional cases fail for complex numbers, which weren't noticed since gradient tests are performed only for float64.

&lt;denchmark-link:https://github.com/Randl&gt;@Randl&lt;/denchmark-link&gt;
 do you mean for einsum or in general?
		</comment>
		<comment id='13' author='Krastanov' date='2020-04-29T21:32:02Z'>
		for einsum. I haven't checked other things, but maybe it worth adding complex number to tests in more systematic way
		</comment>
		<comment id='14' author='Krastanov' date='2020-05-06T02:47:43Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37307&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37307&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>