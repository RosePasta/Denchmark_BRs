<bug id='10685' author='vade' open_date='2017-06-13T17:07:25Z' closed_time='2018-06-02T18:40:14Z'>
	<summary>Darwin support for MKL build / configure script</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mac OS X 10.12.4, Darwin
TensorFlow installed from (source or binary):
Source, git tag 1.2.0 RC 2
TensorFlow version (use command below):
1.2 RC 2
Bazel version (if compiling from source):
bazel version
..............
Build label: 0.4.3-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Dec 22 15:20:15 2016 (1482420015)
Build timestamp: 1482420015
Build timestamp as int: 1482420015
CUDA/cuDNN version:
N/A
GPU model and memory:
N/A
Exact command to reproduce:
./configure
Please specify the location of python. [Default is /usr/bin/python]:
Found possible Python library paths:
/Library/Python/2.7/site-packages
Please input the desired Python library path to use.  Default is [/Library/Python/2.7/site-packages]

Using python library path: /Library/Python/2.7/site-packages
Do you wish to build TensorFlow with MKL support? [y/N] y
MKL support will be enabled for TensorFlow
Do you wish to download MKL LIB from the web? [Y/n] Y
Darwin is unsupported yet
You can collect some of this information using our environment capture script:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&lt;/denchmark-link&gt;

N/A
You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Darwin / Mac OS X support for Intel's optional MKL optimizations. MKL appears to have darwin support, so I am unsure why it is not supported in Tensorflow. I imagine this is on a to-do, but a publicly tracked feature request might be helpful. Thank you.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

N/A
	</description>
	<comments>
		<comment id='1' author='vade' date='2017-06-13T17:22:14Z'>
		Any eta on darwin support?
		</comment>
		<comment id='2' author='vade' date='2017-06-14T03:12:30Z'>
		&lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
 Who would be a good person to address MKL support on MacOS?
		</comment>
		<comment id='3' author='vade' date='2017-06-15T02:18:33Z'>
		You have to manually tweak the config script to download the OSX MKL version.  The URL is slightly different.  Intel did not include that check in the script.  I will own this as I want to do the process so I can finish up some benchmarks to include in an updated performance guide.  It would be awesome but not necessary if you (&lt;denchmark-link:https://github.com/vade&gt;@vade&lt;/denchmark-link&gt;
) found the URL and updated the config script.
		</comment>
		<comment id='4' author='vade' date='2017-06-15T03:19:43Z'>
		Isn't there a separate problem that  Tensorflow MKL build requires MKL-DNN which is currently Linux only?  See this issue - &lt;denchmark-link:https://github.com/oneapi-src/oneDNN/issues/10&gt;oneapi-src/oneDNN#10&lt;/denchmark-link&gt;
.
Discussion that Tensorflow MKL build uses MKL-DNN primitives is in the Intel press release - &lt;denchmark-link:https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture&gt;https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='vade' date='2017-06-15T04:13:25Z'>
		I am 99% sure (not 100% as I like to leave room for error) that we are not using MKL-DNN open source.  It downloads the binary MKL if I am not mistaken.  I also spoke to Intel today (the people that did the PRs for MKL) and the person assured me it supports Mac OSX and I needed to tweak the config.  I am trying to do the build but Google policy is slowing me down.
Update:  I checked the ./configure file and it does seem to be downloading the OSS version, which is not what I was told by Intel.  I am talking with them now and working to figure it out.  There is a free but non OSS version of the MKL as well, which might provide better support for OSX.
		</comment>
		<comment id='6' author='vade' date='2017-06-15T05:59:08Z'>
		Hit the same pole, using a mac mini
&lt;denchmark-code&gt;Do you wish to download MKL LIB from the web? [Y/n] 
Darwin is unsupported yet
&lt;/denchmark-code&gt;

What to do next?
&lt;denchmark-code&gt;== cat /etc/issue ===============================================
Darwin yuldeMac-mini.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.4

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.1.0 (clang-802.0.42)
Target: x86_64-apple-darwin16.5.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin yuldeMac-mini.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.2.0)
tensorflow (1.1.0)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='vade' date='2017-06-15T13:39:54Z'>
		I took a first pass and it was not as easy as tweaking the download and small change to the ./configure file.  This may take a few days or even longer to figure out.  The performance improvement I have personally tested on Linux is substantial which should translate equally to OSX.  I will update this thread as I go.  One option I have not tried is to download the MKL from Intel and give that a try over the OSS version.
		</comment>
		<comment id='8' author='vade' date='2017-06-15T13:59:58Z'>
		Thank you &lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
 for looking into this so thoroughly and quickly. With the loss of potential GPU support on OS X, us Mac users can take all the client side gains we can!
Very appreciated!
		</comment>
		<comment id='9' author='vade' date='2017-06-15T14:15:23Z'>
		&lt;denchmark-link:https://github.com/vade&gt;@vade&lt;/denchmark-link&gt;
 In the mean time make sure you are compiling with AVX or AVX2 as that makes a big difference.  I hope to publish some info on the performance page soon.  I just got an email back from Intel and I believe they are interested in helping us work through it.  Sadly the dream of just swapping out the download was not the solution.  :-)  In some ways I am not sure why I thought it would be that easy....nothing is that easy.
		</comment>
		<comment id='10' author='vade' date='2017-06-15T14:23:57Z'>
		I have been using AVX/AVX2 and FMA and it certainly does help!
		</comment>
		<comment id='11' author='vade' date='2017-06-16T15:44:24Z'>
		Update:  Using my limited Bazel and c++ skills I was a able to get it to compile on Mac OSX but when I tried to import tensorflow I ended up with an error.  I am going to try to find someone on the team with a much higher level of skill to work on this.  My gut feeling is this is doing to take some time.  Leaving assigned to me until I find someone and I am very interested in tracking this to completion or finding out it will not work.  And wow, compiling on OSX beyond CPU looks less than fun.  I read all the old bugs on cuDNN, that looked less than pleasant
The error I ended up with after I turned of SIP so the libraries would load and used an updated version of clang via brew.
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/Library/Python/2.7/site-packages/tensorflow/__init__.py", line 24, in &lt;module&gt;
    from tensorflow.python import *
  File "/Library/Python/2.7/site-packages/tensorflow/python/__init__.py", line 64, in &lt;module&gt;
    from tensorflow.python.framework.framework_lib import *
  File "/Library/Python/2.7/site-packages/tensorflow/python/framework/framework_lib.py", line 100, in &lt;module&gt;
    from tensorflow.python.framework.subscribe import subscribe
  File "/Library/Python/2.7/site-packages/tensorflow/python/framework/subscribe.py", line 26, in &lt;module&gt;
    from tensorflow.python.ops import variables
  File "/Library/Python/2.7/site-packages/tensorflow/python/ops/variables.py", line 26, in &lt;module&gt;
    from tensorflow.python.ops import control_flow_ops
  File "/Library/Python/2.7/site-packages/tensorflow/python/ops/control_flow_ops.py", line 69, in &lt;module&gt;
    from tensorflow.python.ops import math_ops
  File "/Library/Python/2.7/site-packages/tensorflow/python/ops/math_ops.py", line 2452, in &lt;module&gt;
    fft = gen_spectral_ops.fft
AttributeError: 'module' object has no attribute 'fft'

		</comment>
		<comment id='12' author='vade' date='2017-06-18T15:47:18Z'>
		I managed to compile it on a work computer. Besides editing the configure script I remember also changing the file names in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/third_party/mkl/BUILD&gt;https://github.com/tensorflow/tensorflow/blob/master/third_party/mkl/BUILD&lt;/denchmark-link&gt;
 to match the ones I downloaded (that file has  for linux shared libraries but I had downloaded  dynamic libraries).
I also symlinked the dylibs into /usr/local/lib/ --- having configure set the default path to /opt/intel/mklml wasn't sufficient for me because some intermediate binaries were causing the linker to complain about not finding intermediate binaries. passing the /opt/intel/mklml/ path to the linker at the bazel build stage didn't work.
		</comment>
		<comment id='13' author='vade' date='2017-06-19T14:58:43Z'>
		&lt;denchmark-link:https://github.com/nuchi&gt;@nuchi&lt;/denchmark-link&gt;
   Were you able to use it after you compiled?  Asking because I was able to get it to compile and MKL was 100% included but then I get the error when I first tired to use it.
This is great data.  We and maybe I will keep trying.  Any info you ca provide would be great.  I also had to do the symlink thing  :-)
		</comment>
		<comment id='14' author='vade' date='2017-06-19T15:34:17Z'>
		&lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
 yes, passed the mkl unit tests and also could successfully import tensorflow and eval a hello world tensor. I'll be able to provide more info in a week or so — I'm away from that computer at the moment.
		</comment>
		<comment id='15' author='vade' date='2017-06-19T15:52:07Z'>
		That is awesome.  No rush.   Any info is great and knowing it worked for you I will give it a try again from scratch.  By the time mine compiled I had made a huge mess.  :-)
		</comment>
		<comment id='16' author='vade' date='2017-06-25T20:26:53Z'>
		&lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
 More information!
System: Mac OS X 10.11.6
Intel MKL library: mklml_mac_20180.0.20170425.tgz (from &lt;denchmark-link:https://github.com/01org/mkl-dnn/releases&gt;https://github.com/01org/mkl-dnn/releases&lt;/denchmark-link&gt;
)
Tensorflow commit: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/38e0922d1e2dcd572379af4496f878492e9f689a&gt;38e0922&lt;/denchmark-link&gt;
...
Installed MKL to /opt/intel/mklml
Symlink the two .dylib files to /usr/local/lib
Changes to configure: Change MKL_ML_LIB_PATH to lib/libmklml.dylib, MKL_ML_OMP_LIB_PATH to lib/libiomp5.dylib, comment out the parts that say "if linux:", comment out the parts that deal with libdl.so.2.
Changes to third_party/mkl/BUILD: Change the list of three .so files to the two .dylib files
When configuring: Yes to use MKL, No to download. (I downloaded manually.) Path to MKL: /opt/intel/mklml
Build command: bazel build --verbose-failures -c opt --config=opt --config=mkl --copt="-DEIGEN_USE_VML" --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.1 --copt=-msse4.2 --linkopt="-Wl,-rpath,/opt/intel/mklml/lib" --linkopt="-L/opt/intel/mklml/lib" --linkopt="-lmklml" --linkopt="-iomp5" //tensorflow/tools/pip_package:build_pip_package
It's possible I missed some stuff, but I think that's it. Some of this stuff is surely superfluous, but after it worked I didn't spend any effort trying to pare it down to the minimum.
		</comment>
		<comment id='17' author='vade' date='2017-06-26T03:30:28Z'>
		&lt;denchmark-link:https://github.com/nuchi&gt;@nuchi&lt;/denchmark-link&gt;
   This is great.  The team is very much interested in making this work.  I hope we get it sort out officially in a few weeks but no promises as anything can happen and it looks like vacation season is here.  I will try you info and at a min, include it for people on the performance guide page as a short-term solution if I post some MKL stuff in a couple weeks.  Your effort is really appreciated.  I think I was close but I I did not use the rpath variable and I suspect that is why I ended up with a broken build.  :-)
		</comment>
		<comment id='18' author='vade' date='2017-07-02T05:28:14Z'>
		Something like CC=clang-mp-4.0  bazel build  --copt=-I/usr/local/include/libomp -c opt --config=opt --config=mkl --copt="-DEIGEN_USE_VML" --copt="-march=haswell" --linkopt="-Wl,-rpath,/opt/intel/mklml/lib" --linkopt="-L//opt/intel/mklml/lib" --linkopt="-lmklml" --linkopt="-liomp5" //tensorflow/tools/benchmark:benchmark_model works for me. The clang come with Xcode doesn't enable OpenMP support. I use clang-4.0 (clang-mp-4.0) from MacPort instead. However, on my late 2014 iMac, MKL doesn't provide better performance for most cases I tested. Anyway, I'll try to create patches and send PR later.
		</comment>
		<comment id='19' author='vade' date='2017-07-02T05:41:39Z'>
		It seems I should delay the patch till &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/11212&gt;#11212&lt;/denchmark-link&gt;
 from &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 is done.
		</comment>
		<comment id='20' author='vade' date='2018-02-27T09:04:54Z'>
		I am not sure if I am going to keep digging this rabbit hole for too long.
I might stick to build with commented out lite.toco or just use it from Docker, as performance overhead is barely noticeable.
		</comment>
		<comment id='21' author='vade' date='2018-02-27T22:46:25Z'>
		🎉I DID IT!
It am not sure what was causing the issue (I was also playing with different optimization level and debug build, switching branches, etc.), but restarting from fresh checkout, clean conda env, rerun configure and build gave a working native binaries!!!
With all the possible CPU runtime optimizations settings from &lt;denchmark-link:https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu&gt;here&lt;/denchmark-link&gt;
 I got this:
&lt;denchmark-h:h1&gt;MKL - total images/sec: 5.82&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;no MKL - total images/sec: 1.31&lt;/denchmark-h&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

MKL benchmark command line
&lt;denchmark-code&gt;python tf_cnn_benchmarks.py --forward_only=False --device=cpu --mkl=True \ 
            --kmp_blocktime=0 --nodistortions --model=resnet50 --data_format=NCHW \
            --batch_size=32 --num_inter_threads=1 --num_intra_threads=4
&lt;/denchmark-code&gt;

		</comment>
		<comment id='22' author='vade' date='2018-02-27T23:51:47Z'>
		I have uploaded my wheel with MKL here &lt;denchmark-link:https://github.com/anton-matosov/tensorflow-wheels&gt;https://github.com/anton-matosov/tensorflow-wheels&lt;/denchmark-link&gt;

If you would like to build it yourself, please follow instructions provided here: &lt;denchmark-link:https://github.com/anton-matosov/tensorflow-wheels/tree/master/Tensorflow-Wheels/MacOS/MKL&gt;https://github.com/anton-matosov/tensorflow-wheels/tree/master/Tensorflow-Wheels/MacOS/MKL&lt;/denchmark-link&gt;
 (Disclaimer: tested on my machine only)
Meanwhile I am going to complete the MKL build to have MKL dylib files bundled inside the wheel and I will submit PR after that.
		</comment>
		<comment id='23' author='vade' date='2018-03-17T15:00:10Z'>
		Nagging Assignees &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='24' author='vade' date='2018-04-01T12:32:09Z'>
		Nagging Assignees &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='25' author='vade' date='2018-04-01T20:31:45Z'>
		This issue was fixed by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/17396&gt;#17396&lt;/denchmark-link&gt;

		</comment>
		<comment id='26' author='vade' date='2018-04-16T12:32:11Z'>
		Nagging Assignees &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='27' author='vade' date='2018-05-01T18:39:33Z'>
		Nagging Assignees &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='28' author='vade' date='2018-05-01T22:14:49Z'>
		I have just tried and it looks like addition of OMP threads is actually causing a breakage on macos now.
&lt;denchmark-link:https://github.com/tatianashp&gt;@tatianashp&lt;/denchmark-link&gt;
 Could you link in Intel on this issue? What is the plan for support for macos, especially since clang does not have openmp support?
		</comment>
		<comment id='29' author='vade' date='2018-05-01T22:17:33Z'>
		&lt;denchmark-link:https://github.com/jbobba&gt;@jbobba&lt;/denchmark-link&gt;
 It looks like &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/17931&gt;#17931&lt;/denchmark-link&gt;
 is breaking MKL support on macos.
What is your recommendation?
		</comment>
		<comment id='30' author='vade' date='2018-05-01T22:32:09Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 will investigate. "clang does not have openmp support" - are you referring to a TF-specific clang version/build? In general, clang does support openmp, so i'm surprised it fails here.
		</comment>
		<comment id='31' author='vade' date='2018-05-01T22:35:02Z'>
		I am using the out of the box clang that comes with xcode. A quick search showed that omp.h is generally unavailable with xcode's clang.
		</comment>
		<comment id='32' author='vade' date='2018-05-01T23:03:24Z'>
		The clang version that comes with Mac OS does not support openmp.  The current clang (6.0) that comes with LLVM supports openmp which is how I built TF 1.8 with MKL and can be installed with brew.  Just have to point compiler, include, linker flags to the new location, e.g, CC=/usr/local/opt/llvm/bin/clang and set path so it sees this version of clang and not the default Mac OS version.
I had to add these statements to bazel-build :   --config=mkl --cpu=darwin   the later statement is because bazel 0.12 seems to want to generate ARM code on the Mac.
		</comment>
		<comment id='33' author='vade' date='2018-05-01T23:36:40Z'>
		At head bazel 0.12 issue on mac should be resolved.
For this case, we want to fully support the most common compiler on the platforms, which for macos case is clang that comes with xcode, rather than llvm.
		</comment>
		<comment id='34' author='vade' date='2018-05-01T23:55:23Z'>
		The Xcode version of clang goes not support openmp (omp.h) which is now required to build TF 1.8 (at least with MKL support).
		</comment>
		<comment id='35' author='vade' date='2018-05-02T01:08:53Z'>
		&lt;denchmark-link:https://github.com/dfumento&gt;@dfumento&lt;/denchmark-link&gt;
 the PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/18726&gt;#18726&lt;/denchmark-link&gt;
 about supporting  mac mkl build  could resove the issue that default clang goes not support openmp flag in MacOs.
For defalut macos compiler clang you should use openmp as below:

if_mkl_darwin(["-Xpreprocessor", "-fopenmp"])

		</comment>
		<comment id='36' author='vade' date='2018-05-02T23:13:21Z'>
		Unfortunately, adding "-fopenmp" on macos will result in:
&lt;denchmark-code&gt;clang: error: unsupported option '-fopenmp'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='37' author='vade' date='2018-05-02T23:42:15Z'>
		
Unfortunately, adding "-fopenmp" on macos will result in:


clang: error: unsupported option '-fopenmp'

As I said, you must install the llvm version of clang (6.0) which handles mp support, e.g.  '-fopenmp' . which I did with brew.  Then update the various compiler, include, and linker environment variables to point to the brew installed version of clang as I noted above.
		</comment>
		<comment id='38' author='vade' date='2018-05-02T23:47:42Z'>
		&lt;denchmark-link:https://github.com/dfumento&gt;@dfumento&lt;/denchmark-link&gt;
 As I mentioned before, the official support of tensorflow will have to stay with whatever default toolchain macos has.
Therefore, if we (TensorFlow team) will support MKL officially, one of the requirements would be to either roll back &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/17931&gt;#17931&lt;/denchmark-link&gt;
, or write more preprocessor commands to avoid using openmp on macos.
		</comment>
		<comment id='39' author='vade' date='2018-05-03T00:36:39Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 we will look into adding more preprocessor guards to avoid openmp on default macos builds.
		</comment>
		<comment id='40' author='vade' date='2018-05-03T13:47:48Z'>
		
@gunan we will look into adding more preprocessor guards to avoid openmp on default macos builds.

I'm assuming you'll put in a bazel-build option flag for the openmp version?
		</comment>
		<comment id='41' author='vade' date='2018-05-03T15:47:54Z'>
		Yes and _OPENMP around openmp code.
		</comment>
		<comment id='42' author='vade' date='2018-05-04T08:33:42Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jbobba&gt;@jbobba&lt;/denchmark-link&gt;
 default toolchain clang of  macos would use ["-Xpreprocessor", "-fopenmp"] to support openmap flag but xcode version clang can't use in this method.
		</comment>
		<comment id='43' author='vade' date='2018-05-05T03:02:54Z'>
		&lt;denchmark-link:https://github.com/opencici2006&gt;@opencici2006&lt;/denchmark-link&gt;
 default toolchain on macOS is "Xcode command line tools" which has clang that doesn't support "-fopenmp"
		</comment>
		<comment id='44' author='vade' date='2018-05-22T17:31:55Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/19136&gt;#19136&lt;/denchmark-link&gt;
 has the preprocessor guards around openmp code.
		</comment>
		<comment id='45' author='vade' date='2018-06-02T18:40:14Z'>
		I just verified that this is now working.
Thanks &lt;denchmark-link:https://github.com/anton-matosov&gt;@anton-matosov&lt;/denchmark-link&gt;
 for contributing this, and thanks &lt;denchmark-link:https://github.com/jbobba&gt;@jbobba&lt;/denchmark-link&gt;
 for openmp fixes!
		</comment>
	</comments>
</bug>