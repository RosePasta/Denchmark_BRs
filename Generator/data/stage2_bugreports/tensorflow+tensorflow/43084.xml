<bug id='43084' author='bertankursun' open_date='2020-09-09T16:51:33Z' closed_time='2020-09-28T16:13:45Z'>
	<summary>"Failed starting model allocation." while trying to allocate tensors</summary>
	<description>
System information
Hello everyone,
I am working on a project to implement a prediction algorithm, which is to be implemented for a microcontroller, based on an LSTM network. Therefore, I have not installed the complete library, instead I have downloaded the most recent repository and I have been selecting the files that are useful for my purpose(one by one). For the beginning I am building the c++ project on "S32 Design Studio" and running it on the laptop with Windows 10(haven't started to compile on microcontroller yet)
**the tf keras model which was as below: **
&lt;denchmark-code&gt;model = tf.keras.models.Sequential([
    tf.keras.layers.Input(batch_input_shape=(1,6, 3), name='input'),
    tf.keras.layers.LSTM(n_neurons, time_major=False, return_sequences=False),
    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid, name='output')
])
model.compile(loss='mean_squared_error', optimizer='adam')
&lt;/denchmark-code&gt;

and I have converted it without any problem. This is the output of conversion :
&lt;denchmark-code&gt;run_model = tf.function(lambda x: model(x))
# This is important, let's fix the input size.
BATCH_SIZE = 1
STEPS = time_ev
INPUT_SIZE = 3
concrete_func = run_model.get_concrete_function(
    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], model.inputs[0].dtype))

# model directory.
MODEL_DIR = "keras_lstm"
model.save(MODEL_DIR, save_format="tf", signatures=concrete_func)

converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)
tflite_model = converter.convert()

# Save the TF Lite model.
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:109: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:109: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: keras_lstm/assets
&lt;/denchmark-code&gt;

Then I have downloaded the model as a .cc file because I could not use the function to read .tflite file:
&lt;denchmark-code&gt;# Define paths to model files
import os

MODELS_DIR = 'models/'
if not os.path.exists(MODELS_DIR):
    os.mkdir(MODELS_DIR)
MODEL_TF = MODELS_DIR + 'model.pb'
MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'
MODEL_TFLITE = MODELS_DIR + 'model.tflite'
MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'

# # Save the model to disk
open(MODEL_NO_QUANT_TFLITE, "wb").write(tflite_model)

# Install xxd if it is not available
!apt-get update &amp;&amp; apt-get -qq install xxd
# Convert to a C source file
!xxd -i {MODEL_NO_QUANT_TFLITE} &gt; {MODEL_TFLITE_MICRO}
# Update variable names
REPLACE_TEXT = MODEL_NO_QUANT_TFLITE.replace('/', '_').replace('.', '_')
!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}

files.download("models/model.cc") 
&lt;/denchmark-code&gt;

Finally I have this small script just to import the model and build the interpreter:
&lt;denchmark-code&gt;#include &lt;string.h&gt;

#include "tensorflow/lite/micro/kernels/micro_ops.h"
#include "tensorflow/lite/micro/micro_error_reporter.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "tensorflow/lite/micro/all_ops_resolver.h"
#include "tensorflow/lite/version.h"
#include "model.h"
#include "tensorflow/lite/micro/micro_optional_debug_tools.h"

// Globals, used for compatibility with Arduino-style sketches.
namespace {
tflite::ErrorReporter* error_reporter;
//const tflite::Model* model ;
tflite::MicroInterpreter* interpreter = nullptr;

// Create an area of memory to use for input, output, and intermediate arrays.
// Minimum arena size, at the time of writing. After allocating tensors
// you can retrieve this value by invoking interpreter.arena_used_bytes().
constexpr size_t allocator_buffer_size = 2096 /* optimal arena size at the time of writting. */
			+ 16 /* alignment */ + 100 /* some headroom */;

uint8_t allocator_buffer[allocator_buffer_size];
} // namespace

int main() {

	const tflite::Model* model = ::tflite::GetModel(g_model);

	if (model-&gt;version() == TFLITE_SCHEMA_VERSION) {
		puts("Model provided is supported.\n");
		//fprintf(stderr, "Model provided is supported.\n");

	}

	tflite::MicroErrorReporter micro_error_reporter;
	error_reporter = &amp;micro_error_reporter;

	static tflite::AllOpsResolver resolver;

         static tflite::MicroInterpreter static_interpreter(model, resolver, allocator_buffer, allocator_buffer_size, error_reporter);

         interpreter = &amp;static_interpreter;
         interpreter-&gt;AllocateTensors();
         printf("Interpreter has %d tensors and %d nodes\n",
                 interpreter-&gt;tensors_size(), interpreter-&gt;operators_size());
	return 0;

}
&lt;/denchmark-code&gt;

When I run the code, I obtain this in the console :
&lt;denchmark-code&gt;Model provided is supported.

Interpreter has 0 tensors and 4 nodes

Didn't find op for builtin opcode 'UNIDIRECTIONAL_SEQUENCE_LSTM' version '1'


Failed to get registration from op code UNIDIRECTIONAL_SEQUENCE_LSTM
 

Failed starting model allocation.
&lt;/denchmark-code&gt;

Can anybody help me ? Is this network not supported ?
	</description>
	<comments>
		<comment id='1' author='bertankursun' date='2020-09-09T17:40:37Z'>
		Can you try with TF nightly?
		</comment>
		<comment id='2' author='bertankursun' date='2020-09-10T04:59:16Z'>
		Hi &lt;denchmark-link:https://github.com/bertankursun&gt;@bertankursun&lt;/denchmark-link&gt;
 As I check the op is not supported in TFlite Micro now.
If possible, you should tweak your model to only use supported op in: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/all_ops_resolver.cc&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/all_ops_resolver.cc&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='bertankursun' date='2020-09-10T13:16:25Z'>
		
Can you try with TF nightly?

I had done this at the beginning :
&lt;denchmark-code&gt;!pip install tf-nightly

import tensorflow.compat.v2 as tf
tf.enable_v2_behavior()

&lt;/denchmark-code&gt;

then I have changed to "import tensorflow as tf" and I had another error with the model :
Because now the subgraph size is 2 whereas it was 1 before...
&lt;denchmark-code&gt;Only 1 subgraph is currently supported.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='bertankursun' date='2020-09-10T13:54:11Z'>
		
Hi @bertankursun As I check the op is not supported in TFlite Micro now.
If possible, you should tweak your model to only use supported op in: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/all_ops_resolver.cc

Thanks for the suggestion. I am just confused because my model is very simple and I can not believe that LSTM layer is unsupported.
		</comment>
		<comment id='5' author='bertankursun' date='2020-09-10T14:44:40Z'>
		&lt;denchmark-link:https://github.com/bertankursun&gt;@bertankursun&lt;/denchmark-link&gt;
 take a look at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/40574#issuecomment-647922464&gt;#40574 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='bertankursun' date='2020-09-11T06:48:49Z'>
		
@bertankursun take a look at #40574 (comment)

The case is a bit different. &lt;denchmark-link:https://github.com/bertankursun&gt;@bertankursun&lt;/denchmark-link&gt;
 is trying to run the model on Micro controller using TFLite Micro.
Issue#40574 is about running it on Android using TFLite.
		</comment>
		<comment id='7' author='bertankursun' date='2020-09-11T10:24:22Z'>
		&lt;denchmark-link:https://github.com/thaink&gt;@thaink&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 I have found the UNIDIRECTIONAL_SEQUENCE_LSTM op under tensorflow/lite/kernels. Do you think that can be used by adding to lite/micro/kernels? I started yesterday but it required many other files from the library and it got complicated and some references were not found in the end.
		</comment>
		<comment id='8' author='bertankursun' date='2020-09-11T11:42:41Z'>
		&lt;denchmark-link:https://github.com/thaink&gt;@thaink&lt;/denchmark-link&gt;
 You are right. With just a quick overview I was confused by the  only label as generally we tag with the micro one.
		</comment>
		<comment id='9' author='bertankursun' date='2020-09-14T06:02:01Z'>
		
@thaink @bhack I have found the UNIDIRECTIONAL_SEQUENCE_LSTM op under tensorflow/lite/kernels. Do you think that can be used by adding to lite/micro/kernels? I started yesterday but it required many other files from the library and it got complicated and some references were not found in the end.

Most kernels are ported from TFLite to Micro so I think it is possible.
can some reference commits like &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/172647f58355ae0e87b9160a43da89f420151fd0&gt;172647f&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/891e3dc6219bc886e5dbd22b268cd097ab2effcd&gt;891e3dc&lt;/denchmark-link&gt;
 help?
		</comment>
		<comment id='10' author='bertankursun' date='2020-09-14T07:47:18Z'>
		And make sure the conversion follow &lt;denchmark-link:https://www.tensorflow.org/lite/convert/rnn&gt;https://www.tensorflow.org/lite/convert/rnn&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='bertankursun' date='2020-09-21T15:34:00Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='12' author='bertankursun' date='2020-09-28T16:13:43Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='13' author='bertankursun' date='2020-09-28T16:13:46Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43084&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43084&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>