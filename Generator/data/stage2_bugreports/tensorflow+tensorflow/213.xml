<bug id='213' author='evanthebouncy' open_date='2015-11-14T00:56:03Z' closed_time='2016-06-16T22:48:56Z'>
	<summary>tensorflow howto for sharing variable is confusing</summary>
	<description>
at here:
&lt;denchmark-link:http://tensorflow.org/how_tos/variable_scope/index.md&gt;http://tensorflow.org/how_tos/variable_scope/index.md&lt;/denchmark-link&gt;

The tutorial talk about using "two sets of variables" and talk about their duplication, however the network itself uses 2 layers of convolution. So there's 2 different things that can be the quantity of 2.

The number of layers is 2, being conv1 and conv2, these 2 should be distinct
The number of image filters, applied once to each image, these 2 should be identical

I was having a hard time understanding at first and thought we're attempting to use the same weights for both of the conv layers. It didn't help that the definition for "variables_dict" only explicitly states the existence for the weights for the first conv layer, leading me to believe that the weights of the 2 layers are actually shared as well.
I think a simple fix is to make the network have say 5 conv layers instead of 2, this way you get to demonstrate variable_scope as well in the later section
Just my 2 cents, I starred at this for much longer than I should have because of this confusion.
	</description>
	<comments>
		<comment id='1' author='evanthebouncy' date='2015-11-14T17:33:34Z'>
		Thanks, we'll take a look to see if we can reduce the confusion!
		</comment>
		<comment id='2' author='evanthebouncy' date='2015-11-18T21:42:04Z'>
		just as a follow up:
I think it'll be useful to include a discussion on variable creation in places where it is not explicit.
For instance,
cell1 = rnn.lstm( ... )
actually does not create any variables, and it's only when you call it
out, state = cell1(x, state)
does the variables gets created. Since the variable creating is not explicit in both case, one (such as me) can get very confused on where to use variable sharing and when to not use it.
		</comment>
		<comment id='3' author='evanthebouncy' date='2016-06-06T17:25:09Z'>
		&lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
: Did this ever happen?
		</comment>
		<comment id='4' author='evanthebouncy' date='2016-06-06T17:47:49Z'>
		I doubt it -- assigning to Lukasz
		</comment>
		<comment id='5' author='evanthebouncy' date='2016-06-16T22:48:56Z'>
		Improved the tutorial to clarify which sets of variables are meant in a recent CL, is now live on master.
		</comment>
		<comment id='6' author='evanthebouncy' date='2017-05-31T23:07:55Z'>
		Hi,
My question may be a little bit different than what is already asked.
If I define a class like below:
&lt;denchmark-code&gt;
class Dense:
    def __init__(self,Dsize,OSize):
        self.variables_dict = {
            "FirstLayer": tf.Variable(tf.random_normal(Dsize),  name="weights"),
            "FirstLayer_b": tf.Variable(tf.zeros(OSize), name="biases")
        }
    def apply(self, input, equation = 'ijk,kd-&gt;ijd'):
        output = tf.einsum(equation, input, self.variables_dict['FirstLayer']) + self.variables_dict['FirstLayer_b']
        return output
&lt;/denchmark-code&gt;

And get one instance of this class in my code and use it multiple times by using its apply function. Does it mean that I have shared the same weight matrix (they have equal values in them) in different parts of my graph? Or it will make different matrices and update the variables differently?
I am not using the reuse = True option.
I would appreciate if someone helps me with this issue. It will help me a lot to understand the logic behind generating a graph in Tensorflow and also writing a clean and readable code.
		</comment>
		<comment id='7' author='evanthebouncy' date='2017-05-31T23:16:51Z'>
		Please use tf.get_variable. Reuse will not work with tf.Variable and you should basically never use it, always go for tf.get_variable instead.
		</comment>
		<comment id='8' author='evanthebouncy' date='2017-05-31T23:25:39Z'>
		&lt;denchmark-link:https://github.com/lukaszkaiser&gt;@lukaszkaiser&lt;/denchmark-link&gt;
  Thanks a lot for your prompt response and the good tip.
Actually, my main concern is about using object oriented style programming in TF.
If I implement a costume layer as a class (Dense layer in my toy example above), can I do weight sharing by just getting one instance of that class and use it multiple times? Or the TF engine will internally make different ones and update them completely different and that layer won't have same weights with other ones?
Thanks
		</comment>
		<comment id='9' author='evanthebouncy' date='2017-05-31T23:52:30Z'>
		It is a little tricky to do the OO-style right, but we're working to provide a convenient way to do it as follows.
First of all, let your class be a sub-class of Layer from tensorflow/python/layers/base.py: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/base.py&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/base.py&lt;/denchmark-link&gt;

This will handle everything related to scopes. It will open new scope if you provide a name for your layer, it will reuse if you're referring to the same object, but create new variables when you create a new object. If you subclass from Layer, the only thing you need to implement are the "build" and "call" functions, similar to Keras. You can see how we do it for the core Dense layer here:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/core.py#L106&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/core.py#L106&lt;/denchmark-link&gt;

I think the easiest way to do OO is to do the same, you can even use our OO layers already. They are not part of the public API yet because we want to test them properly and let them mature, but I think they're far enough to give them a try. If you want to have a look, the expected behaviors in terms of interaction with reuse have their unit tests here:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/core_test.py&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/core_test.py&lt;/denchmark-link&gt;

Hope that helps, we want to make a great OO interface too, so let us know if you try the core OO stuff and have troubles.
		</comment>
	</comments>
</bug>