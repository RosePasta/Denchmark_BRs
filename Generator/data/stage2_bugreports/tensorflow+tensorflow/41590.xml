<bug id='41590' author='sedol1339' open_date='2020-07-21T11:46:13Z' closed_time='2020-07-27T15:57:35Z'>
	<summary>Jpeg decoding (for example when loading TFRecords from files) causes error on TPU when trying to fit a model</summary>
	<description>
System information

TensorFlow version (use command below): 2.2.0 (v2.2.0-0-g2b96f3662b)
Python version: 3.6.9
GPU model and memory: Google Colab TPU

I'm not sure that this is a bug, but I've encountered this weird behaviour with my .tfrec dataset and made simple code to reproduce it. This problem only exists at TPU.
Firstly I initialize TPU:
&lt;denchmark-code&gt;import os
import tensorflow as tf
import numpy as np

tf.get_logger().propagate = False
resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu = 'grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;INFO:tensorflow:Initializing the TPU system: grpc://10.26.115.226:8470
INFO:tensorflow:Clearing out eager caches
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
&lt;/denchmark-code&gt;

Then I run the following code, which creates tf.data.Dataset of dummy images, encodes it to jpeg and back, then normalizes to float32 and makes batches.
&lt;denchmark-code&gt;with strategy.scope():

  def encode_jpg(image, class_idx):
    return tf.io.encode_jpeg(image, quality = 95, optimize_size = True, chroma_downsampling = False), class_idx

  def decode_jpg(image, class_idx):
    return tf.image.decode_jpeg(image, channels = 3), class_idx

  def normalize_img(image, class_idx):
    return image / 255 - 0.5, class_idx

  dataset = tf.data.Dataset.from_tensor_slices((
    [tf.cast(np.zeros((256, 256, 3)), dtype = tf.uint8) for _ in range(300)],
    [0 for _ in range(300)]
  ))
  dataset = dataset.map(encode_jpg)
  dataset = dataset.map(decode_jpg)
  dataset = dataset.map(normalize_img)
  dataset = dataset.batch(8)

  print('\nhow does our dataset look like?')
  for i, (image, label) in enumerate(dataset):
    print(image.shape, label.shape)
    if i == 2: break

  model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape = (256, 256, 3)),
    tf.keras.layers.Dense(100, activation = 'relu'),
    tf.keras.layers.Dense(10)
  ])

  print('\nhow does our model model like?')
  model.summary()

  model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam')
  model.fit(dataset, epochs = 1)
&lt;/denchmark-code&gt;

I receive the following output which ends with exception:
&lt;denchmark-code&gt;how does our dataset look like?
(8, 256, 256, 3) of &lt;dtype: 'float32'&gt; (8,) of &lt;dtype: 'int32'&gt;
(8, 256, 256, 3) of &lt;dtype: 'float32'&gt; (8,) of &lt;dtype: 'int32'&gt;
(8, 256, 256, 3) of &lt;dtype: 'float32'&gt; (8,) of &lt;dtype: 'int32'&gt;

how does our model model like?
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 196608)            0         
_________________________________________________________________
dense (Dense)                (None, 100)               19660900  
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1010      
=================================================================
Total params: 19,661,910
Trainable params: 19,661,910
Non-trainable params: 0
_________________________________________________________________
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
&lt;ipython-input-2-9c1762b0cefe&gt; in &lt;module&gt;()
     36 
     37   model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam')
---&gt; 38   model.fit(dataset, epochs = 1)

10 frames
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnimplementedError: {{function_node __inference_train_function_5323}} Compilation failure: Asked to propagate a
dynamic dimension from hlo dot.472@{}@0 to hlo %all-reduce.477 = f32[&lt;=196608,100]{1,0}
all-reduce(f32[&lt;=196608,100]{1,0} %dot.472), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%sum.473,
metadata={op_type="CrossReplicaSum" op_name="CrossReplicaSum_2"}, which is not implemented.
	TPU compilation failed
	 [[{{node tpu_compile_succeeded_assert/_4970277850434216321/_5}}]]
&lt;/denchmark-code&gt;

When I remove these two lines:
&lt;denchmark-code&gt;dataset = dataset.map(encode_jpg)
dataset = dataset.map(decode_jpg)
&lt;/denchmark-code&gt;

Then it works:
&lt;denchmark-code&gt;38/38 [==============================] - 1s 16ms/step - loss: 16.8563
&lt;/denchmark-code&gt;

However shapes and types of dataset batches remain the same:
&lt;denchmark-code&gt;how does our dataset look like?
(8, 256, 256, 3) of &lt;dtype: 'float32'&gt; (8,) of &lt;dtype: 'int32'&gt;
(8, 256, 256, 3) of &lt;dtype: 'float32'&gt; (8,) of &lt;dtype: 'int32'&gt;
(8, 256, 256, 3) of &lt;dtype: 'float32'&gt; (8,) of &lt;dtype: 'int32'&gt;
&lt;/denchmark-code&gt;

To fix this error I tried to case labels to tf.int64, but error still occurs. I tried to run this code on CPU version of Colab (removing with strategy.scope():), and then it works perfectly. So I guess the problem is in TPU and jpeg encoding-decoding.
	</description>
	<comments>
		<comment id='1' author='sedol1339' date='2020-07-21T11:50:22Z'>
		I also tried to change label to tf.one_hot(label, 10) and change loss to categorical_crossentropy, but the error remains the same.
		</comment>
		<comment id='2' author='sedol1339' date='2020-07-22T09:58:07Z'>
		Was able to reproduce the issue with TF v2.2. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/b90177eba7517553edf96d0d50a50add/41590.ipynb#scrollTo=SFy8e1tob2Xm&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='sedol1339' date='2020-07-23T15:07:39Z'>
		The error is not reproducible with MirroredStrategy so I think this is TPU specific.
Based on the error it looks like you're passing in some dynamic shape. I wonder if the following has something to do with it?
If you look at the DatasetSpec of the dataset without the encoding/decoding the dimensions are known.
DatasetSpec(&lt;BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)&gt;, TensorShape([]))
But the encoded/decoded dataset has None for the height and width.
DatasetSpec(&lt;BatchDataset shapes: ((None, None, None, 3), (None,)), types: (tf.float32, tf.int32)&gt;, TensorShape([]))
		</comment>
		<comment id='4' author='sedol1339' date='2020-07-23T15:28:22Z'>
		Try explicitly setting the size after you decode, using tf.reshape. I think that should work.
&lt;denchmark-code&gt;def decode_jpg(image, class_idx):
  return tf.reshape(tf.image.decode_jpeg(image, channels = 3),[256,256, 3]), class_idx
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='sedol1339' date='2020-07-23T18:25:26Z'>
		&lt;denchmark-link:https://github.com/nikitamaia&gt;@nikitamaia&lt;/denchmark-link&gt;
 thanks! that helped
		</comment>
		<comment id='6' author='sedol1339' date='2020-07-27T15:57:35Z'>
		Closing this issue since a solution was found. Explicit size is needed for TPUs.
		</comment>
		<comment id='7' author='sedol1339' date='2020-07-27T15:57:37Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41590&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41590&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>