<bug id='25069' author='msiddique1436' open_date='2019-01-21T11:49:02Z' closed_time='2019-02-26T10:58:09Z'>
	<summary>Floating point exception when trying to build and compile my keras model  with xla support.</summary>
	<description>
SYSTEM INFO:
UBUNTU 16.04
TENSORFLOW 1.12.0 (compiled from source with XLA support)
KERAS 2.2.4
GPU Nvidia Geforce RTX 2080 Ti
I am trying to build and compile a simple CNN with XLA but I get a floating point exception.
&lt;denchmark-h:h1&gt;Here's the block of code&lt;/denchmark-h&gt;

`
&lt;denchmark-code&gt;import keras.backend.tensorflow_backend as bck
config = bck.tf.ConfigProto()
config.graph_options.optimizer_options.global_jit_level = bck.tf.OptimizerOptions.ON_1
bck.set_session(bck.tf.Session(config=config))


model = Sequential()

model.add(Conv2D(32, (3,3),padding="same",input_shape=input_shape))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))

model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dense(256))#64
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(34))#num_classes
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='SGD',metrics=["accuracy"])


model.summary()
model.get_config()


from keras import callbacks

filename='model_train_new.csv'
csv_log=callbacks.CSVLogger(filename, separator=',', append=False)
filepath="save_xla/Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5"


checkpoint = callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=False, mode='auto',period=1)

callbacks_list = [csv_log,checkpoint]



hist = model.fit(x, y, batch_size=32,epochs=num_epoch, verbose=1,callbacks=callbacks_list)
&lt;/denchmark-code&gt;

I am getting the following Output for this
2019-01-21 16:33:21.512092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-21 16:33:21.512662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
totalMemory: 10.73GiB freeMemory: 10.33GiB
2019-01-21 16:33:21.512678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-21 16:33:24.538253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-21 16:33:24.538298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
2019-01-21 16:33:24.538312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
2019-01-21 16:33:24.538695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9966 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;Layer (type)                 Output Shape              Param #&lt;/denchmark-h&gt;

conv2d_1 (Conv2D)            (None, 128, 128, 32)      320
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

activation_1 (Activation)    (None, 128, 128, 32)      0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

conv2d_2 (Conv2D)            (None, 126, 126, 32)      9248
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

activation_2 (Activation)    (None, 126, 126, 32)      0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

dropout_1 (Dropout)          (None, 63, 63, 32)        0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

conv2d_3 (Conv2D)            (None, 61, 61, 64)        18496
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

activation_3 (Activation)    (None, 61, 61, 64)        0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

dropout_2 (Dropout)          (None, 30, 30, 64)        0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

flatten_1 (Flatten)          (None, 57600)             0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

dense_1 (Dense)              (None, 256)               14745856
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

activation_4 (Activation)    (None, 256)               0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

dropout_3 (Dropout)          (None, 256)               0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

dense_2 (Dense)              (None, 34)                8738
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;activation_5 (Activation)    (None, 34)                0&lt;/denchmark-h&gt;

Total params: 14,782,658
Trainable params: 14,782,658
Non-trainable params: 0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

2019-01-21 16:33:25.223019: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x7f6f20001130 executing computations on platform CUDA. Devices:
2019-01-21 16:33:25.223063: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
Floating point exception (core dumped)
when I remove this part import keras.backend.tensorflow_backend as bck config = bck.tf.ConfigProto() config.graph_options.optimizer_options.global_jit_level = bck.tf.OptimizerOptions.ON_1 bck.set_session(bck.tf.Session(config=config))
everything works fine.
	</description>
	<comments>
		<comment id='1' author='msiddique1436' date='2019-01-30T16:55:54Z'>
		I run in the same issue when using XLA with the GeForce RTX 2080 TI. It is reproducible using example code from tensorflow. More concretely I tried running the follwing script: tensorflow/examples/tutorials/mnist/mnist_softmax_xla.py
Here is the console output when running with the 2080:
&lt;denchmark-code&gt;CUDA_VISIBLE_DEVICES="0" python3 mnist_softmax_xla.py 
WARNING:tensorflow:From mnist_softmax_xla.py:35: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/zomeck/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/zomeck/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/zomeck/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/zomeck/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2019-01-30 17:50:03.027620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.575
pciBusID: 0000:06:00.0
totalMemory: 10.73GiB freeMemory: 10.53GiB
2019-01-30 17:50:03.027659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-30 17:50:03.297256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-30 17:50:03.297288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-01-30 17:50:03.297296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-01-30 17:50:03.297543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10169 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:06:00.0, compute capability: 7.5)
2019-01-30 17:50:03.513752: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x7ff6e40021c0 executing computations on platform CUDA. Devices:
2019-01-30 17:50:03.513808: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
Floating point exception (core dumped)
&lt;/denchmark-code&gt;

Here is the console output when running with a 1080:
&lt;denchmark-code&gt;CUDA_VISIBLE_DEVICES="1" python3 mnist_softmax_xla.py 
WARNING:tensorflow:From mnist_softmax_xla.py:35: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/zomeck/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/zomeck/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/zomeck/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/zomeck/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2019-01-30 17:47:56.221149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:05:00.0
totalMemory: 7.93GiB freeMemory: 7.81GiB
2019-01-30 17:47:56.221186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-30 17:47:56.434690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-30 17:47:56.434722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-01-30 17:47:56.434729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-01-30 17:47:56.434924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7535 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:05:00.0, compute capability: 6.1)
2019-01-30 17:47:56.624224: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x1669cce0 executing computations on platform CUDA. Devices:
2019-01-30 17:47:56.624275: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
2019-01-30 17:47:56.734490: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:402] *** WARNING *** You are using ptxas 10.0.145, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2019-01-30 17:47:58.106152: I tensorflow/stream_executor/dso_loader.cc:151] successfully opened CUDA library libcupti.so.10.0 locally
0.91859996
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='msiddique1436' date='2019-02-16T00:37:38Z'>
		&lt;denchmark-link:https://github.com/jlebar&gt;@jlebar&lt;/denchmark-link&gt;
 Could you please take a look at this issue? Thanks!
		</comment>
		<comment id='3' author='msiddique1436' date='2019-02-20T10:00:45Z'>
		Judging from the warning output, it seems you are running with a old version of tensorflow. There was a bug in the detection logic if you are using an old ptxas which was fixed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/83ff640fa5026b8bd3cb9c2ceff9e99e8e03823a&gt;83ff640&lt;/denchmark-link&gt;

This is how I know you are using an old version.
Can you try to run this with tensorflow at head, or a nightly version?
		</comment>
		<comment id='4' author='msiddique1436' date='2019-02-22T08:26:00Z'>
		I also have this exact problem, using the newest release of TensorFlow. Without XLA, the network runs at similar speed on an RTX 2080 Ti as it does with XLA on a GTX 1080 Ti.
		</comment>
		<comment id='5' author='msiddique1436' date='2019-02-22T12:45:59Z'>
		The newest release means TF 1.12.0 like mentioned above? It is very much possible that those bugs have been fixed in the meantime. So could you please try with a version compiled from head?
		</comment>
		<comment id='6' author='msiddique1436' date='2019-02-22T13:40:31Z'>
		Yes, TF 1.12. I've just finished compiling TF 1.13rc2 (on branch r1.13), and with it, I can run 'tensorflow/examples/tutorials/mnist/mnist_softmax_xla.py' without crashing. The incorrect warning because of ptxas is also gone. But I get a new warning:
&lt;denchmark-code&gt;2019-02-22 13:33:11.390128: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/nvptx_backend_lib.cc:134] Unknown compute capability (7, 5) .Defaulting to telling LLVM that we're compiling for sm_30
&lt;/denchmark-code&gt;

The result of this is faster than without XLA, and it appears to work :) But it is not as fast as expected, maybe compiling for sm_30 is not optimal. This line is probably missing from 1.13rc2:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/nvptx_backend_lib.cc#L126&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/nvptx_backend_lib.cc#L126&lt;/denchmark-link&gt;
, I'll try master next.
		</comment>
		<comment id='7' author='msiddique1436' date='2019-02-22T14:55:14Z'>
		Thanks for trying it out, and pointing out the new warning. We should try to get this line cherry-picked into the next release if it is not too late for that.
		</comment>
		<comment id='8' author='msiddique1436' date='2019-02-22T16:04:55Z'>
		On master, the warning is not present, as expected, but its performance on our internal graph of the result is slower than with 1.13rc2. (Still faster than without XLA though :)
I have no idea why yet, or if this is a more general problem or just an artefact of my testing.
		</comment>
		<comment id='9' author='msiddique1436' date='2019-02-22T17:10:45Z'>
		&lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
 re the cherry-pick of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/83ff640fa5026b8bd3cb9c2ceff9e99e8e03823a&gt;83ff640&lt;/denchmark-link&gt;
.
The new warning about sm75 should also be fixed in master.
mnist is such a small thing that we haven't been bothered by its performance in XLA one way or another.  If you have "real" models where XLA is slower, we'd definitely be interested in seeing those.
I think otherwise this bug is closed?
		</comment>
		<comment id='10' author='msiddique1436' date='2019-02-22T18:54:50Z'>
		This bug isn't originally mine, so I can't say if it is fixed, but at least for me, 1.13rc2 works.
On the model I'm working on at the moment, XLA itself in master is still faster than not using it, but it is slower than XLA in 1.13rc2 was. But the model is private and I'm not allowed to disclose any details, so I'll try to debug why this is the case on my own, and open a separate ticket should I find out anything.
		</comment>
		<comment id='11' author='msiddique1436' date='2019-02-26T09:49:47Z'>
		So the only solution for this is to install TF 1.13 ?
		</comment>
		<comment id='12' author='msiddique1436' date='2019-02-26T10:49:34Z'>
		Yes.
		</comment>
		<comment id='13' author='msiddique1436' date='2019-02-26T10:58:09Z'>
		&lt;denchmark-link:https://github.com/akuegel&gt;@akuegel&lt;/denchmark-link&gt;

Alright then I am closing this issue.
Also is there any wheel file availabe for TF 1.13 with XLA. Compiling 1.12 from source with XLA was a pain and I don't want to go through the same steps again. If anybody has a wheel file plz share!!
		</comment>
		<comment id='14' author='msiddique1436' date='2019-02-26T11:12:31Z'>
		I thought that TF version 1.12 already had XLA support linked in by default?
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/releases/tag/v1.12.0&gt;https://github.com/tensorflow/tensorflow/releases/tag/v1.12.0&lt;/denchmark-link&gt;

(under major features and improvements)
The same should be true for every TF release after that.
		</comment>
		<comment id='15' author='msiddique1436' date='2019-02-26T11:19:21Z'>
		&lt;denchmark-link:https://github.com/akuegel&gt;@akuegel&lt;/denchmark-link&gt;

Oh okay I didn't knew that. actually I was working with an older version on a Jetson tx2 and then cross compiled from source for xla support. and then I wanted to use a newer version on my PC so I compiled 1.12 from source without even knowing that it had already xla support by default.
		</comment>
	</comments>
</bug>