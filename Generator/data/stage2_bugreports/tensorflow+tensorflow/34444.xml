<bug id='34444' author='vmarkovtsev' open_date='2019-11-20T09:48:18Z' closed_time='2020-05-22T04:26:18Z'>
	<summary>tf.reduce_mean crashes TensorFlow Lite</summary>
	<description>
System information

Ubuntu 18.04 4.15.0-66-generic x86_64
TensorFlow installed from (source or binary): official wheel
TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
Python version: 3.7
CUDA/cuDNN version: N/A

Describe the current behavior
The program SIGABRTs (see the code below).
Describe the expected behavior
The program does not crash.
Code to reproduce the issue

Code
from time import time

import numpy as np
import tensorflow as tf
from tensorflow.lite.python.interpreter import load_delegate


def measure(size, rep, tpu):
    @tf.function(input_signature=[tf.TensorSpec([size] * 2, tf.float32)] * 2)
    def bench_func(a, b):
        x = tf.linalg.matmul(a, b)
        return tf.reduce_mean(x)
    
    def gen_input_samples():
        i = np.identity(size, np.float32)
        yield [-i, i]
        yield [i, i]

    converter = tf.lite.TFLiteConverter.from_concrete_functions([bench_func.get_concrete_function()])
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = gen_input_samples
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.uint8
    converter.inference_output_type = tf.uint8
    tflite_model = converter.convert()
    delegates = [load_delegate("libedgetpu.so.1.0")] if tpu else []
    interpreter = tf.lite.Interpreter(model_content=tflite_model, experimental_delegates=delegates)
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    tensor_in1 = interpreter.tensor(input_details[0]["index"])
    tensor_in2 = interpreter.tensor(input_details[1]["index"])
    tensor_out = interpreter.tensor(output_details[0]["index"])
    inp1 = np.random.rand(size, size) - 0.5
    inp2 = np.random.rand(size, size) - 0.5
    tensor_in1()[:] = inp1
    tensor_in2()[:] = inp2
    now = time()
    for _ in range(rep):
        interpreter.invoke()
    return time() - now
 
print(measure(2048, 1, tpu=False))

Other info / logs

Log
2019-11-20 10:43:18.538007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-11-20 10:43:18.546197: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-11-20 10:43:18.546227: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vadim-XPS-13-9380): /proc/driver/nvidia/version does not exist
2019-11-20 10:43:18.546569: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-11-20 10:43:18.572569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1992000000 Hz
2019-11-20 10:43:18.573251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x48fd5a0 executing computations on platform Host. Devices:
2019-11-20 10:43:18.573290: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-11-20 10:43:18.671265: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2019-11-20 10:43:18.671336: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-20 10:43:18.690246: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-20 10:43:18.690274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2019-11-20 10:43:18.690277: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-11-20 10:43:18.700228: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2019-11-20 10:43:18.700397: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-11-20 10:43:18.720772: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2019-11-20 10:43:18.720800: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 0.895ms.
2019-11-20 10:43:18.720822: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 6 nodes (0), 5 edges (0), time = 0.072ms.
INFO: Initialized TensorFlow Lite runtime.
INFO: Initialized TensorFlow Lite runtime.
Aborted (core dumped)



gdb bt
#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51
#1  0x00007ffff7a24801 in __GI_abort () at abort.c:79
#2  0x00007fff3c18b616 in TfLiteStatus tflite::ops::builtin::reduce::EvalMean&lt;(tflite::ops::builtin::reduce::KernelType)0&gt;(TfLiteContext*, TfLiteNode*) ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#3  0x00007fff3c1f0577 in tflite::Subgraph::Invoke() ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#4  0x00007fff3c1f222a in tflite::Interpreter::Invoke() ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#5  0x00007fff3c0bff58 in tflite::interpreter_wrapper::InterpreterWrapper::Invoke() ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#6  0x00007fff3c0be054 in _wrap_InterpreterWrapper_Invoke ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#7  0x00000000005b0462 in _PyMethodDef_RawFastCallKeywords () at ../Objects/call.c:694
#8  0x00000000005cc860 in _PyCFunction_FastCallKeywords (kwnames=&lt;optimized out&gt;, nargs=&lt;optimized out&gt;, args=0x7fff6c1216c0, func=
    &lt;built-in method InterpreterWrapper_Invoke of module object at remote 0x7fff6c11ed18&gt;) at ../Objects/call.c:730
#9  call_function.lto_priv () at ../Python/ceval.c:4568
#10 0x000000000051add9 in _PyEval_EvalFrameDefault () at ../Python/ceval.c:3093
#11 0x00000000005b0eac in PyEval_EvalFrameEx (throwflag=0, f=
    Frame 0x7fff6c121540, for file /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py, line 109, in Invoke (self=&lt;InterpreterWrapper(this=&lt;SwigPyObject at remote 0x7fff74aca030&gt;) at remote 0x7fff741f1c88&gt;)) at ../Python/ceval.c:547
#12 function_code_fastcall (globals=&lt;optimized out&gt;, nargs=&lt;optimized out&gt;, args=&lt;optimized out&gt;, co=&lt;optimized out&gt;) at ../Objects/call.c:283
#13 _PyFunction_FastCallKeywords () at ../Objects/call.c:408
#14 0x00000000005cc6ea in call_function.lto_priv () at ../Python/ceval.c:4616
#15 0x000000000051add9 in _PyEval_EvalFrameDefault () at ../Python/ceval.c:3093
#16 0x00000000005b0eac in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0x7fff6c125048, for file /usr/local/lib/python3.7/dist-packages/tensorflow_core/lite/python/interpreter.py, line 453, in invoke (self=&lt;Interpreter(_model_content=b' \x00\x00\x00TFL3\x00\x00\x00\x00\x00\x00\x12\x00\x1c\x00\x04\x00\x08\x00\x0c\x00\x10\x00\x14\x00\x00\x00\x18\x00\x12\x00\x00\x00\x03\x00\x00\x00\x00&amp;\x00\x00\xf0 \x00\x00\xd8 \x00\x00&lt;\x00\x00\x00\x04\x00\x00\x00\x01\x00\x00\x00\x0c\x00\x00\x00\x08\x00\x0c\x00\x04\x00\x08\x00\x08\x00\x00\x00\x08\x00\x00\x00\t\x00\x00\x00\x13\x00\x00\x00min_runtime_version\x00\n\x00\x00\x00\x90 \x00\x00\x80\x00\x00\x00p\x00\x00\x00d\x00\x00\x00L\x00\x00\x004\x00\x00\x00,\x00\x00\x00$\x00\x00\x00\x1c\x00\x00\x00\x04\x00\x00\x00\xaa\xff\xff\xff\x04\x00\x00\x00\x05\x00\x00\x001.6.0\x00\x00\x00\xa4\xda\xff\xff\xa8\xda\xff\xff\xac\xda\xff\xff\xca\xff\xff\xff\x04\x00\x00\x00\x08\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\xde\xff\xff\xff\x04\x00\x00\x00\x08\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\xd8\xda\xff\xff\x04\x00\x06\x00\x04\x00\x00\x00\x00\x00\x06\x00\x...(truncated)) at ../Python/ceval.c:547
#17 function_code_fastcall (globals=&lt;optimized out&gt;, nargs=&lt;optimized out&gt;, args=&lt;optimized out&gt;, co=&lt;optimized out&gt;) at ../Objects/call.c:283
#18 _PyFunction_FastCallKeywords () at ../Objects/call.c:408
#19 0x0000000000516d6a in call_function (kwnames=0x0, oparg=&lt;optimized out&gt;, pp_stack=0x7fffffffd010) at ../Python/ceval.c:4616
#20 _PyEval_EvalFrameDefault () at ../Python/ceval.c:3110
#21 0x00000000005cd202 in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0xf20238, for file bench.py, line 40, in measure (rep=1, tpu=False, bench_func=&lt;Function(_lock=&lt;_thread.lock at remote 0x7fffe26e7b98&gt;, _python_function=&lt;function at remote 0x7fffe05bf9d8&gt;, _function_spec=&lt;FunctionSpec(_fullargspec=&lt;FullArgSpec at remote 0x7fff74b27c88&gt;, _is_method=False, _default_values=None, _args_to_indices={'a': 0, 'b': 1}, arg_names=['a', 'b'], vararg_name=None, _arg_indices_to_default_values={}, _input_signature=(&lt;TensorSpec at remote 0x7fff74ab6dc8&gt;, &lt;...&gt;), _flat_input_signature=(&lt;...&gt;, &lt;...&gt;)) at remote 0x7ffff6614710&gt;, _autograph=True, _experimental_autograph_options=None, experimental_relax_shapes=False, _created_variables=[], _stateful_fn=&lt;Function(_python_function=&lt;function at remote 0x7fff74ac2158&gt;, _function_spec=&lt;FunctionSpec(_fullargspec=&lt;FullArgSpec at remote 0x7fff74b27cf8&gt;, _is_method=False, _default_values=None, _args_to_indices={'a': 0, 'b': 1}, arg_names=['a', 'b'], vararg_name=None, _arg_indices_to_default_values={}, _input_signature=(...), _flat_input_signature=...(truncated)) at ../Python/ceval.c:547


tf.reduce_sum() does not crash.
	</description>
	<comments>
		<comment id='1' author='vmarkovtsev' date='2019-11-21T05:55:41Z'>
		&lt;denchmark-link:https://github.com/vmarkovtsev&gt;@vmarkovtsev&lt;/denchmark-link&gt;
, Please paste the code snippet to reproduce the reported issue here. Thanks!
		</comment>
		<comment id='2' author='vmarkovtsev' date='2019-11-21T06:45:34Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 But it's already here.
&lt;denchmark-link:https://user-images.githubusercontent.com/2793551/69313816-e3ebc900-0c32-11ea-9730-464a974ed199.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='vmarkovtsev' date='2019-11-21T07:54:34Z'>
		
@gadagashwini But it's already here.


Sorry I didn't check. My bad. Thanks!
		</comment>
		<comment id='4' author='vmarkovtsev' date='2019-12-10T22:32:14Z'>
		Could you please try this on the nightly which you can install with pip install --upgrade tf-nightly (after uninstalling the regular version). It works for me on the nightly but not on the release version.
		</comment>
		<comment id='5' author='vmarkovtsev' date='2020-05-08T02:57:43Z'>
		&lt;denchmark-link:https://github.com/vmarkovtsev&gt;@vmarkovtsev&lt;/denchmark-link&gt;
 This was resolved in . Can you please verify once and close the issue. I ran it in  and don't see any error. &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/5af626d6d5e36951af15f3eb0ee2caac/34444_tfliteconv_with_concretefun.ipynb&gt;Here&lt;/denchmark-link&gt;
 is the gist for your reference. Thanks!
		</comment>
		<comment id='6' author='vmarkovtsev' date='2020-05-15T03:44:20Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='7' author='vmarkovtsev' date='2020-05-22T04:26:17Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='8' author='vmarkovtsev' date='2020-05-22T04:26:20Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34444&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34444&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>