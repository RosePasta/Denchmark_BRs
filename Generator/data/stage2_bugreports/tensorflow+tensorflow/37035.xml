<bug id='37035' author='songs18' open_date='2020-02-25T04:00:51Z' closed_time='2020-06-04T02:49:02Z'>
	<summary>absl.flags._exceptions.UnparsedFlagAccessError if used flags in tf.TensorSpec</summary>
	<description>
System information

Have I written custom code
Yes:
OS Platform and Distribution
Win10:
Mobile device
No:
TensorFlow installed from (source or
binary): - TensorFlow version (use command below):
Python version: 2.1.0


code snippets url: &lt;denchmark-link:https://gitee.com/songhaohao2018/codes/cmunjs6zqbe895y7h0gpa21&gt;https://gitee.com/songhaohao2018/codes/cmunjs6zqbe895y7h0gpa21&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='songs18' date='2020-02-25T10:06:52Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;

As i understand , you are using TF version 2.1.0.Please provide details about what platform you are using (operating system, architecture).
The url you have provided is not working. Request you to provide colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='2' author='songs18' date='2020-02-25T14:02:03Z'>
		OS : Win10 PRO 1903
CPU : i5-4210U
Memory : 8G
TF version : 2.1.0 python CPU version
reproduce code:
from future import absolute_import, division, print_function
import tensorflow as tf
import numpy as np
from absl import app, logging, flags
FLAGS = flags.FLAGS
flags.DEFINE_integer('height', 28, help='image height')
flags.DEFINE_integer('width', 28, help='image width')
flags.DEFINE_integer('num_classes', default=10, help='class number')
flags.DEFINE_integer('num_futures', default=784, help='num futures')
flags.DEFINE_float('lr', default=0.001, help='learning rate')
flags.DEFINE_integer('training_steps', default=1000, help='training steps')
flags.DEFINE_integer('batch_size', default=100, help='batch size')
flags.DEFINE_integer('display_step', default=100, help='display step')
flags.DEFINE_integer('num_input', default=28, help='number input')
flags.DEFINE_integer('timesteps', default=28, help='tiemsteps')
flags.DEFINE_integer('num_units', default=32, help='num_units')
def get_data():
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)
x_train, x_test = x_train.reshape([-1, 28, 28]), x_test.reshape([-1, FLAGS.num_futures])
x_train, x_test = x_train / 255., x_test / 255.
train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_data = train_data.repeat().shuffle(5000).batch(FLAGS.batch_size).prefetch(1)
&lt;denchmark-code&gt;return train_data
&lt;/denchmark-code&gt;

class BiRNN(tf.keras.Model):
def init(self):
super(BiRNN, self).init()
&lt;denchmark-code&gt;    lstm_fw = tf.keras.layers.LSTM(units=FLAGS.num_units)
    lstm_bw = tf.keras.layers.LSTM(units=FLAGS.num_units, go_backwards=True)

    self.bi_lstm = tf.keras.layers.Bidirectional(lstm_fw, backward_layer=lstm_bw)
    self.out = tf.keras.layers.Dense(FLAGS.num_classes)

@tf.function(input_signature=[tf.TensorSpec(shape=[None, FLAGS.height, FLAGS.width], dtype=tf.float32)])
def call(self, x):
    x = self.bi_lstm(x)
    x = self.out(x)

    x = tf.nn.softmax(x)
    return x
&lt;/denchmark-code&gt;

def cross_entropy_loss(x, y):
y = tf.cast(y, tf.int64)
loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)
return tf.reduce_mean(loss)
def accuracy(y_pred, y_true):
correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))
return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)
def run_optimization(birnn_net, optimizer, x, y):
with tf.GradientTape() as tape:
pred = birnn_net(x)
loss = cross_entropy_loss(pred, y)
trainable_variables = birnn_net.trainable_variables
gradients = tape.gradient(loss, trainable_variables)
optimizer.apply_gradients(zip(gradients, trainable_variables))
def main(argv):
del argv
&lt;denchmark-code&gt;train_data = get_data()
birnn_net = BiRNN()
optimizer = tf.optimizers.Adam(FLAGS.lr)

for step, (batch_x, batch_y) in enumerate(train_data.take(FLAGS.training_steps), 1):
    run_optimization(birnn_net, optimizer, batch_x, batch_y)
    if step % FLAGS.display_step == 0:
        pred = birnn_net(batch_x)
        loss = accuracy(pred, batch_y)
        acc = accuracy(pred, batch_y)
        logging.info('step: {}, loss: {}, accuracy: {}'.format(step, loss, acc))
&lt;/denchmark-code&gt;

if name == 'main':
app.run(main)
		</comment>
		<comment id='3' author='songs18' date='2020-02-26T10:45:24Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;

Request you to share colab link or simple standalone code with proper indentation to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='4' author='songs18' date='2020-03-01T09:47:20Z'>
		&lt;denchmark-link:https://gitee.com/songhaohao2018/tf_issues/blob/master/absl_202002.py&gt;https://gitee.com/songhaohao2018/tf_issues/blob/master/absl_202002.py&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='songs18' date='2020-03-02T12:09:43Z'>
		I have tried on colab with TF version 2.1.0 and i am able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/7b0655f72b550f1789d328f63800b5b4/untitled697.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='6' author='songs18' date='2020-06-04T02:49:02Z'>
		This is expected. The flag is parsed when app.run(main) is executed. However, the @tf.function annotation is parsed when the class BiRNN and all its methods are parsed. Note that method body is not parsed until it get invoked, but method signature is parsed when class is parsed. This means that you can't have FLAG.hight in the annotation for the typespec.
Note that input_signature is used to control the shape and dtype of the tensor passed to the function. It's fine to be None, and it won't cause any issue / retrace, as long as the data passed are with same dtype and shape.
		</comment>
		<comment id='7' author='songs18' date='2020-06-04T02:49:03Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37035&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37035&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>