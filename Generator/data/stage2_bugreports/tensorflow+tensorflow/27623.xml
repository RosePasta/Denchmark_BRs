<bug id='27623' author='MartinSmeyer' open_date='2019-04-08T09:06:07Z' closed_time='2019-12-26T19:59:19Z'>
	<summary>CUDA 10 / CUDNN 7.5 performance loss (Titan V)</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): openSUSE Leap 42.3
GPU model and memory: Titan V
GCC/Compiler version (if compiling from source): 4.8
Nvidia Driver Version: 418.56

Problem: I experience consistent performance losses in TF using CUDA 10.0/CUDNN 7.5.
Here is a minimal example:
&lt;denchmark-code&gt;import tensorflow as tf
import time

matrix_dim = (5120,5120)
noof_matmul = 512
num_gpus = 1
float_type = tf.float32
c = []

print(tf.__file__)
for d in range(num_gpus):
    with tf.device('/gpu:%s' % d):
        a=tf.random_normal(matrix_dim,dtype=float_type)
        for i in range(noof_matmul):
            a=tf.matmul(a,a)
        c.append(a.op)

with tf.Session() as sess:
    sess.run(c)
    start=time.time()
    for i in range(10):
        sess.run(c)

t = (time.time()-start)/10.
tflops = noof_matmul * (2 * matrix_dim[0]**3 - matrix_dim[0]**2) / t / 10**12
print(t, 'sec, ', tflops, 'TFlops')
&lt;/denchmark-code&gt;

Results Titan V:
Tensorflow 1.13.1 built from source, bazel 0.24.0, CUDA 10.0, CUDNN 7.5.0:
-FP16: 1.6899 sec, 81.3209 TFlops
-FP32: 10.6873 sec, 12.8588 TFlops
Tensorflow 1.9 built from source (same configuration besides versions), bazel 0.11.1, CUDA 9.1, CUDNN 7.1.4:
+FP16: 1.5391 sec, 89.2890 TFlops
+FP32: 10.1137 sec, 13.5881 TFlops
Pip wheel tensorflow_gpu-1.13.1-cp27-cp27mu-manylinux1_x86_64.whl, CUDA 10.0, CUDNN 7.5.0:
-FP16: 1.6902 sec, 81.3057 TFlops
-FP32: 10.5577 sec, 13.01656 TFlops
Conda (Python 3.6) linux-64/tensorflow-gpu-1.13.1-h0d30ee6_0.tar.bz2, CUDA 9.2, CUDNN 7.3.1:
+FP16: 1.5389 sec, 89.2995 TFlops
+FP32: 10.1150 sec, 13.5863 TFlops
Have you experienced similar performance losses? Do you know any solutions? If necessary, I can run tests on other GPU models as well.
	</description>
	<comments>
		<comment id='1' author='MartinSmeyer' date='2019-06-18T09:31:11Z'>
		Could I ask a question? When I turn "tf.float32" into "tf.float64" , this program cannot be stopped. How can I calculate FP64 for our GPUs? Thank you
		</comment>
		<comment id='2' author='MartinSmeyer' date='2019-12-26T19:59:19Z'>
		This is fixed in tf-nightly (could have been a TF fix or because we're now using CUDA 10.1).
On TF 2.0.0:
fp16: 81.29 tflops
fp32: 13.12 tflops
On TF 2.1.0-dev20191226
fp16: 93.51 tflops
fp32: 13.58 tflops
All numbers on Titan-V.
		</comment>
		<comment id='3' author='MartinSmeyer' date='2019-12-26T19:59:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27623&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27623&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='MartinSmeyer' date='2019-12-26T19:59:54Z'>
		
Could I ask a question? When I turn "tf.float32" into "tf.float64" , this program cannot be stopped. How can I calculate FP64 for our GPUs? Thank you

&lt;denchmark-link:https://github.com/zkzhu0110&gt;@zkzhu0110&lt;/denchmark-link&gt;
 please open a separate github issue for this if your question is still relevant.
		</comment>
	</comments>
</bug>