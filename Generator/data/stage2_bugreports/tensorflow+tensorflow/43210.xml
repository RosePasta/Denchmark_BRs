<bug id='43210' author='hamidkhb' open_date='2020-09-14T14:28:00Z' closed_time='2020-09-15T08:18:38Z'>
	<summary>clone_model doesn't work properly. Dimensions of inputs should match.</summary>
	<description>
System information

TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.1
Python version: 3.7:
GCC/Compiler version (if compiling from source):
GPU model and memory: tesla v100

Describe the current behavior
I am training my custom models and I have used the following code to clone and train a model for domain adaptation tasks. Suddenly this stopped working. I am training on a cluster and using this line of code for 4 months without a problem.
&lt;denchmark-code&gt;model.fit(train_dataset)
model_target = tf.keras.models.clone_model(model)
model_target.set_weights(model.get_weights())

for layer in model_target.layers:
        layer._name = layer.name + str("_target")

model_target.compile(optimizer=tf.keras.optimizers.Adam(0.0001),
                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                      metrics=["accuracy"])

model_target.fit(train_dataset)
&lt;/denchmark-code&gt;

It produces the error :
&lt;denchmark-code&gt;InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-46-095ac6db4568&gt; in &lt;module&gt;
     15                       metrics=["accuracy"])
     16 print("second")
---&gt; 17 model_target.fit(train_dataset)

~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--&gt; 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)
   1377             with trace.Trace('TraceContext', graph_type='test', step_num=step):
   1378               callbacks.on_test_batch_begin(step)
-&gt; 1379               tmp_logs = test_function(iterator)
   1380               if data_handler.should_sync:
   1381                 context.async_wait()

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = "nonXla"
--&gt; 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    838         # Lifting succeeded, so variables are initialized and we can run the
    839         # stateless function.
--&gt; 840         return self._stateless_fn(*args, **kwds)
    841     else:
    842       canon_args, canon_kwds = \

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2827     with self._lock:
   2828       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-&gt; 2829     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2830 
   2831   @property

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1846                            resource_variable_ops.BaseResourceVariable))],
   1847         captured_inputs=self.captured_inputs,
-&gt; 1848         cancellation_manager=cancellation_manager)
   1849 
   1850   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1922       # No tape is watching; skip to running the function.
   1923       return self._build_call_outputs(self._inference_function.call(
-&gt; 1924           ctx, args, cancellation_manager=cancellation_manager))
   1925     forward_backward = self._select_forward_and_backward_functions(
   1926         args,

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    548               inputs=args,
    549               attrs=attrs,
--&gt; 550               ctx=ctx)
    551         else:
    552           outputs = execute.execute_with_cancellation(

~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---&gt; 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError:  ConcatOp : Dimensions of inputs should match: shape[0] = [5,16384] vs. shape[1] = [20,8192]
	 [[node functional_1/features_target/concat (defined at &lt;ipython-input-46-095ac6db4568&gt;:17) ]] [Op:__inference_test_function_125643]

Function call stack:
test_function
&lt;/denchmark-code&gt;

the main model trains without any problem on the same dataset, so the dataset can not be the problem.
I am making the main model using the following code:
&lt;denchmark-code&gt;input_range = Input(input_shape_range, name="input_range")
    input_doppler = Input(input_shape_doppler, name="input_doppler")

    r = Conv2D(filters=8, kernel_size=(3, 3), padding="same", activation="relu", name="c1_r",
               data_format="channels_first")(input_range)
    r = Conv2D(filters=16, kernel_size=(3, 3), padding="same", activation="relu", name="c2_r",
               data_format="channels_first")(r)
    r = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding="Valid", name="m1_r",
                  data_format="channels_first")(r)
    r = Conv2D(filters=16, kernel_size=(3, 3), padding="same", activation="relu", name="c3_r",
               data_format="channels_first")(r)
    r = Conv2D(filters=32, kernel_size=(3, 3), padding="same", activation="relu", name="c4_r",
               data_format="channels_first")(r)
    r = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding="Valid", name="m2_r",
                  data_format="channels_first")(r)

    features_range = Flatten(name="flatten_r")(r)

    d = Conv2D(filters=8, kernel_size=(3, 3), padding="same", activation="relu", name="c1_d",
               data_format="channels_first")(input_doppler)
    d = Conv2D(filters=16, kernel_size=(3, 3), padding="same", activation="relu", name="c2_d",
               data_format="channels_first")(d)
    d = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding="Valid", name="m1_d",
                  data_format="channels_first")(d)
    d = Conv2D(filters=16, kernel_size=(3, 3), padding="same", activation="relu", name="c3_d",
               data_format="channels_first")(d)
    d = Conv2D(filters=32, kernel_size=(3, 3), padding="same", activation="relu", name="c4_d",
               data_format="channels_first")(d)
    d = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding="Valid", name="m2_d",
                  data_format="channels_first")(d)
    features_doppler = Flatten(name="flatten_d")(d)

    features = tf.keras.layers.concatenate([features_range, features_doppler], name="features" ,axis=1)

    fc_1 = Dense(256, activation="relu", use_bias=True, name="fc_1",
                 kernel_regularizer= tf.keras.regularizers.l2(0.01))(features)
    drop_1 = Dropout(0.2)(fc_1)
    fc_2 = Dense(128, activation="relu", use_bias=True, name="fc_2",
                 kernel_regularizer= tf.keras.regularizers.l2(0.01))(features)
    drop_2 = Dropout(0.2)(fc_2)
    fc_3 = Dense(64, activation="relu", use_bias=True, name="fc_3",
                 kernel_regularizer= tf.keras.regularizers.l2(0.01))(drop_2)
    drop_3 = Dropout(0.2)(fc_3)
    out = Dense(5, use_bias=True, name="out")(drop_3)

    model = tf.keras.Model(inputs=[input_range, input_doppler], outputs=out)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='hamidkhb' date='2020-09-14T14:47:39Z'>
		Please could you share a very, very minimal but complete standalone or colab example that we could copy, past and run to reproduce your issue?
		</comment>
		<comment id='2' author='hamidkhb' date='2020-09-14T16:11:11Z'>
		Sorry but I don't know any dataset, which needs 2 inputs. And apparently the Concatenation is causing the problem.
		</comment>
		<comment id='3' author='hamidkhb' date='2020-09-14T16:24:36Z'>
		But I just found out that this is causing the Problem
&lt;denchmark-code&gt;for layer in model_source.layers:
        layer._name = layer.name + str("_source")
&lt;/denchmark-code&gt;

actually changing the name of Inputs causing the error.
any idea how to solve this?
		</comment>
		<comment id='4' author='hamidkhb' date='2020-09-14T19:34:05Z'>
		I don't think It Is a bug. For support request on your model use &lt;denchmark-link:https://stackoverflow.com/questions/tagged/tensorflow&gt;stackoverflow&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='hamidkhb' date='2020-09-15T04:43:32Z'>
		&lt;denchmark-link:https://github.com/hamidkhb&gt;@hamidkhb&lt;/denchmark-link&gt;

Please feel free to move the issue to closed status as it will be taken care at stack-overflow.
		</comment>
		<comment id='6' author='hamidkhb' date='2020-09-15T08:18:38Z'>
		Well I tried the code in different ways and even made the network again and it all works.
		</comment>
		<comment id='7' author='hamidkhb' date='2020-09-15T08:18:40Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43210&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43210&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>