<bug id='9487' author='sedghi' open_date='2017-04-27T14:27:05Z' closed_time='2018-02-09T17:35:26Z'>
	<summary>terminate called after throwing an instance of 'std::bad_alloc', not out of memory</summary>
	<description>
Hi, I'm using Keras with tensorflow back-end to train a LSTM network, I was doing a grid search over the learning_rate and dropout factor with the fixed batch size of 64, It ran perfectly but in the middle of it was interrupted by signal 6: SIGABRT with the following error:
&lt;denchmark-code&gt;terminate called after throwing an instance of 'std::bad_alloc'  what():  std::bad_alloc
&lt;/denchmark-code&gt;

It should not be a memory allocation problem because it was running earlier for batch size of 64 which is not too much in my case
you can find my system information(tf_env.txt) from the following link:
&lt;denchmark-link:https://www.dropbox.com/s/wcv8y88fh659zck/tf_env.txt?dl=0&gt;https://www.dropbox.com/s/wcv8y88fh659zck/tf_env.txt?dl=0&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='sedghi' date='2017-04-27T15:41:48Z'>
		Your memory usage may be on the edge. That is exactly the error given when running out of memory. Try running it again and monitor using ps or top the memory usage.
		</comment>
		<comment id='2' author='sedghi' date='2017-04-27T17:19:14Z'>
		I tried my training with batch-size of 128 (instead of 64) but it ran without any error, I'm wondering how it could be out of memory error while it can be run on a bigger batch size
		</comment>
		<comment id='3' author='sedghi' date='2017-04-28T04:44:38Z'>
		Because it could be memory fragmentation causing your memory usage to go up over run. Why don't you rerun your problem and graph the memory usage and see if that is the case?
		</comment>
		<comment id='4' author='sedghi' date='2017-04-28T18:16:05Z'>
		thanks for the reply, here is my memory usage (free memory available in time)
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/7490180/25541440/ab076890-2c1c-11e7-932d-bbe868453f35.png&gt;&lt;/denchmark-link&gt;

I noticed those plateaus are when it reaches the last epoch number in the current training and moves to another training with different sets of parameters ( as i said earlier I'm doing a parameter search ), I'm wondering why it cannot free the memory after it reaches the end of the training and then moves to the next training (with different parameter sets).
		</comment>
		<comment id='5' author='sedghi' date='2017-04-28T20:37:48Z'>
		Are you clearing your tensorflow graph between these trainings?  e.g.
tf.reset_default_graph()
		</comment>
		<comment id='6' author='sedghi' date='2017-04-28T23:53:08Z'>
		I used clear_session() in keras which is supposed to do the same thing. it fails to release the RAM that it was using.
		</comment>
		<comment id='7' author='sedghi' date='2017-05-01T20:06:29Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
, do you have any ideas?
		</comment>
		<comment id='8' author='sedghi' date='2017-06-16T23:43:00Z'>
		clear_session() should definitely work here.
		</comment>
		<comment id='9' author='sedghi' date='2017-12-22T07:31:50Z'>
		It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
		</comment>
		<comment id='10' author='sedghi' date='2018-01-05T19:06:57Z'>
		Nagging Awaiting TensorFlower: It has been 14 days with no activityand the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
		</comment>
		<comment id='11' author='sedghi' date='2018-01-23T23:13:05Z'>
		A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.
		</comment>
		<comment id='12' author='sedghi' date='2018-01-25T01:17:23Z'>
		&lt;denchmark-link:https://github.com/sedghi&gt;@sedghi&lt;/denchmark-link&gt;
 is this still a problem for you?
		</comment>
		<comment id='13' author='sedghi' date='2018-02-08T19:29:48Z'>
		Nagging Awaiting Response: It has been 14 days with no activityand the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='14' author='sedghi' date='2018-02-08T19:55:31Z'>
		&lt;denchmark-link:https://github.com/tatatodd&gt;@tatatodd&lt;/denchmark-link&gt;
 I was able to resolve it by
&lt;denchmark-code&gt;from keras import backend as K
K.clear_session()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='15' author='sedghi' date='2018-02-23T17:21:15Z'>
		&lt;denchmark-link:https://github.com/sedghi&gt;@sedghi&lt;/denchmark-link&gt;
 did you call the K.clear_session() at the end of training or at the start of it?
		</comment>
		<comment id='16' author='sedghi' date='2018-02-23T18:16:53Z'>
		@ambodi at the end.
I was doing 5-fold cross-validation
		</comment>
		<comment id='17' author='sedghi' date='2019-02-13T10:54:25Z'>
		Hi I'm using pi camera interfaced in raspberry pi3 b+ model.
Kindly guide to resolve the error
terminate called after throwing an instance of 'std::bad_alloc'
what():  std::bad_alloc
		</comment>
		<comment id='18' author='sedghi' date='2019-05-01T00:09:16Z'>
		I got same issue as &lt;denchmark-link:https://github.com/KoushikRaghav&gt;@KoushikRaghav&lt;/denchmark-link&gt;
 . I have a Tensorflow 2.0 keras model that use tf.cast, tf.exp and a division by 2. I noticed these operations idependently fail to run the TfLite file using TFLiteInterpreter.
&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
  Do you have some idea about why these operations are failing in tf-nightly-gpu-2.0-preview?
		</comment>
		<comment id='19' author='sedghi' date='2020-06-16T14:48:49Z'>
		I'm getting this error (which I assume is from libtensorflow, the C++ binary) when using Tensorflow.js in a Node.js environment:
&lt;denchmark-code&gt;2020-06-16 15:46:14.057597: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 8998027264 exceeds 10% of system memory.
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted (core dumped)
&lt;/denchmark-code&gt;

I can confirm that it is absolutely not using anywhere close to 10% of my system memory. In htop it caps out at well under 1GiB - I have 24GiB to give it, but it keeps crashing as above.
		</comment>
	</comments>
</bug>