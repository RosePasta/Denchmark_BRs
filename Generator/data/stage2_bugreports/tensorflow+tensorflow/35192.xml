<bug id='35192' author='aLeX1443' open_date='2019-12-17T16:20:22Z' closed_time='2019-12-20T10:37:25Z'>
	<summary>Automatic Mixed Precision and XLA not working with `model.fit_generator`</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


**OS Platform and Distribution **: tensorflow/tensorflow:nightly-gpu-py3 Nvidia Docker image (ec33d38d1b43)
TensorFlow version (use command below): 2.1.0-dev20191106
Python version: Python 3.6.8
CUDA/cuDNN version: 10.0
GPU model and memory: Titan RTX 24GB

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

When using model.fit_generator(), Automatic Mixed Precision (AMP) and compiling XLA doesn't seem to work. However, it all works fine with model.fit().
Please see below for a complete code sample to reproduce this.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import Sequence
import numpy as np
import random


def mixed_precision_test(use_generator):
    # use XLA
    tf.config.optimizer.set_jit(True)

    input_shape = (100, 100, 100)
    n_samples = 1000

    # build the model
    model = Sequential()
    model.add(Dense(16, input_shape=input_shape, activation='relu'))
    model.add(Flatten())
    model.add(Dense(8, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))

    optimiser = Adam(lr=0.001)
     
    # use AMP
    optimiser = tf.train.experimental.enable_mixed_precision_graph_rewrite(
        optimiser)

    model.compile(optimizer=optimiser,
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    if use_generator:
        class DataGen(Sequence):

            def __len__(self):
                return n_samples

            def __getitem__(self, index):
                _x = np.random.rand(1, *input_shape)
                _x = np.array(_x, dtype='uint8')
                _y = np.array([random.choice([0, 1])], dtype='uint8')
                return _x, _y

        model.fit_generator(generator=DataGen())
    else:
        x = np.random.rand(n_samples, *input_shape)
        x = np.array(x, dtype='uint8')
        y = np.array([random.choice([0, 1]) for _ in range(len(x))],
                     dtype='uint8')

        model.fit(x, y)


if __name__ == '__main__':
    mixed_precision_test(use_generator=False)
    mixed_precision_test(use_generator=True)
&lt;/denchmark-code&gt;

When setting use_generator=False, TensorFlow prints out the following logs:
&lt;denchmark-code&gt;2019-12-17 15:51:43.549128: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1857] Converted 26/409 nodes to float16 precision using 2 cast(s) to float16 (excluding Const and Variable casts)
2019-12-17 15:51:43.755273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-12-17 15:51:45.048967: I tensorflow/compiler/jit/xla_compilation_cache.cc:242] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
&lt;/denchmark-code&gt;

indicating that AMP and XLA are working as intended.
When setting use_generator=True, those logs are not present and GPU memory consumption is higher, suggesting that no casting to FP16 was performed.
	</description>
	<comments>
		<comment id='1' author='aLeX1443' date='2019-12-18T15:13:16Z'>
		According to &lt;denchmark-link:https://stackoverflow.com/questions/59380430/how-to-use-model-fit-which-supports-generators-after-fit-generator-deprecation&gt;this SO post&lt;/denchmark-link&gt;
,  is deprecated as of TF 2.1.0. It suggests passing the generator to  instead. I am not able to test this right now, but I'll try to update as soon as I can.
		</comment>
		<comment id='2' author='aLeX1443' date='2019-12-19T10:16:11Z'>
		
According to this SO post, fit_generator is deprecated as of TF 2.1.0. It suggests passing the generator to model.fit instead. I am not able to test this right now, but I'll try to update as soon as I can.

For more read here &lt;denchmark-link:https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/Model#fit_generator&gt;https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/Model#fit_generator&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='aLeX1443' date='2019-12-20T10:37:25Z'>
		Can confirm that using  model.fit(x=DataGen()) allows you to use mixed precision and XLA.
		</comment>
		<comment id='4' author='aLeX1443' date='2019-12-20T10:37:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35192&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35192&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>