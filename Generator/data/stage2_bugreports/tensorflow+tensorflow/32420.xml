<bug id='32420' author='grananqvist' open_date='2019-09-11T10:42:28Z' closed_time='2019-11-01T20:52:09Z'>
	<summary>TF2.0 - Multiple calls to Keras .fit and .evaluate makes RAM explode and is 25x slower</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.0.0-dev20190909
Python version: 3.6.5
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: -
GPU model and memory: -

Describe the current behavior
(Everything is done on the CPU)
Consecutive calls to either .fit() or .evaluate() increase the RAM used, even if calling with the same data. The calls takes approximately 10 times longer than with TF1.x
Describe the expected behavior
I expect the RAM usage to remain constant just like in TF1.x
Code to reproduce the issue
from memory_profiler import profile
from time import time
import numpy as np
import tensorflow as tf

model = tf.keras.Sequential([tf.keras.layers.Dense(100, activation=tf.nn.softmax)])
model.compile(loss='mse', optimizer='sgd')

@profile
def eval(x, y):
    model.evaluate(x, y)

x = np.random.normal(size=(1,100))
y = np.random.normal(size=(1,100))

for i in range(100000):
    print('iteration', i)
    tic = time()
    eval(x, y)
    print('timeit', time() - tic)
Using TF2.0. 229MB RAM used and evaluate completed in 99ms
&lt;denchmark-code&gt;iteration 20
Train on 1 samples
1/1 [==============================] - 0s 10ms/sample - loss: 1.0597
Filename: reproduce_keras_oom.py

Line #    Mem usage    Increment   Line Contents
================================================
     9    228.8 MiB    228.8 MiB   @profile
    10                             def eval(x, y):
    11    229.1 MiB      0.2 MiB       model.evaluate(x, y)

timeit 0.09978580474853516
&lt;/denchmark-code&gt;

Using TF2.0 1508MB RAM used after calling .evaluate() 3312 times.
&lt;denchmark-code&gt;iteration 3312
1/1 [==============================] - 0s 4ms/sample - loss: 1.0205
Filename: reproduce_keras_oom.py

Line #    Mem usage    Increment   Line Contents
================================================
     9   1508.3 MiB   1508.3 MiB   @profile
    10                             def eval(x, y):
    11   1508.7 MiB      0.4 MiB       model.evaluate(x, y)

timeit 0.09004998207092285
&lt;/denchmark-code&gt;

Using TF1.x, the RAM used is not increasing over consecutive calls of .evaluate(). RAM stays at 176MB indefinitely (iteration 5100 below). Also note that it is 25 times faster!
&lt;denchmark-code&gt;iteration 5100
1/1 [==============================] - 0s 1ms/sample - loss: 1.2716
Filename: reproduce_keras_oom.py

Line #    Mem usage    Increment   Line Contents
================================================
     9    176.0 MiB    176.0 MiB   @profile
    10                             def eval(x, y):
    11    176.0 MiB      0.0 MiB       model.evaluate(x, y)

timeit 0.004405021667480469
&lt;/denchmark-code&gt;

I just discovered that wrapping (x, y) into a tf.data.Dataset does not have this issue!
Modified code:
from memory_profiler import profile
from time import time
import numpy as np
import tensorflow as tf

model = tf.keras.Sequential([tf.keras.layers.Dense(100, activation=tf.nn.softmax)])
model.compile(loss='mse', optimizer='sgd')

@profile
def eval(dataset):
    model.evaluate(dataset)

x = np.random.normal(size=(1,100))
y = np.random.normal(size=(1,100))

dataset = tf.data.Dataset.from_tensor_slices((x, y))
dataset = dataset.batch(1)

for i in range(100000):
    print('iteration', i)
    tic = time()
    eval(dataset)
    print('timeit', time() - tic)
Using tf.data.Dataset, there is no exploding RAM. 217 MB RAM used after calling .evaluate() 8154 times. It is also only 2.5 times slower than TF1.x
&lt;denchmark-code&gt;iteration 8154
1/1 [==============================] - 0s 3ms/step - loss: 0.9972
Filename: reproduce_keras_oom.py

Line #    Mem usage    Increment   Line Contents
================================================
     9    217.6 MiB    217.6 MiB   @profile
    10                             def eval(dataset):
    11    217.6 MiB      0.0 MiB       model.evaluate(dataset)

timeit 0.010456085205078125
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='grananqvist' date='2019-09-13T05:41:30Z'>
		&lt;denchmark-link:https://github.com/grananqvist&gt;@grananqvist&lt;/denchmark-link&gt;

I tried reproducing the issue. I am attaching the &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/211ae1084a4b922d38cf36bd122ffcad/untitled180.ipynb&gt;gist&lt;/denchmark-link&gt;
 for your reference. Is this the expected behavior?.Thanks!
		</comment>
		<comment id='2' author='grananqvist' date='2019-09-13T11:28:57Z'>
		From what I see in the notebook, using profile to measure the RAM consumption does not work in jupyter
		</comment>
		<comment id='3' author='grananqvist' date='2019-10-10T17:28:54Z'>
		&lt;denchmark-link:https://github.com/grananqvist&gt;@grananqvist&lt;/denchmark-link&gt;
 Sorry for the delay in response. Can you please try  and compare that with . I see similar runtime (~0.004) with  and . Please let us know what you think. Thanks!
		</comment>
		<comment id='4' author='grananqvist' date='2019-10-21T23:22:13Z'>
		&lt;denchmark-link:https://github.com/grananqvist&gt;@grananqvist&lt;/denchmark-link&gt;
 Did you had time to review my comments? Thanks!
		</comment>
		<comment id='5' author='grananqvist' date='2019-10-22T23:24:08Z'>
		Sorry I have not had the time to test this yet.
		</comment>
		<comment id='6' author='grananqvist' date='2019-11-01T20:52:09Z'>
		Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!
		</comment>
		<comment id='7' author='grananqvist' date='2019-11-01T20:52:11Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32420&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32420&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>