<bug id='29043' author='dulm' open_date='2019-05-27T01:40:19Z' closed_time='2020-04-23T17:18:45Z'>
	<summary>[TF2.0] tf.feature_column.shared_embeddings trace twice and throw exception with @tf.function</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): osx 10.13.1 (17B1003)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): tf-nightly-2.0-preview           2.0.0.dev20190506
Python version: 3.6.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 

&lt;denchmark-link:https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/shared_embeddings&gt;shared_embeddings&lt;/denchmark-link&gt;
 not surport eager mode, so i call it with @tf.function, but still throw exception:
ValueError: Variable color_color2_color3_shared_embedding already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?
Find the reason is that the function will be traced twice after add line df =  tf.keras.layers.DenseFeatures(color_column_embed)(color_data),  the print will run twice.
first time stack:
&lt;denchmark-code&gt;embedding_weights, feature_column_v2.py:3247
_get_dense_tensor_internal, feature_column_v2.py:3326
get_dense_tensor, feature_column_v2.py:3349
_call_unconverted, api.py:173
converted_call, api.py:271
loop_body, tmpf4q73us7.py:51
_py_for_stmt, control_flow.py:111
for_stmt, control_flow.py:102
tf__call, tmpf4q73us7.py:70
converted_call, api.py:375
wrapper, api.py:89
__call__, base_layer.py:632
_call_unconverted, api.py:173
converted_call, api.py:271
tf__shared_embedding_column_with_hash_bucket, tmp5d_py4a8.py:16
converted_call, api.py:375
wrapper, func_graph.py:705
wrapped_fn, def_function.py:292
func_graph_from_py_func, func_graph.py:713
_create_graph_function, function.py:1529
_maybe_define_function, function.py:1596
_get_concrete_function_internal_garbage_collected, function.py:1333
_initialize, def_function.py:342
__call__, def_function.py:399
&lt;module&gt;, main.py:43
&lt;/denchmark-code&gt;

second time call stack:
&lt;denchmark-code&gt;embedding_weights, feature_column_v2.py:3247
_get_dense_tensor_internal, feature_column_v2.py:3326
get_dense_tensor, feature_column_v2.py:3349
_call_unconverted, api.py:173
converted_call, api.py:271
loop_body, tmpf4q73us7.py:51
_py_for_stmt, control_flow.py:111
for_stmt, control_flow.py:102
tf__call, tmpf4q73us7.py:70
converted_call, api.py:375
wrapper, api.py:89
__call__, base_layer.py:632
_call_unconverted, api.py:173
converted_call, api.py:271
tf__shared_embedding_column_with_hash_bucket, tmp5d_py4a8.py:16
converted_call, api.py:375
wrapper, func_graph.py:705
wrapped_fn, def_function.py:292
func_graph_from_py_func, func_graph.py:713
_create_graph_function, function.py:1529
_maybe_define_function, function.py:1596
__call__, function.py:1307
__call__, def_function.py:411
&lt;module&gt;, main.py:43
&lt;/denchmark-code&gt;

The only difference is before _maybe_define_function, function.py:1596.
The code in second time fails,  because it is new obj , so there's no cache in self._embedding_weights, then will run variable_scope.get_variable with no reuse:
&lt;denchmark-code&gt;  @property
  def embedding_weights(self):
    key = ops.get_default_graph()._graph_key  # pylint: disable=protected-access
    if key not in self._embedding_weights:
      embedding_shape = (self._num_buckets, self._dimension)
      var = variable_scope.get_variable(
          name=self._name,
          shape=embedding_shape,
          dtype=dtypes.float32,
          initializer=self._initializer,
          trainable=self._trainable)

      if self._ckpt_to_load_from is not None:
        to_restore = var
        if isinstance(to_restore, variables.PartitionedVariable):
          to_restore = to_restore._get_variable_list()  # pylint: disable=protected-access
        checkpoint_utils.init_from_checkpoint(
            self._ckpt_to_load_from, {self._tensor_name_in_ckpt: to_restore})
      self._embedding_weights[key] = var
    return self._embedding_weights[key]
&lt;/denchmark-code&gt;

Describe the expected behavior
Could use the shared_embeddings.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow import feature_column

@tf.function
def shared_embedding_column_with_hash_bucket():
    color_data = {'color': [[2], [5], [-1], [0]],
                  'color2': [[2, 2], [5, 5], [0, -1], [0, 0]],
                  'color3': [[2,2,2], [5,5,5], [-1,-1,-1], [0,0,0]]
                 }
    color_column = feature_column.categorical_column_with_hash_bucket('color', 5, dtype=tf.int32)
    color_column2 = feature_column.categorical_column_with_hash_bucket('color2', 5, dtype=tf.int32)
    color_column3 = feature_column.categorical_column_with_hash_bucket('color3', 5, dtype=tf.int32)
    color_column_embed = tf.feature_column.shared_embeddings([color_column, color_column2, color_column3], 4, combiner='sum')
    print(color_column_embed)
    print(type(color_column_embed))
    print('use input_layer' + '_' * 40)
    df =  tf.keras.layers.DenseFeatures(color_column_embed)(color_data)
    return df

dense = shared_embedding_column_with_hash_bucket()
print(dense)
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py", line 1758, in &lt;module&gt;
    main()
  File "/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py", line 1752, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py", line 1147, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/Users/lqk/project/PycharmProjects/TF2/main.py", line 40, in &lt;module&gt;
    dense = shared_embedding_column_with_hash_bucket()
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 411, in __call__
    return self._stateless_fn(*args, **kwds)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1307, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1596, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1529, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 713, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 292, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 705, in wrapper
    ), args, kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 375, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/var/folders/4x/njl257j95bx4mt08j65fxqg00000gp/T/tmp5y1g76hx.py", line 16, in tf__shared_embedding_column_with_hash_bucket
    df = ag__.converted_call(tf.keras.layers.DenseFeatures(color_column_embed), None, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (color_data,), None)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 271, in converted_call
    return _call_unconverted(f, args, kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 173, in _call_unconverted
    return f(*args)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 632, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 89, in wrapper
    ), args, kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 375, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/var/folders/4x/njl257j95bx4mt08j65fxqg00000gp/T/tmpshzfamoc.py", line 70, in tf__call
    ag__.for_stmt(self._feature_columns, None, loop_body, ())
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/operators/control_flow.py", line 102, in for_stmt
    return _py_for_stmt(iter_, extra_test, body, init_state)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/operators/control_flow.py", line 111, in _py_for_stmt
    state = body(target, *state)
  File "/var/folders/4x/njl257j95bx4mt08j65fxqg00000gp/T/tmpshzfamoc.py", line 51, in loop_body
    tensor = ag__.converted_call('get_dense_tensor', column, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (transformation_cache, self._state_manager), None)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 271, in converted_call
    return _call_unconverted(f, args, kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 173, in _call_unconverted
    return f(*args)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py", line 3349, in get_dense_tensor
    return self._get_dense_tensor_internal(transformation_cache, state_manager)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py", line 3326, in _get_dense_tensor_internal
    embedding_weights = self.shared_embedding_column_creator.embedding_weights
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py", line 3253, in embedding_weights
    trainable=self._trainable)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 1496, in get_variable
    aggregation=aggregation)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 1239, in get_variable
    aggregation=aggregation)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 562, in get_variable
    aggregation=aggregation)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 514, in _true_getter
    aggregation=aggregation)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 856, in _get_single_variable
    raise ValueError(err_msg)
ValueError: Variable color_color2_color3_shared_embedding already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='dulm' date='2019-05-29T07:04:01Z'>
		I was able to get the mentioned error on Colab with TensorFlow version 2.0.
		</comment>
		<comment id='2' author='dulm' date='2019-07-15T10:20:11Z'>
		New error for 'tf-nightly-2.0-preview 2.0.0.dev20190714 ' with @tf.function
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py", line 1758, in &lt;module&gt;
    main()
  File "/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py", line 1752, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py", line 1147, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/Users/lqk/project/PycharmProjects/TF2/shared_embedding.py", line 44, in &lt;module&gt;
    df = shared_embedding_column_with_hash_bucket(dic_data)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 429, in __call__
    return self._stateless_fn(*args, **kwds)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1661, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1991, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1877, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py", line 791, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 310, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/Users/lqk/anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py", line 781, in wrapper
    raise e.ag_error_metadata.to_exception(type(e))
AttributeError: in converted code:
    relative to /Users/lqk:

    project/PycharmProjects/TF2/shared_embedding.py:36 shared_embedding_column_with_hash_bucket  *
        df = tf.keras.layers.DenseFeatures(color_column_embed)(dic_data)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:758 __call__
        outputs = self.call(inputs, *args, **kwargs)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:508 call
        self._state_manager)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3418 get_dense_tensor
        return self._get_dense_tensor_internal(transformation_cache, state_manager)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3395 _get_dense_tensor_internal
        embedding_weights = self.shared_embedding_column_creator.embedding_weights
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3322 embedding_weights
        trainable=self._trainable)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:1500 get_variable
        aggregation=aggregation)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:1243 get_variable
        aggregation=aggregation)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:567 get_variable
        aggregation=aggregation)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:519 _true_getter
        aggregation=aggregation)
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py:861 _get_single_variable
        tb = var.op.traceback[::-1]
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:558 op
        return self._handle.op
    anaconda2/envs/p36t2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:986 op
        "Tensor.op is meaningless when eager execution is enabled.")

    AttributeError: Tensor.op is meaningless when eager execution is enabled.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='dulm' date='2020-03-12T10:17:03Z'>
		Was able to replicate the issue with  and .
Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/5c02761608274ceb4720812d78d6390d/untitled444.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='dulm' date='2020-04-23T17:18:45Z'>
		Thanks &lt;denchmark-link:https://github.com/dulm&gt;@dulm&lt;/denchmark-link&gt;
 for the report. The Feature Column shared embeddings are best used with Estimators, which internally escape into graph mode. If you want support for tf.function and eager execution, please look at Keras Embedding Layers: &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding&gt;https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding&lt;/denchmark-link&gt;
 , as these are better suited for eager execution.
		</comment>
		<comment id='5' author='dulm' date='2020-04-23T17:18:47Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29043&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29043&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='dulm' date='2020-07-08T07:17:05Z'>
		
Thanks @dulm for the report. The Feature Column shared embeddings are best used with Estimators, which internally escape into graph mode. If you want support for tf.function and eager execution, please look at Keras Embedding Layers: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding , as these are better suited for eager execution.

I don't think it's right, feature_column is a method to solve feature transform, and it's easy and efficient, all of feature_columns are supported tf2.0's DenseFeatures except shared_embeddings.   Laziness is no excuse.
		</comment>
	</comments>
</bug>