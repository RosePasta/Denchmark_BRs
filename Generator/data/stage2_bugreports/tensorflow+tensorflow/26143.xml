<bug id='26143' author='lazysjb' open_date='2019-02-26T21:12:27Z' closed_time='2019-06-04T13:17:06Z'>
	<summary>[TF2.0] Error Logging for GradientTape</summary>
	<description>
Hello everyone,
I was wondering if there is an option for error logging / or could we have tf output error message for gradient calculation. In the example below, the below will output None values in the current setting but will output correct gradients when the tf.Variables are a float type. My question is, could we please add an error message stating something like gradient calculation supports only float types?
Best Regards,
Seung-jae Bang
&lt;denchmark-code&gt;def forward(a, b):
    """f = a * b"""
    return a * b

params = [tf.Variable(1), tf.Variable(2)]

with tf.GradientTape() as tape:
    result = forward(*params)

tape.gradient(result, params)
&lt;/denchmark-code&gt;

System information

Linux
TensorFlow installed from pip install -U tf-nightly-2.0-preview - "2.0.0-dev20190226"
Python version: 3.6

ccing: &lt;denchmark-link:https://github.com/random-forests&gt;@random-forests&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='lazysjb' date='2019-03-04T17:12:49Z'>
		I'd love to approve a PR adding this test. Feel like giving it a shot?
		</comment>
		<comment id='2' author='lazysjb' date='2019-03-05T01:55:20Z'>
		I would be happy to give it a shot - I haven't contributed to TF before, would you have any pointers?
Also, would tensorflow/python/eager/backprop.py be the right place to make this change?
cc: &lt;denchmark-link:https://github.com/random-forests&gt;@random-forests&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='lazysjb' date='2019-03-05T16:39:13Z'>
		Yes, the change would be to add some logging to that particular file.

If you need any more pointers, happy to help.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, Mar 4, 2019 at 5:58 PM lazysjb ***@***.***&gt; wrote:
 I would be happy to give it a shot - I haven't contributed to TF before,
 would you have any pointers?
 Also, would tensorflow/python/eager/backprop.py be the right place to make
 this change?

 cc: @random-forests &lt;https://github.com/random-forests&gt;

 —
 You are receiving this because you were assigned.
 Reply to this email directly, view it on GitHub
 &lt;#26143 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAATxdlUmDjQehdKpLmQuotUBd4yku7iks5vTc9VgaJpZM4bTIcM&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='4' author='lazysjb' date='2019-03-08T14:20:08Z'>
		i would also like to contribute can you please help me where i can add logging in backprop.py
		</comment>
		<comment id='5' author='lazysjb' date='2019-03-08T16:51:54Z'>
		You probably want to add the warning in tape.watch here 


tensorflow/tensorflow/python/eager/backprop.py


         Line 804
      in
      d280d3d






 def watch(self, tensor): 




 and tape.gradient here 


tensorflow/tensorflow/python/eager/backprop.py


         Line 890
      in
      d280d3d






 def gradient(self, 





		</comment>
		<comment id='6' author='lazysjb' date='2019-03-23T11:04:05Z'>
		Hi,
I wish to start contributing to TensorFlow and hence would like to know if someone is already working on this issue.
		</comment>
		<comment id='7' author='lazysjb' date='2019-03-25T10:00:19Z'>
		&lt;denchmark-link:https://github.com/achalagarwal&gt;@achalagarwal&lt;/denchmark-link&gt;
 I think &lt;denchmark-link:https://github.com/shashvatshahi1998&gt;@shashvatshahi1998&lt;/denchmark-link&gt;
 is already working on this. &lt;denchmark-link:https://github.com/shashvatshahi1998&gt;@shashvatshahi1998&lt;/denchmark-link&gt;
 can you confirm?
		</comment>
		<comment id='8' author='lazysjb' date='2019-03-25T12:23:22Z'>
		Ya I am working on that, but anyone else who is interested can start working.
		</comment>
		<comment id='9' author='lazysjb' date='2019-06-04T07:21:25Z'>
		Hey, This would be my first contribution to tf and i would like to know whether this issue is open and if anybody is contributing to this.
		</comment>
		<comment id='10' author='lazysjb' date='2019-06-04T13:17:06Z'>
		Closing this out since I understand it to be resolved by the PR. I have checked the code which output warning as expected. Thanks!
		</comment>
		<comment id='11' author='lazysjb' date='2019-06-04T13:17:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26143&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26143&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>