<bug id='39451' author='MilimaBwana' open_date='2020-05-12T10:13:12Z' closed_time='2020-05-12T11:17:57Z'>
	<summary>Custom metric: update_state() raises error.</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.1.0
Python version: 3.7.1
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: 10.1/ 7.6.5
GPU model and memory: -

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
I am trying to build a custom multiclass precision and recall for a image classification task.

If i run the code below without keras and the @tf.function annotator (tf_run), it works fine.
If i'm trying to use the @tf-function annotator or use the keras model.fit function, the error below is thrown.
To make sure that the error is not caused by my own implementation I copied the implementation of BinaryTruePositives  from the tf website into my own file and tried to run it, but it produced the same error. I know this metric doesnt make much sense here, but it's only for testing purposes.
I tried the code below on Google Colab and there it works fine.
I am aware of this issue, but removing the return statements had no effects.

The code to reproduce this is shown below.
Describe the expected behavior
The custom metric should work like without the @tf.function annotator.
Standalone code to reproduce the issue
import tensorflow as tf
import keras

class BinaryTruePositives(tf.keras.metrics.Metric):

    def __init__(self, name='binary_true_positives', **kwargs):
        super(BinaryTruePositives, self).__init__(name=name, **kwargs)
        self.true_positives = self.add_weight(name='tp', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(y_true, tf.bool)
        y_pred = tf.cast(y_pred, tf.bool)

        values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
        values = tf.cast(values, self.dtype)
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, self.dtype)
            sample_weight = tf.broadcast_weights(sample_weight, values)
            values = tf.multiply(values, sample_weight)
        self.true_positives.assign_add(tf.reduce_sum(values))

    def result(self):
        return self.true_positives


class fashion_model(tf.keras.Model):
    def __init__(self):
        super(fashion_model, self).__init__()
        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)

        self.flatten = tf.keras.layers.Flatten(data_format='channels_last')
        self.dense1 = tf.keras.layers.Dense(units=128, input_shape=(28 * 28,), activation='relu')
        self.out_layer = tf.keras.layers.Dense(units=10)

        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
            from_logits=True,
            reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)

        self.train_loss = tf.keras.metrics.Mean('train_loss')
        self.train_btp = BinaryTruePositives()
        self.train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()

    def call(self, inputs, training=None, mask=None):
        x = self.flatten(inputs)
        x = self.dense1(x)
        x = self.out_layer(x)
        return x


@tf.function
def train_step(model, sample):
    images, labels = sample

    with tf.GradientTape() as tape:
        logits = model(images, training=True)
        loss = model.loss_object(y_pred=logits, y_true=labels)

    gradients = tape.gradient(loss, model.trainable_variables)
    model.optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))

    model.train_loss(loss)
    model.train_accuracy.update_state(y_pred=logits, y_true=labels)
    model.train_btp.update_state(y_pred=tf.argmax(logits, axis=-1), y_true=labels)


def tf_run():
    fashion_mnist = keras.datasets.fashion_mnist

    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
    train_dataset.shuffle(5000)
    train_dataset = train_dataset.batch(32, drop_remainder=True)
    model = fashion_model()

    for epoch in range(1, 10):

        for sample in train_dataset:
            train_step(model, sample)

        template = 'Epoch {}, Loss: {} , Acc: {}, BinaryTP: {} '
        print(template.format(epoch,
                              model.train_loss.result(),
                              model.train_accuracy.result(),
                              model.train_btp.result()))

        model.train_loss.reset_states()
        model.train_btp.reset_states()
        model.train_accuracy.reset_states()


def keras_run():
    fashion_mnist = keras.datasets.fashion_mnist

    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

    model = keras.Sequential([
        keras.layers.Flatten(input_shape=(28, 28)),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dense(10)
    ])

    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy', BinaryTruePositives()])

    model.fit(train_images, train_labels, epochs=10)


if __name__ == "__main__":
    tf_run()
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Traceback (most recent call last):
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/Code/playground/tf_metric_issue.py", line 192, in &lt;module&gt;
    main()
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/Code/playground/tf_metric_issue.py", line 188, in main
    tf_run()
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/Code/playground/tf_metric_issue.py", line 150, in tf_run
    model.train_step(sample)
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 568, in __call__
    result = self._call(*args, **kwds)
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 497, in _initialize
    *args, **kwds))
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2385, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2699, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2589, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 3207, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File "/home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in converted code:

    /home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/Code/playground/tf_metric_issue.py:130 train_step  *
        self.train_btp.update_state(y_pred=tf.argmax(logits, axis=-1), y_true=labels)
    /home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/Code/playground/tf_metric_issue.py:81 decorated  *
        update_op = update_state_fn(*args, **kwargs)
    /home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py:568 __call__
        result = self._call(*args, **kwds)
    /home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py:638 _call
        return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    /home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py:1609 _filtered_call
        self.captured_inputs)
    /home/jakob/Dokumente/INFORMATIK/_SOMMERSEMESTER_20/Masterarbeit/pollenanalysis2.0/pollenvenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py:1711 _call_flat
        flat_outputs = forward_function.call(ctx, )

    TypeError: call() missing 1 required positional argument: 'args'
	</description>
	<comments>
		<comment id='1' author='MilimaBwana' date='2020-05-12T11:17:57Z'>
		I could solve the issue by re-installing tensorflow-gpu 2.1.0
		</comment>
		<comment id='2' author='MilimaBwana' date='2020-05-12T11:17:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39451&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39451&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>