<bug id='2752' author='dans-msft' open_date='2019-10-17T23:07:39Z' closed_time='2019-11-06T00:40:56Z'>
	<summary>gym_unity.envs.UnityEnv generates incorrect observation space when uint8_visual is True</summary>
	<description>
Describe the bug
When using wrapping a Unity ML Agents environment in a Gym environment, the gym_unity.envs.UnityEnv class will create an incorrect Box observation space for visual observations when uint8_visual is True.  Specifically, it creates a Box with a dtype of float32, low of 0, and high of 1 which is only appropriate when uint8_visual is False.  It should create a Box with a dtype of uint8, low of 0, and high of 256.
To Reproduce
Setup a Unity environment that has a visual observation.  I used the GridWorld sample.
Open up a Jupyter notebook and write the following code:
from gym_unity.envs import UnityEnv
env = UnityEnv(, 1, True, True)
Now take a look at env.observation_space.low and env.observation_space.high and you'll see the incorrect values.
Furthermore, if you run
env.observation_space.contains(env.step(1)[0])
You will get 'False', indicating that the returned observation is out-of-range for its declared observation space.  This will cause a failure if you try to use this environment with Ray/RLLib (for example).
Environment (please complete the following information):

OS + version:  Ubuntu 18.04.3 LTS
ML-Agents version: mlagents version 0.10.1  gym_unity version 0.4.8
Environment: GridWorld

NOTE: We are unable to help reproduce bugs with custom environments.  Please attempt to reproduce your issue with one of the example environments, or provide a minimal patch to one of the environments needed to reproduce the issue.
	</description>
	<comments>
		<comment id='1' author='dans-msft' date='2019-10-23T03:43:13Z'>
		Hi &lt;denchmark-link:https://github.com/dans-msft&gt;@dans-msft&lt;/denchmark-link&gt;
 ,
Sorry for the delay on this.
I confirmed today that the results for env.observation_space.low and high where what you described.
It looks like we currently only use uint8_visual for scaling the observations here:



ml-agents/gym-unity/gym_unity/envs/__init__.py


        Lines 242 to 268
      in
      3643317






 def _preprocess_single(self, single_visual_obs): 



 if self.uint8_visual: 



 return (255.0 * single_visual_obs).astype(np.uint8) 



 else: 



 return single_visual_obs 



 



 def _multi_step(self, info): 



 if self.use_visual: 



 self.visual_obs = self._preprocess_multi(info.visual_observations) 



 default_observation = self.visual_obs 



 else: 



 default_observation = info.vector_observations 



 return ( 



 list(default_observation), 



 info.rewards, 



 info.local_done, 



         {"text_observation": info.text_observations, "brain_info": info}, 



     ) 



 



 def _preprocess_multi(self, multiple_visual_obs): 



 if self.uint8_visual: 



 return [ 



             (255.0 * _visual_obs).astype(np.uint8) 



 for _visual_obs in multiple_visual_obs 



         ] 



 else: 



 return multiple_visual_obs 





but we should probably be using it when setting up the observation_space here too 


ml-agents/gym-unity/gym_unity/envs/__init__.py


        Lines 139 to 147
      in
      3643317






 self._observation_space = spaces.Box( 



 0, 



 1, 



 dtype=np.float32, 



 shape=( 



 brain.camera_resolutions[0]["height"], 



 brain.camera_resolutions[0]["width"], 



 depth, 



     ), 





I'll follow up tomorrow with some folks that are more familiar with this part of the code than I am...
		</comment>
		<comment id='2' author='dans-msft' date='2019-11-06T00:40:53Z'>
		Hi &lt;denchmark-link:https://github.com/dans-msft&gt;@dans-msft&lt;/denchmark-link&gt;
,
This was fixed in &lt;denchmark-link:https://github.com/Unity-Technologies/ml-agents/pull/2783&gt;#2783&lt;/denchmark-link&gt;
, and the latest version of gym_unity (0.11.0) contains the fix.
		</comment>
	</comments>
</bug>