<bug id='2961' author='albertoxamin' open_date='2019-11-24T19:34:05Z' closed_time='2019-11-25T17:39:41Z'>
	<summary>Can't train from built linux player</summary>
	<description>
Describe the bug
I am unable to train from a built player, this is the directory of my build
(sample-env) alberto@server-x:~/builds$ ls
buildsbuild  buildsbuild_Data
this is the output of mlagents-learn
(sample-env) alberto@server-x:~/builds$ xvfb-run --auto-servernum --server-args='-screen 0 640x480x24' mlagents-learn ../config.yaml --run-id=gpu-1 --env=buildsbuild --train --no-graphics
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.



                        ▄▄▄▓▓▓▓
                   ╓▓▓▓▓▓▓█▓▓▓▓▓
              ,▄▄▄m▀▀▀'  ,▓▓▓▀▓▓▄                           ▓▓▓  ▓▓▌
            ▄▓▓▓▀'      ▄▓▓▀  ▓▓▓      ▄▄     ▄▄ ,▄▄ ▄▄▄▄   ,▄▄ ▄▓▓▌▄ ▄▄▄    ,▄▄
          ▄▓▓▓▀        ▄▓▓▀   ▐▓▓▌     ▓▓▌   ▐▓▓ ▐▓▓▓▀▀▀▓▓▌ ▓▓▓ ▀▓▓▌▀ ^▓▓▌  ╒▓▓▌
        ▄▓▓▓▓▓▄▄▄▄▄▄▄▄▓▓▓      ▓▀      ▓▓▌   ▐▓▓ ▐▓▓    ▓▓▓ ▓▓▓  ▓▓▌   ▐▓▓▄ ▓▓▌
        ▀▓▓▓▓▀▀▀▀▀▀▀▀▀▀▓▓▄     ▓▓      ▓▓▌   ▐▓▓ ▐▓▓    ▓▓▓ ▓▓▓  ▓▓▌    ▐▓▓▐▓▓
          ^█▓▓▓        ▀▓▓▄   ▐▓▓▌     ▓▓▓▓▄▓▓▓▓ ▐▓▓    ▓▓▓ ▓▓▓  ▓▓▓▄    ▓▓▓▓`
            '▀▓▓▓▄      ^▓▓▓  ▓▓▓       └▀▀▀▀ ▀▀ ^▀▀    `▀▀ `▀▀   '▀▀    ▐▓▓▌
               ▀▀▀▀▓▄▄▄   ▓▓▓▓▓▓,                                      ▓▓▓▓▀
                   `▀█▓▓▓▓▓▓▓▓▓▌
                        ¬`▀▀▀█▓


INFO:mlagents.trainers:CommandLineOptions(debug=False, num_runs=1, seed=-1, env_path='buildsbuild', run_id='gpu-1', load_model=False, train_model=True, save_freq=50000, keep_checkpoints=5, base_port=5005, num_envs=1, curriculum_folder=None, lesson=0, slow=False, no_graphics=True, multi_gpu=False, trainer_config_path='../config.yaml', sampler_file_path=None, docker_target_name=None, env_args=None, cpu=False)
Process Process-1:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/home/alberto/python-envs/sample-env/lib/python3.6/site-packages/mlagents/envs/subprocess_env_manager.py", line 82, in worker
    env = env_factory(worker_id)
  File "/home/alberto/python-envs/sample-env/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 359, in create_unity_environment
    args=env_args,
  File "/home/alberto/python-envs/sample-env/lib/python3.6/site-packages/mlagents/envs/environment.py", line 96, in __init__
    self.executable_launcher(file_name, docker_training, no_graphics, args)
  File "/home/alberto/python-envs/sample-env/lib/python3.6/site-packages/mlagents/envs/environment.py", line 221, in executable_launcher
    true_filename
mlagents.envs.exception.UnityEnvironmentException: Couldn't launch the buildsbuild environment. Provided filename does not match any environments.
Traceback (most recent call last):
  File "/home/alberto/python-envs/sample-env/bin/mlagents-learn", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/home/alberto/python-envs/sample-env/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 408, in main
    run_training(0, run_seed, options, Queue())
  File "/home/alberto/python-envs/sample-env/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 222, in run_training
    options.sampler_file_path, env.reset_parameters, run_seed
  File "/home/alberto/python-envs/sample-env/lib/python3.6/site-packages/mlagents/envs/subprocess_env_manager.py", line 225, in reset_parameters
    return self.env_workers[0].recv().payload
  File "/home/alberto/python-envs/sample-env/lib/python3.6/site-packages/mlagents/envs/subprocess_env_manager.py", line 59, in recv
    response: EnvironmentResponse = self.conn.recv()
  File "/usr/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/usr/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
Environment (please complete the following information):

OS + version: ubuntu server 18.04
ML-Agents version: 11.0
TensorFlow version: 2

	</description>
	<comments>
		<comment id='1' author='albertoxamin' date='2019-11-25T16:44:28Z'>
		It seems it doesn't find your build. In the documentation it says you should run it from the directory where you have ML-Agents installed. It seems to still find ml agents, but maybe the --env path needs to be relative to ml agents folder?
		</comment>
		<comment id='2' author='albertoxamin' date='2019-11-25T16:49:25Z'>
		I have installed mlagents from pip, in that case what should be the env path?
I have even tried with the absolute path, and I still get this error
		</comment>
		<comment id='3' author='albertoxamin' date='2019-11-25T17:37:31Z'>
		Hm if absolute path doesn't work maybe there's some other issue.
I notice that your --env points to something without file extension, is that the executable file that you would usually run the game with? On Windows for example I need to point to the .exe file. Not sure how it works on Linux. Maybe someone from Unity team can help out better.
		</comment>
		<comment id='4' author='albertoxamin' date='2019-11-25T17:39:41Z'>
		I found the problem! Linux executables usually don't have an extension.
However mlagents-learn looks for a file ending with .x86_64
		</comment>
	</comments>
</bug>