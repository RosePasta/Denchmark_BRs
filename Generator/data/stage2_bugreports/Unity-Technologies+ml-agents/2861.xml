<bug id='2861' author='BlonskiP' open_date='2019-11-06T22:07:31Z' closed_time='2019-11-07T21:00:37Z'>
	<summary>mini_batch["next_visual_obs%d" % i] = next_info.visual_observations[i] IndexError: list index out of range</summary>
	<description>
I'm trying to reset environment after a goal is completed.
I have implemented check function which sets Academy to Done.
On Academy Reset I'm trying to destroy all agents and then Spawn few new.
Academy is cheking if competition is won/lose each step.
Academy has 0 max step.
Agent doesn't have ResetOnDone checked, because I want to respawn agents where the spawner object is and begin a new episode.
OnAgentDone Agent does nothing. I want to destoy him after academy is done. (Because he hold model etc.)
The problem is that when I get one of the agents done in a few first steps (probably)
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "C:\Users\Wilk-PC\Anaconda3\envs\ml-agents\Scripts\mlagents-learn-script.py", line 11, in &lt;module&gt;
    load_entry_point('mlagents', 'console_scripts', 'mlagents-learn')()
  File "c:\studia\ml-agents-master\ml-agents-master\ml-agents\mlagents\trainers\learn.py", line 337, in main
    run_training(0, run_seed, options, Queue())
  File "c:\studia\ml-agents-master\ml-agents-master\ml-agents\mlagents\trainers\learn.py", line 132, in run_training
    tc.start_learning(env)
  File "c:\studia\ml-agents-master\ml-agents-master\ml-agents\mlagents\trainers\trainer_controller.py", line 202, in start_learning
    n_steps = self.advance(env_manager)
  File "c:\studia\ml-agents-master\ml-agents-master\ml-agents-envs\mlagents\envs\timers.py", line 261, in wrapped
    return func(*args, **kwargs)
  File "c:\studia\ml-agents-master\ml-agents-master\ml-agents\mlagents\trainers\trainer_controller.py", line 279, in advance
    step_info.brain_name_to_action_info[brain_name].outputs,
  File "c:\studia\ml-agents-master\ml-agents-master\ml-agents\mlagents\trainers\rl_trainer.py", line 159, in add_experiences
    tmp_reward_signal_outs[name] = signal.evaluate(curr_to_use, next_info)
  File "c:\studia\ml-agents-master\ml-agents-master\ml-agents\mlagents\trainers\components\reward_signals\curiosity\signal.py", line 65, in evaluate
    mini_batch["next_visual_obs%d" % i] = next_info.visual_observations[i]
IndexError: list index out of range
&lt;/denchmark-code&gt;

I don't use any visual_observation. What should I correct to don't get this learning freezing error?
&lt;denchmark-link:https://github.com/BlonskiP/Competing-neural-networks-in-arcade-games/&gt;https://github.com/BlonskiP/Competing-neural-networks-in-arcade-games/&lt;/denchmark-link&gt;

Trening parameters:
default:
trainer: ppo
batch_size: 1024
beta: 5.0e-3
buffer_size: 10240
epsilon: 0.2
hidden_units: 128
lambd: 0.95
learning_rate: 3.0e-4
max_steps: 5.0e4
memory_size: 256
normalize: false
num_epoch: 3
num_layers: 2
time_horizon: 64
sequence_length: 64
summary_freq: 1000
use_recurrent: false
vis_encode_type: simple
reward_signals:
extrinsic:
strength: 1.0
gamma: 0.99
curiosity:
strength: 0.02
gamma: 0.99
encoding_size: 256
Team1Warrior:
max_steps: 5.0e5
learning_rate: 1e-3
batch_size: 128
num_epoch: 3
buffer_size: 2000
beta: 1.0e-2
hidden_units: 256
summary_freq: 2000
time_horizon: 128
num_layers: 2
normalize: false
	</description>
	<comments>
	</comments>
</bug>