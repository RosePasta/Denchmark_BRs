<bug id='2401' author='DooblyNoobly' open_date='2019-08-07T05:38:31Z' closed_time='2019-08-08T01:54:59Z'>
	<summary>Error when trying to use a demo brain with Gail</summary>
	<description>
Describe the bug
When using a demo brain with gail, mlagents throws an error after pressing play in the editor.
&lt;denchmark-code&gt;File "C:\Users\andre\.conda\envs\ml\Scripts\mlagents-learn-script.py", line 11, in &lt;module&gt;
    load_entry_point('mlagents', 'console_scripts', 'mlagents-learn')()
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\learn.py", line 319, in main
    run_training(0, run_seed, options, Queue())
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\learn.py", line 118, in run_training
    tc.start_learning(env, trainer_config)
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\trainer_controller.py", line 283, in start_learning
    self.initialize_trainers(trainer_config, env_manager.external_brains)
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\trainer_controller.py", line 206, in initialize_trainers
    run_id=self.run_id,
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\ppo\trainer.py", line 68, in __init__
    self.policy = PPOPolicy(seed, brain, trainer_parameters, self.is_training, load)
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\ppo\policy.py", line 57, in __init__
    self, reward_signal, config
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\components\reward_signals\reward_signal_factory.py", line 40, in create_reward_signal
    class_inst = rcls(policy, **config_entry)
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\components\reward_signals\gail\signal.py", line 53, in __init__
    _, self.demonstration_buffer = demo_to_buffer(demo_path, policy.sequence_length)
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\demo_loader.py", line 64, in demo_to_buffer
    demo_buffer = make_demo_buffer(brain_infos, brain_params, sequence_length)
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\demo_loader.py", line 49, in make_demo_buffer
    0, batch_size=None, training_length=sequence_length
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\buffer.py", line 272, in append_update_buffer
    batch_size=batch_size, training_length=training_length
  File "d:\github\ml-agents\ml-agents\mlagents\trainers\buffer.py", line 126, in get_batch
    padding = np.array(self[-1]) * self.padding_value
IndexError: list index out of range
&lt;/denchmark-code&gt;

config:
default:
    trainer: ppo
    batch_size: 128
    beta: 0.0001
    buffer_size: 64000
    epsilon: 0.2
    hidden_units: 256
    lambd: 0.95
    learning_rate: 0.002
    max_steps: Infinity
    memory_size: 512
    normalize: True
    num_epoch: 2
    num_layers: 1
    time_horizon: 400
    sequence_length: 32
    summary_freq: 1000
    use_recurrent: True
    reward_signals:
        extrinsic:
            strength: 1
            gamma: 0.99
        gail:
            strength: 0.1
            gamma: 0.99
            encoding_size: 128
            demo_path: demos/BigBotBrain.demo
To Reproduce
Steps to reproduce the behavior:

Record a demonstration on the player brain (up to 500 steps)
Add the demo brain path and gail reward parameters to config
Disable player brain, enable Learningbrain and add to Academy with control
Start mlagents-learn and press play in editor
See error

Environment (please complete the following information):

Win_10
ML-Agents version: v0.9 latest master as of today

**Note: I updated mlagents in the anaconda environment by pulling the latest from master and running the commands as outlined in windows install guide:
cd ml-agents-envs
pip install -e .
cd ..
cd ml-agents
pip install -e .
Screenshot of Demo Asset:
&lt;denchmark-link:https://user-images.githubusercontent.com/20813925/62597410-5907ec80-b929-11e9-9808-c066f8ae4ed6.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='DooblyNoobly' date='2019-08-07T06:57:11Z'>
		Describe the bug
When using a visual demo brain with gail, mlagents throws an error after pressing play in the editor.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "e:\program files\anaconda\envs\mlagents\lib\runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "e:\program files\anaconda\envs\mlagents\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "E:\Program Files\anaconda\envs\mlagents\Scripts\mlagents-learn.exe\__main__.py", line 9, in &lt;module&gt;
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\learn.py", line 319, in main
    run_training(0, run_seed, options, Queue())
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\learn.py", line 118, in run_training
    tc.start_learning(env, trainer_config)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\trainer_controller.py", line 283, in start_learning
    self.initialize_trainers(trainer_config, env_manager.external_brains)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\trainer_controller.py", line 206, in initialize_trainers
    run_id=self.run_id,
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\ppo\trainer.py", line 68, in __init__
    self.policy = PPOPolicy(seed, brain, trainer_parameters, self.is_training, load)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\ppo\policy.py", line 57, in __init__
    self, reward_signal, config
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\components\reward_signals\reward_signal_factory.py", line 40, in create_reward_signal
    class_inst = rcls(policy, **config_entry)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\components\reward_signals\gail\signal.py", line 51, in __init__
    policy.model, 128, learning_rate, encoding_size, use_actions, use_vail
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\components\reward_signals\gail\model.py", line 41, in __init__
    self.make_inputs()
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\components\reward_signals\gail\model.py", line 125, in make_inputs
    False,
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\mlagents\trainers\models.py", line 249, in create_visual_observation_encoder
    name="conv_1",
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\layers\convolutional.py", line 619, in conv2d
    return layer.apply(inputs)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\layers\base.py", line 825, in apply
    return self.__call__(inputs, *args, **kwargs)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\layers\base.py", line 696, in __call__
    self.build(input_shapes)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\layers\convolutional.py", line 144, in build
    dtype=self.dtype)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\layers\base.py", line 546, in add_variable
    partitioner=partitioner)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\training\checkpointable.py", line 415, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\ops\variable_scope.py", line 1297, in get_variable
    constraint=constraint)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\ops\variable_scope.py", line 1093, in get_variable
    constraint=constraint)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\ops\variable_scope.py", line 439, in get_variable
    constraint=constraint)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\ops\variable_scope.py", line 408, in _true_getter
    use_resource=use_resource, constraint=constraint)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\ops\variable_scope.py", line 747, in _get_single_variable
    name, "".join(traceback.format_list(tb))))
ValueError: Variable stream_0_visual_obs_encoder/conv_1/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\framework\ops.py", line 1654, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\framework\ops.py", line 3290, in create_op
    op_def=op_def)
  File "e:\program files\anaconda\envs\mlagents\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
&lt;/denchmark-code&gt;

config
&lt;denchmark-code&gt;    trainer: ppo
    batch_size: 1024
    beta: 5.0e-3
    buffer_size: 10240
    epsilon: 0.2
    hidden_units: 128
    lambd: 0.95
    learning_rate: 3.0e-4
    max_steps: 5.0e4
    memory_size: 256
    normalize: false
    num_epoch: 3
    num_layers: 2
    time_horizon: 64
    sequence_length: 64
    summary_freq: 1000
    use_recurrent: true
    vis_encode_type: simple
    pretraining:
        demo_path: ./UnitySDK/Assets/Demonstrations/VisualPushBlock.demo
        strength: 0.5
        steps: 10000
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.99
        curiosity:
            strength: 0.02
            gamma: 0.99
            encoding_size: 256
        gail:
            strength: 0.01
            gamma: 0.99
            encoding_size: 128
            demo_path: ./UnitySDK/Assets/Demonstrations/VisualPushBlock.demo
&lt;/denchmark-code&gt;

When I remove curiousity config， error had disappeared
		</comment>
		<comment id='2' author='DooblyNoobly' date='2019-08-07T07:09:28Z'>
		Hi &lt;denchmark-link:https://github.com/DooblyNoobly&gt;@DooblyNoobly&lt;/denchmark-link&gt;
, thanks for raising this issue. Could you try with the latest  branch?  is the bleeding edge and may have issues.
&lt;denchmark-link:https://github.com/arixlin&gt;@arixlin&lt;/denchmark-link&gt;
, are you on  or ? If  this seems like a bug and we'll investigate. Thanks!
		</comment>
		<comment id='3' author='DooblyNoobly' date='2019-08-07T07:18:30Z'>
		&lt;denchmark-link:https://github.com/ervteng&gt;@ervteng&lt;/denchmark-link&gt;
  on release v0.9 Thanks
		</comment>
		<comment id='4' author='DooblyNoobly' date='2019-08-07T07:25:03Z'>
		&lt;denchmark-link:https://github.com/ervteng&gt;@ervteng&lt;/denchmark-link&gt;
 my mistake, turns out I was already on latest master. I'll edit my bug report:
&lt;denchmark-link:https://user-images.githubusercontent.com/20813925/62602948-3cbf7c00-b938-11e9-8c47-0f592d4a6afa.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='DooblyNoobly' date='2019-08-07T22:30:09Z'>
		&lt;denchmark-link:https://github.com/DooblyNoobly&gt;@DooblyNoobly&lt;/denchmark-link&gt;
 - I wasn't able to replicate your issue on the sample environments, unfortunately. Could you try on the Hallway example and see if you're getting the same behavior? Thanks!
&lt;denchmark-link:https://github.com/arixlin&gt;@arixlin&lt;/denchmark-link&gt;
 - I was able to replicate this issue, it's a naming conflict between Curiosity and GAIL. It will be fixed in a patch in the next couple days. For now, I'd use GAIL only - usually, curiosity + GAIL doesn't add too much value.
		</comment>
		<comment id='6' author='DooblyNoobly' date='2019-08-08T01:54:59Z'>
		I just confirmed that hallway example works fine. I have even tested recording a new demonstration and there wasn't any problem. Must be something I'm doing specifically with my project.
		</comment>
		<comment id='7' author='DooblyNoobly' date='2019-08-08T02:00:01Z'>
		&lt;denchmark-link:https://github.com/ervteng&gt;@ervteng&lt;/denchmark-link&gt;
  Thanks for your work.
		</comment>
		<comment id='8' author='DooblyNoobly' date='2019-08-08T17:24:49Z'>
		&lt;denchmark-link:https://github.com/DooblyNoobly&gt;@DooblyNoobly&lt;/denchmark-link&gt;
 it really does seem like a bug in the demo loader from your error message though . The only thing I can think of is if any of the brain settings changed between recording and training. Anyways, feel free to re-open the issue if you're unable to get it to work.
		</comment>
	</comments>
</bug>