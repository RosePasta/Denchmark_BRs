<bug id='571' author='cemunds' open_date='2018-04-03T17:44:24Z' closed_time='2018-04-04T18:46:15Z'>
	<summary>Visual observation inputs connected to wrong outputs</summary>
	<description>
I needed a visualization of the default neural network that is used by the PPO model, so I tried to plot the computation graph with TensorFlow. In my environment, I use three camera observations per brain. It was then that I noticed that all convolutional layers of the network are connected to the same  node and that the other two nodes are not connected to any outputs.
&lt;denchmark-link:https://user-images.githubusercontent.com/8558936/38265474-513e437c-3776-11e8-8271-871f23a72e19.png&gt;&lt;/denchmark-link&gt;

I'm a beginner in TensorFlow, but I doubt this setup is correct. I had a look at the create_visual_encoder method in the models.py file and found this line:
conv1 = tf.layers.conv2d(self.visual_in[-1], 16, kernel_size=[8, 8], strides=[4, 4], activation=tf.nn.elu)
Here it wraps a convolutional layer around the last item in visual_in, which seems incorrect to me if there are multiple visual observations. I hope someone can tell me whether this is a real error in the code, or if I missed something else which explains using only the last item of visual_in.
	</description>
	<comments>
		<comment id='1' author='cemunds' date='2018-04-04T00:13:50Z'>
		Could you try again on hotfix-multiple-visual? I modified the line of code you mentioned.
		</comment>
		<comment id='2' author='cemunds' date='2018-04-04T11:02:07Z'>
		Now it seems to be correct. Thank you for addressing this issue so quickly.
&lt;denchmark-link:https://user-images.githubusercontent.com/8558936/38304059-4ff4cd28-3808-11e8-802b-ce5505e6683c.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='cemunds' date='2019-07-22T15:08:44Z'>
		Hi,
Do you have the full updated graph please ?
Cheers
		</comment>
	</comments>
</bug>