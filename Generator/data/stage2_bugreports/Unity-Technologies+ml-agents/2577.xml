<bug id='2577' author='leobol96' open_date='2019-09-17T17:01:20Z' closed_time='2020-03-10T17:29:02Z'>
	<summary>ValueError: Cannot feed value of shape</summary>
	<description>
Hello,
I have this error using learning by demostration.
This is the error message:
INFO:mlagents.envs:Hyperparameters for the OfflineBCTrainer of brain RightBrain:
trainer: offline_bc
batch_size: 256
summary_freq: 1000
max_steps: 5.0e6
batches_per_epoch: 10
use_recurrent: True
hidden_units: 256
learning_rate: 0.0003
num_layers: 3
sequence_length: 32
memory_size: 256
demo_path: nodescription_1.demo
summary_path: ./summaries/ppo_RightBrain
model_path: ./models/ppo-0/RightBrain
keep_checkpoints: 5
Traceback (most recent call last):
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\runpy.py", line 193, in _run_module_as_main
"main", mod_spec)
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\runpy.py", line 85, in run_code
exec(code, run_globals)
File "C:\Users\Leonardo\Anaconda3\envs\ml-agents\Scripts\mlagents-learn.exe_main.py", line 9, in
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\mlagents\trainers\learn.py", line 337, in main
run_training(0, run_seed, options, Queue())
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\mlagents\trainers\learn.py", line 132, in run_training
tc.start_learning(env)
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\mlagents\trainers\trainer_controller.py", line 202, in start_learning
n_steps = self.advance(env_manager)
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\mlagents\envs\timers.py", line 261, in wrapped
return func(*args, **kwargs)
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\mlagents\trainers\trainer_controller.py", line 292, in advance
trainer.update_policy()
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\mlagents\trainers\bc\trainer.py", line 138, in update_policy
run_out = self.policy.update(mini_batch, self.n_sequences)
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\mlagents\trainers\bc\policy.py", line 95, in update
run_out = self._execute_model(feed_dict, self.update_dict)
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\mlagents\trainers\tf_policy.py", line 148, in _execute_model
network_out = self.sess.run(list(out_dict.values()), feed_dict=feed_dict)
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\tensorflow\python\client\session.py", line 905, in run
run_metadata_ptr)
File "c:\users\leonardo\anaconda3\envs\ml-agents\lib\site-packages\tensorflow\python\client\session.py", line 1116, in _run
str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (8, 5) for Tensor 'teacher_action:0', which has shape '(?, 4)'
	</description>
	<comments>
		<comment id='1' author='leobol96' date='2019-09-17T17:48:57Z'>
		Hi &lt;denchmark-link:https://github.com/leobol96&gt;@leobol96&lt;/denchmark-link&gt;

It seems that your teacher and student brains have different action spaces.
		</comment>
		<comment id='2' author='leobol96' date='2019-09-17T20:15:30Z'>
		&lt;denchmark-link:https://github.com/awjuliani&gt;@awjuliani&lt;/denchmark-link&gt;

I checked and the brains have:

Same action spaces.
Same environment with 28 obs.

&lt;denchmark-link:https://user-images.githubusercontent.com/36326039/65075792-e06c6500-d997-11e9-87c5-b47fe120b9c0.PNG&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/36326039/65075801-e5311900-d997-11e9-8767-100454b61eb6.PNG&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='leobol96' date='2019-09-18T12:10:56Z'>
		&lt;denchmark-link:https://github.com/leobol96&gt;@leobol96&lt;/denchmark-link&gt;
  I had a very similar issue where the error was :

I found out that 64 was my batch_size in the offline_bc_config.yaml
So i tried to increase it till the error has disappear
Now my batch_size is 10000
		</comment>
		<comment id='4' author='leobol96' date='2019-09-18T12:44:44Z'>
		&lt;denchmark-link:https://github.com/djsdvg&gt;@djsdvg&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/awjuliani&gt;@awjuliani&lt;/denchmark-link&gt;

Same for me , the error disappear with a batch size of 1000000.
		</comment>
		<comment id='5' author='leobol96' date='2019-09-21T07:30:16Z'>
		I tried several training with a large batch_sizeto avoid   the error but the training is not learning.
It seems that the policy is never updated.
In fact on Tensorboard the graph under the policy section is empty
		</comment>
		<comment id='6' author='leobol96' date='2020-03-10T17:29:01Z'>
		Hi all,
We have depreciated the online and offline BC trainers in favor of a new approach which can work concurrently with RL training. It should also resolve the issues that have been described here: &lt;denchmark-link:https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Training-Imitation-Learning.md&gt;https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Training-Imitation-Learning.md&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='7' author='leobol96' date='2020-03-10T18:28:17Z'>
		ok
		</comment>
	</comments>
</bug>