<bug id='196' author='andreaBassich' open_date='2017-12-20T19:09:14Z' closed_time='2018-01-08T12:41:39Z'>
	<summary>[Solved] Cumulative reward/ episode length not updating</summary>
	<description>
Hi,
When i train my model all the data about the agent's performance is collected correctly at first, but then it stops displaying the mean reward, and stops updating cumulative reward and episode length on TensorBoard. A typical example of this is below, with the model saving every 50k steps and the results updating every 5k:
Step: 5000. Mean Reward: -1.46849992063. Std of Reward: 0.464499920865.
Step: 10000. Mean Reward: -1.04049990218. Std of Reward: 0.0.
Saved Model
Saved Model
...
Any clue on how to fix this problem or on what caused it?
Also as a little side note, are there any plans of training as fast as possible, without having to be bound to a time scale of 100?
Cheers
	</description>
	<comments>
		<comment id='1' author='andreaBassich' date='2017-12-23T18:12:13Z'>
		Hi &lt;denchmark-link:https://github.com/andreaBassich&gt;@andreaBassich&lt;/denchmark-link&gt;
,
Is this perhaps linked to the length of the episodes in your environment?
We are working on unlocking timescale, but it will take a little time to come to realization, since it is tied closely to the game engine itself.
		</comment>
		<comment id='2' author='andreaBassich' date='2017-12-24T19:10:33Z'>
		Hi &lt;denchmark-link:https://github.com/awjuliani&gt;@awjuliani&lt;/denchmark-link&gt;
,
I capped the length of my episode to 1k game steps in the academy, at the moment I don't even get the initial info at 5 and 10k steps, but only the save model is displayed when I train my net.
Following your question I tried a mock run with maxsteps = 100 in the academy, the environment does reset correctly after 100 game steps, but I didn't have any luck with the logs.
Any idea on what could cause this besides the episode length?
Cheers
		</comment>
		<comment id='3' author='andreaBassich' date='2017-12-26T16:24:47Z'>
		Do you get the same issue when running the example environments?
		</comment>
		<comment id='4' author='andreaBassich' date='2017-12-27T18:26:45Z'>
		&lt;denchmark-link:https://github.com/awjuliani&gt;@awjuliani&lt;/denchmark-link&gt;

No, everything was fine when I ran the example environments. I think it might be a problem specific to my environment, in fact today i tried to run the Basics notebook on my environment and it raises the following exception when line 8 is executed:
UnityActionException: The episode is completed. Reset the environment with 'reset()'
Although the PPO notebook doesn't give me any exceptions.
How would i go about fixing this?
		</comment>
		<comment id='5' author='andreaBassich' date='2018-01-08T12:40:49Z'>
		Turns out all the issues I've been having were because for some reason at the end of the AgentReset method i decided to set done = false. Thank you for your help.
		</comment>
		<comment id='6' author='andreaBassich' date='2020-01-04T20:17:07Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>