<bug id='1418' author='4rzael' open_date='2018-11-13T17:00:24Z' closed_time='2018-11-14T15:29:07Z'>
	<summary>Deterministic agent order for multi-agent and parallel training ?</summary>
	<description>
Hello,
I am currently experimenting with Unity ml-agents, and having a small problem:
My use case is the following:
I have two agents (Green and Red, in the image below), that both need to go to an objective (Blue).
Green and Red have the same observation and action space, and are therefore using the same brain. However, I have to, in the python environment, use two different neural networks to control them (in order to be able to have two completely different behaviours for the agents).
Moreover, I saw that ml-agent was able to have multiple copies of the environment simulating at the same time, which, from what I understood, would allow to increase the speed at which our agents obtain  experiences (as seen in the tennis environment, for example). I would therefore like to have that working in my environment too.
Note: I am using Unity-gym (that is not a hard requirement, but keeping it would be a huge plus).
Here is what my full scene looks like, after 1 step (we can see the 9 environments, each with 2 agents).
&lt;denchmark-link:https://user-images.githubusercontent.com/9220115/48429454-7da1b000-e76d-11e8-9926-8fa8a0dba017.png&gt;&lt;/denchmark-link&gt;

When I get the observation vector in python, I get something like that:
[array([-3.66145349, 39.95597839, -5.42713928, -3.27645111]),
 array([ 1.40901756, 84.54786682, 10.44488716, -1.08152771]),
 array([ 11.79083633,   4.87645292,  -9.44654083, -11.14302635]),
 array([  5.23679304,  48.76234436, -14.32538605, -12.08281708]),
 array([34.60759735, 33.54735947,  6.45320129, 11.7821846 ]),
 array([69.73635864, 86.62394714,  5.67533875, -6.65470886]),
 array([28.70316696, -8.5767231 , 16.01457596,  7.94912148]),
 array([72.08556366, 11.37228584,  8.72614288, -9.40304756]),
 array([32.47013855, 73.6333313 ,  3.48246765, 17.45579529]),
 array([89.70376587, -0.09075928, -8.89205933,  2.05999756]),
 array([ 0.62114334,  0.7161808 ,  1.72315216, -6.98275375]),
 array([28.51509476, 85.4638443 ,  7.43751144,  5.62528229]),
 array([77.98065186, 37.98202133,  6.69857788, -1.5790596 ]),
 array([-10.31629372,  91.48905945,  22.17019844,  -8.02272034]),
 array([51.70516205,  7.97335052, -6.98741913, -8.60095215]),
 array([ 89.1384201 ,  78.8328476 , -13.72672272,   1.13639069]),
 array([35.11167908, 44.54938507,  5.94911957,  0.780159  ]),
 array([75.83343506, 33.60383224,  8.84579468,  2.79912949])]
We can see that agents are not sorted at all, either by environment, or anything else I can understand (looking at the first two values, corresponding to the agent's position, we can see that the 3rd one in the array is in the same environment as the 11th one).
How can I fix this problem ? Is there any way to make the order of the agents deterministic ? Should I send useless informations in the observation vector (like something saying which agent it is), which I use to select which model to use ?
Thanks a lot
	</description>
	<comments>
		<comment id='1' author='4rzael' date='2018-11-13T18:01:08Z'>
		Hi,
It is currently not possible to have multi brain training with the gym wrapper. If you do not use the wrapper, you could access the ids of the agents by doing
&lt;denchmark-code&gt;env.step(&lt;action&gt;)[&lt;brain-name&gt;].agents
&lt;/denchmark-code&gt;

If you really want to keep using gym, when calling step(action) you will have 4 objects returned : obs, reward, done, info. Fortunately, the forth one : info is the original info used in mlagents.envs api. By calling info.agents you will get a list of ids. these ids are uniques and specific to an agent. The position of agent 3 might change in the list but the order of the ids should be the same as the order of observations, rewards and done.
I hope this helps.
		</comment>
		<comment id='2' author='4rzael' date='2018-11-14T15:29:06Z'>
		Thanks a lot,
I think I will stop using gym, then, and move to your API.
		</comment>
		<comment id='3' author='4rzael' date='2019-01-05T03:26:37Z'>
		I have a follow-up question. I have the same setup (2 agents, multiple Areas, but without gym wrapper). I can get the two lists of ids
&lt;denchmark-code&gt;all_brain_info[&lt;brain-1&gt;].agents
all_brain_info[&lt;brain-2&gt;].agents
&lt;/denchmark-code&gt;

But how do I pair up the ids across the two lists by Area? This is important because I sum their rewards for a cooperative task.
		</comment>
		<comment id='4' author='4rzael' date='2019-01-05T19:58:58Z'>
		Here is a quick solution. If you output the area id in the first element of vector_observations, e.g.     AddVectorObs(areaID), then the following script will reorder observations, rewards, and actions according to the areaID.
&lt;denchmark-code&gt;def sort_observations_by_area(all_brain_info):
  """
  Sorts the observations and rewards by the first element of the
  vector_observation. By outputting an area_id as the first element
  of the vector_observation, you can use this function to sort
  observations and rewards by area_id.

  Care is taken to maintain original references, in case they are
  used elsewhere by ml-agents.

  Returns a function that unsorts actions to their appropriate index
  unsort_actions_by_area(actions)
  """
  area2idxs = {}
  for brain_name, brain_info in all_brain_info.items():
    n_areas = len(brain_info.vector_observations)

    # area2idx[i] -&gt; index. If i&lt;=j then vector_observations[i][0] &lt;= vector_observations[j][0]
    area2idx = np.argsort([vobs[0] for vobs in brain_info.vector_observations])
    area2idxs[brain_name] = area2idx

    # sort agents
    original = brain_info.agents[:] # original references
    for a in range(n_areas):
      brain_info.agents[a] = original[area2idx[a]]

    # sort visual_observations
    for cam_i in range(len(brain_info.visual_observations)): # for each camera of the brain
      brain_info.visual_observations[cam_i][:] = brain_info.visual_observations[cam_i][area2idx]

    # sort vector_observations
    original = brain_info.vector_observations[:] # original references
    for a in range(n_areas):
      brain_info.vector_observations[a] = original[area2idx[a]]

    # sort rewards
    original = brain_info.rewards[:] # original references
    for a in range(n_areas):
      brain_info.rewards[a] = original[area2idx[a]]

  def unsort_actions_by_area_fn(actions_d):
    for brain_name, actions in actions_d.items():
      area2idx = area2idxs[brain_name]
      n_areas = len(area2idx)
      assert len(actions) == n_areas, "{} actions expected, {} actions received".format(len(actions), n_areas)

      # unsort actions
      original = actions[:]
      for a in range(n_areas):
        actions[area2idx[a]] = original[a]

  return unsort_actions_by_area_fn
&lt;/denchmark-code&gt;

Usage:
&lt;denchmark-code&gt;all_brain_info = env.reset()
unsort_actions_by_area_fn = sort_observations_by_area(all_brain_info)
...
unsort_actions_by_area_fn(actions)
all_brain_info = env.step(actions)
unsort_actions_by_area_fn = sort_observations_by_area(all_brain_info)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='4rzael' date='2020-01-05T21:34:41Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>