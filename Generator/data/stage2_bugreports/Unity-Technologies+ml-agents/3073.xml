<bug id='3073' author='Dastyn' open_date='2019-12-11T09:45:04Z' closed_time='2020-04-03T01:39:48Z'>
	<summary>YAML: demo number of experiences and PPO batch_size</summary>
	<description>
Hi All!
I recorded a demo with 116 "number experiences", for pre-training and GAIL objectives.
It seems that in the Yaml file used as config file for mlagents-learn process, it is mandatory to specify that the PPO batch_size is 115 (i.e. 116-1).
Otherwise an error is raised (see below: 512 is the batch_size defined at PPO level in the Yaml - note that even specifying 115 as the batch_size in pretraining section does not solve the issue):
Traceback (most recent call last):
File "/users/dastyn/.local/bin/mlagents-learn", line 11, in
sys.exit(main())
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 422, in main
run_training(0, run_seed, options, Queue())
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 266, in run_training
tc.start_learning(env)
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/trainers/trainer_controller.py", line 209, in start_learning
n_steps = self.advance(env_manager)
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/envs/timers.py", line 262, in wrapped
return func(*args, **kwargs)
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/trainers/trainer_controller.py", line 297, in advance
trainer.update_policy()
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/trainers/ppo/trainer.py", line 259, in update_policy
buffer.make_mini_batch(l, l + batch_size), n_sequences
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/envs/timers.py", line 262, in wrapped
return func(*args, **kwargs)
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/trainers/ppo/policy.py", line 188, in update
update_vals = self._execute_model(feed_dict, self.update_dict)
File "/users/dastyn/.local/lib/python3.6/site-packages/mlagents/trainers/tf_policy.py", line 162, in _execute_model
network_out = self.sess.run(list(out_dict.values()), feed_dict=feed_dict)
File "/users/dastyn/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 950, in run
run_metadata_ptr)
File "/users/dastyn/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1173, in _run
feed_dict_tensor, options, run_metadata)
File "/users/dastyn/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1350, in _do_run
run_metadata)
File "/users/dastyn/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1370, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Incompatible shapes: [115] vs. [512]
A few info on releases used:
mlagents (0.12.0, /users/dastyn/.local/lib/python3.6/site-packages)
mlagents-envs (0.12.0, /users/dastyn/.local/lib/python3.6/site-packages)
tensorflow (1.14.0)
Thanks in advance for your help and any hints!
	</description>
	<comments>
		<comment id='1' author='Dastyn' date='2019-12-17T18:12:40Z'>
		Thanks for bringing this to our attention &lt;denchmark-link:https://github.com/Dastyn&gt;@Dastyn&lt;/denchmark-link&gt;
 We will have a look at it.
		</comment>
		<comment id='2' author='Dastyn' date='2020-04-03T01:39:48Z'>
		Hi &lt;denchmark-link:https://github.com/Dastyn&gt;@Dastyn&lt;/denchmark-link&gt;
, this issue has been fixed in the latest release 0.15.1; thanks for reporting! Feel free to re-open the issue if you're still having problems.
		</comment>
	</comments>
</bug>