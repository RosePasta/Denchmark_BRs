<bug id='38' author='ashwal' open_date='2017-09-26T18:03:18Z' closed_time='2017-09-26T18:54:46Z'>
	<summary>CoreBrainInternal throws error when trying to use an internal brain with observations.</summary>
	<description>
This line (197) fails runner.AddInput(graph[graphScope + placeholder.name][0], new float[] { Random.Range(placeholder.minValue, placeholder.maxValue) }).
I grabbed the latest script and it now throws an exception but I've confirmed that epsilon is set on the brain. Debug.Log shows that graph is failing to return anything, the other vars have values (except graphScope, could that be the problem?).
I also noticed when trying to debug that the GridWorld example does not have an internal brain option, related?
Brain screenshot attached.
&lt;denchmark-link:https://user-images.githubusercontent.com/433628/30876122-8a1194f8-a2aa-11e7-98ed-f2bea59afbf8.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='ashwal' date='2017-09-26T18:21:12Z'>
		Hi! Can I ask you what is the error reported in the console ? What are the inputs and outputs of the robot-env.bytes graph? I think this error might occur because there is no placeholder called epsilon in the graph.
		</comment>
		<comment id='2' author='ashwal' date='2017-09-26T18:29:18Z'>
		&lt;denchmark-link:https://github.com/vincentpierre&gt;@vincentpierre&lt;/denchmark-link&gt;
 Now the Try Catch block snags it but before it was:

NullReferenceException: Object reference not set to an instance of an object
CoreBrainInternal.DecideAction () (at Assets/ML-Agents/Scripts/CoreBrainInternal.cs:198)
Brain.DecideAction () (at Assets/ML-Agents/Scripts/Brain.cs:312)
Academy.DecideAction () (at Assets/ML-Agents/Scripts/Academy.cs:250)
Academy.RunMdp () (at Assets/ML-Agents/Scripts/Academy.cs:337)
Academy.FixedUpdate () (at Assets/ML-Agents/Scripts/Academy.cs:260)

The graph is from the provided PPO implementation. Is there more info I can provide that's not included in the above screenshot?
		</comment>
		<comment id='3' author='ashwal' date='2017-09-26T18:43:14Z'>
		My best guess is that  there are no placeholder called epsilon in your robot-env.bytes graph. Can you try removing the graph placeholder (set its size to 0) in the inspector and see if the error is different?
		</comment>
		<comment id='4' author='ashwal' date='2017-09-26T18:44:38Z'>
		Hi &lt;denchmark-link:https://github.com/ashwal&gt;@ashwal&lt;/denchmark-link&gt;
,
If you used discrete actions, then there won't be a need for an epsilon value, since that corresponds to continuous control models which need to sample noise in order to decide their action.
		</comment>
		<comment id='5' author='ashwal' date='2017-09-26T18:51:42Z'>
		&lt;denchmark-link:https://github.com/awjuliani&gt;@awjuliani&lt;/denchmark-link&gt;
 yep that cleared it up  Maybe a table in the docs that disambiguates the parameters/setup needed for each environment permutation?
		</comment>
		<comment id='6' author='ashwal' date='2017-09-26T18:54:46Z'>
		Agreed. We currently don't make it clear the reason epsilon is added to the 3DBall demo. Glad you were able to get it working.
		</comment>
		<comment id='7' author='ashwal' date='2020-01-04T23:27:28Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>