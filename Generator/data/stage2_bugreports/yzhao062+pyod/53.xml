<bug id='53' author='GiovannaR' open_date='2019-01-30T20:00:03Z' closed_time='2019-02-10T19:33:20Z'>
	<summary>Problem in CBLOF when the number of clusters is big and the train set has too many repeated value</summary>
	<description>
Hi
If the train set has many repeated values and a large number of clusters is used, then some clusters will have the same value for the center. So, when defining the equation self.cluster_sizes_=np.bincount(clf.cluster_labels_), the results is an array smaller than the number of cluster, which generate an error and turns impossible to set large and small clusters. This could be avoided by changing self.cluster_sizes_=np.bincount(clf.cluster_labels_) to self.cluster_sizes_=np.bincount(clf.cluster_labels_, minlength=n_clusters). This is an issue that is damaging my code flexibility and I want to know if it is worth getting fixed.
Example of code:
&lt;denchmark-code&gt;from pyod.utils.data import generate_data
x = [[ 0.30244003],  [0.01218177],[-0.50835109], [-0.36951435],[ 0.97274482], [-0.68325119], 
     [0.0], [0.0], [0.08], [0.0], [0.0], [ 0.0],[ 0.0], [ 0.0],[0.09], [0.0],[ 0.0], [0.0],
     [0.0], [ 0.0],[-20.29518778], [0.0],[ 0.0], [0.0],[ 0.0], [ 0.0],
     [0.0], [ 8.38548823], [0.0], [ 0.0]]
test = generate_data(train_only=True)
clf_name = 'CBLOF'
clf = CBLOF(alpha=0.1, n_clusters=15, beta=10, check_estimator=False)
try:
    clf.fit(x)
except Exception as ex:
    print(str(ex))
    print("\n Cluster centers: " + str(clf.cluster_centers_))
    print("\n Cluster sizes: " + str(clf.cluster_sizes_))
    print('\n Supposed to be the cluster size: ' + str(np.bincount(clf.cluster_labels_, minlength=15)))
    print("\n Large clusters: " + str(clf.large_cluster_labels_))
    print("\n Small clusters: " + str(clf.small_cluster_labels_))
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;index 11 is out of bounds for axis 0 with size 11

 Cluster centers: [[ 0.00000000e+00]
 [-2.02951878e+01]
 [ 8.38548823e+00]
 [ 9.72744820e-01]
 [-5.08351090e-01]
 [ 3.02440030e-01]
 [-6.83251190e-01]
 [-3.69514350e-01]
 [ 8.00000000e-02]
 [ 1.21817700e-02]
 [ 9.00000000e-02]
 [ 0.00000000e+00]
 [ 0.00000000e+00]
 [ 8.00000000e-02]
 [ 0.00000000e+00]]

 Cluster sizes: [20  1  1  1  1  1  1  1  1  1  1]

 Supposed to be the cluster size: [20  1  1  1  1  1  1  1  1  1  1  0  0  0  0]
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
&lt;ipython-input-39-1b14a2099b96&gt; in &lt;module&gt;()
     18 try:
---&gt; 19     clf.fit(x)
     20 except Exception as ex:

/usr/local/lib/python3.5/dist-packages/pyod/models/cblof.py in fit(self, X, y)
    168         self._set_cluster_centers(X, n_features)
--&gt; 169         self._set_small_large_clusters(n_samples)
    170 

/usr/local/lib/python3.5/dist-packages/pyod/models/cblof.py in _set_small_large_clusters(self, n_samples)
    251 
--&gt; 252             if size_clusters[sorted_cluster_indices[i]] / size_clusters[
    253                 sorted_cluster_indices[i - 1]] &gt;= self.beta:

IndexError: index 11 is out of bounds for axis 0 with size 11

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
&lt;ipython-input-39-1b14a2099b96&gt; in &lt;module&gt;()
     23     print("\n Cluster sizes: " + str(clf.cluster_sizes_))
     24     print('\n Supposed to be the cluster size: ' + str(np.bincount(clf.cluster_labels_, minlength=15)))
---&gt; 25     print("\n Large clusters: " + str(clf.large_cluster_labels_))
     26     print("\n Small clusters: " + str(clf.small_cluster_labels_))
     27 

AttributeError: 'CBLOF' object has no attribute 'large_cluster_labels_'

&lt;/denchmark-code&gt;

Thanks for your help,
Giovanna
	</description>
	<comments>
		<comment id='1' author='GiovannaR' date='2019-02-01T20:41:14Z'>
		Thanks for pointing this out. Will do some checks and let you know if a PR is needed:)
		</comment>
		<comment id='2' author='GiovannaR' date='2019-02-05T16:38:55Z'>
		&lt;denchmark-link:https://github.com/GiovannaR&gt;@GiovannaR&lt;/denchmark-link&gt;
 did some experiments and understood what is going on:)
The error happens when the underlying clustering algorithm could not form the exact number of clusters set by the user. In the case you mentioned, kmeans returns 11 clusters other than 15 clusters.
There are two ways to fix:

Use the actual number of clusters instead of the user-defined one, i.e., use 11 instead of 15 for the calculation. Throw warnings as well.
Raise errors directly to ask for a smaller number of cluster definition.

I feel enforcing np.bincount with minlength==n_clusters is unsafe as empty clusters may result in unpredictable results.
Any thoughts?
		</comment>
		<comment id='3' author='GiovannaR' date='2019-02-06T18:43:10Z'>
		I changed the MiniBatchKMeans for the KMeans and the problem ended. When I use MiniBatchKMeans, it finds sometimes repeated cluster centers even if the number of cluster is smaller than the number of unique values. Using KMeans, it only finds repeated cluster centers when the number of cluster is bigger than the number of unique values. I will investigate more the both algorithms.
When comes to the error, I suggest turn it into a warning about changing the number of clusters to use and use the number which is appropriate instead the input.  It is possible to change the for i in range(1, self.n_clusters) in def _set_small_large_clusters(self, n_samples) function to for i in range(1, len(size_clusters), but I don't know if it is the ideal.
Thanks for your help,
Giovanna
		</comment>
		<comment id='4' author='GiovannaR' date='2019-02-10T19:35:45Z'>
		
refactor default clustering algorithm from MiniBatchKMeans to KMeans.
add a check to calculate the actual number of clusters.
supports multiple-core running with n_jobs.

Thanks for reporting this &lt;denchmark-link:https://github.com/GiovannaR&gt;@GiovannaR&lt;/denchmark-link&gt;
 :)
		</comment>
	</comments>
</bug>