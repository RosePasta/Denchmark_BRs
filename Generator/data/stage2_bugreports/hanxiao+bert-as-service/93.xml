<bug id='93' author='nrty' open_date='2018-12-05T13:12:17Z' closed_time='2018-12-05T13:44:23Z'>
	<summary>REDUCE_MEAN is calculated without "input_mask"?</summary>
	<description>
Maybe only calculate the mean of non_padding characters is more reasonable?
i.e., only calculate the mean of the top 6 characters in the following example
tokens: [CLS] 我 还 可 以 [SEP]
input_ids: 101 2769 6820 1377 809 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
	</description>
	<comments>
		<comment id='1' author='nrty' date='2018-12-05T13:25:18Z'>
		geez, shame on me. thought i was doing that. thanks a lot
		</comment>
		<comment id='2' author='nrty' date='2018-12-05T13:46:49Z'>
		thanks again for pointing out this issue. I've fixed in &lt;denchmark-link:https://github.com/hanxiao/bert-as-service/pull/94&gt;#94&lt;/denchmark-link&gt;
 and now it's in master, specifically at here &lt;denchmark-link:https://github.com/hanxiao/bert-as-service/blob/master/bert/extract_features.py#L66&gt;https://github.com/hanxiao/bert-as-service/blob/master/bert/extract_features.py#L66&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='nrty' date='2018-12-06T09:59:47Z'>
		nice job~
		</comment>
	</comments>
</bug>