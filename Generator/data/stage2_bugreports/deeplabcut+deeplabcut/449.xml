<bug id='449' author='felixhol' open_date='2019-10-08T20:58:11Z' closed_time='2019-10-20T22:02:13Z'>
	<summary>issue when using analyze_time_lapse_frames with grayscale image</summary>
	<description>
Describe the bug
When running inference on a directory with gray scale png images using analyze time lapse, the code expects a color images regardles of rgb=False and returns:
ValueError: not enough values to unpack (expected 3, got 2)
To Reproduce
Steps to reproduce the behavior:
run:
deeplabcut.analyze_time_lapse_frames(config, imageDir, save_as_csv=True, rgb=False)
on a grayscale png
Expected behavior
Ideally this would work on gray scale images, yet there are several points downstream in the code that seem incompatible with gray scale images  (e.g. expect shape (x, y, 3))
Desktop (please complete the following information about your system):

OS: ubuntu 18.04, encountered same issue on macOS
DeepLabCut Version 2.0.9
Browser chrome on ubuntu, safari on macOS

Additional context
A quick and dirty work around is to add:
im=gray2rgb(im)
after:
im=io.imread(os.path.join(directory,framelist[0]))
and,
im=io.imread(os.path.join(directory,framename))
and,
im=io.imread(os.path.join(directory,framename))
to convert the gray scale image to rgb. With that everything runs smooth, though it's not the ideal long term solution.
	</description>
	<comments>
		<comment id='1' author='felixhol' date='2019-10-20T22:02:13Z'>
		Sorry for the delay. I finally looked into this, in the latest version (since 2.1 this works). Also notice that images need to be converted to RGB, because the pretrained nets will want to have 3 channel input. Thus, for grayscale we just copy the channels.
		</comment>
	</comments>
</bug>