<bug id='1077' author='donglabimaging' open_date='2021-01-12T06:34:07Z' closed_time='2021-01-14T19:11:48Z'>
	<summary>2 Errors running testscript.py</summary>
	<description>
Thanks for opening this issue, and thanks for using DeepLabCut (we hope you are enjoying it ;). Please fill out the template completely, including the full "traceback" and input code that you ran to hit this error.
Your Operating system and DeepLabCut version

OS: Windows 10
DeepLabCut Version 2.1.9
dlc-windowsCPU
DeepLabCut testscript.py


Hi, I updated DLC to 2.1.9 using &lt;pip install --upgrade deeplabcut&gt;, ran the testscript.py, and received two errors.  The first error shows up in the middle of training and the other one at the CREATE VIDEO part.  I have looked into &lt;denchmark-link:https://github.com/DeepLabCut/DeepLabCut/issues/992&gt;#992&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://github.com/DeepLabCut/DeepLabCut/issues/1050&gt;#1050&lt;/denchmark-link&gt;
, but they seem different.  Any suggestions would be greatly appreciated.  Many thanks!
Here are the errors:
CancelledError (see above for traceback): Enqueue operation was cancelled
[[Node: fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device="/job:localhost/replica:0/task:0/device:CPU:0"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]
CREATE VIDEO
Traceback (most recent call last):
File "testscript.py", line 107, in 
deeplabcut.create_labeled_video(path_config_file,[newvideo], destfolder=dfolder)
TypeError: create_labeled_video() got an unexpected keyword argument 'destfolder'
Code output
[Imported DLC!
CREATING PROJECT
Created "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\videos"
Created "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\labeled-data"
Created "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\training-datasets"
Created "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models"
Copying the videos
C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\videos\reachingvideo1.avi
Generated "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\config.yaml"
A new project with name TEST-Alex-2021-01-12 is created at C:\Users\allenli\DeepLabCut\examples and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.
Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.
. [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).
EXTRACTING FRAMES
C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\generate_training_dataset\frame_extraction.pyðŸ’¯ YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
cfg = yaml.load(ymlfile)
Config file read successfully.
Extracting frames based on kmeans ...
Kmeans-quantization based extracting of frames from 0.0  seconds to 8.53  seconds.
Extracting and downsampling... 256  frames from the video.
256it [00:01, 251.22it/s]
Kmeans clustering ... (this might take a while)
Frames were selected.
You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).
CREATING-SOME LABELS FOR THE FRAMES
Plot labels...
Creating images with labels by Alex.
They are stored in the following folder: C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\labeled-data\reachingvideo1_labeled.
If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!
CREATING TRAININGSET
C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\generate_training_dataset\trainingsetmanipulation.py:328: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
docs.append(yaml.load(raw_doc))
The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!
C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\utils\auxiliaryfunctions.py:101: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
yaml_cfg = yaml.load(f)
CHANGING training parameters to end quickly!
TRAIN
C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\config.py:43: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
yaml_cfg = edict(yaml.load(f))
Config:
{'all_joints': [[0], [1], [2], [3]],
'all_joints_names': ['Hand', 'Finger1', 'Finger2', 'Joystick'],
'batch_size': 1,
'bottomheight': 400,
'crop': True,
'crop_pad': 0,
'cropratio': 0.4,
'dataset': 'training-datasets\iteration-0\UnaugmentedDataSet_TESTJan12\TEST_Alex80shuffle1.mat',
'dataset_type': 'default',
'display_iters': 2,
'fg_fraction': 0.25,
'global_scale': 0.8,
'init_weights': 'C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\models\pretrained\resnet_v1_50.ckpt',
'intermediate_supervision': False,
'intermediate_supervision_layer': 12,
'leftwidth': 400,
'location_refinement': True,
'locref_huber_loss': True,
'locref_loss_weight': 0.05,
'locref_stdev': 7.2801,
'log_dir': 'log',
'max_input_size': 1500,
'mean_pixel': [123.68, 116.779, 103.939],
'metadataset': 'training-datasets\iteration-0\UnaugmentedDataSet_TESTJan12\Documentation_data-TEST_80shuffle1.pickle',
'min_input_size': 64,
'minsize': 100,
'mirror': False,
'multi_step': [[0.001, 10]],
'net_type': 'resnet_50',
'num_joints': 4,
'optimizer': 'sgd',
'pos_dist_thresh': 17,
'project_path': 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12',
'regularize': False,
'rightwidth': 400,
'save_iters': 10,
'scale_jitter_lo': 0.5,
'scale_jitter_up': 1.25,
'scoremap_dir': 'test',
'shuffle': True,
'snapshot_prefix': 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1\train\snapshot',
'stride': 8.0,
'topheight': 400,
'use_gt_segm': False,
'video': False,
'video_batch': False,
'weigh_negatives': False,
'weigh_only_present_joints': False,
'weigh_part_predictions': False,
'weight_decay': 0.0001}
INFO:tensorflow:Restoring parameters from C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\models\pretrained\resnet_v1_50.ckpt
Restoring parameters from C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\models\pretrained\resnet_v1_50.ckpt
Training parameter:
{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1\train\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'dataset_type': 'default', 'use_gt_segm': False, 'batch_size': 1, 'video': False, 'video_batch': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['Hand', 'Finger1', 'Finger2', 'Joystick'], 'dataset': 'training-datasets\iteration-0\UnaugmentedDataSet_TESTJan12\TEST_Alex80shuffle1.mat', 'display_iters': 2, 'init_weights': 'C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\models\pretrained\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\iteration-0\UnaugmentedDataSet_TESTJan12\Documentation_data-TEST_80shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.001, 10]], 'net_type': 'resnet_50', 'num_joints': 4, 'pos_dist_thresh': 17, 'project_path': 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12', 'save_iters': 10, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}
Starting training....
iteration: 2 loss: 1.2938 lr: 0.001
iteration: 4 loss: 0.6296 lr: 0.001
iteration: 6 loss: 0.4733 lr: 0.001
iteration: 8 loss: 0.3677 lr: 0.001
iteration: 10 loss: 0.2125 lr: 0.001
Exception in thread Thread-2:
Traceback (most recent call last):
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\client\session.py", line 1322, in _do_call
return fn(*args)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\client\session.py", line 1307, in _run_fn
options, feed_dict, fetch_list, target_list, run_metadata)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\client\session.py", line 1409, in _call_tf_sessionrun
run_metadata)
tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled
[[Node: fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device="/job:localhost/replica:0/task:0/device:CPU:0"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\threading.py", line 916, in _bootstrap_inner
self.run()
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\threading.py", line 864, in run
self._target(*self._args, **self._kwargs)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\train.py", line 53, in load_and_enqueue
sess.run(enqueue_op, feed_dict=food)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\client\session.py", line 900, in run
run_metadata_ptr)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\client\session.py", line 1135, in _run
feed_dict_tensor, options, run_metadata)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\client\session.py", line 1316, in _do_run
run_metadata)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\client\session.py", line 1335, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled
[[Node: fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device="/job:localhost/replica:0/task:0/device:CPU:0"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]
Caused by op 'fifo_queue_enqueue', defined at:
File "testscript.py", line 81, in 
deeplabcut.train_network(path_config_file)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\training.py", line 79, in train_network
train(str(poseconfigfile),displayiters,saveiters,maxiters,max_to_keep=max_snapshots_to_keep) #pass on path and file name for pose_cfg.yaml!
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\train.py", line 88, in train
batch, enqueue_op, placeholders = setup_preloading(batch_spec)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\train.py", line 39, in setup_preloading
enqueue_op = q.enqueue(placeholders_list)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\ops\data_flow_ops.py", line 346, in enqueue
self._queue_ref, vals, name=scope)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\ops\gen_data_flow_ops.py", line 4373, in queue_enqueue_v2
timeout_ms=timeout_ms, name=name)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 787, in _apply_op_helper
op_def=op_def)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\framework\ops.py", line 3392, in create_op
op_def=op_def)
File "C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\tensorflow\python\framework\ops.py", line 1718, in init
self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
CancelledError (see above for traceback): Enqueue operation was cancelled
[[Node: fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device="/job:localhost/replica:0/task:0/device:CPU:0"](fifo_queue, _arg_Placeholder_0_0, _arg_Placeholder_1_0_1, _arg_Placeholder_2_0_2, _arg_Placeholder_3_0_3, _arg_Placeholder_4_0_4)]]
The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.
EVALUATE
Config:
{'all_joints': [[0], [1], [2], [3]],
'all_joints_names': ['Hand', 'Finger1', 'Finger2', 'Joystick'],
'batch_size': 1,
'bottomheight': 400,
'crop': True,
'crop_pad': 0,
'cropratio': 0.4,
'dataset': 'training-datasets\iteration-0\UnaugmentedDataSet_TESTJan12\TEST_Alex80shuffle1.mat',
'dataset_type': 'default',
'display_iters': 2,
'fg_fraction': 0.25,
'global_scale': 0.8,
'init_weights': 'C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\models\pretrained\resnet_v1_50.ckpt',
'intermediate_supervision': False,
'intermediate_supervision_layer': 12,
'leftwidth': 400,
'location_refinement': True,
'locref_huber_loss': True,
'locref_loss_weight': 0.05,
'locref_stdev': 7.2801,
'log_dir': 'log',
'max_input_size': 1500,
'mean_pixel': [123.68, 116.779, 103.939],
'metadataset': 'training-datasets\iteration-0\UnaugmentedDataSet_TESTJan12\Documentation_data-TEST_80shuffle1.pickle',
'min_input_size': 64,
'minsize': 100,
'mirror': False,
'multi_step': [[0.001, 10]],
'net_type': 'resnet_50',
'num_joints': 4,
'optimizer': 'sgd',
'pos_dist_thresh': 17,
'project_path': 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12',
'regularize': False,
'rightwidth': 400,
'save_iters': 10,
'scale_jitter_lo': 0.5,
'scale_jitter_up': 1.25,
'scoremap_dir': 'test',
'shuffle': True,
'snapshot_prefix': 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1\test\snapshot',
'stride': 8.0,
'topheight': 400,
'use_gt_segm': False,
'video': False,
'video_batch': False,
'weigh_negatives': False,
'weigh_only_present_joints': False,
'weigh_part_predictions': False,
'weight_decay': 0.0001}
Running  DeepCut_resnet50_TESTJan12shuffle1_10  with # of trainingiterations: 10
INFO:tensorflow:Restoring parameters from C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1\train\snapshot-10
Restoring parameters from C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1\train\snapshot-10
Analyzing data...
5it [00:13,  2.72s/it]
Done and results stored for snapshot:  snapshot-10
Results for 10  training iterations: 80 1 train error: 472.51 pixels. Test error: 388.32  pixels.
With pcutoff of 0.01  train error: 472.51 pixels. Test error: 388.32 pixels
Thereby, the errors are given by the average distances between the labels by DLC and the scorer.
Plotting...
The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.
If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.
Use the function 'analyze_video' to make predictions on new videos.
Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)
CUT SHORT VIDEO AND ANALYZE
ffmpeg version N-94129-g098ab93257 Copyright (c) 2000-2019 the FFmpeg developers
built with gcc 9.1.1 (GCC) 20190621
configuration: --enable-gpl --enable-version3 --enable-sdl2 --enable-fontconfig --enable-gnutls --enable-iconv --enable-libass --enable-libdav1d --enable-libbluray --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopus --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libtheora --enable-libtwolame --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libzimg --enable-lzma --enable-zlib --enable-gmp --enable-libvidstab --enable-libvorbis --enable-libvo-amrwbenc --enable-libmysofa --enable-libspeex --enable-libxvid --enable-libaom --enable-libmfx --enable-amf --enable-ffnvcodec --enable-cuvid --enable-d3d11va --enable-nvenc --enable-nvdec --enable-dxva2 --enable-avisynth --enable-libopenmpt
libavutil      56. 29.100 / 56. 29.100
libavcodec     58. 53.100 / 58. 53.100
libavformat    58. 28.101 / 58. 28.101
libavdevice    58.  7.100 / 58.  7.100
libavfilter     7. 55.100 /  7. 55.100
libswscale      5.  4.101 /  5.  4.101
libswresample   3.  4.100 /  3.  4.100
libpostproc    55.  4.100 / 55.  4.100
Input #0, avi, from 'C:\Users\allenli\DeepLabCut\examples\Reaching-Mackenzie-2018-08-30\videos\reachingvideo1.avi':
Duration: 00:00:08.53, start: 0.000000, bitrate: 12642 kb/s
Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 832x747 [SAR 1:1 DAR 832:747], 12682 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc
Metadata:
title           : ImageJ AVI
Output #0, mp4, to 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\videos\brief.mp4':
Metadata:
encoder         : Lavf58.28.101
Stream #0:0: Video: mjpeg (Baseline) (mp4v / 0x7634706D), yuvj420p(pc, bt470bg/unknown/unknown), 832x747 [SAR 1:1 DAR 832:747], q=2-31, 12682 kb/s, 30 fps, 30 tbr, 15360 tbn, 30 tbc
Metadata:
title           : ImageJ AVI
Stream mapping:
Stream #0:0 -&gt; #0:0 (copy)
Press [q] to stop, [?] for help
frame=   12 fps=0.0 q=-1.0 Lsize=     635kB time=00:00:00.36 bitrate=14176.5kbits/s speed=69.2x
video:634kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.136212%
Config:
{'all_joints': [[0], [1], [2], [3]],
'all_joints_names': ['Hand', 'Finger1', 'Finger2', 'Joystick'],
'batch_size': 1,
'bottomheight': 400,
'crop': True,
'crop_pad': 0,
'cropratio': 0.4,
'dataset': 'training-datasets\iteration-0\UnaugmentedDataSet_TESTJan12\TEST_Alex80shuffle1.mat',
'dataset_type': 'default',
'display_iters': 2,
'fg_fraction': 0.25,
'global_scale': 0.8,
'init_weights': 'C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\pose_estimation_tensorflow\models\pretrained\resnet_v1_50.ckpt',
'intermediate_supervision': False,
'intermediate_supervision_layer': 12,
'leftwidth': 400,
'location_refinement': True,
'locref_huber_loss': True,
'locref_loss_weight': 0.05,
'locref_stdev': 7.2801,
'log_dir': 'log',
'max_input_size': 1500,
'mean_pixel': [123.68, 116.779, 103.939],
'metadataset': 'training-datasets\iteration-0\UnaugmentedDataSet_TESTJan12\Documentation_data-TEST_80shuffle1.pickle',
'min_input_size': 64,
'minsize': 100,
'mirror': False,
'multi_step': [[0.001, 10]],
'net_type': 'resnet_50',
'num_joints': 4,
'optimizer': 'sgd',
'pos_dist_thresh': 17,
'project_path': 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12',
'regularize': False,
'rightwidth': 400,
'save_iters': 10,
'scale_jitter_lo': 0.5,
'scale_jitter_up': 1.25,
'scoremap_dir': 'test',
'shuffle': True,
'snapshot_prefix': 'C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1\test\snapshot',
'stride': 8.0,
'topheight': 400,
'use_gt_segm': False,
'video': False,
'video_batch': False,
'weigh_negatives': False,
'weigh_only_present_joints': False,
'weigh_part_predictions': False,
'weight_decay': 0.0001}
Using snapshot-10 for model C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1
INFO:tensorflow:Restoring parameters from C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1\train\snapshot-10
Restoring parameters from C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\dlc-models\iteration-0\TESTJan12-trainset80shuffle1\train\snapshot-10
Starting to analyze %  C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\videos\brief.mp4
Loading  C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\videos\brief.mp4
Duration of video [s]:  0.4 , recorded with  30.0 fps!
Overall # of frames:  12  found with (before cropping) frame dimensions:  832 747
Starting to extract posture
20it [00:20,  1.05s/it]                                                                                                                                                  Detected frames:  12
Saving results in C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-12\videos...
Saving csv poses!
The videos are analyzed. Now your research can truly start!
You can create labeled videos with 'create_labeled_video'.
If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!
CREATE VIDEO
Traceback (most recent call last):
File "testscript.py", line 107, in 
deeplabcut.create_labeled_video(path_config_file,[newvideo], destfolder=dfolder)
TypeError: create_labeled_video() got an unexpected keyword argument 'destfolder']

How to Reproduce the problem
Steps to reproduce the behavior:

Go to env 'activate dlc-windowsCPU'
run 'python testscript.py'
See error

	</description>
	<comments>
		<comment id='1' author='donglabimaging' date='2021-01-13T09:20:46Z'>
		Your testscript.py is likely outdated. The first occurrence of deeplabcut.create_labeled_video is normally at line 184 


DeepLabCut/examples/testscript.py


        Lines 183 to 186
      in
      8745531






 print("CREATE VIDEO") 



 deeplabcut.create_labeled_video( 



 path_config_file, [newvideo], destfolder=dfolder, save_frames=True 



 ) 




. Just update your local testscript file or clone our master branch and you should be fine ðŸ˜Š
		</comment>
		<comment id='2' author='donglabimaging' date='2021-01-14T18:19:05Z'>
		&lt;denchmark-link:https://github.com/jeylau&gt;@jeylau&lt;/denchmark-link&gt;

Thank you for the reply.  I will try it out!
		</comment>
		<comment id='3' author='donglabimaging' date='2021-01-14T18:46:27Z'>
		&lt;denchmark-link:https://github.com/jeylau&gt;@jeylau&lt;/denchmark-link&gt;

I updated the testscript.py and ran the script.  It goes straight to an error before training.  Below is the output.
Code output
[(dlc-windowsCPU) C:\Users\allenli\DeepLabCut\examples&gt;python testscript.py
Imported DLC!
On Windows/OSX tensorpack is not tested by default.
CREATING PROJECT
Created "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-14\videos"
Created "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-14\labeled-data"
Created "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-14\training-datasets"
Created "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-14\dlc-models"
Copying the videos
C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-14\videos\reachingvideo1.avi
Generated "C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-14\config.yaml"
A new project with name TEST-Alex-2021-01-14 is created at C:\Users\allenli\DeepLabCut\examples and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.
Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.
. [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).
EXTRACTING FRAMES
C:\Users\allenli\anaconda3\envs\dlc-windowsCPU\lib\site-packages\deeplabcut\generate_training_dataset\frame_extraction.pyðŸ’¯ YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
cfg = yaml.load(ymlfile)
Config file read successfully.
Extracting frames based on kmeans ...
Kmeans-quantization based extracting of frames from 0.0  seconds to 8.53  seconds.
Extracting and downsampling... 256  frames from the video.
256it [00:01, 253.14it/s]
Kmeans clustering ... (this might take a while)
Frames were selected.
You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).
CREATING-SOME LABELS FOR THE FRAMES
Plot labels...
Creating images with labels by Alex.
They are stored in the following folder: C:\Users\allenli\DeepLabCut\examples\TEST-Alex-2021-01-14\labeled-data\reachingvideo1_labeled.
If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!
CREATING TRAININGSET
Traceback (most recent call last):
File "testscript.py", line 116, in 
path_config_file, net_type=net_type, augmenter_type=augmenter_type
TypeError: create_training_dataset() got an unexpected keyword argument 'net_type']
		</comment>
		<comment id='4' author='donglabimaging' date='2021-01-14T19:11:48Z'>
		&lt;denchmark-link:https://github.com/jeylau&gt;@jeylau&lt;/denchmark-link&gt;

I realized that I updated deeplabcut under the GPU environment, but tested the testscript.py in the CPU environment.  Hence, the error in the last comment popped up.
I upgraded deeplabcut with &lt;pip install --upgrade deeplabcut&gt; in the CPU environment and it passed the testscript!
"ALL DONE!!! - default cases are functional."
Thank you for your help!
		</comment>
	</comments>
</bug>