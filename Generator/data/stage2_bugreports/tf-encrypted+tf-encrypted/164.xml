<bug id='164' author='yanndupis' open_date='2018-09-21T17:49:24Z' closed_time='2018-10-17T19:25:25Z'>
	<summary>Debug models from SecureNN paper</summary>
	<description>
We want to validate the private prediction accuracy from the model trained in the folder &lt;denchmark-link:https://github.com/mortendahl/tf-encrypted/tree/master/examples/securenn&gt;/examples/securenn&lt;/denchmark-link&gt;
.
	</description>
	<comments>
		<comment id='1' author='yanndupis' date='2018-09-22T00:17:55Z'>
		&lt;denchmark-link:https://github.com/mortendahl&gt;@mortendahl&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jvmancuso&gt;@jvmancuso&lt;/denchmark-link&gt;
 here is a quick status:
I have trained the different models with tensorflow then exported them as protobuf file and finally made private predictions with tfe on a sample size of 100 images. I have trained these models in plaintext completely separately from the tfe predictions (e.g. &lt;denchmark-link:https://github.com/mortendahl/tf-encrypted/blob/master/examples/securenn/network_a.py&gt;network_a.py&lt;/denchmark-link&gt;
) to check if we had an issue or not with our plaintext training (Tensorlfow). Here are the preliminary results:
Network a: Tensorflow and tfe predictions agree at 97%
Network b: Tensorflow and tfe predictions agree at 75%
Network c: Tensorflow and tfe predictions agree at 70% (can go down sometimes to 44% when re-trained)
Network d": I think I have an issue with my implementation, the model was returning a matrix of shape [3,10].
Based on these observations, I think we have two issues:

We have an issue in our plaintext training in the code located in the folder /examples/securenn or maybe when we transfer the weight to make private prediction. For example, when we execute the code network_a.py, the accuracy is around 10/20% however with the approach above I get 97%.
We have an issue with the relu approximation. The accuracy decreases when the complexity of the model increases. Currently in tfe, we have approximated relu on the interval [-9,9]. The errors compound when we are outside this range or in the middle.

Here are the output distributions for each layer before relu for the . These distributions are based on the model trained in plaintext:
&lt;denchmark-link:https://user-images.githubusercontent.com/8001016/45910877-adfa4d00-bdc1-11e8-9d5d-e4e094254b59.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/8001016/45910881-b9e60f00-bdc1-11e8-9d86-f0b5c98f7720.png&gt;&lt;/denchmark-link&gt;

As we can see, some of the layer outputs before Relu are outside the expected range.
		</comment>
		<comment id='2' author='yanndupis' date='2018-09-22T00:22:16Z'>
		&lt;denchmark-link:https://github.com/yanndupis&gt;@yanndupis&lt;/denchmark-link&gt;
 this is excellent! can you push your training code somewhere, perhaps in &lt;denchmark-link:https://github.com/dropoutlabs/hacks&gt;this repo&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='3' author='yanndupis' date='2018-09-22T00:34:19Z'>
		Thank you &lt;denchmark-link:https://github.com/jvmancuso&gt;@jvmancuso&lt;/denchmark-link&gt;
 ! I will have to clean up the code a bit before pushing it. I have added a branch called securenn_models in tfe for now.
		</comment>
		<comment id='4' author='yanndupis' date='2018-09-22T10:11:50Z'>
		This is amazing Yann, brilliant! Away this weekend but very much looking
forward to digging deeper on Monday ðŸ™Œ

&lt;denchmark-link:#&gt;â€¦&lt;/denchmark-link&gt;


On Sat 22 Sep 2018 at 02:34, Yann Dupis ***@***.***&gt; wrote:
 Thank you @jvmancuso &lt;https://github.com/jvmancuso&gt; ! I will have to
 clean up the code a bit before pushing it. I have added a branch called
 securenn_models for now.

 â€”
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#164 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AFpZSecauL7rfYML2swVno2GmLDPXEtNks5udYWMgaJpZM4W0muv&gt;
 .



		</comment>
		<comment id='5' author='yanndupis' date='2018-09-22T15:51:49Z'>
		Thank you &lt;denchmark-link:https://github.com/mortendahl&gt;@mortendahl&lt;/denchmark-link&gt;
! Looking forward to Monday as well.
		</comment>
		<comment id='6' author='yanndupis' date='2018-09-25T06:00:14Z'>
		quick update:
I am trying to train the models with batchnorm before relu to see if it will improve the accuracy. I am experiencing some challenges to export the model from tf to a .pb file then import it into tf-encrypted.
I trained couple weeks ago the network b with Pytorch. This model was transferred to tensorflow then exported to a .pb. It has batchnom before each relu. When comparing the output from tfe and tf, they agreed at 25%. vs 75% without batchnorm :(. I have found the problem. It's because relu is approximated on the interval [-9,9] so we loose precision in the middle. This has a bigger impact with batchnorm because the values are centered around 0.
When I re-approximate relu on the interval [-3,3], for the network b with batchnorm, tfe and tf agree at 94%.
		</comment>
		<comment id='7' author='yanndupis' date='2018-09-26T03:02:36Z'>
		I think I was finally able to train the models with batchnorm in Tensorflow then export them in .pb file make predictions with tfe. Here are the preliminary results on the same images (sample size:100).
Network a:

Relu Approximated [-3,3]: Tensorflow and tfe predictions agree at 100%
Relu Approximated [-9,9]: Tensorflow and tfe predictions agree at 97%

Network b:

Relu Approximated [-3,3]: Tensorflow and tfe predictions agree at 100%
Relu Approximated [-9,9]: Tensorflow and tfe predictions agree at 90%

Network c:

Relu Approximated [-3,3]: Tensorflow and tfe predictions agree at 100%
Relu Approximated [-9,9]: Tensorflow and tfe predictions agree at 88%

So adding batchnorm before each relu seems to help, especially with relu is approximated on a smaller interval ( .e.g. [-3,3]). However, I am not sure that these results are always consistent depending how the model converged. I will have to re-train the model several time to validate.
Thanks
		</comment>
		<comment id='8' author='yanndupis' date='2018-10-01T06:13:49Z'>
		I have compared the predictions with tf vs tfe on the full MNIST test dataset (10,000 images). With the Relu approximated on the intervall [-3,3] and batchnorm, here are the results:
Network a:

Relu Approximated [-3,3]: Tensorflow and tfe predictions agree at 98.5%

Network b:

Relu Approximated [-3,3]: Tensorflow and tfe predictions agree at 98.5%

Network c:

Relu Approximated [-3,3]: Tensorflow and tfe predictions agree at 99.5%

		</comment>
		<comment id='9' author='yanndupis' date='2018-10-01T12:41:14Z'>
		Beautiful!
		</comment>
		<comment id='10' author='yanndupis' date='2018-10-16T20:20:01Z'>
		Quick update on this. By merging the pr &lt;denchmark-link:https://github.com/tf-encrypted/tf-encrypted/pull/234&gt;#234&lt;/denchmark-link&gt;
, it should solve most of our problems. In this example we should use Securenn protocol so we have the exact relu and won't have to add batchnorm before each relu. We also had some issues with plaintext training. All the drastic simplification Morgan introduced should solve most of our issues. Thank you.
		</comment>
	</comments>
</bug>