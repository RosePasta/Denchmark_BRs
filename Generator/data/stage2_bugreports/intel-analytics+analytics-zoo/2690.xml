<bug id='2690' author='hkvision' open_date='2020-08-07T10:20:08Z' closed_time='2020-09-16T01:15:37Z'>
	<summary>Should not let users export PYTHONHOME for PyTorch example local mode</summary>
	<description>
I run pytorch/train/mnist/main.py on Spark local and get the following error after the training:
&lt;denchmark-code&gt;java.lang.IllegalArgumentException: requirement failed
	at scala.Predef$.require(Predef.scala:212)
	at com.intel.analytics.zoo.feature.PythonFeatureSet$.toArrayTensor(FeatureSet.scala:390)
	at com.intel.analytics.zoo.pipeline.api.net.TorchModel.getExtraParameter(TorchModel.scala:188)
	at com.intel.analytics.zoo.pipeline.api.keras.models.InternalOptimizerUtil$$anonfun$8.apply(Topology.scala:1041)
	at com.intel.analytics.zoo.pipeline.api.keras.models.InternalOptimizerUtil$$anonfun$8.apply(Topology.scala:1041)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:394)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)
	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
&lt;/denchmark-code&gt;

Also:

Is the following warning expected? Look quite like an error stack actually:

&lt;denchmark-code&gt;Warn: jep.JepException: &lt;class 'NameError'&gt;: name 'loader3b553ae7_0_iter_true' is not defined
	at &lt;string&gt;.&lt;module&gt;(&lt;string&gt;:2)
	at jep.Jep.exec(Native Method)
	at jep.Jep.exec(Jep.java:478)
	at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:94)
	at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)
	at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Warn: jep.JepException: &lt;class 'StopIteration'&gt;
	at jep.Jep.exec(Native Method)
	at jep.Jep.exec(Jep.java:478)
	at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:94)
	at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)
	at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
&lt;/denchmark-code&gt;


Seems if JEP is not installed, the program would crash? Can we instead raise some error on Python side directly?

	</description>
	<comments>
		<comment id='1' author='hkvision' date='2020-08-07T11:11:22Z'>
		Yes, we need to improve the error checking and error message
		</comment>
		<comment id='2' author='hkvision' date='2020-08-10T02:30:31Z'>
		The error is thrown after training&amp;validation finished, when optimizer try to get extraparameters.
This bug is fixing in &lt;denchmark-link:https://github.com/intel-analytics/analytics-zoo/pull/2630&gt;#2630&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='hkvision' date='2020-08-10T02:32:21Z'>
		Six issues in total:

java.lang.IllegalArgumentException: requirement failed showed above.
In the README: https://github.com/intel-analytics/analytics-zoo/tree/master/pyzoo/zoo/examples/pytorch/train/mnist

&lt;denchmark-code&gt;conda install pytorch-cpu torchvision-cpu -c pytorch #command for linux
&lt;/denchmark-code&gt;

This will install pytorch 1.1.0 but not 1.5.0 as guided in the readme.

In README, hdfs dfs -put /tmp/zoo/dogs_cats dogs_cats  This sentence is wrong.
Not installing JEP would cause the program to crash. Better detect first on Python side.
[Low priority] For local mode, users need to manually set PYTHONHOME. Actually this can be detected in code instead of setting by users.
[Low priority] The warning stack of JEP may not be friendly to users, seems like to be an error stack.

		</comment>
		<comment id='4' author='hkvision' date='2020-08-31T07:38:37Z'>
		Better fix the issue of letting users export PYTHONHOME for running PyTorch example in local mode. This environment variable would affect other programs, for example conda-pack and conda install.
If I first run on local mode and export PYTHONHOME, then I want to run for yarn-client mode without starting a new session or cleaning the environment variables, it would throw the following error:
&lt;denchmark-code&gt;Start to pack current python env
Collecting packages...
CondaPackError: Failed to determine path to environment: 'orca-kai'. This may be due to conda not being on your PATH. The full error is below:

b''
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='hkvision' date='2020-09-16T01:15:37Z'>
		Fixed in &lt;denchmark-link:https://github.com/intel-analytics/analytics-zoo/pull/2869&gt;#2869&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>