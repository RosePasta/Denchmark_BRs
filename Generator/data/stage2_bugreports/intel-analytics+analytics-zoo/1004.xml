<bug id='1004' author='hhbyyh' open_date='2018-12-21T13:05:20Z' closed_time='2019-04-16T02:49:55Z'>
	<summary>[Issue] Keras model save/load error</summary>
	<description>
I found an issue with Keras model save/load. Iâ€™m using the master branch of Zoo. I need to save a transfer learning model for the customer use case.
If the model saving and loading happen in one python program, everything works fine. But when I try to load a model that was saved in another python program, I met error.
Code to repro (run it first with the save part, then run another time with just loading)
&lt;denchmark-code&gt;from bigdl.nn.criterion import *
from bigdl.optim.optimizer import *
from bigdl.nn.layer import Model as BigDLModel
from zoo.common.nncontext import *
from zoo.feature.image.imagePreprocessing import *
from zoo.pipeline.api.keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D
from zoo.pipeline.api.keras.models import Model as KModel
from zoo.pipeline.api.net import Net

sparkConf = create_spark_conf().setAppName("test_dell_x_ray")
sc = init_nncontext(sparkConf)

# full_model = Net.load_bigdl("/home/yuhao/workspace/model/analytics-zoo_resnet-50_imagenet_0.1.0.model")
# model = full_model.new_graph(["pool5"])
# print(('num of model layers: ', len(model.layers)))
# inputNode = Input(name="input", shape=(3, 224, 224))
# inception = model.to_keras()(inputNode)
# flatten = GlobalAveragePooling2D(dim_ordering='th')(inception)
# logits = Dense(14, activation="sigmoid")(flatten)
# finalModel = KModel(inputNode, logits)
# finalModel.saveModel("./kerasModel/m.bigdl", "./kerasModel/m.bin", True)

loaded = BigDLModel.loadModel("./kerasModel/m.bigdl", "./kerasModel/m.bin")
print("reload succeed")
&lt;/denchmark-code&gt;

Exception message:
&lt;denchmark-code&gt;Caused by: java.lang.IllegalArgumentException: requirement failed: _inputs value cannot be found
              at scala.Predef$.require(Predef.scala:224)
              at com.intel.analytics.bigdl.utils.serializer.ModuleSerializable$$anonfun$doLoadModule$1$$anonfun$apply$1.apply(ModuleSerializable.scala:137)
              at com.intel.analytics.bigdl.utils.serializer.ModuleSerializable$$anonfun$doLoadModule$1$$anonfun$apply$1.apply(ModuleSerializable.scala:125)
              at scala.collection.immutable.List.foreach(List.scala:381)
              at com.intel.analytics.bigdl.utils.serializer.ModuleSerializable$$anonfun$doLoadModule$1.apply(ModuleSerializable.scala:125)
              at com.intel.analytics.bigdl.utils.serializer.ModuleSerializable$$anonfun$doLoadModule$1.apply(ModuleSerializable.scala:124)
              at scala.collection.immutable.List.foreach(List.scala:381)
              at com.intel.analytics.bigdl.utils.serializer.ModuleSerializable$class.doLoadModule(ModuleSerializable.scala:124)
              at com.intel.analytics.bigdl.utils.serializer.ContainerSerializer$.com$intel$analytics$bigdl$utils$serializer$ContainerSerializable$$super$doLoadModule(ModuleSerializable.scala:421)
              at com.intel.analytics.bigdl.utils.serializer.ContainerSerializable$class.doLoadModule(ModuleSerializable.scala:394)
              at com.intel.analytics.bigdl.utils.serializer.ContainerSerializer$.doLoadModule(ModuleSerializable.scala:421)
              at com.intel.analytics.bigdl.utils.serializer.ModuleSerializable$class.loadModule(ModuleSerializable.scala:95)
              at com.intel.analytics.bigdl.utils.serializer.ContainerSerializer$.loadModule(ModuleSerializable.scala:421)
              at com.intel.analytics.bigdl.utils.serializer.ModuleSerializer$.load(ModuleSerializer.scala:149)
              ... 14 more
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='hhbyyh' date='2018-12-21T13:52:06Z'>
		In theory protobuf format is neutral to process, so my wild guess is the  wasn't correctly serialized to binary. &lt;denchmark-link:https://github.com/hkvision&gt;@hkvision&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='hhbyyh' date='2018-12-23T02:41:09Z'>
		call Net.load()?
		</comment>
		<comment id='3' author='hhbyyh' date='2019-04-12T20:35:42Z'>
		I met the same exception with scala code. And the code is quite simple:
val x = Variable[Float](Shape(1, 10)) val y = Variable[Float](Shape(1, 10)) val z = x + y val model = Model[Float](input = Array(x, y), output = z) val absPath = "/tmp/para.model" model.saveModule(absPath, overWrite = true)
and load code is:
   val absPath2 = "/tmp/para.model" val model2 = Module.loadModule[Float](absPath2)
		</comment>
		<comment id='4' author='hhbyyh' date='2019-04-15T06:24:28Z'>
		&lt;denchmark-link:https://github.com/hhbyyh&gt;@hhbyyh&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/dding3&gt;@dding3&lt;/denchmark-link&gt;
  Please use   and try again for your case as the model you constructed is based on the API from Analytics-ZOO.
		</comment>
		<comment id='5' author='hhbyyh' date='2019-04-15T17:50:01Z'>
		Thanks for your suggestions. It works for me now :)
		</comment>
		<comment id='6' author='hhbyyh' date='2019-04-16T02:49:55Z'>
		Closing this for now as it has been solved. Please reopen it if still facing the problem.
		</comment>
	</comments>
</bug>