<bug id='255' author='keijimaeda82' open_date='2016-08-02T11:09:05Z' closed_time='2017-04-14T06:51:34Z'>
	<summary>Segmentation fault when changing the minibatch size</summary>
	<description>
for my NN model, i load the weights of 2 previously trained NN models, pass two inputs through to get the features, append the 2 vectors to get 1 feature vector (for a total of 10000 feature vectors). However, when I try to change the minibatch size from 30 to any other number, I will get segmentation fault. Additionally, when i reduce the number of feature vectors for training, I will need a different minibatch size as 30 will also give segmentation fault.
Thanks for the help
	</description>
	<comments>
		<comment id='1' author='keijimaeda82' date='2016-08-02T13:24:16Z'>
		set the minibatch size = 1? try ?
		</comment>
		<comment id='2' author='keijimaeda82' date='2016-08-02T13:37:45Z'>
		it seems that for lower minibatch size it works but for higher values it will not work. Can you tell me what can be the cause of this issue? (size 1, 10, 15 works fine but 20 and above doesn't)
		</comment>
		<comment id='3' author='keijimaeda82' date='2016-08-02T19:59:43Z'>
		&lt;denchmark-link:https://github.com/keijimaeda82&gt;@keijimaeda82&lt;/denchmark-link&gt;
 Could you run with gdb or similar in Debug mode and backtrace the seg fault?
		</comment>
		<comment id='4' author='keijimaeda82' date='2016-08-03T07:15:28Z'>
		Program received signal SIGSEGV, Segmentation fault. 0x0000000000458e58 in std::vector&lt;std::vector&lt;double, tiny_cnn::aligned_allocator&lt;double, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;double, tiny_cnn::aligned_allocator&lt;double, 64ul&gt; &gt; &gt; &gt; tiny_cnn::gradient&lt;tiny_cnn::mse&gt;(std::vector&lt;std::vector&lt;double, tiny_cnn::aligned_allocator&lt;double, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;double, tiny_cnn::aligned_allocator&lt;double, 64ul&gt; &gt; &gt; &gt; const&amp;, std::vector&lt;std::vector&lt;double, tiny_cnn::aligned_allocator&lt;double, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;double, tiny_cnn::aligned_allocator&lt;double, 64ul&gt; &gt; &gt; &gt; const&amp;) () 
that's the error I got with gdb
		</comment>
		<comment id='5' author='keijimaeda82' date='2016-08-03T08:33:49Z'>
		As you can see minibatch feature is quite new and a bit experimental. For your log it seems to be related to an allocation memory error.
Could you describe a bit more your network architecture? Besides, how many RAM do you have? Was it working in a previous version?
/cc &lt;denchmark-link:https://github.com/nyanp&gt;@nyanp&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='keijimaeda82' date='2016-08-03T09:41:56Z'>
		I run the network on my Ubuntu VM with 4gb of ram. I was working with the standard MNIST for minibatch of size 30 to 50, I have not tested further.
About the network, I have previously trained 2 networks (NN1 and NN2) and stored the weights in NN1 and NN2 weight files. The fusion network loads the weights, pass the input through the NN1 and NN2 separately to get 2 sets of features (size 50x1 each). Afterwards, I append the 2 feature vectors into 1 vector and add it to the train vector for the fusion network. This is repeated 10000 times (1000 x 10 digits). Then i feed the training vector into the network and start training for classification. Most of the structure is similar to the mnist example, with slight modification (layer sizes, depth, activator)
		</comment>
		<comment id='7' author='keijimaeda82' date='2016-08-04T14:39:31Z'>
		&lt;denchmark-link:https://github.com/keijimaeda82&gt;@keijimaeda82&lt;/denchmark-link&gt;
  Thanks for your detailed report :) but it's a bit difficult to estimate what's happened... could you show me your code?
		</comment>
		<comment id='8' author='keijimaeda82' date='2017-03-07T09:21:02Z'>
		&lt;denchmark-link:https://github.com/keijimaeda82&gt;@keijimaeda82&lt;/denchmark-link&gt;
  Can you try the latest version and check if the bug is still present?
		</comment>
	</comments>
</bug>