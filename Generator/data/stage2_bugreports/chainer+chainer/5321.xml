<bug id='5321' author='ryotayamazaki' open_date='2018-09-11T05:02:54Z' closed_time='2018-09-17T14:06:15Z'>
	<summary>Links to_gpu return None</summary>
	<description>
I'm trying to construct an LSTM network with multi GPUs using Chainer (v4.0.0b1). As in the following code.
&lt;denchmark-code&gt;import numpy as np
import chainer
from chainer import optimizers, Chain, training, iterators, serializers, cuda, Variable
import chainer.functions as F
import chainer.links as L

...

class Network(Chain):
    def __init__(self):
        super(Network, self).__init__()
        with self.init_scope():
            ...
            self.fc1  = L.Liner(3000, 1000).to_gpu(1)
            self.lstm = L.LSTM(1000, 1000).to_gpu(1)
            self.fc2  = L.Liner(1000, 3000).to_gpu(1)
            ...

    def __call__(self, x, t):
        ...

...
&lt;/denchmark-code&gt;

However, the LSTM link becomes "NoneType". As in the following error in call.

TypeError: 'NoneType' object is not callble

I thought it was strange so I displayed 'self.lstm'. As a result, "None" was displayed. For example, fc1 which is "Link" is displayed as follows.

&lt;chainer.links.connection.linear.Linear object at hogehoge&gt;

I found out that 'self.lstm' could not be declared as Link in 'self.lstm = L.LSTM(1000, 1000).to_gpu(1)'. However, I don't know why I can't declare it.
I use &lt;denchmark-link:https://ngc.nvidia.com/registry/partners-chainer&gt;Chainer's Docker&lt;/denchmark-link&gt;
 as the execution environment.

Chainer 4.0.0b1
CuPy 4.0.0b1
Ubuntu 16.04.3 LTS
Cuda 9.0.176
cudnn 7.0.5

	</description>
	<comments>
		<comment id='1' author='ryotayamazaki' date='2018-09-11T05:47:09Z'>
		I reproduced this with Chainer v5.0.0b4.
		</comment>
		<comment id='2' author='ryotayamazaki' date='2018-09-12T05:21:31Z'>
		Is it the expected behavior?
If the returned instance is recognized differently from the input-argument instance by Chainer, the API is reasonable I think. For example, in pytorch,  the returned value of Variable.cuda() is another Variable instance different from the original Variable. However, it is not the case in Chainer.
In addition, I'm worried that enabling initialization of a network by registering a link both on GPU and CPU cause contamination of GPU-array and CPU-array and the API confuses the user. (Is not model.to_gpu() enough?)
		</comment>
		<comment id='3' author='ryotayamazaki' date='2018-09-12T05:27:47Z'>
		Chain.to_gpu sends all the links under the chain to the specified GPU.  The code would be cleaner if there's a chain for each GPU.
		</comment>
		<comment id='4' author='ryotayamazaki' date='2018-09-12T05:48:46Z'>
		I coded the code to use multi GPUs with reference to &lt;denchmark-link:https://docs.chainer.org/en/stable/guides/gpu.html#model-parallel-computation-on-multiple-gpus&gt;Chainer's Guide&lt;/denchmark-link&gt;
.
Chain.to_gpu let the code be a single GPUï¿½, right?
		</comment>
	</comments>
</bug>