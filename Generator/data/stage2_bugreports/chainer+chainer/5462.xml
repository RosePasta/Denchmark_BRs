<bug id='5462' author='koreyou' open_date='2018-10-10T10:31:01Z' closed_time='2018-10-11T06:36:52Z'>
	<summary>CaffeFunction ignores pad_w from Convolution</summary>
	<description>
&lt;denchmark-h:h1&gt;Problem description&lt;/denchmark-h&gt;

Trying to import inception from &lt;denchmark-link:https://github.com/soeaver/caffe-model/tree/master/cls&gt;Caffe model&lt;/denchmark-link&gt;
 fails.

download and unzip files from https://drive.google.com/open?id=0B9mkjlmP0d7zTEJmNEh6c0RfYzg
Run following python script (should fail)

test_inception_v3.py:
import chainer
from chainer.links.caffe import CaffeFunction
import numpy as np

func = CaffeFunction('inception-v3/inception-v3.caffemodel')

# Image size as specified in inception-v3/deploy_inception-v3.prototxt
x_data = np.random.uniform(size=(1, 3, 299, 299)).astype(np.float32)

x = chainer.Variable(x_data)
y, = func(inputs={'data': x}, outputs=['prob'])
print(y)
This will raise following error.
&lt;denchmark-code&gt;/home/koreyou/.pyenv/versions/chainer-inception-v3/lib/python3.6/site-packages/chainer/links/caffe/caffe_function.py:166: UserWarning: Skip the layer "input", since CaffeFunction does notsupport Input layer
  'support %s layer' % (layer.name, layer.type))
Traceback (most recent call last):
  File "test_inception_v3.py", line 14, in &lt;module&gt;
    y, = func(inputs={'data': x}, outputs=['prob'])
...
  File "/home/koreyou/.pyenv/versions/chainer-inception-v3/lib/python3.6/site-packages/chainer/functions/array/concat.py", line 41, in check_type_forward
    type_check.expect(in_types[0].shape[d] == in_types[i].shape[d])
  File "/home/koreyou/.pyenv/versions/chainer-inception-v3/lib/python3.6/site-packages/chainer/utils/type_check.py", line 546, in expect
    expr.expect()
  File "/home/koreyou/.pyenv/versions/chainer-inception-v3/lib/python3.6/site-packages/chainer/utils/type_check.py", line 483, in expect
    '{0} {1} {2}'.format(left, self.inv, right))
chainer.utils.type_check.InvalidType:
Invalid operation is performed in: Concat (Forward)

Expect: in_types[0].shape[3] == in_types[1].shape[3]
Actual: 17 != 11
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Platform: Linux-4.4.0-135-generic-x86_64-with-debian-stretch-sid
Chainer: 5.0.0rc1
NumPy: 1.15.2
CuPy: Not Available
&lt;/denchmark-code&gt;

&lt;denchmark-h:h1&gt;Reason for failure&lt;/denchmark-h&gt;

By running debugger, I figured out that problem was that  in caffe model was ignored (it was 7x1 convolution on 17x17 features -&gt; wrong padding resulted in the size of 11). I also noticed that &lt;denchmark-link:https://github.com/chainer/chainer/blob/v4.5.0/chainer/links/caffe/caffe_function.py#L524-L525&gt;only pad_h was being checked to apply padding&lt;/denchmark-link&gt;
. Thus, applying check for  will fix the problem.
  def _get_pad(param):
-     if param.pad_h &gt; 0:
+     if param.pad_h &gt; 0 or param.pad_w &gt; 0:
          return param.pad_h, param.pad_w
      elif type(param.pad) == int:
          return param.pad 
&lt;denchmark-h:h2&gt;Checking&lt;/denchmark-h&gt;

pip uninstall chainer
pip install git+https://github.com/koreyou/chainer.git@fix-caffe-pad_w
# should run without a problem
python test_inception_v3.py
I will send merge request for this problem. Please check and see if it can be merged.
	</description>
	<comments>
	</comments>
</bug>