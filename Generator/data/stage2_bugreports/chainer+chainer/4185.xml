<bug id='4185' author='murawaki' open_date='2018-01-16T04:35:57Z' closed_time='2018-02-14T10:27:47Z'>
	<summary>double backprop with embed_id raises an error</summary>
	<description>
Code to reproduce:
import numpy as np                                                                                                                                                                                                                                                                                                                                                                     
import chainer                                                                                                                                                                                                                                                                                                                                                                         
from chainer import Variable                                                                                                                                                                                                                                                                                                                                                           
import chainer.functions as F                                                                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                                                                                       
mat = Variable(np.random.uniform(size=(16, 32)).astype(np.float32))                                                                                                                                                                                                                                                                                                                    
x = F.embed_id(Variable(np.array([1, 2], dtype=np.int32)), mat)                                                                                                                                                                                                                                                                                                                        
l = F.sum(x)                                                                                                                                                                                                                                                                                                                                                                           
grad, = chainer.grad([l], [mat], enable_double_backprop=True)
This gives the following error:
&lt;denchmark-code&gt;Traceback (most recent call last):                                                                                                                                                                                                                                                                                                                                                     
  File "test_embed.py", line 11, in &lt;module&gt;                                                                                                                                                                                                                                                                                                                                           
    grad, = chainer.grad([l], [mat], enable_double_backprop=True)                                                                                                                                                                                                                                                                                                                      
  File "/home/murawaki/local3/lib/python3.6/site-packages/chainer/function_node.py", line 763, in grad                                                                                                                                                                                                                                                                                 
    _backprop(outputs, inputs, grad_required, retain_grad, grads)                                                                                                                                                                                                                                                                                                                      
  File "/home/murawaki/local3/lib/python3.6/site-packages/chainer/function_node.py", line 822, in _backprop                                                                                                                                                                                                                                                                            
    new_gxs = func.backward_accumulate(input_indexes, gys, gxs)                                                                                                                                                                                                                                                                                                                        
  File "/home/murawaki/local3/lib/python3.6/site-packages/chainer/function_node.py", line 514, in backward_accumulate                                                                                                                                                                                                                                                                  
    gxs = self.backward(target_input_indexes, grad_outputs)                                                                                                                                                                                                                                                                                                                            
  File "/home/murawaki/local3/lib/python3.6/site-packages/chainer/functions/connection/embed_id.py", line 55, in backward                                                                                                                                                                                                                                                              
    self._w_shape, self.ignore_label).apply(inputs + grad_outputs)[0]                                                                                                                                                                                                                                                                                                                  
TypeError: can only concatenate tuple (not "list") to tuple 
&lt;/denchmark-code&gt;

Replacing
&lt;denchmark-code&gt;inputs + grad_outputs
&lt;/denchmark-code&gt;

with
&lt;denchmark-code&gt;inputs + tuple(grad_outputs)
&lt;/denchmark-code&gt;

eliminates the error, but I am not sure if this is an elegant way to solve the problem.
	</description>
	<comments>
		<comment id='1' author='murawaki' date='2018-01-16T05:01:58Z'>
		The error has been confirmed. Thank you for reporting!
		</comment>
	</comments>
</bug>