<bug id='2854' author='niboshi' open_date='2017-06-13T05:16:46Z' closed_time='2017-12-11T09:31:18Z'>
	<summary>Test failure on test_spatial_transformer_sampler.TestSpatialTransformerSampler</summary>
	<description>
&lt;denchmark-link:https://travis-ci.org/chainer/chainer/builds/241979452?utm_source=github_status&amp;utm_medium=notification&gt;https://travis-ci.org/chainer/chainer/builds/241979452?utm_source=github_status&amp;utm_medium=notification&lt;/denchmark-link&gt;

(Occured in a PR based on  branch. Also confirmed in  branch.)
Looks like this is numeric unstability due to non-deterministic behavior of cudnnSpatialTfSamplerBackward function. This error has occurred in cpu mode.
&lt;denchmark-code&gt;FAIL: test_backward_cpu (test_spatial_transformer_sampler.TestSpatialTransformerSampler_param_1)  parameter: {'use_cudnn': False}
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/chainer/testing/condition.py", line 74, in wrapper
    fail()
  File "/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/chainer/testing/condition.py", line 51, in fail
    instance.fail(msg)
AssertionError: 
Fail: 3, Success: 0
The first error message:
Traceback (most recent call last):
  File "/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/chainer/testing/condition.py", line 60, in &lt;lambda&gt;
    lambda: f(ins, *args[1:], **kwargs),
  File "/home/travis/build/chainer/chainer/tests/chainer_tests/functions_tests/array_tests/test_spatial_transformer_sampler.py", line 81, in test_backward_cpu
    self.check_backward(self.x, self.grid, self.grads)
  File "/home/travis/build/chainer/chainer/tests/chainer_tests/functions_tests/array_tests/test_spatial_transformer_sampler.py", line 77, in check_backward
    (x, grid), (grads,), atol=1e-2, rtol=1e-2, eps=1e-5)
  File "/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/chainer/gradient_check.py", line 261, in check_backward
    testing.assert_allclose(gx, x.grad, atol=atol, rtol=rtol)
  File "/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/chainer/testing/array.py", line 24, in assert_allclose
    x, y, atol=atol, rtol=rtol, verbose=verbose)
  File "/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/numpy/testing/utils.py", line 1297, in assert_allclose
    verbose=verbose, header=header)
  File "/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/numpy/testing/utils.py", line 665, in assert_array_compare
    raise AssertionError(msg)
AssertionError: 
Not equal to tolerance rtol=0.01, atol=0.01
(mismatch 100.0%)
 x: array([[[[ 0.      ,  1.745135,  0.018301],
         [ 0.      ,  0.059922,  0.      ],
         [ 0.675761,  0.      ,  0.011499]],...
 y: array([[[[ 0.      ,  1.74235 ,  0.018444],
         [ 0.      ,  0.059806,  0.      ],
         [ 0.674425, -0.      ,  0.01307 ]],...
-------------------- &gt;&gt; begin captured stdout &lt;&lt; ---------------------
('error:', 0.030225635)
('error:', 0.02776432)
('error:', 0.025904417)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='niboshi' date='2017-06-13T07:35:20Z'>
		From the log, it seems that the test failed during CPU mode. I think cuDNN is not related to this issue.
Due to the nature of the function, the backward pass has been unstable.
How should we improve the stability?
		</comment>
		<comment id='2' author='niboshi' date='2017-06-13T07:42:48Z'>
		Oh, you're right! Thank you for pointing out.
Can you locate the exact source of numeric unstability?
		</comment>
		<comment id='3' author='niboshi' date='2017-06-13T08:54:37Z'>
		Ah, I found it's due to random numbers in the test...
I think it can be easily fixed by using fixed random seed.
Actually I'm working on similar problem in cupy: &lt;denchmark-link:https://github.com/cupy/cupy/pull/82&gt;cupy/cupy#82&lt;/denchmark-link&gt;

I will port it after it's fixed in cupy.
		</comment>
		<comment id='4' author='niboshi' date='2017-06-13T08:59:07Z'>
		
Can you locate the exact source of numeric unstability?

I can not really describe the instability mathematically, but it seems that the gradient for the grid is always failing the test.
FYI, I changed the setting of retry option to never retry, and I observed that the backward pass fails once in every ten trial.
		</comment>
		<comment id='5' author='niboshi' date='2017-06-14T01:58:03Z'>
		Thank you for checking.
We're discussing internally on how to deal with random tests.
But 1/10 failure rate is quite large...
Perhaps this test needs a fix after we decide random test policy.
		</comment>
		<comment id='6' author='niboshi' date='2017-06-14T02:06:02Z'>
		Yes. 1/10 fails so, even with retry(3) option, 1 / 1000 fail.
		</comment>
		<comment id='7' author='niboshi' date='2017-12-11T09:31:18Z'>
		It seems this has been fixed in the latest v3 branch.
I close this issue.
		</comment>
	</comments>
</bug>