<bug id='6119' author='toslunar' open_date='2019-01-28T09:36:15Z' closed_time='2019-02-05T01:05:04Z'>
	<summary>Strange result with `L.Linear`, `to_gpu`, and `zerograds`.</summary>
	<description>

Conditions

&lt;denchmark-code&gt;&gt;&gt;&gt; chainer.print_runtime_info()
Platform: Linux-4.4.0-103-generic-x86_64-with-debian-stretch-sid
Chainer: 6.0.0b2
NumPy: 1.17.0.dev0+8f547f2
CuPy:
  CuPy Version          : 6.0.0b2
  CUDA Root             : /usr/local/cuda
  CUDA Build Version    : 9000
  CUDA Driver Version   : 9000
  CUDA Runtime Version  : 9000
  cuDNN Build Version   : 7104
  cuDNN Version         : 7104
  NCCL Build Version    : 2005
iDeep: 2.0.0.post3
&lt;/denchmark-code&gt;


Code to reproduce

&lt;denchmark-code&gt;&gt;&gt;&gt; l = chainer.links.Linear(3, 4)
&gt;&gt;&gt; l.zerograds()
&gt;&gt;&gt; l.W.grad
array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
&gt;&gt;&gt; l = chainer.links.Linear(3, 4).to_gpu(0)
&gt;&gt;&gt; l.zerograds()
&gt;&gt;&gt; l.W.grad
array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan]], dtype=float32)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='toslunar' date='2019-01-29T01:59:53Z'>
		This can be observed in v6.0.0b1, but is not observed in 5.2.0.
&lt;denchmark-code&gt;&gt;&gt;&gt; chainer.print_runtime_info()
Platform: Linux-4.4.0-135-generic-x86_64-with-Ubuntu-16.04-xenial
Chainer:  6.0.0b1
NumPy: 1.15.4
CuPy:
  CuPy Version          : 6.0.0b1
  CUDA Root             : /home/hashimoto/.local/cuda/cuda-9.2
  CUDA Build Version    : 9020
  CUDA Driver Version   : 10000
  CUDA Runtime Version  : 9020
  cuDNN Build Version   : 7401
  cuDNN Version         : 7401
  NCCL Build Version    : 2307
iDeep: Not Available
&gt;&gt;&gt; l = chainer.links.Linear(3, 4)
&gt;&gt;&gt; l.zerograds()
&gt;&gt;&gt; l.W.grad
array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
&gt;&gt;&gt; l = chainer.links.Linear(3, 4).to_gpu(0)
&gt;&gt;&gt; l.zerograds()
&gt;&gt;&gt; l.W.grad
array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan]], dtype=float32)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;&gt;&gt;&gt; chainer.print_runtime_info()
Platform: Linux-4.4.0-135-generic-x86_64-with-debian-stretch-sid
Chainer: 5.2.0
NumPy: 1.16.0
CuPy:
  CuPy Version          : 5.2.0
  CUDA Root             : /home/hashimoto/.local/cuda/cuda-9.2
  CUDA Build Version    : 9020
  CUDA Driver Version   : 10000
  CUDA Runtime Version  : 9020
  cuDNN Build Version   : 7301
  cuDNN Version         : 7301
  NCCL Build Version    : 2307
iDeep: Not Available
&gt;&gt;&gt; l = chainer.links.Linear(3, 4)
&gt;&gt;&gt; l.zerograds()
&gt;&gt;&gt; l.W.grad
array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
&gt;&gt;&gt; l = chainer.links.Linear(3, 4).to_gpu(0)
&gt;&gt;&gt; l.zerograds()
&gt;&gt;&gt; l.W.grad
array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.]], dtype=float32)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='toslunar' date='2019-01-29T02:48:37Z'>
		I found the reason, and this might be a critical bug.
I don't know the exact specification, but I guess Parameter._grad should be reference to Parameter._grad_var.array when W._grad_var is not None, but it is not the case after to_gpu().
Even after to_gpu()ed, Parameter._grad remains as numpy.ndarray!
&lt;denchmark-code&gt;&gt;&gt;&gt; l = chainer.links.Linear(3, 4)
&gt;&gt;&gt; W = l.W
&gt;&gt;&gt; W._grad
array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan]], dtype=float32)
&gt;&gt;&gt; W._grad_var is None
True
&gt;&gt;&gt; W.to_gpu()
&gt;&gt;&gt; W._grad
array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan]], dtype=float32)
&gt;&gt;&gt; type(W._grad)
&lt;class 'numpy.ndarray'&gt;
&gt;&gt;&gt; W._grad_var
variable([[nan, nan, nan],
          [nan, nan, nan],
          [nan, nan, nan],
          [nan, nan, nan]])
&gt;&gt;&gt; W._grad is W._grad_var.array
False
&lt;/denchmark-code&gt;

Because Parameter.zerograd() set zeros to W._grad, not W._grad_var.array, it causes unexpected behavior.



chainer/chainer/variable.py


        Lines 1153 to 1156
      in
      f7724b6






 gv = self._grad_var 



 if gv is not None: 



 gv.unchain() 



 self._grad.fill(0) 





I think the most trivial solution is changing self._grad.fill(0) to self.grad.fill(0), but I think leaving np.ndarray (Parameter._grad) in Parameter on GPU might be causing some other side-effects.
		</comment>
		<comment id='3' author='toslunar' date='2019-02-05T01:05:00Z'>
		Fixed via &lt;denchmark-link:https://github.com/chainer/chainer/pull/6170&gt;#6170&lt;/denchmark-link&gt;
.
&lt;denchmark-link:https://github.com/fiarabbit&gt;@fiarabbit&lt;/denchmark-link&gt;
 Thank you for investigation!
		</comment>
	</comments>
</bug>