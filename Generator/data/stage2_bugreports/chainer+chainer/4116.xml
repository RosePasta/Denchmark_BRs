<bug id='4116' author='beam2d' open_date='2017-12-18T01:42:45Z' closed_time='2018-03-29T07:52:11Z'>
	<summary>`chainer.grad` does not call `backward_{pre,post}process` of function hooks</summary>
	<description>
The following code can be used for reproduction. It does not print anything on grad.
import chainer
import numpy

class MyHook(chainer.FunctionHook):
    def __init__(self, name):
        self.name = name

    def backward_preprocess(self, f, in_d, out_g):
        print(self.name, ':', 'preproc', f.label)

    def backward_postprocess(self, f, in_d, out_g):
        print(self.name, ':', 'postproc', f.label)

x = chainer.Variable(numpy.array([2.]))
y = x * x
with MyHook('backward'):
    y.backward()
with MyHook('grad'):
    chainer.grad([y], [x])
which shows
&lt;denchmark-code&gt;backward : preproc _ * _
backward : postproc _ * _
&lt;/denchmark-code&gt;

I confirmed it with Chainer 3.2.0 and 4.0.0b2.
	</description>
	<comments>
		<comment id='1' author='beam2d' date='2018-03-18T02:30:24Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed after 30 days if no further activity occurs. Thank you for your contributions.
		</comment>
		<comment id='2' author='beam2d' date='2018-03-19T01:09:23Z'>
		bump
		</comment>
	</comments>
</bug>