<bug id='1175' author='muupan' open_date='2016-05-12T15:03:30Z' closed_time='2016-05-17T04:23:51Z'>
	<summary>HuberLoss's backward() should not ignore gy</summary>
	<description>
HuberLoss's backward() ignores gy, so any computation after HuberLoss has no effect for gradients backpropagated by HuberLoss. I think such a behavior is not correct.
&gt;&gt;&gt; x = chainer.Variable(np.zeros((1,1), dtype=np.float32))
&gt;&gt;&gt; t = chainer.Variable(np.ones((1,1), dtype=np.float32))
&gt;&gt;&gt; F.huber_loss(x, t, 1.0).backward()
&gt;&gt;&gt; x.grad
array([[-1.]], dtype=float32)
&gt;&gt;&gt; x = chainer.Variable(np.zeros((1,1), dtype=np.float32))
&gt;&gt;&gt; t = chainer.Variable(np.ones((1,1), dtype=np.float32))
&gt;&gt;&gt; (F.huber_loss(x, t, 1.0) * 0).backward()  # Multiply the loss by zero
&gt;&gt;&gt; x.grad
array([[-1.]], dtype=float32)
	</description>
	<comments>
	</comments>
</bug>