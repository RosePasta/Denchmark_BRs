<bug id='4017' author='Hiroshiba' open_date='2017-12-03T01:53:07Z' closed_time='2018-03-09T03:59:48Z'>
	<summary>LSTM double backprop raise error</summary>
	<description>
I tried double backprop with LSTM. Then two error occurred.
import chainer
import numpy

print('chainer version:', chainer.__version__)

lstm = chainer.links.StatelessLSTM(3, 3)
x = chainer.Variable(numpy.random.rand(2, 3).astype(numpy.float32))
_, y = lstm(None, None, x)

g, = chainer.grad([y], [x], enable_double_backprop=True)
l = chainer.functions.mean_squared_error(g, numpy.ones_like(g.data, numpy.float32))
l.backward()
print(l)
First error,
&lt;denchmark-code&gt;chainer version: 3.1.0
Traceback (most recent call last):
  File "check.py", line 10, in &lt;module&gt;
    g, = chainer.grad([y], [x], enable_double_backprop=True)
  File "/hoge/lib/python3.6/site-packages/chainer/function_node.py", line 758, in grad
    _backprop(outputs, inputs, grad_required, retain_grad, grads)
  File "/hoge/lib/python3.6/site-packages/chainer/function_node.py", line 817, in _backprop
    new_gxs = func.backward_accumulate(input_indexes, gys, gxs)
  File "/hoge/lib/python3.6/site-packages/chainer/function_node.py", line 509, in backward_accumulate
    gxs = self.backward(target_input_indexes, grad_outputs)
  File "/hoge/lib/python3.6/site-packages/chainer/functions/activation/lstm.py", line 113, in backward
    self.get_retained_inputs() + self.get_retained_outputs() + grads)
TypeError: can only concatenate tuple (not "list") to tuple
&lt;/denchmark-code&gt;

This error may be caused that grads is not tuple.
So I changed such as tuple(grads).
Then second error is occurred.
Second error,
&lt;denchmark-code&gt;chainer version: 3.1.0
Traceback (most recent call last):
  File "check.py", line 13, in &lt;module&gt;
    l.backward()
  File "/hoge/lib/python3.6/site-packages/chainer/variable.py", line 852, in backward
    self._backward_main(retain_grad)
  File "/hoge/lib/python3.6/site-packages/chainer/variable.py", line 953, in _backward_main
    target_input_indexes, out_grad, in_grad)
  File "/hoge/lib/python3.6/site-packages/chainer/function_node.py", line 509, in backward_accumulate
    gxs = self.backward(target_input_indexes, grad_outputs)
  File "/hoge/lib/python3.6/site-packages/chainer/function.py", line 139, in backward
    gxs = self._function.backward(in_data, grad_out_data)
  File "/hoge/lib/python3.6/site-packages/chainer/functions/activation/lstm.py", line 186, in backward
    ggc = ggc_prev.copy()
AttributeError: 'NoneType' object has no attribute 'copy'
&lt;/denchmark-code&gt;

I cannot understand why this error was occurred.
	</description>
	<comments>
		<comment id='1' author='Hiroshiba' date='2018-01-15T00:57:56Z'>
		This is just to say I need this bug to be fixed :-)
Looks like some weakref-ed VariableNode (and Variable?) objects are dead.
And GRU has the same problem. Something goes wrong with LinearInterpolateGrad, just like LSTMGrad for LSTM.
		</comment>
		<comment id='2' author='Hiroshiba' date='2018-03-09T03:59:47Z'>
		This problem is fixed via &lt;denchmark-link:https://github.com/chainer/chainer/pull/4320&gt;#4320&lt;/denchmark-link&gt;
. Your code works well now. If you face the same problem, please reopen the issue.
		</comment>
	</comments>
</bug>