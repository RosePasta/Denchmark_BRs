<bug id='7370' author='keisukefukuda' open_date='2019-06-03T08:13:19Z' closed_time='2019-06-06T05:30:47Z'>
	<summary>ChainerMN test fails in `check_allreduce_grad_empty_half` test</summary>
	<description>
ChainerMN CI fails with the following error:
I'm not sure how this issue is different from &lt;denchmark-link:https://github.com/chainer/chainer/pull/7273&gt;#7273&lt;/denchmark-link&gt;
, but I confirmed that &lt;denchmark-link:https://github.com/chainer/chainer/pull/7273&gt;#7273&lt;/denchmark-link&gt;
 does not fix the problem.
The problem seems to happen only on Python 2.7.x, and 4 processes .
&lt;denchmark-code&gt;=================================== FAILURES ===================================
________________________ test_communicator_cpu[param0] _________________________

cls = &lt;class '_pytest.runner.CallInfo'&gt;
func = &lt;function &lt;lambda&gt; at 0x7f7e892958c0&gt;, when = 'call'
reraise = (&lt;class '_pytest.outcomes.Exit'&gt;, &lt;type 'exceptions.KeyboardInterrupt'&gt;)

    @classmethod
    def from_call(cls, func, when, reraise=None):
        #: context of invocation: one of "setup", "call",
        #: "teardown", "memocollect"
        start = time()
        excinfo = None
        try:
&gt;           result = func()

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/runner.py:225:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

&gt;       lambda: ihook(item=item, **kwds), when=when, reraise=reraise
    )

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/runner.py:197:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;_HookCaller 'pytest_runtest_call'&gt;, args = ()
kwargs = {'item': &lt;Function test_communicator_cpu[param0]&gt;}, notincall = set([])

    def __call__(self, *args, **kwargs):
        if args:
            raise TypeError("hook calling supports only keyword arguments")
        assert not self.is_historic()
        if self.spec and self.spec.argnames:
            notincall = (
                set(self.spec.argnames) - set(["__multicall__"]) - set(kwargs.keys())
            )
            if notincall:
                warnings.warn(
                    "Argument(s) {} which are declared in the hookspec "
                    "can not be found in this hook call".format(tuple(notincall)),
                    stacklevel=2,
                )
&gt;       return self._hookexec(self, self.get_hookimpls(), kwargs)

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/pluggy/hooks.py:289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;_pytest.config.PytestPluginManager object at 0x7f7ea1ce3510&gt;
hook = &lt;_HookCaller 'pytest_runtest_call'&gt;
methods = [&lt;HookImpl plugin_name='runner', plugin=&lt;module '_pytest.runner' from '/usr/local/pyenv/versions/2.7.15/lib/python2.7/...u[param0]&gt;&gt;&gt;, &lt;HookImpl plugin_name='logging-plugin', plugin=&lt;_pytest.logging.LoggingPlugin object at 0x7f7ea18dab10&gt;&gt;]
kwargs = {'item': &lt;Function test_communicator_cpu[param0]&gt;}

    def _hookexec(self, hook, methods, kwargs):
        # called from all hookcaller instances.
        # enable_tracing will set its own wrapping function at self._inner_hookexec
&gt;       return self._inner_hookexec(hook, methods, kwargs)

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/pluggy/manager.py:87:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

hook = &lt;_HookCaller 'pytest_runtest_call'&gt;
methods = [&lt;HookImpl plugin_name='runner', plugin=&lt;module '_pytest.runner' from '/usr/local/pyenv/versions/2.7.15/lib/python2.7/...u[param0]&gt;&gt;&gt;, &lt;HookImpl plugin_name='logging-plugin', plugin=&lt;_pytest.logging.LoggingPlugin object at 0x7f7ea18dab10&gt;&gt;]
kwargs = {'item': &lt;Function test_communicator_cpu[param0]&gt;}

    self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(
        methods,
        kwargs,
&gt;       firstresult=hook.spec.opts.get("firstresult") if hook.spec else False,
    )

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/pluggy/manager.py:81:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

item = &lt;Function test_communicator_cpu[param0]&gt;

    def pytest_runtest_call(item):
        _update_current_test_var(item, "call")
        sys.last_type, sys.last_value, sys.last_traceback = (None, None, None)
        try:
&gt;           item.runtest()

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/runner.py:122:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;Function test_communicator_cpu[param0]&gt;

    def runtest(self):
        """ execute the underlying test function. """
&gt;       self.ihook.pytest_pyfunc_call(pyfuncitem=self)

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/python.py:1467:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;_HookCaller 'pytest_pyfunc_call'&gt;, args = ()
kwargs = {'pyfuncitem': &lt;Function test_communicator_cpu[param0]&gt;}
notincall = set([])

    def __call__(self, *args, **kwargs):
        if args:
            raise TypeError("hook calling supports only keyword arguments")
        assert not self.is_historic()
        if self.spec and self.spec.argnames:
            notincall = (
                set(self.spec.argnames) - set(["__multicall__"]) - set(kwargs.keys())
            )
            if notincall:
                warnings.warn(
                    "Argument(s) {} which are declared in the hookspec "
                    "can not be found in this hook call".format(tuple(notincall)),
                    stacklevel=2,
                )
&gt;       return self._hookexec(self, self.get_hookimpls(), kwargs)

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/pluggy/hooks.py:289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;_pytest.config.PytestPluginManager object at 0x7f7ea1ce3510&gt;
hook = &lt;_HookCaller 'pytest_pyfunc_call'&gt;
methods = [&lt;HookImpl plugin_name='python', plugin=&lt;module '_pytest.python' from '/usr/local/pyenv/versions/2.7.15/lib/python2.7/...n=&lt;module '_pytest.skipping' from '/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/skipping.py'&gt;&gt;]
kwargs = {'pyfuncitem': &lt;Function test_communicator_cpu[param0]&gt;}

    def _hookexec(self, hook, methods, kwargs):
        # called from all hookcaller instances.
        # enable_tracing will set its own wrapping function at self._inner_hookexec
&gt;       return self._inner_hookexec(hook, methods, kwargs)

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/pluggy/manager.py:87:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

hook = &lt;_HookCaller 'pytest_pyfunc_call'&gt;
methods = [&lt;HookImpl plugin_name='python', plugin=&lt;module '_pytest.python' from '/usr/local/pyenv/versions/2.7.15/lib/python2.7/...n=&lt;module '_pytest.skipping' from '/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/skipping.py'&gt;&gt;]
kwargs = {'pyfuncitem': &lt;Function test_communicator_cpu[param0]&gt;}

    self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(
        methods,
        kwargs,
&gt;       firstresult=hook.spec.opts.get("firstresult") if hook.spec else False,
    )

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/pluggy/manager.py:81:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

pyfuncitem = &lt;Function test_communicator_cpu[param0]&gt;

    @hookimpl(trylast=True)
    def pytest_pyfunc_call(pyfuncitem):
        testfunction = pyfuncitem.obj
        iscoroutinefunction = getattr(inspect, "iscoroutinefunction", None)
        if iscoroutinefunction is not None and iscoroutinefunction(testfunction):
            msg = "Coroutine functions are not natively supported and have been skipped.\n"
            msg += "You need to install a suitable plugin for your async framework, for example:\n"
            msg += "  - pytest-asyncio\n"
            msg += "  - pytest-trio\n"
            msg += "  - pytest-tornasync"
            warnings.warn(PytestUnhandledCoroutineWarning(msg.format(pyfuncitem.nodeid)))
            skip(msg="coroutine function and no async plugin installed (see warnings)")
        funcargs = pyfuncitem.funcargs
        testargs = {arg: funcargs[arg] for arg in pyfuncitem._fixtureinfo.argnames}
&gt;       testfunction(**testargs)

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/python.py:179:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

param = {'allreduce_grad_dtype': None,
 'batched_copy': False,
 'communicator_class': ...one,
 'gpu': False,
 'model_dtype': None,
 'multi_node': True,
 'nccl1': False}

    @pytest.mark.parametrize('param', cpu_params)
    def test_communicator_cpu(param):
        check_send_recv(param, False)
&gt;       check_collective_communication(param, False)

tests/chainermn_tests/communicator_tests/test_communicator.py:516:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

param = {'allreduce_grad_dtype': None,
 'batched_copy': False,
 'communicator_class': ...one,
 'gpu': False,
 'model_dtype': None,
 'multi_node': True,
 'nccl1': False}
use_gpu = False

    def check_collective_communication(param, use_gpu):
        communicator = create_communicator(param, use_gpu)
        mpi_comm.barrier()

        model = ExampleModel(param.model_dtype)
        if use_gpu:
            model.to_gpu()
        check_bcast_data(communicator, model)

        model = ExampleModel(param.model_dtype)
        if use_gpu:
            model.to_gpu()
        check_allreduce_grad(communicator, model)

        model = ExampleModel(param.model_dtype)
        if use_gpu:
            model.to_gpu()
        check_allreduce_grad_empty(communicator, model)
        model = ExampleModel(param.model_dtype)
        if use_gpu:
            model.to_gpu()
&gt;       check_allreduce_grad_empty_half(communicator, model)

tests/chainermn_tests/communicator_tests/test_communicator.py:492:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

communicator = &lt;chainermn.communicators.naive_communicator.NaiveCommunicator object at 0x7f7ea1006ed0&gt;
model = &lt;test_communicator.ExampleModel object at 0x7f7ea19688d0&gt;

    def check_allreduce_grad_empty_half(communicator, model):
        # We need to repeat twice for regressions on lazy initialization of
        # sub communicators.

        for _ in range(2):
            model.a.W.data[:] = communicator.rank
            model.b.W.data[:] = communicator.rank + 1
            model.c.b.data[:] = communicator.rank + 2

            model.a.W.grad[:] = communicator.rank
            model.b.W.grad[:] = communicator.rank + 1
            if communicator.rank % 2 == 0:
                model.c.b.grad[:] = communicator.rank + 2
            else:
                model.c.b.grad = None

            communicator.allreduce_grad(model, zero_fill=True)
            base = (communicator.size - 1.0) / 2

            chainer.testing.assert_allclose(model.a.W.grad,
                                            (base + 0) * np.ones((3, 2)))
            chainer.testing.assert_allclose(model.b.W.grad,
                                            (base + 1) * np.ones((4, 3)))

            v = 0
            for i in range(communicator.size):
                if i % 2 == 0:
                    v += i + 2
            v /= communicator.size
            chainer.testing.assert_allclose(model.c.b.grad,
                                            v * np.ones((5, )),
                                            rtol=1e-3,
&gt;                                           atol=1e-4)

tests/chainermn_tests/communicator_tests/test_communicator.py:368:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = array([1.5, 1.5, 1.5, 1.5, 1.5], dtype=float32)
y = array([1., 1., 1., 1., 1.]), atol = 0.0001, rtol = 0.001, verbose = True

    def assert_allclose(x, y, atol=1e-5, rtol=1e-4, verbose=True):
        """Asserts if some corresponding element of x and y differs too much.

        This function can handle both CPU and GPU arrays simultaneously.

        Args:
            x: Left-hand-side array.
            y: Right-hand-side array.
            atol (float): Absolute tolerance.
            rtol (float): Relative tolerance.
            verbose (bool): If ``True``, it outputs verbose messages on error.

        """
        x = backend.CpuDevice().send(utils.force_array(x))
        y = backend.CpuDevice().send(utils.force_array(y))
        try:
            numpy.testing.assert_allclose(
                x, y, atol=atol, rtol=rtol, verbose=verbose)
        except AssertionError as e:
            f = six.StringIO()
            f.write(str(e) + '\n\n')
            f.write(
                'assert_allclose failed: \n' +
                '  shape: {} {}\n'.format(x.shape, y.shape) +
                '  dtype: {} {}\n'.format(x.dtype, y.dtype))
            if x.shape == y.shape:
                xx = numpy.atleast_1d(x)
                yy = numpy.atleast_1d(y)
                err = numpy.abs(xx - yy)
                tol_err = atol + rtol * numpy.abs(yy).astype(numpy.float64)
                i = numpy.unravel_index(
                    numpy.argmax(err.astype(numpy.float64) - tol_err), err.shape)
                if yy[i] == 0:
                    rel_err = 'inf'
                else:
                    rel_err = err[i] / numpy.abs(yy[i])
                f.write(
                    '  i: {}\n'.format(i) +
                    '  x[i]: {}\n'.format(xx[i]) +
                    '  y[i]: {}\n'.format(yy[i]) +
                    '  relative error[i]: {}\n'.format(rel_err) +
                    '  absolute error[i]: {}\n'.format(err[i]))
            opts = numpy.get_printoptions()
            try:
                numpy.set_printoptions(threshold=10000)
                f.write('x: ' + numpy.array2string(x, prefix='x: ') + '\n')
                f.write('y: ' + numpy.array2string(y, prefix='y: ') + '\n')
            finally:
                numpy.set_printoptions(**opts)
&gt;           raise AssertionError(f.getvalue())
E           AssertionError:
E           Not equal to tolerance rtol=0.001, atol=0.0001
E
E           Mismatch: 100%
E           Max absolute difference: 0.5
E           Max relative difference: 0.5
E            x: array([1.5, 1.5, 1.5, 1.5, 1.5], dtype=float32)
E            y: array([1., 1., 1., 1., 1.])
E
E           assert_allclose failed:
E             shape: (5,) (5,)
E             dtype: float32 float64
E             i: (0,)
E             x[i]: 1.5
E             y[i]: 1.0
E             relative error[i]: 0.5
E             absolute error[i]: 0.5
E           x: [1.5 1.5 1.5 1.5 1.5]
E           y: [1. 1. 1. 1. 1.]

chainer/testing/array.py:59: AssertionError
=============================== warnings summary ===============================
/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/mark/structures.py:324
  /usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/mark/structures.py:324: PytestUnknownMarkWarning: Unknown pytest.mark.gpu - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

/usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/mark/structures.py:324
  /usr/local/pyenv/versions/2.7.15/lib/python2.7/site-packages/_pytest/mark/structures.py:324: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/latest/mark.html
    PytestUnknownMarkWarning,

-- Docs: https://docs.pytest.org/en/latest/warnings.html
========================== slowest 10 test durations ===========================
1.11s call     tests/chainermn_tests/communicator_tests/test_communication_utility.py::TestCommunicationUtility::test_chunked_bcast_objs
0.27s call     tests/chainermn_tests/communicator_tests/test_communicator.py::test_communicator_cpu[param0]

(0.00 durations hidden.  Use -vv to show these durations.)
========= 1 failed, 1 passed, 4 deselected, 2 warnings in 7.81 seconds =========
&lt;/denchmark-code&gt;

	</description>
	<comments>
	</comments>
</bug>