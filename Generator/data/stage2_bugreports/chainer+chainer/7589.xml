<bug id='7589' author='zaltoprofen' open_date='2019-06-24T12:36:13Z' closed_time='2019-07-09T07:37:19Z'>
	<summary>`PickleDataset` crashes when using `MultiprocessIterator`</summary>
	<description>
I guess the cause is using the same open file description in child processes at the same time.
Should use multiprocessing.RLock instead of threading.RLock in PickleDataset and disable buffering, or close and reopen file in child processes.
&lt;denchmark-h:h2&gt;Conditions&lt;/denchmark-h&gt;

Platform: Darwin-18.6.0-x86_64-i386-64bit
Chainer: 6.0.0
NumPy: 1.16.2
CuPy: Not Available
iDeep: Not Available
&lt;denchmark-h:h2&gt;code&lt;/denchmark-h&gt;

import chainer
import numpy as np


def main():
    with chainer.datasets.open_pickle_dataset_writer('data.pkl') as w:
        for i in range(100):
            w.write(np.full(100, i))

    with chainer.datasets.open_pickle_dataset('data.pkl') as ds:
        it = chainer.iterators.MultiprocessIterator(ds, 10, repeat=False, shuffle=False)
        for batch in it:
            print(batch)


if __name__ == '__main__':
    main()
&lt;denchmark-h:h2&gt;stacktrace&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Exception in thread prefetch_loop:
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/pool.py", line 121, in worker
    result = (True, func(*args, **kwds))
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/pool.py", line 44, in mapstar
    return list(map(*args))
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/site-packages/chainer/iterators/multiprocess_iterator.py", line 509, in _fetch_run
    data = _fetch_dataset[index]
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/site-packages/chainer/dataset/dataset_mixin.py", line 67, in __getitem__
    return self.get_example(index)
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/site-packages/chainer/datasets/pickle_dataset.py", line 119, in get_example
    return pickle.load(self._reader)
_pickle.UnpicklingError: invalid load key, '&amp;'.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/threading.py", line 917, in _bootstrap_inner
    self.run()
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/threading.py", line 865, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/site-packages/chainer/iterators/multiprocess_iterator.py", line 452, in _run
    alive = self._task()
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/site-packages/chainer/iterators/multiprocess_iterator.py", line 476, in _task
    data_all = future.get(_response_time)
  File "/Users/zaltoprofen/.pyenv/versions/3.7.3/lib/python3.7/multiprocessing/pool.py", line 657, in get
    raise self._value
_pickle.UnpicklingError: invalid load key, '&amp;'.
&lt;/denchmark-code&gt;

	</description>
	<comments>
	</comments>
</bug>