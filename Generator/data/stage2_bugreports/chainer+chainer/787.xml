<bug id='787' author='sinhrks' open_date='2015-12-19T04:59:09Z' closed_time='2016-01-07T07:18:41Z'>
	<summary>Function may raise CUDNN_STATUS_BAD_PARAM when CPU/GPU mismatch</summary>
	<description>
When cuDNN is available, spatial_pyramid_pooling_2d raises following error when function is on CPU and passed Variable is on GPU. Can this error to be more understandable?
&lt;denchmark-code&gt;# GPU
arr = np.random.randn(5, 3, 5, 5)
v = Variable(arr)
v.to_gpu()

F.spatial_pyramid_pooling_2d(v, 3, F.MaxPooling2D)
# cupy/cuda/cudnn.pyx in cupy.cuda.cudnn.poolingForward (cupy/cuda/cudnn.cpp:6127)()
# cupy/cuda/cudnn.pyx in cupy.cuda.cudnn.poolingForward (cupy/cuda/cudnn.cpp:5978)()
# cupy/cuda/cudnn.pyx in cupy.cuda.cudnn.check_status (cupy/cuda/cudnn.cpp:1308)()
# CuDNNError: CUDNN_STATUS_BAD_PARAM: CUDNN_STATUS_BAD_PARAM
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='sinhrks' date='2015-12-27T02:51:24Z'>
		I think this error is not caused by inconsistency between CPU and GPU because spatial_pyramid_pooling_2d does call cuDNN (and it fails).
When I change the dtype of arr to float32 by arr = np.random.randn(5, 3, 5, 5).astype(np.float32), error does not occur. So we should check the dtype of inputs passed to cuDNN. Or change the function called according to the dtype of inputs.
		</comment>
		<comment id='2' author='sinhrks' date='2015-12-27T03:18:20Z'>
		I fix the code that would solve the problem.
		</comment>
	</comments>
</bug>