<bug id='398' author='c0stya' open_date='2015-09-10T15:48:09Z' closed_time='2015-09-16T05:29:28Z'>
	<summary>Strange behavior of 'Linear' transform with shape (x, 1) in GPU mode</summary>
	<description>
I tried to make a linear transformation from x to 1 dimension using this code:
from chainer import cuda, Variable
from chainer import functions as F

a = Variable(cuda.ones((100,5)))
l = F.Linear(5,1).to_gpu()

print  l(a).data
The 'strange' thing is that I'm getting different types of errors. For this particular snippet I got:
&lt;denchmark-code&gt; ** On entry to SGEMV  parameter number 6 had an illegal value
Traceback (most recent call last):
  File "test_linear_to_1.py", line 7, in &lt;module&gt;
    print  l(a).data
  File "/home/light/prj/chainer/chainer/function.py", line 174, in __call__
    outputs = self.forward(in_data)
  File "/home/light/prj/chainer/chainer/functions/connection/linear.py", line 111, in forward
    Wx = x.dot(self.W.T)
  File "/home/light/prj/chainer/cupy/__init__.py", line 1016, in dot
    return dot(self, b, out)
  File "/home/light/prj/chainer/cupy/linalg/product.py", line 72, in dot
    return _tensordot_core(a, b, out, n, m, k, ret_shape)
  File "/home/light/prj/chainer/cupy/linalg/product.py", line 349, in _tensordot_core
    c.data.ptr, 1)
  File "/home/light/prj/chainer/cupy/cuda/cublas.py", line 238, in sgemv
    check_status(status)
  File "/home/light/prj/chainer/cupy/cuda/cublas.py", line 60, in check_status
    raise CUBLASError(status)
cupy.cuda.cublas.CUBLASError: CUBLAS_STATUS_INVALID_VALUE
&lt;/denchmark-code&gt;

And with different values of batch size and the size of the first dimension I get NANs or extremely large numbers.
But if I change this
l = F.Linear(5,1).to_gpu()
to this
l = F.Linear(5,2).to_gpu()
the error disappears.
ps I tried to dig deeper but with no luck. Still new to your lib.
pps Great job btw, I really like the Chainer approach!
	</description>
	<comments>
		<comment id='1' author='c0stya' date='2015-09-11T02:02:07Z'>
		I met same error too. My chainer version is v1.3.0.
In my environment, the shape of a (in your example) is also affect to the error.
When I changed the shape of a, the error disappears.
(edit)
sorry, the shape of a has already been reported.
I compared the behavior with two computers, both GPU mode, one computer returns 'NANs or extremely large numbers' and the another works well with same code.
Then I changed the shape of a, the latter computer also returns wrong values.
		</comment>
		<comment id='2' author='c0stya' date='2015-09-11T02:32:36Z'>
		Hi.
Thank you for reporting. We have reproduced the error and are now investigating it.
Different behaviors of the case  and  are caused because these two cases pass through different code paths. While the former one enter &lt;denchmark-link:https://github.com/pfnet/chainer/blob/master/cupy/linalg/product.py#L336&gt;here&lt;/denchmark-link&gt;
, the other  &lt;denchmark-link:https://github.com/pfnet/chainer/blob/master/cupy/linalg/product.py#L350&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='c0stya' date='2015-09-11T15:19:54Z'>
		Hi, I believe I've seen similar issues where ndim=1 in the bilinear function too :)
		</comment>
		<comment id='4' author='c0stya' date='2015-09-12T12:38:12Z'>
		Looks like the problem is &lt;denchmark-link:https://github.com/pfnet/chainer/blob/master/cupy/linalg/product.py#L340&gt;here&lt;/denchmark-link&gt;
.
if not transa:
should be
if transa:
The n,k should be swapped for F-contiguous array and be passed as is for C-contiguous. From the code,
&lt;denchmark-code&gt;shape(A) = (k,n) 
shape(B) = (k,m)
&lt;/denchmark-code&gt;

but gemv invocation goes with n as leading dimension:
gemv(handle, transa, n, k, 1, a.data.ptr, lda, b.data.ptr, incb, 0,
             c.data.ptr, 1)
and this is incorrect. The dimensions should be swapped to (k,n) in this case.
For the C-contiguous case there is no transpose and (n,k) goes as is.
Also the 'incb' should be always 1 for one-dimensional vector (but I can be wrong here).
Edit: Oh, I see &lt;denchmark-link:https://github.com/okuta&gt;@okuta&lt;/denchmark-link&gt;
 has already sorted this out. Thanks.
		</comment>
		<comment id='5' author='c0stya' date='2015-09-15T06:28:03Z'>
		Thank you for the detailed analysis @lightcaster.
		</comment>
		<comment id='6' author='c0stya' date='2015-09-16T04:40:06Z'>
		I added unit tests for Bilinear to confirm the problem reported by &lt;denchmark-link:https://github.com/cemoody&gt;@cemoody&lt;/denchmark-link&gt;
 is certainly resolved.
		</comment>
	</comments>
</bug>