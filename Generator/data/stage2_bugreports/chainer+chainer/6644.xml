<bug id='6644' author='tkerola' open_date='2019-03-27T03:06:19Z' closed_time='2019-11-14T08:51:26Z'>
	<summary>Non-owned input to cuDNN deconvolution with 1-dim data causes error.</summary>
	<description>
The cuDNN implementation of deconv for 1-dim input causes an error if the input does not own its data.
I guess we can fix this by adding (x.shape[1] &gt; 1 or x.flags.owndata) to 


chainer/chainer/functions/connection/deconvolution_2d.py


        Lines 187 to 194
      in
      2615ab6






 use_cudnn = ( 



 chainer.should_use_cudnn('&gt;=auto') 



 and not self.cover_all 



 and x.dtype == W.dtype 



 and ((self.dy == 1 and self.dx == 1) 



 or (_cudnn_version &gt;= 6000 



 and not configuration.config.cudnn_deterministic)) 



 and (self.groups &lt;= 1 or _cudnn_version &gt;= 7000) 





(I'm not sure about exactly what in the cuDNN call causes this though, but the above idea is a possible workaround, what do you think?)
MWE:
&lt;denchmark-code&gt;In [105]: x = xp.ones((100, 28, 28, 1)).astype(np.float32)

In [106]: y = F.moveaxis(x, 3, 1)

In [107]: y.array.flags.owndata
Out[107]: False

In [108]: l1 = L.Deconvolution2D(in_channels=1, out_channels=1, ksize=3, pad=1)

In [109]: l1.to_gpu()
Out[109]: &lt;chainer.links.connection.deconvolution_2d.Deconvolution2D at 0x7f9f1c9ee0b8&gt;

In [110]: z = l1(y)  # Causes cuDNN error
---------------------------------------------------------------------------
CuDNNError                                Traceback (most recent call last)
&lt;ipython-input-110-052cbf70953b&gt; in &lt;module&gt;
----&gt; 1 z = l1(y)  # Causes cuDNN error

/usr/local/lib/python3.6/dist-packages/chainer/link.py in __call__(self, *args, **kwargs)
    271             # forward is implemented in the child classes
    272             forward = self.forward  # type: ignore
--&gt; 273         out = forward(*args, **kwargs)
    274
    275         # Call forward_postprocess hook

/usr/local/lib/python3.6/dist-packages/chainer/links/connection/deconvolution_2d.py in forward(self, x)
    174         return deconvolution_2d.deconvolution_2d(
    175             x, self.W, self.b, self.stride, self.pad, self.outsize,
--&gt; 176             groups=self.groups)
    177
    178

/usr/local/lib/python3.6/dist-packages/chainer/functions/connection/deconvolution_2d.py in deconvolution_2d(x, W, b, stride, pad, outsize, **kwargs)
    444     else:
    445         args = x, W, b
--&gt; 446     y, = func.apply(args)
    447     return y

/usr/local/lib/python3.6/dist-packages/chainer/function_node.py in apply(self, inputs)
    316             else:
    317                 # In normal case, simply run the forward method.
--&gt; 318                 outputs = self.forward(in_data)
    319
    320         # Check for output array types

/usr/local/lib/python3.6/dist-packages/chainer/function_node.py in forward(self, inputs)
    503         assert len(inputs) &gt; 0
    504         if isinstance(inputs[0], cuda.ndarray):
--&gt; 505             return self.forward_gpu(inputs)
    506         return self.forward_cpu(inputs)
    507

/usr/local/lib/python3.6/dist-packages/chainer/functions/connection/deconvolution_2d.py in forward_gpu(self, inputs)
    197         if use_cudnn:
    198             # cuDNN implementation
--&gt; 199             return self._forward_cudnn(x, W, b)
    200
    201         elif self.groups &gt; 1:

/usr/local/lib/python3.6/dist-packages/chainer/functions/connection/deconvolution_2d.py in _forward_cudnn(self, x, W, b)
    266             W, x, b, y, pad, stride, dilation, self.groups,
    267             deterministic=deterministic, auto_tune=auto_tune,
--&gt; 268             tensor_core=tensor_core)
    269
    270         return y,

cupy/cudnn.pyx in cupy.cudnn.convolution_backward_data()

cupy/cudnn.pyx in cupy.cudnn._get_algorithm_bwd_data()

cupy/cuda/cudnn.pyx in cupy.cuda.cudnn.getConvolutionBackwardDataAlgorithm_v6()

cupy/cuda/cudnn.pyx in cupy.cuda.cudnn.check_status()

CuDNNError: CUDNN_STATUS_NOT_SUPPORTED

In [111]: y2 = xp.copy(y.array)

In [112]: y2.flags.owndata                                                                                                                                                                                                                                                                                                                                                                  
Out[112]: True

In [113]: z = l1(y2)  # Works with cuDNN

In [114]: chainer.print_runtime_info()                                                                                                                                                                                                                                                                                                                                                      
Platform: Linux-4.4.0-116-generic-x86_64-with-Ubuntu-18.04-bionic
Chainer: 6.0.0b2
NumPy: 1.16.2
CuPy:
  CuPy Version          : 6.0.0b2
  CUDA Root             : /usr/local/cuda
  CUDA Build Version    : 9020
  CUDA Driver Version   : 10000
  CUDA Runtime Version  : 9020
  cuDNN Build Version   : 7402
  cuDNN Version         : 7402
  NCCL Build Version    : 2307
iDeep: Not Available
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='tkerola' date='2019-03-27T05:09:57Z'>
		I tried L.DeonvolutionND with ndim = 1, 2, 3 and found that L.Deconvolution1D somehow dealt with an input whose owndata flag is False.
environment
&lt;denchmark-code&gt;Platform: Linux-4.4.0-98-generic-x86_64-with-debian-stretch-sid
Chainer: 6.0.0b3
NumPy: 1.16.2
CuPy:
  CuPy Version          : 6.0.0b3
  CUDA Root             : /usr/local/cuda
  CUDA Build Version    : 9020
  CUDA Driver Version   : 9020
  CUDA Runtime Version  : 9020
  cuDNN Build Version   : 7201
  cuDNN Version         : 7201
  NCCL Build Version    : None
  NCCL Runtime Version  : None
iDeep: 2.0.0.post3
&lt;/denchmark-code&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;In [15]: x1d = cp.random.uniform(-1, 1, (10, 28, 1)).astype(cp.float32)

In [16]: _ = L.Deconvolution1D(1, 1, 3, 1).to_gpu()(F.moveaxis(x1d, 2, 1))

In [17]: x3d = cp.random.uniform(-1, 1, (10, 28, 28, 28, 1)).astype(cp.float32)

In [18]: _ = L.Deconvolution3D(1, 1, 3, 1).to_gpu()(F.moveaxis(x3d, 4, 1))
---------------------------------------------------------------------------
CuDNNError                                Traceback (most recent call last)
...
~/code_ghq/github.com/crcrpar/cupy/cupy/cuda/cudnn.pyx in cupy.cuda.cudnn.getConvolutionBackwardDataAlgorithm_v6()

~/code_ghq/github.com/crcrpar/cupy/cupy/cuda/cudnn.pyx in cupy.cuda.cudnn.check_status()

CuDNNError: CUDNN_STATUS_NOT_SUPPORTED

In [19]: F.moveaxis(x1d, 2, 1).array.flags
Out[19]:
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False

In [20]: F.moveaxis(x3d, 4, 1).array.flags
Out[20]:
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False

In [22]: x2d = cp.random.uniform(-1, 1, (10, 28, 28, 1)).astype(cp.float32)

In [23]: _ = L.DeconvolutionND(2, 1, 1, 3, 1).to_gpu()(F.moveaxis(x2d, 3, 1))
---------------------------------------------------------------------------
CuDNNError                                Traceback (most recent call last)
...

~/code_ghq/github.com/crcrpar/cupy/cupy/cuda/cudnn.pyx in cupy.cuda.cudnn.check_status()

CuDNNError: CUDNN_STATUS_NOT_SUPPORTED

In [24]: F.moveaxis(x2d, 3, 1).array.flags
Out[24]:
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : False
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='tkerola' date='2019-07-01T08:22:34Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed after 30 days if no further activity occurs. Thank you for your contributions.
		</comment>
		<comment id='3' author='tkerola' date='2019-10-23T09:33:49Z'>
		The 2-dim case below is fixed by &lt;denchmark-link:https://github.com/cupy/cupy/pull/1885&gt;cupy/cupy#1885&lt;/denchmark-link&gt;
.   is suspicious.

		</comment>
	</comments>
</bug>