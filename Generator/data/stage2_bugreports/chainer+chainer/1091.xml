<bug id='1091' author='jheymann85' open_date='2016-04-05T04:10:21Z' closed_time='2016-04-08T14:04:08Z'>
	<summary>Bug in batch normalization when finetune = True?</summary>
	<description>
Correct me if I'm wrong, but from my understanding, if the option finetune is True, we want to compute the population statistics of the training data so we can use this mean/var during testing.
In the current implementation, once the finetune mode is set, decay gets smaller the more training batches we see. However, the code weights the accumulated mean/var with decay and the current mean/var with 1-decay.
Hence, if N gets very big, self.avg_mean/self.avg_var are almost equal to the mean/var of the current batch. It should be the other way around, e.g. the more data we saw, the less influence should the current mean/var have on the average statistics.
TD;LR decay = 1. / self.N should be replaced by decay = 1. - 1. / self.N
	</description>
	<comments>
		<comment id='1' author='jheymann85' date='2016-04-07T23:06:36Z'>
		Hi. I guess it is a bug that should be fixed. Thank you for reporting!
		</comment>
	</comments>
</bug>