<bug id='3922' author='sonots' open_date='2017-11-20T06:52:14Z' closed_time='2018-06-11T14:00:10Z'>
	<summary>CUDNN_STATUS_BAD_PARAM with Volta Tensor Core</summary>
	<description>
I tried to evaluate v100 Tensor Core with Chainer following &lt;denchmark-link:https://www.slideshare.net/NVIDIAJapan/volta-chainer&gt;https://www.slideshare.net/NVIDIAJapan/volta-chainer&lt;/denchmark-link&gt;
, but I got following errors.
&lt;denchmark-h:h1&gt;Environments&lt;/denchmark-h&gt;


Chainer version: master
CuPy version: master
OS/Platform: ubunt16.04
Python 3.5.2 (/usr/bin/python3 of Ubuntu 16.04)
CUDA/cuDNN version: CUDA9 and cuDNN7
Machine: AWS p3.2xlarge

&lt;denchmark-h:h1&gt;Code to reproduce&lt;/denchmark-h&gt;

I applied following patch to chainer/examples/imagenet/train_imagenet.py because I just did not want to prepare dataset for alex_fp16.
--- a/examples/imagenet/train_imagenet.py
+++ b/examples/imagenet/train_imagenet.py
@@ -27,16 +27,21 @@ import resnet50

 class PreprocessedDataset(chainer.dataset.DatasetMixin):

-    def __init__(self, path, root, mean, crop_size, random=True):
-        self.base = chainer.datasets.LabeledImageDataset(path, root)
-        self.mean = mean.astype('f')
+    def __init__(self, length, root, mean, crop_size, random=True):
+        # self.base = chainer.datasets.LabeledImageDataset(path, root)
+        self.length = int(length)
+        self.mean = mean.astype('float16')
         self.crop_size = crop_size
         self.random = random

     def __len__(self):
-        return len(self.base)
+        return self.length # len(self.base)

     def get_example(self, i):
+        image = np.random.rand(3, self.crop_size, self.crop_size).astype('float16')
+        label = np.random.randint(0, 9, 1, 'int32')[0]
+        return image, label
+
         # It reads the i-th image/label pair and return a preprocessed image.
         # It applies following preprocesses:
         #     - Cropping (random or center rectangular)
@@ -117,7 +122,7 @@ def main():
         model.to_gpu()

     # Load the datasets and mean file
-    mean = np.load(args.mean)
+    mean = np.random.rand(3, model.insize, model.insize).astype('float16') #  np.load(args.mean)
     train = PreprocessedDataset(args.train, args.root, mean, model.insize)
     val = PreprocessedDataset(args.val, args.root, mean, model.insize, False)
     # These iterators load the images with subprocesses running in parallel to
&lt;denchmark-code&gt;python3 chainer/examples/imagenet/train_imagenet.py --arch alex_fp16 --epoch 100 --batchsize 32 --gpu 0 2048 2048
&lt;/denchmark-code&gt;

&lt;denchmark-h:h1&gt;Error messages, stack traces, or logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Exception in main training loop: CUDNN_STATUS_BAD_PARAM: b'CUDNN_STATUS_BAD_PARAM'
Traceback (most recent call last):
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/trainer.py", line 302, in run
    entry.extension(self)
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/reporter.py", line 98, in scope
    yield
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/trainer.py", line 299, in run
    update()
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/updater.py", line 223, in update
    self.update_core()
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/updater.py", line 234, in update_core
    optimizer.update(loss_func, *in_arrays)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/optimizer.py", line 534, in update
    loss = lossfun(*args, **kwds)
  File "/home/sonots/chainer/examples/imagenet/alex.py", line 72, in __call__
    return Alex.__call__(self, F.cast(x, self.dtype), t)
  File "/home/sonots/chainer/examples/imagenet/alex.py", line 31, in __call__
    F.relu(self.conv2(h))), 3, stride=2)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/links/connection/convolution_2d.py", line 159, in __call__
    x, self.W, self.b, self.stride, self.pad, dilate=self.dilate)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/functions/connection/convolution_2d.py", line 495, in convolution_2d
    y, = fnode.apply(args)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/function_node.py", line 245, in apply
    outputs = self.forward(in_data)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/function_node.py", line 337, in forward
    return self.forward_gpu(inputs)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/functions/connection/convolution_2d.py", line 198, in forward_gpu
    y_desc.value, y.data.ptr)
  File "cupy/cuda/cudnn.pyx", line 728, in cupy.cuda.cudnn.convolutionForward
  File "cupy/cuda/cudnn.pyx", line 742, in cupy.cuda.cudnn.convolutionForward
  File "cupy/cuda/cudnn.pyx", line 449, in cupy.cuda.cudnn.check_status
Will finalize trainer extensions and updater before reraising the exception.
Traceback (most recent call last):
  File "/home/sonots/chainer/examples/imagenet/train_imagenet_fp16.py", line 169, in &lt;module&gt;
    main()
  File "/home/sonots/chainer/examples/imagenet/train_imagenet_fp16.py", line 165, in main
    trainer.run()
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/trainer.py", line 313, in run
    six.reraise(*sys.exc_info())
  File "/home/sonots/.local/lib/python3.5/site-packages/six.py", line 693, in reraise
    raise value
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/trainer.py", line 302, in run
    entry.extension(self)
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/reporter.py", line 98, in scope
    yield
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/trainer.py", line 299, in run
    update()
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/updater.py", line 223, in update
    self.update_core()
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/training/updater.py", line 234, in update_core
    optimizer.update(loss_func, *in_arrays)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/optimizer.py", line 534, in update
    loss = lossfun(*args, **kwds)
  File "/home/sonots/chainer/examples/imagenet/alex.py", line 72, in __call__
    return Alex.__call__(self, F.cast(x, self.dtype), t)
  File "/home/sonots/chainer/examples/imagenet/alex.py", line 31, in __call__
    F.relu(self.conv2(h))), 3, stride=2)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/links/connection/convolution_2d.py", line 159, in __call__
    x, self.W, self.b, self.stride, self.pad, dilate=self.dilate)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/functions/connection/convolution_2d.py", line 495, in convolution_2d
    y, = fnode.apply(args)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/function_node.py", line 245, in apply
    outputs = self.forward(in_data)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/function_node.py", line 337, in forward
    return self.forward_gpu(inputs)
  File "/home/sonots/.local/lib/python3.5/site-packages/chainer-4.0.0b1-py3.5.egg/chainer/functions/connection/convolution_2d.py", line 198, in forward_gpu
    y_desc.value, y.data.ptr)
  File "cupy/cuda/cudnn.pyx", line 728, in cupy.cuda.cudnn.convolutionForward
  File "cupy/cuda/cudnn.pyx", line 742, in cupy.cuda.cudnn.convolutionForward
  File "cupy/cuda/cudnn.pyx", line 449, in cupy.cuda.cudnn.check_status
cupy.cuda.cudnn.CuDNNError: CUDNN_STATUS_BAD_PARAM: b'CUDNN_STATUS_BAD_PARAM'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='sonots' date='2017-11-20T06:53:57Z'>
		I added print debug as:
chainer/functions/connection/convolution_2d.py
&lt;denchmark-code&gt;+           print('x.shape', x.shape, 'W.shape', W.shape, 'workspace.shape', workspace.shape, 'y.shape', y.shape)
            libcudnn.convolutionForward(
                handle, one.data, x_desc.value, x.data.ptr,
                filter_desc.value, W.data.ptr, conv_desc.value,
                algo, workspace.data.ptr, workspace_size, zero.data,
                y_desc.value, y.data.ptr)
&lt;/denchmark-code&gt;

I got like:
&lt;denchmark-code&gt;x.shape (32, 3, 227, 227) W.shape (96, 3, 11, 11) workspace.shape (8388608,) y.shape (32, 96, 55, 55)
x.shape (32, 96, 27, 27) W.shape (256, 96, 5, 5) workspace.shape (8388608,) y.shape (32, 256, 27, 27)
Exception in main training loop: CUDNN_STATUS_BAD_PARAM: b'CUDNN_STATUS_BAD_PARAM'
[omitted]
&lt;/denchmark-code&gt;

So, it looks the error occurred when numbers of channels are multiples of 8,  thus when tensor core is used.
		</comment>
		<comment id='2' author='sonots' date='2017-11-20T07:20:53Z'>
		&lt;denchmark-link:https://github.com/anaruse&gt;@anaruse&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='sonots' date='2017-11-27T08:44:29Z'>
		Thank you for reporting an issue, &lt;denchmark-link:https://github.com/sonots&gt;@sonots&lt;/denchmark-link&gt;
.
As a result of the investigation, it was found that the root cause is that work-space size for cuDNN is not sufficient. Please increase the work-space size as follows:
&lt;denchmark-code&gt;ws_size = 128*1024*1024
chainer.cuda.set_max_workspace_size(ws_size)
trainer.run()
&lt;/denchmark-code&gt;

I think that current method to select an algorithm for Tensor Core is not appropriate. Now, I'm preparing a PR that uses safer algorithm selection method showing warning messages when Tensor Core is not available.
		</comment>
		<comment id='4' author='sonots' date='2018-06-11T14:00:09Z'>
		Warning is shown if tensor core algorithm is not selected now &lt;denchmark-link:https://github.com/cupy/cupy/pull/890&gt;cupy/cupy#890&lt;/denchmark-link&gt;
.
Let me close.
		</comment>
	</comments>
</bug>