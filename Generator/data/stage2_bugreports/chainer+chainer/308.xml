<bug id='308' author='beam2d' open_date='2015-08-13T03:47:19Z' closed_time='2015-08-13T06:25:18Z'>
	<summary>split_axis.backward fails on incomplete gradients</summary>
	<description>
When there is a None in the grad_outputs, split_axis fails to backprop the incomplete gradients.
	</description>
	<comments>
		<comment id='1' author='beam2d' date='2015-08-13T03:58:30Z'>
		minimum reproducing example:
import chainer
from chainer import cuda
import chainer.functions as F
from chainer import optimizers
import numpy as np

xs = chainer.Variable(np.array([i for i in range(100)],dtype=np.float32))
_, smaller, _ = F.split_axis(xs, [24,47], axis=0)
smaller.backward()
result:
&lt;denchmark-code&gt;$ python split.py 
Traceback (most recent call last):
  File "split.py", line 11, in &lt;module&gt;
    smaller.backward()
  File "build/bdist.linux-x86_64/egg/chainer/variable.py", line 189, in backward
  File "build/bdist.linux-x86_64/egg/chainer/function.py", line 317, in backward
  File "build/bdist.linux-x86_64/egg/chainer/functions/split_axis.py", line 88, in backward_cpu
ValueError: zero-dimensional arrays cannot be concatenated
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>