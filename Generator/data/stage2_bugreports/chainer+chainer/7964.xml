<bug id='7964' author='gwtnb' open_date='2019-08-17T06:27:18Z' closed_time='2019-09-12T08:10:02Z'>
	<summary>GroupNormalization fails with CHAINER_DTYPE=float16 or CHAINER_DTYPE=mixed16</summary>
	<description>
&lt;denchmark-code&gt;% cat main.py                         
import numpy

import chainer
import chainer.links
import cupy


gn = chainer.links.GroupNormalization(1)
gn.to_gpu()

dtype = chainer.get_dtype()
x = chainer.Variable(cupy.ones((1, 2, 3, 4), dtype=dtype))
y = gn(x)

y.grad = cupy.ones_like(y.array)
y.backward()
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;% CHAINER_DTYPE=float32 python main.py
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;% CHAINER_DTYPE=float16 python main.py
Traceback (most recent call last):
  File "main.py", line 16, in &lt;module&gt;
    y.backward()
  File "/path/to/chainer/chainer/variable.py", line 1470, in backward
    [(node, grad_var)], retain_grad, loss_scale)
  File "/path/to/chainer/chainer/_backprop.py", line 226, in _backprop_to_all
    func, target_input_indexes, out_grad, in_grad, is_debug)
  File "/path/to/chainer/chainer/_backprop_utils.py", line 140, in backprop_step
    _reraise_with_stack(func, e)
  File "/path/to/chainer/chainer/_backprop_utils.py", line 138, in backprop_step
    target_input_indexes, grad_outputs)
  File "/path/to/chainer/chainer/functions/normalization/group_normalization.py", line 122, in backward
    self.dummy_gamma).apply((x,))
  File "/path/to/chainer/chainer/function_node.py", line 325, in apply
    outputs = self.forward(in_data)
  File "/path/to/chainer/chainer/function_node.py", line 518, in forward
    return self.forward_gpu(inputs)
  File "/path/to/chainer/chainer/functions/normalization/group_normalization.py", line 201, in forward_gpu
    'groupnorm_x_hat')(x, self.mean[:, None], self.inv_std[:, None])
  File "cupy/core/_kernel.pyx", line 539, in cupy.core._kernel.ElementwiseKernel.__call__
  File "cupy/core/_kernel.pyx", line 582, in cupy.core._kernel.ElementwiseKernel._decide_params_type
  File "cupy/core/_kernel.pyx", line 292, in cupy.core._kernel._decide_params_type_core
TypeError: Type is mismatched. mean &lt;class 'numpy.float32'&gt; &lt;class 'numpy.float16'&gt; T
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;% CHAINER_DTYPE=mixed16 python main.py
Traceback (most recent call last):
  File "main.py", line 16, in &lt;module&gt;
    y.backward()
  File "/path/to/chainer/chainer/variable.py", line 1470, in backward
    [(node, grad_var)], retain_grad, loss_scale)
  File "/path/to/chainer/chainer/_backprop.py", line 226, in _backprop_to_all
    func, target_input_indexes, out_grad, in_grad, is_debug)
  File "/path/to/chainer/chainer/_backprop_utils.py", line 140, in backprop_step
    _reraise_with_stack(func, e)
  File "/path/to/chainer/chainer/_backprop_utils.py", line 138, in backprop_step
    target_input_indexes, grad_outputs)
  File "/path/to/chainer/chainer/functions/normalization/group_normalization.py", line 122, in backward
    self.dummy_gamma).apply((x,))
  File "/path/to/chainer/chainer/function_node.py", line 325, in apply
    outputs = self.forward(in_data)
  File "/path/to/chainer/chainer/function_node.py", line 518, in forward
    return self.forward_gpu(inputs)
  File "/path/to/chainer/chainer/functions/normalization/group_normalization.py", line 201, in forward_gpu
    'groupnorm_x_hat')(x, self.mean[:, None], self.inv_std[:, None])
  File "cupy/core/_kernel.pyx", line 539, in cupy.core._kernel.ElementwiseKernel.__call__
  File "cupy/core/_kernel.pyx", line 582, in cupy.core._kernel.ElementwiseKernel._decide_params_type
  File "cupy/core/_kernel.pyx", line 292, in cupy.core._kernel._decide_params_type_core
TypeError: Type is mismatched. mean &lt;class 'numpy.float32'&gt; &lt;class 'numpy.float16'&gt; T
&lt;/denchmark-code&gt;

	</description>
	<comments>
	</comments>
</bug>