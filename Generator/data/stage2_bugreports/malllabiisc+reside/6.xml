<bug id='6' author='zhoudayang' open_date='2018-11-20T05:59:30Z' closed_time='2018-11-26T08:34:15Z'>
	<summary>cannot reproduce the result in the paper</summary>
	<description>
hello, I run the code, and I cannot reproduce the result announced in paper, I use the default parameter as your code, what's wrong with this issue?
&lt;denchmark-link:https://user-images.githubusercontent.com/12538446/48754379-7843e880-eccc-11e8-8730-a33b6d561e93.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='zhoudayang' date='2018-11-20T06:00:41Z'>
		the photo showed that the performance of reside is worse than pcnn
		</comment>
		<comment id='2' author='zhoudayang' date='2018-11-20T06:04:40Z'>
		Seems like the model has not converged, you need to train it for more epochs with a lower learning rate. After 3-4 epochs with Adam you can train it further with SGD with learning rate .001 or lower. I think then it should be fine. You can do that easily by executing:
python -restore -name &lt;full_name_of_run&gt; -opt sgd -lr 0.001
		</comment>
		<comment id='3' author='zhoudayang' date='2018-11-20T06:07:08Z'>
		thanks, I will try it again asap.
		</comment>
		<comment id='4' author='zhoudayang' date='2018-11-21T04:14:41Z'>
		Hi &lt;denchmark-link:https://github.com/zhoudayang&gt;@zhoudayang&lt;/denchmark-link&gt;
.
I looked into the problem, there was a slight error in copying hyperparameters. You can pull the code and start afresh training and let it get finished on its own.
python reside.py -name new_train_run -data data/riedel_processed.pkl
After that, you can restore and train the model again with SGD for 2-3 epochs
python reside.py -name new_train_run_xx_xx_xxxx_xx:xx:xx -restore -opt sgd -lr 0.001 -l2 0.0 -epoch 3
Then run python plot_pr.py -name new_train_run_20_11_2018_13:05:18 to get the plot.
		</comment>
	</comments>
</bug>