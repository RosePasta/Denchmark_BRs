<bug id='31' author='jacypne' open_date='2019-05-13T12:34:58Z' closed_time='2019-06-23T14:09:19Z'>
	<summary>OOM appears when training the model</summary>
	<description>
Hi! I have a problom like the issue &lt;denchmark-link:https://github.com/malllabiisc/RESIDE/issues/18&gt;#18&lt;/denchmark-link&gt;
 , and I tried with reduced batch size and dimensions as you answered. I set the batch equal one but it also had same problom,  OOM. My graphics card is Nvidia GeForce RTX 2080ti (11G), why is the memory superimposed when the program is running? Moreover,  when I set the lstm_dim equal 64 and the batch equal 32, I got result auc: 0.397, it didn't match your paper auc: 0.416 on Riedel. Could you please give any help? The error is shown as follow:
&lt;denchmark-link:https://user-images.githubusercontent.com/29938134/57621629-88bf8680-75be-11e9-8563-c1e622b2bbce.PNG&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='jacypne' date='2019-05-13T16:12:06Z'>
		Hi, can you try running it on CPU to check whether it is working or not?
Use larger LSTM dimension like 128 or 192 for matching the reported performance.
		</comment>
		<comment id='2' author='jacypne' date='2019-05-14T04:30:10Z'>
		&lt;denchmark-link:https://github.com/svjan5&gt;@svjan5&lt;/denchmark-link&gt;
 Hi, I am having a same error on Nvidia 1080Ti, it does work on CPU though very slow. Whatever batchsize I try it always runs out of memory. I wonder how we can reproduce the results under these hardware settings?
		</comment>
		<comment id='3' author='jacypne' date='2019-05-14T04:32:55Z'>
		I have trained all the models on 1080Ti only. It used to take around 8gb of memory. I think the new version of Tensorflow might be demanding some more space. Can you try experimenting with 1.8 version?
		</comment>
		<comment id='4' author='jacypne' date='2019-05-14T04:42:40Z'>
		
I have trained all the models on 1080Ti only. It used to take around 8gb of memory. I think the new version of Tensorflow might be demanding some more space. Can you try experimenting with 1.8 version?

Thanks for the hint, I will try and let you know how it goes. 8gb should be alright, we have the same card with 11gb I believe. The strange thing is that it can always start training normally, with reasonable memory usage,  but after some random steps the oom error appears. It seems the cuda memory is stacking up during the training process.
		</comment>
		<comment id='5' author='jacypne' date='2019-05-14T06:14:15Z'>
		
I have trained all the models on 1080Ti only. It used to take around 8gb of memory. I think the new version of Tensorflow might be demanding some more space. Can you try experimenting with 1.8 version?

Hi, we have tried using 1.8, still have the same problem, do you have any other suggestions? could you post a list of the packages you use so we can check?
		</comment>
		<comment id='6' author='jacypne' date='2019-06-23T14:09:19Z'>
		I am sorry for the late reply. I am able to still run my code without any OOM error. You can look at the output of  here: &lt;denchmark-link:https://codebunk.com/b/694343322/&gt;https://codebunk.com/b/694343322/&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>