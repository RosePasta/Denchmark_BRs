<bug id='10' author='csypeng' open_date='2018-08-05T11:17:53Z' closed_time='2018-08-06T05:16:00Z'>
	<summary>Must need GPU?</summary>
	<description>
model/util.py has two following lines that requires GPU.
LineNum 59: order = torch.LongTensor(order).to(sequence_emb.get_device())
LineNum 73: order = torch.LongTensor(order).to(lstm_states[0].get_device())
However, my server has no GPU. When I train my own model using
python train_abstractor.py --no-cuda --path=mypath/abstractor --w2v=mypath/word2vec.128d.226k.bin
I will get the error:
fast_abs_rl/model/util.py", line 73, in reorder_lstm_states
order = torch.LongTensor(order).to(lstm_states[0].get_device())
RuntimeError: _th_get_device is not implemented for type torch.FloatTensor
I just check the doc of pytorch. It says that only GPU tensor has the method get_device().
"For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides. For CPU tensors, an error is thrown." as "RuntimeError: get_device is not implemented for type torch.FloatTensor"
Does the code must need a GPU? Thank you.
	</description>
	<comments>
		<comment id='1' author='csypeng' date='2018-08-06T05:16:00Z'>
		The issue should be fixed now.
NOTE: It is still recommended to use GPU (with CUDA) for both training and evaluation if you want to get a reasonable good result in reasonable amount of time.
		</comment>
	</comments>
</bug>