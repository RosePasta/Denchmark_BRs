<bug id='516' author='kermitt2' open_date='2019-10-23T10:46:03Z' closed_time='2019-11-09T23:16:58Z'>
	<summary>2 issues with n-fold eval</summary>
	<description>
&lt;denchmark-h:h2&gt;Issues&lt;/denchmark-h&gt;



The current n-fold average is based on an average of the macro-average f-scores for the n folds to determine the worst and best fold. It should use the micro-average f-score which is more standard and meaningful. The macro-average is given more as additional information to see the impact of the document-level in the evaluation.


The final average over the 10 folds of the 10 f-scores should be the (macro) average of the micro-average scores and not the (macro) average of the macro-average scores.


&lt;denchmark-h:h2&gt;Example&lt;/denchmark-h&gt;

In the following example (FTB corpus for grobid-ner):
&lt;denchmark-code&gt;Summary results: 
Worst fold

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.96        100          66.67        80           3      
BUSINESS             96.25        84.83        84.05        84.44        326    
INSTITUTION          99.55        82.61        70.37        76           27     
LOCATION             97.99        94.29        92.96        93.62        426    
ORGANISATION         96.81        80.81        72.4         76.37        192    
PERSON               98.55        92.2         90.13        91.16        223    

all (micro avg.)     98.19        89.03        86.13        87.56        1197   
all (macro avg.)     98.19        89.12        79.43        83.6         1197   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1105
Instance-level recall:      87.56

Best fold:

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             100          100          100          100          8      
BUSINESS             95.66        84           84.45        84.22        373    
INSTITUTION          99.74        94.74        75           83.72        24     
LOCATION             98.27        94.46        94.23        94.34        416    
ORGANISATION         96.84        83.71        72.33        77.6         206    
PERSON               98.57        90.58        89.18        89.87        194    

all (micro avg.)     98.18        88.95        86.4         87.66        1221   
all (macro avg.)     98.18        91.25        85.86        88.29        1221   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1100
Instance-level recall:      87.16


Average over 10 folds: 

label                accuracy     precision    recall       f1           support

ARTIFACT             99.94        95.56        81.56        86.63        67     
BUSINESS             95.71        84.8         83.27        84           3537   
INSTITUTION          99.72        88.94        76           81.69        212    
LOCATION             97.95        92.55        93.33        92.93        3778   
ORGANISATION         96.77        81.75        73.97        77.62        1979   
PERSON               98.83        93.32        91.54        92.42        2044   

all (macro avg.)     98.15        89.49        83.28        85.88  

===== Instance-level results =====

Total expected instances:   1262.5
Correct instances:          1110.6
Instance-level recall:      87.97
&lt;/denchmark-code&gt;

Here, worst and best folds are selected based on the macro-average instead of the micro-average (we have actually two similar folds in term of performance, the difference is due to the distribution of entities the documents/sentences).
The final:
&lt;denchmark-code&gt;all (macro avg.)     98.15        89.49        83.28        85.88 
&lt;/denchmark-code&gt;

is an average of the all (macro avg.) of the 10 folds, it should be an average of the all (micro avg.) fields. This average itself over the 10 folds, is an average of 10 values, so this is a "macro" average which does not take into account the global number of entities of every folds in one go.
Below the detailed result of each fold for this example:
&lt;denchmark-code&gt;====================== Fold 0 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_0.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr4964085922044051931.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr3460261874063572567.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             100          100          100          100          8      
BUSINESS             96.34        86.2         86.46        86.33        325    
INSTITUTION          99.75        100          64.71        78.57        17     
LOCATION             97.94        93           93           93           357    
ORGANISATION         97           82.95        77.25        80           189    
PERSON               98.6         92.97        89.12        91.01        193    

all (micro avg.)     98.27        89.37        87.24        88.29        1089   
all (macro avg.)     98.27        92.52        85.09        88.15        1089   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1122
Instance-level recall:      88.91



====================== Fold 1 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_1.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr2063807343207588552.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr3298447510019290458.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.96        100          66.67        80           3      
BUSINESS             96.25        84.83        84.05        84.44        326    
INSTITUTION          99.55        82.61        70.37        76           27     
LOCATION             97.99        94.29        92.96        93.62        426    
ORGANISATION         96.81        80.81        72.4         76.37        192    
PERSON               98.55        92.2         90.13        91.16        223    

all (micro avg.)     98.19        89.03        86.13        87.56        1197   
all (macro avg.)     98.19        89.12        79.43        83.6         1197   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1105
Instance-level recall:      87.56



====================== Fold 2 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_2.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr9083275989560503992.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr4986952311997117473.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.88        88.89        80           84.21        10     
BUSINESS             95.94        88.65        80.95        84.63        357    
INSTITUTION          99.73        94.74        75           83.72        24     
LOCATION             97.95        90.56        94.49        92.48        345    
ORGANISATION         96.25        75           72.19        73.57        187    
PERSON               98.76        92.61        93.42        93.01        228    

all (micro avg.)     98.08        87.99        85.93        86.95        1151   
all (macro avg.)     98.08        88.41        82.68        85.27        1151   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1110
Instance-level recall:      87.96



====================== Fold 3 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_3.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr8743892660771315900.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr4869985208860217753.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             100          100          100          100          8      
BUSINESS             95.66        84           84.45        84.22        373    
INSTITUTION          99.74        94.74        75           83.72        24     
LOCATION             98.27        94.46        94.23        94.34        416    
ORGANISATION         96.84        83.71        72.33        77.6         206    
PERSON               98.57        90.58        89.18        89.87        194    

all (micro avg.)     98.18        88.95        86.4         87.66        1221   
all (macro avg.)     98.18        91.25        85.86        88.29        1221   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1100
Instance-level recall:      87.16



====================== Fold 4 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_4.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr1373252657039401195.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr6048481451685416914.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.93        100          80           88.89        10     
BUSINESS             96.03        87.16        84.17        85.64        379    
INSTITUTION          99.7         84.21        76.19        80           21     
LOCATION             98.03        93.56        93.33        93.45        405    
ORGANISATION         97.18        81.4         76.09        78.65        184    
PERSON               99.07        94.47        93.07        93.77        202    

all (micro avg.)     98.32        89.81        87.34        88.56        1201   
all (macro avg.)     98.32        90.13        83.81        86.73        1201   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1099
Instance-level recall:      87.08



====================== Fold 5 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_5.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr3563467982851258361.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr6247179096245324693.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.96        100          66.67        80           3      
BUSINESS             95.33        80.47        83.38        81.9         331    
INSTITUTION          99.85        89.47        89.47        89.47        19     
LOCATION             97.4         91.71        91.25        91.48        400    
ORGANISATION         96.94        81.98        74.21        77.9         190    
PERSON               98.85        93.5         91.67        92.57        204    

all (micro avg.)     98.05        87.13        86.14        86.63        1147   
all (macro avg.)     98.05        89.52        82.78        85.55        1147   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1101
Instance-level recall:      87.24



====================== Fold 6 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_6.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr6420141884218653468.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr2803049028553295602.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.96        100          83.33        90.91        6      
BUSINESS             94.82        81.42        79.54        80.47        347    
INSTITUTION          99.65        84.21        72.73        78.05        22     
LOCATION             97.88        90.51        94.35        92.39        354    
ORGANISATION         96.79        84.53        73.56        78.66        208    
PERSON               98.61        91.5         90.59        91.04        202    

all (micro avg.)     97.95        86.88        84.9         85.88        1139   
all (macro avg.)     97.95        88.7         82.35        85.25        1139   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1107
Instance-level recall:      87.72



====================== Fold 7 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_7.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr6181989155189614173.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr3525916517893574313.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.92        66.67        100          80           4      
BUSINESS             95.82        86.44        85.08        85.75        382    
INSTITUTION          99.69        80           70.59        75           17     
LOCATION             98.1         93.44        91.44        92.43        327    
ORGANISATION         96.36        81.82        75.33        78.44        227    
PERSON               99.38        97.04        95.17        96.1         207    

all (micro avg.)     98.21        89.28        86.6         87.92        1164   
all (macro avg.)     98.21        84.23        86.27        84.62        1164   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1124
Instance-level recall:      89.06



====================== Fold 8 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_8.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr52889262892285618.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr6706030373640894531.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.85        100          55.56        71.43        9      
BUSINESS             95.57        84.77        82.4         83.57        358    
INSTITUTION          99.85        94.44        85           89.47        20     
LOCATION             98.32        94.03        94.52        94.27        383    
ORGANISATION         96.41        78.06        75           76.5         204    
PERSON               98.7         91.94        90           90.96        190    

all (micro avg.)     98.12        88.14        86.17        87.14        1164   
all (macro avg.)     98.12        90.54        80.41        84.37        1164   

===== Instance-level results =====

Total expected instances:   1262
Correct instances:          1110
Instance-level recall:      87.96



====================== Fold 9 ====================== 
Saving model in /home/lopez/grobid/grobid-home/tmp/nerfr_nfold_9.wapiti
Training input data: /home/lopez/grobid/grobid-home/tmp/nerfr6292576295493581446.train
Evaluation input data: /home/lopez/grobid/grobid-home/tmp/nerfr4664087895338338698.test

===== Field-level results =====

label                accuracy     precision    recall       f1           support

ARTIFACT             99.96        100          83.33        90.91        6      
BUSINESS             95.34        84.05        82.17        83.1         359    
INSTITUTION          99.73        85           80.95        82.93        21     
LOCATION             97.63        90           93.7         91.81        365    
ORGANISATION         97.09        87.26        71.35        78.51        192    
PERSON               99.18        96.39        93.03        94.68        201    

all (micro avg.)     98.15        88.8         85.93        87.34        1144   
all (macro avg.)     98.15        90.45        84.09        86.99        1144   

===== Instance-level results =====

Total expected instances:   1267
Correct instances:          1128
Instance-level recall:      89.03

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='kermitt2' date='2019-10-23T11:05:30Z'>
		In the above example, the final average should be:
&lt;denchmark-code&gt;Average over 10 folds: 

label                accuracy     precision    recall       f1           support

ARTIFACT             99.94        95.56        81.56        86.63        67     
BUSINESS             95.71        84.8         83.27        84           3537   
INSTITUTION          99.72        88.94        76           81.69        212    
LOCATION             97.95        92.55        93.33        92.93        3778   
ORGANISATION         96.77        81.75        73.97        77.62        1979   
PERSON               98.83        93.32        91.54        92.42        2044   

all                  98.15        88.54        86.28        87.39        1161.7
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='kermitt2' date='2019-11-05T22:36:09Z'>
		Note on point 2:

the label averages are the macro averages over the labels results from each fold, is this correct?
by consequence the total average is the average over all the labels, should I just replace this with the average of the micro averages of all the results from each folds?

		</comment>
		<comment id='3' author='kermitt2' date='2019-11-06T07:00:35Z'>
		
the label averages are the macro averages over the labels results from each fold, is this correct?

yes! (I think no change with how it is currently done)

by consequence the total average is the average over all the labels, should I just replace this with the average of the micro averages of all the results from each folds?

yes average of the micro-average from each fold (instead of the average of the macro-average from each fold)
		</comment>
		<comment id='4' author='kermitt2' date='2019-11-06T07:07:37Z'>
		&lt;denchmark-link:https://github.com/kermitt2&gt;@kermitt2&lt;/denchmark-link&gt;
 Thanks!
Could you please test it and let me know if it's working?
		</comment>
		<comment id='5' author='kermitt2' date='2019-11-08T07:33:27Z'>
		It works fine! Best/worse are selected by micro-average f-score and I have the following:
&lt;denchmark-code&gt;Average over 10 folds: 

label                accuracy     precision    recall       f1           support

ARTIFACT             99.94        95.56        81.56        86.63        67     
BUSINESS             95.74        84.93        83.33        84.1         3537   
INSTITUTION          99.73        89.32        76           81.85        212    
LOCATION             97.94        92.46        93.38        92.91        3778   
ORGANISATION         96.75        81.58        73.98        77.54        1979   
PERSON               98.81        93.17        91.49        92.32        2044   

all                  87.39        87.39        87.39        87.39
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='kermitt2' date='2019-11-09T22:03:29Z'>
		Ah I overlooked the averages, we have by error the same average of f-score for accuracy, precision and recall:
&lt;denchmark-code&gt;all                  87.39        87.39        87.39        87.39
&lt;/denchmark-code&gt;

expected is:
&lt;denchmark-code&gt;all                  98.15        88.54        86.28        87.39        1161.7
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='kermitt2' date='2019-11-09T23:16:51Z'>
		fix with &lt;denchmark-link:https://github.com/kermitt2/grobid/commit/b4644c286897c7b831fa90d21cc5fa137192d445&gt;b4644c2&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>