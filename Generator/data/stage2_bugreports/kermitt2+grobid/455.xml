<bug id='455' author='Vitaliy-1' open_date='2019-07-04T11:11:32Z' closed_time='2019-08-09T14:35:10Z'>
	<summary>FullText Model: files are silently rejected from training starting from 0.5.4</summary>
	<description>
The problem appears to be starting from version 0.5.4 and persists on the current master branch.
To reproduce on the default set from the current master branch:
./gradlew train_fulltext
master branch vs 0.5.3
master branch:
&lt;denchmark-code&gt;* Summary
    nb train:    23
    nb labels:   22
    nb blocks:   481337
    nb features: 10589876
&lt;/denchmark-code&gt;

25 files for training overall. Accoding to logs, 0 files are rejected: &lt;denchmark-link:https://github.com/Vitaliy-1/grobid_terminal_output/blob/master/output_default_grobid-master.txt&gt;https://github.com/Vitaliy-1/grobid_terminal_output/blob/master/output_default_grobid-master.txt&lt;/denchmark-link&gt;
 but apparently only 23 from 25 were used for training.
0.5.3:
&lt;denchmark-code&gt;* Summary
    nb train:    25
    nb labels:   22
    nb blocks:   515588
    nb features: 11343398
&lt;/denchmark-code&gt;

According to logs, 0 files are rejected: &lt;denchmark-link:https://github.com/Vitaliy-1/grobid_terminal_output/blob/master/output_default_grobid-0.5.3&gt;https://github.com/Vitaliy-1/grobid_terminal_output/blob/master/output_default_grobid-0.5.3&lt;/denchmark-link&gt;
. All 25 documents are used for training
Terminal outputs are identical.
The problem is more substantial if comparing training of our test corpus from 800+ articles, none of which doesn't pass to the training in any version after 0.5.3 but according to logs 150+ annotated documents should pass sync check.
	</description>
	<comments>
		<comment id='1' author='Vitaliy-1' date='2019-07-04T13:10:58Z'>
		The problem firstly appears in this commit: &lt;denchmark-link:https://github.com/kermitt2/grobid/commit/f6cce2436323c9dff958b7ba6d6c49f801d783bb&gt;f6cce24&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/kermitt2&gt;@kermitt2&lt;/denchmark-link&gt;
, you probably know more about it.
		</comment>
		<comment id='2' author='Vitaliy-1' date='2019-07-04T14:18:14Z'>
		Hello &lt;denchmark-link:https://github.com/Vitaliy-1&gt;@Vitaliy-1&lt;/denchmark-link&gt;
 !
Thanks for reporting the issue.
Actually the problem is when Wapiti reads the training file, it's not silent, the Wapiti error message is:

warning: missing tokens, cannot apply pattern

So some features are missing apparently somewhere in the newly generated raw files. In the commit you indicate, I added a new feature to the model and re-generated the raw file accordingly. It would have been nice if Wapiti was indicating the line number of the problem :/
Interestingly I have only one example rejected by Wapiti on my side with the current master:
&lt;denchmark-code&gt;totalExamples: 25
        epsilon: 1.0E-4
        window: 20
        nb max iterations: 1500
        nb threads: 8
* Load patterns
* Load training data
warning: missing tokens, cannot apply pattern
* Initialize the model
* Summary
    nb train:    24
    nb labels:   22
    nb blocks:   506906
    nb features: 11152394
* Train the model with l-bfgs
...
&lt;/denchmark-code&gt;

I will have a look and try to regenerate the raw files without the issue.
		</comment>
		<comment id='3' author='Vitaliy-1' date='2019-07-08T11:51:37Z'>
		Ahh, yes, I see the message.
This problem is triggered by new data entered into CRF template by this commit: 


grobid/grobid-trainer/resources/dataset/fulltext/crfpp-templates/fulltext.template


        Lines 137 to 145
      in
      f6cce24






 # callout style for bibliographiucal references (1) 



 UM1:%x[0,24] 



 



 # if callout is known for this token (1) 



 UN1:%x[-2,25] 



 UN2:%x[-1,25] 



 UN3:%x[0,25] 



 UN4:%x[1,25] 



 UN5:%x[2,25] 





		</comment>
		<comment id='4' author='Vitaliy-1' date='2019-07-08T11:58:37Z'>
		Yes, those new features are generated here:
&lt;denchmark-link:https://github.com/kermitt2/grobid/blob/master/grobid-core/src/main/java/org/grobid/core/engines/FullTextParser.java#L794&gt;https://github.com/kermitt2/grobid/blob/master/grobid-core/src/main/java/org/grobid/core/engines/FullTextParser.java#L794&lt;/denchmark-link&gt;

using this:
&lt;denchmark-link:https://github.com/kermitt2/grobid/blob/master/grobid-core/src/main/java/org/grobid/core/engines/FullTextParser.java#L375&gt;https://github.com/kermitt2/grobid/blob/master/grobid-core/src/main/java/org/grobid/core/engines/FullTextParser.java#L375&lt;/denchmark-link&gt;

One of those feature should be missing for one token I guess in the case of "generateTrainingData" is used (I didn't see this issue with large file process normally).
		</comment>
		<comment id='5' author='Vitaliy-1' date='2019-07-08T16:24:12Z'>
		After re-generating raw files with Grobid, the problem is more or less solved for our corpus. At least I don't see the message and articles are passing for the training, although the number of articles that pass sync check is slightly different than was before.
So, probably the same would be true and for the default set. I don't have original PDFs to test.
		</comment>
		<comment id='6' author='Vitaliy-1' date='2019-07-10T14:49:18Z'>
		I've re-generated the fulltext feature files and indeed it fixed the problem of number of features (there was certainly something done in-between to solve it, but I don't remember exactly what!).
I have also updated the fulltext model (commit &lt;denchmark-link:https://github.com/kermitt2/grobid/commit/b01c2ad63fb41ba1a48b319468cf0cd5d8882ea5&gt;b01c2ad&lt;/denchmark-link&gt;
) and it improves slightly the header+fulltext and citation matching &lt;denchmark-link:https://github.com/kermitt2/grobid/blob/master/grobid-trainer/doc/PMC_sample_1943.results.grobid-0.5.5-Glutton-09.07.2019&gt;accuracy&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='7' author='Vitaliy-1' date='2019-08-09T14:35:10Z'>
		Thanks! Closing as is resolved.
		</comment>
	</comments>
</bug>