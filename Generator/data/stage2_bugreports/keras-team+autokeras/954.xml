<bug id='954' author='fucker007' open_date='2020-02-10T04:26:11Z' closed_time='2020-04-19T03:53:13Z'>
	<summary>文本分类clf.export_model()出现一下报错，autokeras1.0.1,tensorflow-gpu 2.1.0,请问是怎么回事</summary>
	<description>
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.
Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.layers.core.Dense object at 0x000001A755E62DA0&gt; and &lt;tensorflow.python.keras.layers.core.Dense object at 0x000001A761126940&gt;).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.
Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.layers.core.Dense object at 0x000001A755E62DA0&gt; and &lt;tensorflow.python.keras.layers.core.Dense object at 0x000001A761126940&gt;).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.
Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.layers.core.Dense object at 0x000001A761126940&gt; and &lt;tensorflow.python.keras.layers.advanced_activations.Softmax object at 0x000001A75F4DD630&gt;).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.
Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.layers.core.Dense object at 0x000001A761126940&gt; and &lt;tensorflow.python.keras.layers.advanced_activations.Softmax object at 0x000001A75F4DD630&gt;).
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

ValueError                                Traceback (most recent call last)
 in 
1 #第三步保存查看模型层次
----&gt; 2 clf.export_model()
D:\anaconda\envs\ak1.0\lib\site-packages\autokeras\auto_model.py in export_model(self)
373             with trained weights.
374         """
--&gt; 375         return self.tuner.get_best_model()
D:\anaconda\envs\ak1.0\lib\site-packages\autokeras\engine\tuner.py in get_best_model(self)
35
36     def get_best_model(self):
---&gt; 37         model = super().get_best_models()[0]
38         model.load_weights(self.best_model_path)
39         return model
D:\anaconda\envs\ak1.0\lib\site-packages\kerastuner\engine\tuner.py in get_best_models(self, num_models)
229         """
230         # Method only exists in this class for the docstring override.
--&gt; 231         return super(Tuner, self).get_best_models(num_models)
232
233     def _deepcopy_callbacks(self, callbacks):
D:\anaconda\envs\ak1.0\lib\site-packages\kerastuner\engine\base_tuner.py in get_best_models(self, num_models)
236         """
237         best_trials = self.oracle.get_best_trials(num_models)
--&gt; 238         models = [self.load_model(trial) for trial in best_trials]
239         return models
240
D:\anaconda\envs\ak1.0\lib\site-packages\kerastuner\engine\base_tuner.py in (.0)
236         """
237         best_trials = self.oracle.get_best_trials(num_models)
--&gt; 238         models = [self.load_model(trial) for trial in best_trials]
239         return models
240
D:\anaconda\envs\ak1.0\lib\site-packages\kerastuner\engine\tuner.py in load_model(self, trial)
155         with hm_module.maybe_distribute(self.distribution_strategy):
156             model.load_weights(self._get_checkpoint_fname(
--&gt; 157                 trial.trial_id, best_epoch))
158         return model
159
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\keras\engine\training.py in load_weights(self, filepath, by_name, skip_mismatch)
232         raise ValueError('Load weights is not yet supported with TPUStrategy '
233                          'with steps_per_run greater than 1.')
--&gt; 234     return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
235
236   @trackable.no_automatic_dependency_tracking
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\keras\engine\network.py in load_weights(self, filepath, by_name, skip_mismatch)
1191         save_format = 'h5'
1192     if save_format == 'tf':
-&gt; 1193       status = self._trackable_saver.restore(filepath)
1194       if by_name:
1195         raise NotImplementedError(
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\tracking\util.py in restore(self, save_path)
1281         graph_view=self._graph_view)
1282     base.CheckpointPosition(
-&gt; 1283         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)
1284     load_status = CheckpointLoadStatus(
1285         checkpoint,
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\tracking\base.py in restore(self, trackable)
207         # This object's correspondence with a checkpointed object is new, so
208         # process deferred restorations for it and its dependencies.
--&gt; 209         restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access
210         if restore_ops:
211           self._checkpoint.new_restore_ops(restore_ops)
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\tracking\base.py in _restore_from_checkpoint_position(self, checkpoint_position)
906     restore_ops.extend(
907         current_position.checkpoint.restore_saveables(
--&gt; 908             tensor_saveables, python_saveables))
909     return restore_ops
910
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\tracking\util.py in restore_saveables(self, tensor_saveables, python_saveables)
287              "expecting %s") % (tensor_saveables.keys(), validated_names))
288       new_restore_ops = functional_saver.MultiDeviceSaver(
--&gt; 289           validated_saveables).restore(self.save_path_tensor)
290       if not context.executing_eagerly():
291         for name, restore_op in sorted(new_restore_ops.items()):
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py in restore(self, file_prefix)
253     for device, saver in sorted(self._single_device_savers.items()):
254       with ops.device(device):
--&gt; 255         restore_ops.update(saver.restore(file_prefix))
256     return restore_ops
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\saving\functional_saver.py in restore(self, file_prefix)
100                                           structured_restored_tensors):
101       restore_ops[saveable.name] = saveable.restore(
--&gt; 102           restored_tensors, restored_shapes=None)
103     return restore_ops
104
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\training\saving\saveable_object_util.py in restore(self, restored_tensors, restored_shapes)
114       restored_tensor = array_ops.identity(restored_tensor)
115       return resource_variable_ops.shape_safe_assign_variable_handle(
--&gt; 116           self.handle_op, self._var_shape, restored_tensor)
117
118
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py in shape_safe_assign_variable_handle(handle, shape, value, name)
295   with _handle_graph(handle):
296     value_tensor = ops.convert_to_tensor(value)
--&gt; 297   shape.assert_is_compatible_with(value_tensor.shape)
298   return gen_resource_variable_ops.assign_variable_op(handle,
299                                                       value_tensor,
D:\anaconda\envs\ak1.0\lib\site-packages\tensorflow_core\python\framework\tensor_shape.py in assert_is_compatible_with(self, other)
1108     """
1109     if not self.is_compatible_with(other):
-&gt; 1110       raise ValueError("Shapes %s and %s are incompatible" % (self, other))
1111
1112   def most_specific_compatible_shape(self, other):
ValueError: Shapes (20000, 32) and (32, 32) are incompatible
	</description>
	<comments>
		<comment id='1' author='fucker007' date='2020-02-10T04:28:49Z'>
		&lt;denchmark-link:https://github.com/kthakore&gt;@kthakore&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='fucker007' date='2020-02-10T17:12:07Z'>
		&lt;denchmark-link:https://github.com/fucker007&gt;@fucker007&lt;/denchmark-link&gt;
 Would you paste your code for reproducing this bug? Thanks.
		</comment>
		<comment id='3' author='fucker007' date='2020-02-11T03:11:46Z'>
		#!/usr/bin/env python
# coding: utf-8
import autokeras as ak
from autokeras import TextClassifier
import csv
import numpy as np
import pandas as pd
import matplotlib
import os
clf = TextClassifier()#获取分类器
data_path = "../data2/" #数据存储的路径
data = pd.DataFrame() #数据存储的位置
csvFile = open("data2/total.csv","r",encoding='utf-8')
df_ = pd.read_csv(csvFile)
data = data.append(df_)
y_train = data["ItemName"].values  
data['Length'],data['Depth'],data['Height'],data['Volume'],data['Surface'] = data['Length'].astype('str'),data['Depth'].astype('str'),data['Height'].astype('str'),data['Volume'].astype('str'),data['Surface'].astype('str')
x_train = data["ElementName"].str.cat([
    data['FamilyName'],
    data['CategoryName'],
    data['Length'],
    data['Depth'],
    data['Height'],
    data['Volume'],
    data['Surface']],
    sep='_')  #行拼接
x_train = np.array(x_train ,dtype=np.str)
# print(x_train)  #array，每個元素為每行中幾個屬性拼接起來的字符串
# print(x_train[1]) #工法桩 850mm_混凝土-圆形-柱_结构柱_2.7887139107610888_2.7791890388965257_78.41207349081365_607.7220435970835_888.682356823353

# y_train[12000] #'钻孔灌注桩立柱桩'
# type(y_train[12000]) #str
y_train = np.array(y_train ,dtype=np.str)
# y_train[12000] #'钻孔灌注桩立柱桩'
# type(y_train[12000]) #numpy.str_


print(x_train.shape,y_train.shape) #(12955,) (12955, 1)
x_train,y_train = x_train.reshape(-1),y_train.reshape(-1,1)#-1是模糊控制的意思 比如人reshape（-1,2）固定2列 多少行不知道
#reshape獲取可以省略
print(x_train.shape,y_train.shape) # (12955,) (12955, 1)

#第二步将数据加入模型
import autokeras as ak
input_node = ak.TextInput()
output_node = ak.TextBlock(vectorizer='ngram')(input_node)
output_node = ak.ClassificationHead()(output_node)
clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)
clf.fit(x_train, y_train,verbose=1)
#第三步保存查看模型层次
clf.export_model()
&lt;denchmark-link:https://github.com/haifeng-jin&gt;@haifeng-jin&lt;/denchmark-link&gt;
 this is my code
		</comment>
		<comment id='4' author='fucker007' date='2020-02-12T02:36:08Z'>
		&lt;denchmark-link:https://github.com/fucker007&gt;@fucker007&lt;/denchmark-link&gt;

This is not the right data for text input. Currently, we are only supporting natural language like inputs to TextInput.
The separate character between words should be spaces.
Otherwise, it might not work.
		</comment>
		<comment id='5' author='fucker007' date='2020-04-12T02:54:45Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>