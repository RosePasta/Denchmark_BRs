<bug id='218' author='wenyawei' open_date='2018-09-25T09:10:03Z' closed_time='2018-09-29T21:01:53Z'>
	<summary>out of memory</summary>
	<description>
&lt;denchmark-h:h3&gt;Bug Description&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Reproducing Steps&lt;/denchmark-h&gt;

I run autokeras with my own dataset, and the size is:
&lt;denchmark-code&gt;(196, 60, 60, 3)
(196,)
&lt;/denchmark-code&gt;

When I run it after 205 models, it CANNOT create new model to run. The log is
&lt;denchmark-code&gt;╒==============================================╕
|              Training model 205              |
╘==============================================╛
/home/adt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
                                                                           out of memory
/home/adt/anaconda3/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
  len(cache))
&lt;/denchmark-code&gt;

My GPU is GTX 1080Ti, and the memory is 12GB.
&lt;denchmark-h:h3&gt;It continue to run&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Setup Details&lt;/denchmark-h&gt;

Include the details about the versions of:

OS type and version: Ubuntu 1804
Python:  3.6
autokeras: 
scikit-learn: 0.19.1
numpy: 1.14.5
keras: 2.22
tensorflow: 1.10
pytorch: 0.41

	</description>
	<comments>
		<comment id='1' author='wenyawei' date='2018-09-26T15:27:23Z'>
		I received the same error, but on Model 1. I never reach more than two models.
I read here that maybe the problem is the autokeras generates heavy models to try.
		</comment>
		<comment id='2' author='wenyawei' date='2018-09-29T21:01:53Z'>
		&lt;denchmark-link:https://github.com/wenyawei&gt;@wenyawei&lt;/denchmark-link&gt;
 Thank you for your report.
It is an expected behavior.
It would affect the search too much.
Thanks.
		</comment>
	</comments>
</bug>