<bug id='342' author='psinger' open_date='2018-11-26T11:00:06Z' closed_time='2019-08-19T04:31:55Z'>
	<summary>TextClassifier memory issues</summary>
	<description>
I constantly run into memory issues when working with moderately sized text data in the new TextClassifier. Apparently, the problematic lines are for example:
x_train = x_train.astype('float64') in validate_xy(x, y) or x_train = model.predict(x_train) in processing.
For text pre-processing, it appears to me that the whole matrix is loaded to memory and batch_size is completely ignored. For example, the batch_size parameter of fit has no impact.
	</description>
	<comments>
		<comment id='1' author='psinger' date='2019-08-12T03:55:39Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>