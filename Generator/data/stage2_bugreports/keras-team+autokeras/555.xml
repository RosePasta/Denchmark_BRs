<bug id='555' author='kylechang523' open_date='2019-02-26T22:31:02Z' closed_time='2019-03-26T22:30:59Z'>
	<summary>Why Mlp module use conv.py?</summary>
	<description>
&lt;denchmark-h:h3&gt;Bug Description&lt;/denchmark-h&gt;

When I using the Mlp module for training the dataset with shape (897000,43), it can work for some model. However when i extend the training time, there is a bug saying 'weight should at least have at  least two dimensions' appearing. We check the source code and this because the mlp module using convolution method in pytorch. This seems very strange.
May I ask how to solve this problem?
&lt;denchmark-h:h3&gt;Reproducing Steps&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

Step 1: ...
Step 2: ...

&lt;denchmark-h:h3&gt;Expected Behavior&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Setup Details&lt;/denchmark-h&gt;

Include the details about the versions of:

OS type and version:
Python: 3.6
autokeras: 0.3.7
scikit-learn: 0.20.2
numpy:
keras:
scipy:
tensorflow: 1.12.0
pytorch:

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='kylechang523' date='2019-02-28T07:57:19Z'>
		I have the exact same issue using the MlpModule. The training work for a few models and then throws an error saying weight should have at least two dimensions.
Any ideas will be appreciated.
Here is the traceback:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "py36/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "py36/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "py36/lib/python3.6/site-packages/autokeras/search.py", line 350, in train
    raise e
  File "py36/lib/python3.6/site-packages/autokeras/search.py", line 343, in train
    verbose=verbose).train_model(**trainer_args)
  File "py36/lib/python3.6/site-packages/autokeras/nn/model_trainer.py", line 137, in train_model
    self._train()
  File "py36/lib/python3.6/site-packages/autokeras/nn/model_trainer.py", line 173, in _train
    outputs = self.model(inputs)
  File "py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 123, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 133, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "py36/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 77, in parallel_apply
    raise output
  File "py36/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 53, in _worker
    output = module(*input, **kwargs)
  File "py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "py36/lib/python3.6/site-packages/autokeras/nn/graph.py", line 686, in forward
    temp_tensor = torch_layer(edge_input_tensor)
  File "py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "py36/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 421, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: weight should have at least two dimensions
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='kylechang523' date='2019-02-28T13:32:52Z'>
		After more extensive testing, I'm able to add some information:
Each time the error is thrown, the last added operation in the log is either to_add_skip_model or to_concat_skip_model. It's also the first time they are called.
I'm able to reproduce the bug easily with the small iris dataset in less than 5 minutes with the following code:
from sklearn import datasets
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from autokeras import MlpModule
from autokeras.nn.loss_function import classification_loss
from autokeras.nn.metric import Accuracy
from autokeras.preprocessor import DataTransformerMlp

iris = datasets.load_iris()

X = iris.data
Y = iris.target.reshape(-1, 1)

encoder = OneHotEncoder(sparse=False)
encoder.fit(Y)
Y_encoded = encoder.transform(Y)
n_classes = len(Y_encoded[0])

x_train, x_test, y_train, y_test = train_test_split(
        X,
        Y_encoded,
        test_size=0.33)

data_transformer = DataTransformerMlp(x_train)
train_data = data_transformer.transform_train(x_train, y_train)
test_data = data_transformer.transform_test(x_test, y_test)

clf = MlpModule(loss=classification_loss,
                metric=Accuracy,
                searcher_args={},
                verbose=True,
                path='./result_tmp/')

clf.fit(n_output_node=n_classes,
        input_shape=train_data.dataset.dataset.shape,
        train_data=train_data,
        test_data=test_data,
        time_limit=1 * 5 * 60)

clf.final_fit(train_data,
              test_data,
              retrain=False,
              trainer_args={
                  'max_iter_num': 20,
                  'max_no_improvement_num': 5
                  })
Unfortunately, my knowledge on the project is too low for me to dig deeper.
		</comment>
		<comment id='3' author='kylechang523' date='2019-03-02T20:46:54Z'>
		I think this is a bug. we need to figure out a way to prevent it from calling these two functions in the MLP module.
		</comment>
		<comment id='4' author='kylechang523' date='2019-03-08T02:27:49Z'>
		This sounds similar to the bug I just opened &lt;denchmark-link:https://github.com/keras-team/autokeras/issues/570&gt;#570&lt;/denchmark-link&gt;
, except that it complains that i should have at least three dimensions. Also, mine occurred at line 451 in conv.py but looks like same area.
		</comment>
		<comment id='5' author='kylechang523' date='2019-03-15T15:55:23Z'>
		Stuck here with the same bug. To add on, hoping it might help: for me it stops with the exact same exception and it does so consistently on the third model training ("training model 2") irrespective of the input regression data.
Just to let you know: very much looking forward to using this when fixed. Your project's very much appreciated.
		</comment>
	</comments>
</bug>