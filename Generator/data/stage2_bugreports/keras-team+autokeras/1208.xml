<bug id='1208' author='PascalSchimmler' open_date='2020-06-25T09:51:29Z' closed_time='2020-07-15T20:57:02Z'>
	<summary>Autokeras 1.0.3 restarting training for 1 epoch after training</summary>
	<description>
&lt;denchmark-h:h3&gt;Bug Description&lt;/denchmark-h&gt;

I updated from 1.0.2 to 1.0.3 and ran the same code, 1.0.3 retrains the model (still with the model.fit function)
for 1 epoch after the last trial has ended and model.export() seems to take this retrained model.
This results in a very poorly trained model.
Example output of Tf 2.2.0 + Ak 1.0.3:
[Trial complete]
[Trial summary]
|-Trial ID: 8250363f50777f4dad9d3c983a581481
|-Score: 1313.1522216796875
|-Best step: 4

Hyperparameters:
|-optimizer: adam
|-regression_head_1/dropout_rate: 0.0
|-rnn_block_1/bidirectional: True
|-rnn_block_1/layer_type: gru
|-rnn_block_1/num_layers: 1
9/9 [==============================] - 19s 2s/step - loss: 2780.6660 - mean_squared_error: 2780.6660 - val_loss: 4133.9131 - val_mean_squared_error: 4133.9131
79.95622976590295

Same model training stuff etc, but Tf 2.1.0 + Ak 1.0.2:
&lt;denchmark-h:h3&gt;Bug Reproduction&lt;/denchmark-h&gt;

Code for reproducing the bug:
In order to make this model work I changed the Autokeras sourcecode a bit, in particular the RNNBlock.
It has to have the parameter "mask_value" and then of course self.mask_value = mask_value
Then just look through the rnnblock and add the marked lines:
&lt;denchmark-code&gt;   in_layer = rnn_layers[layer_type]

        mask = layers.Masking(mask_value=self.mask_value, input_shape=shape) # TODO: added
        output_node = mask(output_node) # TODO: added
        for i in range(num_layers):
            return_sequences = True
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;import autokeras as ak
import numpy as np
import os
from sklearn.metrics import mean_squared_error
from math import sqrt

def RMSE(y_test, y_prediction):
	pred = y_prediction[:,-1]
	grnTrth = y_test[:,-1]
	return sqrt(mean_squared_error(grnTrth, pred))

def RNN_Default(directory, maxTrials):
	input = ak.Input()
	output = ak.RNNBlock(return_sequences=True, mask_value = 10000.)(input)
	output = ak.RegressionHead()(output)

	autoModel = ak.AutoModel(
		inputs=input,
		outputs=output,
		max_trials=maxTrials,
		directory=directory,
		overwrite=True
	)
	return autoModel

base_folder = r'C:\...\src\test\\'  CHANGE THIS

x_test = np.load(os.path.join(base_folder, 'test_x.npy'))
y_test = np.load(os.path.join(base_folder, 'test_x.npy'))
x_train = np.load(os.path.join(base_folder, 'x_train.npy'))
y_train = np.load(os.path.join(base_folder, 'y_train.npy'))
x_val= np.load(os.path.join(base_folder, 'x_val.npy'))
y_val = np.load(os.path.join(base_folder, 'y_val.npy'))

model = RNN_Default(maxTrials=2, directory=base_folder)

model.fit(x=x_train, y=y_train,
					  validation_data = (x_val, y_val),
					  validation_split=0,
					  epochs=5,
					  )

model = model.export_model()
y_prediction = model.predict(x_test)
print(RMSE(y_test, y_prediction))

&lt;/denchmark-code&gt;

Data used by the code:
&lt;denchmark-link:https://github.com/keras-team/autokeras/files/4830377/data.zip&gt;data.zip&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Expected Behavior&lt;/denchmark-h&gt;

Model trains and the best model is exported
&lt;denchmark-h:h3&gt;Setup Details&lt;/denchmark-h&gt;

Include the details about the versions of:

OS type and version: Windows 10
Python:  Python 3.6.7
autokeras: 1.0.3
keras-tuner: 1.0.2rc0
scikit-learn: 0.21.1
numpy: 1.16.3
pandas: 0.25.0
tensorflow: 2.2.0

	</description>
	<comments>
		<comment id='1' author='PascalSchimmler' date='2020-07-12T08:32:46Z'>
		Same here but not only one epoch, I have 4 trials after resuming more than one training processes and training ends with export of a very bad model comparing to previous saved metrics (i do not use validation split and have separate validation tf.dataset).
I train 2 different models at the same time on different gpus and in different project directories. I had low disk space and my processes stopped, but I started them at different time and that is why first process stopped at trial 267 and second stopped at trial 78. After I cleared disk space and resumed processes both of them got same 4 more trials and finished training with exporting. The finished "best_model" was 20% worse than several models in saved checkpoints by saved metrics (compared manually).
I expected that after resuming the train process my previous best models would be compared to new "current best" model. And the fact that when I resumed both processes I got same low number of trials is suspicious. I had practically the same behaviour when interrupt the process by ctrl+c and resume it after - the training process does not last more than several trials not more than 4 even if I interupt at one finished trial.
Is this a bug or I missed something, &lt;denchmark-link:https://github.com/haifeng-jin&gt;@haifeng-jin&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='2' author='PascalSchimmler' date='2020-07-15T20:56:58Z'>
		&lt;denchmark-link:https://github.com/I-Kryachko&gt;@I-Kryachko&lt;/denchmark-link&gt;
 It seems you are experiencing multiple bugs while using AutoKeras.
We would like to schedule a video call with you to see if we can help you solve the problems.
And we also have some questions about your experience in using AutoKeras.
Would you like to do it? You can ping me on slack. &lt;denchmark-link:https://autokeras.com/#community&gt;https://autokeras.com/#community&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>