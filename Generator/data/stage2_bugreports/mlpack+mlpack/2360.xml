<bug id='2360' author='mrityunjay-tripathi' open_date='2020-04-07T15:07:51Z' closed_time='2020-04-14T05:48:21Z'>
	<summary>error in backward function in log softmax</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue description&lt;/denchmark-h&gt;

The backward function of log_softmax.hpp doesn't give the correct output.
&lt;denchmark-h:h4&gt;Steps to reproduce&lt;/denchmark-h&gt;

In mlpack:
&lt;denchmark-code&gt;#include &lt;bits/stdc++.h&gt;
#include &lt;mlpack/core.hpp&gt;
#include &lt;mlpack/methods/ann/layer/log_softmax.hpp&gt;

using namespace std;
using namespace mlpack::ann;
using namespace arma;

int main()
{
  arma::mat input = arma::mat("0.1; 0.9");
  arma::mat output, gy = arma::ones(2, 1), g;
  // May be I am not using 'gy' in correct way.

  LogSoftMax&lt;&gt; module;
  module.Forward(input, output);
  output.print("Forward:");
  module.Backward(output, gy, g);
  g.print("Backward:");
}
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;Forward:
  -1.1711
  -0.3711
Backward:
  1.31003 
  1.68997
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Expected behavior&lt;/denchmark-h&gt;

In PyTorch
&lt;denchmark-code&gt;import torch
import torch.nn as nn
input = torch.tensor([0.1, 0.9], requires_grad = True)
output = nn.LogSoftmax()(input)
print("Forward:", output)
output.backward(torch.ones(2))
print("Backward:", input.grad)
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;Forward: tensor([-1.1711, -0.3711], grad_fn=&lt;LogSoftmaxBackward&gt;)
Backward: tensor([ 0.3799, -0.3799])
&lt;/denchmark-code&gt;

Probably, the code in the backward function of  adds  in place of the &lt;denchmark-link:https://en.wikipedia.org/wiki/Kronecker_delta&gt;Kronecker-Delta&lt;/denchmark-link&gt;
 function.
Or am I doing something fundamentally wrong?
	</description>
	<comments>
		<comment id='1' author='mrityunjay-tripathi' date='2020-04-09T07:00:20Z'>
		Alos, log_softmax doesn't pass JacobianTest when I tested it locally as the error was around 0.8.
		</comment>
	</comments>
</bug>