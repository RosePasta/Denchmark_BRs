<bug id='479' author='davudadiguezel' open_date='2015-11-20T15:21:50Z' closed_time='2015-11-24T18:26:46Z'>
	<summary>hmm_train number of gaussians</summary>
	<description>
Hi,
I am just playing around with hmm_train and experience some problems with the number of gaussians. I don't have a strategy on how to decide the number of gaussians, yet. So I just tried some.
With values around five everything seems to be fine. But with 10 and above I get
error: Mat::col(): index out of bounds
terminate called after throwing an instance of 'std::logic_error'
I run it like this:
./hmm_train -i observationPKM.csv -n 13 -t gmm -g 10 -o hmm.xml -l labels.csv
Also the Debug informations look like this:
[DEBUG] Covariance matrix is not positive definite.  Adding perturbation.
[DEBUG] Covariance matrix is not positive definite.  Adding perturbation.
[DEBUG] Covariance matrix is not positive definite.  Adding perturbation.
[DEBUG] Covariance matrix is not positive definite.  Adding perturbation.
[DEBUG] Covariance matrix is not positive definite.  Adding perturbation.
[DEBUG] Covariance matrix is not positive definite.  Adding perturbation.
[DEBUG] Covariance matrix is not positive definite.  Adding perturbation.
[DEBUG] Point 4 assigned to empty cluster 0.
[DEBUG] Point 5 assigned to empty cluster 2.
[DEBUG] Point 6 assigned to empty cluster 3.
...
Is this normal? And is there an upper limit to the number of gaussian?
Greetings
Davud
	</description>
	<comments>
		<comment id='1' author='davudadiguezel' date='2015-11-20T18:26:47Z'>
		Hi Davud,
Consider running with '-v' (--verbose) for more output.  I think that one issue might be that you don't have labeled points from every state.  If that was the problem, it should be fixed in &lt;denchmark-link:https://github.com/mlpack/mlpack/commit/2eface7b7a0add7d155c151158dce277d2237e4d&gt;2eface7&lt;/denchmark-link&gt;
.  Another possible issue would have been that invalid labels were specified; if so, it should be fixed in &lt;denchmark-link:https://github.com/mlpack/mlpack/commit/fa8919245e69fb9dbfa98e43f6c060213e6a1937&gt;fa89192&lt;/denchmark-link&gt;
.
If neither of those fix your issue, if you can get me a copy of observationPKM.csv and labels.csv, I can reproduce it and dig deeper.
There is no restriction on the number of Gaussians, but note that as you add more and more Gaussians to the GMM, if you don't have many samples, you may have stability issues with the empirical covariance matrices (the debug messages that mention that the covariance matrix is not positive definite could be an indicator of this).
		</comment>
		<comment id='2' author='davudadiguezel' date='2015-11-24T08:57:36Z'>
		Hi Ryan,
I got some more output with -v and with gdb:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

[INFO ] GMM::Estimate(): log-likelihood of trained GMM is 9248.34.
[INFO ] Cluster 1 is empty.
[DEBUG] Point 63 assigned to empty cluster 1.
[INFO ] Cluster 2 is empty.
[DEBUG] Point 42 assigned to empty cluster 2.
[INFO ] Cluster 4 is empty.
[DEBUG] Point 43 assigned to empty cluster 4.
[INFO ] Cluster 5 is empty.
error: Mat::col(): index out of bounds
terminate called after throwing an instance of 'std::logic_error'
what():  Mat::col(): index out of bounds
Program received signal SIGABRT, Aborted.
0x00007ffff651fcc9 in __GI_raise (sig=sig@entry=6)
at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
56      ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) bt
#0  0x00007ffff651fcc9 in __GI_raise (sig=sig@entry=6)
at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/1&gt;#1&lt;/denchmark-link&gt;
  0x00007ffff65230d8 in __GI_abort () at abort.c:89
&lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2&gt;#2&lt;/denchmark-link&gt;
  0x00007ffff6e2a535 in __gnu_cxx::__verbose_terminate_handler() ()
from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/3&gt;#3&lt;/denchmark-link&gt;
  0x00007ffff6e286d6 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
&lt;denchmark-link:https://github.com/mlpack/mlpack/pull/4&gt;#4&lt;/denchmark-link&gt;
  0x00007ffff6e28703 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
&lt;denchmark-link:https://github.com/mlpack/mlpack/pull/5&gt;#5&lt;/denchmark-link&gt;
  0x00007ffff6e28922 in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/6&gt;#6&lt;/denchmark-link&gt;
  0x00000000005c39f7 in arma::arma_stop&lt;char const*&gt; (
x=@0x7fffffffabf8: 0x677e20 "Mat::col(): index out of bounds")
at /usr/include/armadillo_bits/debug.hpp:113
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/7&gt;#7&lt;/denchmark-link&gt;
  0x00000000005e5e52 in arma::arma_check&lt;char [32]&gt; (state=true, x=...)
at /usr/include/armadillo_bits/debug.hpp:358
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/8&gt;#8&lt;/denchmark-link&gt;
  0x0000000000617ddd in col (col_num=77, this=0x7fffffffc8d0)
at /usr/include/armadillo_bits/Mat_meat.hpp:2588
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/9&gt;#9&lt;/denchmark-link&gt;
  mlpack::kmeans::MaxVarianceNewCluster::EmptyCluster&lt;mlpack::metric::LMetric&lt;2, true&gt;, arma::Mat &gt; (this=0xb72460, data=..., emptyCluster=5, oldCentroids=..., newCentroids=...,
clusterCounts=..., metric=..., iteration=0)
at /org/share/home/adigueze/mlpack-master/src/mlpack/../mlpack/methods/kmeans/max_variance_new_cluster_impl.hpp:58
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/10&gt;#10&lt;/denchmark-link&gt;
 0x0000000000610b56 in mlpack::kmeans::KMeans&lt;mlpack::metric::LMetric&lt;2, true&gt;, mlpack::kmeans::RandomPartition, mlpack::kmeans::MaxVarianceNewCluster, mlpack::kmeans::NaiveKMeans, arma::Mat &gt;::Cluster (this=0xb72450, data=..., clusters=10, centroids=...,
initialGuess=false)
at /org/share/home/adigueze/mlpack-master/src/mlpack/../mlpack/methods/kmeans/kmeans_impl.hpp:160
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/11&gt;#11&lt;/denchmark-link&gt;
 0x0000000000609bc0 in mlpack::kmeans::KMeans&lt;mlpack::metric::LMetric&lt;2, true&gt;, mlpack::kmeans::RandomPartition, mlpack::kmeans::MaxVarianceNewCluster, mlpack::kmeans::NaiveKMeans, arma::Mat &gt;::Cluster (this=0xb72450, data=..., clusters=10, assignments=..., centroids=...,
initialAssignmentGuess=false, initialCentroidGuess=false)
at /org/share/home/adigueze/mlpack-master/src/mlpack/../mlpack/methods/kmeans/kmeans_impl.hpp:241
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/12&gt;#12&lt;/denchmark-link&gt;
 0x0000000000602135 in mlpack::kmeans::KMeans&lt;mlpack::metric::LMetric&lt;2, true&gt;, mlpack::kmeans::RandomPartition, mlpack::kmeans::MaxVarianceNewCluster, mlpack::kmeans::NaiveKMeans, arma::Mat &gt;::Cluster (this=0xb72450, data=..., clusters=10, assignments=...,
initialGuess=false)
at /org/share/home/adigueze/mlpack-master/src/mlpack/../mlpack/methods/kmeans/kmeans_impl.hpp:64
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/13&gt;#13&lt;/denchmark-link&gt;
 0x00000000005fcb75 in mlpack::gmm::EMFit&lt;mlpack::kmeans::KMeans&lt;mlpack::metric::LMetric&lt;2, true&gt;, mlpack::kmeans::RandomPartition, mlpack::kmeans::MaxVarianceNewCluster, mlpack::kmeans::NaiveKMeans, arma::Mat &gt;, mlpack::gmm::PositiveDefiniteConstraint&gt;::InitialClustering
(this=0xb72440, observations=..., dists=..., weights=...)
at /org/share/home/adigueze/mlpack-master/src/mlpack/../mlpack/methods/gmm/em_fit_impl.hpp:214
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/14&gt;#14&lt;/denchmark-link&gt;
 0x00000000005f3524 in mlpack::gmm::EMFit&lt;mlpack::kmeans::KMeans&lt;mlpack::metric::LMetric&lt;2, true&gt;, mlpack::kmeans::RandomPartition, mlpack::kmeans::MaxVarianceNewCluster, mlpack::kmeans::NaiveKMeans, arma::Mat &gt;, mlpack::gmm::PositiveDefiniteConstraint&gt;::Estimate (
this=0xb72440, observations=..., dists=..., weights=..., useInitialModel=false)
---Type  to continue, or q  to quit---
at /org/share/home/adigueze/mlpack-master/src/mlpack/../mlpack/methods/gmm/em_fit_impl.hpp:39
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/15&gt;#15&lt;/denchmark-link&gt;
 0x00000000005e81d5 in mlpack::gmm::GMM&lt;mlpack::gmm::EMFit&lt;mlpack::kmeans::KMeans&lt;mlpack::metric::LMetric&lt;2, true&gt;, mlpack::kmeans::RandomPartition, mlpack::kmeans::MaxVarianceNewCluster, mlpack::kmeans::NaiveKMeans, arma::Mat &gt;, mlpack::gmm::PositiveDefiniteConstraint&gt; &gt;::Estimate (this=0x9a3ed0, observations=..., trials=1, useExistingModel=false)
at /org/share/home/adigueze/mlpack-master/src/mlpack/../mlpack/methods/gmm/gmm_impl.hpp:190
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/16&gt;#16&lt;/denchmark-link&gt;
 0x00000000005dbdbf in mlpack::hmm::HMM&lt;mlpack::gmm::GMM&lt;mlpack::gmm::EMFit&lt;mlpack::kmeans::KMeans&lt;mlpack::metric::LMetric&lt;2, true&gt;, mlpack::kmeans::RandomPartition, mlpack::kmeans::MaxVarianceNewCluster, mlpack::kmeans::NaiveKMeans, arma::Mat &gt;, mlpack::gmm::PositiveDefiniteConstraint&gt; &gt; &gt;::Train (this=0x7fffffffd790, dataSeq=..., stateSeq=...)
at /org/share/home/adigueze/mlpack-master/src/mlpack/methods/hmm/hmm_impl.hpp:274
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/17&gt;#17&lt;/denchmark-link&gt;
 0x00000000005d0b53 in Train::Apply&lt;mlpack::hmm::HMM&lt;mlpack::gmm::GMM&lt;mlpack::gmm::EMFit&lt;mlpack::kmeans::KMeans&lt;mlpack::metric::LMetric&lt;2, true&gt;, mlpack::kmeans::RandomPartition, mlpack::kmeans::MaxVarianceNewCluster, mlpack::kmeans::NaiveKMeans, arma::Mat &gt;, mlpack::gmm::PositiveDefiniteConstraint&gt; &gt; &gt; &gt; (hmm=..., trainSeqPtr=0x7fffffffd420)
at /org/share/home/adigueze/mlpack-master/src/mlpack/methods/hmm/hmm_train_main.cpp:146
&lt;denchmark-link:https://github.com/mlpack/mlpack/issues/18&gt;#18&lt;/denchmark-link&gt;
 0x00000000005c3335 in main (argc=15, argv=0x7fffffffe148)
at /org/share/home/adigueze/mlpack-master/src/mlpack/methods/hmm/hmm_train_main.cpp:320
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

There is a "no such file" - error, but I don't think it comes from me. I am pretty that I have labels for every state and I don't get invalid label errors.
Here are my files:
&lt;denchmark-link:https://github.com/mlpack/mlpack/files/42512/observationPKM.csv.txt&gt;observationPKM.csv.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/mlpack/mlpack/files/42513/labels.csv.txt&gt;labels.csv.txt&lt;/denchmark-link&gt;

(you will have to delete the .txt extension)
How many samples are about "enough" samples? I just run with 4000. I will get some more but I don't think I will have more than 50k. Will that be enough to do some more gaussians?
Greetings
Davud
		</comment>
		<comment id='3' author='davudadiguezel' date='2015-11-24T18:26:45Z'>
		Hey Davud,
Thanks for the backtrace; judging by its output, it looks like this bug is exactly what was fixed in &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/481&gt;#481&lt;/denchmark-link&gt;
 a few days ago.  I used the dataset that you linked to, and tested with the current git master and had no problem, then tested with git master before &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/481&gt;#481&lt;/denchmark-link&gt;
 was merged (specifically, &lt;denchmark-link:https://github.com/mlpack/mlpack/commit/a7d8231fe7526dcfaadae0bf37d67b50d286e45d&gt;a7d8231&lt;/denchmark-link&gt;
), and had the exact same issue that you had here.  So I believe the issue is solved if you update to the newest git master.
If you do try to keep increasing the number of Gaussians, though, note that you can't increase it past the number of samples in your smallest class.  For instance, in your data, here is the class breakdown:
&lt;denchmark-code&gt;(( ryan @ adam )) ~/src/mlpack/build $ cat labels.csv | sort | uniq -c
    158 0
    101 1
     34 10
     67 11
     68 12
     45 2
     27 3
     54 4
     56 5
    194 6
     26 7
     42 8
    162 9
&lt;/denchmark-code&gt;

So you can't increase the number of Gaussians above 26, because class 7 only has 26 observations.  If you, for instance, specify -g 45, but only have 26 observations, k-means (which is used before GMM training to initialize the model) will end up with empty clusters no matter what is done, and this will probably cause the program to fail (note that you'll get a warning: [WARN ] KMeans::Cluster(): more clusters requested than points given.).  It would be possible to add a check for this to hmm_train but at the moment I don't have the time, unfortunately...
		</comment>
		<comment id='4' author='davudadiguezel' date='2015-11-25T09:31:10Z'>
		Thanks for the help and the good explanation. Now everything works fine.
Greetings
		</comment>
	</comments>
</bug>