<bug id='288' author='rcurtin' open_date='2014-12-29T13:53:20Z' closed_time='2015-01-09T01:50:48Z'>
	<summary>allknn fails for mnist8m dataset</summary>
	<description>
Reported by rozyang on 16 Nov 43622165 12:23 UTC
I tried to build KNN for the mnist8m dataset (a larger version of MNIST, with 8 million samples). The dataset is available at
&lt;denchmark-link:http://ml.nec-labs.com/download/data/mnist8m/&gt;http://ml.nec-labs.com/download/data/mnist8m/&lt;/denchmark-link&gt;

% allknn -r mnist8m.csv -n mnist8m_3nn.csv -d distances_out.csv -k 3 -v
[INFO ] Loading 'mnist8m.csv' as CSV data.  Segmentation fault
The same procedure works for MNIST with 70000 samples. I am wondering whether there is some size limit in allknn. Or is it simply constrained by memory? Currently I use 16G RAM. I am using mlpack version 1.0.5.
Migrated-From: &lt;denchmark-link:http://trac.research.cc.gatech.edu/fastlab/ticket/300&gt;http://trac.research.cc.gatech.edu/fastlab/ticket/300&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='rcurtin' date='2014-12-30T05:10:26Z'>
		Commented by rcurtin on 7 Oct 43622634 08:51 UTC
Hello there,
How are you getting mnist8m.csv out of train8m-images-idx3-ubyte? (or is that the wrong file?)  Also, can you try with mlpack-1.0.6 or svn trunk to see if the issue has been fixed?
There should not be a problem loading the file as far as RAM is concerned.  allknn will use RAM at least 2x the size of the dataset, because the dataset is transposed upon loading.
		</comment>
		<comment id='2' author='rcurtin' date='2014-12-30T05:11:27Z'>
		Commented by rozyang on 10 May 43622702 12:28 UTC
The idx file format is given in the MNIST website
&lt;denchmark-link:http://yann.lecun.com/exdb/mnist/&gt;http://yann.lecun.com/exdb/mnist/&lt;/denchmark-link&gt;

I used Matlab for the conversion:
X = readidx_uint8(train8m-images-idx3-ubyte',8100000, 8100000);
csvwrite('mnist8m.csv', X);
The first function is given below. The second function is a Matlab built-in. I have checked the variable 'X' as well as the content of mnist8m.csv. The rows are indeed valid handwritten digit images.
function [arr1,arr2] = readidx_uint8(FILENAME,t1,t2)
fid= fopen(FILENAME,'r','b');
magic = fread(fid, 1, 'int32');
if magic==2051
num = fread(fid, 1, 'int32');
ndim(1) = fread(fid, 1, 'int32');
ndim(2) = fread(fid, 1, 'int32');
a = ndim(1)*ndim(2);
elseif magic==2049
num = fread(fid, 1, 'int32');
a=1;
else
disp('unknown magic number');
end
arr1 = uint8(zeros(a,t1));
arr2 = uint8(zeros(a,t2-t1));
for i=1:t1
arr1(:,i) = fread(fid, a, 'uint8');
end
for i=t1+1:t2
arr2(:,i-t1) = fread(fid, a, 'uint8');
end
fclose(fid);
		</comment>
		<comment id='3' author='rcurtin' date='2014-12-30T05:12:27Z'>
		Commented by rcurtin on 9 Sep 43624707 14:39 UTC
Ok, I can reproduce this on a system with 16GB of RAM.  The debug output is slightly more helpful in this case:
&lt;denchmark-code&gt;[Compiled with debugging symbols.
[INFO ](DEBUG]) Loading '/home/ryan/mnist8m.csv' as CSV data.  
error: Mat::init(): requested size is too large

terminate called after throwing an instance of 'std::logic_error'
  what():  

Program received signal SIGABRT, Aborted.
&lt;/denchmark-code&gt;

This output is not a part of the non-debug version; the debugging checks are not compiled in when Armadillo is compiled with -DNDEBUG (which mlpack releases are by default).
As a side note, mnist8m.csv as you gave it has 784 lines (points) and 8.1M rows (features).  I think that the dataset should have 8.1M points each with 784 features (dimensions), so I changed the csvwrite() command to transpose X before saving.  But that shouldn't affect the problem you've reported.
So, there are a few workarounds.

Buy more RAM.  This might be unfeasible, and realistically I think you'll need 32GB or 48GB if you want allknn to run without problems.
Use sparse matrices, assuming that the dataset is sparse.  There are not mlpack loaders for sparse data at this time, so you'd have to write one or wait for me to write the code to do it.  The easiest way would be with HDF5.  This may be slower than dense matrix kd-tree searching, depending on about a million different factors---mostly the sparsity of the input data.  I don't know how sparse the MNIST featureset is.
Use mmap() to avoid actually loading the matrix into memory, and use one of the advanced arma::mat() constructors to force the matrix to use the mmap()'ed memory.  This is going to be much slower because of the disk accesses.  I don't really want to detail how to do this unless you actually want to.
Run on a smaller set of data.  This is probably not an option, because if I had to guess, you probably chose mlpack because it supports large datasets.  It does---but only ones that fit in RAM, unless you want to do some of the hackery I've detailed above.

I am thinking about a way to potentially handle the out-of-memory situation without a segfault and without compromising the speed of the internal Armadillo code.  I'm not entirely sure it's possible.
Let me know which of those four ways you want to go and I can provide more advice and potentially some relevant code.  Unfortunately for any of those options, except the last, we'll have to deal with C++ so the nice allknn executable won't really be able to help us here.
		</comment>
		<comment id='4' author='rcurtin' date='2014-12-30T05:13:27Z'>
		Commented by rozyang on 16 Mar 43638741 14:47 UTC
Hi, rcurtin, thank you very much. Your answer really make sense. If the whole matrix has to be loaded to RAM in DOUBLE, then it is
8100000 * 784 * 8 = 47.3142 G
I will wait for you new codes and buy more RAM. Besides your suggestions, I tried this dataset because the matrix entries are actually not DOUBLE. They are UINT8, i.e. a byte of each. So what should really be in memory is
8100000 * 784 * 1 = 5.9143 G
which should be affordable in 16G RAM, by some extra online integer-double conversion. Of course, it requires modification of the allknn code. I am not sure whether it is doable in the near future. It should be useful for all applications uisng UINT8, especially for vision.
		</comment>
		<comment id='5' author='rcurtin' date='2014-12-30T05:14:27Z'>
		Commented by rcurtin on 6 Apr 43643790 19:28 UTC
You are right, if you use uint8_t, then it will take up about 6GB of RAM and then the method should run.  The difficulty here is that mlpack does not support types other than double.  The reason for this was API simplicity.  I don't have a good solution for this now, or soon, so you shouldn't expect code that will work with uint8_t anytime soon (sorry!).  There is some serious code restructuring that would need to happen to make uint8_t datatypes easy and I have other restructuring that right now is more important.
I've opened ticket &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/302&gt;#302&lt;/denchmark-link&gt;
 to propose the idea of arbitrary-precision support; you can follow that ticket.  Like I said, I don't think it will happen anytime soon...
I will leave this ticket open as blocked by &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/302&gt;#302&lt;/denchmark-link&gt;
, so that if/when that is finished, this can be closed.
		</comment>
		<comment id='6' author='rcurtin' date='2014-12-30T05:15:28Z'>
		Commented by rozyang on 28 Jul 44847869 08:38 UTC
Now I obtain enough RAM (1TB) and use MLPACK 1.0.10, but the problem remains:
allknn -r mnist8m.csv -n mnist8m_3nn.csv -d distances_out.csv -k 3 -v
[INFO ] Loading 'mnist8m.csv' as CSV data.  Segmentation fault
I am wondering whether there can be some other problems.
For your convenience, I put the data file in
&lt;denchmark-link:https://share.ics.aalto.fi/user/rozyang/mnist8m.zip&gt;https://share.ics.aalto.fi/user/rozyang/mnist8m.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='rcurtin' date='2014-12-30T05:16:28Z'>
		Commented by rcurtin on 7 Jun 44847997 20:41 UTC
Wow -- 1TB... I don't have access to a machine with that much RAM. :(
Since I won't be able to reproduce the results, then, could I have you get a little debugging output with gdb?  If you can recompile mlpack with debugging symbols (i.e. call CMake with the -DDEBUG=ON flag when you configure mlpack), then run your program in gdb:
&lt;denchmark-code&gt;$ gdb allknn
...
(gdb) run -r mnist8m.csv -n mnist8m_3nn.csv -d distances_out.csv -k 3 -v
&lt;/denchmark-code&gt;

When it crashes, if you can get a backtrace (bt), that would probably be helpful enough to figure out what is going on.
Also, do you know if ARMA_64BIT_WORD is enabled in Armadillo?  You can do that by modifying include/armadillo_bits/config.hpp, or adding #define ARMA_64BIT_WORD at the top of your program (before #include &lt;mlpack/core.hpp&gt;).  If it isn't enabled, then Armadillo will refuse to create very large matrices because they cannot be indexed uniquely with a 32-bit type.
		</comment>
		<comment id='8' author='rcurtin' date='2014-12-30T05:17:28Z'>
		Commented by rozyang on 15 Nov 44863454 01:20 UTC
After using a 64-bit Armadillo, it seems the data loading is successful. But the program still crashes when computing K-nearest neighbors. Below is the output
$ gdb ../../codes/others/mlpack-1.0.10/build/bin/allknn
GNU gdb (GDB) Red Hat Enterprise Linux (7.2-64.el6_5.2)
Copyright (C) 2010 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;denchmark-link:http://gnu.org/licenses/gpl.html&gt;http://gnu.org/licenses/gpl.html&lt;/denchmark-link&gt;

This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-redhat-linux-gnu".
For bug reporting instructions, please see:
&lt;denchmark-link:http://www.gnu.org/software/gdb/bugs/&gt;http://www.gnu.org/software/gdb/bugs/&lt;/denchmark-link&gt;
...
Reading symbols from /triton/ics/project/bayes/rozyang/codes/others/mlpack-1.0.10/build/bin/allknn...done.
(gdb) run -r mnist8m_T.csv -n mnist8m_3nn.csv -d mnist8m_3nn_distances.csv -k 3 -v
Starting program: /triton/ics/project/bayes/rozyang/codes/others/mlpack-1.0.10/build/bin/allknn -r mnist8m_T.csv -n mnist8m_3nn.csv -d mnist8m_3nn_distances.csv -k 3 -v
&lt;denchmark-link:Thread&gt;debugging using libthread_db enabled&lt;/denchmark-link&gt;

[Compiled with debugging symbols.
&lt;denchmark-link:DEBUG%5D&gt;INFO &lt;/denchmark-link&gt;
 Loading 'mnist8m_T.csv' as CSV data.  Size is 8100000 x 784.
[INFO ] Loaded reference data from 'mnist8m_T.csv' (8100000 x 784).
[INFO ] Building reference tree...
[INFO ] Trees built.
[INFO ] Computing 3 nearest neighbors...
Program received signal SIGSEGV, Segmentation fault.
mlpack::neighbor::NearestNeighborSort::SortDistance (list=..., indices=..., newDistance=18.303005217723125)
at /triton/ics/project/bayes/rozyang/codes/others/mlpack-1.0.10/src/mlpack/methods/neighbor_search/sort_policies/nearest_neighbor_sort.cpp:32
32    if (newDistance &gt; list&lt;denchmark-link:list.n_elem&gt;- 1&lt;/denchmark-link&gt;
)
Missing separate debuginfos, use: debuginfo-install atlas-3.8.4-2.el6.x86_64 libxml2-2.7.6-17.el6_6.1.x86_64 openblas-0.2.11-1.el6.x86_64
		</comment>
		<comment id='9' author='rcurtin' date='2014-12-30T05:18:28Z'>
		Commented by rozyang on 25 Nov 44866897 00:38 UTC
I also tried the data matrix without transpose, but the problem looks the same.
$ gdb ../../codes/others/mlpack-1.0.10/build/bin/allknn
GNU gdb (GDB) Red Hat Enterprise Linux (7.2-64.el6_5.2)
Copyright (C) 2010 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;denchmark-link:http://gnu.org/licenses/gpl.html&gt;http://gnu.org/licenses/gpl.html&lt;/denchmark-link&gt;

This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-redhat-linux-gnu".
For bug reporting instructions, please see:
&lt;denchmark-link:http://www.gnu.org/software/gdb/bugs/&gt;http://www.gnu.org/software/gdb/bugs/&lt;/denchmark-link&gt;
...
Reading symbols from /triton/ics/project/bayes/rozyang/codes/others/mlpack-1.0.10/build/bin/allknn...done.
(gdb) run -r mnist8m.csv -n mnist8m_3nn.csv -d mnist8m_3nn_distances.csv -k 3 -v
Starting program: /triton/ics/project/bayes/rozyang/codes/others/mlpack-1.0.10/build/bin/allknn -r mnist8m.csv -n mnist8m_3nn.csv -d mnist8m_3nn_distances.csv -k 3 -v
&lt;denchmark-link:Thread&gt;debugging using libthread_db enabled&lt;/denchmark-link&gt;

[Compiled with debugging symbols.
&lt;denchmark-link:DEBUG%5D&gt;INFO &lt;/denchmark-link&gt;
 Loading 'mnist8m.csv' as CSV data.  Size is 784 x 8100000.
[INFO ] Loaded reference data from 'mnist8m.csv' (784 x 8100000).
[INFO ] Building reference tree...
[INFO ] Trees built.
[INFO ] Computing 3 nearest neighbors...
Program received signal SIGSEGV, Segmentation fault.
mlpack::neighbor::NearestNeighborSort::SortDistance (list=..., indices=..., newDistance=1892.1474572559084)
at /triton/ics/project/bayes/rozyang/codes/others/mlpack-1.0.10/src/mlpack/methods/neighbor_search/sort_policies/nearest_neighbor_sort.cpp:32
32    if (newDistance &gt; list&lt;denchmark-link:list.n_elem&gt;- 1&lt;/denchmark-link&gt;
)
Missing separate debuginfos, use: debuginfo-install atlas-3.8.4-2.el6.x86_64 libxml2-2.7.6-17.el6_6.1.x86_64 openblas-0.2.11-1.el6.x86_64
		</comment>
		<comment id='10' author='rcurtin' date='2014-12-30T05:19:28Z'>
		Commented by rcurtin on 30 Dec 44867121 10:57 UTC
So I realize now I should have actually asked for a core dump, because I can open that and deal with it myself...
&lt;denchmark-code&gt;(gdb) generate-core-file
&lt;/denchmark-code&gt;

Then you can attach the generated core dump to this ticket and I can poke around in gdb and try and figure out what is actually wrong.
As a side note, there is no need to transpose the data in the CSV file (so the second trace is the one that looks right to me).  Armadillo stores matrices in column-major format, but matrices are generally stored on-disk as row-major.  So mlpack automatically transposes row-major matrices to be column-major at load time, which means that the .csv should have one observation per row (which is how the mnist8m.zip file you linked to is).
Thanks,
Ryan
		</comment>
		<comment id='11' author='rcurtin' date='2014-12-30T05:20:29Z'>
		Commented by rozyang on 9 Apr 44879943 10:38 UTC
The core dump file is huge (89G). I zipped it and put it in the following link. The zipped file is about 5G.
&lt;denchmark-link:https://share.ics.aalto.fi/user/rozyang/core.16869.zip&gt;https://share.ics.aalto.fi/user/rozyang/core.16869.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='rcurtin' date='2014-12-30T05:21:29Z'>
		Commented by rcurtin on 26 Oct 44881491 04:29 UTC
Oops, looks like I forgot some things.  Can you also attach:

the allknn executable
the libmlpack.so file allknn is linked against
the libarmadillo.so file allknn is linked against

I think that will be everything I need.  Thank you!  (and sorry this process is taking so long)
		</comment>
		<comment id='13' author='rcurtin' date='2014-12-30T05:22:29Z'>
		Commented by rozyang on 26 Jan 44882756 04:09 UTC
I have attached the files.
		</comment>
		<comment id='14' author='rcurtin' date='2014-12-30T05:23:29Z'>
		Commented by rcurtin on 11 Jul 44887021 09:40 UTC
Okay, digging into this I think I may have isolated the issue.  Here is what I think happened:
I suggested that you add #define ARMA_64BIT_WORD to your program.  This was successful and you were able to rebuild the program just fine and now the matrix loaded.  But libmlpack.so.1 is compiled without ARMA_64BIT_WORD, meaning that the structs arma::vec (for instance) in libmlpack.so.1 and allknn are different.  So when NearestNeighborSort::InsertDistance() (which is in libmlpack.so.1 and not allknn) is called, everything is misaligned and a segfault happens.
So, I should not have recommended that you add #define ARMA_64BIT_WORD to the top of your program, and I'll remember not to make that suggestion in the future.  Sorry about that.  (That can work in some situations, but those situations are specifically when your program happens to only use templated functions and classes and nothing at all that has been compiled into libmlpack.so.)
Can you try recompiling mlpack against a version of Armadillo with ARMA_64BIT_WORD enabled?  You can do this by changing include/armadillo_bits/config.hpp and uncommenting the line // #define ARMA_64BIT_WORD.  I think this will solve your problem; can you let me know if it does?  If not, I'll keep digging... :)
		</comment>
		<comment id='15' author='rcurtin' date='2015-01-09T01:50:48Z'>
		I believe that this is resolved, and I don't think the user is aware we are on Github now.  I'll resolve this here with R: inactivity, and if the user reopens it on Trac (where I won't close it), I'll post the updates here for archival purposes.
		</comment>
	</comments>
</bug>