<bug id='922' author='rcurtin' open_date='2017-03-06T19:56:07Z' closed_time='2018-04-02T17:43:24Z'>
	<summary>Identify commonly failing tests and address them</summary>
	<description>
This is a large ticket that many people can collaborate on.
mlpack has very many tests, and many of these tests are probabilistic.  This means that they can randomly fail, even when something isn't actually wrong with the code.  The purpose of this ticket is to identify these tests, open issues to address those failing tests, and fix the tests.  Typically this will involve understanding an algorithm, understanding the test, and adjusting the tolerance.  This is a good way to get your hands dirty with mlpack, so I think this is a good starter ticket for anyone looking to get involved.  I've labeled it all of 'easy', 'moderate', and 'difficult', because depending on the test, it might be easy to solve and it might not.  Identifying failing tests should be an easy task too.
mlpack has a build server that runs a nightly matrix build.  This can be found at
&lt;denchmark-link:http://masterblaster.mlpack.org/job/mlpack%20-%20nightly%20matrix%20build/&gt;http://masterblaster.mlpack.org/job/mlpack%20-%20nightly%20matrix%20build/&lt;/denchmark-link&gt;

If you click on any of the 'yellow' builds, you can get to the list of failing tests.  You can also look at the Travis build history for mlpack, or run tests locally.  We should identify tests that fail sometimes, and then open tickets to handle those individually.  I will start with a couple here.

 RANNTest/RAModelTest: #734 (difficult)
 LARSTest/NoCholeskyTest: #355 (difficult) -- only on i386
 GMMTest/GMMTrainEMOneGaussian
 VanillaNetworkTest in convolutional_network_test.cpp
 EmbeddedReberGrammarTest in recurrent_network_test.cpp
 LocalCoordinateCodingTest: #943 (difficult) -- only on sparc64

Debugging tests that fail randomly can be done (or finding how often they fail) can be done by setting the random seed at the top of the test in question:
&lt;denchmark-code&gt;math::RandomSeed(std::time(NULL));
&lt;/denchmark-code&gt;

Then, you can run that individual test in a loop to see how often it fails:
&lt;denchmark-code&gt;while(true); do bin/mlpack_test -t TestSuiteName/TestCaseName; sleep 1; done
&lt;/denchmark-code&gt;

and this will run the test over and over again, and you can see how often it fails.  That is usually a good first step to start understanding why the test is failing.
These failing tests are important to fix, because users (and new contributors) often get confused by failing Travis builds.  We can close this bug when we've got the list down to 0. :)
If you'd like to contribute to this effort:

Comment with the name of a test that seems to be commonly failing (and I'll update the list above).
Open a separate issue for a test that is commonly failing (and I'll update the list above).
Investigate a test that is commonly failing and submit a PR to fix it.

	</description>
	<comments>
		<comment id='1' author='rcurtin' date='2017-03-07T02:34:11Z'>
		Hi &lt;denchmark-link:https://github.com/rcurtin&gt;@rcurtin&lt;/denchmark-link&gt;
 , I think a test system should get same  result as long as the function worked correctly. I suggest to run these randomize methods using a fixed seed, and we can choose some seeds and run test on these seeds, to ensure a generic test.
		</comment>
		<comment id='2' author='rcurtin' date='2017-03-07T02:48:21Z'>
		Testing the tolerance of a algorithm can give some information to improve stability, and we can provide a appropriate suggestion(default) tolerance to users. So I think it's better to do a determinate test(same data sets and same random seeds), and consider improve stability   separately
		</comment>
		<comment id='3' author='rcurtin' date='2017-03-07T14:11:51Z'>
		Unfortunately, "as long as the function worked correctly" is not really an easy thing to know, especially with randomized algorithms.  One example would be LSH, which can't really be tested deterministically.  So we cannot take the randomness out of the tests.  Also, testing on a random dataset instead of a specific, hand-chosen dataset has revealed very many bugs to us in the past.  So I would not want to change the strategy that has been successful for us.
Therefore, our coverage is better if we use randomized tests, and we should focus on making the failure probabilities extremely low.
		</comment>
		<comment id='4' author='rcurtin' date='2017-03-07T14:44:25Z'>
		I see.. What about running the test several times until a success? And only if the tests all failed then throw a fatal error. If it fails on 45% tests(as &lt;denchmark-link:https://github.com/lozhnikov&gt;@lozhnikov&lt;/denchmark-link&gt;
 said in &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/734&gt;#734&lt;/denchmark-link&gt;
), we can run it for 6 times to ensure a error under 0.01%.(very time consuming indeed, but I think it maybe more robust than change tolerance?)
&lt;denchmark-link:https://github.com/rcurtin&gt;@rcurtin&lt;/denchmark-link&gt;
  Thanks for your detailed explanation, learned a lot. :)
		</comment>
		<comment id='5' author='rcurtin' date='2017-03-07T14:48:54Z'>
		Yes, running many times is sometimes a solution.  That's done for the simulated annealing tests ().  &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/734&gt;#734&lt;/denchmark-link&gt;
 will be a bit difficult, because the RASearch algorithm is supposed to guarantee an approximation, and it is failing that guarantee---there is probably something wrong with the algorithm itself (or maybe the guarantee does not apply for certain types of trees).  So unfortunately we can't get away with the strategy of running many times for that one.
		</comment>
		<comment id='6' author='rcurtin' date='2017-03-07T15:01:58Z'>
		I have been reading "IMPROVING DUAL-TREE ALGORITHMS" by you today. I found it wonderful to get familiar with mlpack and dual-tree algorithms (I've been using kd-tree to solve problems in contests, and dual-tree is more powerful). I'll spend some time on &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/734&gt;#734&lt;/denchmark-link&gt;
, may have no progress on this issue, just for my interest.
		</comment>
		<comment id='7' author='rcurtin' date='2017-03-20T07:28:21Z'>
		Here are some more tests which I observed failing quite commonly:

VanillaNetworkTest in convolutional_network_test.cpp
EmbeddedReberGrammarTest in recurrent_network_test.cpp

Anyone can take them up and fix. Correct me if I am wrong somewhere. :)
		</comment>
		<comment id='8' author='rcurtin' date='2017-03-21T03:55:21Z'>
		@abhinavmoudgil95 I did run the two tests for 25 times each, but did not get any error. Since the initial weights are randomly choosen, I don't think that you should have errors very frequently. Can you tell me with how much frequency is the error show and what is the error in case of convolutional_network_test.cpp
		</comment>
		<comment id='9' author='rcurtin' date='2017-03-21T20:21:45Z'>
		I've updated the list of failing tests, thanks.
When you run the tests to see if they are failing, be sure to add math::RandomSeed(std::time(NULL)) to the top of the test.
		</comment>
		<comment id='10' author='rcurtin' date='2017-03-25T17:44:15Z'>
		I have been able to replicate ConvolutionalNetworkTest/VanillaNetworkTest with the seed value 1490461915.
For anyone else trying to work on this issue, I wrote a simple shell script that runs the test again and again till it fails, halting at the failing case :
&lt;denchmark-code&gt;#!/usr/bin/zsh

correct=0
while [[ $correct == 0 ]]; do
  ./mlpack_test -t ConvolutionalNetworkTest/VanillaNetworkTest;
  correct=$?;
done
&lt;/denchmark-code&gt;

You can open multiple instances in different terminals if you have more threads to work with.
I'll try and fix the problem with the CNN test.
		</comment>
		<comment id='11' author='rcurtin' date='2017-04-04T03:47:46Z'>
		&lt;denchmark-link:https://github.com/rcurtin&gt;@rcurtin&lt;/denchmark-link&gt;
 I think we can checkoff  from the list now.
		</comment>
		<comment id='12' author='rcurtin' date='2017-04-04T19:42:33Z'>
		Done, thanks again for the contribution!
		</comment>
		<comment id='13' author='rcurtin' date='2017-04-04T20:18:50Z'>
		Thanks Ryan, always happy to contribute! :)
		</comment>
		<comment id='14' author='rcurtin' date='2017-11-12T12:33:59Z'>
		Hi, I saw that this issue was still open. I wanted to contribute to mlpack and this seemed a good place to start contributing. Is anybody working on it?  If nobody is then maybe I should? :)
		</comment>
		<comment id='15' author='rcurtin' date='2017-11-13T15:15:36Z'>
		Hi Gaurav, you are more than welcome to contribute to this issue.  Just identify a commonly failing test (some are listed above) and then see if you can either fix an issue in the code that causes it, or adjust the tolerance of the test accordingly if the code is behaving properly.
		</comment>
		<comment id='16' author='rcurtin' date='2018-01-26T19:37:24Z'>
		Hi &lt;denchmark-link:https://github.com/rcurtin&gt;@rcurtin&lt;/denchmark-link&gt;
, I am getting a failed test for adaboost 'WeakLearnerErrorIris' in my local machine.
fatal error in "WeakLearnerErrorIris": critical check error &lt;= weakLearnerErrorRate failed [0.040000000000000001 &gt; 0.033333333333333333]
		</comment>
		<comment id='17' author='rcurtin' date='2018-02-24T13:14:24Z'>
		Here are some failed tests which I met:


'PerceptronSerializationTest' and 'DecisionStumpSerializationTest' in serialization.cpp;


'GMMLoadSaveTest' in gmm_test.cpp;


'GMMHMMLoadSaveTest' , 'GaussianHMMLoadSaveTest' and 'DiscreteHMMLoadSaveTest' in hmm_test.cpp;


'LSHTest' in serialization_test.cpp;


		</comment>
		<comment id='18' author='rcurtin' date='2018-02-24T15:24:47Z'>
		&lt;denchmark-link:https://github.com/wangxindsb&gt;@wangxindsb&lt;/denchmark-link&gt;
: what version of Boost are you using? This might be the same problem that was just fixed with &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1257&gt;#1257&lt;/denchmark-link&gt;
, if you are using Boost 1.58. If that's the case you could update to the latest code and try again and that would likely fix it.
		</comment>
		<comment id='19' author='rcurtin' date='2018-04-02T17:43:24Z'>
		I really like the look of the matrix build these days:
&lt;denchmark-link:http://masterblaster.mlpack.org/job/docker%20mlpack%20monthly%20build/&gt;http://masterblaster.mlpack.org/job/docker%20mlpack%20monthly%20build/&lt;/denchmark-link&gt;

So I think there are no more "commonly" failing tests, and I think we can finally mark this issue as fixed.
		</comment>
	</comments>
</bug>