<bug id='638' author='yuanjinq' open_date='2016-05-13T03:05:48Z' closed_time='2016-05-16T19:22:40Z'>
	<summary>Issues of HMM training</summary>
	<description>
Hi, I'm new to HMM and I'm trying to use Mlpack to train a model of Gaussian HMM with a few observation sequences. So I used the mlpack_hmm_train with following command:
mlpack_hmm_train -i 11.txt -n 4 -t gaussian -o 11out.xml
Then I went to the model file and try to find the emissions and transform matrix. I found that the transform matrix are uniform and every emission are the same with a strange value. Then I changed different observation sequences, the result were similar.
Did I do the training right? I read through the document and didn't find the solution. Thank you.
	</description>
	<comments>
		<comment id='1' author='yuanjinq' date='2016-05-13T15:58:45Z'>
		Can you provide the training set you used, and the output of the program when you run with -v?  That might be helpful in figuring out what is going on.
		</comment>
		<comment id='2' author='yuanjinq' date='2016-05-16T04:59:18Z'>
		Hi rcurtln,
Sorry for the late reply.
Here's the training set I used in the beginning.
data.txt is the file that contains all other observation sequences. And other files contain three or four normalized observations with 6 DOF.
"data.txt"
data11.txt
data21.txt
data31.txt
data41.txt
data51.txt
"data11.txt"
1.407188 -0.825524 -0.581664 1.330260 -0.249431 -1.080829
1.064666 0.273809 -1.338475 -1.414204 0.702534 0.711669
1.118510 0.190213 -1.308723 -0.978695 1.373439 -0.394744
"data21.txt"
1.413624 -0.742167 -0.671457 1.393726 -0.489149 -0.904577
1.414185 -0.699330 -0.714855 1.414114 -0.721602 -0.692512
1.413064 -0.755915 -0.657149 -1.414117 0.721405 0.692712
"data31.txt"
1.731182 -0.618199 -0.529350 -0.583632 1.604384 0.056298
-0.682269 -0.978413 1.210370 0.761583 -0.912841 -1.059112
-0.443458 1.726382 -0.642271 -0.640653 1.157285 0.828081
-0.947201 -1.038165 -0.964568 -1.034804 1.004618 0.994753
"data41.txt"
1.731235 -0.530060 -0.585568 -0.615607 1.636155 -0.075307
-0.557711 -1.003137 1.190107 0.789548 -0.970546 -1.009108
-0.423812 1.724491 -0.632598 -0.668081 1.092094 0.901500
-0.935888 -1.057706 -0.977638 -1.011645 0.849429 1.139854
"data51.txt"
1.715604 -0.348052 -0.699034 -0.668518 1.633409 -0.045010
-0.609211 -0.979189 1.245627 0.717635 -0.925878 -1.037384
1.496415 0.177980 -0.432682 -1.241713 1.319591 0.616885
-1.007997 -0.928479 -0.970147 -1.026679 0.923957 1.072869
The output is as follows:
[INFO ] Reading list of training sequences from 'data.txt'.
[INFO ] Adding training sequence from 'data11.txt'.
[INFO ] Loading 'data11.txt' as raw ASCII formatted data.  Size is 6 x 3.
[INFO ] Adding training sequence from 'data21.txt'.
[INFO ] Loading 'data21.txt' as raw ASCII formatted data.  Size is 6 x 3.
[INFO ] Adding training sequence from 'data31.txt'.
[INFO ] Loading 'data31.txt' as raw ASCII formatted data.  Size is 6 x 4.
[INFO ] Adding training sequence from 'data41.txt'.
[INFO ] Loading 'data41.txt' as raw ASCII formatted data.  Size is 6 x 4.
[INFO ] Adding training sequence from 'data51.txt'.
[INFO ] Loading 'data51.txt' as raw ASCII formatted data.  Size is 6 x 4.
[INFO ]
[INFO ] Execution parameters:
[INFO ]   batch: true
[INFO ]   gaussians: 0
[INFO ]   help: false
[INFO ]   info: ""
[INFO ]   input_file: data.txt
[INFO ]   labels_file: ""
[INFO ]   model_file: ""
[INFO ]   output_model_file: dataout.xml
[INFO ]   seed: 0
[INFO ]   states: 6
[INFO ]   tolerance: 1e-05
[INFO ]   type: gaussian
[INFO ]   verbose: true
[INFO ]   version: false
[INFO ]
[INFO ] Program timers:
[INFO ]   loading_data: 0.000880s
[INFO ]   total_time: 0.062300s
Then  I used one file contains a list of datas:
-0.049332,0.632684,1.930238
-0.045342,0.653824,1.949537
0.223055,0.607684,1.885569
0.456205,0.482629,1.495054
0.62325,0.454105,1.333082
0.740229,0.468617,1.399701
0.758242,0.476387,1.570806
0.772725,0.504061,1.601133
0.799275,0.537727,1.666062
0.872294,0.580186,1.646654
0.889642,0.612556,1.607951
0.835107,0.669644,1.528674
0.704884,0.683599,1.427598
0.736671,0.727499,1.386765
0.875919,0.762281,1.269978
0.974008,0.842077,0.490348
1.041494,0.898995,0.123952
1.061031,0.943553,0.208335
0.960244,0.917036,1.008331
0.54015,0.698827,1.148918
0.350406,0.631777,1.10327
0.242643,0.615209,1.044297
0.238878,0.624707,1.015939
0.336262,0.713242,1.063636
0.743459,0.792901,1.232002
1.005647,0.869002,1.491689
1.205512,0.929804,1.472736
1.149689,0.895766,1.373127
1.059189,0.759632,1.278505
0.978293,0.743314,1.199621
0.917716,0.755696,1.180213
0.686448,0.741106,1.228388
0.576865,0.679422,1.248577
0.574938,0.675374,1.475239
0.62893,0.690035,1.629235
0.699362,0.786216,1.768085
0.695823,0.876179,1.723242
0.509356,0.969935,1.704582
or discrete datas:
1
7
8
9
4
3
1
7
8
9
4
3
1
7
8
9
4
3
The output of the program is the same and the result models turn out to be similar: uniform matrix and weird emissions.
Thank you.
Jinqiang
		</comment>
		<comment id='3' author='yuanjinq' date='2016-05-16T19:22:40Z'>
		Hi Jinqiang,
I took a look, and the HMM code initializes the transition matrix uniformly.  But I think this is a saddle point for the EM optimization, so the optimization gets stuck.  In &lt;denchmark-link:https://github.com/mlpack/mlpack/commit/3e4f3cade8a59f1a49c07e08c39fe6af33e2da06&gt;3e4f3ca&lt;/denchmark-link&gt;
 I added an option to  called , which will start the optimization with uniformly randomly distributed emission and transition matrices.  I think this will fix your issue.  So if you update to the latest git master branch and rebuild, I think this will solve your problem.  Let me know if it doesn't, and we can reopen the issue and I can try again... :)
Thanks,
Ryan
		</comment>
	</comments>
</bug>