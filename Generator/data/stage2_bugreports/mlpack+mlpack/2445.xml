<bug id='2445' author='menkaur' open_date='2020-06-06T23:22:39Z' closed_time='2020-08-10T00:07:15Z'>
	<summary>Getting following error while trying to train LSTM network: "each_col(): incompatible size; expected 0x1, got 1200x1"</summary>
	<description>
Here is the code I'm using to build and train the network:
&lt;denchmark-code&gt;void SpawnAndTrainRNN(size_t nIterations, size_t studyChunkSize){
    using namespace mlpack;
    using namespace mlpack::ann;
    using namespace ens;

    const size_t inputSize=dataPointsCount, outputSize=1, historyLength=1;
    const size_t innerLayerSize=inputSize;
    const double STEP_SIZE = 5e-5;

    RNN&lt;MeanSquaredError&lt;&gt;, HeInitialization&gt; model(historyLength);
    if(!std::experimental::filesystem::exists(modelTmpFile)) {
        model.Add&lt;IdentityLayer&lt;&gt; &gt;();
        model.Add&lt;LSTM&lt;&gt; &gt;(inputSize, innerLayerSize, historyLength);
        model.Add&lt;LeakyReLU&lt;&gt; &gt;();
        model.Add&lt;LSTM&lt;&gt; &gt;(innerLayerSize, innerLayerSize, historyLength);
        model.Add&lt;LeakyReLU&lt;&gt; &gt;();
        model.Add&lt;Linear&lt;&gt; &gt;(innerLayerSize, outputSize);
    }
    else{
        data::Load(modelTmpFile, modelName, model);
    }

    for(int _=0;_&lt;nIterations;_++) {
        EnumerateDataChunks(studyChunkSize,[&amp;](const auto &amp;data, const auto &amp;labels){
            arma::cube work, res;
            work.set_size(inputSize, data.n_cols - historyLength + 1, historyLength);
            res.set_size(outputSize, labels.n_cols - historyLength + 1, historyLength);

            //this will only work for historyLength=1
            work.subcube(arma::span(0, inputSize-1),arma::span(0,data.n_cols - historyLength ),arma::span())=data;
            res.subcube(arma::span(0),arma::span(0,labels.n_cols-historyLength),arma::span()) = labels;


            // Set parameters for the Stochastic Gradient Descent (SGD) optimizer.
            SGD&lt;AdamUpdate&gt; optimizer(
                    STEP_SIZE, // Step size of the optimizer.
                    data.n_cols, // Batch size. Number of data points used per iteration.
                    data.n_cols, // Max number of iterations.
                    1e-8, // Tolerance.
                    false, // Shuffle.
                    AdamUpdate(1e-8, 0.9, 0.999)); // Adam update policy.

            // Instead of terminating based on the tolerance of the objective function,
            // we'll depend on the maximum number of iterations, and terminate early
            // using the EarlyStopAtMinLoss callback.
            optimizer.Tolerance() = -1;

            model.Train(work,
                        res,
                        optimizer,
                    // PrintLoss Callback prints loss for each epoch.
                        ens::PrintLoss(),
                    // Progressbar Callback prints progress bar for each epoch.
                        ens::ProgressBar(),
                    // Stops the optimization process if the loss stops decreasing
                    // or no improvement has been made. This will terminate the
                    // optimization once we obtain a minima on training set.
                        ens::EarlyStopAtMinLoss());

            data::Save(modelTmpFile, modelName, model);
        });
    }
}
&lt;/denchmark-code&gt;

mostly, it  has been taken from &lt;denchmark-link:https://github.com/mlpack/models/blob/master/LSTM/TimeSeries-Univariate/src/LSTMTimeSeriesUnivariate.cpp&gt;this example&lt;/denchmark-link&gt;
.
Input data's dimmension is 1200 (dataPointsCount) and is fed in chunks of 100 data points, label has 1 dimmension
For each iteration, data has following dimensions:
work {n_rows=1200, n_cols=100, n_slices=1}
res    {n_rows=1,       n_cols=100, n_slices=1}
The call fails in the model.Train(...) with callstack:
&lt;denchmark-code&gt;__GI_raise 0x00007f073d22de97
__GI_abort 0x00007f073d22f801
&lt;unknown&gt; 0x00007f073dc22957
&lt;unknown&gt; 0x00007f073dc28ae6
std::terminate() 0x00007f073dc28b21
__cxa_throw 0x00007f073dc28d54
arma::arma_stop_logic_error&lt;std::__cxx11::basic_string&lt;char&gt; &gt; debug.hpp:144
arma::subview_each_common&lt;arma::Mat&lt;double&gt;, 0u&gt;::check_size subview_each_meat.hpp:76
arma::subview_each1_aux::operator_schur&lt;arma::Mat&lt;double&gt;, 0u, arma::Mat&lt;double&gt; &gt; subview_each_meat.hpp:848
arma::operator%&lt;arma::Mat&lt;double&gt;, 0u, arma::Mat&lt;double&gt; &gt; operator_schur.hpp:274
mlpack::ann::LSTM&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;::Backward&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt; lstm_impl.hpp:347
mlpack::ann::BackwardVisitor::LayerBackward&lt;mlpack::ann::LSTM&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt; &gt; backward_visitor_impl.hpp:63
mlpack::ann::BackwardVisitor::operator()&lt;mlpack::ann::LSTM&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt; &gt; backward_visitor_impl.hpp:50
boost::detail::variant::invoke_visitor&lt;mlpack::ann::BackwardVisitor const, false&gt;::internal_visit&lt;mlpack::ann::LSTM&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;*&amp;&gt; variant.hpp:1028
boost::detail::variant::visitation_impl_invoke_impl&lt;boost::detail::variant::invoke_visitor&lt;mlpack::ann::BackwardVisitor const, false&gt;, void*, mlpack::ann::LSTM&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;*&gt; visitation_impl.hpp:119
_ZN5boost6detail7variant22visitation_impl_invokeINS1_14invoke_visitorIKN6mlpack3ann15BackwardVisitorELb0EEEPvPNS5_4LSTMIN4arma3MatIdEESD_EENS_7variantIPNS5_3AddISD_SD_EEJPNS5_8AddMergeISD_SD_JEEEPNS5_17AtrousConvolutionINS5_16NaiveConvolutionINS5_16ValidConvolutionEEENSO_INS5_15FullConvolutionEEESQ_SD_SD_EEPNS5_9BaseLayerINS5_16LogisticFunctionESD_SD_EEPNSV_INS5_16IdentityFunctionESD_SD_EEPNSV_INS5_12TanhFunctionESD_SD_EEPNSV_INS5_17RectifierFunctionESD_SD_EEPNSV_INS5_16SoftplusFunctionESD_SD_EEPNS5_9BatchNormISD_SD_EEPNS5_21BilinearInterpolationISD_SD_EEPNS5_6ConcatISD_SD_JEEEPNS5_11ConcatenateISD_SD_EEPNS5_17ConcatPerformanceINS5_21NegativeLogLikelihoodISD_SD_EESD_SD_EEPNS5_8ConstantISD_SD_EEPNS5_11ConvolutionISQ_SS_SQ_SD_SD_EEPNS5_21TransposedConvolutionISQ_SQ_SQ_SD_SD_EEPNS5_11DropConnectISD_SD_EEPNS5_7DropoutISD_SD_EEPNS5_12AlphaDropoutISD_SD_EEPNS5_3ELUISD_SD_EEPNS5_12FlexibleReLUISD_SD_EEPNS5_7GlimpseISD_SD_EEPNS5_8HardTanHISD_SD_EEPNS5_7HighwayISD_SD_JEEEPNS5_4JoinISD_SD_EEPNS5_9LayerNormISD_SD_EEPNS5_9LeakyReLUISD_SD_EEPNS5_5CReLUISD_SD_EEPNS5_6LinearISD_SD_NS5_13NoRegularizerEEEPNS5_12LinearNoBiasISD_SD_S32_EEPNS5_10LogSoftMaxISD_SD_EEPNS5_6LookupISD_SD_EESF_PNS5_3GRUISD_SD_EEPNS5_8FastLSTMISD_SD_EEPNS5_10MaxPoolingISD_SD_EEPNS5_11MeanPoolingISD_SD_EEPNS5_23MiniBatchDiscriminationISD_SD_EEPNS5_16MultiplyConstantISD_SD_EEPNS5_13MultiplyMergeISD_SD_JEEEPS1P_PNS5_7PaddingISD_SD_EEPNS5_5PReLUISD_SD_EEPNS5_10WeightNormISD_SD_JEEEPNS5_4CELUISD_SD_EENSG_IPNS5_9RecurrentISD_SD_JEEEJPNS5_18RecurrentAttentionISD_SD_EEPNS5_15ReinforceNormalISD_SD_EEPNS5_17ReparametrizationISD_SD_EEPNS5_6SelectISD_SD_EEPNS5_10SequentialISD_SD_Lb0EJEEEPNS4R_ISD_SD_Lb1EJEEEPNS5_7SubviewISD_SD_EEPNS5_13VRClassRewardISD_SD_EEPNS5_16VirtualBatchNormISD_SD_EEEEEEE18has_fallback_type_EEENT_11result_typeEiRS58_T0_PT1_T2_i visitation_impl.hpp:157
_ZN5boost6detail7variant15visitation_implIN4mpl_4int_ILi0EEENS1_20visitation_impl_stepINS_3mpl6l_iterINS7_6l_itemINS3_5long_ILl46EEEPN6mlpack3ann3AddIN4arma3MatIdEESH_EENS9_INSA_ILl45EEEPNSD_8AddMergeISH_SH_JEEENS9_INSA_ILl44EEEPNSD_17AtrousConvolutionINSD_16NaiveConvolutionINSD_16ValidConvolutionEEENSQ_INSD_15FullConvolutionEEESS_SH_SH_EENS9_INSA_ILl43EEEPNSD_9BaseLayerINSD_16LogisticFunctionESH_SH_EENS9_INSA_ILl42EEEPNSY_INSD_16IdentityFunctionESH_SH_EENS9_INSA_ILl41EEEPNSY_INSD_12TanhFunctionESH_SH_EENS9_INSA_ILl40EEEPNSY_INSD_17RectifierFunctionESH_SH_EENS9_INSA_ILl39EEEPNSY_INSD_16SoftplusFunctionESH_SH_EENS9_INSA_ILl38EEEPNSD_9BatchNormISH_SH_EENS9_INSA_ILl37EEEPNSD_21BilinearInterpolationISH_SH_EENS9_INSA_ILl36EEEPNSD_6ConcatISH_SH_JEEENS9_INSA_ILl35EEEPNSD_11ConcatenateISH_SH_EENS9_INSA_ILl34EEEPNSD_17ConcatPerformanceINSD_21NegativeLogLikelihoodISH_SH_EESH_SH_EENS9_INSA_ILl33EEEPNSD_8ConstantISH_SH_EENS9_INSA_ILl32EEEPNSD_11ConvolutionISS_SU_SS_SH_SH_EENS9_INSA_ILl31EEEPNSD_21TransposedConvolutionISS_SS_SS_SH_SH_EENS9_INSA_ILl30EEEPNSD_11DropConnectISH_SH_EENS9_INSA_ILl29EEEPNSD_7DropoutISH_SH_EENS9_INSA_ILl28EEEPNSD_12AlphaDropoutISH_SH_EENS9_INSA_ILl27EEEPNSD_3ELUISH_SH_EENS9_INSA_ILl26EEEPNSD_12FlexibleReLUISH_SH_EENS9_INSA_ILl25EEEPNSD_7GlimpseISH_SH_EENS9_INSA_ILl24EEEPNSD_8HardTanHISH_SH_EENS9_INSA_ILl23EEEPNSD_7HighwayISH_SH_JEEENS9_INSA_ILl22EEEPNSD_4JoinISH_SH_EENS9_INSA_ILl21EEEPNSD_9LayerNormISH_SH_EENS9_INSA_ILl20EEEPNSD_9LeakyReLUISH_SH_EENS9_INSA_ILl19EEEPNSD_5CReLUISH_SH_EENS9_INSA_ILl18EEEPNSD_6LinearISH_SH_NSD_13NoRegularizerEEENS9_INSA_ILl17EEEPNSD_12LinearNoBiasISH_SH_S3U_EENS9_INSA_ILl16EEEPNSD_10LogSoftMaxISH_SH_EENS9_INSA_ILl15EEEPNSD_6LookupISH_SH_EENS9_INSA_ILl14EEEPNSD_4LSTMISH_SH_EENS9_INSA_ILl13EEEPNSD_3GRUISH_SH_EENS9_INSA_ILl12EEEPNSD_8FastLSTMISH_SH_EENS9_INSA_ILl11EEEPNSD_10MaxPoolingISH_SH_EENS9_INSA_ILl10EEEPNSD_11MeanPoolingISH_SH_EENS9_INSA_ILl9EEEPNSD_23MiniBatchDiscriminationISH_SH_EENS9_INSA_ILl8EEEPNSD_16MultiplyConstantISH_SH_EENS9_INSA_ILl7EEEPNSD_13MultiplyMergeISH_SH_JEEENS9_INSA_ILl6EEEPS21_NS9_INSA_ILl5EEEPNSD_7PaddingISH_SH_EENS9_INSA_ILl4EEEPNSD_5PReLUISH_SH_EENS9_INSA_ILl3EEEPNSD_10WeightNormISH_SH_JEEENS9_INSA_ILl2EEEPNSD_4CELUISH_SH_EENS9_INSA_ILl1EEENS_7variantIPNSD_9RecurrentISH_SH_JEEEJPNSD_18RecurrentAttentionISH_SH_EEPNSD_15ReinforceNormalISH_SH_EEPNSD_17ReparametrizationISH_SH_EEPNSD_6SelectISH_SH_EEPNSD_10SequentialISH_SH_Lb0EJEEEPNS64_ISH_SH_Lb1EJEEEPNSD_7SubviewISH_SH_EEPNSD_13VRClassRewardISH_SH_EEPNSD_16VirtualBatchNormISH_SH_EEEEENS7_5l_endEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEENS8_IS6J_EEEENS1_14invoke_visitorIKNSD_15BackwardVisitorELb0EEEPvNS5O_ISJ_JSN_SW_S11_S15_S19_S1D_S1H_S1L_S1P_S1T_S1X_S23_S27_S2B_S2F_S2J_S2N_S2R_S2V_S2Z_S33_S37_S3B_S3F_S3J_S3N_S3R_S3W_S40_S44_S48_S4C_S4G_S4K_S4O_S4S_S4W_S50_S54_S56_S5A_S5E_S5I_S5M_S6I_EE18has_fallback_type_EEENT1_11result_typeEiiRS84_T2_NS3_5bool_ILb0EEET3_PT_PT0_ visitation_impl.hpp:238
_ZN5boost7variantIPN6mlpack3ann3AddIN4arma3MatIdEES6_EEJPNS2_8AddMergeIS6_S6_JEEEPNS2_17AtrousConvolutionINS2_16NaiveConvolutionINS2_16ValidConvolutionEEENSD_INS2_15FullConvolutionEEESF_S6_S6_EEPNS2_9BaseLayerINS2_16LogisticFunctionES6_S6_EEPNSK_INS2_16IdentityFunctionES6_S6_EEPNSK_INS2_12TanhFunctionES6_S6_EEPNSK_INS2_17RectifierFunctionES6_S6_EEPNSK_INS2_16SoftplusFunctionES6_S6_EEPNS2_9BatchNormIS6_S6_EEPNS2_21BilinearInterpolationIS6_S6_EEPNS2_6ConcatIS6_S6_JEEEPNS2_11ConcatenateIS6_S6_EEPNS2_17ConcatPerformanceINS2_21NegativeLogLikelihoodIS6_S6_EES6_S6_EEPNS2_8ConstantIS6_S6_EEPNS2_11ConvolutionISF_SH_SF_S6_S6_EEPNS2_21TransposedConvolutionISF_SF_SF_S6_S6_EEPNS2_11DropConnectIS6_S6_EEPNS2_7DropoutIS6_S6_EEPNS2_12AlphaDropoutIS6_S6_EEPNS2_3ELUIS6_S6_EEPNS2_12FlexibleReLUIS6_S6_EEPNS2_7GlimpseIS6_S6_EEPNS2_8HardTanHIS6_S6_EEPNS2_7HighwayIS6_S6_JEEEPNS2_4JoinIS6_S6_EEPNS2_9LayerNormIS6_S6_EEPNS2_9LeakyReLUIS6_S6_EEPNS2_5CReLUIS6_S6_EEPNS2_6LinearIS6_S6_NS2_13NoRegularizerEEEPNS2_12LinearNoBiasIS6_S6_S2R_EEPNS2_10LogSoftMaxIS6_S6_EEPNS2_6LookupIS6_S6_EEPNS2_4LSTMIS6_S6_EEPNS2_3GRUIS6_S6_EEPNS2_8FastLSTMIS6_S6_EEPNS2_10MaxPoolingIS6_S6_EEPNS2_11MeanPoolingIS6_S6_EEPNS2_23MiniBatchDiscriminationIS6_S6_EEPNS2_16MultiplyConstantIS6_S6_EEPNS2_13MultiplyMergeIS6_S6_JEEEPS1E_PNS2_7PaddingIS6_S6_EEPNS2_5PReLUIS6_S6_EEPNS2_10WeightNormIS6_S6_JEEEPNS2_4CELUIS6_S6_EENS0_IPNS2_9RecurrentIS6_S6_JEEEJPNS2_18RecurrentAttentionIS6_S6_EEPNS2_15ReinforceNormalIS6_S6_EEPNS2_17ReparametrizationIS6_S6_EEPNS2_6SelectIS6_S6_EEPNS2_10SequentialIS6_S6_Lb0EJEEEPNS4J_IS6_S6_Lb1EJEEEPNS2_7SubviewIS6_S6_EEPNS2_13VRClassRewardIS6_S6_EEPNS2_16VirtualBatchNormIS6_S6_EEEEEEE27internal_apply_visitor_implINS_6detail7variant14invoke_visitorIKNS2_15BackwardVisitorELb0EEEPvEENT_11result_typeEiiRS57_T0_ variant.hpp:2337
_ZN5boost7variantIPN6mlpack3ann3AddIN4arma3MatIdEES6_EEJPNS2_8AddMergeIS6_S6_JEEEPNS2_17AtrousConvolutionINS2_16NaiveConvolutionINS2_16ValidConvolutionEEENSD_INS2_15FullConvolutionEEESF_S6_S6_EEPNS2_9BaseLayerINS2_16LogisticFunctionES6_S6_EEPNSK_INS2_16IdentityFunctionES6_S6_EEPNSK_INS2_12TanhFunctionES6_S6_EEPNSK_INS2_17RectifierFunctionES6_S6_EEPNSK_INS2_16SoftplusFunctionES6_S6_EEPNS2_9BatchNormIS6_S6_EEPNS2_21BilinearInterpolationIS6_S6_EEPNS2_6ConcatIS6_S6_JEEEPNS2_11ConcatenateIS6_S6_EEPNS2_17ConcatPerformanceINS2_21NegativeLogLikelihoodIS6_S6_EES6_S6_EEPNS2_8ConstantIS6_S6_EEPNS2_11ConvolutionISF_SH_SF_S6_S6_EEPNS2_21TransposedConvolutionISF_SF_SF_S6_S6_EEPNS2_11DropConnectIS6_S6_EEPNS2_7DropoutIS6_S6_EEPNS2_12AlphaDropoutIS6_S6_EEPNS2_3ELUIS6_S6_EEPNS2_12FlexibleReLUIS6_S6_EEPNS2_7GlimpseIS6_S6_EEPNS2_8HardTanHIS6_S6_EEPNS2_7HighwayIS6_S6_JEEEPNS2_4JoinIS6_S6_EEPNS2_9LayerNormIS6_S6_EEPNS2_9LeakyReLUIS6_S6_EEPNS2_5CReLUIS6_S6_EEPNS2_6LinearIS6_S6_NS2_13NoRegularizerEEEPNS2_12LinearNoBiasIS6_S6_S2R_EEPNS2_10LogSoftMaxIS6_S6_EEPNS2_6LookupIS6_S6_EEPNS2_4LSTMIS6_S6_EEPNS2_3GRUIS6_S6_EEPNS2_8FastLSTMIS6_S6_EEPNS2_10MaxPoolingIS6_S6_EEPNS2_11MeanPoolingIS6_S6_EEPNS2_23MiniBatchDiscriminationIS6_S6_EEPNS2_16MultiplyConstantIS6_S6_EEPNS2_13MultiplyMergeIS6_S6_JEEEPS1E_PNS2_7PaddingIS6_S6_EEPNS2_5PReLUIS6_S6_EEPNS2_10WeightNormIS6_S6_JEEEPNS2_4CELUIS6_S6_EENS0_IPNS2_9RecurrentIS6_S6_JEEEJPNS2_18RecurrentAttentionIS6_S6_EEPNS2_15ReinforceNormalIS6_S6_EEPNS2_17ReparametrizationIS6_S6_EEPNS2_6SelectIS6_S6_EEPNS2_10SequentialIS6_S6_Lb0EJEEEPNS4J_IS6_S6_Lb1EJEEEPNS2_7SubviewIS6_S6_EEPNS2_13VRClassRewardIS6_S6_EEPNS2_16VirtualBatchNormIS6_S6_EEEEEEE22internal_apply_visitorINS_6detail7variant14invoke_visitorIKNS2_15BackwardVisitorELb0EEEEENT_11result_typeERS56_ variant.hpp:2349
_ZNR5boost7variantIPN6mlpack3ann3AddIN4arma3MatIdEES6_EEJPNS2_8AddMergeIS6_S6_JEEEPNS2_17AtrousConvolutionINS2_16NaiveConvolutionINS2_16ValidConvolutionEEENSD_INS2_15FullConvolutionEEESF_S6_S6_EEPNS2_9BaseLayerINS2_16LogisticFunctionES6_S6_EEPNSK_INS2_16IdentityFunctionES6_S6_EEPNSK_INS2_12TanhFunctionES6_S6_EEPNSK_INS2_17RectifierFunctionES6_S6_EEPNSK_INS2_16SoftplusFunctionES6_S6_EEPNS2_9BatchNormIS6_S6_EEPNS2_21BilinearInterpolationIS6_S6_EEPNS2_6ConcatIS6_S6_JEEEPNS2_11ConcatenateIS6_S6_EEPNS2_17ConcatPerformanceINS2_21NegativeLogLikelihoodIS6_S6_EES6_S6_EEPNS2_8ConstantIS6_S6_EEPNS2_11ConvolutionISF_SH_SF_S6_S6_EEPNS2_21TransposedConvolutionISF_SF_SF_S6_S6_EEPNS2_11DropConnectIS6_S6_EEPNS2_7DropoutIS6_S6_EEPNS2_12AlphaDropoutIS6_S6_EEPNS2_3ELUIS6_S6_EEPNS2_12FlexibleReLUIS6_S6_EEPNS2_7GlimpseIS6_S6_EEPNS2_8HardTanHIS6_S6_EEPNS2_7HighwayIS6_S6_JEEEPNS2_4JoinIS6_S6_EEPNS2_9LayerNormIS6_S6_EEPNS2_9LeakyReLUIS6_S6_EEPNS2_5CReLUIS6_S6_EEPNS2_6LinearIS6_S6_NS2_13NoRegularizerEEEPNS2_12LinearNoBiasIS6_S6_S2R_EEPNS2_10LogSoftMaxIS6_S6_EEPNS2_6LookupIS6_S6_EEPNS2_4LSTMIS6_S6_EEPNS2_3GRUIS6_S6_EEPNS2_8FastLSTMIS6_S6_EEPNS2_10MaxPoolingIS6_S6_EEPNS2_11MeanPoolingIS6_S6_EEPNS2_23MiniBatchDiscriminationIS6_S6_EEPNS2_16MultiplyConstantIS6_S6_EEPNS2_13MultiplyMergeIS6_S6_JEEEPS1E_PNS2_7PaddingIS6_S6_EEPNS2_5PReLUIS6_S6_EEPNS2_10WeightNormIS6_S6_JEEEPNS2_4CELUIS6_S6_EENS0_IPNS2_9RecurrentIS6_S6_JEEEJPNS2_18RecurrentAttentionIS6_S6_EEPNS2_15ReinforceNormalIS6_S6_EEPNS2_17ReparametrizationIS6_S6_EEPNS2_6SelectIS6_S6_EEPNS2_10SequentialIS6_S6_Lb0EJEEEPNS4J_IS6_S6_Lb1EJEEEPNS2_7SubviewIS6_S6_EEPNS2_13VRClassRewardIS6_S6_EEPNS2_16VirtualBatchNormIS6_S6_EEEEEEE13apply_visitorIKNS2_15BackwardVisitorEEENT_11result_typeERS52_ variant.hpp:2393
_ZN5boost13apply_visitorIN6mlpack3ann15BackwardVisitorERNS_7variantIPNS2_3AddIN4arma3MatIdEES8_EEJPNS2_8AddMergeIS8_S8_JEEEPNS2_17AtrousConvolutionINS2_16NaiveConvolutionINS2_16ValidConvolutionEEENSF_INS2_15FullConvolutionEEESH_S8_S8_EEPNS2_9BaseLayerINS2_16LogisticFunctionES8_S8_EEPNSM_INS2_16IdentityFunctionES8_S8_EEPNSM_INS2_12TanhFunctionES8_S8_EEPNSM_INS2_17RectifierFunctionES8_S8_EEPNSM_INS2_16SoftplusFunctionES8_S8_EEPNS2_9BatchNormIS8_S8_EEPNS2_21BilinearInterpolationIS8_S8_EEPNS2_6ConcatIS8_S8_JEEEPNS2_11ConcatenateIS8_S8_EEPNS2_17ConcatPerformanceINS2_21NegativeLogLikelihoodIS8_S8_EES8_S8_EEPNS2_8ConstantIS8_S8_EEPNS2_11ConvolutionISH_SJ_SH_S8_S8_EEPNS2_21TransposedConvolutionISH_SH_SH_S8_S8_EEPNS2_11DropConnectIS8_S8_EEPNS2_7DropoutIS8_S8_EEPNS2_12AlphaDropoutIS8_S8_EEPNS2_3ELUIS8_S8_EEPNS2_12FlexibleReLUIS8_S8_EEPNS2_7GlimpseIS8_S8_EEPNS2_8HardTanHIS8_S8_EEPNS2_7HighwayIS8_S8_JEEEPNS2_4JoinIS8_S8_EEPNS2_9LayerNormIS8_S8_EEPNS2_9LeakyReLUIS8_S8_EEPNS2_5CReLUIS8_S8_EEPNS2_6LinearIS8_S8_NS2_13NoRegularizerEEEPNS2_12LinearNoBiasIS8_S8_S2T_EEPNS2_10LogSoftMaxIS8_S8_EEPNS2_6LookupIS8_S8_EEPNS2_4LSTMIS8_S8_EEPNS2_3GRUIS8_S8_EEPNS2_8FastLSTMIS8_S8_EEPNS2_10MaxPoolingIS8_S8_EEPNS2_11MeanPoolingIS8_S8_EEPNS2_23MiniBatchDiscriminationIS8_S8_EEPNS2_16MultiplyConstantIS8_S8_EEPNS2_13MultiplyMergeIS8_S8_JEEEPS1G_PNS2_7PaddingIS8_S8_EEPNS2_5PReLUIS8_S8_EEPNS2_10WeightNormIS8_S8_JEEEPNS2_4CELUIS8_S8_EENS4_IPNS2_9RecurrentIS8_S8_JEEEJPNS2_18RecurrentAttentionIS8_S8_EEPNS2_15ReinforceNormalIS8_S8_EEPNS2_17ReparametrizationIS8_S8_EEPNS2_6SelectIS8_S8_EEPNS2_10SequentialIS8_S8_Lb0EJEEEPNS4L_IS8_S8_Lb1EJEEEPNS2_7SubviewIS8_S8_EEPNS2_13VRClassRewardIS8_S8_EEPNS2_16VirtualBatchNormIS8_S8_EEEEEEEEEENT_11result_typeERKS52_OT0_ apply_visitor_unary.hpp:68
mlpack::ann::RNN&lt;mlpack::ann::MeanSquaredError&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;, mlpack::ann::HeInitialization&gt;::Backward rnn_impl.hpp:518
mlpack::ann::RNN&lt;mlpack::ann::MeanSquaredError&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;, mlpack::ann::HeInitialization&gt;::EvaluateWithGradient&lt;arma::Mat&lt;double&gt; &gt; rnn_impl.hpp:408
ens::AddSeparableEvaluateWithGradient&lt;mlpack::ann::RNN&lt;mlpack::ann::MeanSquaredError&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;, mlpack::ann::HeInitialization&gt;, arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt;, true, true&gt;::EvaluateWithGradient add_separable_evaluate_with_gradient.hpp:81
ens::SGD&lt;ens::AdamUpdate, ens::NoDecay&gt;::Optimize&lt;mlpack::ann::RNN&lt;mlpack::ann::MeanSquaredError&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;, mlpack::ann::HeInitialization&gt;, arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt;, ens::PrintLoss&amp;, ens::ProgressBar&amp;, ens::EarlyStopAtMinLoss&amp;&gt; sgd_impl.hpp:145
ens::SGD&lt;ens::AdamUpdate, ens::NoDecay&gt;::Optimize&lt;mlpack::ann::RNN&lt;mlpack::ann::MeanSquaredError&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;, mlpack::ann::HeInitialization&gt;, arma::Mat&lt;double&gt;, ens::PrintLoss&amp;, ens::ProgressBar&amp;, ens::EarlyStopAtMinLoss&amp;&gt; sgd.hpp:143
mlpack::ann::RNN&lt;mlpack::ann::MeanSquaredError&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;, mlpack::ann::HeInitialization&gt;::Train&lt;ens::SGD&lt;ens::AdamUpdate, ens::NoDecay&gt;, ens::PrintLoss, ens::ProgressBar, ens::EarlyStopAtMinLoss&gt; rnn_impl.hpp:124
&lt;lambda(const auto:4&amp;, const auto:5&amp;)&gt;::operator()&lt;arma::Mat&lt;double&gt;, arma::Mat&lt;double&gt; &gt;(const arma::Mat&lt;double&gt; &amp;, const arma::Mat&lt;double&gt; &amp;) const main.cpp:162
std::_Function_handler&lt;void(const arma::Mat&lt;double&gt;&amp;, const arma::Mat&lt;double&gt;&amp;), SpawnAndTrainRNN(size_t, size_t)::&lt;lambda(const auto:4&amp;, const auto:5&amp;)&gt; &gt;::_M_invoke(const std::_Any_data &amp;, const arma::Mat&lt;double&gt; &amp;, const arma::Mat&lt;double&gt; &amp;) std_function.h:316
std::function&lt;void (arma::Mat&lt;double&gt; const&amp;, arma::Mat&lt;double&gt; const&amp;)&gt;::operator()(arma::Mat&lt;double&gt; const&amp;, arma::Mat&lt;double&gt; const&amp;) const std_function.h:706
&lt;lambda(const auto:2&amp;, const auto:3&amp;)&gt;::operator()&lt;arma::Col&lt;double&gt;, arma::Col&lt;double&gt; &gt;(const arma::Col&lt;double&gt; &amp;, const arma::Col&lt;double&gt; &amp;) main.cpp:100
std::_Function_handler&lt;bool(const arma::Col&lt;double&gt;&amp;, const arma::Col&lt;double&gt;&amp;), EnumerateDataChunks(size_t, std::function&lt;void(const arma::Mat&lt;double&gt;&amp;, const arma::Mat&lt;double&gt;&amp;)&gt;)::&lt;lambda(const auto:2&amp;, const auto:3&amp;)&gt; &gt;::_M_invoke(const std::_Any_data &amp;, const arma::Col&lt;double&gt; &amp;, const arma::Col&lt;double&gt; &amp;) std_function.h:302
std::function&lt;bool (arma::Col&lt;double&gt; const&amp;, arma::Col&lt;double&gt; const&amp;)&gt;::operator()(arma::Col&lt;double&gt; const&amp;, arma::Col&lt;double&gt; const&amp;) const std_function.h:706
&lt;lambda(auto:1&amp;)&gt;::operator()&lt;const std::__cxx11::basic_string&lt;char&gt; &gt;(const std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &amp;) const main.cpp:74
std::_Function_handler&lt;bool(const std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;&amp;), EnumerateDataPoints(std::function&lt;bool(const arma::Col&lt;double&gt;&amp;, const arma::Col&lt;double&gt;&amp;)&gt;)::&lt;lambda(auto:1&amp;)&gt; &gt;::_M_invoke(const std::_Any_data &amp;, const std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &amp;) std_function.h:302
std::function&lt;bool (std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)&gt;::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const std_function.h:706
StringOps::EnumerateLines(std::istream&amp;, std::function&lt;bool (std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)&gt; const&amp;, long) StringOps.cpp:36
StringOps::ZEnumerateLines(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::function&lt;bool (std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)&gt; const&amp;, long) StringOps.cpp:69
EnumerateDataPoints(std::function&lt;bool (arma::Col&lt;double&gt; const&amp;, arma::Col&lt;double&gt; const&amp;)&gt;) main.cpp:35
EnumerateDataChunks(unsigned long, std::function&lt;void (arma::Mat&lt;double&gt; const&amp;, arma::Mat&lt;double&gt; const&amp;)&gt;) main.cpp:95
SpawnAndTrainRNN main.cpp:138
main main.cpp:182
__libc_start_main 0x00007f073d210b97
_start 0x000055ea4995426a
&lt;/denchmark-code&gt;

The example I was testing, was working properly, so this looks like something that I did.
What did I miss?
	</description>
	<comments>
		<comment id='1' author='menkaur' date='2020-06-09T23:46:21Z'>
		Does this one file with a new model or with the loaded one?
		</comment>
		<comment id='2' author='menkaur' date='2020-06-10T01:09:28Z'>
		This happens when I train a new model
		</comment>
		<comment id='3' author='menkaur' date='2020-06-10T11:37:59Z'>
		Okay, so it's not a serialization issue.
		</comment>
		<comment id='4' author='menkaur' date='2020-07-03T23:48:30Z'>
		&lt;denchmark-link:https://github.com/menkaur&gt;@menkaur&lt;/denchmark-link&gt;
 I'm not sure what's going wrong here---can you provide a simple example program and data so that we can reproduce this issue and try to debug it?
		</comment>
		<comment id='5' author='menkaur' date='2020-08-03T00:07:11Z'>
		This issue has been automatically marked as stale because it has not had any recent activity.  It will be closed in 7 days if no further activity occurs.  Thank you for your contributions! üëç
		</comment>
	</comments>
</bug>