<bug id='2310' author='prince776' open_date='2020-03-17T13:38:42Z' closed_time='2020-03-20T08:19:28Z'>
	<summary>Convolution&amp;lt;&amp;gt; Layer cauing Segmentation Fault( core dumped) error.</summary>
	<description>
Hi, I was working on developing models and whenever I exceeded a certain limit of output maps in convolution layer, and then tried to train, I got the error : Segmentation fault (core dumped)
basically:
&lt;denchmark-code&gt;model.Add&lt;Convolution&lt;&gt;&gt;(3, 16, 7, 7, 2, 2, 3, 3, 28,28);
model.Add&lt;Convolution&lt;&gt;&gt;(16, 192, 3, 3, 1, 1, 1, 1, 10,10);
...
model.Train(Xs,Ys,optimizer);
&lt;/denchmark-code&gt;

works, but
&lt;denchmark-code&gt;model.Add&lt;Convolution&lt;&gt;&gt;(3, 64, 7, 7, 2, 2, 3, 3, 28,28);
model.Add&lt;Convolution&lt;&gt;&gt;(64 192, 3, 3, 1, 1, 1, 1, 10,10);
...
model.Train(Xs,Ys,optimizer);
&lt;/denchmark-code&gt;

terminates with error:
&lt;denchmark-code&gt;Segmentation fault (core dumped)
&lt;/denchmark-code&gt;

As suggested by &lt;denchmark-link:https://github.com/zoq&gt;@zoq&lt;/denchmark-link&gt;
, I used gdb to find what exactly is causing error and I found that
&lt;denchmark-code&gt;arma::Mat&lt;double&gt;::operator=(arma::Mat&lt;double&gt; const&amp;) ()
&lt;/denchmark-code&gt;

inside  Gradient() function of Convolution&lt;&gt; class is causing this error when called during Training process, which probably means when a matrix is being filled, but where exactly I have no idea.
Full backtrace: &lt;denchmark-link:https://pastebin.com/bvVzJJjs&gt;https://pastebin.com/bvVzJJjs&lt;/denchmark-link&gt;

I'm not able to figure out further what to try.
Any help/suggestion are welcome.
	</description>
	<comments>
		<comment id='1' author='prince776' date='2020-03-17T13:56:07Z'>
		I am facing similar issues with the ZFNet model I have implemented.
		</comment>
		<comment id='2' author='prince776' date='2020-03-17T14:58:52Z'>
		&lt;denchmark-link:https://github.com/prince776&gt;@prince776&lt;/denchmark-link&gt;
, Could you try one more thing please. Could run predict without training, if the problem is associated with Gradient then at least predict part should work fine. Thanks a lot for opening this issue and I think the above simple check might give us more insight. Thanks a ton.
		</comment>
		<comment id='3' author='prince776' date='2020-03-17T16:31:43Z'>
		Hi &lt;denchmark-link:https://github.com/codeboy5&gt;@codeboy5&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/kartikdutt18&gt;@kartikdutt18&lt;/denchmark-link&gt;
 Thanks for the responses. Yes &lt;denchmark-link:https://github.com/kartikdutt18&gt;@kartikdutt18&lt;/denchmark-link&gt;
 Predict is working totally fine. Just as gbd showed, it's due to Gradient Function of Convolution class.
		</comment>
		<comment id='4' author='prince776' date='2020-03-17T16:40:04Z'>
		Okay, I'll try to debug it tonight / early tomorrow. Whatever find I'll post it here. Thanks.
		</comment>
		<comment id='5' author='prince776' date='2020-03-17T16:43:00Z'>
		How did you run AlexNet by the way? I saw your implementation of AlexNet it also had 64 output maps. You were using Sequential&lt;&gt; instead of FFN&lt;&gt;, can you tell me how did you train it?
		</comment>
		<comment id='6' author='prince776' date='2020-03-17T16:48:57Z'>
		&lt;denchmark-link:https://github.com/prince776&gt;@prince776&lt;/denchmark-link&gt;
 Thanks for posting this &lt;denchmark-link:https://github.com/kartikdutt18&gt;@kartikdutt18&lt;/denchmark-link&gt;
 I will also try to debug this if I find something I will post it here.
		</comment>
		<comment id='7' author='prince776' date='2020-03-17T16:56:17Z'>
		&lt;denchmark-link:https://github.com/prince776&gt;@prince776&lt;/denchmark-link&gt;
, I think as far as I remember for AlexNet I used padding and FFN type implementation rather than a class type. The class type always failed so I assumed that I had misused a pointer somewhere. Also one thing to know is  Thanks a lot &lt;denchmark-link:https://github.com/himanshupathak21061998&gt;@himanshupathak21061998&lt;/denchmark-link&gt;
, I think this way if there is really an issue we can get it resolved as quickly as possible.
		</comment>
		<comment id='8' author='prince776' date='2020-03-18T09:52:48Z'>
		So far this is what I have done:

Built a neural network test case to add in mlpack.
Tested it for various output channels. (2, 8, 16, 32).
Result : Worked for 2, 8, 16.
Test is stuck on 32 channel output.
Also there are model implementation of VGG19, 16 which have channels upto 512. And if they do work then it maybe it is related to limitation of our device.

		</comment>
		<comment id='9' author='prince776' date='2020-03-18T10:15:22Z'>
		Okay so the test didn't segfault on 32 channels. Going for vgdb.
		</comment>
		<comment id='10' author='prince776' date='2020-03-18T11:51:50Z'>
		I was also thinking if it's due to some sort of device limitation, but while running the program the memory and CPU usage all were not nearly full.
I think you said you have a raspberry pi set up with mlpack so, can you try to see at how many output channels does it segfaults compared with your laptop/computer.
		</comment>
		<comment id='11' author='prince776' date='2020-03-18T11:57:58Z'>
		I can try that but before I go for it, I think &lt;denchmark-link:https://github.com/adithya-tp&gt;@adithya-tp&lt;/denchmark-link&gt;
 has implemented VGG16, so I wanted to know if he could share some results to ensure that it works. That way we know that it's not related to the device. Could you also share details of your system:
My Local System has the following config:

16 GB RAM
i7, 7 th gen (2.3 GHz)
OS: OSX (Catalina)

		</comment>
		<comment id='12' author='prince776' date='2020-03-18T12:05:38Z'>
		My Local system has the following specifications:

8 GB RAM
i5 8th gen (2.3 GHz)
OS: Ubuntu 16.04
Dedicated Nvidia GTX 1050 Ti, 4GB VRAM (I wasn't using BLAS though)

		</comment>
		<comment id='13' author='prince776' date='2020-03-18T12:14:12Z'>
		If you apply the changes from &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2234&gt;#2234&lt;/denchmark-link&gt;
, does it fix the issue?
		</comment>
		<comment id='14' author='prince776' date='2020-03-18T12:17:40Z'>
		I am building mlpack using that right now, Hopefully will get to know about that soon.
		</comment>
		<comment id='15' author='prince776' date='2020-03-18T12:46:25Z'>
		Hey &lt;denchmark-link:https://github.com/prince776&gt;@prince776&lt;/denchmark-link&gt;
, I took my LeNet and made the following change:
&lt;denchmark-code&gt;  leNet = new Sequential&lt;&gt;();
  ConvolutionBlock(inputChannel, 6, 5, 5, 1, 1, 2, 2);
  PoolingBlock(2, 2, 2, 2);
  ConvolutionBlock(6, 512, 5, 5, 1, 1, 2, 2);
  PoolingBlock(2, 2, 2, 2);
  // Add linear layer for LeNet.
  if (leNetVer == 1)
  {
    leNet-&gt;Add&lt;Linear&lt;&gt;&gt;(512 * inputWidth * inputHeight, numClasses);
  }
&lt;/denchmark-code&gt;

It even works with 4048.
It's working fine for me (almost 1 epoch complete, will try higher channels and get back to you).
However alexnet fails so maybe the problem isn't with convolution?
Hopefully I will know more in an hour.
		</comment>
		<comment id='16' author='prince776' date='2020-03-18T13:43:24Z'>
		Other thing I tried, I reduced kernel sizes in alexnet and printed input shape after each convolution.
&lt;denchmark-code&gt;16
8
4
4
5
&lt;/denchmark-code&gt;

But it segfaults even after creating a copy for inputs in convolution layer.
		</comment>
		<comment id='17' author='prince776' date='2020-03-18T15:09:11Z'>
		
Hey @prince776, I took my LeNet and made the following change:
  leNet = new Sequential&lt;&gt;();
  ConvolutionBlock(inputChannel, 6, 5, 5, 1, 1, 2, 2);
  PoolingBlock(2, 2, 2, 2);
  ConvolutionBlock(6, 512, 5, 5, 1, 1, 2, 2);
  PoolingBlock(2, 2, 2, 2);
  // Add linear layer for LeNet.
  if (leNetVer == 1)
  {
    leNet-&gt;Add&lt;Linear&lt;&gt;&gt;(512 * inputWidth * inputHeight, numClasses);
  }

It even works with 4048.
It's working fine for me (almost 1 epoch complete, will try higher channels and get back to you).
However alexnet fails so maybe the problem isn't with convolution?
Hopefully I will know more in an hour.

Can you share the full code of this please.
		</comment>
		<comment id='18' author='prince776' date='2020-03-18T15:13:12Z'>
		The code is available &lt;denchmark-link:https://github.com/mlpack/models/pull/60&gt;here&lt;/denchmark-link&gt;
.Changes that you need to make are:

There is an incomplete if condition in data loader, remove that.
replace output channel = 16 there by any number you want and make the change in if condition to match that number.
Run using ./bin/mnist_tutorial_cnn

		</comment>
		<comment id='19' author='prince776' date='2020-03-18T15:29:37Z'>
		Thanks
		</comment>
		<comment id='20' author='prince776' date='2020-03-18T15:46:44Z'>
		Quick update:
I used Sequential&lt;&gt; to add convolution layers then wraped it in FFN with identity layer first (just like in your example of mnist) and it worked.
However if convolution layer was directly added to FFN and not to Sequential&lt;&gt; then it terminates with segfault.
So:
&lt;denchmark-code&gt;  Sequential&lt;&gt; module;
  module.Add&lt;Convolution&lt;&gt;&gt;(1, 64, 5, 5, 1, 1, 0, 0, 28,28);
  module.Add&lt;LeakyReLU&lt;&gt;&gt;();
  module.Add&lt;MaxPooling&lt;&gt;&gt;(2, 2, 2, 2);
  module.Add&lt;Convolution&lt;&gt;&gt;(64, 128, 5, 5, 1, 1, 0, 0, 12,12);

  FFN&lt;NegativeLogLikelihood&lt;&gt;, RandomInitialization&gt; model;
  model.Add&lt;IdentityLayer&lt;&gt;&gt;();
  model.Add&lt;Sequential&lt;&gt;&gt;(module);
  model.Train(Xs,Ys);
&lt;/denchmark-code&gt;

works.
but,
&lt;denchmark-code&gt;  FFN&lt;NegativeLogLikelihood&lt;&gt;, RandomInitialization&gt; model;
  model.Add&lt;Convolution&lt;&gt;&gt;(1, 64, 5, 5, 1, 1, 0, 0, 28,28);
  model.Add&lt;LeakyReLU&lt;&gt;&gt;();
  model.Add&lt;MaxPooling&lt;&gt;&gt;(2, 2, 2, 2);
  model.Add&lt;Convolution&lt;&gt;&gt;(64, 128, 5, 5, 1, 1, 0, 0, 12,12);
  model.Train(Xs,Ys);
&lt;/denchmark-code&gt;

gives segfault error
		</comment>
		<comment id='21' author='prince776' date='2020-03-18T15:50:42Z'>
		Hey &lt;denchmark-link:https://github.com/prince776&gt;@prince776&lt;/denchmark-link&gt;
, Did you try out my LeNet yet?
I am really happy with that model, it worked everywhere so if you would like you can try that too. What do you think could be causing this, maybe we missed some documentation?
Like Identity layer bit that I said was written as a comment in sequential.hpp .
		</comment>
		<comment id='22' author='prince776' date='2020-03-18T15:50:51Z'>
		Update:
FFN also works without Sequential if IndentityLayer&lt;&gt; is added before everything. However it is slower.
		</comment>
		<comment id='23' author='prince776' date='2020-03-18T15:53:34Z'>
		
Hey @prince776, Did you try out my LeNet yet?
I am really happy with that model, it worked everywhere so if you would like you can try that too. What do you think could be causing this, maybe we missed some documentation?
Like Identity layer bit that I said was written as a comment in sequential.hpp .

I am working on it. Getting error: [FATAL] Cannot open file './../data/mnist_train.csv'. Problem is it still persists even if I add mnist_train.csv file
		</comment>
		<comment id='24' author='prince776' date='2020-03-18T15:54:03Z'>
		In build folder,
Run this, cmake -DDOWNLOAD_MNIST=ON ../
It's off by default. It's will place the file in the right folder.
Then run make command followed by ./bin/mnist_tutorial_cnn.
The cmake checks for existing file so I would delete it incase there was an issue with it.
		</comment>
		<comment id='25' author='prince776' date='2020-03-18T15:58:08Z'>
		It works correctly.
		</comment>
		<comment id='26' author='prince776' date='2020-03-18T15:58:12Z'>
		Other option is -DDOWNLOAD_DATASETS=ON (It will download all datasets though). I am working on a dataloader to download file during runtime rather than when it is compiled.
		</comment>
		<comment id='27' author='prince776' date='2020-03-18T15:58:30Z'>
		Great!!!
		</comment>
		<comment id='28' author='prince776' date='2020-03-18T15:59:37Z'>
		So Apparently as long as IndentityLayer&lt;&gt; is added before these convolution layers, it works fine, but without it can terminate with segfault for some 50+ outputChannels.
		</comment>
		<comment id='29' author='prince776' date='2020-03-18T17:40:21Z'>
		
If you apply the changes from #2234, does it fix the issue?

This fixed the issue for me.
		</comment>
		<comment id='30' author='prince776' date='2020-03-18T18:04:39Z'>
		&lt;denchmark-link:https://github.com/prince776&gt;@prince776&lt;/denchmark-link&gt;
, Should we close this? If this issue is resolved for you.
		</comment>
		<comment id='31' author='prince776' date='2020-03-18T18:16:10Z'>
		Oh, I am late &lt;denchmark-link:https://github.com/kartikdutt18&gt;@kartikdutt18&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/prince776&gt;@prince776&lt;/denchmark-link&gt;
  thanks for working on this. Maybe next time I will be able to help you guys and also get help from you.
		</comment>
		<comment id='32' author='prince776' date='2020-03-18T18:57:30Z'>
		
@prince776, Should we close this? If this issue is resolved for you.

I will close it later tomorrow because I'm still getting some segfaults in inception network. I'm not sure if that's because of my implementation or convolution layer. I will be doing further testing and once I'm done I'll close it if it's resolved.
		</comment>
		<comment id='33' author='prince776' date='2020-03-20T08:19:28Z'>
		I'm closing this issue, &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2234&gt;#2234&lt;/denchmark-link&gt;
 solves it.
		</comment>
	</comments>
</bug>