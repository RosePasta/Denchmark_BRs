<bug id='534' author='theSundayProgrammer' open_date='2016-03-01T20:42:59Z' closed_time='2016-03-07T21:54:29Z'>
	<summary>Neural Network: RNN test  Internal Compiler Error on MSVC</summary>
	<description>
This is a Microsoft bug. I hope there is a work around:
...\mlpack\src\mlpack\methods\ann\rnn_impl.hpp(302): fatal error C1001: An internal error has occurred in the compiler.
(compiler file 'msc1.cpp', line 1421)
To work around this problem, try simplifying or changing the program near the locations listed above.
Please choose the Technical Support command on the Visual C++
Help menu, or open the Technical Support help file for more information
...\mlpack\src\mlpack\methods\ann\rnn_impl.hpp(283): note: while compiling class template member function 'void mlpack::ann::RNNstd::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;::Gradient(const arma::mat &amp;,const size_t,arma::mat &amp;)'
...\mlpack\src\mlpack\core\optimizers\sgd\sgd_impl.hpp(88): note: see reference to function template instantiation 'void mlpack::ann::RNNstd::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;::Gradient(const arma::mat &amp;,const size_t,arma::mat &amp;)' being compiled
...\mlpack\src\mlpack\core\optimizers\sgd\sgd_impl.hpp(33): note: while compiling class template member function 'double mlpack::optimization::SGDmlpack::ann::RNN&lt;std::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;&gt;::Optimize(arma::mat &amp;)'
...\mlpack\src\mlpack\methods\ann\rnn_impl.hpp(168): note: see reference to function template instantiation 'double mlpack::optimization::SGDmlpack::ann::RNN&lt;std::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;&gt;::Optimize(arma::mat &amp;)' being compiled
...\mlpack\src\mlpack\core\optimizers\sgd\sgd_impl.hpp(22): note: while compiling class template member function 'mlpack::optimization::SGDmlpack::ann::RNN&lt;std::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;&gt;::SGD(DecomposableFunctionType &amp;,const double,const size_t,const double,const bool)'
with
[
DecomposableFunctionType=mlpack::ann::RNNstd::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;
]
...\mlpack\src\mlpack\tests\recurrent_network_test.cpp(108): note: see reference to function template instantiation 'mlpack::optimization::SGDmlpack::ann::RNN&lt;std::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;&gt;::SGD(DecomposableFunctionType &amp;,const double,const size_t,const double,const bool)' being compiled
with
[
DecomposableFunctionType=mlpack::ann::RNNstd::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;
]
...\mlpack\src\mlpack\tests\recurrent_network_test.cpp(108): note: see reference to class template instantiation 'mlpack::optimization::SGDmlpack::ann::RNN&lt;std::tuple&lt;mlpack::ann::LinearLayer&lt;arma::mat,arma::mat &amp;,mlpack::ann::RecurrentLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;,mlpack::ann::LinearLayerarma::mat,arma::mat &amp;,mlpack::ann::BaseLayermlpack::ann::LogisticFunction,arma::mat,arma::mat &amp;&gt;,mlpack::ann::BinaryClassificationLayer,mlpack::ann::RandomInitialization,mlpack::ann::MeanSquaredErrorFunction&gt;&gt;' being compiled
	</description>
	<comments>
		<comment id='1' author='theSundayProgrammer' date='2016-03-02T13:13:20Z'>
		Is this VS2015 or an earlier version?
		</comment>
		<comment id='2' author='theSundayProgrammer' date='2016-03-02T22:11:44Z'>
		VS2015
On Thu, Mar 3, 2016 at 12:13 AM, Ryan Curtin &lt;denchmark-link:mailto:notifications@github.com&gt;notifications@github.com&lt;/denchmark-link&gt;

wrote:

Is this VS2015 or an earlier version?
—
Reply to this email directly or view it on GitHub
#534 (comment).

&lt;denchmark-h:h2&gt;&lt;/denchmark-h&gt;

Joseph Chakravarti Mariadassou
&lt;denchmark-link:http://thesundayprogrammer.com&gt;http://thesundayprogrammer.com&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='theSundayProgrammer' date='2016-03-02T22:32:08Z'>
		:(
I don't know what to tell you on this one then.  If you find a workaround that doesn't change the flexibility of the code, we can include it, but finding workarounds for C1001s is usually a nightmare.  I hear the Intel compiler generally gives better results, but I haven't tried that myself...
		</comment>
		<comment id='4' author='theSundayProgrammer' date='2016-03-02T22:44:10Z'>
		I was wondering if the FFN or CNN class goes through without any errors?
		</comment>
		<comment id='5' author='theSundayProgrammer' date='2016-03-03T00:47:13Z'>
		FFN and CNN are fine.
On Thu, Mar 3, 2016 at 9:44 AM, Marcus Edel &lt;denchmark-link:mailto:notifications@github.com&gt;notifications@github.com&lt;/denchmark-link&gt;

wrote:

I was wondering if the FFN or CNN class goes through without any errors?
—
Reply to this email directly or view it on GitHub
#534 (comment).

&lt;denchmark-h:h2&gt;&lt;/denchmark-h&gt;

Joseph Chakravarti Mariadassou
&lt;denchmark-link:http://thesundayprogrammer.com&gt;http://thesundayprogrammer.com&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='theSundayProgrammer' date='2016-03-03T01:27:08Z'>
		In this case, we should be able to find a workaround. I have to setup a windows machine first, I guess I can use your tutorial for that? Any updates to make things easier? Or maybe I can use the modified mlpack windows version that &lt;denchmark-link:https://github.com/rcurtin&gt;@rcurtin&lt;/denchmark-link&gt;
 mentioned, I can't remember the name of the project.
		</comment>
		<comment id='7' author='theSundayProgrammer' date='2016-03-03T01:32:50Z'>
		&lt;denchmark-link:https://github.com/vespucciproject&gt;https://github.com/vespucciproject&lt;/denchmark-link&gt;

Maybe AppVeyor would be useful to use for testing here.
Sometimes workarounds for MSVC like this involve stuff like reordering data members and other bizarre things.  I have no idea what will work here, though.
		</comment>
		<comment id='8' author='theSundayProgrammer' date='2016-03-07T21:54:29Z'>
		I fixed the issue in &lt;denchmark-link:https://github.com/mlpack/mlpack/commit/f58aa3662eae235f74ed8fc6ef1e3446b0f28445&gt;f58aa36&lt;/denchmark-link&gt;
. I'm going to go ahead and close this issue then.
		</comment>
	</comments>
</bug>