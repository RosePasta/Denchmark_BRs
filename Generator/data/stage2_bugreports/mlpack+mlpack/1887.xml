<bug id='1887' author='pensivevoice' open_date='2019-04-30T17:07:13Z' closed_time='2019-05-23T04:22:14Z'>
	<summary>Increasing the number of trees in the random forest model does not improve performance</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue description&lt;/denchmark-h&gt;

Increasing the number of trees in the random forest model does not improve performance. It is as if all the trees in the forest are equal. Is there a setting to turn on randomness that I am missing?
&lt;denchmark-link:https://github.com/mlpack/mlpack/files/3132297/RandomForestNumTreesPotentialBug.txt&gt;RandomForestNumTreesPotentialBug.txt&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Your environment&lt;/denchmark-h&gt;


version of mlpack: 3.0.4
operating system: Windows 10
compiler: Visual Studio 2015
version of dependencies (Boost/Armadillo): 1_66_0/7.800.2
any other environment information you think is relevant:

&lt;denchmark-h:h4&gt;Steps to reproduce&lt;/denchmark-h&gt;

Create one random forest model with numTrees = 2 and another with numTrees = 10. Keep all other parameters constant. Training performance (e.g. accuracy) does not change.
&lt;denchmark-h:h4&gt;Expected behavior&lt;/denchmark-h&gt;

Training performance should improve when the number of trees increases since the more complex model is better able to overfit the training data.
&lt;denchmark-h:h4&gt;Actual behavior&lt;/denchmark-h&gt;

Training performance does not change.
&lt;denchmark-link:https://github.com/mlpack/mlpack/files/3132299/RandomForestNumTreesPotentialBug.txt&gt;RandomForestNumTreesPotentialBug.txt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='pensivevoice' date='2019-05-03T10:05:07Z'>
		&lt;denchmark-link:https://github.com/pensivevoice&gt;@pensivevoice&lt;/denchmark-link&gt;
 thanks for opening the issue. I think there might be a bug. I will let you know if I find any.
		</comment>
		<comment id='2' author='pensivevoice' date='2019-05-04T07:06:08Z'>
		I guess &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1891&gt;#1891&lt;/denchmark-link&gt;
 resolves the issue.
		</comment>
		<comment id='3' author='pensivevoice' date='2019-05-04T15:51:09Z'>
		Right, thanks for pointing it out &lt;denchmark-link:https://github.com/MuLx10&gt;@MuLx10&lt;/denchmark-link&gt;
.  I should have updated this too.  I ended up having some time to look into this yesterday after an IRC discussion and I think I found what the issue was.  Sorry if I stepped on your toes a bit while you were debugging.
&lt;denchmark-link:https://github.com/pensivevoice&gt;@pensivevoice&lt;/denchmark-link&gt;
 If you can test that &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1891&gt;#1891&lt;/denchmark-link&gt;
 fixes the issue, it would be really helpful. 
		</comment>
		<comment id='4' author='pensivevoice' date='2019-05-07T00:43:29Z'>
		Thanks so much for looking into it. Now changing the number of trees makes a difference but not in the expected way. Training performance follows an inverted U shape: it reaches a maximum at some point instead of continue increasing with the number of trees. Also training performance peaks at a low value. It is not what you would expect from a random forest model with enough trees and a small minimum leaf size.
		</comment>
		<comment id='5' author='pensivevoice' date='2019-05-07T19:52:43Z'>
		In case this might help this is the output I obtained after running the attached program. Here Type is training data (as opposed to test data), Trees is the number of trees in the forest, MLSz is the minimum leaf size parameter, Acc stands for accuracy and Prec for precision.
&lt;denchmark-link:https://github.com/mlpack/mlpack/files/3154307/RandomForestNumTreesBug2.txt&gt;RandomForestNumTreesBug2.txt&lt;/denchmark-link&gt;

Type,  Trees,   MLSz,      Acc,     Prec,   Recall,       F1
Train,      2,      1,            0.876,   0.864, 0.954,       0.906486
Train,     10,     1,            0.873,   0.834, 0.997,       0.908171
Train,     20,     1,            0.868,   0.827, 1.000,       0.905172
Train,     40,     1,            0.880,   0.840, 1.000,       0.913043
Train,    100,     1,           0.878,   0.838, 1.000,       0.911722
Train,    200,     1,           0.878,   0.838, 1.000,       0.911722
		</comment>
		<comment id='6' author='pensivevoice' date='2019-05-08T11:33:39Z'>
		You're right, there is something else wrong here.  I am currently digging into the issue.
		</comment>
		<comment id='7' author='pensivevoice' date='2019-05-08T19:20:45Z'>
		It was pointed out to me that I should use the template  MultipleRandomDimensionSelect instead of RandomDimensionSelect. When doing this the random forest model seems to work as expected. I am attaching a sample C++ program that illustrate how to use the random forest model so that it performs as most users would expect. The results now look good. Once again thanks for looking into this issue.
Dataset german.csv has 23 features,  4 = sqrt(23) will be used for splitting.
Type,  Trees,   MLSz,      Acc,     Prec,   Recall,       F1
Train,      2,      1, 0.923000, 0.971039, 0.904762, 0.936730
Train,     10,      1, 0.985000, 0.978227, 0.998413, 0.988217
Train,     20,      1, 0.999000, 0.998415, 1.000000, 0.999207
Train,     40,      1, 0.998000, 0.996835, 1.000000, 0.998415
Train,    100,      1, 0.999000, 0.998415, 1.000000, 0.999207
Train,    200,      1, 0.998000, 0.996835, 1.000000, 0.998415
&lt;denchmark-link:https://github.com/mlpack/mlpack/files/3158946/RandomForestExample.txt&gt;RandomForestExample.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='pensivevoice' date='2019-05-16T22:50:46Z'>
		Hey &lt;denchmark-link:https://github.com/pensivevoice&gt;@pensivevoice&lt;/denchmark-link&gt;
, sorry for the slow response.  I've been looking into it for some time and I think a fix is prepared in &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1891&gt;#1891&lt;/denchmark-link&gt;
.  You can give that a shot and let me know if it works.  Once that is merged we'll release 3.1.1 with the fix.
And yeah, using MultipleRandomDimensionSelect with a large number of dimensions should help in the existing code.  However the PR has some additional fixes that I think will help further. üëç
		</comment>
		<comment id='9' author='pensivevoice' date='2019-05-17T17:26:33Z'>
		Hi &lt;denchmark-link:https://github.com/MuLx10&gt;@MuLx10&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/rcurtin&gt;@rcurtin&lt;/denchmark-link&gt;
. Thanks for making time to deal with this issue. Here are my results.
Validation The mlpack results were validated against scikit-learn in a binary classification task using 100 bootstrap datasets and their complement (those samples not in the bootstrap set). I trained on the bootstrap dataset and used the complement as a test set. The hyperparameters used were: 50 trees, a minimum leave size of 2, and the splitting dimensions to use was set to the square root of the number of features. For this last parameter I used MultipleRandomDimensionSelect(sqrt(number_of_features) in mlpack. The mean squared error on each test set was selected as the performance measure.
Results Plotting mlpack versus scikit-learn produced points along a 45 degree line. It was very interesting that both implementations had a "hard time" on the same datasets. The difference of the means was 3e-4 and all differences were within 1e-3. In summary, no statistically significant difference was detected among the implementations. A speed-up of 2.7 was detected. This means that what took 2.7 units of time before, now takes 1 unit.
		</comment>
		<comment id='10' author='pensivevoice' date='2019-05-17T18:42:40Z'>
		&lt;denchmark-link:https://github.com/pensivevoice&gt;@pensivevoice&lt;/denchmark-link&gt;
 nice results, glad that the fixes helped.  Any chance you could share the plot?
		</comment>
		<comment id='11' author='pensivevoice' date='2019-05-17T19:01:09Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/50149223/58280040-a924d900-7d54-11e9-9404-230de21be323.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='pensivevoice' date='2019-05-23T04:22:14Z'>
		With &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1891&gt;#1891&lt;/denchmark-link&gt;
 merged, and your feedback, I think that this issue is solved.  Once I see that the builds are passing I will release mlpack 3.1.1 with the fix. :)  Thanks again for the report! 
		</comment>
		<comment id='13' author='pensivevoice' date='2019-05-23T19:20:02Z'>
		Thanks for fixing it!
		</comment>
	</comments>
</bug>