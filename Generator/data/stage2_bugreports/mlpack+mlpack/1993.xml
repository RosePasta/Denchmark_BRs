<bug id='1993' author='rcurtin' open_date='2019-09-01T00:51:20Z' closed_time='2019-09-21T15:34:29Z'>
	<summary>Fix sometimes-failing tests before 3.2.0 release</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue description&lt;/denchmark-h&gt;

Some of the mlpack tests seem to be failing; we should avoid making a release until we know that the tests won't regularly fail (thus causing bug reports). :)
Here are the ones I've found that seem to be failing:

 (#1998) RLComponentsTest/SimplePendulumTest: link
 (#1995) RandomForestMainTest/RandomForestDiffMinLeafSize: link
 (#1995) RandomForestMainTest/RandomForestDiffNumTreeTest: link
 (#1999) RewardClippingTest/RewardClippedAcrobotWithDQN: link
 (#2002) LinearSVMTest/LinearSVMLBFGSTwoClasses: link
 (#2001) LSHTest/MultiprobeTest: link
 (#2000) CFTest/SerializationUserMeanNormalizationTest: link
 (#2000) CFTest/SerializationItemMeanNormalizationTest: link
 (#2000) CFTest/SerializationCombinedNormalizationTest: link

Those last three seem to be only on OS X and may be caused by &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1989&gt;#1989&lt;/denchmark-link&gt;
 (though I think that would be a bit strange).
After fixing all these and re-running the nightly and weekly builds, these tests failed:

 (#2004) GmmTrainMainTest/GmmTrainTrialsTest
 QLearningTest/DoubleCartPoleWithDQN
 (#2007) KNNMainTest/KNNAllTreeTypesTest
 (#2006) DecisionTreeTest/PerfectTrainingSet

&lt;denchmark-h:h4&gt;Your environment&lt;/denchmark-h&gt;


version of mlpack: git master
operating system: Linux, OS X, various
compiler: g++, clang
version of dependencies (Boost/Armadillo): various
any other environment information you think is relevant: these are off the build farm, so various configurations produce the failures

&lt;denchmark-h:h4&gt;Steps to reproduce&lt;/denchmark-h&gt;

Reproducing the test for an individual failure should be doable like this:

Add the following snippet at the top of the test case (right under BOOST_AUTO_TEST_CASE()):

&lt;denchmark-code&gt;mlpack::math::RandomSeed(std::time(NULL));
&lt;/denchmark-code&gt;

Note that if this is one of the tests in main_tests/, because those don't allow setting the random seed, use this instead:
&lt;denchmark-code&gt;const size_t seed = std::time(NULL);
mlpack::math::randGen.seed((uint32_t) seed);
srand((unsigned int) seed);
arma::arma_rng::set_seed(seed);
&lt;/denchmark-code&gt;



Recompile the tests.


Run many times until you find a failure (maybe it is useful to print the seed too, so you can reproduce it later).  I typically use a loop like this:


&lt;denchmark-code&gt;$ i=0; while(true); do echo $i; i=$(($i + 1)); bin/mlpack_test -t TestSuiteName/TestCaseName 2&gt;&amp;1 | grep 'fatal'; sleep 1; done
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Expected behavior&lt;/denchmark-h&gt;

Hopefully, the only output from that loop above should be the number of the test, with no failures.
&lt;denchmark-h:h4&gt;Actual behavior&lt;/denchmark-h&gt;

For these tests in particular, it's likely that they'll fail more than once in a thousand runs.  If they do, we should adjust them such that they don't fail.
Generally, but not always, this means increasing the tolerance of the tests.  However, the fact that a test sometimes fails doesn't always mean the tolerance is wrong---it can also mean a deeper issue with the code.
	</description>
	<comments>
		<comment id='1' author='rcurtin' date='2019-09-01T02:57:31Z'>
		I opened &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1995&gt;#1995&lt;/denchmark-link&gt;
 for the  failures.  I'll look into the  failure next; I'm not currently looking into anything else (I'll update this issue if that changes).
		</comment>
		<comment id='2' author='rcurtin' date='2019-09-01T11:56:23Z'>
		I opened &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1998&gt;#1998&lt;/denchmark-link&gt;
 for the failure. I'll look into the failure next.
		</comment>
		<comment id='3' author='rcurtin' date='2019-09-01T13:37:50Z'>
		I opened &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/1999&gt;#1999&lt;/denchmark-link&gt;
 for the  failure. Will look into the CF serialization issue next, unless someone else likes to.
		</comment>
		<comment id='4' author='rcurtin' date='2019-09-01T17:51:19Z'>
		I opened &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2000&gt;#2000&lt;/denchmark-link&gt;
 for the  test failures.
		</comment>
		<comment id='5' author='rcurtin' date='2019-09-02T22:59:34Z'>
		I figured out the LSH test failure in &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2001&gt;#2001&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='6' author='rcurtin' date='2019-09-03T06:31:46Z'>
		You both are super heroes :) , opened and debugged in a day :-p
		</comment>
		<comment id='7' author='rcurtin' date='2019-09-03T13:44:48Z'>
		&lt;denchmark-link:https://github.com/jeffin143&gt;@jeffin143&lt;/denchmark-link&gt;
 thanks!  Mostly I am just letting the tests run in the background and then take a look later.  Usually the fixes are already with code I'm familiar with, so it's not too hard. :)
I investigated the last failing linear SVM test and opened a fix in &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2002&gt;#2002&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='8' author='rcurtin' date='2019-09-04T21:09:14Z'>
		All the fixes so far are merged.  Now I'm going to run the nightly build and the weekly build and see if there are any additional failures. :)
		</comment>
		<comment id='9' author='rcurtin' date='2019-09-05T13:19:30Z'>
		Here are the four tests that failed in the weekly and nightly builds:

GmmTrainMainTest/GmmTrainTrialsTest
QLearningTest/DoubleCartPoleWithDQN
KNNMainTest/KNNAllTreeTypesTest
DecisionTreeTest/PerfectTrainingSet

I updated the issue description above to add those.  I'm working on GmmTrainTrialsTest now.
		</comment>
		<comment id='10' author='rcurtin' date='2019-09-05T17:49:04Z'>
		Will take a look at the QLearningTest/DoubleCartPoleWithDQN failure.
		</comment>
		<comment id='11' author='rcurtin' date='2019-09-06T02:31:44Z'>
		 should be handled in &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2004&gt;#2004&lt;/denchmark-link&gt;
.  I'll look into  tomorrow.
		</comment>
		<comment id='12' author='rcurtin' date='2019-09-06T12:07:43Z'>
		I'll look into KNNMainTest/KNNAllTreeTypesTest tomorrow.
		</comment>
		<comment id='13' author='rcurtin' date='2019-09-06T13:15:21Z'>
		&lt;denchmark-link:https://github.com/KimSangYeon-DGU&gt;@KimSangYeon-DGU&lt;/denchmark-link&gt;
 sounds good, I'll look into  then. 
		</comment>
		<comment id='14' author='rcurtin' date='2019-09-06T15:56:11Z'>
		&lt;denchmark-link:https://github.com/rcurtin&gt;@rcurtin&lt;/denchmark-link&gt;
 Oops... sorry, thanks!
		</comment>
		<comment id='15' author='rcurtin' date='2019-09-06T20:01:13Z'>
		&lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2006&gt;#2006&lt;/denchmark-link&gt;
 fixes .
		</comment>
		<comment id='16' author='rcurtin' date='2019-09-16T15:59:57Z'>
		I'm also working on the  failures.  These turn out to be caused at a lower level in ensmallen, and I opened &lt;denchmark-link:https://github.com/mlpack/ensmallen/pull/136&gt;mlpack/ensmallen#136&lt;/denchmark-link&gt;
 to solve it; but I am also working on workarounds for  now.  I think once those are merged in, we should get some clean builds. :)
		</comment>
		<comment id='17' author='rcurtin' date='2019-09-17T17:56:02Z'>
		&lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2014&gt;#2014&lt;/denchmark-link&gt;
 should fix the failure.
		</comment>
		<comment id='18' author='rcurtin' date='2019-09-21T15:34:29Z'>
		I'm sure we will encounter more failing tests in the future, but I think that we have addressed a lot of the big ones that users might encounter failures with.  So for the purpose of mlpack 3.2.0, I think we can close this.
		</comment>
	</comments>
</bug>