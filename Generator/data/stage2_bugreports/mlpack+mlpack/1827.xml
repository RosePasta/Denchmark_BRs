<bug id='1827' author='saksham189' open_date='2019-04-01T19:02:43Z' closed_time='2019-04-02T14:06:08Z'>
	<summary>Use batchSize parameter for GAN</summary>
	<description>
Currently the parameter batchSize is commented out for methods EvaluateWithGradient and Evaluate in GAN. I think this is resulting in a bug where we pass both the real and fake images for training the discriminator at once.
For example consider batchSize = 4 and numFunctions = 10.
Then we would have calls to EvaluateWithGradient with values of i being 0, 4, and 8.
When we use value of i = 8 with batchSize of 4 we end up training the discriminator on fake data as well.
&lt;denchmark-code&gt;double res = discriminator.EvaluateWithGradient(discriminator.parameter,
      i, gradientDiscriminator, batchSize);
&lt;/denchmark-code&gt;

Instead I think we should use the batchSize parameter passed to EvaluateWithGradient in GAN which would be 2 when i is equal to 8.
&lt;denchmark-link:https://github.com/ShikharJ&gt;@ShikharJ&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/zoq&gt;@zoq&lt;/denchmark-link&gt;
  let me know what you think.
	</description>
	<comments>
		<comment id='1' author='saksham189' date='2019-04-01T20:15:01Z'>
		I'm not sure that this is a bug-report. If you really want to setup a batch size, it is always going to be a number which is a divisor of the total number of input data points you wish to consider. So I'd rather that this remain untouched. Also if you make use of the batchSize parameter which is passed, you'll face a problem here, if you try to reason:
&lt;denchmark-code&gt;generator.Gradient(generator.parameter, 0, gradientGenerator, batchSize);
&lt;/denchmark-code&gt;

Now the generator will only pick up the gradients from the reduced number of data points, which is not what we want. Let me know if I should clarify anything.
		</comment>
		<comment id='2' author='saksham189' date='2019-04-01T20:34:13Z'>
		
If you really want to setup a batch size, it is always going to be a number which is a divisor of the total number of input data points you wish to consider.

So this must always be true? If this is true, then obviously there will be no problem.
I was considering using the max batch size for the generator and reduced batch size for the discriminator.
		</comment>
		<comment id='3' author='saksham189' date='2019-04-02T14:06:08Z'>
		
So this must always be true? If this is true, then obviously there will be no problem.

Yes, it hardly makes sense to choose a batchSize such that for certain epochs it leads to uneven gradient update.
		</comment>
	</comments>
</bug>