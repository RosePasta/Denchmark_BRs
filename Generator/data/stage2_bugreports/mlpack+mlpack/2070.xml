<bug id='2070' author='rcurtin' open_date='2019-11-01T03:06:26Z' closed_time='2019-12-23T14:34:53Z'>
	<summary>A too-large rho value causes a failure, but maybe it shouldn't</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue description&lt;/denchmark-h&gt;

While working with &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/2048&gt;#2048&lt;/denchmark-link&gt;
, I noticed that if  is longer than the sequence length, an error is given:
&lt;denchmark-code&gt;
error: Cube::slice(): index out of bounds
terminate called after throwing an instance of 'std::logic_error'
  what():  Cube::slice(): index out of bounds
Aborted
&lt;/denchmark-code&gt;

However, if rho is longer than the sequence length, I think we should instead handle this gracefully, and only perform a number of BPTT steps equal to the sequence length.  (I am not 100% certain on that, but at a glance, that seems like it should be the right thing to do.)
&lt;denchmark-h:h4&gt;Your environment&lt;/denchmark-h&gt;


version of mlpack: git master
operating system: Debian üêß
compiler: g++ 8.3.0
version of dependencies (Boost/Armadillo): Boost 1.67.0, Armadillo 9.600.5
any other environment information you think is relevant: This should be reproducible anywhere.

&lt;denchmark-h:h4&gt;Steps to reproduce&lt;/denchmark-h&gt;

You can compile the adapted example from &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/2048&gt;#2048&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;#include &lt;mlpack/core.hpp&gt;
#include &lt;mlpack/methods/ann/rnn.hpp&gt;
#include &lt;mlpack/methods/ann/ffn.hpp&gt;
#include &lt;mlpack/methods/ann/layer/lstm.hpp&gt;
#include &lt;mlpack/methods/ann/layer/dropout.hpp&gt;

#include &lt;vector&gt;
#include &lt;string&gt;

int main(int argc, char *argv[])
{
  using namespace mlpack;
  using namespace mlpack::data;
  using namespace mlpack::tree;
  using namespace mlpack::cv;
  using namespace mlpack::ann;
  using namespace arma;

  // SUCCEEDS if maxLineLength = 17.
  // FAILS if maxLineLength = 18.
  const int maxLineLength = 18;
  const int hiddenSize = 128;
  const int numLetters = 256;

  using MatType = cube;
  std::vector&lt;std::string&gt; trainingData;
  trainingData.push_back(std::string("THIS IS THE INPUT"));

  //This is the orignal network that I used (FFN) but then I also tried a RNN
  RNN&lt;&gt; rnn(maxLineLength);
  rnn.Add&lt;IdentityLayer&lt;&gt;&gt;();
  rnn.Add&lt;LSTM&lt;&gt;&gt;(numLetters, hiddenSize, maxLineLength);
  rnn.Add&lt;Dropout&lt;&gt;&gt;(0.1);
  rnn.Add&lt;Linear&lt;&gt;&gt;(hiddenSize, numLetters);

  const auto makeInput = [](const char *line) -&gt; MatType {
    const auto strLen = strlen(line);
    // rows: number of dimensions
    // cols: number of sequences/points
    // slices: number of steps in sequences
    MatType result(numLetters, 1, strLen, fill::zeros);
    for(int i = 0; i &lt; strLen; ++i)
    {
      const auto letter = line[i];
      result.at(static_cast&lt;uword&gt;(letter), 0, i) = 1.0;
    }
    return result;
  };

  const auto makeTarget = [] (const char *line) -&gt; MatType {
    const auto strLen = strlen(line);
    // responses for NegativeLogLikelihood should be
    // non-one-hot-encoded class IDs (from 1 to num_classes)
    cube result(1, 1, strLen, fill::zeros);
    // the response is the *next* letter in the sequence
    for(int i = 0; i &lt; strLen - 1; ++i)
    {
      const auto letter = line[i + 1];
      result.at(0, 0, i) = static_cast&lt;uword&gt;(letter) + 1.0;
    }
    // the final response is empty, so we set it to class 0
    result.at(0, 0, strLen - 1) = 1.0;
    return result;
  };

  std::vector&lt;cube&gt; inputs(trainingData.size());
  std::vector&lt;cube&gt; targets(trainingData.size());
  for(int i = 0; i &lt; trainingData.size(); ++i)
  {
    inputs[i] = makeInput(trainingData[i].c_str());
    targets[i] = makeTarget(trainingData[i].c_str());
  }

  ens::SGD&lt;&gt; sgd(0.01, 1, 100 /* only 100 maximum iterations, just to see it work */);
  rnn.Train(inputs[0], targets[0], sgd);
  return 0;
}
&lt;/denchmark-code&gt;

I compiled on my system in my mlpack build directory with
&lt;denchmark-code&gt;$ g++ -g -O0 -o test ../test.cpp -Iinclude/ -Llib/ -lmlpack -larmadillo -I deps/stb/ -I deps/ensmallen-2.10.3/include/ -fopenmp
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Expected behavior&lt;/denchmark-h&gt;

When maxLineLength is set to anything greater than 17, training should proceed without failure.
&lt;denchmark-h:h4&gt;Actual behavior&lt;/denchmark-h&gt;

With maxLineLength at 18, we get
&lt;denchmark-code&gt;$ ./test 

error: Cube::slice(): index out of bounds
terminate called after throwing an instance of 'std::logic_error'
  what():  Cube::slice(): index out of bounds
Aborted
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Notes for helping out&lt;/denchmark-h&gt;

If you're interested in working on this issue, here are a few good suggestions for how to get started.

Have some understanding of what backpropagation through time is (BPTT); if you aren't already familiar, it would be helpful to know the algorithm, so that the code can be more easily understood.
Read and understand the RNN&lt;&gt; class in src/mlpack/methods/ann/; specifically, the use of the rho variable.
Try tracing the error with gdb to understand exactly what is going on.
Adapt the code in the RNN class to specifically handle the case when rho is greater than the sequence length.

In the end, it's likely to be a lot of time reading and understanding the code, but the patch itself will probably be fairly simple.
There's no need to claim the issue---just work on it, and once you have a working solution, open a PR and someone will review it when they have a chance. :)
	</description>
	<comments>
		<comment id='1' author='rcurtin' date='2019-11-10T14:20:32Z'>
		&lt;denchmark-link:https://github.com/rcurtin&gt;@rcurtin&lt;/denchmark-link&gt;
 I want to work on this issue
		</comment>
		<comment id='2' author='rcurtin' date='2019-12-10T15:20:12Z'>
		This issue has been automatically marked as stale because it has not had any recent activity.  It will be closed in 7 days if no further activity occurs.  Thank you for your contributions! üëç
		</comment>
		<comment id='3' author='rcurtin' date='2019-12-23T14:34:53Z'>
		Solved via &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2102&gt;#2102&lt;/denchmark-link&gt;
.  Thanks &lt;denchmark-link:https://github.com/himanshupathak21061998&gt;@himanshupathak21061998&lt;/denchmark-link&gt;
!
		</comment>
	</comments>
</bug>