<bug id='349' author='rcurtin' open_date='2014-12-29T15:43:49Z' closed_time='2019-02-25T20:26:20Z'>
	<summary>Ball trees are not guaranteed to have decreasing child furthest descendant distances</summary>
	<description>
Reported by rcurtin on 2 Feb 44653621 04:25 UTC
The BallBound class uses an iterative algorithm to determine a bounding ball of a set of points.  But this is not guaranteed to be the minimum bounding ball.  This means that a parent node may end up with a bounding ball that has radius smaller than the bounding balls of its children!  This may break the assumption that the FurthestDescendantDistance() of a child is smaller than the FurthestDescendantDistance() of the parent.
In r17121 I have committed a workaround fix, which makes NeighborSearch work correctly with ball trees, but that workaround (the use of std::min()) should be removed when this bug is resolved.
For this bug to be resolved, we must be able to guarantee that any BinarySpaceTree&lt;BallBound&lt;...&gt;, ...&gt; tree is such that the parent node's furthest descendant distance is always larger than any child's furthest descendant distance.  This probably requires a rewrite and rethink of the algorithm implemented in BallBound&lt;&gt;::operator|=(MatType&amp;).
Migrated-From: &lt;denchmark-link:http://trac.research.cc.gatech.edu/fastlab/ticket/367&gt;http://trac.research.cc.gatech.edu/fastlab/ticket/367&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='rcurtin' date='2016-04-18T10:10:49Z'>
		I would like to work on this if no one else is working.
Let me go to through the code and think of an idea for improving BallBound&lt;&gt;::operator|=(MatType&amp;).
I'll update you soon.
		</comment>
		<comment id='2' author='rcurtin' date='2016-04-18T14:25:32Z'>
		Sure, I don't think anyone else is working on this.  I would be happy to merge in a fix if you are able to fix it.  Also, the commit r17121 in the old svn repository is now &lt;denchmark-link:https://github.com/mlpack/mlpack/commit/98dcfd600d79302bcdddb18a39fbe6d1a95a6517&gt;98dcfd6&lt;/denchmark-link&gt;
, I think (not certain, it may also be &lt;denchmark-link:https://github.com/mlpack/mlpack/commit/cae07019cd98a1221e374de33940fbbcbea4372f&gt;cae0701&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='3' author='rcurtin' date='2017-04-23T13:47:27Z'>
		I spent some time looking at this issue and I have some comment/questions.

Neither 98dcfd6 nor cae0701 seem to contain the fix with std::min you mentioned in the first post.


98dcfd6 introduces MinimumBoundDistance (no new functionality) and adds some code in binary_space_tree_impl.hpp that is no longer present.
cae0701 changes nothing in our case, because FurthestDescendantDistance equals MinimumBoundDistance for ball bounds.



I wonder if breaking the assumption that the FurthestDescendantDistance() of a child is smaller than the FurthestDescendantDistance() of a parent really changes anything. In the end the difference only comes from error in our approximation. NeighborSearch can safely discard whole parent tree even if a child tree would give it a false suggestion that some points may be closer.
Or maybe it's just me not seeing the actual problem (because of point 1).


If we want to change algorithm to one that always calculates minimum bounding ball I suggest Emo Welzl‚Äôs randomized algorithm. It is mentioned on Wikipedia and you can also see the paper.
According to publication it is faster in practice than linear programming solution (and also a lot easier to implement). However, it has some downsides:



For high dimensions, it will be significantly slower than the approximation we use right now.
It is an offline algorithm and at the moment BallBound::operator| allows adding points one by one.
We could change it to either take always all the points and calculate new ball bound, or to store previous points and recalculate ball bound every time when new point is added. Second solution would require making sure that it doesn‚Äôt happen too often.

		</comment>
		<comment id='4' author='rcurtin' date='2017-04-24T15:59:09Z'>
		Hi there &lt;denchmark-link:https://github.com/Farqd&gt;@Farqd&lt;/denchmark-link&gt;
!  Thank you for looking into this.  Some responses:


I was wrong, the commit is actually 813441a; it's a change to NeighborSearchRules specifically, not the tree class itself.  The key part of the change is the std::max(0.0, ...), so my comment about std::min is actually backwards.


It actually does change things because of the strange parent-child pruning rules used by many of the dual-tree algorithms.  If the child has larger furthest descendant distance, then queryNode.FurthestDescendantDistance() - queryNode.Child(i).FurthestDescendantDistance() becomes negative.  This causes the pruning to be invalid.  If you are interested in the details, see http://proceedings.mlr.press/v28/curtin13.pdf ; the equation that becomes invalid is B_2(N_q) on page 4 (specifically, the second line becomes invalid).


If you'd like to implement it we can try it.  When you say it will be slow in high dimensions, what do you have in mind for 'high dimension'?  If you are thinking 10k+ dimensions, that's not a problem since trees will typically perform very poorly in that regime anyway so we don't need to worry much about that.  But if you mean 10+ dimensions, then that would be a problem.  For what it's worth, typically tree construction is a small amount of time compared spent to the time performing the task with the tree (like nearest neighbor search) so it is not a huge deal if we slow down ball tree construction a little bit to get better bounds.


I wonder if another thing we could do, is to simply recalculate the radius given a fixed center right before the return *this in BallBound::operator|=().  But I think also we would need some guarantee that the center we would choose could have radius less than or equal to the radius of the parent node.
		</comment>
		<comment id='5' author='rcurtin' date='2017-08-23T03:42:43Z'>
		Does this mean that the current implementation of Ball tree is invalid and if I use it when running knn I may get inaccurate results?
		</comment>
		<comment id='6' author='rcurtin' date='2017-08-23T12:56:09Z'>
		No, KNN works properly with , I just had to commit a workaround in &lt;denchmark-link:https://github.com/mlpack/mlpack/commit/813441af376d1b84cc8e5dffaa50b862d76309b9&gt;813441a&lt;/denchmark-link&gt;
.   is tested in  in the , and it passes the tests so there is no problem there.  (On the other hand,  does not work with rank-approximate nearest neighbor search---see &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/338&gt;#338&lt;/denchmark-link&gt;
---but if you are just using  and not  there is no problem.)
		</comment>
		<comment id='7' author='rcurtin' date='2017-08-23T13:35:56Z'>
		Got it - thanks a lot =)
		</comment>
		<comment id='8' author='rcurtin' date='2019-02-18T19:58:22Z'>
		This issue has been automatically marked as stale because it has not had any recent activity.  It will be closed in 7 days if no further activity occurs.  Thank you for your contributions! üëç
		</comment>
	</comments>
</bug>