<bug id='2042' author='aabghari' open_date='2019-10-03T18:08:11Z' closed_time='2019-12-28T05:26:45Z'>
	<summary>The choice of API is problematic</summary>
	<description>
Hi,
The choice of API to access the internal members of a class is problematic in mlpack. For example, in case of HMM, it's more efficient (both CPU and memory wise) if we keep the initial and transition matrix in log value. But this is not possible without breaking the existing APIs. If the API to access the transition matrix were like this:
&lt;denchmark-code&gt;const arma::mat&amp; GetTransition() { return transition;}
void SetTransition(const arma::mat &amp;netTrans) {transition = newTrans;}

&lt;/denchmark-code&gt;

I would be easily  able to change the set API to something like this and change the code to use the
logTransition instead of transition matrix without breaking the APIs:
&lt;denchmark-code&gt;const arma::mat&amp; GetTransition() { return exp(logTransition);}

void SetTransition(const arma::mat &amp;netTrans) {
    logTransition = log(newTrans);
}
&lt;/denchmark-code&gt;

but with the existing API, I cannot convert the transition to the log version because the modifier returns a reference to transition mat.
arma::mat&amp; Transition() { return transition; }
So to make the change I need to break the API, remove the existing one and introduce a new one such as
arma::mat&amp; LogTransition() { return logTransition; }
to force the end user to change their code:
hmm.Transition() = trans; --&gt; hmm.LogTransitioin() = log(trans)
or modify the existing API to:
arma::mat&amp; Transition() { return logTransition; } 
and hope that the end user will change their code to get the correct result:
hmm.Transition() = trans; --&gt; hmm.Transitioin() = log(trans)
I wonder what you recommend?
	</description>
	<comments>
		<comment id='1' author='aabghari' date='2019-10-03T19:55:37Z'>
		Can you elaborate on your answer. I cannot see the solution.
		</comment>
		<comment id='2' author='aabghari' date='2019-10-03T20:01:52Z'>
		Sorry, for the confusion I was talking about &lt;denchmark-link:https://github.com/mlpack/mlpack/issues/2041&gt;#2041&lt;/denchmark-link&gt;
. I will take a look at this issue later.
		</comment>
		<comment id='3' author='aabghari' date='2019-10-04T03:08:51Z'>
		&lt;denchmark-link:https://github.com/aabghari&gt;@aabghari&lt;/denchmark-link&gt;
 I see what you mean and this is a little bit tricky to figure out how to do right.  Here's one idea:
We can add an extra bool template parameter to HMM and call it UseLogProbabilities; by default this is false, but if it's set to true, then HMM will internally store log probabilities in transition and initial.
In this way, it won't break reverse-compatibility for users who don't explicitly set UseLogProbabilities to true, and then when mlpack 4.0.0 comes around we can break reverse compatibility by changing the default for UseLogProbabilities to true.
This is only the start of an idea and there would be some additional thinking about how to do it right and nicely, but it would at least allow us to work natively in logspace for transition probabilities.  The internal implementation would also need to be adapted so that they depend on the value of UseLogProbabilities.
Let me know what you think or if you'd like me to spend a bit of time elaborating and clarifying the idea. üëç
		</comment>
		<comment id='4' author='aabghari' date='2019-10-07T14:06:50Z'>
		I am not sure if adding a bool will fix the problem because the implementation for log space is different. The issue is not whether or not to store the transition  and  initial in log space per se. If UseLogProbabilities is true then the transition and initial are  in log space therefore the implementation is different for example all the multiplies becomes addition compare to the none log one. If I understand properly, we need two implementations and switch between them based on the UseLogProbabilities. I am not sure this is a right approach unless I am missing something. My issue is that this choice of modifier arma::mat&amp; Transition() { return transition; } does not let to hide the implementation from the end user.
		</comment>
		<comment id='5' author='aabghari' date='2019-10-16T19:11:48Z'>
		I agree, you are right that arma::mat&amp; Transition() has no way to hide the underlying implementation detail.  But no matter what we do, we have to break reverse compatibility in mlpack 4.0.0 if we want to change this to work in logspace.
Suppose that we instead just created an additional member logTransition, and then used that in the computations (and just made sure that transition was equal to log(transition) when we finished training).  This seems like it would allow us to avoid breaking reverse compatibility, but if a user modifies transition by calling Transition() but does not correspondingly modify LogTransition(), then their HMM will not predict/compute with the modified transition matrix (since we use logTransition internally).
In essence, what I am saying is that there is no way to hide this from the end user, specifically because we have this arma::mat&amp; Transition() { return transition; } function: when that is called, we have no way to know what was updated and if it is in sync with another version of the log transition matrix or something.
You are right though that the implementation would have to be different.  My suggestion would be this:

Change the implementation so that during training, transition is always treated as though it is in logspace.
If UseLogProbabilities is false, then at the end of training, take transition = exp(transition) (and now the transition probabilities are not in logspace).
Create two implementations of Estimate(), Generate(), Predict() and LogLikehood() that change behavior based on whether UseLogProbabilities is true or false.

This is extra code for now, but when mlpack 4.0.0 comes around we can remove that extra code and have only the logspace implementation.
I'm open to other ideas, if you have them, but I don't currently see another way than what I just described.  Maybe you have a different idea that is cleaner? :)
		</comment>
		<comment id='6' author='aabghari' date='2019-11-15T19:20:03Z'>
		This issue has been automatically marked as stale because it has not had any recent activity.  It will be closed in 7 days if no further activity occurs.  Thank you for your contributions! üëç
		</comment>
		<comment id='7' author='aabghari' date='2019-11-25T16:31:28Z'>
		No need to close this until &lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2081&gt;#2081&lt;/denchmark-link&gt;
 is done.
		</comment>
		<comment id='8' author='aabghari' date='2019-12-25T17:20:15Z'>
		This issue has been automatically marked as stale because it has not had any recent activity.  It will be closed in 7 days if no further activity occurs.  Thank you for your contributions! üëç
		</comment>
		<comment id='9' author='aabghari' date='2019-12-28T05:26:45Z'>
		&lt;denchmark-link:https://github.com/mlpack/mlpack/pull/2081&gt;#2081&lt;/denchmark-link&gt;
 is done, so I think we can go ahead and close this.  Thanks again &lt;denchmark-link:https://github.com/aabghari&gt;@aabghari&lt;/denchmark-link&gt;
 for the nice patches. :)
		</comment>
	</comments>
</bug>