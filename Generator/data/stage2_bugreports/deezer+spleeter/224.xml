<bug id='224' author='aidv' open_date='2020-01-06T08:16:24Z' closed_time='2020-01-30T12:24:18Z'>
	<summary>[Bug] Training "assertion failed:" on large dataset</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

I've had this problem for a while now and it does not seem to go away.
I partially solved it for testing purposes by removing 94% of my dataset by going from 13000 files down to 800 files, and as you can imagine, that's not really what anyone is looking for.
&lt;denchmark-h:h2&gt;Step to reproduce&lt;/denchmark-h&gt;

Really not much to it. Just having a very large dataset and let the error occur.
&lt;denchmark-h:h2&gt;Output&lt;/denchmark-h&gt;

INFO:spleeter:Audio data loaded successfully

INFO:spleeter:Audio data loaded successfully

Traceback (most recent call last):
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1356, in _do_call
    return fn(*args)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: assertion failed: [Need value.shape &gt;= size, got ] [858 3072 1] [512 3072 2]
	 [[{{node random_crop/Assert/Assert}}]]
	 [[IteratorGetNext]]
	 [[gradients/sub_grad/Shape_1/_2089]]
  (1) Invalid argument: assertion failed: [Need value.shape &gt;= size, got ] [858 3072 1] [512 3072 2]
	 [[{{node random_crop/Assert/Assert}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\user\anaconda3\lib\runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "c:\users\user\anaconda3\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "c:\users\user\anaconda3\lib\site-packages\spleeter\__main__.py", line 58, in &lt;module&gt;
    entrypoint()
  File "c:\users\user\anaconda3\lib\site-packages\spleeter\__main__.py", line 54, in entrypoint
    main(sys.argv)
  File "c:\users\user\anaconda3\lib\site-packages\spleeter\__main__.py", line 46, in main
    entrypoint(arguments, params)
  File "c:\users\user\anaconda3\lib\site-packages\spleeter\commands\train.py", line 98, in entrypoint
    evaluation_spec)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\training.py", line 473, in train_and_evaluate
    return executor.run()
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\training.py", line 613, in run
    return self.run_local()
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\training.py", line 714, in run_local
    saving_listeners=saving_listeners)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py", line 367, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py", line 1158, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py", line 1192, in _train_model_default
    saving_listeners)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py", line 1484, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py", line 754, in run
    run_metadata=run_metadata)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py", line 1252, in run
    run_metadata=run_metadata)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py", line 1353, in run
    raise six.reraise(*original_exc_info)
  File "c:\users\user\anaconda3\lib\site-packages\six.py", line 693, in reraise
    raise value
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py", line 1338, in run
    return self._sess.run(*args, **kwargs)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py", line 1411, in run
    run_metadata=run_metadata)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\training\monitored_session.py", line 1169, in run
    return self._sess.run(*args, **kwargs)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 950, in run
    run_metadata_ptr)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1350, in _do_run
    run_metadata)
  File "c:\users\user\anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: assertion failed: [Need value.shape &gt;= size, got ] [858 3072 1] [512 3072 2]
	 [[{{node random_crop/Assert/Assert}}]]
	 [[IteratorGetNext]]
	 [[gradients/sub_grad/Shape_1/_2089]]
  (1) Invalid argument: assertion failed: [Need value.shape &gt;= size, got ] [858 3072 1] [512 3072 2]
	 [[{{node random_crop/Assert/Assert}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored.
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;










OS
Windows


Installation type
Conda


RAM available
32GB


Hardware spec
i7-9900K / RTX2080



&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

Mr &lt;denchmark-link:https://github.com/mmoussallam&gt;@mmoussallam&lt;/denchmark-link&gt;
 (i think) asked me in a previous opened issue if the file is mono. No.
None of the files are mono. All the same format and same duration.
Currently I run a script that removes the specific failed five from the csv and restarts the training process, and training seem to fail at around file number 860-something.
But when this takes several minutes it adds up over time.
	</description>
	<comments>
		<comment id='1' author='aidv' date='2020-01-06T20:24:12Z'>
		After running my script for the whole day there's barely any files left to train on and Spleeter seems to fail at around file 860 regardless of what the dataset looks like.
I'm so confused tbh I don't know what else to do.
		</comment>
	</comments>
</bug>