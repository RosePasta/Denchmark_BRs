<bug id='939' author='carolmanderson' open_date='2020-01-08T04:46:32Z' closed_time='2020-01-08T06:13:45Z'>
	<summary>Caching loading of Keras model generates errors on prediction</summary>
	<description>
&lt;denchmark-h:h1&gt;Summary&lt;/denchmark-h&gt;

My goal is to load a Keras model once and then run predictions multiple times without reloading the model.
When I add the @st.cache(allow_mutation=True) decorator to the loading function, the first prediction step goes fine, but subsequent rounds generate the error RuntimeError: The Session graph is empty. Add operations to the graph before calling run().
Â 
Everything runs fine if I remove the @st.cache decorator, but then the model reloads itself before every prediction, which is inefficient.
&lt;denchmark-h:h1&gt;Steps to reproduce&lt;/denchmark-h&gt;

I wrote a super simple Keras model to reproduce this.
&lt;denchmark-h:h3&gt;Code to train and save the model:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import numpy as np
from keras.models import Sequential
from keras.layers import Dense

def generate_features(length):
    """Function to create fake feature data for a simple model.
    Generates (length) rows x 2 columns;
    each entry is  a random integer between 1 and 9."""
    return np.random.randint(1, 10, size=(length, 2))

def generate_targets(features):
    """Function to create fake target data for a simple model.
    If both input features are odd or both are even, output is 0.
    Otherwise output is 1.
    """
    target = []
    for row in features:
        f1 = row[0]
        f2 = row[1]
        if f1 % 2 == 0 and f2 % 2 == 0:
            target.append(1)
        elif f1 % 2 !=0 and f2 % 2 != 0:
            target.append(1)
        else:
            target.append(0)
    return target

X_train = generate_features(1000000)
y_train = generate_targets(X_train)

model = Sequential()
model.add(Dense(36, input_dim=2, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

model.fit(X_train, y_train, epochs=10, batch_size=64)

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
model.save_weights("model.h5")
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Streamlit app using model trained above&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import numpy as np
from keras.models import model_from_json
import streamlit as st

def generate_features(length):
    """Function to create fake feature data for a simple model.
    Generates (length) rows x 2 columns;
    each entry is  a random integer between 1 and 9."""
    return np.random.randint(1, 10, size=(length, 2))

@st.cache(allow_output_mutation=True)
def load_model():
    model_weights = "model.h5"
    model_json = "model.json"
    with open(model_json) as json_file:
        loaded_model = model_from_json(json_file.read())
    loaded_model.load_weights(model_weights)
    loaded_model.summary()  # included to make it visible when model is reloaded
    return loaded_model


if __name__ == "__main__":
    # load the saved model
    model = load_model()

    # generate some test input data
    num_examples = st.number_input('Number of examples to generate', 10)
    X_test = generate_features(num_examples)

    # predict on test input data
    predictions = model.predict(X_test)

    # display input and results
    st.write(X_test)
    st.write(predictions)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected behavior:&lt;/denchmark-h&gt;

Predictions should occur without reloading the model weights each time.
&lt;denchmark-h:h2&gt;Actual behavior:&lt;/denchmark-h&gt;

If the @st.cache decorator isn't used, things are fine but the model reloads every time a prediction is requested.
If the @st.cache decorator is used, this error comes up on the second prediction:
&lt;denchmark-link:https://user-images.githubusercontent.com/25518180/71951041-ce0c7600-3196-11ea-8352-9aa805394011.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Is this a regression?&lt;/denchmark-h&gt;

No
&lt;denchmark-h:h1&gt;Debug info&lt;/denchmark-h&gt;


Streamlit version: 0.52.2
Python version: 3.6.6
Using Conda
OS version: Mac OS 10.13.6
Browser version: Safari 13.0.2

	</description>
	<comments>
		<comment id='1' author='carolmanderson' date='2020-01-08T06:13:45Z'>
		Found solution:
&lt;denchmark-code&gt;import numpy as np
from keras.models import model_from_json
from keras import backend as K
import streamlit as st

def generate_features(length):
    """Function to create fake feature data for a simple model.
    Generates (length) rows x 2 columns;
    each entry is  a random integer between 1 and 9."""
    return np.random.randint(1, 10, size=(length, 2))

@st.cache(allow_output_mutation=True)
def load_model():
    model_weights = "/Users/caanderson/Documents/Misc/keras_toy_example/model.h5"
    model_json = "/Users/caanderson/Documents/Misc/keras_toy_example/model.json"
    with open(model_json) as json_file:
        loaded_model = model_from_json(json_file.read())
    loaded_model.load_weights(model_weights)
    loaded_model.summary()  # included to make it visible when model is reloaded
    session = K.get_session()
    return loaded_model, session


if __name__ == "__main__":
    # load the saved model
    model, session = load_model()

    # generate some test input data
    num_examples = st.number_input('Number of examples to generate', 10)
    X_test = generate_features(num_examples)

    # predict on test input data
    K.set_session(session)
    predictions = model.predict(X_test)

    # display input and results
    st.write(X_test)
    st.write(predictions)
&lt;/denchmark-code&gt;

Here, load_model returns the session along with the model itself. That session is then explicitly set via K.set_session at prediction time.
		</comment>
	</comments>
</bug>