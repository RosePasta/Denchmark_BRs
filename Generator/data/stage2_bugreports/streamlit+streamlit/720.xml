<bug id='720' author='monchier' open_date='2019-11-20T19:05:24Z' closed_time='2020-04-01T16:09:10Z'>
	<summary>Performance of the image widget</summary>
	<description>
&lt;denchmark-h:h1&gt;Summary&lt;/denchmark-h&gt;

When swapping out images frame by frame with st.image the performance penalty seems to be significant.
Relevant thread on discourse:
&lt;denchmark-link:https://discuss.streamlit.io/t/is-is-possible-to-stream-video-and-overlay-bounding-boxes/412/3&gt;https://discuss.streamlit.io/t/is-is-possible-to-stream-video-and-overlay-bounding-boxes/412/3&lt;/denchmark-link&gt;


would be to calculate bounding boxes for each frame of the video and pass the frames one by one to st.image instead.

I have an app where I’m doing this ^. However, what I’m noticing is that there seems to be a lot of overhead in swapping out the images frame by frame. The rendering of the frames in the app can’t keep up with my object detector and the CPU usage goes through the roof (on a pretty beefy dev server). Is there any way to improve the efficiency of the image widget? Is there some other way to do this more efficiently?
	</description>
	<comments>
		<comment id='1' author='monchier' date='2020-02-14T20:59:14Z'>
		Will be drastically improved once &lt;denchmark-link:https://github.com/streamlit/streamlit/pull/1029&gt;#1029&lt;/denchmark-link&gt;
 goes into the release.
		</comment>
		<comment id='2' author='monchier' date='2020-04-01T16:09:10Z'>
		Drastically improved
		</comment>
	</comments>
</bug>