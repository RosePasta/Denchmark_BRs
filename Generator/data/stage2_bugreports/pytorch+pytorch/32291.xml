<bug id='32291' author='jeongukjae' open_date='2020-01-16T15:16:39Z' closed_time='2020-04-14T07:16:16Z'>
	<summary>PyTorch-1.4.0 doesn't encode numpy dependency</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Traceback (most recent call last):
  File "create_dummy_weight.py", line 1, in &lt;module&gt;
    import torch
  File "{some-path}/env/lib/python3.6/site-packages/torch/__init__.py", line 81, in &lt;module&gt;
    from torch._C import *
ImportError: numpy.core.multiarray failed to import
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

Install torch-1.4.0
Run below code snippet

import torch
from torch import nn, optim
from torch.nn import functional as F

# Define model
class TheModelClass(nn.Module):
    def __init__(self):
        super(TheModelClass, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Initialize model
model = TheModelClass()

# Initialize optimizer
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Print model's state_dict
print("Model's state_dict:")
for param_tensor in model.state_dict():
    print(param_tensor, "\t", model.state_dict()[param_tensor].size())

# Print optimizer's state_dict
print("Optimizer's state_dict:")
for var_name in optimizer.state_dict():
    print(var_name, "\t", optimizer.state_dict()[var_name])
&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

That code should print logs like below.
&lt;denchmark-code&gt;Model's state_dict:
conv1.weight     torch.Size([6, 3, 5, 5])
conv1.bias       torch.Size([6])
conv2.weight     torch.Size([16, 6, 5, 5])
conv2.bias       torch.Size([16])
fc1.weight       torch.Size([120, 400])
fc1.bias         torch.Size([120])
fc2.weight       torch.Size([84, 120])
fc2.bias         torch.Size([84])
fc3.weight       torch.Size([10, 84])
fc3.bias         torch.Size([10])
Optimizer's state_dict:
state    {}
param_groups     [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [4309507096, 4407714728, 4407714800, 4407714872, 4407714944, 4407715016, 4407715088, 4407715160, 4407715304, 4407715376]}]
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


PyTorch Version (e.g., 1.0): 1.4.0
OS (e.g., Linux): Mac OSX 10.15.2
How you installed PyTorch (conda, pip, source): pip
Build command you used (if compiling from source):
Python version: 3.6
CUDA/cuDNN version: N/A
GPU models and configuration: N/A
Any other relevant information: Above code is from "pytorch's beginner tutorial (saving loading models)"

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

I met this error and I installed numpy (1.18.1), then above code ran without any errors.
cc &lt;denchmark-link:https://github.com/ezyang&gt;@ezyang&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gchanan&gt;@gchanan&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/zou3519&gt;@zou3519&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='jeongukjae' date='2020-01-16T19:08:54Z'>
		&lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
 given the new title you added, are we going make changes in the pip wheel to automatically pull numpy when install v1.4?
		</comment>
		<comment id='2' author='jeongukjae' date='2020-04-09T16:02:57Z'>
		Fixed by &lt;denchmark-link:https://github.com/pytorch/pytorch/pull/34510&gt;#34510&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='jeongukjae' date='2020-04-14T07:16:15Z'>
		&lt;denchmark-link:https://github.com/gchanan&gt;@gchanan&lt;/denchmark-link&gt;
 Thank you! :)
		</comment>
	</comments>
</bug>