<bug id='922' author='Maratyszcza' open_date='2017-03-05T00:09:02Z' closed_time='2017-04-19T15:00:48Z'>
	<summary>pytorch does not build on ppc64le</summary>
	<description>
It looks like libTH tries to dispatch to VSX-specific versions of the functions, which are not defined.
&lt;denchmark-code&gt;mdukhan3@power8:~/tools/pytorch/pytorch$ python setup.py build
running build
running build_deps
/home/mdukhan3/tools/pytorch/pytorch/torch/_thnn/utils.py:1: RuntimeWarning: Parent module 'torch._thnn' not found while handling absolute import
  import os
/home/mdukhan3/tools/pytorch/pytorch/torch/_thnn/utils.py:2: RuntimeWarning: Parent module 'torch._thnn' not found while handling absolute import
  import itertools
/home/mdukhan3/tools/pytorch/pytorch/torch/_thnn/utils.py:3: RuntimeWarning: Parent module 'torch._thnn' not found while handling absolute import
  import importlib
-- The C compiler identification is GNU 4.8.4
-- The CXX compiler identification is GNU 4.8.4
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/c++
-- Check for working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Try OpenMP C flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
CMake Warning (dev) at /usr/local/share/cmake-3.7/Modules/FindOpenMP.cmake:179 (if):
  if given arguments:

    "TRUE"

  An argument named "TRUE" appears in a conditional statement.  Policy
  CMP0012 is not set: if() recognizes numbers and boolean constants.  Run
  "cmake --help-policy CMP0012" for policy details.  Use the cmake_policy
  command to set the policy and suppress this warning.
Call Stack (most recent call first):
  /usr/local/share/cmake-3.7/Modules/FindOpenMP.cmake:224 (_OPENMP_GET_SPEC_DATE)
  CMakeLists.txt:65 (FIND_PACKAGE)
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Try OpenMP CXX flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
CMake Warning (dev) at /usr/local/share/cmake-3.7/Modules/FindOpenMP.cmake:179 (if):
  if given arguments:

    "TRUE"

  An argument named "TRUE" appears in a conditional statement.  Policy
  CMP0012 is not set: if() recognizes numbers and boolean constants.  Run
  "cmake --help-policy CMP0012" for policy details.  Use the cmake_policy
  command to set the policy and suppress this warning.
Call Stack (most recent call first):
  /usr/local/share/cmake-3.7/Modules/FindOpenMP.cmake:266 (_OPENMP_GET_SPEC_DATE)
  CMakeLists.txt:65 (FIND_PACKAGE)
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Found OpenMP: -fopenmp
-- Compiling with OpenMP support
-- Could not find hardware support for NEON on this machine.
-- No OMAP3 processor on this machine.
-- No OMAP4 processor on this machine.
-- Looking for cpuid.h
-- Looking for cpuid.h - not found
-- Performing Test NO_GCC_EBX_FPIC_BUG
-- Performing Test NO_GCC_EBX_FPIC_BUG - Failed
-- Performing Test C_HAS_SSE1_1
-- Performing Test C_HAS_SSE1_1 - Failed
-- Performing Test C_HAS_SSE1_2
-- Performing Test C_HAS_SSE1_2 - Failed
-- Performing Test C_HAS_SSE1_3
-- Performing Test C_HAS_SSE1_3 - Failed
-- Performing Test C_HAS_SSE2_1
-- Performing Test C_HAS_SSE2_1 - Failed
-- Performing Test C_HAS_SSE2_2
-- Performing Test C_HAS_SSE2_2 - Failed
-- Performing Test C_HAS_SSE2_3
-- Performing Test C_HAS_SSE2_3 - Failed
-- Performing Test C_HAS_SSE3_1
-- Performing Test C_HAS_SSE3_1 - Failed
-- Performing Test C_HAS_SSE3_2
-- Performing Test C_HAS_SSE3_2 - Failed
-- Performing Test C_HAS_SSE3_3
-- Performing Test C_HAS_SSE3_3 - Failed
-- Performing Test C_HAS_SSE4_1_1
-- Performing Test C_HAS_SSE4_1_1 - Failed
-- Performing Test C_HAS_SSE4_1_2
-- Performing Test C_HAS_SSE4_1_2 - Failed
-- Performing Test C_HAS_SSE4_1_3
-- Performing Test C_HAS_SSE4_1_3 - Failed
-- Performing Test C_HAS_SSE4_1_4
-- Performing Test C_HAS_SSE4_1_4 - Failed
-- Performing Test C_HAS_SSE4_2_1
-- Performing Test C_HAS_SSE4_2_1 - Failed
-- Performing Test C_HAS_SSE4_2_2
-- Performing Test C_HAS_SSE4_2_2 - Failed
-- Performing Test C_HAS_SSE4_2_3
-- Performing Test C_HAS_SSE4_2_3 - Failed
-- Performing Test C_HAS_SSE4_2_4
-- Performing Test C_HAS_SSE4_2_4 - Failed
-- Performing Test C_HAS_AVX_1
-- Performing Test C_HAS_AVX_1 - Failed
-- Performing Test C_HAS_AVX_2
-- Performing Test C_HAS_AVX_2 - Failed
-- Performing Test C_HAS_AVX_3
-- Performing Test C_HAS_AVX_3 - Failed
-- Performing Test C_HAS_AVX2_1
-- Performing Test C_HAS_AVX2_1 - Failed
-- Performing Test C_HAS_AVX2_2
-- Performing Test C_HAS_AVX2_2 - Failed
-- Performing Test C_HAS_AVX2_3
-- Performing Test C_HAS_AVX2_3 - Failed
-- Performing Test CXX_HAS_SSE1_1
-- Performing Test CXX_HAS_SSE1_1 - Failed
-- Performing Test CXX_HAS_SSE1_2
-- Performing Test CXX_HAS_SSE1_2 - Failed
-- Performing Test CXX_HAS_SSE1_3
-- Performing Test CXX_HAS_SSE1_3 - Failed
-- Performing Test CXX_HAS_SSE2_1
-- Performing Test CXX_HAS_SSE2_1 - Failed
-- Performing Test CXX_HAS_SSE2_2
-- Performing Test CXX_HAS_SSE2_2 - Failed
-- Performing Test CXX_HAS_SSE2_3
-- Performing Test CXX_HAS_SSE2_3 - Failed
-- Performing Test CXX_HAS_SSE3_1
-- Performing Test CXX_HAS_SSE3_1 - Failed
-- Performing Test CXX_HAS_SSE3_2
-- Performing Test CXX_HAS_SSE3_2 - Failed
-- Performing Test CXX_HAS_SSE3_3
-- Performing Test CXX_HAS_SSE3_3 - Failed
-- Performing Test CXX_HAS_SSE4_1_1
-- Performing Test CXX_HAS_SSE4_1_1 - Failed
-- Performing Test CXX_HAS_SSE4_1_2
-- Performing Test CXX_HAS_SSE4_1_2 - Failed
-- Performing Test CXX_HAS_SSE4_1_3
-- Performing Test CXX_HAS_SSE4_1_3 - Failed
-- Performing Test CXX_HAS_SSE4_1_4
-- Performing Test CXX_HAS_SSE4_1_4 - Failed
-- Performing Test CXX_HAS_SSE4_2_1
-- Performing Test CXX_HAS_SSE4_2_1 - Failed
-- Performing Test CXX_HAS_SSE4_2_2
-- Performing Test CXX_HAS_SSE4_2_2 - Failed
-- Performing Test CXX_HAS_SSE4_2_3
-- Performing Test CXX_HAS_SSE4_2_3 - Failed
-- Performing Test CXX_HAS_SSE4_2_4
-- Performing Test CXX_HAS_SSE4_2_4 - Failed
-- Performing Test CXX_HAS_AVX_1
-- Performing Test CXX_HAS_AVX_1 - Failed
-- Performing Test CXX_HAS_AVX_2
-- Performing Test CXX_HAS_AVX_2 - Failed
-- Performing Test CXX_HAS_AVX_3
-- Performing Test CXX_HAS_AVX_3 - Failed
-- Performing Test CXX_HAS_AVX2_1
-- Performing Test CXX_HAS_AVX2_1 - Failed
-- Performing Test CXX_HAS_AVX2_2
-- Performing Test CXX_HAS_AVX2_2 - Failed
-- Performing Test CXX_HAS_AVX2_3
-- Performing Test CXX_HAS_AVX2_3 - Failed
-- Performing Test HAS_C11_ATOMICS
-- Performing Test HAS_C11_ATOMICS - Failed
-- Performing Test HAS_MSC_ATOMICS
-- Performing Test HAS_MSC_ATOMICS - Failed
-- Performing Test HAS_GCC_ATOMICS
-- Performing Test HAS_GCC_ATOMICS - Success
-- TH_SO_VERSION: 1
-- Atomics: using GCC intrinsics
-- Looking for sys/types.h
-- Looking for sys/types.h - found
-- Looking for stdint.h
-- Looking for stdint.h - found
-- Looking for stddef.h
-- Looking for stddef.h - found
-- Check size of void*
-- Check size of void* - done
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - pthread - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - pthread - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - pthread - m]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - pthread - m]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - pthread - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - pthread - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - pthread - m]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - pthread - m]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_sequential - mkl_core - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_sequential - mkl_core - m]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_sequential - mkl_core - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_sequential - mkl_core - m]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_sequential - mkl_core - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_sequential - mkl_core - m]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_sequential - mkl_core - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_sequential - mkl_core - m]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - iomp5 - pthread - m]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - pthread - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - pthread - m]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - pthread - m]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - pthread - m]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - pthread - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - pthread - m]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - pthread - m]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - pthread - m]
--   Library mkl_intel: not found
-- Checking for [mkl - guide - pthread - m]
--   Library mkl: not found
-- MKL library not found
-- Checking for [openblas]
--   Library openblas: BLAS_openblas_LIBRARY-NOTFOUND
-- Checking for [openblas - pthread]
--   Library openblas: BLAS_openblas_LIBRARY-NOTFOUND
-- Checking for [goto2 - gfortran]
--   Library goto2: BLAS_goto2_LIBRARY-NOTFOUND
-- Checking for [goto2 - gfortran - pthread]
--   Library goto2: BLAS_goto2_LIBRARY-NOTFOUND
-- Checking for [acml - gfortran]
--   Library acml: BLAS_acml_LIBRARY-NOTFOUND
-- Checking for [Accelerate]
--   Library Accelerate: BLAS_Accelerate_LIBRARY-NOTFOUND
-- Checking for [vecLib]
--   Library vecLib: BLAS_vecLib_LIBRARY-NOTFOUND
-- Checking for [ptf77blas - atlas - gfortran]
--   Library ptf77blas: BLAS_ptf77blas_LIBRARY-NOTFOUND
-- Checking for [blas]
--   Library blas: /usr/lib/libblas.so
-- Looking for sgemm_
-- Looking for sgemm_ - found
-- Performing Test BLAS_F2C_DOUBLE_WORKS
-- Performing Test BLAS_F2C_DOUBLE_WORKS - Success
-- Performing Test BLAS_F2C_FLOAT_WORKS
-- Performing Test BLAS_F2C_FLOAT_WORKS - Success
-- Found a library with BLAS API (generic).
-- Looking for cheev_
-- Looking for cheev_ - found
-- Found a library with LAPACK API. (generic)
-- Looking for clock_gettime in rt
-- Looking for clock_gettime in rt - found
-- Looking for mmap
-- Looking for mmap - found
-- Looking for shm_open
-- Looking for shm_open - found
-- Looking for shm_unlink
-- Looking for shm_unlink - found
-- Looking for malloc_usable_size
-- Looking for malloc_usable_size - found
-- Performing Test C_HAS_THREAD
-- Performing Test C_HAS_THREAD - Success
-- Configuring done
-- Generating done
CMake Warning:
  Manually-specified variables were not used by the project:

    CUDA_NVCC_FLAGS
    NO_CUDA
    THCUNN_SO_VERSION
    THC_LIBRARIES
    THC_SO_VERSION
    THD_SO_VERSION
    THNN_SO_VERSION
    THPP_LIBRARIES
    THS_LIBRARIES
    TH_INCLUDE_PATH
    TH_LIB_PATH
    Torch_FOUND


-- Build files have been written to: /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/build/TH
Scanning dependencies of target TH
[ 13%] Building C object CMakeFiles/TH.dir/THGeneral.c.o
[ 13%] Building C object CMakeFiles/TH.dir/THHalf.c.o
[ 20%] Building C object CMakeFiles/TH.dir/THAllocator.c.o
[ 26%] Building C object CMakeFiles/TH.dir/THStorage.c.o
[ 33%] Building C object CMakeFiles/TH.dir/THTensor.c.o
[ 40%] Building C object CMakeFiles/TH.dir/THBlas.c.o
[ 53%] Building C object CMakeFiles/TH.dir/THRandom.c.o
[ 53%] Building C object CMakeFiles/TH.dir/THLapack.c.o
[ 60%] Building C object CMakeFiles/TH.dir/THLogAdd.c.o
[ 66%] Building C object CMakeFiles/TH.dir/THFile.c.o
[ 73%] Building C object CMakeFiles/TH.dir/THDiskFile.c.o
[ 80%] Building C object CMakeFiles/TH.dir/THMemoryFile.c.o
[ 86%] Building C object CMakeFiles/TH.dir/THAtomic.c.o
[ 93%] Building C object CMakeFiles/TH.dir/THVector.c.o
In file included from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.c:3:0:
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.h:6:37: error: ‘THFloatVector_adds_VSX’ undeclared here (not in a function)
 #define THVector_(NAME) TH_CONCAT_4(TH,Real,Vector_,NAME)
                                     ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/simd/simd.h:19:25: note: in definition of macro ‘FUNCTION_IMPL’
     { .function=(void *)NAME,    \
                         ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/build/TH/THGeneral.h:109:30: note: in expansion of macro ‘TH_CONCAT_4_EXPAND’
 #define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)
                              ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.h:6:25: note: in expansion of macro ‘TH_CONCAT_4’
 #define THVector_(NAME) TH_CONCAT_4(TH,Real,Vector_,NAME)
                         ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:90:21: note: in expansion of macro ‘THVector_’
       FUNCTION_IMPL(THVector_(adds_VSX), SIMDExtension_VSX),
                     ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.h:6:37: error: ‘THFloatVector_muls_VSX’ undeclared here (not in a function)
 #define THVector_(NAME) TH_CONCAT_4(TH,Real,Vector_,NAME)
                                     ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/simd/simd.h:19:25: note: in definition of macro ‘FUNCTION_IMPL’
     { .function=(void *)NAME,    \
                         ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/build/TH/THGeneral.h:109:30: note: in expansion of macro ‘TH_CONCAT_4_EXPAND’
 #define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)
                              ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.h:6:25: note: in expansion of macro ‘TH_CONCAT_4’
 #define THVector_(NAME) TH_CONCAT_4(TH,Real,Vector_,NAME)
                         ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:151:21: note: in expansion of macro ‘THVector_’
       FUNCTION_IMPL(THVector_(muls_VSX), SIMDExtension_VSX),
                     ^
In file included from generic/THVectorDispatch.c:1:0,
                 from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THGenerateAllTypes.h:7,
                 from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.c:30:
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:151:7: error: initializer element is not constant
       FUNCTION_IMPL(THVector_(muls_VSX), SIMDExtension_VSX),
       ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:151:7: error: (near initialization for ‘THFloatVector_muls_DISPATCHTABLE[0].function’)
In file included from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.c:3:0:
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.h:6:37: error: ‘THDoubleVector_adds_VSX’ undeclared here (not in a function)
 #define THVector_(NAME) TH_CONCAT_4(TH,Real,Vector_,NAME)
                                     ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/simd/simd.h:19:25: note: in definition of macro ‘FUNCTION_IMPL’
     { .function=(void *)NAME,    \
                         ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/build/TH/THGeneral.h:109:30: note: in expansion of macro ‘TH_CONCAT_4_EXPAND’
 #define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)
                              ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.h:6:25: note: in expansion of macro ‘TH_CONCAT_4’
 #define THVector_(NAME) TH_CONCAT_4(TH,Real,Vector_,NAME)
                         ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:90:21: note: in expansion of macro ‘THVector_’
       FUNCTION_IMPL(THVector_(adds_VSX), SIMDExtension_VSX),
                     ^
In file included from generic/THVectorDispatch.c:1:0,
                 from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THGenerateAllTypes.h:7,
                 from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.c:30:
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:90:7: error: initializer element is not constant
       FUNCTION_IMPL(THVector_(adds_VSX), SIMDExtension_VSX),
       ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:90:7: error: (near initialization for ‘THDoubleVector_adds_DISPATCHTABLE[0].function’)
In file included from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.c:3:0:
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.h:6:37: error: ‘THDoubleVector_muls_VSX’ undeclared here (not in a function)
 #define THVector_(NAME) TH_CONCAT_4(TH,Real,Vector_,NAME)
                                     ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/simd/simd.h:19:25: note: in definition of macro ‘FUNCTION_IMPL’
     { .function=(void *)NAME,    \
                         ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/build/TH/THGeneral.h:109:30: note: in expansion of macro ‘TH_CONCAT_4_EXPAND’
 #define TH_CONCAT_4(x,y,z,w) TH_CONCAT_4_EXPAND(x,y,z,w)
                              ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.h:6:25: note: in expansion of macro ‘TH_CONCAT_4’
 #define THVector_(NAME) TH_CONCAT_4(TH,Real,Vector_,NAME)
                         ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:151:21: note: in expansion of macro ‘THVector_’
       FUNCTION_IMPL(THVector_(muls_VSX), SIMDExtension_VSX),
                     ^
In file included from generic/THVectorDispatch.c:1:0,
                 from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THGenerateAllTypes.h:7,
                 from /nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/THVector.c:30:
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:151:7: error: initializer element is not constant
       FUNCTION_IMPL(THVector_(muls_VSX), SIMDExtension_VSX),
       ^
/nethome/mdukhan3/tools/pytorch/pytorch/torch/lib/TH/generic/THVectorDispatch.c:151:7: error: (near initialization for ‘THDoubleVector_muls_DISPATCHTABLE[0].function’)
make[2]: *** [CMakeFiles/TH.dir/THVector.c.o] Error 1
make[2]: *** Waiting for unfinished jobs....
make[1]: *** [CMakeFiles/TH.dir/all] Error 2
make: *** [all] Error 2```
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Maratyszcza' date='2017-03-05T16:34:25Z'>
		yes, do you have an ssh to a ppc64 machine that i can use to fix these issues? &lt;denchmark-link:https://github.com/Jokeren&gt;@Jokeren&lt;/denchmark-link&gt;
 's optimizations PR broke the VSX part as the interfaces were changed.
		</comment>
		<comment id='2' author='Maratyszcza' date='2017-03-06T06:43:56Z'>
		Nope, its a university machine, I have only user-level access to it.
		</comment>
		<comment id='3' author='Maratyszcza' date='2017-03-15T00:09:46Z'>
		&lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
 are you able to explain what dependency is broken? I can't find the PR you mentioned.
		</comment>
		<comment id='4' author='Maratyszcza' date='2017-03-15T01:06:59Z'>
		&lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
  Looks like the issue is that it is looks for THFloatVector_add_VSX but the function is THFloatVector_add_VSX. Commit &lt;denchmark-link:https://github.com/pytorch/pytorch/commit/5ca6516ecbf230772eb393f320e14c1fb2e6ff87&gt;5ca6516&lt;/denchmark-link&gt;
 adds an 's' onto a whole bunch of things, maybe this introduced the problem?
		</comment>
		<comment id='5' author='Maratyszcza' date='2017-03-21T00:55:10Z'>
		I'm running into this error when trying to install modules via luarocks (and so cannot run tests that require these modules). I would appreciate any help in getting this resolved!  &lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
  I'm happy to try things out on a ppc64le machine on your behalf, or you could use &lt;denchmark-link:https://www.ibm.com/developerworks/library/l-qemu-development/&gt;qemu&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://ptopenlab.com/cloudlabconsole/#/&gt;SuperVessel &lt;/denchmark-link&gt;
or &lt;denchmark-link:http://osuosl.org/services/powerdev/&gt;osuosl &lt;/denchmark-link&gt;
 to set up a ppc test environment.
		</comment>
		<comment id='6' author='Maratyszcza' date='2017-03-21T13:56:43Z'>
		I'm running into the same issue.
&lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
 it is failing with not declared error for  and . Also there is the &lt;denchmark-link:http://openpower.ic.unicamp.br/minicloud/&gt;minicloud&lt;/denchmark-link&gt;
, which you can create and use a PPC64le machine.
		</comment>
		<comment id='7' author='Maratyszcza' date='2017-03-23T01:54:38Z'>
		I've requested access to minicloud, and once I get access I shall fix the issue.
		</comment>
		<comment id='8' author='Maratyszcza' date='2017-03-23T21:00:28Z'>
		&lt;denchmark-link:https://github.com/gchanan&gt;@gchanan&lt;/denchmark-link&gt;
 is going to look into it, we got access to minicloud.
		</comment>
		<comment id='9' author='Maratyszcza' date='2017-03-30T06:46:16Z'>
		Hi guys, any news on the subject?
		</comment>
		<comment id='10' author='Maratyszcza' date='2017-03-31T18:36:38Z'>
		&lt;denchmark-link:https://github.com/torch/torch7/pull/990&gt;torch/torch7#990&lt;/denchmark-link&gt;
 seems to fix the compile issue.  At least with my combination of OS (CentOS7) /compiler (gcc 4.8.x)/etc tests were failing because  is defined to be  (it definitely shouldn't be), and my attempt at quick workarounds didn't fix all the issues.  You might want to try with an up-to-date compiler and see if it works for you.
		</comment>
		<comment id='11' author='Maratyszcza' date='2017-03-31T19:57:39Z'>
		pytorch should now be building with master.
But as &lt;denchmark-link:https://github.com/gchanan&gt;@gchanan&lt;/denchmark-link&gt;
 noted, when we used the minicloud systems,  was defined as , which makes no sense (it has to be ). The OS was CentOS7 and compiler was gcc 4.8.3.
We are assuming that a more up-to-date compiler or a different compiler fixes this on PPC64, and that's how you guys have been using torch7 under the &lt;denchmark-link:https://github.com/PPC64/&gt;https://github.com/PPC64/&lt;/denchmark-link&gt;
 branch.
If you are going to try pytorch on an OpenPower system, please run unit tests and make sure they pass.
		</comment>
		<comment id='12' author='Maratyszcza' date='2017-04-01T07:53:55Z'>
		Hi,
pytorch is now building for me now, but unit tests give me Segmentation Fault
(gan) user@minsky31:~$ repositories/pytorch/test/run_test.sh ~/repositories/pytorch/test ~ Running torch tests ...repositories/pytorch/test/run_test.sh: line 24: 66034 Segmentation fault      (core dumped) $PYCMD test_torch.py $@
I am using gcc (Ubuntu/IBM 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
		</comment>
		<comment id='13' author='Maratyszcza' date='2017-04-01T13:55:33Z'>
		yes, see my comment above. Something is weird on IBM. &lt;denchmark-link:https://github.com/tomsercu&gt;@tomsercu&lt;/denchmark-link&gt;
 if there's a chance you can ask one of the IBM engineers about &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/922#issuecomment-290814414&gt;#922 (comment)&lt;/denchmark-link&gt;
 and why it deviates from the OpenPower spec, it would be great.
		</comment>
		<comment id='14' author='Maratyszcza' date='2017-04-03T07:07:04Z'>
		&lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
 , I see. But are we sure this is true for all OSes and compilers? I am running Ubuntu 16.04 with gcc 4.8.5 and when I compile the following code with the  flag it gives me no warning, while the same is not true if I use an  variable.
&lt;denchmark-code&gt;(pytorch) pedro@hal9000:~/repositories/pytorch$ cat testptr.c 
#include "stdio.h"
#include "stddef.h"
int main(){
    ptrdiff_t var = -3;
    return 0;
}

(pytorch) pedro@hal9000:~/repositories/pytorch$ gcc -Wconversion testptr.c 
(pytorch) pedro@hal9000:~/repositories/pytorch$
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;(pytorch) pedro@hal9000:~/repositories/pytorch$ cat testptr.c 
#include "stdio.h"
#include "stddef.h"
int main(){
    unsigned long var = -3;
    return 0;
}

(pytorch) pedro@hal9000:~/repositories/pytorch$ gcc -Wconversion testptr2.c 
testptr2.c: In function ‘main’:
testptr2.c:4:5: warning: negative integer implicitly converted to unsigned type [-Wsign-conversion]
     unsigned long var = -3;
     ^
&lt;/denchmark-code&gt;

Is this a valid test? Thanks
		</comment>
		<comment id='15' author='Maratyszcza' date='2017-04-03T14:40:26Z'>
		Just from the spec:
std::ptrdiff_t is the signed integer type of the result of subtracting two pointers.
&lt;denchmark-link:http://en.cppreference.com/w/cpp/types/ptrdiff_t&gt;http://en.cppreference.com/w/cpp/types/ptrdiff_t&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='Maratyszcza' date='2017-04-03T14:42:09Z'>
		I'm just saying that on the platform we saw, ptrdiff_t was unsigned long. We are not sure why. But that's the reason for the segfault and the incorrect behavior of rest of pytorch under PPC64 in what we tested.
		</comment>
		<comment id='17' author='Maratyszcza' date='2017-04-03T14:43:01Z'>
		Your test is valid. we want ptrdiff_t to be signed, and in your test case it gives no warning correctly when using ptrdiff_t which is a signed type.
		</comment>
		<comment id='18' author='Maratyszcza' date='2017-04-03T20:00:00Z'>
		When I'm compiling &lt;denchmark-link:https://github.com/pedropgusmao&gt;@pedropgusmao&lt;/denchmark-link&gt;
 's tests, similar as for him, no problem for  ie for me it is signed as it should be.
That is on rhel7 gcc 4.8.5.
So this might be specific to  minicloud? I'm checking whether we can give you access to an IBM machine.
If  is unsigned on your test machine, does that mean it is incorrecly defined in the Linux header files?
In accordance with the ELFV2 ABI, the definition of  should be

		</comment>
		<comment id='19' author='Maratyszcza' date='2017-04-04T02:01:54Z'>
		Weird, for both my ppc64le machines -  CentOS 7.2 with gcc 4.8.5 and Ubuntu 16.04 with gcc 4.5.x -  ptrdiff_t was signed.
		</comment>
		<comment id='20' author='Maratyszcza' date='2017-04-04T02:34:06Z'>
		ok then we'll resign this to some weirdness with the minicloud systems then.
If you guys compile pytorch and PPC64 and all unit tests pass, then you're good to go :)
		</comment>
		<comment id='21' author='Maratyszcza' date='2017-04-04T03:03:16Z'>
		At first sight no existing way to give you acces to a power machine at IBM, but the recommedation is  that Power users obtain virtual machines on NIMBIX (a Power cloud with with support for up-to-date OSes).
Tomorrow I'll compile torch &amp; pytorch with this recent fix and update if any issues or segfaults.
		</comment>
		<comment id='22' author='Maratyszcza' date='2017-04-04T07:08:28Z'>
		I have compiled pytorch from source and, although compilation runs fine, I still get:
&lt;denchmark-code&gt;(gan) user@minsky31:~/repositories/pytorch/test$ ./run_test.sh 
~/repositories/pytorch/test ~/repositories/pytorch/test
Running torch tests
..../run_test.sh: line 24: 88566 Segmentation fault      (core dumped) $PYCMD test_torch.py $@
&lt;/denchmark-code&gt;

		</comment>
		<comment id='23' author='Maratyszcza' date='2017-04-04T08:25:05Z'>
		GDB gives me:
&lt;denchmark-code&gt;(gan) user@minsky31:~/repositories/pytorch/test$ gdb python 
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1
Copyright (C) 2016 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "powerpc64le-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
&lt;http://www.gnu.org/software/gdb/bugs/&gt;.
Find the GDB manual and other documentation resources online at:
&lt;http://www.gnu.org/software/gdb/documentation/&gt;.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from python...done.
(gdb) run test_torch.py
Starting program: /home/user/miniconda3/envs/gan/bin/python test_torch.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/powerpc64le-linux-gnu/libthread_db.so.1".
[New Thread 0x3fff18eef1a0 (LWP 89871)]
...
Thread 1 "python" received signal SIGSEGV, Segmentation fault.
0x00003fff346d9ff4 in THDoubleVector_muls_VSX () from /home/user/miniconda3/envs/gan/lib/python3.6/site-packages/torch/lib/libTH.so.1
&lt;/denchmark-code&gt;

		</comment>
		<comment id='24' author='Maratyszcza' date='2017-04-04T11:36:37Z'>
		FYI,
I also tried to run the test in &lt;denchmark-link:https://github.com/pytorch/pytorch/blob/master/torch/lib/TH/vector/VSX.c&gt;https://github.com/pytorch/pytorch/blob/master/torch/lib/TH/vector/VSX.c&lt;/denchmark-link&gt;
 (where THDoubleVector_muls_VSX () is defined ) and got some definition problems. It seems that the  and  were defined but the code actually required standardDouble_mul() and standardFloat_mul(), as noticed by &lt;denchmark-link:https://github.com/RashmicaG&gt;@RashmicaG&lt;/denchmark-link&gt;
.
Modifying the code to new function names resulted in all All tests passed:
&lt;denchmark-code&gt;standardDouble_fill() test took 0.33023 seconds
THDoubleVector_fill_VSX() test took 0.16157 seconds
All assertions PASSED for THDoubleVector_fill_VSX() test.

standardFloat_fill() test took 0.31468 seconds
THFloatVector_fill_VSX() test took 0.08073 seconds
All assertions PASSED for THFloatVector_fill_VSX() test.

standardDouble_adds() test took 0.45609 seconds
THDoubleVector_adds_VSX() test took 0.30265 seconds
All assertions PASSED for THDoubleVector_adds_VSX() test.

standardFloat_adds() test took 0.38353 seconds
THFloatVector_adds_VSX() test took 0.14310 seconds
All assertions PASSED for THFloatVector_adds_VSX() test.

standardDouble_diff() test took 0.42574 seconds
THDoubleVector_diff_VSX() test took 0.29341 seconds
All assertions PASSED for THDoubleVector_diff_VSX() test.

standardFloat_diff() test took 0.48570 seconds
THFloatVector_diff_VSX() test took 0.15327 seconds
All assertions PASSED for THFloatVector_diff_VSX() test.

standardDouble_scale() test took 0.31753 seconds
THDoubleVector_scale_VSX() test took 0.17237 seconds
All assertions PASSED for THDoubleVector_scale_VSX() test.

standardFloat_scale() test took 0.31478 seconds
THFloatVector_scale_VSX() test took 0.08644 seconds
All assertions PASSED for THFloatVector_scale_VSX() test.

standardDouble_muls() test took 0.45221 seconds
THDoubleVector_muls_VSX() test took 0.29897 seconds
All assertions PASSED for THDoubleVector_muls_VSX() test.

standardFloat_muls() test took 0.38739 seconds
THFloatVector_muls_VSX() test took 0.14117 seconds
All assertions PASSED for THFloatVector_muls_VSX() test.

Finished runnning all tests. All tests PASSED.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='25' author='Maratyszcza' date='2017-04-05T11:20:32Z'>
		&lt;denchmark-link:https://github.com/pedropgusmao&gt;@pedropgusmao&lt;/denchmark-link&gt;
 Hi, I see what you mean:
&lt;denchmark-code&gt;$ gcc ./torch/lib/TH/vector/VSX.c -o vsx -DRUN_VSX_TESTS
./torch/lib/TH/vector/VSX.c: In function ‘test_THDoubleVector_muls_VSX’:
./torch/lib/TH/vector/VSX.c:1739:5: warning: implicit declaration of function ‘standardDouble_muls’ [-Wimplicit-function-declaration]
     standardDouble_muls(y_standard, x, VSX_PERF_NUM_TEST_ELEMENTS  );
     ^
./torch/lib/TH/vector/VSX.c: In function ‘test_THFloatVector_muls_VSX’:
./torch/lib/TH/vector/VSX.c:1811:5: warning: implicit declaration of function ‘standardFloat_muls’ [-Wimplicit-function-declaration]
     standardFloat_muls(y_standard, x, VSX_PERF_NUM_TEST_ELEMENTS  );
     ^
/tmp/ccTWsGeZ.o: In function `test_THDoubleVector_muls_VSX':
VSX.c:(.text+0xbfcc): undefined reference to `standardDouble_muls'
VSX.c:(.text+0xbfe4): undefined reference to `standardDouble_muls'
VSX.c:(.text+0xbffc): undefined reference to `standardDouble_muls'
VSX.c:(.text+0xc014): undefined reference to `standardDouble_muls'
VSX.c:(.text+0xc134): undefined reference to `standardDouble_muls'
/tmp/ccTWsGeZ.o:VSX.c:(.text+0xc168): more undefined references to `standardDouble_muls' follow
/tmp/ccTWsGeZ.o: In function `test_THFloatVector_muls_VSX':
VSX.c:(.text+0xc534): undefined reference to `standardFloat_muls'
VSX.c:(.text+0xc54c): undefined reference to `standardFloat_muls'
VSX.c:(.text+0xc564): undefined reference to `standardFloat_muls'
VSX.c:(.text+0xc57c): undefined reference to `standardFloat_muls'
VSX.c:(.text+0xc69c): undefined reference to `standardFloat_muls'
/tmp/ccTWsGeZ.o:VSX.c:(.text+0xc6d0): more undefined references to `standardFloat_muls' follow
collect2: error: ld returned 1 exit status
&lt;/denchmark-code&gt;

But after adding your diff:
diff --git i/torch/lib/TH/vector/VSX.c w/torch/lib/TH/vector/VSX.c
index 796d3b8..fbc7d61 100644
--- i/torch/lib/TH/vector/VSX.c
+++ w/torch/lib/TH/vector/VSX.c
@@ -1105,13 +1105,13 @@ static void standardFloat_scale(float *y, const float c, const ptrdiff_t n)
     y[i] *= c;
 }

-static void standardDouble_mul(double *y, const double *x, const ptrdiff_t n)
+static void standardDouble_muls(double *y, const double *x, const ptrdiff_t n)
 {
   for (ptrdiff_t i = 0; i &lt; n; i++)
     y[i] *= x[i];
 }

-static void standardFloat_mul(float *y, const float *x, const ptrdiff_t n)
+static void standardFloat_muls(float *y, const float *x, const ptrdiff_t n)
 {
   for (ptrdiff_t i = 0; i &lt; n; i++)
     y[i] *= x[i];
I coud compile and run VSX's tests, however I still didn't accomplish to have torch's tests passing. They segfault as you said on &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/922#issuecomment-291429297&gt;#922 (comment)&lt;/denchmark-link&gt;

Does anybody have progress on this?
		</comment>
		<comment id='26' author='Maratyszcza' date='2017-04-05T14:51:36Z'>
		I'm still digging, but I believe there is a problem in the interface between torch.mul() and the vector multiplication functions in VSX.c. Also I think functions in VSX.c are only called when multiplication does not use slices.
I say this because the segmentation fault that emerges for torch's set of tests is actually generated from test_abs and not from test_mul.
You can check this by running:
&lt;denchmark-code&gt;$ ptyhon path_to_pytorch/test/test_torch.py TestTorch.test_abs
Segmentation fault (core dumped)
&lt;/denchmark-code&gt;

and
&lt;denchmark-code&gt;$ ptyhon path_to_pytorch/test/test_torch.py TestTorch.test_mul
.
----------------------------------------------------------------------
Ran 1 test in 0.001s

OK
&lt;/denchmark-code&gt;

Now, if you check the code for each one of these tests you will see that test_abs uses tensor.mul(value)  while test_mul uses a sliced_tensor[:,3].mul_(value).
This become clearer if you add the following tests to the same script
&lt;denchmark-code&gt;def test_mul_slice_mat(self):
    m1 = torch.ones(10,10)
    m  = m1[:,0].mul(5)
 
def test_mul_vec(self):
    m1 = torch.ones(10,1)
    m = m1.mul(5)
&lt;/denchmark-code&gt;

and run them as before.
At least for me, using the sliced version gives no error while the normal version it gives me segfault.
Now, when compiling pytorch with a DEBUG flag (I guess I just exported export DEBUG=1 before compiling it) and using gdb with a breakpoint at path_to_pytorch/torch/lib/TH/vector/VSX.c:408 (inside the function but outside a loop) it lets me see that test_abs enters THDoubleVector_muls_VSX while test_mul doesn't .
&lt;denchmark-code&gt;(gan) user@minsky31:~/repositories/pytorch$ gdb python
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1
....
(gdb) b /home/user/repositories/pytorch/torch/lib/TH/vector/VSX.c:408
No source file named /home/user/repositories/pytorch/torch/lib/TH/vector/VSX.c.
Make breakpoint pending on future shared library load? (y or [n]) y
Breakpoint 1 (/home/user/repositories/pytorch/torch/lib/TH/vector/VSX.c:408) pending.
(gdb) run test/test_torch.py TestTorch.test_abs
Starting program: /home/user/miniconda3/envs/gan/bin/python test/test_torch.py TestTorch.test_abs
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/powerpc64le-linux-gnu/libthread_db.so.1".
[New Thread 0x3fff156ef1a0 (LWP 3286)]

Thread 1 "python" hit Breakpoint 1, THDoubleVector_muls_VSX (y=0x10ba1e00, x=0x10b9fe00, n=70367515247288) at /home/user/repositories/pytorch/torch/lib/TH/vector/VSX.c:411
411         for (i = 0; i &lt;= n-24; i += 24)
&lt;/denchmark-code&gt;

and
&lt;denchmark-code&gt;(gan) user@minsky31:~/repositories/pytorch$ gdb python
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.04) 7.11.1
...
(gdb) b /home/user/repositories/pytorch/torch/lib/TH/vector/VSX.c:408
No source file named /home/user/repositories/pytorch/torch/lib/TH/vector/VSX.c.
Make breakpoint pending on future shared library load? (y or [n]) y
Breakpoint 1 (/home/user/repositories/pytorch/torch/lib/TH/vector/VSX.c:408) pending.
(gdb) run test/test_torch.py TestTorch.test_mul
Starting program: /home/user/miniconda3/envs/gan/bin/python test/test_torch.py TestTorch.test_mul
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/powerpc64le-linux-gnu/libthread_db.so.1".
[New Thread 0x3fff156ef1a0 (LWP 3396)]
.
----------------------------------------------------------------------
Ran 1 test in 0.001s

OK
[Thread 0x3fff156ef1a0 (LWP 3396) exited]
[Inferior 1 (process 3393) exited normally]
&lt;/denchmark-code&gt;

At this point, if we check the values of n and y inside THDoubleVector_muls_VSX (for test_abs),  we see some strange things:
&lt;denchmark-code&gt;(gdb) p n
$1 = 70367515247288
(gdb) p *x
$2 = 0.69646918727084994
(gdb) p *y
$3 = 0
(gdb) p *(y+9)
$4 = 0
(gdb) p *(y+10)
$5 = 0
(gdb) p *(x+9)
$6 = 0.49111893260851502
(gdb) p *(x+10)
$7 = 0.42310646059922874
(gdb) p *x
$8 = 0.69646918727084994
(gdb) p *(x+999)
$9 = 0.56434643105603755
(gdb) p *(x+1000)
$10 = 0
(gdb) p *(y+999)
$11 = 0
(gdb) p *(y+1000)
$12 = 0
(gdb) p *(y)
$13 = 0
&lt;/denchmark-code&gt;

It is as if x is correctly passed (its size should be 1000 in test_abs); y is not correctly passed; and n, which I believe should be the length of each vector (expanded in the case of multiplication by constant), is just a huge number.
If someone could point me to where mul calls THDoubleVector_muls_VSX and alike, I could keep digging.
		</comment>
		<comment id='27' author='Maratyszcza' date='2017-04-05T20:43:24Z'>
		there's a huge mistake here. &lt;denchmark-link:https://github.com/gut&gt;@gut&lt;/denchmark-link&gt;
 really triggered my memory.
So,
THXVector_mul(double *y, const double *x, const ptrdiff_t n) used to be the operation:
y = y * x
See this old commit that has the non-SIMD versions:
&lt;denchmark-link:https://github.com/torch/torch7/blob/1e86025cfa78e13da16835cfc8d459eedfb71f15/lib/TH/generic/THVectorDefault.c&gt;https://github.com/torch/torch7/blob/1e86025cfa78e13da16835cfc8d459eedfb71f15/lib/TH/generic/THVectorDefault.c&lt;/denchmark-link&gt;

After some commits from Keren Zhou revamping our SIMD stuff, we removed that function, and added:
THXVector_muls(double *y, const double *x, const double c, const ptrdiff_t n)
which is
y = x * c
Clearly they are not compatible.
I wonder if we should remove the VSX.c file, unless &lt;denchmark-link:https://github.com/gut&gt;@gut&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://github.com/tomsercu&gt;@tomsercu&lt;/denchmark-link&gt;
 want to actually retain the VSX optimizations and fix the functions to actually do this new prototype. I myself dont know the VSX instruction set to fix this stuff.
		</comment>
		<comment id='28' author='Maratyszcza' date='2017-04-06T12:12:06Z'>
		&lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
 thanks for the explanation. That looks clear to me. I'll start implementing it and will reply to this issue soon to report my progress.
		</comment>
		<comment id='29' author='Maratyszcza' date='2017-04-06T13:42:21Z'>
		By applying &lt;denchmark-link:https://gist.github.com/gut/0bac048d1539b26d326c7eb231e92df9&gt;this diff&lt;/denchmark-link&gt;
, the VSX test looks ok on my machine:
&lt;denchmark-code&gt;standardDouble_fill() test took 3.52016 seconds
THDoubleVector_fill_VSX() test took 0.61788 seconds
All assertions PASSED for THDoubleVector_fill_VSX() test.

standardFloat_fill() test took 3.28862 seconds
THFloatVector_fill_VSX() test took 0.20691 seconds
All assertions PASSED for THFloatVector_fill_VSX() test.

standardDouble_adds() test took 3.23111 seconds
THDoubleVector_adds_VSX() test took 1.26806 seconds
All assertions PASSED for THDoubleVector_adds_VSX() test.

standardFloat_adds() test took 3.09554 seconds
THFloatVector_adds_VSX() test took 0.61319 seconds
All assertions PASSED for THFloatVector_adds_VSX() test.

standardDouble_diff() test took 3.48718 seconds
THDoubleVector_diff_VSX() test took 1.20493 seconds
All assertions PASSED for THDoubleVector_diff_VSX() test.

standardFloat_diff() test took 3.23055 seconds
THFloatVector_diff_VSX() test took 0.56289 seconds
All assertions PASSED for THFloatVector_diff_VSX() test.

standardDouble_scale() test took 3.15807 seconds
THDoubleVector_scale_VSX() test took 0.83008 seconds
All assertions PASSED for THDoubleVector_scale_VSX() test.

standardFloat_scale() test took 3.13747 seconds
THFloatVector_scale_VSX() test took 0.42771 seconds
All assertions PASSED for THFloatVector_scale_VSX() test.

standardDouble_muls() test took 3.22186 seconds
THDoubleVector_muls_VSX() test took 0.86646 seconds
All assertions PASSED for THDoubleVector_muls_VSX() test.

standardFloat_muls() test took 3.15087 seconds
THFloatVector_muls_VSX() test took 0.41949 seconds
All assertions PASSED for THFloatVector_muls_VSX() test.

Finished runnning all tests. All tests PASSED.
&lt;/denchmark-code&gt;

However the test suite still doesn't work:
&lt;denchmark-code&gt;python test/test_torch.py
...F..F..terminate called after throwing an instance of 'THException'
  what():  given function should return a number at /home/gut/pytorch/torch/csrc/generic/TensorMethods.cpp:3888
Aborted
&lt;/denchmark-code&gt;

When debugging, I see that:
&lt;denchmark-code&gt;#8  0x00003fff8fdac2ac in _THError (file=0x3fff9067ee00 "/home/gut/pytorch/torch/csrc/generic/TensorMethods.cpp", line=3888,
    fmt=0x3fff9067f520 "given function should return a number") at /home/gut/pytorch/torch/lib/TH/THGeneral.c:54
54          (*defaultErrorHandler)(msg, defaultErrorHandlerData);
(gdb) up
#9  0x00003fff902c23c4 in THPDoubleTensor_apply (self=0x3fff8f23a7e8, arg=0x3fff8f1f08c0) at /home/gut/pytorch/torch/csrc/generic/TensorMethods.cpp:3877
3877      TH_TENSOR_APPLY(real, tensor,
(gdb ppc) l
3872        THPUtils_setError("apply requires a callable as it's first argument");
3873        return NULL;
3874      }
3875
3876      THTensor *tensor = self-&gt;cdata;
3877      TH_TENSOR_APPLY(real, tensor,
3878                      PyObject *ret =
3879                          PyObject_CallFunction(arg, (char*)BUILD_REAL_FMT, *tensor_data);
3880                      if (!ret)
3881                        return NULL;
(gdb)
3882                      if (!THPUtils_(checkReal)(ret)) {
3883                        Py_DECREF(ret);
3884                        THError("given function should return a number");
3885                      }
3886                      *tensor_data = THPUtils_(unpackReal)(ret);
3887                      Py_DECREF(ret);
3888                      );
3889
3890      Py_INCREF(self);
3891      return (PyObject*)self;
&lt;/denchmark-code&gt;

Any hints? I'm analysing this but I'm quite new on torch.
		</comment>
		<comment id='30' author='Maratyszcza' date='2017-04-06T14:38:33Z'>
		Hi &lt;denchmark-link:https://github.com/gut&gt;@gut&lt;/denchmark-link&gt;
, I am currently working on it. I guess by tomorrow I will have a VSX.c file with tests etc...
The problem I guess is that not only  and  changed but also . I am currenlty writing/modifying calls for &lt;denchmark-link:https://github.com/pytorch/pytorch/blob/master/torch/lib/TH/generic/THVectorDefault.c&gt;https://github.com/pytorch/pytorch/blob/master/torch/lib/TH/generic/THVectorDefault.c&lt;/denchmark-link&gt;

		</comment>
		<comment id='31' author='Maratyszcza' date='2017-04-06T14:45:57Z'>
		&lt;denchmark-link:https://github.com/pedropgusmao&gt;@pedropgusmao&lt;/denchmark-link&gt;
 alright. I hope the &lt;denchmark-link:https://gist.github.com/gut/0bac048d1539b26d326c7eb231e92df9&gt;https://gist.github.com/gut/0bac048d1539b26d326c7eb231e92df9&lt;/denchmark-link&gt;
 helps you.
		</comment>
		<comment id='32' author='Maratyszcza' date='2017-04-07T08:55:22Z'>
		Hi &lt;denchmark-link:https://github.com/gut&gt;@gut&lt;/denchmark-link&gt;
, indeed we were working on the same thing. Could you please check out &lt;denchmark-link:https://gist.github.com/pedropgusmao/fe283d613a3f47ea57b3bf6f81f85fed&gt;https://gist.github.com/pedropgusmao/fe283d613a3f47ea57b3bf6f81f85fed&lt;/denchmark-link&gt;
 and see if it works for you. Right now I get 147/157 passing tests. The ones that are not passing are:  , , , , , , ,   and . Exceptions are of type  and 
		</comment>
		<comment id='33' author='Maratyszcza' date='2017-04-07T10:34:27Z'>
		Hi &lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
, the previous tests are failing during . They are each throwing a specific TH exception which is not being accepted as . Any idea why this is happening? Thanks
&lt;denchmark-code&gt;test_linspace:
throws : 'THArgException'
expects: RuntimeError

test_logspace:
throws : 'THArgException'
expects: RuntimeError

test_gather:
throws : 'THException'
expects: RuntimeError

test_scatter:
throws : 'THException'
expects: RuntimeError

test_scatterFill:
throws : 'THException'
expects: RuntimeError

test_masked_copy:
throws : 'THException'
expects: RuntimeError

test_view:
throws : 'THArgException'
expects: RuntimeError

test_unsqueeze:
throws : 'THArgException'
expects: RuntimeError

test_numpy_unresizable:
throws : 'THException'
expects: RuntimeError

test_apply:
throws : 'THException'
expects: RuntimeError
&lt;/denchmark-code&gt;

		</comment>
		<comment id='34' author='Maratyszcza' date='2017-04-07T11:36:31Z'>
		&lt;denchmark-link:https://github.com/pedropgusmao&gt;@pedropgusmao&lt;/denchmark-link&gt;
 Hi. It looks like it solved the tests that I saw failing:
&lt;denchmark-code&gt;.........terminate called after throwing an instance of 'THException'
  what():  given function should return a number at /home/gut/pytorch/torch/csrc/generic/TensorMethods.cpp:3888
Aborted
&lt;/denchmark-code&gt;

Please note that the execution is being aborted, so I don't know what happened for all tests and I'm curious why yours doesn't abort as well.
		</comment>
		<comment id='35' author='Maratyszcza' date='2017-04-07T11:54:32Z'>
		Hi &lt;denchmark-link:https://github.com/gut&gt;@gut&lt;/denchmark-link&gt;
, I had to run one test at a time.
I first got a list containing the names for each test:
&lt;denchmark-code&gt;grep 'def test_' pytorch/test/test_torch.py | sed 's/^[^t]*//'| sed 's/(self)\://' &gt; pytorch/list_tests.txt

&lt;/denchmark-code&gt;

then I ran each one of those individually:
&lt;denchmark-code&gt; while read in; do echo "$in" &amp;&amp; python pytorch/test/test_torch.py TestTorch."$in"; done &lt; pytorch/list_tests.txt &amp;&gt; test_passed.txt
&lt;/denchmark-code&gt;

If this also works for you and if the "exception" problem is not related to the VSX.c call, then I will open a PR for this file. Thanks
		</comment>
		<comment id='36' author='Maratyszcza' date='2017-04-07T12:02:33Z'>
		Hello &lt;denchmark-link:https://github.com/pedropgusmao&gt;@pedropgusmao&lt;/denchmark-link&gt;
 , nice. Now I see that the one is aborting the test suite looks like it's the "test_apply", as it's the only one with exception 
And these are all the exceptions for the test_torch.py suite. I'll try to take a look at them. Whenever I find out something, I'll post it here:
&lt;denchmark-code&gt;$ grep pytorch test_passed.txt
  what():  invalid number of points at /home/gut/pytorch/torch/lib/TH/generic/THTensorMath.c:2970
  what():  invalid number of points at /home/gut/pytorch/torch/lib/TH/generic/THTensorMath.c:2993
  what():  Invalid index in gather at /home/gut/pytorch/torch/lib/TH/generic/THTensorMath.c:441
  what():  Invalid index in scatter at /home/gut/pytorch/torch/lib/TH/generic/THTensorMath.c:466
  what():  Invalid index in scatter at /home/gut/pytorch/torch/lib/TH/generic/THTensorMath.c:489
  what():  Number of elements of src &lt; number of ones in mask at /home/gut/pytorch/torch/lib/TH/generic/THTensorMath.c:168
  what():  size '[15 x 0]' is invalid for input of with 15 elements at /home/gut/pytorch/torch/lib/TH/THStorage.c:59
  what():  cannot unsqueeze empty tensor at /home/gut/pytorch/torch/lib/TH/generic/THTensor.c:530
  what():  Trying to resize storage that is not resizable at /home/gut/pytorch/torch/lib/TH/generic/THStorage.c:183
  what():  given function should return a number at /home/gut/pytorch/torch/csrc/generic/TensorMethods.cpp:3888
&lt;/denchmark-code&gt;

		</comment>
		<comment id='37' author='Maratyszcza' date='2017-04-07T14:01:11Z'>
		okay, for some reason THArgException isn't being rewrapped as a RuntimeError on this platform. &lt;denchmark-link:https://github.com/apaszke&gt;@apaszke&lt;/denchmark-link&gt;
 do you have ideas on why?
		</comment>
		<comment id='38' author='Maratyszcza' date='2017-04-07T15:38:24Z'>
		PR: &lt;denchmark-link:https://github.com/pytorch/pytorch/pull/1210&gt;#1210&lt;/denchmark-link&gt;

		</comment>
		<comment id='39' author='Maratyszcza' date='2017-04-10T20:51:32Z'>
		well, now it builds, so I guess this issue can be closed.
However the tests are still not passing, so we might want to open another one
		</comment>
		<comment id='40' author='Maratyszcza' date='2017-04-19T12:35:47Z'>
		guys? &lt;denchmark-link:https://github.com/soumith&gt;@soumith&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/apaszke&gt;@apaszke&lt;/denchmark-link&gt;

		</comment>
		<comment id='41' author='Maratyszcza' date='2017-04-19T13:10:02Z'>
		I guess we can just rename this one. Any clues on what causes the tests to fail?
		</comment>
		<comment id='42' author='Maratyszcza' date='2017-04-19T13:12:23Z'>
		Or nvm, there are so many messages that it's probably better to move the discussion elsewhere -&gt; &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/1297&gt;#1297&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='43' author='Maratyszcza' date='2017-09-22T19:51:19Z'>
		Hate to re-open such an long thread :P
I'm trying to install PyTorch on a PPC64 system.  The currently available instructions for installing PyTorch (&lt;denchmark-link:https://github.com/pytorch/pytorch#from-source&gt;https://github.com/pytorch/pytorch#from-source&lt;/denchmark-link&gt;
) fail because the pip whl and conda channel do not have binaries for PPC64.
It seems like the old egg install files for version 0.1 worked on PPC, but is there a recommended way to install the recent version 0.2 on PPC systems?
Also, when building from source on PPC, the compiler seems to go into an infinite loop on the output line


[  6%] Building C object CMakeFiles/TH.dir/THTensor.c.o


..and this turns out to be a pretty hard problem to fix.
		</comment>
		<comment id='44' author='Maratyszcza' date='2017-09-22T22:15:52Z'>
		Currently the only way to install pytorch on ppc64le is by building it from source. I am using ubuntu 16.04.  Download the 0.2.0 branch.  Follow some of the instructions in the Dockerfile for installing conda with a slight mod for ppc64.
curl -o ~/miniconda.sh -O  &lt;denchmark-link:https://repo.continuum.io/miniconda/Miniconda3-4.2.12-Linux-ppc64le.sh&gt;https://repo.continuum.io/miniconda/Miniconda3-4.2.12-Linux-ppc64le.sh&lt;/denchmark-link&gt;
 (there should be a newer version).  chmod the sh file and install anaconda. And then proceed to install the required packages minus mkl .  I also built magma-cuda version 2.2 &lt;denchmark-link:http://icl.cs.utk.edu/projectsfiles/magma/downloads/magma-2.2.0.tar.gz&gt;http://icl.cs.utk.edu/projectsfiles/magma/downloads/magma-2.2.0.tar.gz&lt;/denchmark-link&gt;
.    And then  /opt/conda/bin/python setup.py install.   I am also using cuda but it should work with cpu only.   There are some failing tests in test_cuda when using CharTensor.  All the other functional test seems to pass.
		</comment>
		<comment id='45' author='Maratyszcza' date='2017-09-23T00:44:13Z'>
		Unfortunately, I don't have docker to work with.  All I have is a native Anaconda running on PPC64.
Still..you're telling me that setup.py ran with no modifications inside your PPC64le environment?
		</comment>
		<comment id='46' author='Maratyszcza' date='2017-09-23T00:55:40Z'>
		I've built both in Docker and baremetal.  It built "out of the box". No mods to setup.py.   I've built both using anaconda (using python 3.5) and outside of anaconda (using 2.7 and 3.5)
		</comment>
		<comment id='47' author='Maratyszcza' date='2017-09-23T01:51:58Z'>
		I see.  It may be that I'm having a compilation problem that is not specific to ppc64le.  Perhaps this belongs in another thread, but thanks, avmgithub, for trying to help!
Here's the problem for anyone who's sees this:
The compiler stalls on the line

[  6%] Building C object CMakeFiles/TH.dir/THTensor.c.o

The compiler runs forever without running out of memory.  Seems to be in some sort of infinite loop.  Stack Exchange seems to think this is a known problem with gcc when using the -O* flags.  However, I tried hacking the CMakeLists file to remove the -O flags, and the problem persists.
		</comment>
		<comment id='48' author='Maratyszcza' date='2017-10-10T08:50:07Z'>
		I tried building pytorch with gcc 5.4.0 on POWER8 (ppc64le) with Ubuntu 16.04.3.  It works fine.  I did not test all the test suites, but at least MNIST example runs quite well.  I just ignored mkl and installed openblas instead as you recommended.  You can find the log &lt;denchmark-link:https://hwengineer.blogspot.kr/2017/10/minsky-pytorch-mnist.html&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='49' author='Maratyszcza' date='2018-03-20T16:04:41Z'>
		I am also facing similar problems with installing pytorch on POWER8.
The compiler output is as follows:
&lt;denchmark-code&gt;running install
running build_deps
+ WITH_CUDA=0
+ [[ --with-cuda == \-\-\w\i\t\h\-\c\u\d\a ]]
+ WITH_CUDA=1
+ shift
+ WITH_NNPACK=0
+ [[ --with-nnpack == \-\-\w\i\t\h\-\n\n\p\a\c\k ]]
+ WITH_NNPACK=1
+ shift
+ WITH_GLOO_IBVERBS=0
+ [[ nccl == \-\-\w\i\t\h\-\g\l\o\o\-\i\b\v\e\r\b\s ]]
+ USER_CFLAGS=
+ USER_LDFLAGS=
+ [[ -n '' ]]
+ [[ -n '' ]]
+ [[ -n '' ]]
++ dirname torch/lib/build_libs.sh
+ cd torch/lib/../..
+++ pwd
++ printf '%q\n' /home/sathap1/Software/pytorch
+ PWD=/home/sathap1/Software/pytorch
+ BASE_DIR=/home/sathap1/Software/pytorch
+ cd torch/lib
+ INSTALL_DIR=/home/sathap1/Software/pytorch/torch/lib/tmp_install
+ CMAKE_VERSION=cmake
+ C_FLAGS=' -DTH_INDEX_BASE=0 -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/TH" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THC"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THS" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCS"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THNN" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCUNN"'
+ C_FLAGS=' -DTH_INDEX_BASE=0 -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/TH" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THC"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THS" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCS"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THNN" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCUNN" -DOMPI_SKIP_MPICXX=1'
+ LDFLAGS='-L"/home/sathap1/Software/pytorch/torch/lib/tmp_install/lib" '
+ LD_POSTFIX=.so.1
+ LD_POSTFIX_UNVERSIONED=.so
++ uname
+ [[ Linux == \D\a\r\w\i\n ]]
+ LDFLAGS='-L"/home/sathap1/Software/pytorch/torch/lib/tmp_install/lib"  -Wl,-rpath,$ORIGIN'
+ CPP_FLAGS=' -std=c++11 '
+ GLOO_FLAGS=
+ THD_FLAGS=
+ NCCL_ROOT_DIR=/home/sathap1/Software/pytorch/torch/lib/tmp_install
+ [[ 1 -eq 1 ]]
+ GLOO_FLAGS='-DUSE_CUDA=1 -DNCCL_ROOT_DIR=/home/sathap1/Software/pytorch/torch/lib/tmp_install'
+ [[ 0 -eq 1 ]]
+ CWRAP_FILES='/home/sathap1/Software/pytorch/torch/lib/ATen/Declarations.cwrap;/home/sathap1/Software/pytorch/torch/lib/THNN/generic/THNN.h;/home/sathap1/Software/pytorch/torch/lib/THCUNN/generic/THCUNN.h;/home/sathap1/Software/pytorch/torch/lib/ATen/nn.yaml'
+ CUDA_NVCC_FLAGS=' -DTH_INDEX_BASE=0 -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/TH" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THC"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THS" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCS"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THNN" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCUNN" -DOMPI_SKIP_MPICXX=1'
+ [[ '' -eq 1 ]]
+ '[' -z 160 ']'
+ mkdir -p tmp_install
+ for arg in '"$@"'
+ [[ nccl == \n\c\c\l ]]
+ build_nccl
+ mkdir -p build/nccl
+ cd build/nccl
+ cmake ../../nccl -DCMAKE_MODULE_PATH=/home/sathap1/Software/pytorch/cmake/FindCUDA -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/home/sathap1/Software/pytorch/torch/lib/tmp_install '-DCMAKE_C_FLAGS= -DTH_INDEX_BASE=0 -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/TH" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THC"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THS" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCS"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THNN" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCUNN" -DOMPI_SKIP_MPICXX=1 ' '-DCMAKE_CXX_FLAGS= -DTH_INDEX_BASE=0 -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/TH" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THC"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THS" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCS"   -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THNN" -I"/home/sathap1/Software/pytorch/torch/lib/tmp_install/include/THCUNN" -DOMPI_SKIP_MPICXX=1  -std=c++11  ' -DCMAKE_SHARED_LINKER_FLAGS=
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /opt/apps/gcc/5.4.0/bin/gcc
-- Check for working C compiler: /opt/apps/gcc/5.4.0/bin/gcc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /opt/apps/gcc/5.4.0/bin/g++
-- Check for working CXX compiler: /opt/apps/gcc/5.4.0/bin/g++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found CUDA: /usr/local/cuda (found suitable version "8.0", minimum required is "7.0") 
-- Configuring done
-- Generating done
-- Build files have been written to: /home/sathap1/Software/pytorch/torch/lib/build/nccl
+ make install
Scanning dependencies of target nccl
[100%] Generating lib/libnccl.so
Grabbing  src/nccl.h                          &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/include/nccl.h
Compiling src/libwrap.cu                      &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/obj/libwrap.o
Compiling src/core.cu                         &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/obj/core.o
Compiling src/all_gather.cu                   &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/obj/all_gather.o
Compiling src/all_reduce.cu                   &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/obj/all_reduce.o
Compiling src/broadcast.cu                    &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/obj/broadcast.o
Compiling src/reduce.cu                       &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/obj/reduce.o
Compiling src/reduce_scatter.cu               &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/obj/reduce_scatter.o
ptxas warning : Too big maxrregcount value specified 96, will be ignored
ptxas warning : Too big maxrregcount value specified 96, will be ignored
ptxas warning : Too big maxrregcount value specified 96, will be ignored
ptxas warning : Too big maxrregcount value specified 96, will be ignored
ptxas warning : Too big maxrregcount value specified 96, will be ignored
ptxas warning : Too big maxrregcount value specified 96, will be ignored
ptxas warning : Too big maxrregcount value specified 96, will be ignored
Linking   libnccl.so.1.3.5                    &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/lib/libnccl.so.1.3.5
Archiving libnccl_static.a                    &gt; /home/sathap1/Software/pytorch/torch/lib/build/nccl/lib/libnccl_static.a
[100%] Built target nccl
Install the project...
-- Install configuration: "Release"
-- Installing: /home/sathap1/Software/pytorch/torch/lib/tmp_install/include/nccl.h
+ mkdir -p /home/sathap1/Software/pytorch/torch/lib/tmp_install/lib
+ cp lib/libnccl.so.1 /home/sathap1/Software/pytorch/torch/lib/tmp_install/lib/libnccl.so.1
+ '[' '!' -f /home/sathap1/Software/pytorch/torch/lib/tmp_install/lib/libnccl.so ']'
+ ln -s /home/sathap1/Software/pytorch/torch/lib/tmp_install/lib/libnccl.so.1 /home/sathap1/Software/pytorch/torch/lib/tmp_install/lib/libnccl.so
+ cd ../..
+ for arg in '"$@"'
+ [[ ATen == \n\c\c\l ]]
+ [[ ATen == \g\l\o\o ]]
+ [[ ATen == \A\T\e\n ]]
+ build_aten
+ mkdir -p build/aten
+ cd build/aten
++ '[' ']'
++ echo Release
+ cmake ../../../../aten -DCMAKE_BUILD_TYPE=Release -DNO_CUDA=0 -DNO_NNPACK=0 -DCUDNN_INCLUDE_DIR=/usr/include/ -DCUDNN_LIB_DIR=/usr/lib/powerpc64le-linux-gnu/ -DCUDNN_LIBRARY=/usr/lib/powerpc64le-linux-gnu/libcudnn.so.6 -DATEN_NO_CONTRIB=1 -DCMAKE_INSTALL_PREFIX=/home/sathap1/Software/pytorch/torch/lib/tmp_install -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_C_FLAGS= -DCMAKE_CXX_FLAGS= -DCMAKE_EXE_LINKER_FLAGS= -DCMAKE_SHARED_LINKER_FLAGS=
-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /opt/apps/gcc/5.4.0/bin/gcc
-- Check for working C compiler: /opt/apps/gcc/5.4.0/bin/gcc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /opt/apps/gcc/5.4.0/bin/g++
-- Check for working CXX compiler: /opt/apps/gcc/5.4.0/bin/g++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Performing Test SUPPORT_GLIBCXX_USE_C99
-- Performing Test SUPPORT_GLIBCXX_USE_C99 - Success
-- Found CUDA: /usr/local/cuda (found suitable version "8.0", minimum required is "5.5") 
-- Autodetected CUDA architecture(s): 6.0
-- Found CUDA with FP16 support, compiling with torch.CudaHalfTensor
-- Removing -DNDEBUG from compile flags
-- Try OpenMP C flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
-- Try OpenMP CXX flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
-- Found OpenMP: -fopenmp  
-- Compiling with OpenMP support
-- Checking prototype magma_get_sgeqrf_nb for MAGMA_V2 - True
-- Compiling with MAGMA support
-- MAGMA INCLUDE DIRECTORIES: /home/sathap1/huckleberry/magma/include
-- MAGMA LIBRARIES: /home/sathap1/huckleberry/magma/lib/libmagma.so
-- MAGMA V2 check: 1
-- Could not find hardware support for NEON on this machine.
-- No OMAP3 processor on this machine.
-- No OMAP4 processor on this machine.
-- Performing Test COMPILER_WORKS
-- Performing Test COMPILER_WORKS - Success
-- Looking for cpuid.h
-- Looking for cpuid.h - not found
-- Performing Test NO_GCC_EBX_FPIC_BUG
-- Performing Test NO_GCC_EBX_FPIC_BUG - Failed
-- Performing Test C_HAS_SSE1_1
-- Performing Test C_HAS_SSE1_1 - Failed
-- Performing Test C_HAS_SSE1_2
-- Performing Test C_HAS_SSE1_2 - Failed
-- Performing Test C_HAS_SSE1_3
-- Performing Test C_HAS_SSE1_3 - Failed
-- Performing Test C_HAS_SSE2_1
-- Performing Test C_HAS_SSE2_1 - Failed
-- Performing Test C_HAS_SSE2_2
-- Performing Test C_HAS_SSE2_2 - Failed
-- Performing Test C_HAS_SSE2_3
-- Performing Test C_HAS_SSE2_3 - Failed
-- Performing Test C_HAS_SSE3_1
-- Performing Test C_HAS_SSE3_1 - Failed
-- Performing Test C_HAS_SSE3_2
-- Performing Test C_HAS_SSE3_2 - Failed
-- Performing Test C_HAS_SSE3_3
-- Performing Test C_HAS_SSE3_3 - Failed
-- Performing Test C_HAS_SSE4_1_1
-- Performing Test C_HAS_SSE4_1_1 - Failed
-- Performing Test C_HAS_SSE4_1_2
-- Performing Test C_HAS_SSE4_1_2 - Failed
-- Performing Test C_HAS_SSE4_1_3
-- Performing Test C_HAS_SSE4_1_3 - Failed
-- Performing Test C_HAS_SSE4_1_4
-- Performing Test C_HAS_SSE4_1_4 - Failed
-- Performing Test C_HAS_SSE4_2_1
-- Performing Test C_HAS_SSE4_2_1 - Failed
-- Performing Test C_HAS_SSE4_2_2
-- Performing Test C_HAS_SSE4_2_2 - Failed
-- Performing Test C_HAS_SSE4_2_3
-- Performing Test C_HAS_SSE4_2_3 - Failed
-- Performing Test C_HAS_SSE4_2_4
-- Performing Test C_HAS_SSE4_2_4 - Failed
-- Performing Test C_HAS_AVX_1
-- Performing Test C_HAS_AVX_1 - Failed
-- Performing Test C_HAS_AVX_2
-- Performing Test C_HAS_AVX_2 - Failed
-- Performing Test C_HAS_AVX_3
-- Performing Test C_HAS_AVX_3 - Failed
-- Performing Test C_HAS_AVX2_1
-- Performing Test C_HAS_AVX2_1 - Failed
-- Performing Test C_HAS_AVX2_2
-- Performing Test C_HAS_AVX2_2 - Failed
-- Performing Test C_HAS_AVX2_3
-- Performing Test C_HAS_AVX2_3 - Failed
-- Performing Test CXX_HAS_SSE1_1
-- Performing Test CXX_HAS_SSE1_1 - Failed
-- Performing Test CXX_HAS_SSE1_2
-- Performing Test CXX_HAS_SSE1_2 - Failed
-- Performing Test CXX_HAS_SSE1_3
-- Performing Test CXX_HAS_SSE1_3 - Failed
-- Performing Test CXX_HAS_SSE2_1
-- Performing Test CXX_HAS_SSE2_1 - Failed
-- Performing Test CXX_HAS_SSE2_2
-- Performing Test CXX_HAS_SSE2_2 - Failed
-- Performing Test CXX_HAS_SSE2_3
-- Performing Test CXX_HAS_SSE2_3 - Failed
-- Performing Test CXX_HAS_SSE3_1
-- Performing Test CXX_HAS_SSE3_1 - Failed
-- Performing Test CXX_HAS_SSE3_2
-- Performing Test CXX_HAS_SSE3_2 - Failed
-- Performing Test CXX_HAS_SSE3_3
-- Performing Test CXX_HAS_SSE3_3 - Failed
-- Performing Test CXX_HAS_SSE4_1_1
-- Performing Test CXX_HAS_SSE4_1_1 - Failed
-- Performing Test CXX_HAS_SSE4_1_2
-- Performing Test CXX_HAS_SSE4_1_2 - Failed
-- Performing Test CXX_HAS_SSE4_1_3
-- Performing Test CXX_HAS_SSE4_1_3 - Failed
-- Performing Test CXX_HAS_SSE4_1_4
-- Performing Test CXX_HAS_SSE4_1_4 - Failed
-- Performing Test CXX_HAS_SSE4_2_1
-- Performing Test CXX_HAS_SSE4_2_1 - Failed
-- Performing Test CXX_HAS_SSE4_2_2
-- Performing Test CXX_HAS_SSE4_2_2 - Failed
-- Performing Test CXX_HAS_SSE4_2_3
-- Performing Test CXX_HAS_SSE4_2_3 - Failed
-- Performing Test CXX_HAS_SSE4_2_4
-- Performing Test CXX_HAS_SSE4_2_4 - Failed
-- Performing Test CXX_HAS_AVX_1
-- Performing Test CXX_HAS_AVX_1 - Failed
-- Performing Test CXX_HAS_AVX_2
-- Performing Test CXX_HAS_AVX_2 - Failed
-- Performing Test CXX_HAS_AVX_3
-- Performing Test CXX_HAS_AVX_3 - Failed
-- Performing Test CXX_HAS_AVX2_1
-- Performing Test CXX_HAS_AVX2_1 - Failed
-- Performing Test CXX_HAS_AVX2_2
-- Performing Test CXX_HAS_AVX2_2 - Failed
-- Performing Test CXX_HAS_AVX2_3
-- Performing Test CXX_HAS_AVX2_3 - Failed
-- Performing Test HAS_C11_ATOMICS
-- Performing Test HAS_C11_ATOMICS - Failed
-- Performing Test HAS_MSC_ATOMICS
-- Performing Test HAS_MSC_ATOMICS - Failed
-- Performing Test HAS_GCC_ATOMICS
-- Performing Test HAS_GCC_ATOMICS - Success
-- Atomics: using GCC intrinsics
-- Looking for sys/types.h
-- Looking for sys/types.h - found
-- Looking for stdint.h
-- Looking for stdint.h - found
-- Looking for stddef.h
-- Looking for stddef.h - found
-- Check size of void*
-- Check size of void* - done
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_sequential - mkl_core - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_sequential - mkl_core - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_sequential - mkl_core - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_sequential - mkl_core - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_sequential - mkl_core - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_sequential - mkl_core - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_sequential - mkl_core - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_sequential - mkl_core - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_sequential - mkl_core - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_sequential - mkl_core - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_sequential - mkl_core - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_sequential - mkl_core - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - gomp - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - iomp5 - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_gf_lp64 - mkl_gnu_thread - mkl_core - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf_lp64 - mkl_intel_thread - mkl_core - pthread - m - dl]
--   Library mkl_gf_lp64: not found
-- Checking for [mkl_gf - mkl_gnu_thread - mkl_core - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_gf - mkl_intel_thread - mkl_core - pthread - m - dl]
--   Library mkl_gf: not found
-- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel_lp64 - mkl_intel_thread - mkl_core - pthread - m - dl]
--   Library mkl_intel_lp64: not found
-- Checking for [mkl_intel - mkl_gnu_thread - mkl_core - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl_intel - mkl_intel_thread - mkl_core - pthread - m - dl]
--   Library mkl_intel: not found
-- Checking for [mkl - guide - pthread - m]
--   Library mkl: not found
-- MKL library not found
-- Checking for [openblas]
--   Library openblas: /opt/apps/anaconda2/4.4.0.1/lib/libopenblas.so
-- Looking for sgemm_
-- Looking for sgemm_ - found
-- Performing Test BLAS_F2C_DOUBLE_WORKS
-- Performing Test BLAS_F2C_DOUBLE_WORKS - Success
-- Performing Test BLAS_F2C_FLOAT_WORKS
-- Performing Test BLAS_F2C_FLOAT_WORKS - Success
-- Performing Test BLAS_USE_CBLAS_DOT
-- Performing Test BLAS_USE_CBLAS_DOT - Success
-- Found a library with BLAS API (open).
-- Looking for cheev_
-- Looking for cheev_ - found
-- Found a library with LAPACK API (open).
-- Found CUDNN: /usr/include  
-- Found cuDNN: v6.0.21  (include: /usr/include, library: /usr/lib/powerpc64le-linux-gnu/libcudnn.so.6)
-- Could NOT find NNPACK (missing:  NNPACK_INCLUDE_DIR NNPACK_LIBRARY CPUINFO_LIBRARY PTHREADPOOL_LIBRARY) 
-- NNPACK not found. Compiling without NNPACK support
-- Using python found in /home/sathap1/.conda/envs/pytorch/bin/python3
-- Performing Test SUPPORTS_STDCXX11
-- Performing Test SUPPORTS_STDCXX11 - Success
-- Performing Test SUPPORTS_MRTM
-- Performing Test SUPPORTS_MRTM - Failed
-- Performing Test SUPPORTS_FLIFETIME
-- Performing Test SUPPORTS_FLIFETIME - Failed
-- Looking for clock_gettime in rt
-- Looking for clock_gettime in rt - found
-- Looking for mmap
-- Looking for mmap - found
-- Looking for shm_open
-- Looking for shm_open - found
-- Looking for shm_unlink
-- Looking for shm_unlink - found
-- Looking for malloc_usable_size
-- Looking for malloc_usable_size - found
-- Performing Test C_HAS_THREAD
-- Performing Test C_HAS_THREAD - Success
CMake Warning at src/ATen/cpu/cpuinfo/CMakeLists.txt:55 (MESSAGE):
  Target processor architecture "ppc64le" is not supported in cpuinfo.
  cpuinfo will compile, but cpuinfo_initialize() will always fail.


disable contrib because ATEN_NO_CONTRIB is set
-- Configuring done
-- Generating done
-- Build files have been written to: /home/sathap1/Software/pytorch/torch/lib/build/aten
+ make install -j160
Scanning dependencies of target aten_files_are_generated
Scanning dependencies of target cpuinfo
[  1%] Generating ATen/CPUByteStorage.cpp, ATen/CPUByteStorage.h, ATen/CPUByteTensor.cpp, ATen/CPUByteTensor.h, ATen/CPUByteType.cpp, ATen/CPUByteType.h, ATen/CPUCharStorage.cpp, ATen/CPUCharStorage.h, ATen/CPUCharTensor.cpp, ATen/CPUCharTensor.h, ATen/CPUCharType.cpp, ATen/CPUCharType.h, ATen/CPUDoubleStorage.cpp, ATen/CPUDoubleStorage.h, ATen/CPUDoubleTensor.cpp, ATen/CPUDoubleTensor.h, ATen/CPUDoubleType.cpp, ATen/CPUDoubleType.h, ATen/CPUFloatStorage.cpp, ATen/CPUFloatStorage.h, ATen/CPUFloatTensor.cpp, ATen/CPUFloatTensor.h, ATen/CPUFloatType.cpp, ATen/CPUFloatType.h, ATen/CPUGenerator.h, ATen/CPUHalfStorage.cpp, ATen/CPUHalfStorage.h, ATen/CPUHalfTensor.cpp, ATen/CPUHalfTensor.h, ATen/CPUHalfType.cpp, ATen/CPUHalfType.h, ATen/CPUIntStorage.cpp, ATen/CPUIntStorage.h, ATen/CPUIntTensor.cpp, ATen/CPUIntTensor.h, ATen/CPUIntType.cpp, ATen/CPUIntType.h, ATen/CPULongStorage.cpp, ATen/CPULongStorage.h, ATen/CPULongTensor.cpp, ATen/CPULongTensor.h, ATen/CPULongType.cpp, ATen/CPULongType.h, ATen/CPUShortStorage.cpp, ATen/CPUShortStorage.h, ATen/CPUShortTensor.cpp, ATen/CPUShortTensor.h, ATen/CPUShortType.cpp, ATen/CPUShortType.h, ATen/CUDAByteStorage.cpp, ATen/CUDAByteStorage.h, ATen/CUDAByteTensor.cpp, ATen/CUDAByteTensor.h, ATen/CUDAByteType.cpp, ATen/CUDAByteType.h, ATen/CUDACharStorage.cpp, ATen/CUDACharStorage.h, ATen/CUDACharTensor.cpp, ATen/CUDACharTensor.h, ATen/CUDACharType.cpp, ATen/CUDACharType.h, ATen/CUDADoubleStorage.cpp, ATen/CUDADoubleStorage.h, ATen/CUDADoubleTensor.cpp, ATen/CUDADoubleTensor.h, ATen/CUDADoubleType.cpp, ATen/CUDADoubleType.h, ATen/CUDAFloatStorage.cpp, ATen/CUDAFloatStorage.h, ATen/CUDAFloatTensor.cpp, ATen/CUDAFloatTensor.h, ATen/CUDAFloatType.cpp, ATen/CUDAFloatType.h, ATen/CUDAGenerator.h, ATen/CUDAHalfStorage.cpp, ATen/CUDAHalfStorage.h, ATen/CUDAHalfTensor.cpp, ATen/CUDAHalfTensor.h, ATen/CUDAHalfType.cpp, ATen/CUDAHalfType.h, ATen/CUDAIntStorage.cpp, ATen/CUDAIntStorage.h, ATen/CUDAIntTensor.cpp, ATen/CUDAIntTensor.h, ATen/CUDAIntType.cpp, ATen/CUDAIntType.h, ATen/CUDALongStorage.cpp, ATen/CUDALongStorage.h, ATen/CUDALongTensor.cpp, ATen/CUDALongTensor.h, ATen/CUDALongType.cpp, ATen/CUDALongType.h, ATen/CUDAShortStorage.cpp, ATen/CUDAShortStorage.h, ATen/CUDAShortTensor.cpp, ATen/CUDAShortTensor.h, ATen/CUDAShortType.cpp, ATen/CUDAShortType.h, ATen/Copy.cpp, ATen/Declarations.yaml, ATen/Functions.h, ATen/NativeFunctions.h, ATen/SparseCPUByteTensor.cpp, ATen/SparseCPUByteTensor.h, ATen/SparseCPUByteType.cpp, ATen/SparseCPUByteType.h, ATen/SparseCPUCharTensor.cpp, ATen/SparseCPUCharTensor.h, ATen/SparseCPUCharType.cpp, ATen/SparseCPUCharType.h, ATen/SparseCPUDoubleTensor.cpp, ATen/SparseCPUDoubleTensor.h, ATen/SparseCPUDoubleType.cpp, ATen/SparseCPUDoubleType.h, ATen/SparseCPUFloatTensor.cpp, ATen/SparseCPUFloatTensor.h, ATen/SparseCPUFloatType.cpp, ATen/SparseCPUFloatType.h, ATen/SparseCPUIntTensor.cpp, ATen/SparseCPUIntTensor.h, ATen/SparseCPUIntType.cpp, ATen/SparseCPUIntType.h, ATen/SparseCPULongTensor.cpp, ATen/SparseCPULongTensor.h, ATen/SparseCPULongType.cpp, ATen/SparseCPULongType.h, ATen/SparseCPUShortTensor.cpp, ATen/SparseCPUShortTensor.h, ATen/SparseCPUShortType.cpp, ATen/SparseCPUShortType.h, ATen/SparseCUDAByteTensor.cpp, ATen/SparseCUDAByteTensor.h, ATen/SparseCUDAByteType.cpp, ATen/SparseCUDAByteType.h, ATen/SparseCUDACharTensor.cpp, ATen/SparseCUDACharTensor.h, ATen/SparseCUDACharType.cpp, ATen/SparseCUDACharType.h, ATen/SparseCUDADoubleTensor.cpp, ATen/SparseCUDADoubleTensor.h, ATen/SparseCUDADoubleType.cpp, ATen/SparseCUDADoubleType.h, ATen/SparseCUDAFloatTensor.cpp, ATen/SparseCUDAFloatTensor.h, ATen/SparseCUDAFloatType.cpp, ATen/SparseCUDAFloatType.h, ATen/SparseCUDAIntTensor.cpp, ATen/SparseCUDAIntTensor.h, ATen/SparseCUDAIntType.cpp, ATen/SparseCUDAIntType.h, ATen/SparseCUDALongTensor.cpp, ATen/SparseCUDALongTensor.h, ATen/SparseCUDALongType.cpp, ATen/SparseCUDALongType.h, ATen/SparseCUDAShortTensor.cpp, ATen/SparseCUDAShortTensor.h, ATen/SparseCUDAShortType.cpp, ATen/SparseCUDAShortType.h, ATen/Tensor.h, ATen/TensorMethods.h, ATen/Type.cpp, ATen/Type.h
[  1%] Building C object src/ATen/cpu/cpuinfo/CMakeFiles/cpuinfo.dir/src/log.c.o
[  1%] Building C object src/ATen/cpu/cpuinfo/CMakeFiles/cpuinfo.dir/src/api.c.o
[  2%] Building C object src/ATen/cpu/cpuinfo/CMakeFiles/cpuinfo.dir/src/init.c.o
/home/sathap1/Software/pytorch/aten/src/ATen/cpu/cpuinfo/src/log.c: In function 'cpuinfo_log_error':
/home/sathap1/Software/pytorch/aten/src/ATen/cpu/cpuinfo/src/log.c:20:4: warning: implicit declaration of function 'dprintf' [-Wimplicit-function-declaration]
    dprintf(STDERR_FILENO, "Error: ");
    ^
/home/sathap1/Software/pytorch/aten/src/ATen/cpu/cpuinfo/src/log.c:21:4: warning: implicit declaration of function 'vdprintf' [-Wimplicit-function-declaration]
    vdprintf(STDERR_FILENO, format, args);
    ^
Scanning dependencies of target tbb_static
[  2%] Linking C static library libcpuinfo.a
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/recursive_mutex.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/queuing_rw_mutex.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/condition_variable.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/mutex.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/tbb_main.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/pipeline.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/observer_proxy.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/spin_rw_mutex.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/concurrent_queue.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/tbb_misc_ex.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/spin_mutex.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/governor.cpp.o
[  3%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/critical_section.cpp.o
[  7%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/tbb_statistics.cpp.o
[  7%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/market.cpp.o
[  7%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/semaphore.cpp.o
[  7%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/concurrent_hash_map.cpp.o
[  7%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/itt_notify.cpp.o
[  8%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/arena.cpp.o
[  8%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/x86_rtm_rw_mutex.cpp.o
[  8%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/tbb_misc.cpp.o
[  9%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/concurrent_monitor.cpp.o
[  9%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/private_server.cpp.o
[ 10%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/reader_writer_lock.cpp.o
[ 10%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/dynamic_link.cpp.o
[ 10%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/tbb_thread.cpp.o
[ 10%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/task_group_context.cpp.o
[ 10%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/old/concurrent_queue_v2.cpp.o
[ 11%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/cache_aligned_allocator.cpp.o
[ 11%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/queuing_mutex.cpp.o
[ 11%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/rml/client/rml_tbb.cpp.o
[ 11%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/old/task_v2.cpp.o
[ 11%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/old/concurrent_vector_v2.cpp.o
[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/scheduler.cpp.o
[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/concurrent_vector.cpp.o
[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/tbb/task.cpp.o
[ 12%] Building CXX object src/ATen/cpu/tbb/CMakeFiles/tbb_static.dir/tbb_remote/src/old/spin_rw_mutex_v2.cpp.o
[ 12%] Built target cpuinfo
[ 12%] Linking CXX static library libtbb_static.a
[ 12%] Built target tbb_static
[ 12%] Built target aten_files_are_generated
[ 15%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCStorageCopy.cu.o
[ 15%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorCopy.cu.o
[ 15%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathMagma.cu.o
[ 15%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensor.cu.o
[ 18%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorIndex.cu.o
[ 18%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathPairwise.cu.o
[ 19%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorConv.cu.o
[ 20%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMode.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorSort.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathReduceByte.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCBlas.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorScatterGather.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCSleep.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCSortUtils.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathPointwiseShort.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorSortShort.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareTChar.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathBlas.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorTopK.cu.o
[ 23%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathScan.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorSortInt.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorSortChar.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareShort.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathReduceShort.cu.o
[ 33%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_GatedLinearUnit.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareTInt.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareByte.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathReduceChar.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathReduceInt.cu.o
[ 26%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorSortByte.cu.o
[ 38%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_Im2Col.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorSortLong.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMaskedChar.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_Col2Im.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathPointwiseInt.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathPointwiseChar.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMaskedInt.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathPointwiseByte.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathReduceHalf.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathReduceLong.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareFloat.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathPointwiseFloat.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathReduceFloat.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorSortDouble.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMaskedHalf.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMath.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorSortHalf.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCReduceApplyUtils.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorSortFloat.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareLong.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareTHalf.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathPointwiseHalf.cu.o
[ 28%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareTDouble.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_TemporalUpSamplingLinear.cu.o
[ 29%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareDouble.cu.o
[ 29%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathReduceDouble.cu.o
[ 33%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_AbsCriterion.cu.o
[ 33%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_BatchNormalization.cu.o
[ 33%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_IndexLinear.cu.o
[ 33%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMaskedDouble.cu.o
[ 33%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathPointwiseLong.cu.o
[ 38%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_ClassNLLCriterion.cu.o
[ 38%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_Abs.cu.o
[ 38%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_FusedRNNKernel.cu.o
[ 38%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_LogSigmoid.cu.o
[ 38%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_PReLU.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_RReLU.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_DistKLDivCriterion.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorMathReduce.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_MSECriterion.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_MarginCriterion.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_FeatureLPPooling.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SoftMarginCriterion.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_L1Cost.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_LookupTableBag.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_Sigmoid.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialAdaptiveMaxPooling.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_MultiLabelMarginCriterion.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SoftMax.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SoftPlus.cu.o
[ 40%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_LogSoftMax.cu.o
[ 41%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SparseLinear.cu.o
[ 41%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialMaxUnpooling.cu.o
[ 41%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialDilatedConvolution.cu.o
[ 43%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialFullConvolution.cu.o
[ 43%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialDilatedMaxPooling.cu.o
[ 43%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialFullDilatedConvolution.cu.o
[ 43%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialAdaptiveAveragePooling.cu.o
[ 43%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialConvolutionMM.cu.o
[ 43%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialReplicationPadding.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialDepthwiseConvolution.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialConvolutionLocal.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialReflectionPadding.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialGridSamplerBilinear.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialClassNLLCriterion.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricAdaptiveAveragePooling.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_TemporalConvolution.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorRandom.cu.o
[ 46%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_Sqrt.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_TemporalMaxPooling.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialUpSamplingBilinear.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_Threshold.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_Tanh.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricAveragePooling.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_TemporalUpSamplingNearest.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialUpSamplingNearest.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_TemporalRowConvolution.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_TemporalReplicationPadding.cu.o
[ 47%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricConvolution.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricDilatedConvolution.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricFullDilatedConvolution.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricMaxUnpooling.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricUpSamplingTrilinear.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricMaxPooling.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricFractionalMaxPooling.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricReplicationPadding.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricFullConvolution.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCS/ATen_generated_THCSparse.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/native/cuda/ATen_generated_Embedding.cu.o
[ 50%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/native/cuda/ATen_generated_RoiPooling.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/native/cuda/ATen_generated_TensorFactories.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/native/cuda/ATen_generated_SparseMM.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/cuda/ATen_generated_CUDAHalf.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCS/ATen_generated_THCSTensor.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareTShort.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/native/cuda/ATen_generated_Distributions.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCStorage.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMaskedByte.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareInt.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorTypeUtils.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMaskedShort.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareTByte.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareTLong.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareChar.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMaskedLong.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareTFloat.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathCompareHalf.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMaskedFloat.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCHalf.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THC/generated/ATen_generated_THCTensorMathPointwiseDouble.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_BCECriterion.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_HardTanh.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_LeakyReLU.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_ELU.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_LookupTable.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_MultiMarginCriterion.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SmoothL1Criterion.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SoftShrink.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialAveragePooling.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialFractionalMaxPooling.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialSubSampling.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialCrossMapLRN.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_SpatialMaxPooling.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricAdaptiveMaxPooling.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_TemporalReflectionPadding.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_Square.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricGridSamplerBilinear.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricUpSamplingNearest.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/__/THCUNN/ATen_generated_VolumetricDilatedMaxPooling.cu.o
[ 52%] Building NVCC (Device) object src/ATen/CMakeFiles/ATen.dir/cuda/detail/ATen_generated_IndexUtils.cu.o
sh: 1: Cannot fork
CMake Error at ATen_generated_THCTensorConv.cu.o.cmake:207 (message):
  Error generating
  /home/sathap1/Software/pytorch/torch/lib/build/aten/src/ATen/CMakeFiles/ATen.dir/__/THC/./ATen_generated_THCTensorConv.cu.o


src/ATen/CMakeFiles/ATen.dir/build.make:161: recipe for target 'src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorConv.cu.o' failed
make[2]: *** [src/ATen/CMakeFiles/ATen.dir/__/THC/ATen_generated_THCTensorConv.cu.o] Error 1
make[2]: *** Waiting for unfinished jobs....
slurmstepd: error: get_exit_code task 0 died by signal

&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>