<bug id='4107' author='nikostr' open_date='2017-12-11T07:58:39Z' closed_time='2020-10-28T05:03:30Z'>
	<summary>CUDNN_STATUS_NOT_SUPPORTED for large matrix input</summary>
	<description>
The following code (adapted from &lt;denchmark-link:https://discuss.pytorch.org/t/cudnn-status-not-supported-error-occurs-when-apply-autograd-grad-to-compute-high-order-differentiation/8256&gt;https://discuss.pytorch.org/t/cudnn-status-not-supported-error-occurs-when-apply-autograd-grad-to-compute-high-order-differentiation/8256&lt;/denchmark-link&gt;
) gives me a CUDNN_STATUS_NOT_SUPPORTED error. I'm running the pytorch 0.3.0 with cuDNN 7.0.4,  CUDA 9.0.176, and python 3.6.
&lt;denchmark-code&gt;from torch.autograd import Variable, grad
import torch.utils.data as Data

class TestDataset(Data.Dataset):

    def __init__(self):
        self.sequences = []
        PROBLEM_SIZE = 171 * 21
        data = torch.rand(1,PROBLEM_SIZE,PROBLEM_SIZE)
        label = torch.rand(PROBLEM_SIZE,PROBLEM_SIZE).round()
        self.sequences.append((data,label))

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self,idx):
        return self.sequences[idx]

train_data = TestDataset()

train_loader = Data.DataLoader(
    dataset=train_data, batch_size=1, shuffle=True, num_workers=1)


class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 1, kernel_size=3, stride=1, dilation=1, padding=1,bias=False)
        self.conv2 = nn.Conv2d(1, 1, kernel_size=3, stride=1, dilation=2, padding=2,bias=False)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x


cnn = CNN()
cnn.cuda()

loss_func = nn.BCEWithLogitsLoss()

for step, (data, label) in enumerate(train_loader):
    input = Variable(data).cuda()
    target = Variable(label).cuda()

    output = cnn(input)[0]
    loss = loss_func(output, target)

    params = cnn.parameters()
    g = grad(loss, params, create_graph=True)

    g_sum = 0
    for g_para in g:
        g_sum += g_para.sum()

    params = cnn.parameters()
    hv = grad(g_sum, params, create_graph=True)

    break
&lt;/denchmark-code&gt;

Running the convolutions individually works, as does running this code for smaller input matrices. I'm pretty sure the problem also occurs for sizes other than 3591 by 3591. The error I receive is the following:
&lt;denchmark-code&gt;  File "/home/n/nikostr/pfs/CompBio-DD2402/experiments/20171209/mwe.py", line 54, in &lt;module&gt;
    g = grad(loss, params, create_graph=True)
  File "/home/n/nikostr/pfs/.conda/envs/myroot/lib/python3.6/site-packages/torch/autograd/__init__.py", line 158, in grad
    inputs, only_inputs, allow_unused)
RuntimeError: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.
&lt;/denchmark-code&gt;

I posted this as a question on the forums (&lt;denchmark-link:https://discuss.pytorch.org/t/cudnn-status-not-supported-for-large-matrix-input/10986&gt;https://discuss.pytorch.org/t/cudnn-status-not-supported-for-large-matrix-input/10986&lt;/denchmark-link&gt;
), and it has been reproduced.
cc &lt;denchmark-link:https://github.com/ezyang&gt;@ezyang&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gchanan&gt;@gchanan&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/zou3519&gt;@zou3519&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/bdhirsh&gt;@bdhirsh&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/heitorschueroff&gt;@heitorschueroff&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/csarofeen&gt;@csarofeen&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ptrblck&gt;@ptrblck&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='nikostr' date='2017-12-12T00:41:01Z'>
		I reproduced this with:
&lt;denchmark-code&gt;import torch
import torch.nn as nn
from torch.autograd import Variable, grad

SIZE=[1, 1, 171*21, 171*21]
input = Variable(torch.cuda.FloatTensor(*SIZE).uniform_(), requires_grad=True)
conv1 = nn.Conv2d(1, 1, kernel_size=3, stride=1, dilation=1, padding=1,bias=False).cuda()
output = conv1(input)
loss = output.sum()
loss.backward()
&lt;/denchmark-code&gt;

I've confirmed it is a cuDNN bug. I've forwarded it to the cuDNN team and they will fix it as soon as possible given their development, testing and release cycle timelines.
		</comment>
		<comment id='2' author='nikostr' date='2017-12-19T18:23:06Z'>
		I met the similar problem, is it solved?
		</comment>
		<comment id='3' author='nikostr' date='2017-12-19T18:54:53Z'>
		for now, you can try disabling cudnn
torch.backends.cudnn.enabled = False. Don't know what kind of performance you'll get, but better than erroring out.
		</comment>
		<comment id='4' author='nikostr' date='2017-12-19T19:24:01Z'>
		Thanks, I tried that and my program has been runnable, but 10 times slower than the original.
		</comment>
		<comment id='5' author='nikostr' date='2017-12-19T19:25:07Z'>
		Can you please show minimum example that generates the error?
		</comment>
		<comment id='6' author='nikostr' date='2017-12-19T19:34:44Z'>
		&lt;denchmark-link:https://github.com/hkharryking&gt;@hkharryking&lt;/denchmark-link&gt;
 as of cuDNN 7.0.5 there was no mention in the release notes of this being resolved. I had a look at this a couple of days ago, but I haven't actually attempted to upgrade and run with the latest version.
		</comment>
		<comment id='7' author='nikostr' date='2017-12-19T19:35:54Z'>
		&lt;denchmark-link:https://github.com/nikostr&gt;@nikostr&lt;/denchmark-link&gt;
 your case is not fixed.
		</comment>
		<comment id='8' author='nikostr' date='2017-12-20T01:27:36Z'>
		Thank you all for the answers, I can reconstruct my problem by the following code.
my cudnn version is 7003
import torch
from torch.autograd import Variable
import torch.nn as nn
x = Variable(torch.rand(100000, 16,200).contiguous()).cuda()
bn = nn.BatchNorm1d(16)
bn.eval()      # add the eval() leads to the error, if it is commented, the programs will be ok.
bn.cuda()
x = bn(x)
print(x.size())
		</comment>
		<comment id='9' author='nikostr' date='2018-01-02T16:51:51Z'>
		&lt;denchmark-link:https://github.com/ngimel&gt;@ngimel&lt;/denchmark-link&gt;
 any idea when this might get resolved? :)
		</comment>
		<comment id='10' author='nikostr' date='2018-04-10T18:24:38Z'>
		To complement this thread, yet another case where CUDNN fails on backward with CUDNN_STATUS_NOT_SUPPORTED.:
m = nn.Conv2d(1, 1, (3, 1), stride=(2, 1)).cuda()
i = torch.rand(131072, 1, 1537, 1).cuda()
o = m(i)
o.sum().backward()
I'm using CUDNN v7.0 with cuda 9.0.
		</comment>
		<comment id='11' author='nikostr' date='2018-05-09T23:25:01Z'>
		any update?
my dirty solution is to add a dummy channel:
&lt;denchmark-code&gt;m = nn.Conv2d(2, 2, (3, 1), stride=(2, 1), groups=2).cuda()
i = torch.rand(131072, 1, 1537, 1).cuda()
o = m(i.repeat(1,2,1,1))[:,:1,:,:]
&lt;/denchmark-code&gt;

this run much faster than torch.backends.cudnn.enabled = False
		</comment>
		<comment id='12' author='nikostr' date='2018-05-10T21:34:11Z'>
		&lt;denchmark-link:https://github.com/Jiaming-Liu&gt;@Jiaming-Liu&lt;/denchmark-link&gt;
 can you elaborate your dummy channel approach? How and why it works? I am also struggling with the error being discussed here.
		</comment>
		<comment id='13' author='nikostr' date='2018-05-10T22:26:29Z'>
		You can also try running with torch.backends.cudnn.benchmark=True
		</comment>
		<comment id='14' author='nikostr' date='2018-05-10T22:36:37Z'>
		&lt;denchmark-link:https://github.com/ngimel&gt;@ngimel&lt;/denchmark-link&gt;
 already tried but didn't solve the issue.
		</comment>
		<comment id='15' author='nikostr' date='2018-05-11T00:34:32Z'>
		&lt;denchmark-link:https://github.com/wasiahmad&gt;@wasiahmad&lt;/denchmark-link&gt;
 I found this trick when using  with 1-channel in &amp; 1-channel out.
CUDNN's Conv2dTranspose (which is basically the backward of Conv2d) seems to hate 1-channel input/output. So just add some dummy input&amp;output channels.
Tiny tricks:
groups=2 would use depthwise conv, which should minimize the extra cost that u need, and make sure that the 1st out-channel is not related to the 2nd in-channel at all.
[:,:1,:,:] slicing would keep the dimension while [:,0,:,:] won't.
To talk about repeat, I guess it is faster than concating a new zero or un-initialized tensor. But I haven't tested it.
		</comment>
		<comment id='16' author='nikostr' date='2018-07-16T19:54:13Z'>
		Do we know whether this is isolated to convolutional layers?  Or any other specifics on when we should expect to see this issue surface? &lt;denchmark-link:https://github.com/ngimel&gt;@ngimel&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='nikostr' date='2018-08-30T15:56:41Z'>
		Yeah, if someone can work out exactly what situations this occurs, we can modify our kernel selection logic to not use cuDNN when parameters satisfy the problem.
		</comment>
		<comment id='18' author='nikostr' date='2019-02-07T04:23:21Z'>
		Still get the same error. When I use the model for testing, if I set batch size to be 1000, I get this error. However, if I set batch size to be 200, it works well.
		</comment>
		<comment id='19' author='nikostr' date='2019-05-30T07:16:39Z'>
		
I reproduced this with:
import torch
import torch.nn as nn
from torch.autograd import Variable, grad

SIZE=[1, 1, 171*21, 171*21]
input = Variable(torch.cuda.FloatTensor(*SIZE).uniform_(), requires_grad=True)
conv1 = nn.Conv2d(1, 1, kernel_size=3, stride=1, dilation=1, padding=1,bias=False).cuda()
output = conv1(input)
loss = output.sum()
loss.backward()

I've confirmed it is a cuDNN bug. I've forwarded it to the cuDNN team and they will fix it as soon as possible given their development, testing and release cycle timelines.

&lt;denchmark-link:https://github.com/csarofeen&gt;@csarofeen&lt;/denchmark-link&gt;
 Hi, I meet a similar problem if I set the batch_size to be bigger than 65535 in calling a batch normalization layer with mxnet. Have you fixed this problem? Will it help to update the version of cudnn?
		</comment>
		<comment id='20' author='nikostr' date='2019-07-08T12:43:12Z'>
		I am running into a similar problem. Does anyone know what causes this by now, or is there a workaround for this problem?
		</comment>
		<comment id='21' author='nikostr' date='2019-07-09T18:31:01Z'>
		&lt;denchmark-link:https://github.com/richard-vogl&gt;@richard-vogl&lt;/denchmark-link&gt;
 try this:

any update?
my dirty solution is to add a dummy channel:
m = nn.Conv2d(2, 2, (3, 1), stride=(2, 1), groups=2).cuda()
i = torch.rand(131072, 1, 1537, 1).cuda()
o = m(i.repeat(1,2,1,1))[:,:1,:,:]

this run much faster than torch.backends.cudnn.enabled = False

		</comment>
		<comment id='22' author='nikostr' date='2019-07-17T15:41:49Z'>
		&lt;denchmark-link:https://github.com/Jiaming-Liu&gt;@Jiaming-Liu&lt;/denchmark-link&gt;


@richard-vogl try this:

any update?
my dirty solution is to add a dummy channel:
m = nn.Conv2d(2, 2, (3, 1), stride=(2, 1), groups=2).cuda()
i = torch.rand(131072, 1, 1537, 1).cuda()
o = m(i.repeat(1,2,1,1))[:,:1,:,:]

this run much faster than torch.backends.cudnn.enabled = False


Thanks for the response! In my case I already use several channels, I also tried to expand the singular batch dimension, but it doesn't really change anything.
Here my minimal code example to reproduce the problem:
&lt;denchmark-code&gt;import torch
x = torch.rand(1, 16, 70000, 100).to('cuda:2')
conv = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), bias=False).to('cuda:2')
out = conv(x)
&lt;/denchmark-code&gt;

Since I have a stack of convolutions where i increase the channel size, and the problem occurs here, it feels like this is a problem linked to memory requirements - note that the total size of matrices exceeds 1GB with this convolution...
Edit: I just did more experimenting, and it doesn't seem to be related to memory requirements. Interestingly it works if I square the input up a bit:
&lt;denchmark-code&gt;import torch
x = torch.rand(1, 16, 7000, 7000).to('cuda:2')
conv = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), bias=False).to('cuda:2')
out = conv(x)
&lt;/denchmark-code&gt;

This works, although the total memory requirement is even larger, but the last two dimensions are equal.
Since the original error mentions contiguousness of a variable, maybe this really has to do with the shape of the matrices and how they are organized in memory, from a certain size? Do you have any optimizations regarding this in pytorch, which could mess with the cuda stuff??
		</comment>
		<comment id='23' author='nikostr' date='2019-07-18T12:06:40Z'>
		Hi &lt;denchmark-link:https://github.com/richard-vogl&gt;@richard-vogl&lt;/denchmark-link&gt;
,
I couldn't reproduce the issue using your code snippet.
Could you post some information about your system (which GPU) and the PyTorch, CUDA, cudnn versions?
		</comment>
		<comment id='24' author='nikostr' date='2019-07-18T12:14:43Z'>
		
Hi @richard-vogl,
I couldn't reproduce the issue using your code snippet.
Could you post some information about your system (which GPU) and the PyTorch, CUDA, cudnn versions?

Hi,
GPU:
GeForce GTX 1080 Ti (rev a1)
pytorch:
&lt;denchmark-code&gt;&gt; pip show torch
Name: torch
Version: 1.1.0
Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration
Home-page: UNKNOWN
Author: UNKNOWN
Author-email: UNKNOWN
License: UNKNOWN
Location: /home/rvogl/.local/lib/python3.6/site-packages
Requires: numpy
Required-by: torchvision
&lt;/denchmark-code&gt;

CUDA:
NVIDIA-SMI 430.26       Driver Version: 430.26       CUDA Version: 10.2
cudnn:
&lt;denchmark-code&gt;torch.backends.cudnn.version()
7501
&lt;/denchmark-code&gt;

		</comment>
		<comment id='25' author='nikostr' date='2019-09-03T09:13:14Z'>
		
Could it be related to lack of remaining memory on GPU device?

definitely not lack of memory since there is more than enough memory available on the cards I used.
but I originally thought that it is somehow related to matrix size, see &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/4107#issuecomment-512336351&gt;#4107 (comment)&lt;/denchmark-link&gt;

but as you can also see from the update/edit - it seems to be related more to the shape of the tensor than its size...
if someone wants to debug this and is unable to reproduce it: I might be able to setup an account on one of the machines where i can reproduce this - if it helps.
		</comment>
		<comment id='26' author='nikostr' date='2019-10-21T22:47:05Z'>
		&lt;denchmark-link:https://github.com/ptrblck&gt;@ptrblck&lt;/denchmark-link&gt;
 I can reproduce this  on  on a Collab notebook (&lt;denchmark-link:https://accounts.google.com/signin/v2/identifier?continue=https%3A%2F%2Fcolab.research.google.com%2Fdrive%2F1MMukaj-kfLAdvVWxI4ccsR07gaA90PFe&amp;authuser=0&amp;hl=en&amp;flowName=GlifWebSignIn&amp;flowEntry=ServiceLogin&gt;https://accounts.google.com/signin/v2/identifier?continue=https%3A%2F%2Fcolab.research.google.com%2Fdrive%2F1MMukaj-kfLAdvVWxI4ccsR07gaA90PFe&amp;authuser=0&amp;hl=en&amp;flowName=GlifWebSignIn&amp;flowEntry=ServiceLogin&lt;/denchmark-link&gt;
)
It seems BatchNorm1d / cuDNN has a upper limit batch size of 2 ** 16.
torch.__version__  # -&gt; '1.3.0+cu100'
x = torch.rand((2 ** 16, 64, 60)).cuda().float()  # this will lead to an error in bn.forward
x = torch.rand((2 ** 16 - 1, 64, 60)).cuda().float()  # no errors for bn.forward
bn = nn.BatchNorm1d(64).eval().cuda()
x = bn.forward(x)
print(x.shape)
&lt;denchmark-code&gt;&gt; nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;&gt; nvidia-smi
NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1 
&lt;/denchmark-code&gt;

This large amount of batch_size is required in my use case due to batched sparse pointcloud input.
Hope this information helps! Are there workarounds you can recommend for now? (except disabling CuDNN)
		</comment>
		<comment id='27' author='nikostr' date='2019-11-08T15:42:59Z'>
		Hi &lt;denchmark-link:https://github.com/felixlaumon&gt;@felixlaumon&lt;/denchmark-link&gt;
,
I am also play with sparse point cloud and meet the same problem. When I disable torch.backends.cudnn during eval phase, the code is runable, but the BN in eval() model acts very strange, especially when working with syncBN. Have you meet something like this?
Thanks very much
		</comment>
		<comment id='28' author='nikostr' date='2019-11-14T04:13:26Z'>
		&lt;denchmark-link:https://github.com/wbhu&gt;@wbhu&lt;/denchmark-link&gt;
 as a workaround you might want to try the non-CuDNN version of batch norm and wraps it as a layer. It's definitely faster than disabling CuDNN in its entirety. Below is an example for non-CuDNN BN in 1D
def no_cudnn_batch_norm(
    input,
    running_mean,
    running_var,
    weight=None,
    bias=None,
    training=False,
    momentum=0.1,
    eps=1e-5,
):
    """F.batch_norm with cuDNN disable"""
    if training:
        size = input.size()
        size_prods = size[0]
        for i in range(len(size) - 2):
            size_prods *= size[i + 2]
        if size_prods == 1:
            raise ValueError(
                "Expected more than 1 value per channel when training, got input size {}".format(
                    size
                )
            )

    return torch.batch_norm(
        input, weight, bias, running_mean, running_var, training, momentum, eps, False
    )


class BatchNorm1dNoCuDNN(nn.modules.batchnorm.BatchNorm1d):
    """BatchNorm1d with CuDNN disabled"""

    def forward(self, input):
        # All of below is copy and pasted. Just replaced F.batch_norm with
        # no_cudnn_batch_norm
        self._check_input_dim(input)
        if self.momentum is None:
            exponential_average_factor = 0.0
        else:
            exponential_average_factor = self.momentum

        if self.training and self.track_running_stats:
            # TODO: if statement only here to tell the jit to skip emitting this when it is None
            if self.num_batches_tracked is not None:
                self.num_batches_tracked += 1
                if self.momentum is None:  # use cumulative moving average
                    exponential_average_factor = 1.0 / float(self.num_batches_tracked)
                else:  # use exponential moving average
                    exponential_average_factor = self.momentum

        return no_cudnn_batch_norm(
            input,
            self.running_mean,
            self.running_var,
            self.weight,
            self.bias,
            self.training or not self.track_running_stats,
            exponential_average_factor,
            self.eps,
        )
		</comment>
		<comment id='29' author='nikostr' date='2019-11-26T07:04:54Z'>
		This is modified code from &lt;denchmark-link:https://github.com/hkharryking&gt;@hkharryking&lt;/denchmark-link&gt;
 .
import torch
from torch.autograd import Variable
import torch.nn as nn

x = torch.rand(65535, 16,200).contiguous().cuda()
bn = nn.BatchNorm1d(16)
bn.eval() # add the eval() leads to the error, if it is commented, the programs will be ok.
bn.cuda()

x = bn(x)
print(x.size())
Output:
torch.Size([65535, 16, 200])
If I increase batch size by 1.
import torch
from torch.autograd import Variable
import torch.nn as nn

x = torch.rand(65536, 16,200).contiguous().cuda()
bn = nn.BatchNorm1d(16)
bn.eval() # add the eval() leads to the error, if it is commented, the programs will be ok.
bn.cuda()

x = bn(x)
print(x.size())
Output:
&lt;denchmark-code&gt;~\.conda\envs\pytorcharcgis\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--&gt; 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

~\.conda\envs\pytorcharcgis\lib\site-packages\torch\nn\modules\batchnorm.py in forward(self, input)
     81             input, self.running_mean, self.running_var, self.weight, self.bias,
     82             self.training or not self.track_running_stats,
---&gt; 83             exponential_average_factor, self.eps)
     84 
     85     def extra_repr(self):

~\.conda\envs\pytorcharcgis\lib\site-packages\torch\nn\functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)
   1695     return torch.batch_norm(
   1696         input, weight, bias, running_mean, running_var,
-&gt; 1697         training, momentum, eps, torch.backends.cudnn.enabled
   1698     )
   1699 

RuntimeError: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.
&lt;/denchmark-code&gt;

Pytorch = 1.1.0
cuda=10.0
cudnn=7401
GPU = Quadro RTX 8000
Same issue is occuring in the latest pytorch.
&lt;denchmark-link:https://user-images.githubusercontent.com/16683472/69606966-37528280-104a-11ea-895d-7eaf4969a172.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='30' author='nikostr' date='2019-11-26T16:09:31Z'>
		Please let's track batchnorm related issues in &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/29744&gt;#29744&lt;/denchmark-link&gt;
, original issue here was for convolution.
		</comment>
		<comment id='31' author='nikostr' date='2019-12-08T23:36:54Z'>
		Just ran into this error while trying to train EfficientNet with batch size 512 on a single GPU.
To reproduce, clone &lt;denchmark-link:https://github.com/rwightman/pytorch-image-models&gt;https://github.com/rwightman/pytorch-image-models&lt;/denchmark-link&gt;
 repo and run this command:

On a single V100 it produces the following error right after it finishes the first epoch of training, either immediately before or during validation stage:
&lt;denchmark-code&gt;Training with a single process on 1 GPUs.
Model efficientnet_b0 created, param count: 5288548
Data processing configuration for current model + dataset:
        input_size: (3, 224, 224)
        interpolation: bicubic
        mean: (0.485, 0.456, 0.406)
        std: (0.229, 0.224, 0.225)
        crop_pct: 0.875
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
NVIDIA APEX installed. AMP on.
Scheduled epochs: 450
Train: 0 [   0/2502 (  0%)]  Loss:  6.952626 (6.9526)  Time: 21.453s,   23.87/s  (21.453s,   23.87/s)  LR: 1.000e-06  Data: 11.892 (11.892)
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Train: 0 [1000/2502 ( 40%)]  Loss:  6.941184 (6.9479)  Time: 0.653s,  783.90/s  (0.870s,  588.41/s)  LR: 1.000e-06  Data: 0.074 (0.277)
Train: 0 [2000/2502 ( 80%)]  Loss:  6.913240 (6.9434)  Time: 0.647s,  791.28/s  (0.826s,  620.06/s)  LR: 1.000e-06  Data: 0.068 (0.239)
/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:804: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0.
  warnings.warn(str(msg))
Train: 0 [2501/2502 (100%)]  Loss:  6.935285 (6.9416)  Time: 0.771s,  663.77/s  (0.828s,  618.38/s)  LR: 1.000e-06  Data: 0.193 (0.242)
Traceback (most recent call last):
  File "train.py", line 581, in &lt;module&gt;
    main()
  File "train.py", line 391, in main
    eval_metrics = validate(model, loader_eval, validate_loss_fn, args)
  File "train.py", line 535, in validate
    output = model(input)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/mklachko/pytorch-image-models/timm/models/efficientnet.py", line 276, in forward
    x = self.forward_features(x)
  File "/home/mklachko/pytorch-image-models/timm/models/efficientnet.py", line 269, in forward_features
    x = self.blocks(x)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/mklachko/pytorch-image-models/timm/models/efficientnet_blocks.py", line 262, in forward
    x = self.conv_pw(x)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 345, in forward
    return self.conv2d_forward(input, self.weight)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 342, in conv2d_forward
    self.padding, self.dilation, self.groups)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/apex/amp/wrap.py", line 28, in wrapper
    return orig_fn(*new_args, **kwargs)
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.
Traceback (most recent call last):
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/distributed/launch.py", line 253, in &lt;module&gt;
    main()
  File "/home/mklachko/miniconda2/envs/pt/lib/python3.7/site-packages/torch/distributed/launch.py", line 249, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/mklachko/miniconda2/envs/pt/bin/python', '-u', 'train.py', '--local_rank=0', '/scratch/mklachko/data/imagenet/', '--model', 'efficientnet_b0', '-b', '512', '--sched', 'step', '--epochs', '450', '--decay-epochs', '2.4', '--decay-rate', '.97', '--opt', 'rmsproptf', '--opt-eps', '.001', '-j', '8', '--warmup-lr', '1e-6', '--weight-decay', '1e-5', '--drop', '0.2', '--drop-connect', '0.2', '--model-ema', '--model-ema-decay', '0.9999', '--aa', 'rand-m9-mstd0.5', '--remode', 'pixel', '--reprob', '0.2', '--amp', '--lr', '.032', '--output', 'output_B0', '--log-interval', '1000', '-j', '8']' returned non-zero exit status 1.
&lt;/denchmark-code&gt;

Same code when used on 4 Titan Xp cards using batch size 128 runs fine.
Pytorch 1.3.1
NVIDIA Driver Version: 418.67
CUDA Version: 10.1
torch.backends.cudnn.version(): 7603
		</comment>
		<comment id='32' author='nikostr' date='2019-12-16T17:41:26Z'>
		I'm closing this issue, dumping all CUDNN_STATUS_NOT_SUPPORTED errors here it not helpful. When encountering this error, please open new issue (unless you are sure that your case is related to the existing), and also try to make your bug report more actionable by isolating the call that causes an error. Try running with CUDA_LAUNCH_BLOCKING=1 and enable cudnn logginghttp://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#api-logging
		</comment>
		<comment id='33' author='nikostr' date='2019-12-16T18:11:58Z'>
		Has this issue been fixed?  I'm talking about CUDNN error that happens for convolution with large matrix sizes - as is clearly shown in my error message. If so, what is the build I should test it with?
		</comment>
		<comment id='34' author='nikostr' date='2019-12-16T19:24:35Z'>
		&lt;denchmark-link:https://github.com/michaelklachko&gt;@michaelklachko&lt;/denchmark-link&gt;
 Your issue might be related to the size limitations for cudnn convs as tracked in &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/22496&gt;this issue&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://github.com/zasdfgbnm&gt;@zasdfgbnm&lt;/denchmark-link&gt;
 is working on a fix.
Let me know, if you think it's unrelated to your issue.
		</comment>
		<comment id='35' author='nikostr' date='2019-12-16T19:56:29Z'>
		Maybe: 512x224x224x128 &gt; 2**32. It’s a pretty standard input size though, so I’m not sure why this isn’t a more widespread problem.
		</comment>
		<comment id='36' author='nikostr' date='2019-12-16T19:59:24Z'>
		That would fail in training though, not after the first epoch. Or do you use large batch size of eval only? It would be helpful if you isolated the failing call with the help of cudnn logging.
		</comment>
		<comment id='37' author='nikostr' date='2019-12-16T20:19:09Z'>
		Good point. It should be pretty easy for whoever is working on this issue to reproduce it by cloning the repo, and running the command on a V100 card. I'm not really familiar with cudnn debugging. Unless it's really simple, in that case please provide the detailed steps of what I need to do.
		</comment>
		<comment id='38' author='nikostr' date='2019-12-16T21:38:31Z'>
		
I'm closing this issue, dumping all CUDNN_STATUS_NOT_SUPPORTED errors here it not helpful. When encountering this error, please open new issue (unless you are sure that your case is related to the existing), and also try to make your bug report more actionable by isolating the call that causes an error. Try running with CUDA_LAUNCH_BLOCKING=1 and enable cudnn logginghttp://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#api-logging

OK so should I open a new issue? I provided an isolated minimal snipped in a comment above:
&lt;denchmark-code&gt;import torch
x = torch.rand(1, 16, 70000, 100).to('cuda:0')
conv = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), bias=False).to('cuda:0')
out = conv(x)
&lt;/denchmark-code&gt;

i can even reproduce the issue using a google colab notebook:
&lt;denchmark-link:https://colab.research.google.com/drive/1szd95jnY0rkcblIq8n9Zo0BpsWdFhrf3&gt;https://colab.research.google.com/drive/1szd95jnY0rkcblIq8n9Zo0BpsWdFhrf3&lt;/denchmark-link&gt;

So it is hard to imagine that the issue cannot be reproduced.
I also offered to create an account on a machine where the issue can be reproduced for debugging purposes...
		</comment>
		<comment id='39' author='nikostr' date='2019-12-16T21:47:04Z'>
		Please file a new issue, tag &lt;denchmark-link:https://github.com/ptrblck&gt;@ptrblck&lt;/denchmark-link&gt;
 on it.
		</comment>
		<comment id='40' author='nikostr' date='2020-06-28T04:55:08Z'>
		I downgraded to torch version 1.1.0 and my error went away "pip install torch==1.1.0"
		</comment>
		<comment id='41' author='nikostr' date='2020-10-27T07:22:01Z'>
		I resolve it by adding contiguous() after permute(). This is NOT only a cuddn issue. See &lt;denchmark-link:https://www.gitmemory.com/issue/pytorch/pytorch/32395/577134996&gt;https://www.gitmemory.com/issue/pytorch/pytorch/32395/577134996&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='42' author='nikostr' date='2020-10-28T00:59:37Z'>
		&lt;denchmark-link:https://github.com/sjtuytc&gt;@sjtuytc&lt;/denchmark-link&gt;
 could you post a code snippet to reproduce this issue?
The linked code snippet runs fine on  and doesn't produce the error.
Also, all other provided code snippets work in this version.
&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/4107#issuecomment-350906473&gt;#4107 (comment)&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/4107#issuecomment-352937808&gt;#4107 (comment)&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/4107#issuecomment-380200677&gt;#4107 (comment)&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/4107#issuecomment-544739942&gt;#4107 (comment)&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/4107#issuecomment-558491584&gt;#4107 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='43' author='nikostr' date='2020-10-28T01:02:14Z'>
		I'm using 1.3.0 because I only have cuda 10.0.
		</comment>
		<comment id='44' author='nikostr' date='2020-10-28T01:05:29Z'>
		&lt;denchmark-link:https://github.com/sjtuytc&gt;@sjtuytc&lt;/denchmark-link&gt;
 The latest stable release binaries () ship with CUDA9.2, 10.1, 10.2, and 11.0.
You can find the install instructions &lt;denchmark-link:https://pytorch.org/get-started/locally/&gt;here&lt;/denchmark-link&gt;
.
Also note, that you would only need to install the appropriate NVIDIA driver, if you want to run native PyTorch workloads.
A local CUDA installation is necessary, if you want to build from source or use custom CUDA extensions, which have to be compiled.
		</comment>
		<comment id='45' author='nikostr' date='2020-10-28T05:03:30Z'>
		Closing based on &lt;denchmark-link:https://github.com/ptrblck&gt;@ptrblck&lt;/denchmark-link&gt;
 comment. Please don't reopen, if you have new repros on the latest builds, please open new issues.
		</comment>
	</comments>
</bug>