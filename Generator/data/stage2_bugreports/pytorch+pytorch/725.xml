<bug id='725' author='apaszke' open_date='2017-02-12T16:05:18Z' closed_time='2017-02-21T14:20:55Z'>
	<summary>LogSoftmax can be numerically unstable on CUDA</summary>
	<description>
It sometimes gives -infs.
	</description>
	<comments>
		<comment id='1' author='apaszke' date='2017-04-09T14:38:21Z'>
		&lt;denchmark-link:https://github.com/apaszke&gt;@apaszke&lt;/denchmark-link&gt;
 - Was this solved? I'm still having increasing losses when using it with Adam.
		</comment>
		<comment id='2' author='apaszke' date='2017-04-09T14:39:27Z'>
		Yes, it's been solved. If you see infs or nans after LogSoftmax then it might be related, otherwise it's likely a different problem with the training procedure.
		</comment>
	</comments>
</bug>