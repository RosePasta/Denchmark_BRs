<bug id='2917' author='soumith' open_date='2017-09-30T20:10:19Z' closed_time='2017-09-30T23:00:45Z'>
	<summary>CuDNN batchnorm has batch size limit</summary>
	<description>
import torch
import torch.nn as nn
from torch.autograd import Variable

torch.backends.cudnn.enabled=True
x = Variable( torch.rand(140000,1).contiguous()).cuda()

print (torch.backends.cudnn.version())

bn = nn.BatchNorm1d(1)
bn.cuda()

xbn = bn(x)
xbn.size()
This will give CUDNN_STATUS_NOT_SUPPORTED error, as reported here: &lt;denchmark-link:https://discuss.pytorch.org/t/cudnn-status-not-supported-with-large-bach-size-when-using-batchnorm/7014/4&gt;https://discuss.pytorch.org/t/cudnn-status-not-supported-with-large-bach-size-when-using-batchnorm/7014/4&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='soumith' date='2017-09-30T20:36:10Z'>
		The magic number is 131070. Anything above this batch size fails.
		</comment>
	</comments>
</bug>