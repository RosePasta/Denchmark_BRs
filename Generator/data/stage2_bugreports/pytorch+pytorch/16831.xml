<bug id='16831' author='moderatelyfunctional' open_date='2019-02-07T01:10:29Z' closed_time='2019-05-05T14:31:20Z'>
	<summary>cuDNN error: CUDNN_STATUS_INTERNAL_ERROR on cudnn.benchmark = True</summary>
	<description>
Hi, I'm running PyTorch on an encoder/decoder architecture and am having a problem with cuDNN.
If I include
import torch.backends.cudnn as cudnn
cudnn.benchmark = True
in my Python code, then I receive an error for CUDNN_STATUS_INTERNAL_ERROR.
The full stack trace is listed here.
&lt;denchmark-code&gt;    main()
  File "main.py", line 152, in main
    train_model(train_dataloader, val_dataloader)
  File "main.py", line 131, in train_model
    network_output = network(network_input)
  File "/.local/lib/python3.5/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/model.py", line 133, in forward
    x = self.decoder(x)
  File "/.local/lib/python3.5/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "model.py", line 54, in forward
    x = self.layer4(x)
  File "/.local/lib/python3.5/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/.local/lib/python3.5/site-packages/torch/nn/modules/conv.py", line 757, in forward
    output_padding, self.groups, self.dilation)
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
&lt;/denchmark-code&gt;

If I comment out cuDNN, I can run the code without any problems.
My system configurations are listed below.

PyTorch Version: 1.0.1
OS: Ubuntu 16.04
PyTorch 1.0.1 installed from pip3
Python version: 3.5
CUDA/cuDNN version: 10.0/7.402
GPU models and configuration: Nvidia GPU Titan X

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

I've tried rm -rf ~/.nv, rebuilt CUDA/cuDNN and reinstalled PyTorch but still cannot get it to work. Thanks for your help!
	</description>
	<comments>
		<comment id='1' author='moderatelyfunctional' date='2019-02-07T07:27:11Z'>
		can you confirm that v1.0.0 works fine?
		</comment>
		<comment id='2' author='moderatelyfunctional' date='2019-02-08T01:27:55Z'>
		It also fails for v1.0.0. I installed it via pip3.
		</comment>
		<comment id='3' author='moderatelyfunctional' date='2019-02-08T01:37:14Z'>
		in that case, this is pretty weird. It shouldn't be failing on a Titan-X.
I see that you have CUDA10 installed on the system. Can you try installing our CUDA10 wheel? The command is at &lt;denchmark-link:https://pytorch.org&gt;https://pytorch.org&lt;/denchmark-link&gt;
 (use the selector wizard in get started and select pip and cuda10)
		</comment>
		<comment id='4' author='moderatelyfunctional' date='2019-02-08T19:26:34Z'>
		I uploaded new 1.0.1.post2 binaries, can you give those a shot?
		</comment>
		<comment id='5' author='moderatelyfunctional' date='2019-02-15T11:10:08Z'>
		Same problem on current official 1.0.1 when pushing batch size to more than 3 per gpu (on multi gpu context). Works when batch_size/ngpu &lt;= 3. Problem only with Group norm layers
		</comment>
		<comment id='6' author='moderatelyfunctional' date='2019-02-19T14:10:48Z'>
		I'd like to investigate this, any chance you can give me a small code snippet that's failing?
		</comment>
		<comment id='7' author='moderatelyfunctional' date='2019-02-20T14:19:42Z'>
		I have the exact same problem.
It works on pytorch 0.4.1 (cuDNN 7104)
It does not work on pytorch 1.0.1.post2 (current stable release, cuDNN 7402)
It does not work on pytorch 1.0.0.dev20190220 (current nightly, cuDNN 7402)
My model is a very large 3D UNet that takes 224x224x224 shaped inputs. If you want to try it you will need 32GB of VRAM. It will not crash with smaller inputs such as 128x128x128 (which you could fit on your regular 12GB card).
Run this snippet to reprocude:
&lt;denchmark-code&gt;from torch.backends import cudnn
from copy import deepcopy
from torch import nn
import torch
import numpy as np
import torch.nn.functional


class ConvDropoutNormNonlin(nn.Module):
    def __init__(self, input_channels, output_channels,
                 conv_op=nn.Conv2d, conv_kwargs=None,
                 norm_op=nn.BatchNorm2d, norm_op_kwargs=None,
                 dropout_op=nn.Dropout2d, dropout_op_kwargs=None,
                 nonlin=nn.LeakyReLU, nonlin_kwargs=None):
        super(ConvDropoutNormNonlin, self).__init__()
        if nonlin_kwargs is None:
            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}
        if dropout_op_kwargs is None:
            dropout_op_kwargs = {'p': 0.5, 'inplace': True}
        if norm_op_kwargs is None:
            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}
        if conv_kwargs is None:
            conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}

        self.nonlin_kwargs = nonlin_kwargs
        self.nonlin = nonlin
        self.dropout_op = dropout_op
        self.dropout_op_kwargs = dropout_op_kwargs
        self.norm_op_kwargs = norm_op_kwargs
        self.conv_kwargs = conv_kwargs
        self.conv_op = conv_op
        self.norm_op = norm_op

        self.conv = self.conv_op(input_channels, output_channels, **self.conv_kwargs)
        if self.dropout_op is not None and self.dropout_op_kwargs['p'] is not None and self.dropout_op_kwargs[
            'p'] &gt; 0:
            self.dropout = self.dropout_op(**self.dropout_op_kwargs)
        else:
            self.dropout = None
        self.instnorm = self.norm_op(output_channels, **self.norm_op_kwargs)
        self.lrelu = nn.LeakyReLU(**self.nonlin_kwargs)

    def forward(self, x):
        x = self.conv(x)
        if self.dropout is not None:
            x = self.dropout(x)
        return self.lrelu(self.instnorm(x))


class StackedConvLayers(nn.Module):
    def __init__(self, input_feature_channels, output_feature_channels, num_convs,
                 conv_op=nn.Conv2d, conv_kwargs=None,
                 norm_op=nn.BatchNorm2d, norm_op_kwargs=None,
                 dropout_op=nn.Dropout2d, dropout_op_kwargs=None,
                 nonlin=nn.LeakyReLU, nonlin_kwargs=None, first_stride=None):
        self.input_channels = input_feature_channels
        self.output_channels = output_feature_channels

        if nonlin_kwargs is None:
            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}
        if dropout_op_kwargs is None:
            dropout_op_kwargs = {'p': 0.5, 'inplace': True}
        if norm_op_kwargs is None:
            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}
        if conv_kwargs is None:
            conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}

        self.nonlin_kwargs = nonlin_kwargs
        self.nonlin = nonlin
        self.dropout_op = dropout_op
        self.dropout_op_kwargs = dropout_op_kwargs
        self.norm_op_kwargs = norm_op_kwargs
        self.conv_kwargs = conv_kwargs
        self.conv_op = conv_op
        self.norm_op = norm_op

        if first_stride is not None:
            self.conv_kwargs_first_conv = deepcopy(conv_kwargs)
            self.conv_kwargs_first_conv['stride'] = first_stride
        else:
            self.conv_kwargs_first_conv = conv_kwargs

        super(StackedConvLayers, self).__init__()
        self.blocks = nn.Sequential(
            *([ConvDropoutNormNonlin(input_feature_channels, output_feature_channels, self.conv_op,
                                     self.conv_kwargs_first_conv,
                                     self.norm_op, self.norm_op_kwargs, self.dropout_op, self.dropout_op_kwargs,
                                     self.nonlin, self.nonlin_kwargs)] +
              [ConvDropoutNormNonlin(output_feature_channels, output_feature_channels, self.conv_op,
                                     self.conv_kwargs,
                                     self.norm_op, self.norm_op_kwargs, self.dropout_op, self.dropout_op_kwargs,
                                     self.nonlin, self.nonlin_kwargs) for _ in range(num_convs - 1)]))

    def forward(self, x):
        return self.blocks(x)


class Generic_UNet(nn.Module):
    def __init__(self, input_channels, base_num_features, num_classes, num_pool):
        super(Generic_UNet, self).__init__()

        self.nonlin_kwargs = {'negative_slope':1e-2, 'inplace':True}
        self.dropout_op_kwargs = {'p':0.0, 'inplace':True}
        self.norm_op_kwargs = {'eps':1e-5, 'affine':True}
        self.conv_kwargs = {'kernel_size':3,'padding':1, 'stride':1, 'dilation':1, 'bias':True}
        self.nonlin = nn.ReLU
        self.conv_op = nn.Conv3d
        self.norm_op = nn.InstanceNorm3d
        self.dropout_op = nn.Dropout3d
        self.num_classes = num_classes

        transpconv = nn.ConvTranspose3d

        self.conv_blocks_encoder = []
        self.conv_blocks_decoder = []
        self.transpConvs = []

        # encoder
        output_features = base_num_features
        input_features = input_channels
        for d in range(num_pool):
            # determine the first stride
            if d != 0:
                first_stride = 2
            else:
                first_stride = 1

            self.conv_blocks_encoder.append(StackedConvLayers(input_features, output_features, 2,
                                                              self.conv_op, self.conv_kwargs, self.norm_op,
                                                              self.norm_op_kwargs, self.dropout_op,
                                                              self.dropout_op_kwargs, self.nonlin, self.nonlin_kwargs,
                                                              first_stride))
            input_features = output_features
            output_features = int(np.round(output_features * 2))
            output_features = min(output_features, 480) # no more filters, otherwise we explode in num parameters

        # now the bottleneck.
        first_stride = 2
        final_num_features = output_features
        self.conv_blocks_encoder.append(nn.Sequential(
            StackedConvLayers(input_features, output_features, 2 - 1, self.conv_op, self.conv_kwargs,
                              self.norm_op, self.norm_op_kwargs, self.dropout_op, self.dropout_op_kwargs, self.nonlin,
                              self.nonlin_kwargs, first_stride),
            StackedConvLayers(output_features, final_num_features, 1, self.conv_op, self.conv_kwargs,
                              self.norm_op, self.norm_op_kwargs, self.dropout_op, self.dropout_op_kwargs, self.nonlin,
                              self.nonlin_kwargs)))

        # now lets build the decoder pathway
        for u in range(num_pool):
            nfeatures_from_down = final_num_features
            nfeatures_from_skip = self.conv_blocks_encoder[-(2 + u)].output_channels # self.conv_blocks_context[-1] is bottleneck, so start with -2
            n_features_after_tu_and_concat = nfeatures_from_skip * 2

            final_num_features = nfeatures_from_skip

            self.transpConvs.append(transpconv(nfeatures_from_down, nfeatures_from_skip, 2, 2, bias=False))

            self.conv_blocks_decoder.append(nn.Sequential(
                StackedConvLayers(n_features_after_tu_and_concat, nfeatures_from_skip, 2 - 1,
                                  self.conv_op, self.conv_kwargs, self.norm_op, self.norm_op_kwargs, self.dropout_op,
                                  self.dropout_op_kwargs, self.nonlin, self.nonlin_kwargs),
                StackedConvLayers(nfeatures_from_skip, final_num_features, 1, self.conv_op, self.conv_kwargs,
                                  self.norm_op, self.norm_op_kwargs, self.dropout_op, self.dropout_op_kwargs,
                                  self.nonlin, self.nonlin_kwargs)
            ))

        self.seg_output = self.conv_op(base_num_features, num_classes, 1, 1, 0, 1, 1, False)

        # register all modules properly
        self.conv_blocks_decoder = nn.ModuleList(self.conv_blocks_decoder)
        self.conv_blocks_encoder = nn.ModuleList(self.conv_blocks_encoder)
        self.transpConvs = nn.ModuleList(self.transpConvs)

    def forward(self, x):
        skips = []
        for d in range(len(self.conv_blocks_encoder) - 1):
            x = self.conv_blocks_encoder[d](x)
            skips.append(x)

        x = self.conv_blocks_encoder[-1](x)

        for u in range(len(self.transpConvs)):
            x = self.transpConvs[u](x)
            x = torch.cat((x, skips[-(u + 1)]), dim=1)
            x = self.conv_blocks_decoder[u](x)

        seg_output = self.seg_output(x)

        return seg_output


if __name__ == "__main__":
    cudnn.benchmark = True

    net = Generic_UNet(1, 30, 3, 5).cuda()

    a = torch.rand((1, 1, 224, 224, 224)).pin_memory().cuda()

    res = net(a)
    loss = res.sum()

    loss.backward()

&lt;/denchmark-code&gt;

Set cudnn.benchmark = False and this example will run on all pytorch versions.
I hope you can help. This seems to be a tricky one... :-)
Best,
Fabian
Edit: I printed the filter map sizes for your convenience:

encoder 0 		x.shape: torch.Size([1, 30, 224, 224, 224])
encoder 1 		x.shape: torch.Size([1, 60, 112, 112, 112])
encoder 2 		x.shape: torch.Size([1, 120, 56, 56, 56])
encoder 3 		x.shape: torch.Size([1, 240, 28, 28, 28])
encoder 4 		x.shape: torch.Size([1, 480, 14, 14, 14])
bottleneck, 		x.shape torch.Size([1, 480, 7, 7, 7])
transpconv 0 		x.shape torch.Size([1, 480, 14, 14, 14])
decoder 0 		x.shape torch.Size([1, 480, 14, 14, 14])
transpconv 1 		x.shape torch.Size([1, 240, 28, 28, 28])
decoder 1 		x.shape torch.Size([1, 240, 28, 28, 28])
transpconv 2 		x.shape torch.Size([1, 120, 56, 56, 56])
decoder 2 		x.shape torch.Size([1, 120, 56, 56, 56])
transpconv 3 		x.shape torch.Size([1, 60, 112, 112, 112])
decoder 3 		x.shape torch.Size([1, 60, 112, 112, 112])
transpconv 4 		x.shape torch.Size([1, 30, 224, 224, 224])
decoder 4 		x.shape torch.Size([1, 30, 224, 224, 224])
segmentation_output.shape	 torch.Size([1, 3, 224, 224, 224])

I also did some additional experiments:

In [2]: torch.__version__                                                                                           
Out[2]: '1.0.0.dev20190220

32x32x32 -&gt; works
64x64x64 -&gt; works
96x96x96 -&gt; works
128x128x128 -&gt; works
160x160x160 -&gt; works
192x192x192 -&gt; works
224x224x224 -&gt; CUDNN_STATUS_INTERNAL_ERROR
256x256x256 -&gt; works (you need to use 20 base_num_features, otherwise it's too large)

224x224x224 with 20 base_num_features -&gt; CUDNN_STATUS_INTERNAL_ERROR
224x224x224 with 24 base_num_features -&gt; CUDNN_STATUS_INTERNAL_ERROR
224x224x224 with 4 base_num_features -&gt; CUDNN_STATUS_INTERNAL_ERROR
224x224x224 with 32 base_num_features -&gt; CUDNN_STATUS_INTERNAL_ERROR

cudnn.benchmark = False -&gt; works


Interestingly the error only appears on 224x224x224 and not on smaller or larger inputs.
I am running the 410.79 driver and Cuda-10.0. All experiments done on a V100 32GB card.
The error message is this one:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-1-2db53cb1edfd&gt; in &lt;module&gt;
    205     loss = res.sum()
    206 
--&gt; 207     loss.backward()
    208 
    209     """

~/dl_venv/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    104                 products. Defaults to ``False``.
    105         """
--&gt; 106         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    107 
    108     def register_hook(self, hook):

~/dl_venv/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     91     Variable._execution_engine.run_backward(
     92         tensors, grad_tensors, retain_graph, create_graph,
---&gt; 93         allow_unreachable=True)  # allow_unreachable flag
     94 
     95 

RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR

&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='moderatelyfunctional' date='2019-03-07T02:03:10Z'>
		Thank you for your investigation and repro &lt;denchmark-link:https://github.com/FabianIsensee&gt;@FabianIsensee&lt;/denchmark-link&gt;
. It's a cudnn bug present at least in cudnn 7.4 and 7.5. I'm trying to get information on workarounds. The failing call is most likely for decoder 4 convolution weight gradient (input size 1,30,224,224,224, output features = 3, filter size =1) - I'm certain on sizes and it being weight gradient, not exactly sure if it's decoder 4 or not.
		</comment>
		<comment id='9' author='moderatelyfunctional' date='2019-03-07T07:16:46Z'>
		Thank you &lt;denchmark-link:https://github.com/ngimel&gt;@ngimel&lt;/denchmark-link&gt;
 for investigating this! If there is anything I can do to help, I'd be happy to do so. This bug is hindering some experiments and it would also be in my interest to get it solved relatively quickly
		</comment>
		<comment id='10' author='moderatelyfunctional' date='2019-03-17T13:11:49Z'>
		Hi, I get this error, when I want to call the .cuda() method on a network which contains a GRU. I have a Windows system with Pytorch 1.0.1, CUDA 10 and cudnn 7.401
		</comment>
		<comment id='11' author='moderatelyfunctional' date='2019-04-05T18:14:13Z'>
		We are working on a fix for this. Will update ASAP.
		</comment>
		<comment id='12' author='moderatelyfunctional' date='2019-04-05T18:19:51Z'>
		That's great to hear, thank you so much!
		</comment>
		<comment id='13' author='moderatelyfunctional' date='2019-04-09T06:36:49Z'>
		Hi, I'm facing the same error.
I receive RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR error running on a multi-gpus server via NGC PyTorch docker image, while running the same code in my personal computer via PyTorch installed by conda gets success.
		</comment>
		<comment id='14' author='moderatelyfunctional' date='2019-04-09T06:41:26Z'>
		&lt;denchmark-link:https://github.com/CyFeng16&gt;@CyFeng16&lt;/denchmark-link&gt;
 can you post a code snippet that reproduces the error you're finding as well as instructions to run the snippet?
Also, which NGC PyTorch docker image are you using?
		</comment>
		<comment id='15' author='moderatelyfunctional' date='2019-04-09T06:47:46Z'>
		&lt;denchmark-link:https://github.com/mruberry&gt;@mruberry&lt;/denchmark-link&gt;
 Some additional info:

NGC docker within PyTorch version 1.1.0a0+be364ac failed.(on server)
REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE
nvcr.io/nvidia/pytorch      19.03-py3           697cd637fb1b        3 weeks ago         7.57GB
Conda env within PyTorch version 1.0.1.post2 run perfectly.(on PC)

Apologize that could not share whole codes for now. Code starts as follows:
&lt;denchmark-code&gt;# Random seed setting
torch.manual_seed(16)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
&lt;/denchmark-code&gt;

		</comment>
		<comment id='16' author='moderatelyfunctional' date='2019-04-09T06:50:29Z'>
		Thank you for reporting the issue, but without a snippet to reproduce the error you're seeing I don't know if we'll be able to fix your issue. While you're seeing the same error, the cause may be different.
		</comment>
		<comment id='17' author='moderatelyfunctional' date='2019-04-09T06:54:57Z'>
		🏷️  will report when I find an alternative way to solve the problem.
[updates]
&lt;denchmark-link:https://github.com/mruberry&gt;@mruberry&lt;/denchmark-link&gt;
 After changing the docker image from  to  which contains PyTorch ver , the code works fine. Cheers.
[configurations]

OS: Ubuntu 18.10(PC)
CUDA Version: 10.0.130(PC)
cuDNN Version: 7.5(PC)
GPU models: 1080 Ti &amp;&amp; 2080 Ti(PC) V100(DGX Server)

[summary]

1.0.0a0+056cfaf used via NGC image 19.01 worked.
1.0.1.post2 installed via conda worked.
1.1.0a0+be364ac used via NGC image 19.03 failed.

It's a pleasure if this could help you work on the fix.
		</comment>
		<comment id='18' author='moderatelyfunctional' date='2019-04-11T19:44:35Z'>
		We believe we have identified the root cause of this issue and are working on a fix in cuDNN.
		</comment>
		<comment id='19' author='moderatelyfunctional' date='2019-04-27T14:12:14Z'>
		Hey &lt;denchmark-link:https://github.com/mruberry&gt;@mruberry&lt;/denchmark-link&gt;
, any updates so far?
		</comment>
		<comment id='20' author='moderatelyfunctional' date='2019-04-29T21:22:40Z'>
		We are testing a fix that we expect will ship in a future version of cuDNN. Unfortunately I cannot be more specific than that at the moment.
		</comment>
		<comment id='21' author='moderatelyfunctional' date='2019-05-05T12:24:00Z'>
		In pytorch1.1, code works well
		</comment>
		<comment id='22' author='moderatelyfunctional' date='2019-05-05T14:31:20Z'>
		thanks for reporting &lt;denchmark-link:https://github.com/FingerRec&gt;@FingerRec&lt;/denchmark-link&gt;

		</comment>
		<comment id='23' author='moderatelyfunctional' date='2019-05-05T14:33:21Z'>
		&lt;denchmark-link:https://github.com/FingerRec&gt;@FingerRec&lt;/denchmark-link&gt;
 glad to hear!
		</comment>
		<comment id='24' author='moderatelyfunctional' date='2019-05-24T23:18:20Z'>
		I'm still able to reproduce what &lt;denchmark-link:https://github.com/FabianIsensee&gt;@FabianIsensee&lt;/denchmark-link&gt;
 posted using pytorch 1.1.0a0+9eb0f43 (NGC 19.04) (using his snippet)
This NGC image only uses cuDNN 7.5.0, not sure if 7.5.1 or 7.6 would fix
		</comment>
		<comment id='25' author='moderatelyfunctional' date='2019-05-24T23:55:34Z'>
		&lt;denchmark-link:https://github.com/ksarma&gt;@ksarma&lt;/denchmark-link&gt;
 please use official pytorch 1.1 conda/pip packages or image from dockerhub/pytorch.
		</comment>
		<comment id='26' author='moderatelyfunctional' date='2019-05-25T00:06:15Z'>
		&lt;denchmark-link:https://github.com/ngimel&gt;@ngimel&lt;/denchmark-link&gt;
 Apologies, was using what I thought was the latest pytorch image from NGC, but it turns out there was a new one yesterday (19.05) and the issue seems to be fixed :) This image has cuDNN 7.6.0 and pytorch 1.1.0a0+828a6a3
		</comment>
	</comments>
</bug>