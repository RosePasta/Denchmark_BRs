<bug id='642' author='aboulch' open_date='2017-01-30T16:35:01Z' closed_time='2017-01-31T09:59:18Z'>
	<summary>Cuda memory leak with unpooling</summary>
	<description>
Hello,
I have tested the following code :
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
from torch.autograd import Variable
import torch.optim as optim
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 3, kernel_size=3, padding=1)
    def forward(self, x):
        x = self.conv1(x)
        x, id1 = F.max_pool2d(x,kernel_size=2, stride=2,return_indices=True)
        x = F.max_unpool2d(x, id1, kernel_size=2, stride=2)
        x = self.conv2(x)
        return x
model = Net()
model.cuda()
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.5)
model.train()
batch_= np.zeros((8,3, 224, 224), dtype=float)
data = Variable(torch.Tensor(batch_))
data = data.cuda()
while(True):
    output = model(data)
I can see the memory usage of my GPU increasing until I get a "RuntimeError: cuda runtime error (2) : out of memory". When I comment the unpooling I get a stable memory usage. Am I missing something ? Could it be a memory leak in the unpooling layer ?
I use Ubuntu 14.04, GTX 1070, cuda 8.
I tested on python 2.7 and 3.4 and got the same result.
Thank you for your help.
	</description>
	<comments>
		<comment id='1' author='aboulch' date='2017-01-31T08:20:41Z'>
		Thanks for the bug rrport Alexandre ! This issue has been fixed in &lt;denchmark-link:https://github.com/pytorch/pytorch/pull/650&gt;#650&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='aboulch' date='2017-01-31T09:59:18Z'>
		Thanks !!
		</comment>
		<comment id='3' author='aboulch' date='2018-08-02T08:43:49Z'>
		Hello! The very same problem seems to still exist in maxunpool3d in pytorch 0.4.
Maybe the fix was only for 2d?
Thanks!
		</comment>
		<comment id='4' author='aboulch' date='2018-08-02T15:52:43Z'>
		&lt;denchmark-link:https://github.com/dmarcosg&gt;@dmarcosg&lt;/denchmark-link&gt;
 this was fixed for MaxUnPool3d in pytorch 0.4.1
		</comment>
		<comment id='5' author='aboulch' date='2018-08-03T06:34:50Z'>
		Oh, perfect, I need to keep more up to date! Thanks a lot!
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Aug 2, 2018 at 5:55 PM Soumith Chintala ***@***.***&gt; wrote:
 @dmarcosg &lt;https://github.com/dmarcosg&gt; this was fixed for MaxUnPool3d in
 pytorch 0.4.1

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#642 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AdBD-4sPeucyLMbGkbhOlMNtWeWLFXjJks5uMyDvgaJpZM4LxnlB&gt;
 .



		</comment>
	</comments>
</bug>