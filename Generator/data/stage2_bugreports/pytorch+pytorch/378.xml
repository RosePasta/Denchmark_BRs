<bug id='378' author='szagoruyko' open_date='2016-12-30T10:53:12Z' closed_time='2017-07-09T19:31:34Z'>
	<summary>Batch normalization needs input dim checks</summary>
	<description>
Right now PyTorch batch_norm accepts any weight and running_mean shapes (eg 128 and 512) and doesn't complain at all, these checks &lt;denchmark-link:https://github.com/torch/nn/blob/master/BatchNormalization.lua#L78&gt;https://github.com/torch/nn/blob/master/BatchNormalization.lua#L78&lt;/denchmark-link&gt;
 should probably be moved to C/CUDA side?
	</description>
	<comments>
	</comments>
</bug>