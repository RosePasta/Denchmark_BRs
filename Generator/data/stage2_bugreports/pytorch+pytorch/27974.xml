<bug id='27974' author='99991' open_date='2019-10-15T12:36:20Z' closed_time='2019-10-17T05:45:43Z'>
	<summary>backward pass slow when using Conv2d</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

My backward passes are roughly 300 times slower than my forward passes when using nn.Conv2D layers. For example, a forward pass using just a convolutional layer takes 0.003 seconds, while the backward pass takes more than one second.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Here is some code to reproduce the problem, which will print the time for a forward and a backward pass on a batch of 32 images with depth 8 and image size 32x32 using 5x5 kernels with a padding of 2 pixels.
import time
import numpy as np
import torch
import torch.nn as nn

n, c, h, w = (32, 8, 32, 32)
device = torch.device("cpu")
model = nn.Conv2d(c, c, 5, padding=2)
model = model.to(device)
model.train()
loss_fn = nn.MSELoss()

for iteration in range(100):
    t0 = time.perf_counter()
    
    x = torch.from_numpy(np.ones((n, c, h, w), np.float32)).to(device)
    y = torch.from_numpy(np.ones((n, c, h, w), np.float32)).to(device)
    loss = loss_fn(model(x), y)
    
    t1 = time.perf_counter()
    
    loss.backward()
    
    t2 = time.perf_counter()
    print("forward: %f seconds" % (t1 - t0))
    print("backward: %f seconds" % (t2 - t1))
    print("")
&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

I'd expect the backward pass to run at least 100 times faster. In fact, the performance is as expected when running the script on a different computer. Performance for Linear layers is also as expected.
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;PyTorch version: 1.0.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Debian GNU/Linux 10 (buster)
GCC version: (Debian 8.3.0-6) 8.3.0
CMake version: version 3.13.4

Python version: 3.7
Is CUDA available: No
CUDA runtime version: No CUDA
GPU models and configuration: No CUDA
Nvidia driver version: No CUDA
cuDNN version: No CUDA

Versions of relevant libraries:
[pip] numpy==1.16.4
[pip] numpydoc==0.9.1
[pip] torch==1.0.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2019.4                      243  
[conda] mkl-service               2.0.2            py37h7b6447c_0  
[conda] mkl_fft                   1.0.12           py37ha843d7b_0  
[conda] mkl_random                1.0.2            py37hd81dba3_0  
[conda] torch                     1.0.0                    pypi_0    pypi
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

Results of python -m torch.utils.bottleneck train.py:
&lt;denchmark-code&gt;--------------------------------------------------------------------------------
  Environment Summary
--------------------------------------------------------------------------------
PyTorch 1.0.0 compiled w/ CUDA 9.0.176
Running with Python 3.7 and 

`pip list` truncated output:
Unable to fetch
--------------------------------------------------------------------------------
  cProfile output
--------------------------------------------------------------------------------
         5000 function calls (4940 primitive calls) in 109.082 seconds

   Ordered by: internal time
   List reduced from 81 to 15 due to restriction &lt;15&gt;

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      100  108.587    1.086  108.587    1.086 {method 'run_backward' of 'torch._C._EngineBase' objects}
      100    0.393    0.004    0.393    0.004 {built-in method conv2d}
      100    0.040    0.000    0.040    0.000 {built-in method torch._C._nn.mse_loss}
      200    0.030    0.000    0.030    0.000 {built-in method numpy.copyto}
        1    0.009    0.009  109.082  109.082 train.py:1(&lt;module&gt;)
      300    0.004    0.000    0.004    0.000 {built-in method builtins.print}
      200    0.003    0.000    0.441    0.002 /home/username/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py:483(__call__)
      200    0.002    0.000    0.002    0.000 {built-in method numpy.empty}
      200    0.002    0.000    0.002    0.000 {built-in method from_numpy}
      100    0.001    0.000    0.001    0.000 {built-in method ones_like}
      202    0.001    0.000    0.001    0.000 {method 'to' of 'torch._C._TensorBase' objects}
      100    0.001    0.000    0.395    0.004 /home/username/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py:317(forward)
      100    0.001    0.000    0.001    0.000 {built-in method broadcast_tensors}
      200    0.001    0.000    0.001    0.000 {built-in method torch._C._get_tracing_state}
      100    0.001    0.000  108.590    1.086 /home/username/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py:38(backward)


--------------------------------------------------------------------------------
  autograd profiler output (CPU mode)
--------------------------------------------------------------------------------
        top 15 events sorted by cpu_time_total

---------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------
Name                                            CPU time        CUDA time            Calls        CPU total       CUDA total
---------------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------
MkldnnConvolutionBackward                  1308761.381us          0.000us                1    1308761.381us          0.000us
mkldnn_convolution_backward                1308753.708us          0.000us                1    1308753.708us          0.000us
mkldnn_convolution_backward_weights        1308749.338us          0.000us                1    1308749.338us          0.000us
MkldnnConvolutionBackward                  1212529.170us          0.000us                1    1212529.170us          0.000us
mkldnn_convolution_backward                1212521.603us          0.000us                1    1212521.603us          0.000us
mkldnn_convolution_backward_weights        1212517.754us          0.000us                1    1212517.754us          0.000us
MkldnnConvolutionBackward                  1198483.938us          0.000us                1    1198483.938us          0.000us
mkldnn_convolution_backward                1198476.239us          0.000us                1    1198476.239us          0.000us
mkldnn_convolution_backward_weights        1198471.536us          0.000us                1    1198471.536us          0.000us
MkldnnConvolutionBackward                  1190918.954us          0.000us                1    1190918.954us          0.000us
mkldnn_convolution_backward                1190911.341us          0.000us                1    1190911.341us          0.000us
mkldnn_convolution_backward_weights        1190907.473us          0.000us                1    1190907.473us          0.000us
MkldnnConvolutionBackward                  1164987.322us          0.000us                1    1164987.322us          0.000us
mkldnn_convolution_backward                1164978.555us          0.000us                1    1164978.555us          0.000us
mkldnn_convolution_backward_weights        1164973.806us          0.000us                1    1164973.806us          0.000us 
&lt;/denchmark-code&gt;

cc &lt;denchmark-link:https://github.com/ezyang&gt;@ezyang&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gchanan&gt;@gchanan&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/zou3519&gt;@zou3519&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gujinghui&gt;@gujinghui&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/PenghuiCheng&gt;@PenghuiCheng&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/XiaobingSuper&gt;@XiaobingSuper&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jianyuh&gt;@jianyuh&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='99991' date='2019-10-15T18:08:57Z'>
		&lt;denchmark-link:https://github.com/gujinghui&gt;@gujinghui&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/PenghuiCheng&gt;@PenghuiCheng&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/XiaobingSuper&gt;@XiaobingSuper&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jianyuh&gt;@jianyuh&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='99991' date='2019-10-15T18:14:15Z'>
		The backward pass is 300x slower than the forward pass, but I'm not sure how long it should actually take. We should investigate if it's not supposed to take that long.
		</comment>
		<comment id='3' author='99991' date='2019-10-15T18:52:46Z'>
		do we use mkldnn backward?  It might not be a dependency bug.
		</comment>
		<comment id='4' author='99991' date='2019-10-15T19:11:59Z'>
		The autograd profiling result suggests that we do:
&lt;denchmark-code&gt;mkldnn_convolution_backward                1308753.708us          0.000us                1    1308753.708us          0.000us
mkldnn_convolution_backward_weights        1308749.338us          0.000us                1    1308749.338us          0.000us
MkldnnConvolutionBackward     
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='99991' date='2019-10-15T19:48:36Z'>
		The best way to see what's going on with Intel MKL-DNN is to run the script with MKLDNN_VERBOSE=1.
		</comment>
		<comment id='6' author='99991' date='2019-10-16T05:55:01Z'>
		
The best way to see what's going on with Intel MKL-DNN is to run the script with MKLDNN_VERBOSE=1.

&lt;denchmark-code&gt;$ export MKLDNN_VERBOSE=1; python train.py 
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nchw out:f32_nChw8c,num:1,32x8x32x32,0.979004
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_oihw out:f32_OIhw8i8o,num:1,8x8x5x5,0.0869141
mkldnn_verbose,exec,convolution,jit:sse42,forward_training,fsrc:nChw8c fwei:OIhw8i8o fbia:x fdst:nChw8c,alg:convolution_direct,mb32_g1ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,2.21387
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nChw8c out:f32_nchw,num:1,32x8x32x32,0.218018
mkldnn_verbose,exec,convolution,ref:any,backward_weights,fsrc:nchw fwei:oihw fbia:x fdst:nchw,alg:convolution_direct,mb32_g1ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,1096.12
forward: 0.007640 seconds
backward: 1.098457 seconds

mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nchw out:f32_nChw8c,num:1,32x8x32x32,0.151123
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_oihw out:f32_OIhw8i8o,num:1,8x8x5x5,0.00292969
mkldnn_verbose,exec,convolution,jit:sse42,forward_training,fsrc:nChw8c fwei:OIhw8i8o fbia:x fdst:nChw8c,alg:convolution_direct,mb32_g1ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,1.56982
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nChw8c out:f32_nchw,num:1,32x8x32x32,0.356934
mkldnn_verbose,exec,convolution,ref:any,backward_weights,fsrc:nchw fwei:oihw fbia:x fdst:nchw,alg:convolution_direct,mb32_g1ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,1031.21
forward: 0.004261 seconds
backward: 1.052957 seconds

mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nchw out:f32_nChw8c,num:1,32x8x32x32,0.334961
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_oihw out:f32_OIhw8i8o,num:1,8x8x5x5,0.032959
mkldnn_verbose,exec,convolution,jit:sse42,forward_training,fsrc:nChw8c fwei:OIhw8i8o fbia:x fdst:nChw8c,alg:convolution_direct,mb32_g1ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,3.0481
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nChw8c out:f32_nchw,num:1,32x8x32x32,0.126953
mkldnn_verbose,exec,convolution,ref:any,backward_weights,fsrc:nchw fwei:oihw fbia:x fdst:nchw,alg:convolution_direct,mb32_g1ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,1033.26
forward: 0.005637 seconds
backward: 1.038410 seconds

[and so on]
&lt;/denchmark-code&gt;

For reference, this is run on an Intel i5-2400.
		</comment>
		<comment id='7' author='99991' date='2019-10-16T07:52:15Z'>
		&lt;denchmark-link:https://github.com/99991&gt;@99991&lt;/denchmark-link&gt;
 , can your try build PyTorch master code which will use MKLDNN v0.21.1? I test it on skx-8180 and there hasn't this problem when using the latest code.  I will also test it on other deveices which not have AVX instruction . Thanks!
		</comment>
		<comment id='8' author='99991' date='2019-10-16T14:13:12Z'>
		I like &lt;denchmark-link:https://github.com/zou3519&gt;@zou3519&lt;/denchmark-link&gt;
's original high prio determination and readded it.
		</comment>
		<comment id='9' author='99991' date='2019-10-16T18:54:55Z'>
		I cannot reproduce on master:
&lt;denchmark-code&gt;forward: 0.002540 seconds
backward: 0.002700 seconds

forward: 0.002412 seconds
backward: 0.002714 seconds

forward: 0.002148 seconds
backward: 0.002837 seconds

forward: 0.001698 seconds
backward: 0.002663 seconds

forward: 0.001774 seconds
backward: 0.002692 seconds

forward: 0.002285 seconds
backward: 0.002783 seconds

forward: 0.002173 seconds
backward: 0.002658 seconds

forward: 0.001775 seconds
backward: 0.002708 seconds

forward: 0.001602 seconds
backward: 0.002700 seconds

forward: 0.001482 seconds
backward: 0.002958 seconds
&lt;/denchmark-code&gt;

mkldnn debug:
&lt;denchmark-code&gt;mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nchw out:f32_nChw8c,num:1,32x8x32x32,1.43896
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_oihw out:f32_OIhw8i8o,num:1,8x8x5x5,0.0100098
mkldnn_verbose,exec,convolution,jit:avx2,forward_training,fsrc:nChw8c fwei:OIhw8i8o fbia:x fdst:nChw8c,alg:convolution_direct,mb32_ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,0.443848
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nChw8c out:f32_nchw,num:1,32x8x32x32,0.182129
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nchw out:f32_nChw8c,num:1,32x8x32x32,1.37402
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nchw out:f32_nChw8c,num:1,32x8x32x32,0.197998
mkldnn_verbose,exec,convolution,jit:avx2,backward_weights,fsrc:nChw8c fwei:OIhw8i8o fbia:x fdst:nChw8c,alg:convolution_direct,mb32_ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,1.23315
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_OIhw8i8o out:f32_oihw,num:1,8x8x5x5,0.0610352
forward: 0.003365 seconds
backward: 0.005018 seconds
&lt;/denchmark-code&gt;

cpuinfo
&lt;denchmark-code&gt;rocessor       : 47
vendor_id       : GenuineIntel
cpu family      : 6
model           : 63
model name      : Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz
stepping        : 2
microcode       : 0x36
cpu MHz         : 2736.043
cache size      : 30720 KB
physical id     : 1
siblings        : 24
core id         : 13
cpu cores       : 12
apicid          : 59
initial apicid  : 59
fpu             : yes
fpu_exception   : yes
cpuid level     : 15
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm abm cpuid_fault epb invpcid_single pti intel_ppin tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts
bugs            : cpu_meltdown spectre_v1 spectre_v2 l1tf
bogomips        : 4999.30
clflush size    : 64
cache_alignment : 64
address sizes   : 46 bits physical, 48 bits virtual
power management:

&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='99991' date='2019-10-17T04:16:51Z'>
		&lt;denchmark-link:https://github.com/99991&gt;@99991&lt;/denchmark-link&gt;
 , Can you help test it using PyTorch latest master code which have upgrade mkldnn to v0.21.1? Thanks!
		</comment>
		<comment id='11' author='99991' date='2019-10-17T05:45:43Z'>
		
@99991 , Can you help test it using PyTorch latest master code which have upgrade mkldnn to v0.21.1? Thanks!

Not quite sure how to do that, but pip install torch==1.3.0+cpu torchvision==0.4.1+cpu -f https://download.pytorch.org/whl/torch_stable.html gave me MKL-DNN v0.20.5, which works well enough for me.
Results of export MKLDNN_VERBOSE=1; python train.py:
&lt;denchmark-code&gt;mkldnn_verbose,info,Intel MKL-DNN v0.20.5 (commit 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
mkldnn_verbose,info,Detected ISA is Intel AVX
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nchw out:f32_nChw8c,num:1,32x8x32x32,0.656006
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_oihw out:f32_OIhw8i8o,num:1,8x8x5x5,0.00488281
mkldnn_verbose,exec,convolution,jit:avx2,forward_training,fsrc:nChw8c fwei:OIhw8i8o fbia:x fdst:nChw8c,alg:convolution_direct,mb32_ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,1.06689
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nChw8c out:f32_nchw,num:1,32x8x32x32,0.165039
mkldnn_verbose,exec,convolution,gemm:jit,backward_weights,fsrc:nchw fwei:oihw fbia:x fdst:nchw,alg:convolution_direct,mb32_ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,26.844
forward: 0.004587 seconds
backward: 0.029260 seconds

mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nchw out:f32_nChw8c,num:1,32x8x32x32,0.0949707
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_oihw out:f32_OIhw8i8o,num:1,8x8x5x5,0.0400391
mkldnn_verbose,exec,convolution,jit:avx2,forward_training,fsrc:nChw8c fwei:OIhw8i8o fbia:x fdst:nChw8c,alg:convolution_direct,mb32_ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,0.900879
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nChw8c out:f32_nchw,num:1,32x8x32x32,0.136963
mkldnn_verbose,exec,convolution,gemm:jit,backward_weights,fsrc:nchw fwei:oihw fbia:x fdst:nchw,alg:convolution_direct,mb32_ic8oc8_ih32oh32kh5sh1dh0ph2_iw32ow32kw5sw1dw0pw2,9.09302
forward: 0.002121 seconds
backward: 0.010544 seconds
&lt;/denchmark-code&gt;

Thank you everyone for your great help :)
		</comment>
	</comments>
</bug>