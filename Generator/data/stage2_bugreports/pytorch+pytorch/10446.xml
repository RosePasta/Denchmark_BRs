<bug id='10446' author='yancz1989' open_date='2018-08-12T03:59:18Z' closed_time='2019-08-17T18:55:49Z'>
	<summary>using nn.functional.interpolation but fails on ONNX export</summary>
	<description>
Hi, everyone,
I'm implementing some segmentation model, and need to use ONNX to convert to caffe2 model. with following code, I have specified the align_corners variable to False, explicitly.
&lt;denchmark-code&gt;for encode, decoder in zip(encodes[::-1][1:], self.decode_layers[1:]):
  x = decoder(torch.cat([F.interpolate(x, encode.size()[2:], mode = 'bilinear', align_corners = False), encode], 1))
return self.segmentation(F.interpolate(x, input_shp, mode = 'bilinear', align_corners = False))
&lt;/denchmark-code&gt;

However, when I use ONNX to export this model to caffe2, following error occurs:
/usr/local/lib/python3.5/dist-packages/torch/onnx/symbolic.py:69: UserWarning: ONNX export failed on upsample_bilinear2d because align_corners == True not supported
warnings.warn("ONNX export failed on " + op + " because " + msg + " not supported")
Traceback (most recent call last):
File "pytorch2caffe.py", line 99, in 
export_params=True)      # store the trained parameter weights inside the model file
File "/usr/local/lib/python3.5/dist-packages/torch/onnx/init.py", line 21, in _export
return utils._export(*args, **kwargs)
File "/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py", line 232, in _export
proto, export_map = graph.export(params, _onnx_opset_version, defer_weight_export, operator_export_type)
RuntimeError: ONNX export failed: Couldn't export operator aten::upsample_bilinear2d
This is strange, since I have explicitly set align_corners to False.
Can anyone help me on this issue? Any kind of suggestion is welcomed. Thanks for your kindly information.
	</description>
	<comments>
		<comment id='1' author='yancz1989' date='2018-08-15T19:37:20Z'>
		Could you provide a minimum code snippet to reproduce the problem?
&lt;denchmark-link:https://github.com/pytorch/pytorch/pull/10550&gt;#10550&lt;/denchmark-link&gt;
, we can successfully export.
		</comment>
		<comment id='2' author='yancz1989' date='2018-09-10T19:20:55Z'>
		Cannot reproduce. Close
		</comment>
		<comment id='3' author='yancz1989' date='2018-09-18T21:38:35Z'>
		I am having same problem trying to export RetinaNet (&lt;denchmark-link:https://github.com/kuangliu/pytorch-retinanet&gt;https://github.com/kuangliu/pytorch-retinanet&lt;/denchmark-link&gt;
). Can you get this to run?
&lt;denchmark-code&gt;import torch
import torch.onnx
from torch import nn
from torch.autograd import Variable
import torch.nn.functional as F

class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        
    def forward(self, x):
        h1 = x
        h2 = F.interpolate(x, size=h1.size()[-2:], mode='bilinear', align_corners=False)
        h = torch.cat([h1, h2], dim=1)
        return h

model = SimpleNet()
x = Variable(torch.randn(1, 3, 10, 10)).cpu()
torch_out = torch.onnx._export(model, x, '~/temp/test_bilinear_onnx_export.txt', export_params=True, verbose=True)
print('finished onnx export')
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='yancz1989' date='2018-09-28T18:46:31Z'>
		Here's a code snippet that might shed some light on the issue --
import torch
import torch.nn as nn
import torch.nn.functional as F
import onnx
from onnx import shape_inference, utils

class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 10, kernel_size=1)

    def forward(self, x):
        x = F.interpolate(x, (100,100), mode='bilinear', align_corners=False)
        # x = F.relu(x)
        x = self.conv1(x)
        return x

filename = 'basic.onnx'
model = SimpleNet()
inputs = torch.randn(1, 3, 224, 224)
torch.onnx.export(model, inputs, filename)

graph = onnx.load(filename)
graph = shape_inference.infer_shapes(graph)
print(graph.graph)
At the bottom of the output is a list of tensors in the model:
&lt;denchmark-code&gt;input {
  name: "0"
  type {
    tensor_type {
      elem_type: FLOAT
      shape {
        dim {
          dim_value: 1
        }
        dim {
          dim_value: 3
        }
        dim {
          dim_value: 224
        }
        dim {
          dim_value: 224
        }
      }
    }
  }
}
input {
  name: "1"
  type {
    tensor_type {
      elem_type: FLOAT
      shape {
        dim {
          dim_value: 10
        }
        dim {
          dim_value: 3
        }
        dim {
          dim_value: 1
        }
        dim {
          dim_value: 1
        }
      }
    }
  }
}
input {
  name: "2"
  type {
    tensor_type {
      elem_type: FLOAT
      shape {
        dim {
          dim_value: 10
        }
      }
    }
  }
}
output {
  name: "4"
  type {
    tensor_type {
      elem_type: FLOAT
      shape {
        dim {
          dim_value: 1
        }
        dim {
          dim_value: 10
        }
        dim {
          dim_value: 100
        }
        dim {
          dim_value: 100
        }
      }
    }
  }
}
&lt;/denchmark-code&gt;

Notice there is no tensor 3, which is the output of the interpolate op:
&lt;denchmark-code&gt;node {
  input: "0"
  output: "3"
  op_type: "Upsample"
...
&lt;/denchmark-code&gt;

and the input of the conv op:
&lt;denchmark-code&gt;node {
  input: "3"
  input: "1"
  input: "2"
  output: "4"
  op_type: "Conv"
...
&lt;/denchmark-code&gt;

However, if I uncomment the F.relu and comment the F.interpolate:
    def forward(self, x):
        # x = F.interpolate(x, (100,100), mode='bilinear', align_corners=False)
        x = F.relu(x)
        x = self.conv1(x)
        return x
and rerun the code, the very bottom of the output now has a value_info section, which contains the needed tensor 3.
&lt;denchmark-code&gt;value_info {
  name: "3"
  type {
    tensor_type {
      elem_type: FLOAT
      shape {
        dim {
          dim_value: 1
        }
        dim {
          dim_value: 3
        }
        dim {
          dim_value: 224
        }
        dim {
          dim_value: 224
        }
      }
    }
  }
}
&lt;/denchmark-code&gt;

which lines up with the relu node (notice output = 3):
&lt;denchmark-code&gt;node {
  input: "0"
  output: "3"
  op_type: "Relu"
&lt;/denchmark-code&gt;

and the conv node (notice input = 3):
&lt;denchmark-code&gt;node {
  input: "3"
  input: "1"
  input: "2"
  output: "4"
  op_type: "Conv"
&lt;/denchmark-code&gt;

So it seems like the F.interpolate operation is not properly being saved in the trace export? Let me know if I am missing a command or something that handles this behavior.
		</comment>
		<comment id='5' author='yancz1989' date='2018-10-09T01:00:29Z'>
		&lt;denchmark-link:https://github.com/thedch&gt;@thedch&lt;/denchmark-link&gt;
 I have used your code to generate the trace. (Upsample is enabled, and relu is commented out.)
I have the tensor 3 in the value_info section, which is expected:
&lt;denchmark-code&gt;value_info {
  name: "3"
  type {
    tensor_type {
      elem_type: FLOAT
      shape {
        dim {
          dim_value: 1
        }
        dim {
          dim_value: 3
        }
        dim {
          dim_value: 100
        }
        dim {
          dim_value: 100
        }
      }
    }
  }
}
&lt;/denchmark-code&gt;

The trace seems good to me.
		</comment>
		<comment id='6' author='yancz1989' date='2018-10-09T21:18:26Z'>
		&lt;denchmark-link:https://github.com/houseroad&gt;@houseroad&lt;/denchmark-link&gt;
 hmmmm, interesting. I have tried it on two different systems and both times I do not get the  3 tensor. What are your system / package details etc?
&lt;denchmark-code&gt;&gt;&gt;&gt; import torch; torch.__version__
'0.4.1'
&gt;&gt;&gt; import onnx; onnx.__version__
'1.3.0'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='yancz1989' date='2018-10-09T21:20:54Z'>
		I always stick to the master. Can you try to update your pytorch master?
ONNX package should be fine.
		</comment>
		<comment id='8' author='yancz1989' date='2018-10-10T18:14:17Z'>
		hi &lt;denchmark-link:https://github.com/houseroad&gt;@houseroad&lt;/denchmark-link&gt;
 -- thank you very much for your help. you are right, nightly build of pytorch fixes this problem:
&lt;denchmark-code&gt;$ conda list | grep -E "pytorch|onnx"
onnx                      1.3.0                     &lt;pip&gt;
pytorch-nightly           1.0.0.dev20180929         py3.6_0    pytorch
&lt;/denchmark-code&gt;

prints:
&lt;denchmark-code&gt;value_info {
  name: "3"
  type {
    tensor_type {
      elem_type: FLOAT
      shape {
        dim {
          dim_value: 1
        }
        dim {
          dim_value: 3
        }
        dim {
          dim_value: 100
        }
        dim {
          dim_value: 100
        }
      }
    }
  }
}
&lt;/denchmark-code&gt;

Note to any future readers: at the time of this writing, the standard conda install -c conda-forge onnx gives version 1.1.2, which does not have shape_inference. As such, you must install pytorch nightly and build onnx from source to get the code snippet I posted above to work.
		</comment>
		<comment id='9' author='yancz1989' date='2018-10-12T16:49:19Z'>
		&lt;denchmark-link:https://github.com/thedch&gt;@thedch&lt;/denchmark-link&gt;
 Will it work with dynamic shape_factor or size?
		</comment>
		<comment id='10' author='yancz1989' date='2018-11-28T06:59:38Z'>
		Hello, &lt;denchmark-link:https://github.com/houseroad&gt;@houseroad&lt;/denchmark-link&gt;
 , I have tried to export F.interpolate(mode='bilinear') as example shows, and it works. But I found that the parameter @align_corners must be set False, or the export would be failed. In the model I used before, I set align_corners True, so I'm wondering if it could be exported when this parameter is set True in the future.
My version:
python: 3.6.5
pytorch: 1.0.0.dev20181125
onnx: 1.3.0
		</comment>
		<comment id='11' author='yancz1989' date='2018-11-30T05:39:01Z'>
		
import torch import torch.nn as nn import torch.nn.functional as F import onnx from onnx import shape_inference, utils class SimpleNet(nn.Module): def init(self): super().init() self.conv1 = nn.Conv2d(3, 10, kernel_size=1) def forward(self, x): x = F.interpolate(x, (100,100), mode='bilinear', align_corners=False) # x = F.relu(x) x = self.conv1(x) return x filename = 'basic.onnx' model = SimpleNet() inputs = torch.randn(1, 3, 224, 224) torch.onnx.export(model, inputs, filename) graph = onnx.load(filename) graph = shape_inference.infer_shapes(graph) print(graph.graph)

&lt;denchmark-link:https://github.com/thedch&gt;@thedch&lt;/denchmark-link&gt;
 I got  when I tried to run the code. I'm using  1.3.0 and  1.0.0.dev20181129.
		</comment>
		<comment id='12' author='yancz1989' date='2018-12-02T09:08:57Z'>
		&lt;denchmark-link:https://github.com/houseroad&gt;@houseroad&lt;/denchmark-link&gt;

torch can export interpolate successfully, but onnx.checker.check_model(onnxmodel) got error.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import torch
import torch.nn as nn
import torch.nn.functional as F
import onnx
from onnx_tf.backend import prepare

class MM(nn.Module):
	def __init__(self, ):
		super(MM, self ).__init__()
		self.conv = nn.Sequential(nn.Conv2d(2, 10, 3, 2, 1), nn.BatchNorm2d(10), nn.ReLU())

	def forward(self, x):
		x = self.conv(x)
		return F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
		return x

dtype = torch.float
data = torch.rand(1, 2, 5, 5).to(dtype=dtype)
mm = MM().to(dtype=dtype)
mm.eval()

torch.onnx.export(mm, data, 'x.onnx', verbose=False, export_params=True)
onnxmodel = onnx.load('x.onnx')
onnx.checker.check_model(onnxmodel)



Traceback (most recent call last):
  File "ttt.py", line 24, in &lt;module&gt;
    onnx.checker.check_model(onnxmodel)
  File "/home/lyuwenyu/anaconda3/envs/onnx/lib/python3.6/site-packages/onnx/checker.py", line 82, in check_model
    C.check_model(model.SerializeToString())
onnx.onnx_cpp2py_export.checker.ValidationError: Input size 2 not in range [min=1, max=1].

==&gt; Context: Bad node spec: input: "10" input: "11" output: "12" op_type: "Upsample" attribute { name: "mode" s: "linear" type: STRING } doc_string: "
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;python: 3.6
onnx: 1.30
pytorch: 1.0.0.dev20181201
&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='yancz1989' date='2018-12-04T19:11:52Z'>
		Yeah, it got changed in recent master, and the changes were not included in the onnx 1.3.0 release. Could you switch to onnx master branch?
		</comment>
		<comment id='14' author='yancz1989' date='2018-12-05T14:26:36Z'>
		Thanks for your kind replay &lt;denchmark-link:https://github.com/houseroad&gt;@houseroad&lt;/denchmark-link&gt;
.    I build  from master, but it occurs the same error.
		</comment>
		<comment id='15' author='yancz1989' date='2019-01-06T14:06:16Z'>
		I have the same error. This is a PyTorch 1.0 error. Is there any known solution?
		</comment>
		<comment id='16' author='yancz1989' date='2019-01-07T07:09:43Z'>
		Reopening for now, as it doesn't seem to be resolved
		</comment>
		<comment id='17' author='yancz1989' date='2019-01-08T00:54:44Z'>
		Actually,unsample error  come from onnx's code,not pytorch's,so you should follow  &lt;denchmark-link:https://github.com/onnx/onnx/issues/1655&gt;onnx/onnx#1655&lt;/denchmark-link&gt;
 .and problem may be handled.
		</comment>
		<comment id='18' author='yancz1989' date='2019-03-07T03:30:05Z'>
		I tried to convert a trained model from pytorch to tensorflow.
If I set align_corners=True , convert failed, and there would be small bias between the model outputs of pytorch and tensorflow, but if I set align_corners=False , convert succeed, but the outputs would be much more biased. Also it seemed that onnx-tf didn't store the align_corners param.
&lt;denchmark-code&gt;python: 3.6.7
onnx: 1.41
pytorch-nightly: 1.0.0.dev20190306'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='19' author='yancz1989' date='2019-08-09T14:58:27Z'>
		Having the same issue of &lt;denchmark-link:https://github.com/CrawlingD&gt;@CrawlingD&lt;/denchmark-link&gt;
 on Pytorch 1.2
		</comment>
		<comment id='20' author='yancz1989' date='2019-08-17T12:01:41Z'>
		
I tried to convert a trained model from pytorch to tensorflow.
If I set align_corners=True , convert failed, and there would be small bias between the model outputs of pytorch and tensorflow, but if I set align_corners=False , convert succeed, but the outputs would be much more biased. Also it seemed that onnx-tf didn't store the align_corners param.
python: 3.6.7
onnx: 1.41
pytorch-nightly: 1.0.0.dev20190306'


Same Issue on PyTorch1.2.
		</comment>
		<comment id='21' author='yancz1989' date='2019-08-17T18:55:49Z'>
		According to &lt;denchmark-link:https://github.com/onnx/onnx/issues/1655&gt;onnx/onnx#1655&lt;/denchmark-link&gt;
 the issue has been fixed in onnx. Please update onnx and let us know if it is still not fixed there. I'm closing this issue.
		</comment>
	</comments>
</bug>