<bug id='1389' author='ssoftcheck' open_date='2020-08-29T08:31:34Z' closed_time='2020-09-09T22:51:29Z'>
	<summary>Isolation forest values look incorrect when features are sampled</summary>
	<description>
When a scikit learn IsolationForest is created with max_features  &lt; 1.0 the shap values are incorrect
I am using this formula to compare score_samples and shape_values
-2 **(-(explainer.shap_values(fit_data).sum(axis=1) + explainer.expected_value) / _average_path_length([model.n_estimators]))
	</description>
	<comments>
		<comment id='1' author='ssoftcheck' date='2020-08-29T16:12:44Z'>
		Thanks for reporting. Could you share a small self contained example to get started debugging?
		</comment>
		<comment id='2' author='ssoftcheck' date='2020-08-29T18:55:07Z'>
		import numpy as np
import shap
from sklearn.ensemble import IsolationForest
# this function is being moved in next release
from sklearn.ensemble.iforest import _average_path_length

X,y = shap.datasets.boston()

iso_all = IsolationForest(max_features=1.0)
iso_some = IsolationForest(max_features=0.75)

iso_all.fit(X)
iso_some.fit(X)


explainer_all = shap.TreeExplainer(iso_all)
explainer_some = shap.TreeExplainer(iso_some)


def validate(data, explainer, iforest):
    validation = - 2**( 
             - (np.sum(explainer.shap_values(data), axis=1) + explainer.expected_value) / 
             _average_path_length(np.array([iforest.max_samples_]))[0] 
             )
    actual = iforest.score_samples(data)
    return np.allclose(actual, validation, atol=1e-7), actual, validation

test_all = validate(X, explainer_all, iso_all)
test_some = validate(X, explainer_some, iso_some)

print("check all features", "\n\tvalidated:", test_all[0], "\n\tMAE:", np.mean(np.abs(test_all[1] - test_all[2])))
print("check subsample of features", "\n\tvalidated:", test_some[0], "\n\tMAE:", np.mean(np.abs(test_some[1] - test_some[2])))
my result
&lt;denchmark-code&gt;check all features 
        validated: True 
        MAE: 9.840613172813887e-17
check subsample of features 
        validated: False 
        MAE: 0.2289718010237057
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='ssoftcheck' date='2020-08-29T19:10:05Z'>
		Not sure, but this might be relevant. It's the main work of score_samples
&lt;denchmark-link:https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/ensemble/_iforest.py#L459&gt;https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/ensemble/_iforest.py#L459&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='ssoftcheck' date='2020-09-06T14:00:49Z'>
		&lt;denchmark-link:https://github.com/ssoftcheck&gt;@ssoftcheck&lt;/denchmark-link&gt;
: I ran into this same issue, and I've fixed it in &lt;denchmark-link:https://github.com/slundberg/shap/pull/1412&gt;#1412&lt;/denchmark-link&gt;
, it should work for your example.
		</comment>
	</comments>
</bug>