<bug id='464' author='kyoungrok0517' open_date='2019-02-27T06:14:31Z' closed_time='2019-03-21T15:20:40Z'>
	<summary>Bug when using `xgb_model.pred(pred_interactions=True)`</summary>
	<description>
As suggested in &lt;denchmark-link:https://github.com/slundberg/shap/issues/452&gt;#452&lt;/denchmark-link&gt;
 I'm now trying to use the native functionality of xgboost to get the SHAP importance and interaction. I'm posting here presuming the shap team is involved in adding shap into xgboost library.
Problem
I get the following error when I use pred_interactions=True to get the feature interaction.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-14-6baa08e16bb5&gt; in &lt;module&gt;()
----&gt; 1 preds = model.predict(dtest, pred_contribs=True, approx_contribs=True, pred_interactions=True)

~/anaconda/lib/python3.6/site-packages/xgboost/core.py in predict(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)
   1237                     preds = preds.reshape(nrow, data.num_col() + 1, data.num_col() + 1)
   1238                 else:
-&gt; 1239                     preds = preds.reshape(nrow, ngroup, data.num_col() + 1, data.num_col() + 1)
   1240             elif pred_contribs:
   1241                 ngroup = int(chunk_size / (data.num_col() + 1))

ValueError: cannot reshape array of size 148317785 into shape (35255,0,601,601)
	</description>
	<comments>
		<comment id='1' author='kyoungrok0517' date='2019-03-02T00:13:07Z'>
		Does anything change when you use approx_contribs=False?
		</comment>
		<comment id='2' author='kyoungrok0517' date='2019-03-03T11:12:47Z'>
		I'm posting the result of combinations.

pred_contribs=True, approx_contribs=False, pred_interactions=True

X (the same error)


approx_contribs=True, pred_interactions=True

O



I'll stick to the second combination of arguments, but I think the result of parameter combination is unpredictable. Hope to be fixed for better usability.
		</comment>
		<comment id='3' author='kyoungrok0517' date='2019-03-04T05:59:16Z'>
		I suspect that the problem occurs when I use objective=multi:softprob with xgboost. unlike multi:softmax that objective produces the probabilities for each class. So if I have 8 classes then the 2nd dimension in the error message will be 8, not 1. Maybe this is causing the problem.
		</comment>
		<comment id='4' author='kyoungrok0517' date='2019-03-11T23:01:55Z'>
		Sorry for the slow reply. This is an issue inside XGBoost, and it looks like  is 0. Which it should not be. If we look at the relevant section in XGBoost it seems like ngroup should never be zero: &lt;denchmark-link:https://github.com/dmlc/xgboost/blob/6fb4c5efef6a2d5231f7d3e2d40716c2a774ab08/python-package/xgboost/core.py#L1297-L1306&gt;https://github.com/dmlc/xgboost/blob/6fb4c5efef6a2d5231f7d3e2d40716c2a774ab08/python-package/xgboost/core.py#L1297-L1306&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='kyoungrok0517' date='2019-04-25T14:24:56Z'>
		I have the same issue while I am calling the "explainer.shap_values(test_df)". In my case, the model was built using CLI version of Xgboost and loaded using booster.load_model()
		</comment>
		<comment id='6' author='kyoungrok0517' date='2019-04-25T15:27:56Z'>
		
I have the same issue while I am calling the "explainer.shap_values(test_df)". In my case, the model was built using CLI version of Xgboost and loaded using booster.load_model()

Hi, This issue is resolved, after a work around..
        shap_values = xgb_model.predict(xgb.DMatrix(test_df[xgb_features]), pred_interactions=False, approx_contribs=True )
but, can you help me , How do I calculate explainer.expected_value with this approach..
		</comment>
	</comments>
</bug>