<bug id='629' author='swanderz' open_date='2019-10-23T17:47:26Z' closed_time='2020-04-21T05:29:05Z'>
	<summary>BUG with header param on Dataset.Tabular.from_delimited_files()</summary>
	<description>
&lt;denchmark-h:h2&gt;SDK VERSION: 1.0.69&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Passing  to the  param throws the error below even though it is listed in the &lt;denchmark-link:https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_type_definitions.promoteheadersbehavior?view=azure-ml-py&gt;PromoteHeaderBehavior enumerator&lt;/denchmark-link&gt;
 which is referenced in the  param for &lt;denchmark-link:https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_factory.tabulardatasetfactory?view=azure-ml-py#from-delimited-files-path--validate-true--include-path-false--infer-column-types-true--set-column-types-none--separator------header--promoteheadersbehavior-all-files-have-same-headers--3---partition-format-none-&gt;Dataset.Tabular.from_delimited_files()&lt;/denchmark-link&gt;
.
The error message led me to another enum, &lt;denchmark-link:https://docs.microsoft.com/en-us/python/api/azureml-dataprep/azureml.dataprep.promoteheadersmode?view=azure-ml-py&gt;PromoteHeadersMode&lt;/denchmark-link&gt;
 which gives another set of possible values, of which both  and  worked for me.
cc: &lt;denchmark-link:https://github.com/MayMSFT&gt;@MayMSFT&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/lostmygithubaccount&gt;@lostmygithubaccount&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;snippet&lt;/denchmark-h&gt;

dataset= Dataset.Tabular.from_delimited_files(
    path=[(datastore, 'AEDW_Updates_Raw/v7/**')],
    separator='\t',
    header='ALL_FILES_HAVE_SAME_HEADERS',          # doesn't work
#     header='ALLFILES'                            # works
#     header='CONSTANTGROUPED'                     # also works
)
&lt;denchmark-h:h2&gt;error message&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;{
    "errorCode": "Microsoft.DataPrep.ErrorCodes.Unknown",
    "message": "Error converting value \"ALL_FILES_HAVE_SAME_HEADERS\" to type \"System.Nullable`1[Microsoft.DPrep.Engine.PromoteHeadersMode]\". Path \"arguments.columnHeadersMode\".",
    "errorData": {}
}
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;stacktrace&lt;/denchmark-h&gt;

---------------------------------------------------------------------------
UnexpectedError                           Traceback (most recent call last)
&lt;ipython-input-15-27e173bf6458&gt; in &lt;module&gt;
      2     path=[(datastore, 'AEDW_Updates_Raw/v7/**')],
      3     separator='\t',
----&gt; 4     header='ALL_FILES_HAVE_SAME_HEADERS', # DOESN'T WORK
      5 #     header='ALLFILES' # WORKS
      6 )

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\data\_loggerfactory.py in wrapper(*args, **kwargs)
     75             logger = get_logger()
     76             with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions):
---&gt; 77                 return func(*args, **kwargs)
     78 
     79         return wrapper

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\data\dataset_factory.py in from_delimited_files(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format)
    214         if validate or infer_column_types or _is_inference_required(set_column_types):
    215             _validate_has_data(dataflow, 'Cannot load any data from the the specified path. ' +
--&gt; 216                                          'Make sure the path is accessible and contains data.')
    217         if infer_column_types:
    218             column_types_builder = dataflow.builders.set_column_types()

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\data\dataset_error_handling.py in _validate_has_data(dataflow, error_message)
     40         raise DatasetValidationError(error_message)
     41     except Exception as e:
---&gt; 42         raise e
     43 
     44 

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\data\dataset_error_handling.py in _validate_has_data(dataflow, error_message)
     35     ensure_dataflow(dataflow)
     36     try:
---&gt; 37         dataflow.verify_has_data()
     38     except (dataprep().api.dataflow.DataflowValidationError,
     39             dataprep().api.errorhandlers.ExecutionError):

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\_loggerfactory.py in wrapper(*args, **kwargs)
    128             logger = get_logger()
    129             with _LoggerFactory.track_activity(logger, func.__name__, DEFAULT_ACTIVITY_TYPE, custom_dimensions):
--&gt; 130                 return func(*args, **kwargs)
    131 
    132         return wrapper

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\dataflow.py in verify_has_data(self)
    755             raise EmptyStepsError()
    756 
--&gt; 757         profile = self.take(1)._get_profile()
    758         if profile.row_count == 0 or profile.row_count is None:
    759             raise DataflowValidationError("The Dataflow produced no records.")

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\dataflow.py in _get_profile(self, include_stype_counts, number_of_histogram_bins, include_average_spaces_count, include_string_lengths)
    530         Actual get_profile implementation
    531         """
--&gt; 532         self._raise_if_missing_secrets()
    533         activity_ref = _to_anonymous_reference(self)
    534         return DataProfile._from_execution(self._engine_api,

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\dataflow.py in _raise_if_missing_secrets(self, secrets)
   2254 
   2255     def _raise_if_missing_secrets(self, secrets: Dict[str, str]=None):
-&gt; 2256         missing_secrets = set(self.get_missing_secrets())
   2257         if len(missing_secrets) == 0:
   2258             return

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\dataflow.py in get_missing_secrets(self)
   2033         :return: A list of missing secret IDs.
   2034         """
-&gt; 2035         secrets = self._engine_api.get_secrets(GetSecretsMessageArguments(steps_to_block_datas(self._steps)))
   2036         missing_secret_ids = map(
   2037             lambda secret: secret.key,

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\_aml_helper.py in wrapper(op_code, message, cancellation_token)
     36             if len(changed) &gt; 0:
     37                 engine_api_func().update_environment_variable(changed)
---&gt; 38             return send_message_func(op_code, message, cancellation_token)
     39 
     40         return wrapper

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\engineapi\api.py in get_secrets(self, message_args, cancellation_token)
    141     @update_aml_env_vars(get_engine_api)
    142     def get_secrets(self, message_args: typedefinitions.GetSecretsMessageArguments, cancellation_token: CancellationToken = None) -&gt; List[typedefinitions.SecretData]:
--&gt; 143         response = self._message_channel.send_message('Engine.GetSecrets', message_args, cancellation_token)
    144         return [typedefinitions.SecretData.from_pod(i) if i is not None else None for i in response] if response is not None else None
    145 

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\engineapi\engine.py in send_message(self, op_code, message, cancellation_token)
     72                 response = self._read_response()
     73                 if 'error' in response:
---&gt; 74                     raise_engine_error(response['error'])
     75                 elif response.get('id') == message_id:
     76                     return response['result']

~\AppData\Local\Continuum\miniconda3\envs\aml62\lib\site-packages\azureml\dataprep\api\errorhandlers.py in raise_engine_error(error_response)
     28         raise OperationCanceled()
     29     else:
---&gt; 30         raise UnexpectedError(error_response)
     31 
     32 

UnexpectedError: {'errorCode': 'Microsoft.DataPrep.ErrorCodes.Unknown', 'message': 'Error converting value "ALL_FILES_HAVE_SAME_HEADERS" to type \'System.Nullable`1[Microsoft.DPrep.Engine.PromoteHeadersMode]\'. Path \'arguments.columnHeadersMode\'.', 'errorData': {}}
	</description>
	<comments>
		<comment id='1' author='swanderz' date='2019-11-21T17:25:22Z'>
		Thanks for reporting it &lt;denchmark-link:https://github.com/swanderz&gt;@swanderz&lt;/denchmark-link&gt;
. This is a bug. We are tracking the fix now.
For what it's worth actually importing the enum would work just fine:
from azureml.data.dataset_type_definitions import PromoteHeadersBehavior
dataset= Dataset.Tabular.from_delimited_files(
    path=[(datastore, 'AEDW_Updates_Raw/v7/**')],
    separator='\t',
    header=PromoteHeadersBehavior.ALL_FILES_HAVE_SAME_HEADERS)
		</comment>
		<comment id='2' author='swanderz' date='2020-02-14T23:52:13Z'>
		Apologies for the delay. Hopefully, you've got the workaround to work for you. We've identified and fixed the bug and the fix should be out in early March through the next experimental release. I will keep you posted when that happens.
		</comment>
		<comment id='3' author='swanderz' date='2020-04-21T05:29:05Z'>
		Thank you for your post. It looks as though this issue was resolved so we closed this thread. Should you have additional questions, please continue to post here and and we will gladly continue the discussion.
		</comment>
	</comments>
</bug>