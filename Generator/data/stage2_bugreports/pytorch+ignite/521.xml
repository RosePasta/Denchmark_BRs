<bug id='521' author='roytseng-tw' open_date='2019-05-09T14:28:03Z' closed_time='2019-05-09T22:23:10Z'>
	<summary>Bug in ConfusionMatrix</summary>
	<description>
When passing in the groundtruth y with the format of shape (batch_size, num_categories, ...) and contains ground-truth class indices, flattened one-hot encoding tensor y_ohe_t will result in wrong order with respect to that of prediction. 


ignite/ignite/metrics/confusion_matrix.py


        Lines 79 to 80
      in
      fc85e25






 else: 



 y_ohe_t = y.transpose(1, -1).reshape(y.shape[1], -1).float() 








ignite/ignite/metrics/confusion_matrix.py


        Lines 82 to 83
      in
      fc85e25






 indices = torch.argmax(y_pred, dim=1) 



 y_pred_ohe = to_onehot(indices.reshape(-1), self.num_classes) 





For example:
y_pred                                       # shape (B, C, H, W)
indices = torch.argmax(y_pred, dim=1)        # shape (B, H, W)
y_pred_ohe = to_onehot(indices.reshape(-1),  # shape (B*H*W)
                       self.num_classes)     # shape (B*H*W, C)

y                                      # shape (B, C, H, W), C: num of classes
y_ohe_t = (y.transpose(1, -1)          # shape (B, W, H, C)
            .reshape(y.shape[1], -1))  # reshape (B, W, H, C) into (C, B*W*H) and the value order is totally wrong
Expected behavior:
y_ohe_t = y.transpose(0, 1).reshape(y.shape[1], -1)
# (B, C, H, W) --&gt; (C, B, H, W) --&gt; (C, B*H*W)
	</description>
	<comments>
		<comment id='1' author='roytseng-tw' date='2019-05-09T14:40:48Z'>
		&lt;denchmark-link:https://github.com/roytseng-tw&gt;@roytseng-tw&lt;/denchmark-link&gt;
 seems like it is a bug and there is &lt;denchmark-link:https://codecov.io/gh/pytorch/ignite/src/fc85e25dc4f938d780b4c425acb2d40f6cac6f24/ignite/metrics/confusion_matrix.py#L80&gt;no test&lt;/denchmark-link&gt;
 for these cases. Thanks for reporting !
		</comment>
		<comment id='2' author='roytseng-tw' date='2019-05-09T14:43:29Z'>
		&lt;denchmark-link:https://github.com/roytseng-tw&gt;@roytseng-tw&lt;/denchmark-link&gt;
 If you would like to contribute to ignite and send a PR with a fix (and a test), it would be awesome 
		</comment>
	</comments>
</bug>