<bug id='736' author='lukeyeager' open_date='2016-05-13T23:23:03Z' closed_time='2016-05-17T17:07:21Z'>
	<summary>Torch error when testing a model trained with multiple GPUs</summary>
	<description>
&lt;denchmark-code&gt;digits.inference.errors.InferenceError:
  torch classify one task failed with error message -
  ...6-05-12/install/share/lua/5.1/cunn/DataParallelTable.lua:374:
  Model was serialized on 2 nGPUs, but you are running on 1 please set 
  DataParallelTable.deserializeNGPUs to ignore  serialized tower-GPU assignments
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/gheinrich&gt;@gheinrich&lt;/denchmark-link&gt;
 Would &lt;denchmark-link:https://github.com/NVIDIA/DIGITS/pull/732&gt;#732&lt;/denchmark-link&gt;
 fix this?
	</description>
	<comments>
		<comment id='1' author='lukeyeager' date='2016-05-17T11:22:42Z'>
		Thanks for the bug report, I have updated the commit on &lt;denchmark-link:https://github.com/NVIDIA/DIGITS/pull/734&gt;#734&lt;/denchmark-link&gt;
 to fix this (with the new programming model we also need to set the number of GPUs when we deserialize a model when doing inference or fine-tuning).
		</comment>
		<comment id='2' author='lukeyeager' date='2016-05-17T16:57:34Z'>
		^ I think you meant &lt;denchmark-link:https://github.com/NVIDIA/DIGITS/pull/732&gt;#732&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='3' author='lukeyeager' date='2016-05-17T19:26:27Z'>
		
I think you meant #732?

Whoops. Indeed!
		</comment>
	</comments>
</bug>