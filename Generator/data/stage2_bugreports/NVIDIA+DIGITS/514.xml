<bug id='514' author='choosehappy' open_date='2016-01-15T00:51:59Z' closed_time='2016-01-15T18:23:05Z'>
	<summary>With encoded datums, Image Dimensions are set to 0x0x0</summary>
	<description>
When generating an LMDB on the command line with the "-encode_type" parameter set (e.g., png, jpg), the associated datums are stored with width/height/channel all equal to zero.
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/9681868/12342399/4ed28da2-bb2a-11e5-90c5-ed6cefb645f2.png&gt;&lt;/denchmark-link&gt;

This causes a set of other bugs:
a) random cropping isn't supported (Digits thinks that the patches are 0x0x0, so any crop size is invalid)
b) "Show visualizations and statistics" return an error "ValueError: unsupported number of channels: 0"
I can think of 3 solutions
a) modify convert_imageset.cpp (or more likely: io.cpp) in caffe such that it correctly sets the patch dimensions
b) modify analyze_db.py such that if it detects datum.encoded=True and datum.width=0, load the image to determine the correct dimensions and then output those instead of the raw values
c) allow the user specify it directly in the UI
I assume the first approach is the optimal one, but i'm unsure if it was left that way intentionally?
	</description>
	<comments>
		<comment id='1' author='choosehappy' date='2016-01-15T18:00:39Z'>
		&lt;denchmark-link:https://github.com/choosehappy&gt;@choosehappy&lt;/denchmark-link&gt;
 thanks for the bug report!
&lt;denchmark-link:https://github.com/NVIDIA/DIGITS/pull/517&gt;#517&lt;/denchmark-link&gt;
 should do the trick - can you try it out for me?
		</comment>
		<comment id='2' author='choosehappy' date='2016-01-15T18:06:34Z'>
		FYI, the DIGITS tool at tools/create_db.py will create the database for you with the shape added. But the Caffe tool is much faster.
		</comment>
		<comment id='3' author='choosehappy' date='2016-01-15T18:23:05Z'>
		yup, that seems to work! it also resolves the other 2 related bugs i mentioned :)
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/9681868/12361086/4aff45b6-bbbc-11e5-82b7-e87cd46fe873.png&gt;&lt;/denchmark-link&gt;

I was getting around to doing it myself, but you beat me to it ;-)
I was thinking about fixing it at the source, convert_imageset.cpp. Then i realized that it likely doesn't support it out of the box because if it sees the files are already encoded, it simply loads them as a byte stream and puts the into the "data" variable. To figure out what the height/width/channel are, it'd have to decode each image. That would likely result in a huge performance hit.
		</comment>
		<comment id='4' author='choosehappy' date='2016-01-15T18:26:26Z'>
		
To figure out what the height/width/channel are, it'd have to decode each image. That would likely result in a huge performance hit.

Yes, and this does result in a huge performance hit on the analysis side of things, too. Make sure you select "No" for "Enforce same shape" when analyzing a database, otherwise it will decode all the images to make sure they all have the same shape!
		</comment>
	</comments>
</bug>