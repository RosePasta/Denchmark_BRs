<bug id='254' author='yankym' open_date='2015-09-01T10:43:37Z' closed_time='2016-02-05T20:59:41Z'>
	<summary>Problem with CPU utilization while creating datasets</summary>
	<description>
is there any difference in the CPU usage in digits v2.2 ?
Cuz while doing Data Pre Processing on v2.1 it did use all my 30 CPU cores and in v2.2 it uses 1 CPU core only.
so it reflects the time remaining.
Thank you very Much.
yanky
	</description>
	<comments>
		<comment id='1' author='yankym' date='2015-09-01T16:04:02Z'>
		What do you mean by "Data Pre Processing"? Are you seeing a difference while creating a dataset in DIGITS, or while training a network with Caffe?
It's certainly possible that this commit may have affected CPU utilization: &lt;denchmark-link:https://github.com/NVIDIA/DIGITS/commit/6003709b5e435ca45677124ff64dab8ca14fbbc6&gt;6003709&lt;/denchmark-link&gt;
.
What do you mean by "it reflects the time remaining"? Is it running faster or slower than before?
		</comment>
		<comment id='2' author='yankym' date='2015-09-01T17:53:40Z'>
		While preparing a dataset via caffe for training, I realized that the processing on Digits 2.1 it utilizes all CPU's and with v2.2 it utilizes one only.
Thank you very much !
		</comment>
		<comment id='3' author='yankym' date='2015-09-01T18:56:31Z'>
		Thank for your fast response :-)
It happens while creating a dataset for caffe training.
And the deference is the CPU used in 2.1 it's full power and in 2.2 1 only :-(
		</comment>
		<comment id='4' author='yankym' date='2015-09-01T19:26:12Z'>
		This seems like a bad thing. &lt;denchmark-link:https://github.com/inovatek&gt;@inovatek&lt;/denchmark-link&gt;
, why are you happy with this?
Here's what I'm seeing when creating an MNIST dataset:



Mode
Max # CPUs used
Creation Time




Multi-writer (before #245)
2
3min, 5sec


Single-writer (after #245)
1
6min, 24sec



On a system with 12 CPU cores, I only saw 2 being used before - not all 12.
		</comment>
		<comment id='5' author='yankym' date='2015-09-01T19:31:02Z'>
		Oh sorry we did realized all 40 CPU's before our update, and right after we got down to one only.
		</comment>
		<comment id='6' author='yankym' date='2015-09-01T19:35:40Z'>
		I can move back to a multi-writer design, but the thing that's throwing me off is this comment:

LMDB is a single-writer design so you wouldn't see any performance gain using multiple writer threads.
jnwatson/py-lmdb#97 (comment)

I'm hoping there will be some computations I can move out of the main thread and into the reader threads without needing to go back to multiple writer threads. I'll look into it some more.
		</comment>
		<comment id='7' author='yankym' date='2015-09-01T19:43:28Z'>
		I really appreciate it.
		</comment>
		<comment id='8' author='yankym' date='2016-01-04T16:17:19Z'>
		Hello,
Has this issue been resolved or addressed?  I'm running a large dataset creation job (~1TB) on an NVIDIA devbox.  With DIGITS version 2.0, this dataset creation made full use of all 12 available CPUs, but with DIGITS version 3.0, it is only making use of a couple CPUs.  With a large dataset creation job like this, the difference in processing time is measured in tens of hours.  Unfortunately, I'm having trouble backtracking to version 2.0.
Thank you for any help!
		</comment>
		<comment id='9' author='yankym' date='2016-01-04T18:53:55Z'>
		Hi &lt;denchmark-link:https://github.com/michaelholm-ce&gt;@michaelholm-ce&lt;/denchmark-link&gt;
, sorry for the inconvenience! I'm looking into this now to see if there's a safe fix to slip in before the final 3.0 release.
To clarify - are you saying that you were seeing a full 1200% CPU utilization in top before the change? Are you seeing more than 100% utilization now? In my initial tests, I'm seeing just over 100% CPU utilization both with DIGITS 2.0 and 3.0, even though multiple cores are technically getting used.
		</comment>
		<comment id='10' author='yankym' date='2016-01-04T19:26:55Z'>
		Thank you, &lt;denchmark-link:https://github.com/lukeyeager&gt;@lukeyeager&lt;/denchmark-link&gt;
.
I seem to remember creating datasets in the past where the cpu's were cranking away at full bore (1200%) to create a set.  However, I don't trust my memory completely.
I was able to get digits-2.0 working since I wrote my post, and did some concrete comparisons:


Digits 2.0:  Uses all 12 cpus, for a net usage of ~700% - 800%.  There is minor variation in usage over time, but all 12 cpu usage plot lines are banded close together.


Digits 3.0:  Uses 6 cpus, for a net usage of ~300%.  Individual cpu usage is not banded together, and usage per cpu varies wildly.


My machine has 6 physical cpus, with another 6 obtained via hyperthreading.
Thanks for your work.
		</comment>
		<comment id='11' author='yankym' date='2016-01-04T21:23:26Z'>
		Thanks for the info - that helps!
I'm able to reproduce what you're seeing when using DIGITS, but not when using tools/create_db.py directly. When I use it directly, I get max 100% utilization for either 2.0 or 3.0. That's weird. Continuing to look into it...
EDIT - oh right, if you don't provide the --shuffle flag, it shifts into single-threaded mode.
		</comment>
		<comment id='12' author='yankym' date='2016-01-04T22:25:39Z'>
		Hey &lt;denchmark-link:https://github.com/michaelholm-ce&gt;@michaelholm-ce&lt;/denchmark-link&gt;
 can you test out my fix at &lt;denchmark-link:https://github.com/NVIDIA/DIGITS/pull/491&gt;#491&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='13' author='yankym' date='2016-01-05T16:06:07Z'>
		Beautiful -- I'm now sailing smooth at ~1100% CPU!  Thank you, &lt;denchmark-link:https://github.com/lukeyeager&gt;@lukeyeager&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='14' author='yankym' date='2016-01-05T17:26:22Z'>
		Excellent!
		</comment>
	</comments>
</bug>