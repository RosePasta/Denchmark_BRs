<bug id='310' author='ajsander' open_date='2015-09-15T14:25:45Z' closed_time='2016-05-18T22:52:28Z'>
	<summary>Getting out of memory error at inference time but very little memory usage</summary>
	<description>
I've trained a couple models (Alexnet and GoogleNet) using DIGITS successfully with statistics shown for test and validation accuracy, but when I try to classify a single image using the web interface I get the following error:
&lt;denchmark-code&gt;WARNING: Logging before InitGoogleLogging() is written to STDERR
F0915 14:10:45.809661 98789 common.cpp:266] Check failed: error == cudaSuccess (2 vs. 0)  out of        memory
*** Check failure stack trace: ***
&lt;/denchmark-code&gt;

When I check nvidia-smi it appears that it the amount of memory is increasing by around 100MB but it's still nowhere near the full memory capacity of the card at 3GB.
	</description>
	<comments>
		<comment id='1' author='ajsander' date='2015-09-15T16:27:58Z'>
		Interesting. You trained the model without memory errors and ran out of memory when testing the model? That doesn't sound right. Are you using the same version of Caffe now as you were when you were training?
I wouldn't expect nvidia-smi to be very useful here. All of the memory allocations should happen very quickly and then release very quickly as soon as the error occurs. So you'd have to run nvidia-smi at just the right time to catch it.
		</comment>
		<comment id='2' author='ajsander' date='2015-09-15T16:31:22Z'>
		Yes, it’s the same version Caffe/DIGITS. I just tried using the test image web UI button and got that error.  I was watching nvidia-smi with the –l option and the memory that’s used doesn’t appear to be released (~90 MB).
From: Luke Yeager &lt;&lt;denchmark-link:mailto:notifications@github.com&gt;notifications@github.com&lt;/denchmark-link&gt;
&lt;denchmark-link:mailto:notifications@github.com&gt;mailto:notifications@github.com&lt;/denchmark-link&gt;
&gt;
Reply-To: NVIDIA/DIGITS &lt;&lt;denchmark-link:mailto:reply@reply.github.com&gt;reply@reply.github.com&lt;/denchmark-link&gt;
&lt;denchmark-link:mailto:reply@reply.github.com&gt;mailto:reply@reply.github.com&lt;/denchmark-link&gt;
&gt;
Date: Tuesday, September 15, 2015 at 12:28 PM
To: NVIDIA/DIGITS &lt;&lt;denchmark-link:mailto:DIGITS@noreply.github.com&gt;DIGITS@noreply.github.com&lt;/denchmark-link&gt;
&lt;denchmark-link:mailto:DIGITS@noreply.github.com&gt;mailto:DIGITS@noreply.github.com&lt;/denchmark-link&gt;
&gt;
Cc: Aaron Sander &lt;&lt;denchmark-link:mailto:Sander_Aaron@bah.com&gt;Sander_Aaron@bah.com&lt;/denchmark-link&gt;
&lt;denchmark-link:mailto:Sander_Aaron@bah.com&gt;mailto:Sander_Aaron@bah.com&lt;/denchmark-link&gt;
&gt;
Subject: [External] Re: [DIGITS] Getting out of memory error at inference time but very little memory usage (&lt;denchmark-link:https://github.com/NVIDIA/DIGITS/issues/310&gt;#310&lt;/denchmark-link&gt;
)
Interesting. You trained the model without memory errors and ran out of memory when testing the model? That doesn't sound right. Are you using the same version of Caffe now as you were when you were training?
I wouldn't expect nvidia-smi to be very useful here. All of the memory allocations should happen very quickly and then release very quickly as soon as the error occurs. So you'd have to run nvidia-smi at just the right time to catch it.
—
Reply to this email directly or view it on GitHubhttps://github.com/&lt;denchmark-link:https://github.com/NVIDIA/DIGITS/issues/310&gt;/issues/310&lt;/denchmark-link&gt;
#issuecomment-140451886.
		</comment>
		<comment id='3' author='ajsander' date='2015-09-15T16:33:39Z'>
		Alright, can you give me a little more information?

GPU[s]
Driver version
CUDA version
cuDNN version
Caffe version
DIGITS version
Network architecture (AlexNet, GoogLeNet, both?)

		</comment>
		<comment id='4' author='ajsander' date='2015-09-15T16:41:52Z'>
		Running on an Amazon g2.8xlarge
GPU[s]: 4x GRID K520
CUDA 7.0
cuDNN 7.0
Caffe version 0.12 NVIDIA fork
DIGITS 2.1
Both Alexnet and GoogleNet Experienced the same problem
From: Luke Yeager &lt;&lt;denchmark-link:mailto:notifications@github.com&gt;notifications@github.com&lt;/denchmark-link&gt;
&lt;denchmark-link:mailto:notifications@github.com&gt;mailto:notifications@github.com&lt;/denchmark-link&gt;
&gt;
Reply-To: NVIDIA/DIGITS &lt;&lt;denchmark-link:mailto:reply@reply.github.com&gt;reply@reply.github.com&lt;/denchmark-link&gt;
&lt;denchmark-link:mailto:reply@reply.github.com&gt;mailto:reply@reply.github.com&lt;/denchmark-link&gt;
&gt;
Date: Tuesday, September 15, 2015 at 12:33 PM
To: NVIDIA/DIGITS &lt;&lt;denchmark-link:mailto:DIGITS@noreply.github.com&gt;DIGITS@noreply.github.com&lt;/denchmark-link&gt;
&lt;denchmark-link:mailto:DIGITS@noreply.github.com&gt;mailto:DIGITS@noreply.github.com&lt;/denchmark-link&gt;
&gt;
Cc: Aaron Sander &lt;&lt;denchmark-link:mailto:Sander_Aaron@bah.com&gt;Sander_Aaron@bah.com&lt;/denchmark-link&gt;
&lt;denchmark-link:mailto:Sander_Aaron@bah.com&gt;mailto:Sander_Aaron@bah.com&lt;/denchmark-link&gt;
&gt;
Subject: [External] Re: [DIGITS] Getting out of memory error at inference time but very little memory usage (&lt;denchmark-link:https://github.com/NVIDIA/DIGITS/issues/310&gt;#310&lt;/denchmark-link&gt;
)
Alright, can you give me a little more information?

GPU[s]
Driver version
CUDA version
cuDNN version
Caffe version
DIGITS version
Network architecture (AlexNet, GoogLeNet, etc.)

—
Reply to this email directly or view it on GitHubhttps://github.com/&lt;denchmark-link:https://github.com/NVIDIA/DIGITS/issues/310&gt;/issues/310&lt;/denchmark-link&gt;
#issuecomment-140453324.
		</comment>
		<comment id='5' author='ajsander' date='2015-09-15T18:12:40Z'>
		I was able to verify the same issue with the v2.0 &lt;denchmark-link:https://developer.nvidia.com/digits&gt;web installer&lt;/denchmark-link&gt;
 as well, which makes this a pretty serious bug. Unfortunately, I don't have time to fight with compilation on AWS right now. I've refiled this bug at &lt;denchmark-link:https://github.com/NVIDIA/caffe/issues/34&gt;NVIDIA/caffe#34&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='6' author='ajsander' date='2015-12-15T19:16:35Z'>
		&lt;denchmark-link:https://github.com/ajsander&gt;@ajsander&lt;/denchmark-link&gt;
 can you try using the v3.0 RC3 deb packages to see if the issue persists?
&lt;denchmark-link:https://github.com/NVIDIA/DIGITS/blob/digits-3.0/docs/UbuntuInstall.md&gt;https://github.com/NVIDIA/DIGITS/blob/digits-3.0/docs/UbuntuInstall.md&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='ajsander' date='2016-05-18T22:52:28Z'>
		I'm going to close this.
A lot of code has changed in cuDNN, Caffe and DIGITS since then. This has likely been fixed. Please reply to this thread if you still see this issue with DIGITS &gt;= 3.0.
		</comment>
		<comment id='8' author='ajsander' date='2017-11-29T09:15:42Z'>
		Hi guys, I'm experiencing the same error and I was wondering if you found a way to fix this.
My info:
Laptop Intel Core i7-6500U CPU @ 2.50 GHzx x 4, 12GB RAM (Ubuntu 16.04, 64b)
GPU: Nvidia BeForce 940M, 2GB
Working with Nvidia-Docker
Caffe: 0.15.14 (Nvidia)
DIGITS: 6.0.0
		</comment>
	</comments>
</bug>