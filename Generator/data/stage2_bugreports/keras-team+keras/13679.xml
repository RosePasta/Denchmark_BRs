<bug id='13679' author='OisinWatkins' open_date='2020-01-09T12:11:12Z' closed_time='2020-02-06T10:56:00Z'>
	<summary>Training Script failed with no Error Stack "exit code 1073740791 0xc0000409"</summary>
	<description>
-Keras Version: 2.3.1
-Tensorflow Version: 2.0
-OS: Windows 10
-Running on: CPU Processor	Intel(R) Core(TM) i7-8850H
-Developed in: PyCharm
I'm attempting to build a novel model using an implementation of a highway layer (implementation found at: &lt;denchmark-link:https://gist.github.com/iskandr/a874e4cf358697037d14a17020304535&gt;https://gist.github.com/iskandr/a874e4cf358697037d14a17020304535&lt;/denchmark-link&gt;
). There was a typo listed on this page which is corrected in my copy of the code.
I have a simplified version of the code I'm using below:
import scipy.io as io
import os
import numpy as np
from keras import layers, losses, Input
from keras.models import Model
from keras2_highway_network import highway_layers

def simple_generator(dim1, dim2, dim3, batch_size=5):
    while True:
        samples = np.random.random_sample((batch_size, dim1, dim2, dim3))
        targets = np.random.random_sample((batch_size, 3))
        yield samples, targets

example_shape = (1100, 4096, 2)

train_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2], batch_size=10)
val_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2])
test_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2])

input_tensor = Input(shape=example_shape)
x = layers.Conv2D(32, 3, activation='relu')(input_tensor)
x = layers.MaxPool2D(pool_size=(3, 3), strides=3)(x)
x = layers.Dense(32, activation='relu')(x)
x = highway_layers(x, 32, activation='relu')
x = highway_layers(x, 32, activation='relu')
x = highway_layers(x, 32, activation='relu')
x = layers.Conv2D(32, 3, activation='relu')(x)
x = layers.MaxPool2D(pool_size=(3, 3), strides=3)(x)
x = layers.Dense(16, activation='relu')(x)
x = highway_layers(x, 16, activation='relu')
x = highway_layers(x, 16, activation='relu')
x = highway_layers(x, 16, activation='relu')
x = layers.Flatten()(x)
output_tensor = layers.Dense(3)(x)

model = Model(input_tensor, output_tensor)

model.compile(loss=losses.mean_absolute_error, optimizer='sgd')
model.summary()

history = model.fit_generator(generator=train_gen, steps_per_epoch=25, epochs=12, validation_data=val_gen, validation_steps=10, verbose=True)
The resulting network has around 2.5 million parameters, which despite the warnings my machine prints it can handle no problem. Once training begins I get a warning about the amount of memory I'm using, which I expect, and then the script simply stops running. The only stack trace I get is: "exit code 1073740791 0xc0000409"
I have seen this is one other issue that was raised in this git, however it has been tagged as "stale" with no answer posted, so I thought I'd ask again.
Thanks in advance for your time!
All the best,
Ois√≠n.
	</description>
	<comments>
		<comment id='1' author='OisinWatkins' date='2020-01-10T10:04:19Z'>
		As a follow-up, I have since attempted to design another multi-input network using the Keras functional API. The exact same issue occurred:
&lt;denchmark-code&gt;Process finished with exit code -1073740791 (0xC0000409)
&lt;/denchmark-code&gt;

No other information is provided. Is this an issue with the Keras functional API?
		</comment>
		<comment id='2' author='OisinWatkins' date='2020-01-29T10:34:33Z'>
		I've tried another simple network layout, exactly the same problem, this with only in-built keras layers:
import scipy.io as io
import os
import numpy as np
from tensorflow.keras import layers, losses, Input
from tensorflow.keras.models import Model

directory = 'C:\\Dataset'

def simple_generator(dim1, dim2, dim3, batch_size=5):
    while True:
        samples = np.random.random_sample((batch_size, dim1, dim2, dim3))
        targets = np.random.random_sample((batch_size, 3))
        yield samples, targets

example_shape = (1100, 4096, 2)

train_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2], batch_size=10)
val_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2])
test_gen = simple_generator(example_shape[0], example_shape[1], example_shape[2])

input_tensor = Input(shape=example_shape)
preprocess = layers.Conv2D(32, 3, activation='relu')(input_tensor)
preprocess = layers.Conv2D(32, 3, activation='relu')(preprocess)
preprocess = layers.MaxPool2D(pool_size=(3, 3), strides=3)(preprocess)

"""   Head 1   """
head_1 = layers.Conv2D(32, 3, activation='relu')(preprocess)
head_1 = layers.Conv2D(32, 3, activation='relu')(head_1)
head_1 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_1)
head_1 = layers.Conv2D(32, 3, activation='relu')(head_1)
head_1 = layers.Conv2D(32, 3, activation='relu')(head_1)
head_1 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_1)
head_1 = layers.Conv2D(16, 3, activation='relu')(head_1)
head_1 = layers.Conv2D(16, 3, activation='relu')(head_1)
head_1 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_1)
head_1 = layers.Dense(8, activation='relu')(head_1)

"""   Head 2   """
head_2 = layers.Conv2D(32, 3, activation='relu')(preprocess)
head_2 = layers.Conv2D(32, 3, activation='relu')(head_2)
head_2 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_2)
head_2 = layers.Conv2D(32, 3, activation='relu')(head_2)
head_2 = layers.Conv2D(32, 3, activation='relu')(head_2)
head_2 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_2)
head_2 = layers.Conv2D(16, 3, activation='relu')(head_2)
head_2 = layers.Conv2D(16, 3, activation='relu')(head_2)
head_2 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_2)
head_2 = layers.Dense(8, activation='relu')(head_2)

"""   Head 3   """
head_3 = layers.Conv2D(32, 3, activation='relu')(preprocess)
head_3 = layers.Conv2D(32, 3, activation='relu')(head_3)
head_3 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_3)
head_3 = layers.Conv2D(32, 3, activation='relu')(head_3)
head_3 = layers.Conv2D(32, 3, activation='relu')(head_3)
head_3 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_3)
head_3 = layers.Conv2D(16, 3, activation='relu')(head_3)
head_3 = layers.Conv2D(16, 3, activation='relu')(head_3)
head_3 = layers.MaxPool2D(pool_size=(3, 3), strides=3)(head_3)
head_3 = layers.Dense(8, activation='relu')(head_3)

concat_out = layers.Concatenate(axis=-1)([head_1, head_2, head_3])
concat_out = layers.Flatten()(concat_out)
output_tensor = layers.Dense(3)(concat_out)
model = Model(input_tensor, output_tensor)

model.compile(loss=losses.mean_absolute_error, optimizer='sgd')
model.summary()

history = model.fit(x=train_gen, steps_per_epoch=25, epochs=12, validation_data=val_gen, validation_steps=10, verbose=True)
model.save(directory + '\\divergent_network.h5')
evaluations = model.evaluate_generator(generator=test_gen, steps=20, verbose=True)
print(evaluations)
Any advice?
		</comment>
		<comment id='3' author='OisinWatkins' date='2020-02-06T10:56:00Z'>
		It seems to have been an issue with my conda environment. I made a new "bare minimum" environment with only the packages I needed and that cleared everything up. The info I used to do this can be found at:
&lt;denchmark-link:https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands&gt;https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands&lt;/denchmark-link&gt;

&lt;denchmark-link:https://www.jetbrains.com/help/pycharm/creating-virtual-environment.html&gt;https://www.jetbrains.com/help/pycharm/creating-virtual-environment.html&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>