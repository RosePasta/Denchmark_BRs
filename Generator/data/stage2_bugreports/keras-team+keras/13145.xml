<bug id='13145' author='pekaalto' open_date='2019-07-24T13:10:41Z' closed_time='2020-12-06T05:05:27Z'>
	<summary>Keras doesn't learn properly when tensor is passed to custom-layer by key-word argument</summary>
	<description>
When I pass tensor to layer by keyword arguments the learning sometimes doesn't happen properly.
I would expect it not to matter if keyword or non-keyword argument is used as long as the model logic is unchanged.  Example below demonstrates that the learning doesn't happen properly for tensors passed by keyword arguments.
System information

Have I written custom code (as opposed to using example directory): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  happens everywhere - tested in colab and os x
TensorFlow backend (yes / no):   yes
TensorFlow version:  1.14.0
Keras version:  2.2.4-tf
Python version:  3.6

Describe the current behavior
Keras doesn't learn properly when tensor is passed to custom layer by keyword argument.
Below all the models should produce roughly same accuracy or loss. However when use MyLayer the loss is clearly higher than in other two case even though it shouldn't affect the model structure.
Describe the expected behavior
Learning shouldn't be affected if use keyword arguments or not as long as the logic is the same.
Code to reproduce the issue
Note that layer_type=1 gives much higher loss even though all the models are logically the same.
Colab: &lt;denchmark-link:https://colab.research.google.com/drive/19iqhjJm2N8yOwVzdDK8j9yRNNdw7whZn&gt;https://colab.research.google.com/drive/19iqhjJm2N8yOwVzdDK8j9yRNNdw7whZn&lt;/denchmark-link&gt;

Code
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
import sys
from tensorflow.python.keras import layers, callbacks
from tensorflow.python.keras.losses import MeanSquaredError
from tensorflow.python.training.gradient_descent import GradientDescentOptimizer

print(tf.__version__)
print(tf.keras.__version__)
print(sys.version)

N = 10000
FEATURES_D = 12


class MyLayer(tf.keras.layers.Layer):
    def call(self, inputs, mask=None, t=None):
        return t

class MyLayer2(tf.keras.layers.Layer):
    def call(self, inputs, mask=None, t=None):
        return inputs


np.random.seed(0)
X1 = np.random.rand(N, FEATURES_D)
X2 = np.random.rand(N, FEATURES_D)
W = np.random.randn(FEATURES_D)
y = X1.dot(W) + np.random.randn(N)


def model(layer_type):
    x1 = tf.keras.Input(shape=FEATURES_D)
    x2 = tf.keras.Input(shape=FEATURES_D)

    x11 = layers.Dense(10)(x1)

    if layer_type == 1:
        x11 = MyLayer()(x2, t=x11)
    elif layer_type == 2:
        x11 = MyLayer2()(x11, t=x2)

    out = layers.Dense(1)(x11)

    model = tf.keras.Model(inputs=[x1, x2], outputs=out)
    model.compile(optimizer=GradientDescentOptimizer(0.01), loss=MeanSquaredError())

    h: callbacks.History = model.fit(
        [X1, X2], y=y, batch_size=256, epochs=10, verbose=0
    )
    return h.history["loss"][-1]


for _ in range(3):
    for layer_type in [0, 1, 2]:
        print(f"{layer_type} - {model(layer_type)}")

    print("---")

&lt;/denchmark-code&gt;

output:
&lt;denchmark-code&gt;1.14.0
2.2.4-tf
3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
WARNING: Logging before flag parsing goes to stderr.
W0724 20:09:44.047463 4648408512 deprecation.py:506] From /anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2019-07-24 20:09:44.151038: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
0 - 1.0245165932655333
1 - 1.788629257965088
2 - 1.0349093259811402
---
0 - 1.0278864135742187
1 - 1.6075011337280274
2 - 1.0326046692848205
---
0 - 1.0317546758651734
1 - 1.3196803382873534
2 - 1.0330685680389404
---
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='pekaalto' date='2020-12-06T05:05:27Z'>
		This problem doesn't happen with TF 2.3 anymore.  The exact same code from OP gives now result:
&lt;denchmark-code&gt;2.3.1
2.4.0
3.8.5 (default, Aug  5 2020, 03:39:04) 
[Clang 10.0.0 ]
2020-12-06 12:02:16.072480: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-06 12:02:16.085526: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e25dd4870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-06 12:02:16.085538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
0 - 1.0734927654266357
1 - 1.0606768131256104
2 - 1.0399056673049927
---
0 - 1.026423454284668
1 - 1.0261292457580566
2 - 1.0366202592849731
---
0 - 1.0420615673065186
1 - 1.0303572416305542
2 - 1.0842583179473877
---
&lt;/denchmark-code&gt;

So all models have roughly same loss and accuracy as expected. I don't know what was the problem but it has now gone.
		</comment>
	</comments>
</bug>