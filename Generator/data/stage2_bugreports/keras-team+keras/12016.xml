<bug id='12016' author='tik0' open_date='2019-01-10T16:30:46Z' closed_time='2019-01-10T20:22:54Z'>
	<summary>metrics are not evaluated if loss is None</summary>
	<description>


[x ] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps


[ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found here.


[ x] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


Using the &lt;denchmark-link:https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py&gt;VAE example from Keras&lt;/denchmark-link&gt;
, one can easily reproduce the effect that any metric defined in the  call will not be evaluated if the  argument is None. For instance, substituting  in &lt;denchmark-link:https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py#L188&gt;line 188&lt;/denchmark-link&gt;
 with
&lt;denchmark-code&gt;    def kl_loss_fun(y_true, y_pred):
        return kl_loss
    def reconstruction_loss_fun(y_true, y_pred):
        return reconstruction_loss
    vae.compile(optimizer='adam', metrics=[kl_loss_fun, reconstruction_loss])
&lt;/denchmark-code&gt;

shows no output of the metrics when fit is called.
I found out that, if &lt;denchmark-link:https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L37&gt;compile&lt;/denchmark-link&gt;
 is called, that the metrics are just skipped if the corresponding loss per output is None in &lt;denchmark-link:https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L443&gt;line 443&lt;/denchmark-link&gt;
. Removing the conditional fixes the issue!
So the main question is, why is the calculation of the metric conditioned on the losses at all? If the user demands it explicitly it should not depend on the loss which is given in the compile call.
	</description>
	<comments>
		<comment id='1' author='tik0' date='2019-01-10T18:18:30Z'>
		This seems very strange. Fix welcome. Can you provide a small and standalone script which would serve as a test to reproduce the issue? Thanks!
		</comment>
		<comment id='2' author='tik0' date='2019-01-10T19:26:12Z'>
		it's a known issue when you add loss with add_loss function.  You can share model weights with a different model compiled in a regular was (using loss='something') and use it to evaluate metrics.
		</comment>
		<comment id='3' author='tik0' date='2019-01-10T20:13:58Z'>
		&lt;denchmark-link:https://github.com/sakvaua&gt;@sakvaua&lt;/denchmark-link&gt;
 this sounds a bit overengineered. It would be more straight forward to evaluate the metric in a callback instead of defining a model with a mockup-loss to actually evaluate the desired metric. Anyway, the question remains concerning &lt;denchmark-link:https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L443&gt;line 443&lt;/denchmark-link&gt;
: Wouldn't removing the conditional fix this issue?
		</comment>
		<comment id='4' author='tik0' date='2019-01-10T20:22:50Z'>
		Just found an open issue concerning this topic: &lt;denchmark-link:https://github.com/keras-team/keras/issues/9459&gt;#9459&lt;/denchmark-link&gt;
.
I will therefore close this issue!
		</comment>
	</comments>
</bug>