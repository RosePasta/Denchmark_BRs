<bug id='6173' author='drscotthawley' open_date='2017-04-06T04:39:47Z' closed_time='2017-04-10T22:56:11Z'>
	<summary>K.batch_dot() doc example fails w/ Tensorflow backend</summary>
	<description>
From the batch_dot section of the Backend docs (&lt;denchmark-link:https://keras.io/backend/&gt;https://keras.io/backend/&lt;/denchmark-link&gt;
):

Shape inference: Let x's shape be (100, 20) and y's shape be (100, 30, 20). If axes is (1, 2), to find the output shape of resultant tensor, loop through each dimension in x's shape and y's shape:
x.shape[0] : 100 : append to output shape
x.shape[1] : 20 : do not append to output shape, dimension 1 of x has been summed over. (dot_axes[0] = 1)
y.shape[0] : 100 : do not append to output shape, always ignore first dimension of y
y.shape[1] : 30 : append to output shape
y.shape[2] : 20 : do not append to output shape, dimension 2 of y has been summed over. (dot_axes[1] = 2) output_shape = (100, 30)


Actually running this (see below code) produces errors when using the newest Tensorflow.  Seems to be ok with Theano.
Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on &lt;denchmark-link:http://stackoverflow.com/questions/tagged/keras&gt;StackOverflow&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://keras-slack-autojoin.herokuapp.com/&gt;join the Keras Slack channel&lt;/denchmark-link&gt;
 and ask there instead of filing a GitHub issue.
Thank you!


 Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps


 If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.


 If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps


 Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


&lt;denchmark-code&gt;from keras import backend as K

x = K.ones(shape=(100,20))
y = K.ones(shape=(100,30,20))
xy = K.batch_dot(x,y,axes=(1,2))
&lt;/denchmark-code&gt;

Fails with...
Using TensorFlow backend.
Traceback (most recent call last):
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py", line 671, in _call_cpp_shape_fn_impl
input_tensors_as_shapes, status)
File "/opt/anaconda/envs/py35/lib/python3.5/contextlib.py", line 66, in exit
next(self.gen)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py", line 466, in raise_exception_on_not_ok_status
pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [100,20], [100,30,20].
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "batch_dot_test.py", line 6, in 
xy = K.batch_dot(x,y,axes=(1,2))
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py", line 917, in batch_dot
out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py", line 1801, in matmul
a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py", line 1263, in _mat_mul
transpose_b=transpose_b, name=name)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py", line 768, in apply_op
op_def=op_def)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 2338, in create_op
set_shapes_for_outputs(ret)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 1719, in set_shapes_for_outputs
shapes = shape_func(op)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 1669, in call_with_requiring
return call_cpp_shape_fn(op, require_shape_fn=True)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py", line 610, in call_cpp_shape_fn
debug_python_shape_fn, require_shape_fn)
File "/opt/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py", line 676, in _call_cpp_shape_fn_impl
raise ValueError(err.message)
ValueError: Shape must be rank 2 but is rank 3 for 'MatMul' (op: 'MatMul') with input shapes: [100,20], [100,30,20].
When using Theano, no output appears at all, indicating success.
	</description>
	<comments>
		<comment id='1' author='drscotthawley' date='2017-04-06T04:57:04Z'>
		just passing x = K.ones(shape=(100,20,1)) resolves this issue.
From keras.backend.tensorflow_backend.py



x_batch = K.ones(shape=(32, 20, 1))
y_batch = K.ones(shape=(32, 30, 20))
xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])
K.int_shape(xy_batch_dot)
(32, 1, 30)



		</comment>
		<comment id='2' author='drscotthawley' date='2017-04-09T03:38:34Z'>
		True, that is a viable workaround, however that is not what the documentation says -- as it stands, there's a contradiction.  And it's not what happens with the Theano backend.  Plus your result produces the wrong number of dimensions; it would need a call to reshape() at the end.
		</comment>
		<comment id='3' author='drscotthawley' date='2017-04-09T21:25:44Z'>
		Can someone please investigate what a solution would look like?
		</comment>
		<comment id='4' author='drscotthawley' date='2017-04-10T18:58:06Z'>
		To me, it is not a bug in code though but somehow inconsistency in the documents. The code example in the official site &lt;denchmark-link:https://keras.io/backend/&gt;https://keras.io/backend/&lt;/denchmark-link&gt;
, which only appears in the docstring in tensorflow backend, actually implies the fact that x and y should be of the same rank.
Theano backend uses  to implement  which happens to help you expand the missing dim if applicable. While in the tensorflow backend, I don't think this is ever supported, no matter using  or latest . Specifically, see &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/matmul&gt;tf.matmul&lt;/denchmark-link&gt;
,
.

It is possible to manually fix this, possibly add as below to (&lt;denchmark-link:https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L911&gt;https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L911&lt;/denchmark-link&gt;
)
        if ndim(x) &lt; ndim(y):
            x = tf.expand_dims(x, axis=ndim(x) if axes[0] == ndim(x) - 1 else ndim(x))
        if ndim(y) &lt; ndim(x):
            y = tf.expand_dims(y, axis=ndim(y) if axes[1] == ndim(y) - 1 else ndim(y))
        
        if axes is not None:
            adj_x = None if axes[0] == ndim(x) - 1 else True
        ....
Use ndim(x)-1 not hard code1 or 2 because tf.matmul now supports the input to have more than 3 ranks. Or would it be better we raise an error to both backends to notify that the inputs x and y should be of the same rank?
if ndim(x) != ndim(y):
     raise ValueError("Inputs should have same ranks but are " + str(ndim(x)) + " and " + str(ndim(y)) + ".")
I am not sure which way is better and the first solution need more checks for conditions.
		</comment>
		<comment id='5' author='drscotthawley' date='2017-04-10T20:54:09Z'>
		&lt;denchmark-link:https://github.com/keras-team/keras/pull/6219&gt;#6219&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>