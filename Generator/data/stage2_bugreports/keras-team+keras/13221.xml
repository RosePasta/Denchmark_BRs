<bug id='13221' author='OverLordGoldDragon' open_date='2019-08-15T21:36:08Z' closed_time='2020-01-09T03:18:15Z'>
	<summary>'recurrent_dropout' with 'relu' in LSTM yields NaNs</summary>
	<description>
Any non-zero recurrent_dropout yields NaN losses and weights; latter are either 0 or NaN. Happens for stacked, shallow, stateful, return_sequences = any, with &amp; w/o Bidirectional(), activation='relu', loss='binary_crossentropy'. NaNs occur within a few batches - the more layers, the sooner.
Any fixes? Help's appreciated.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

TROUBLESHOOTING ATTEMPTED
:


recurrent_dropout=0.2,0.1,0.01,1e-6
kernel_constraint=maxnorm(0.5,axis=0)
recurrent_constraint=maxnorm(0.5,axis=0)
clipnorm=50  (empirically determined), Nadam optimizer
activation='tanh' - no NaNs, weights stable, tested for up to 10 batches
lr=2e-6,2e-5 - no NaNs, weights stable, tested for up to 10 batches
lr=5e-5 - no NaNs, weights stable, for 3 batches - NaNs on batch 4

NOTE: batch_shape=(32,672,16), 17 calls to train_on_batch per batch
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

ENVIRONMENT
:


Keras 2.2.4 (TensorFlow backend), Python 3.7, Spyder 3.3.7 via Anaconda
GTX 1070 6GB, i7-7700HQ, 12GB RAM, Win-10.0.17134 x64
CuDNN 10+, latest Nvidia drives

	</description>
	<comments>
		<comment id='1' author='OverLordGoldDragon' date='2019-08-16T07:59:53Z'>
		Do you have a minimal reproducible example?
		</comment>
		<comment id='2' author='OverLordGoldDragon' date='2019-08-16T21:49:04Z'>
		Before I get a minimal reproducible code, some important results:
Model divergence is spontaneous, occurring at different train updates even with fixed seeds - Numpy, Random, and TensorFlow random seeds. Furthermore, when first diverging, LSTM layer weights are all normal - only going to NaN later.
Below are, in order: (1) inputs to LSTM; (2) LSTM outputs; (3) Dense(1,'sigmoid') outputs -- the three are consecutive, with Dropout(0.5) between each. Preceding (1) are Conv1D layers. Right: LSTM weights. "BEFORE" = 1 train update before; "AFTER = 1 train update after
:
&lt;denchmark-link:https://user-images.githubusercontent.com/16495490/63199693-a9c7c580-c04c-11e9-9396-b77079352720.png&gt;&lt;/denchmark-link&gt;

:
&lt;denchmark-link:https://user-images.githubusercontent.com/16495490/63199806-fca17d00-c04c-11e9-9224-be21a1c2d1c8.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;## LSTM outputs, flattened, stats
(mean,std)        = (inf,nan)
(min,max)         = (0.00e+00,inf)
(abs_min,abs_max) = (0.00e+00,inf)
&lt;/denchmark-code&gt;

:
&lt;denchmark-link:https://user-images.githubusercontent.com/16495490/63200017-9c5f0b00-c04d-11e9-87e5-9ace4cbf9407.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;## Recurrent Gates Weights:
array([[nan, nan, nan, ..., nan, nan, nan],
       [ 0.,  0., -0., ..., -0.,  0.,  0.],
       [ 0., -0., -0., ..., -0.,  0.,  0.],
       ...,
       [nan, nan, nan, ..., nan, nan, nan],
       [ 0.,  0., -0., ..., -0.,  0., -0.],
       [ 0.,  0., -0., ..., -0.,  0.,  0.]], dtype=float32)
## Dense Sigmoid Outputs:
array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='OverLordGoldDragon' date='2019-08-16T23:44:19Z'>
		&lt;denchmark-link:https://github.com/Rainymood&gt;@Rainymood&lt;/denchmark-link&gt;
 :
&lt;denchmark-code&gt;from keras.layers import Input,Dense,LSTM,Dropout
from keras.models import Model
from keras.optimizers  import Nadam 
from keras.constraints import maxnorm
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;ipt = Input(batch_shape=(32,672,16))
x = LSTM(512,activation='relu',return_sequences=False,
             recurrent_dropout=1e-6,
             kernel_constraint   =maxnorm(0.5,axis=0),
             recurrent_constraint=maxnorm(0.5,axis=0))(ipt)
out = Dense(1,activation='sigmoid')(x)

model = Model(ipt,out)
optimizer = Nadam(lr=2e-4,clipnorm=1)
model.compile(optimizer=optimizer,loss='binary_crossentropy')
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;for train_update,_ in enumerate(range(100)):
    x = np.random.randn(32,672,16)
    y = np.array([1]*5 + [0]*27)
    np.random.shuffle(y)
    loss = model.train_on_batch(x,y)
    print(train_update+1,loss,np.sum(y))
&lt;/denchmark-code&gt;

Observations: the following speed up divergence:

Higher units (LSTM)
Higher # of layers (LSTM)
Higher lr &lt;&lt; no divergence when &lt;=1e-4, tested up to 400 trains
Less '1' labels &lt;&lt; no divergence with y below, even with lr=1e-3; tested up to 400 trains

y = np.random.randint(0,2,32) # makes more '1' labels
		</comment>
		<comment id='4' author='OverLordGoldDragon' date='2019-08-18T20:53:31Z'>
		UPDATE: Does NOT occur with GRUs. No clue why.
Also, only recurrent weights fail - I never observed kernel or bias NaNs. And, with Bidirectional, both or one direction can diverge:
&lt;denchmark-link:https://user-images.githubusercontent.com/16495490/63230488-50da6780-c1db-11e9-8701-765b16b79e08.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='OverLordGoldDragon' date='2019-08-29T01:49:29Z'>
		Update: Happens with activation='tanh' also - simply spontaneously, don't even know how to reproduce. Further, NaNs happen above a threshold of lr, recurrent_dropout and timesteps - in my case, 1e-3, .45, and 675
		</comment>
		<comment id='6' author='OverLordGoldDragon' date='2019-09-16T04:59:17Z'>
		Any progress on this? I encountered a new unique instance: validation NaNs, while train is fine - bizarre case, don't know how to reproduce minimally
		</comment>
		<comment id='7' author='OverLordGoldDragon' date='2020-01-09T03:18:15Z'>
		&lt;denchmark-link:https://stackoverflow.com/questions/57516678/lstm-recurrent-dropout-with-relu-yields-nans/59656753#59656753&gt;Solved&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='8' author='OverLordGoldDragon' date='2020-01-09T03:18:16Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/keras-team/keras/issues/13221&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/keras-team/keras/issues/13221&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>