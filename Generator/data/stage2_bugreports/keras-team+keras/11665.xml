<bug id='11665' author='mawright' open_date='2018-11-18T07:38:53Z' closed_time='2018-11-25T14:51:06Z'>
	<summary>Poor memory performance of K.batch_dot under tensorflow backend relative to batched tf.matmul</summary>
	<description>


[ x] Check that you are up-to-date with the master branch of Keras. You can update with:
pip install git+git://github.com/keras-team/keras.git --upgrade --no-deps


[ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found here.


[x ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).


I am performing batch matrix multiplies of two tensors of size (batch, N, M) and (batch, M, K) to get a tensor of size (batch, N, K), with the matrix products. This behavior can be done with both tf.matmul and K.batch_dot with the default axis arguments.
However in K.batch_dot, the elementwise multiplication in the line 


keras/keras/backend/tensorflow_backend.py


         Line 1248
      in
      75a3503






 result = tf.reduce_sum(x * y, 1) 




 eats up a lot of memory. The elementwise multiplication followed by summing over an axis is of course mathematically equivalent to the matrix multiply, but in the two-step implementation, Tensorflow assigns memory to the intermediate very large tensor.
In this simple example, my small GPU (Nvidia 970) is able to perform the calculation using tf.matmul, but using K.batch_dot Tensorflow fails with an OOM error.
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from keras import backend as K

a = np.random.normal(size=(100, 500, 10000)).astype(np.float32)
b = np.random.normal(size=(100, 10000, 32)).astype(np.float32)

a_t = K.placeholder(a.shape)
b_t = K.placeholder(b.shape)

td = tf.matmul(a_t, b_t)
bd = K.batch_dot(a_t, b_t)

sess = K.get_session()
sess.run(td, feed_dict={a_t: a, b_t: b})
sess.run(bd, feed_dict={a_t: a, b_t: b})
&lt;/denchmark-code&gt;

This fails when it tries to assign a tensor of size (100, 10000, 500, 32) in the elementwise multiply in batch_dot (the dimension of 10000 not being strictly necessary in this case since we are only interested in the sum).
	</description>
	<comments>
		<comment id='1' author='mawright' date='2018-11-20T23:10:48Z'>
		Thanks for reporting. Will fix in Keras this Saturday.
		</comment>
		<comment id='2' author='mawright' date='2018-11-23T22:58:44Z'>
		&lt;denchmark-link:https://github.com/keras-team/keras/pull/11719&gt;#11719&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>