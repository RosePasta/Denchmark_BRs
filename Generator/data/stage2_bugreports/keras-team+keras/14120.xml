<bug id='14120' author='VukanJ' open_date='2020-06-15T21:38:19Z' closed_time='2020-10-01T22:56:48Z'>
	<summary>Twice as many bias elements in GRU layer weight file</summary>
	<description>
System information

Have I written custom code (as opposed to using example directory):  yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  ArchLinux 5.4.46-1-lts
TensorFlow backend (yes / no):  yes
TensorFlow version:  2.2.0
Keras version:  2.3.0-tf
Python version:  3.6
CUDA/cuDNN version:
GPU model and memory:

Describe the current behavior
I have noticed, that when a gru layer is saved to a file, two almost identical bias vectors are written to the weight file, even though one of them would be enough. The bias data has the dimension (2x3*kernel_row_dimension) = rank 2. I am not sure whether this is intended, but I think that this is unlikely, given that only one set of kernel tensors is saved.
Describe the expected behavior
The bias tensor should be of rank 1
Code to reproduce the issue
from tensorflow.keras.layers import Input, GRU
from tensorflow.keras.models import Sequential
model = Sequential([Input((3, 12, )), GRU(3)])
model.save_weights("test.h5")

import h5py
F = h5py.File("test.h5", "r")
F["gru"]["gru"]["gru_cell"]["bias:0"]
The output is
&lt;denchmark-code&gt;&lt;HDF5 dataset "bias:0": shape (2,9), type "&lt;f4"&gt;
&lt;/denchmark-code&gt;

Whereas I would expect to see something like (1, 9) since for a GRU 3 operations of the form activation(W x input + U x hidden + b) are evaluated, and since dim(hidden) and dim(input) is 3 here, the bias should store 9 elements in total. When the model is trained beforehand, the two bias vectors stored in the two rows are almost identical and can diverge on the order of a few % for increasing vector indices (I tested this with a bias vector of length 32).
	</description>
	<comments>
	</comments>
</bug>