<bug id='12274' author='ceroxlol' open_date='2019-02-14T17:17:41Z' closed_time='2019-02-15T20:25:49Z'>
	<summary>Loss on last training step and sklearn calculated log_loss differ, but validation_loss doesn't</summary>
	<description>
Hi,
I am using Keras 2.2.4, tensorflow 1.12.0.
I am experiencing a problem, where I use the sklearn.metrics log_loss function on my training and validation data to calculate the loss. Upon comparing it to the result that model.fit prints in the last step, I realized that the validation losses of the model.fit and log_loss function are identical (which they should be), but for the training data, they aren't.
I reproduced the issue on a simple iris network.
The model is set up via
train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y,test_size = 0.1, random_state = 0)
input_dim = len(data.columns) - 1
model = Sequential()
model.add(Dense(8, input_dim = input_dim , activation = 'relu'))
model.add(Dense(10, activation = 'relu'))
model.add(Dense(10, activation = 'relu'))
model.add(Dense(10, activation = 'relu'))
model.add(Dense(3, activation = 'softmax'))
model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' )
validation_data = (test_x, test_y)
model.fit(train_x, train_y, epochs = 1, batch_size = 2, validation_data=validation_data)
and afterwards the losses are calculated like this:
p = model.predict_proba(train_x, batch_size=2)
ll = log_loss(train_y, p)
p = model.predict_proba(test_x, batch_size=2)
ll = log_loss(test_y, p)
The generated output then is:
2/127 [..............................] - ETA: 30s - loss: 0.0097
66/127 [==============&gt;...............] - ETA: 0s - loss: 2.4860
127/127 [==============================] - 1s 5ms/step - loss: 1.8052 - val_loss: 0.9724
# training | log loss: 0.98358043, AUC: 69.53%, accuracy: 0.00%
# testing  | log loss: 0.97241303, AUC: 73.33%, accuracy: 0.00%
Any ideas on why the testing/validation loss are equal, but test loss isn't?
	</description>
	<comments>
		<comment id='1' author='ceroxlol' date='2019-02-14T18:52:29Z'>
		&lt;denchmark-link:https://keras.io/getting-started/faq/#why-is-the-training-loss-much-higher-than-the-testing-loss&gt;https://keras.io/getting-started/faq/#why-is-the-training-loss-much-higher-than-the-testing-loss&lt;/denchmark-link&gt;
 does that answer your question?
		</comment>
		<comment id='2' author='ceroxlol' date='2019-02-14T19:12:53Z'>
		Hi,
nope, not at all. I am not wondering on differences between training and testing loss. I am wondering on differences in training and training loss. keras suggests the loss on the training is 1.8052 and SKlearn with log_loss suggests it is 0.98358043.
		</comment>
		<comment id='3' author='ceroxlol' date='2019-02-14T20:14:06Z'>
		Ho I see, sorry, I was way too quick to read.
klearn and keras functions can give different results. The functions having the same name doesn't mean that they behave in the same way. There can be many differences (from logit or not expecially).
We currently test that the results of the categorical crossentropy on all backends matches exactly the results of this numpy implementation:



keras/keras/backend/numpy_backend.py


         Line 327
      in
      05d7135






 def categorical_crossentropy(target, output, from_logits=False): 





Those tests are run at every commit.
If you think that this numpy implementation is incorrect, then there is a problem in keras, otherwise, it's just that sklearn uses a different implementation than this one for their function.
		</comment>
		<comment id='4' author='ceroxlol' date='2019-02-14T21:35:14Z'>
		No problem!
Sure, I understand that there might be different kinds of implementation on each side and that the outcomes of these may differ. Yet, those two approaches match in one result exactly and differ a lot in the other, which is very weird in my opinion.
So, if I will calculate my loss with the categorical_crossentropy from numpy, I should get the same results for both losses and not just one.
		</comment>
		<comment id='5' author='ceroxlol' date='2019-02-14T22:14:57Z'>
		Can you do model.evaluate on your training set and see what you get? Also in the model.fit a rolling average is done for the training loss (written in the FAQ). That might explain some things.
		</comment>
		<comment id='6' author='ceroxlol' date='2019-02-15T07:40:42Z'>
		I get exactly the value I computed via the sklearn log_loss function.
But shouldn't the loss value at the last step of training, that is written right next to the val_loss, be the one that is received by model.evaluate?
Because this is rather confusing having a rolling average loss for the test right next to the validation loss.
		</comment>
		<comment id='7' author='ceroxlol' date='2019-02-15T08:35:22Z'>
		Can you suggest another method?

If we do a normal average, the result will still be different from sklearn. This is because the weights of the model are changing during the epoch.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, 15 Feb 2019, 08:42 ceroxlol, ***@***.***&gt; wrote:
 I get exactly the value I computed via the sklearn log_loss function.
 But shouldn't the loss value at the last step of training, that is written
 right next to the val_loss, be the one that is received by model.evaluate?
 Because this is rather confusing having a rolling average loss for the
 test right next to the validation loss.

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;#12274 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AMS2K_YvfcB2ktuIL2eaZlPdDY-Cry0uks5vNmT2gaJpZM4a8EBh&gt;
 .



		</comment>
		<comment id='8' author='ceroxlol' date='2019-02-15T10:15:19Z'>
		I am definitely not advanced enough in deep learning yet to propose another method on this.
But, I did further investigations on the issue and I was able to create a case, which just can't exist.
I took the iris dataset and set the input to one single sample with a batch_size of 1 for the network.
So, one would assume that loss during the training and the model evaluation afterwards should be the same, because there is only one sample that causes a loss in one batch, but this isn't true.
the model.fit printed this:
1/1 [==============================] - 1s 581ms/step - loss: 0.5553 - val_loss: 0.8605
and the model.evaluate this:
1/1 [==============================] - 0s 727us/step
0.5386354327201843
and the log_loss for training:
0.5386353731155396
testing:
0.8759744167327881
		</comment>
		<comment id='9' author='ceroxlol' date='2019-02-15T10:24:14Z'>
		This is interesting! There may be a bug in the rolling average function! I'll flag this as a bug. Can you provide the small script that you used for doing this?
		</comment>
		<comment id='10' author='ceroxlol' date='2019-02-15T10:46:04Z'>
		Sure.
I created a repo for the file I used.
&lt;denchmark-link:https://github.com/ceroxlol/IrisExampleTrainingLossError&gt;https://github.com/ceroxlol/IrisExampleTrainingLossError&lt;/denchmark-link&gt;

There is an issue when only 2 samples are drawn that there might not be enough labels provided. Just retry then. It worked in 9/10 cases for me.
		</comment>
		<comment id='11' author='ceroxlol' date='2019-02-15T20:25:49Z'>
		Actually I don't think it's a bug, even for one sample per epoch. When the loss is computed, this is before the backprop (this is actually the loss used by the backprop), so we get the loss, and then update the weights. Which is why the result is different, because the weights are different. I'll close this issue since it's not a bug.
		</comment>
	</comments>
</bug>