<bug id='11769' author='gabrieldemarmiesse' open_date='2018-12-02T12:57:29Z' closed_time='2018-12-04T07:29:14Z'>
	<summary>The method `evaluate` appears to fail on the following model:</summary>
	<description>
    inputs = Input(shape=(3,))
    x = Dense(2)(inputs)
    outputs = Dense(3)(x)

    model = Model(inputs, outputs)
    model.compile(loss=losses.MSE,
                  optimizer=optimizers.Adam(),
                  metrics=['mse'],
                  weighted_metrics=['mse'])
This is due to the model expecting to be fed sample weights (due to the presence of a weighted metric) yet receiving none.
Note created by &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 in the "Requests for contributions".
	</description>
	<comments>
		<comment id='1' author='gabrieldemarmiesse' date='2018-12-03T21:52:58Z'>
		I did a quick test and it seems to work fine, at least on my setup. What do you mean by "the presence of a weighted metric"?
Setup:

Ubuntu 18.04 (on Windows 10's linux subsystem)
Python 3.6.7 (Anaconda distro)
Tensorflow CPU 1.12.0
Keras 2.2.4

Code:
from keras.layers import Input, Dense
from keras.models import Model
from keras import optimizers, losses

import numpy as np

inputs = Input(shape=(3,))
x = Dense(2)(inputs)
outputs = Dense(3)(x)

model = Model(inputs, outputs)
model.compile(loss=losses.MSE,
              optimizer=optimizers.Adam(),
              metrics=['mse'],
              weighted_metrics=['mse'])

for num_samples in range(10):
    X = np.random.rand(num_samples, 3)
    y = np.random.rand(num_samples, 3)
    model.evaluate(x=X,y=y)
Output:
&lt;denchmark-code&gt;1/1 [==============================] - 0s 501us/step
2/2 [==============================] - 0s 261us/step
3/3 [==============================] - 0s 126us/step
4/4 [==============================] - 0s 91us/step
5/5 [==============================] - 0s 77us/step
6/6 [==============================] - 0s 70us/step
7/7 [==============================] - 0s 76us/step
8/8 [==============================] - 0s 59us/step
9/9 [==============================] - 0s 56us/step
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='gabrieldemarmiesse' date='2018-12-04T07:29:14Z'>
		Ho, a WSL user. So it seems I'm not the only one haha. Well I also could not manage to reproduce this bug. Maybe it was already fixed in a past keras commit. Thank you for the investigation. I'll close the issue since two people were not able to reproduce this.
Thanks for the help!
		</comment>
		<comment id='3' author='gabrieldemarmiesse' date='2018-12-05T00:51:50Z'>
		Maybe, I guess that the expected behavior is to hide weighted_metrics (the last element in each row in the following outputs) when sample_weight=none. Currently, the outputs are:
&lt;denchmark-code&gt;1/1 [==============================] - 3s 3s/step
[0.40885260701179504, 0.40885260701179504, 0.40885260701179504]
2/2 [==============================] - 0s 721us/step
[0.7773563861846924, 0.7773563861846924, 0.7773563861846924]
3/3 [==============================] - 0s 411us/step
[0.5119530558586121, 0.5119530558586121, 0.5119530558586121]
4/4 [==============================] - 0s 341us/step
[1.0013830661773682, 1.0013830661773682, 1.0013830661773682]
5/5 [==============================] - 0s 230us/step
[0.6820108890533447, 0.6820108890533447, 0.6820108890533447]
6/6 [==============================] - 0s 208us/step
[0.819098174571991, 0.819098174571991, 0.819098174571991]
7/7 [==============================] - 0s 172us/step
[0.6216490864753723, 0.6216490864753723, 0.6216490864753723]
8/8 [==============================] - 0s 156us/step
[0.5267952680587769, 0.5267952680587769, 0.5267952680587769]
9/9 [==============================] - 0s 137us/step
[0.8654623627662659, 0.8654623627662659, 0.8654623627662659]
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>