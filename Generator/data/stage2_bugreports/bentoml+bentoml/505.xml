<bug id='505' author='omrihar' open_date='2020-01-29T10:15:20Z' closed_time='2020-01-30T14:44:22Z'>
	<summary>Using curl to test lambda deployment fails with dataframe handler</summary>
	<description>
Describe the bug
I deployed a model that uses the DataFrameHandler to aws lambda. When I test it with curl, using, e.g.
curl -i --request POST --data '{"key": "value"}' https://&lt;url&gt;/Prod/predict
I get as response an Internal server error. The cloudwatch logs indicate a problem with the Content-Type header:
&lt;denchmark-code&gt;[ERROR] KeyError: 'Content-Type'
Traceback (most recent call last):
  File "/var/task/app.py", line 66, in api_func
    return bento_service_api.handle_aws_lambda_event(event)
  File "/var/task/bentoml/service.py", line 98, in handle_aws_lambda_event
    return self.handler.handle_aws_lambda_event(event, self.func)
  File "/var/task/bentoml/handlers/dataframe_handler.py", line 203, in handle_aws_lambda_event
    if event["headers"]["Content-Type"] == "application/json":
&lt;/denchmark-code&gt;

When using requests in an ipython shell, however, the request goes as expected. e.g.
import requests
resp = requests.post(url, json={"key": "value"})
works exactly as expected.
To Reproduce
Steps to reproduce the behavior:

Deploy a lambda function that uses the DataFrameHandler
Use curl as described above.
See error

Expected behavior
A response should be sent back instead of an error.
Environment:

OS: Manjaro linux  5.4.14-2
Python/BentoML Version Python 3.7.6, BentoML-0.6.1

	</description>
	<comments>
		<comment id='1' author='omrihar' date='2020-01-29T20:23:41Z'>
		&lt;denchmark-link:https://github.com/omrihar&gt;@omrihar&lt;/denchmark-link&gt;
 I couldn't reproduce this issue on my end this time(I was able to get the error when using curl from a ubuntu docker container testing your deployment endpoint last time we discussed it in slack).
I suspect in some edge case   will set the content-type header improperly in a way that AWS Lambda can not handle. &lt;denchmark-link:https://github.com/bentoml/BentoML/pull/507&gt;#507&lt;/denchmark-link&gt;
 should help with this issue you're encountering.
		</comment>
		<comment id='2' author='omrihar' date='2020-01-29T21:39:03Z'>
		Just merged the pull request, if you installed BentoML from master now and used that version of BentoML to save a new BentoService bundle, you should be able to deploy it to lambda including this change. Let me know if that helped with the issue you ran into.
		</comment>
		<comment id='3' author='omrihar' date='2020-01-30T11:08:57Z'>
		Hi &lt;denchmark-link:https://github.com/parano&gt;@parano&lt;/denchmark-link&gt;
, I suspect that you are correct. I am unable to deploy to lambda from the master version of bentoml, because the PythonPipBuilder isn't able to find the bentoml version. I'll try to edit the source files of the installed bentoml I have locally and see if this will work though...
		</comment>
		<comment id='4' author='omrihar' date='2020-01-30T14:44:21Z'>
		OK, I manually applied these changes to an already-deployed lambda function by downloading it, modifying, and uploading again and it works. So I guess we can close this now.
		</comment>
	</comments>
</bug>