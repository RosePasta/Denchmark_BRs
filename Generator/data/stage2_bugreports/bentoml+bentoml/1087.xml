<bug id='1087' author='bojiang' open_date='2020-09-13T09:16:00Z' closed_time='2020-09-21T15:06:05Z'>
	<summary>Configurable max request body size</summary>
	<description>
Is your feature request related to a problem? Please describe.
How to reproduce:

enable microbatching
post a large file (for example, 2MB) to the API

got:
aiohttp.web_exceptions.HTTPRequestEntityTooLarge: Request Entity Too Large
Describe the solution you'd like
&lt;denchmark-link:https://docs.aiohttp.org/en/stable/web_reference.html#aiohttp.web.Application&gt;https://docs.aiohttp.org/en/stable/web_reference.html#aiohttp.web.Application&lt;/denchmark-link&gt;


enlarge the default client_max_size
make it configurable
do the same for flask

Describe alternatives you've considered
Additional context
	</description>
	<comments>
		<comment id='1' author='bojiang' date='2020-11-24T20:46:13Z'>
		Hi, I'm running into this issue of aiohttp.web_exceptions.HTTPRequestEntityTooLarge when testing out some micro-batching on an image model (e.g. batching 5 images will do this).
I noticed there is a PR that was merged but I don't actually see how it can be configured. Looking at &lt;denchmark-link:https://github.com/bojiang/BentoML/blob/ea44748e14a4d208bbb437c9d7d0b7f5c4dd027c/bentoml/server/gunicorn_server.py#L66&gt;https://github.com/bojiang/BentoML/blob/ea44748e14a4d208bbb437c9d7d0b7f5c4dd027c/bentoml/server/gunicorn_server.py#L66&lt;/denchmark-link&gt;
 it seems that it is reading the config file. Is changing that config file the only way to change this value?
		</comment>
		<comment id='2' author='bojiang' date='2020-11-25T00:40:19Z'>
		&lt;denchmark-link:https://github.com/gregd33&gt;@gregd33&lt;/denchmark-link&gt;
 You can also pass the value as an envvar, 
		</comment>
	</comments>
</bug>