<bug id='365' author='SultanovAR' open_date='2018-08-09T12:47:37Z' closed_time='2018-09-19T12:02:13Z'>
	<summary>Can't use 2 Keras models in one config-file.</summary>
	<description>

Traceback (most recent call last):
File "deep.py", line 81, in 
main()
File "deep.py", line 66, in main
train_evaluate_model_from_config(pipeline_config_path, to_train=False, to_validate=False)
File "/Users/cataha/.deeppavlov/DeepPavlov/deeppavlov/core/commands/train.py", line 179, in train_evaluate_model_from_config
train_config.get('batch_size', -1), 'valid')
File "/Users/cataha/.deeppavlov/DeepPavlov/deeppavlov/core/commands/train.py", line 202, in _test_model
y_predicted = list(model(list(x)))
File "/Users/cataha/.deeppavlov/DeepPavlov/deeppavlov/core/common/chainer.py", line 102, in call
return self._predict(*args, **kwargs)
File "/Users/cataha/.deeppavlov/DeepPavlov/deeppavlov/core/common/chainer.py", line 137, in _predict
res = component(*x)
File "/Users/cataha/.deeppavlov/DeepPavlov/deeppavlov/models/classifiers/intents/intent_model.py", line 229, in call
preds = np.array(self.infer_on_batch(data))
File "/Users/cataha/.deeppavlov/DeepPavlov/deeppavlov/core/models/tf_backend.py", line 28, in _wrapped
return func(*args, **kwargs)
File "/Users/cataha/.deeppavlov/DeepPavlov/deeppavlov/models/classifiers/intents/intent_model.py", line 211, in infer_on_batch
predictions = self.model.predict(features)
File "/Users/cataha/.deeppavlov/env/lib/python3.6/site-packages/keras/engine/training.py", line 1167, in predict
steps=steps)
File "/Users/cataha/.deeppavlov/env/lib/python3.6/site-packages/keras/engine/training_arrays.py", line 294, in predict_loop
batch_outs = f(ins_batch)
File "/Users/cataha/.deeppavlov/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2666, in call
return self._call(inputs)
File "/Users/cataha/.deeppavlov/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2635, in _call
session)
File "/Users/cataha/.deeppavlov/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2587, in _make_callable
callable_fn = session._make_callable_from_options(callable_opts)
File "/Users/cataha/.deeppavlov/env/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1414, in _make_callable_from_options
return BaseSession._Callable(self, callable_options)
File "/Users/cataha/.deeppavlov/env/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1368, in init
session._session, options_ptr, status)
File "/Users/cataha/.deeppavlov/env/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 519, in exit
c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensor activation_5/Sigmoid:0, specified in either feed_devices or fetch_devices was not found in the Graph
Exception ignored in: &lt;bound method BaseSession._Callable.del of &lt;tensorflow.python.client.session.BaseSession._Callable object at 0x11ebc7160&gt;&gt;

	</description>
	<comments>
		<comment id='1' author='SultanovAR' date='2018-08-09T12:49:26Z'>
		Can you provide with a config that caused the error?
		</comment>
		<comment id='2' author='SultanovAR' date='2018-08-10T07:15:23Z'>
		Yeah, sure
There are component, that called "blender_for_classifiers", it is my own-writer component, but error not linked with him. Error appears immediately after initialization.
command, that I use to start script:

sudo python deep.py evaluate "path/to/my/config"

&lt;denchmark-code&gt;{
  "dataset_reader": {
    "name": "basic_classification_reader",
    "x": "Comment",
    "y": "Class",
    "data_path": "insults_data"
  },
  "dataset_iterator": {
    "name": "basic_classification_iterator",
    "seed": 42
  },
  "chainer": {
    "in": [
      "x"
    ],
    "in_y": [
      "y"
    ],
    "pipe": [
      {
        "id": "classes_vocab",
        "name": "default_vocab",
        "fit_on": [
          "y"
        ],
        "level": "token",
        "save_path": "vocabs/insults_kaggle_classes.dict",
        "load_path": "vocabs/insults_kaggle_classes.dict"
      },
      {
        "in": [
          "x"
        ],
        "out": [
          "x_prep"
        ],
        "name": "dirty_comments_preprocessor"
      },
      {
        "id": "my_embedder",
        "name": "fasttext",
        "save_path": "embeddings/wordpunct_tok_reddit_comments_2017_11_300.bin",
        "load_path": "embeddings/wordpunct_tok_reddit_comments_2017_11_300.bin",
        "dim": 300
      },
      {
        "id": "my_tokenizer",
        "name": "nltk_tokenizer",
        "tokenizer": "wordpunct_tokenize"
      },
      {
        "in": [
          "x_prep"
        ],
        "out": [
          "y_labels_1",
          "y_probas_dict_1"
        ],
        "name": "intent_model",
        "save_path": "sentiment/insults_kaggle_v0",
        "load_path": "sentiment/insults_kaggle_v0",
        "classes": "#classes_vocab.keys()",
        "kernel_sizes_cnn": [
          1,
          2,
          3
        ],
        "filters_cnn": 256,
        "confident_threshold": 0.5,
        "optimizer": "Adam",
        "lear_rate": 0.01,
        "lear_rate_decay": 0.1,
        "loss": "binary_crossentropy",
        "last_layer_activation": "softmax",
        "text_size": 100,
        "coef_reg_cnn": 1e-3,
        "coef_reg_den": 1e-2,
        "dropout_rate": 0.5,
        "dense_size": 100,
        "model_name": "cnn_model",
        "embedder": "#my_embedder",
        "tokenizer": "#my_tokenizer"
      },
      {
        "in": [
          "x_prep"
        ],
        "out": [
          "y_labels_2",
          "y_probas_dict_2"
        ],
        "name": "intent_model",
        "save_path": "sentiment/without_source_data/ar-ru-ja/bs16",
        "load_path": "sentiment/without_source_data/ar-ru-ja/bs16",
        "classes": "#classes_vocab.keys()",
        "kernel_sizes_cnn": [
          1,
          2,
          3
        ],
        "filters_cnn": 256,
        "confident_threshold": 0.5,
        "optimizer": "Adam",
        "lear_rate": 0.01,
        "lear_rate_decay": 0.1,
        "loss": "binary_crossentropy",
        "last_layer_activation": "softmax",
        "text_size": 100,
        "coef_reg_cnn": 1e-3,
        "coef_reg_den": 1e-2,
        "dropout_rate": 0.5,
        "dense_size": 100,
        "model_name": "cnn_model",
        "embedder": "#my_embedder",
        "tokenizer": "#my_tokenizer"
      },
      {
        "in": [
          "y_probas_dict_1",
          "y_probas_dict_2"
        ],
        "out": [
          "y_labels",
          "y_probas_dict"
        ],
        "name": "blender_for_classifiers",
        "confident_threshold": 0.5
      }
    ],
    "out": [
      "y_labels",
      "y_probas_dict"
    ]
  },
  "train": {
    "epochs": 1000,
    "batch_size": 64,
    "metrics": [
      "classification_accuracy",
      "classification_f1",
      "classification_roc_auc"
    ],
    "validation_patience": 5,
    "val_every_n_epochs": 5,
    "log_every_n_epochs": 5,
    "show_examples": false,
    "validate_best": true,
    "test_best": true
  },
  "metadata": {
    "labels": {
      "telegram_utils": "IntentModel",
      "server_utils": "KerasIntentModel"
    },
    "download": [
      "http://lnsigo.mipt.ru/export/deeppavlov_data/vocabs.tar.gz",
      "http://lnsigo.mipt.ru/export/deeppavlov_data/sentiment.tar.gz",
      "http://lnsigo.mipt.ru/export/datasets/insults_data.tar.gz",
      {
        "url": "http://lnsigo.mipt.ru/export/embeddings/reddit_fastText/wordpunct_tok_reddit_comments_2017_11_300.bin",
        "subdir": "embeddings"
      }
    ]
  }
}

&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='SultanovAR' date='2018-08-16T09:02:29Z'>
		Currently there has been made a hot fix of intent_classifier so that several keras models could be used in one pipeline. It is in dev branch.
The idea is that every time your model makes operations on tensorflow graph you have to reset it's session via:
from keras import backend as K
K.set_session(self.sess)
Note: your class should be inherited from deeppavlov.core.models.keras_model.KerasModel.
Keeping the issue for better fixes.
		</comment>
		<comment id='4' author='SultanovAR' date='2018-08-18T10:28:14Z'>
		or else set the backend as theano instead of tensorflow it worked me !
&lt;denchmark-link:https://github.com/SultanovAR&gt;@SultanovAR&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='SultanovAR' date='2018-09-13T11:26:48Z'>
		Resolved in &lt;denchmark-link:https://github.com/deepmipt/DeepPavlov/pull/446&gt;#446&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>