<bug id='253' author='neuwangmq' open_date='2019-12-05T07:38:09Z' closed_time='2020-01-07T01:24:11Z'>
	<summary>sample_ssd save and load engine file TensorRT5.1.5 win10</summary>
	<description>
I added the following codes for serialize and save engine file
	std::ofstream p(engineFile.c_str(), std::ios::binary);
	IHostMemory* m_ModelStream = engine-&gt;serialize();
	p.write(reinterpret_cast&lt;const char*&gt;(m_ModelStream-&gt;data()), m_ModelStream-&gt;size());
	p.close();
and the following codes for load and deserialize CudaEngine
std::vector&lt;char&gt; trtModelStreamfromFile;	
	size_t size{ 0 };
	std::ifstream file(engine_file, std::ios::binary);
	if (file.good())
	{
		file.seekg(0, file.end);
		size = file.tellg();
		file.seekg(0, file.beg);
		trtModelStreamfromFile.resize(size);
		file.read(trtModelStreamfromFile.data(), size);
		file.close();
		//IRuntime* infer = createInferRuntime(gLogger.getTRTLogger());
		engine_ = runtime_-&gt;deserializeCudaEngine(trtModelStreamfromFile.data(), size, nullptr);
	}
on  GeForce RTX1080 it works.
but on  GeForce RTX2060 , it got error at
 context_ = engine_-&gt;createExecutionContext();
the error is
[E][TRT] c:\p4sw\sw\gpgpu\MachineLearning\DIT\release\5.1\plugin\priorBoxPlugin.cpp (197) - Cuda Error in nvinfer1::plugin::PriorBox::copyToDevice: 1 (invalid argument)
I don't know how to solve it!!!
thanks~
	</description>
	<comments>
		<comment id='1' author='neuwangmq' date='2019-12-29T15:27:46Z'>
		Hi &lt;denchmark-link:https://github.com/neuwangmq&gt;@neuwangmq&lt;/denchmark-link&gt;
, can you try upgrading to TensorRT 7.0 and see if this fixes your issue?
		</comment>
		<comment id='2' author='neuwangmq' date='2020-01-07T01:23:49Z'>
		thanks for your answer, I have found the problem. I use the5.0.2.6 to generate the calibrator file,and use the 5.1.5.0 to do the inference .after I change the 5.0.2.6 to 5.1.5.0 ,it's OK!
		</comment>
	</comments>
</bug>