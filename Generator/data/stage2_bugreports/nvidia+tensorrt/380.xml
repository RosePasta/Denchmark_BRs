<bug id='380' author='cathy-kim' open_date='2020-02-14T00:09:28Z' closed_time='2021-01-15T08:13:07Z'>
	<summary>Output using TensorRT(nvonnxparser) is different from the one using TF-TRT</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Hi. I found that the output using TensorRT, especially nvonnxparser is
different from the one from TF-TRT.
&lt;denchmark-link:https://user-images.githubusercontent.com/16524103/74489952-d170dc80-4e7b-11ea-8715-643b0882845d.png&gt;&lt;/denchmark-link&gt;

The first picture was the output using nvonnxparser.
The second one came from TF-TRT.
There are 5 different types in the graph that are not converted to TensorRT: Identity, Tile, ResizeNearestNeighbor, NoOp, Placeholder.
Is there a known issue for those operations in TensorRT?
If it is, Let me know.
Thanks!
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

TensorRT Version: 7
GPU Type: 1080Ti
Nvidia Driver Version: 440.33.01
CUDA Version: 10.2
CUDNN Version: 7.6
Operating System + Version: Ubuntu18.04
Python Version (if applicable): 3.6
TensorFlow Version (if applicable): 2.0
PyTorch Version (if applicable):
Baremetal or Container (if container which image + tag):
	</description>
	<comments>
		<comment id='1' author='cathy-kim' date='2020-02-14T00:14:48Z'>
		Hi,
Can you try to narrow down the issue by cutting off the ONNX model (set the output to some intermediate layer), and trying to see at which point the output actually starts to differ from the TF model?
If so, this would be easier to help if you could use the debugging above to create a simpler model containing only the op that differs between TF and TRT and compares the outputs
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

It's likely that something went wrong when converting from TF -&gt; ONNX. Perhaps you could look into that as well. (tf2onnx, keras2onnx, etc.)
		</comment>
		<comment id='2' author='cathy-kim' date='2020-02-14T00:25:43Z'>
		
It's likely that something went wrong when converting from TF -&gt; ONNX. Perhaps you could look into that as well. (tf2onnx, keras2onnx, etc.)

&lt;denchmark-link:https://github.com/rmccorm4&gt;@rmccorm4&lt;/denchmark-link&gt;
 Thanks, I will try the method you told.
Before, I wonder what is the solution for the conversion error.
		</comment>
		<comment id='3' author='cathy-kim' date='2020-02-14T00:43:41Z'>
		
Before, I wonder what is the solution for the conversion error.

Depends on the errors you got. I would suspect a tool like  might've reported some errors during conversion. If so you could raise an issue on that here: &lt;denchmark-link:https://github.com/onnx/tensorflow-onnx&gt;https://github.com/onnx/tensorflow-onnx&lt;/denchmark-link&gt;
 for example.
		</comment>
		<comment id='4' author='cathy-kim' date='2020-02-14T23:17:35Z'>
		

Before, I wonder what is the solution for the conversion error.

Depends on the errors you got. I would suspect a tool like tf2onnx might've reported some errors during conversion. If so you could raise an issue on that here: https://github.com/onnx/tensorflow-onnx for example.

Hi &lt;denchmark-link:https://github.com/rmccorm4&gt;@rmccorm4&lt;/denchmark-link&gt;
, I checked some intermediate outputs of our onnx graph.
And I found that there isn't any noticeable difference between Native-TF and ONNX.

Do you think that the difference came from conversion between ONNX and TensorRT?
		</comment>
		<comment id='5' author='cathy-kim' date='2020-02-15T01:44:58Z'>
		It's possible, please try to narrow down the issue as mentioned here: &lt;denchmark-link:https://github.com/NVIDIA/TensorRT/issues/380#issuecomment-586035356&gt;#380 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='cathy-kim' date='2020-02-19T02:05:22Z'>
		
It's possible, please try to narrow down the issue as mentioned here: #380 (comment)

Hi &lt;denchmark-link:https://github.com/rmccorm4&gt;@rmccorm4&lt;/denchmark-link&gt;
.
I found that TensorRT network started to differ at the point that uses "ResizeNearest" operation from the TF model.
The gap between TF and TensorRT grows bigger from the point.
(But I'm not sure because the average gap of an element, in an array, for the operation starts from a small number, 0.006.)
What I want to know is the known issue for the operation. Also, I'd like to know the solution for it.
===================================================================
I solved this problem. Thanks.
		</comment>
		<comment id='7' author='cathy-kim' date='2020-02-21T21:31:08Z'>
		Hi &lt;denchmark-link:https://github.com/cathy-kim&gt;@cathy-kim&lt;/denchmark-link&gt;
 ,
Can you please share your solution to help others who run into the same issue?
		</comment>
		<comment id='8' author='cathy-kim' date='2020-02-27T22:15:27Z'>
		&lt;denchmark-link:https://github.com/rmccorm4&gt;@rmccorm4&lt;/denchmark-link&gt;
 Hi. It was a quite different error that I had expected.
This process happened when I used nvonnxparser.
At first, TensorRT network just used the marked output as an output tensor automatically.
The result from the marked output was just wrong.
Therefore, I marked all tensors as output and printed.
Finally, I found that the result from automatically marked output, named "landmarks:0" is a lot different from the one from the same tensor, "landmarks:0" when I manually marked all tensors as output.
Maybe there is a bug which occurs when reading and parsing nodes in onnx file.
I just wonder what happened when I marked a tensor as an output of network manually.
		</comment>
		<comment id='9' author='cathy-kim' date='2020-02-27T23:26:48Z'>
		Hi &lt;denchmark-link:https://github.com/cathy-kim&gt;@cathy-kim&lt;/denchmark-link&gt;
 ,
Glad you solved your issue. If I'm understanding your question correctly, I think this might answer your question:
I believe when you mark a layer as an output, it's output value has to be stored, and therefore that essentially turns off fusing for that layer, so the output of that individual layer (when marked as an output) might be different from the output of the equivalent fused layer (if it was actually fused with another layer when not marked as output). That might explain what you're seeing.
Some more details on this post: &lt;denchmark-link:https://github.com/NVIDIA/TensorRT/issues/252#issuecomment-577468499&gt;#252 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='cathy-kim' date='2020-02-29T01:19:55Z'>
		Thank you for your reply &lt;denchmark-link:https://github.com/rmccorm4&gt;@rmccorm4&lt;/denchmark-link&gt;

From your answer, I found the part that had made the wrong result.
When making layer fusion including three types of layer, the result is just different from the original output without layer fusion.
For example, if layer fusion for these three layers occurs, the output goes wrong.
&lt;denchmark-code&gt;heatmap_nchw/0_1_up1/separable_conv2d [LayerType.CONVOLUTION]+
heatmap_nchw/0_1_up1/bn/Relu6 [LayerType.ACTIVATION]+ 
heatmap_nchw/add [LayerType.ELEMENTWISE] 
&lt;/denchmark-code&gt;

Also, the result is different from the next one.
&lt;denchmark-code&gt;heatmap_nchw/0_1_up1/separable_conv2d [LayerType.CONVOLUTION]+
heatmap_nchw/0_1_up1/bn/Relu6 [LayerType.ACTIVATION] 

heatmap_nchw/add [LayerType.ELEMENTWISE] 
&lt;/denchmark-code&gt;

I think this is a kind of bug and hope you to check this problem ;)
I will be grateful to know the solution except marking intermediate tensors as outputs
		</comment>
		<comment id='11' author='cathy-kim' date='2020-02-29T01:44:44Z'>
		Hi &lt;denchmark-link:https://github.com/cathy-kim&gt;@cathy-kim&lt;/denchmark-link&gt;
 ,
May be a bug in layer fusion for this combination.
If you could share the ONNX model, and a full script that demonstrates the differences between the fused vs unfused layers that are giving incorrect results, that would be very helpful.
		</comment>
		<comment id='12' author='cathy-kim' date='2020-10-18T16:11:55Z'>
		&lt;denchmark-link:https://github.com/cathy-kim&gt;@cathy-kim&lt;/denchmark-link&gt;
 following up on Ryan's request, can you please share the model or an isolated example if possible? Thanks.
		</comment>
		<comment id='13' author='cathy-kim' date='2020-10-19T04:59:42Z'>
		&lt;denchmark-link:https://github.com/rajeevsrao&gt;@rajeevsrao&lt;/denchmark-link&gt;
 Hi. I cannot share the model because of NDA. I'm gonna make an isolated example and upload it. Thanks
		</comment>
		<comment id='14' author='cathy-kim' date='2021-01-15T08:13:07Z'>
		I will close since no response for more than 3 weeks, please reopen when you have the isolated repro, thanks!
		</comment>
	</comments>
</bug>