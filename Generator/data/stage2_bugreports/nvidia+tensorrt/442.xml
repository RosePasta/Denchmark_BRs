<bug id='442' author='HandsLing' open_date='2020-03-20T07:51:45Z' closed_time='2020-04-08T06:37:47Z'>
	<summary>kernel weights has count 589824 but 147456 was expected</summary>
	<description>
Here is my error message:
[TensorRT] ERROR: build_feature_pyramid/build_P4/avoid_aliasing/Conv2D: kernel weights has count 589824 but 147456 was expected
[TensorRT] ERROR: build_feature_pyramid/build_P4/avoid_aliasing/Conv2D: count of 589824 weights in kernel, but kernel dimensions (3,3) with 64 input channels, 256 output channels and 1 groups were specified. Expected Weights count is 64 * 3*3 * 256 / 1 = 147456
[TensorRT] ERROR: UffParser: Parser error: build_feature_pyramid/build_P4/avoid_aliasing/BiasAdd: The input to the Scale Layer is required to have a minimum of 3 dimensions.
[TensorRT] ERROR: Network must have at least one output
Traceback (most recent call last):
File "uff_psenet.py", line 99, in 
with build_engine(model_path) as engine:
AttributeError: enter
here is the net definition:
nodes {
id: "build_feature_pyramid/build_P4/avoid_aliasing/Conv2D"
inputs: "build_feature_pyramid/add"
inputs: "build_feature_pyramid/build_P4/avoid_aliasing/weights"
operation: "Conv"
fields {
key: "dilation"
value {
i_list {
val: 1
val: 1
}
}
}
fields {
key: "implicit_padding"
value {
s: "same"
}
}
fields {
key: "inputs_orders"
value {
ref: "orders_N+C_+CK"
}
}
fields {
key: "strides"
value {
i_list {
val: 1
val: 1
}
}
}
}
nodes {
id: "build_feature_pyramid/build_P4/avoid_aliasing/weights"
operation: "Const"
fields {
key: "dtype"
value {
dtype: DT_FLOAT32
}
}
fields {
key: "shape"
value {
i_list {
val: 3
val: 3
val: 256
val: 256
}
}
}
and here is my code:
p, c = feature_pyramid['P' + str(layer + 1)], C['C' + str(layer)]
up_sample_shape = tf.shape(c)
up_sample = tf.image.resize_nearest_neighbor(p, [up_sample_shape[1], up_sample_shape[2]],
name='layer_%d/ResizeNearestNeighbor' % layer)
c = slim.conv2d(c, num_outputs=256, kernel_size=[1, 1], stride=1,
scope='build_P%d/reduce_dimension' % layer)
p = up_sample + c
p = slim.conv2d(p, 256, kernel_size=[3, 3], stride=1,
padding='SAME', scope='build_P%d/avoid_aliasing' % layer)
in this code, for example. shape of p is [None, 32, 32, 256], and shape of c is [None, 64, 64, 256], and this resize layer  was original from TensorRT/plugin/resizeNearestPlugin, i konw the data format in TensorRT was NCHW, it seems this conv layer can't transpose the NHWC format to NCHW, so what should i do?
	</description>
	<comments>
		<comment id='1' author='HandsLing' date='2020-03-31T07:06:23Z'>
		Hi,
Did u solve this bug? cuz I am facing the same issue.
		</comment>
		<comment id='2' author='HandsLing' date='2020-04-02T00:25:32Z'>
		&lt;denchmark-link:https://github.com/derekwong66&gt;@derekwong66&lt;/denchmark-link&gt;
 i found in the code, i use a tf.shape() func to get the shape of a tensor, but when i change tf.shape() to np.shape(), it solves
		</comment>
		<comment id='3' author='HandsLing' date='2020-04-02T00:44:31Z'>
		Thanks for finding the solution &lt;denchmark-link:https://github.com/HandsLing&gt;@HandsLing&lt;/denchmark-link&gt;
 , can I close this issue?
		</comment>
		<comment id='4' author='HandsLing' date='2020-04-02T02:00:15Z'>
		
@derekwong66 i found in the code, i use a tf.shape() func to get the shape of a tensor, but when i change tf.shape() to np.shape(), it solves

I solved it by reshaping its size before passing it into conv
		</comment>
		<comment id='6' author='HandsLing' date='2020-09-04T11:34:56Z'>
		
little bit more ab
Assuming the shape before passing it into conv is (16, 32, 256). add one more tf.reshape to its shape like tf.reshape(feature, (16, 32, 256)) then it will be solved

		</comment>
		<comment id='7' author='HandsLing' date='2020-09-05T06:47:15Z'>
		&lt;denchmark-link:https://github.com/derekwong66&gt;@derekwong66&lt;/denchmark-link&gt;
 &gt; &gt; little bit more ab


Assuming the shape before passing it into conv is (16, 32, 256). add one more tf.reshape to its shape like tf.reshape(feature, (16, 32, 256)) then it will be solved


Perfectly solved! Thanks so much!
		</comment>
	</comments>
</bug>