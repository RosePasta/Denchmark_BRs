<bug id='354' author='SvanKeulen' open_date='2020-01-22T17:01:25Z' closed_time='2020-09-16T15:18:07Z'>
	<summary>cudnnBatchNormalizationBackwardEx</summary>
	<description>
When using TensorRT 7.0.0.11,
I'm getting a complaint about resolving cudnnBatchNormalizationBackwardEx from module myelin64_1.dll (see attachment)
I'm sure I'm using the correct versions according to the &lt;denchmark-link:https://docs.nvidia.com/deeplearning/sdk/tensorrt-support-matrix/index.html&gt;support-matrix&lt;/denchmark-link&gt;
.
Inspecting dependencies and entry-points shows this entry-point is from an other module.
The actual DLL containing the entry-point is cudnn64_7.dll
&lt;denchmark-link:https://user-images.githubusercontent.com/51877138/72976707-60d22500-3dd3-11ea-88b5-848c271ae713.JPG&gt;&lt;/denchmark-link&gt;

Any help is appreciated.
Environment:
Windows10
VisualStudio.15.Release/15.9.16+28307.858
cuda_10.2.89_441.22_win10
cudnn-10.2-windows10-x64-v7.6.5.32
TensorRT-7.0.0.11.Windows10.x86_64.cuda-10.2.cudnn7.6
&lt;denchmark-link:https://user-images.githubusercontent.com/51877138/72915485-aa256480-3d40-11ea-9030-1f745bc50af9.JPG&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='SvanKeulen' date='2020-01-24T11:24:42Z'>
		To add some more context...
When I use functionality from TensorRT in a basic command-line application, all seems fine.
When I use it in a DLL that is used inside a managed environment (C#), the issue described above arises.
No TensorRT functionality is called from C# directly. Only raw-data is shared.
Currently TensorRT6 workes just fine, only with TensorRT7 I get this problem.
I tried a clean install of cuda, cudnn and tensorrt7 on a clean system to be sure. Same problem.
		</comment>
		<comment id='2' author='SvanKeulen' date='2020-01-25T22:32:24Z'>
		Hi &lt;denchmark-link:https://github.com/SvanKeulen&gt;@SvanKeulen&lt;/denchmark-link&gt;
,
Sorry, I don't have any experience using TensorRT on Windows. However, I see this commit on the upstream ONNX parser which sounds related: &lt;denchmark-link:https://github.com/onnx/onnx-tensorrt/commit/2e60cfde7941e9819dfae79cdb1d893e8191d16b&gt;onnx/onnx-tensorrt@2e60cfd&lt;/denchmark-link&gt;

Does building the ONNX parser master branch from source (per this repo's README) solve your issue?
(Though I don't know how supported that is currently per: &lt;denchmark-link:https://github.com/NVIDIA/TensorRT/issues/36&gt;#36&lt;/denchmark-link&gt;
, though it's a pretty old issue)
		</comment>
		<comment id='3' author='SvanKeulen' date='2020-01-28T15:13:02Z'>
		&lt;denchmark-link:https://github.com/rmccorm4&gt;@rmccorm4&lt;/denchmark-link&gt;

Thanks for the reply, unfortunately I don't have an opportunity to do a deeper, code level investigation at the moment.
		</comment>
		<comment id='4' author='SvanKeulen' date='2020-02-10T10:06:07Z'>
		I had the same error, but it was the result of a wrong cuDNN version (7.3). After updating to 7.6.5 it worked with CUDA 10.0.
		</comment>
		<comment id='5' author='SvanKeulen' date='2020-09-16T15:18:07Z'>
		After testing TensorRT 7.1.3
&lt;denchmark-code&gt;CUDA Runtime            : 11.0 (11000)
CUDA driver             : 11.0 (11000)
cuDNN                   : 8.0.3
NVidia ONNX parser      : 0.1.0
NVidia UFF parser       : 0.6.9

&lt;/denchmark-code&gt;

I can confirm the issue is now resolved.
		</comment>
	</comments>
</bug>