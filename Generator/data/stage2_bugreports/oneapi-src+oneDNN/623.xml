<bug id='623' author='ghost(ghost)' open_date='2019-12-21T02:13:01Z' closed_time='2020-02-10T17:58:14Z'>
	<summary>sudden bad performance with binary multiplication using broadcasting</summary>
	<description>
A while ago I was using the binary multiplication primitive using broadcasting for implementing a
channelwise multiplication. Just multiply two tensors  (N, C, H, W) * (N, C, 1, 1) in the same optimized blocked format. It still works as it used to work only the performance is now very very bad. So Source0 is the tensor (N,C,HW) in nChw8c format and Source1 is a tensor (N, C, 1, 1) also in nChw8c format wich should be broadcasted and multiplied together. I never changed my code and it used to be very fast. For some weird reason it is now the most time consuming primtive in the whole network. Very weird.
thanks
DNNL:
latest master build:
Environment:
cpu: AMD 3900X
os: Windows 10 18363
compiler: Visual Studio 2019
cmake: 3.16.1
&lt;denchmark-code&gt;dnnl_verbose,info,DNNL v1.1.0 (commit 144f241bd3ba474afc9a495d9d312d8f5ed5ddfe)
dnnl_verbose,info,Detected ISA is Intel AVX2
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb8a:f0,,,64x3x3x3,0,4692
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb8a:f0,,,64x3x3x3,11,142
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:abcd:f0 src_f32::blocked:abcd:f0 dst_f32::blocked:abcd:f0,,alg:binary_add,128x3x32x32:128x3x32x32 128x3x32x32,25,5485
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x64x1x1,0,3945
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x64x1x1,0,4079
...
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x64x32x32:128x64x32x32 128x64x32x32,0,1988
nl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1672
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,forward_training,data_f32::blocked:aBcd8b:f0 diff_undef::undef::f0,,flags:,mb128ic256ih8iw8,0,4292
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,flags:,mb128ic256ih8iw8,0,3418
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1473
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x256x1x1,0,1672
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x256x1x1,0,1538
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1893
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x3x3,0,1726
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x3x3,0,055
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,142
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x5x5,0,3857
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x5x5,0,0148
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1426
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x7x7,0,2201
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x7x7,0,0173
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1484
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x9x9,0,4141
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x9x9,0,0244
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1448
dnnl_verbose,create,cpu,concat,simple:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,axis:1,128x384x8x8:128x384x8x8:128x384x8x8:128x384x8x8 128x1536x8x8,0,018
dnnl_verbose,create,cpu,pooling,jit:avx,forward_training,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0 ws_undef::undef::f0,,alg:pooling_avg_exclude_padding,mb128ic1536_ih8oh1kh8sh8ph0_iw8ow1kw8sw8pw0,0,1338
dnnl_verbose,create,cpu,pooling,jit:avx,backward_data,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0 ws_undef::undef::f0,,alg:pooling_avg_exclude_padding,mb128ic1536_ih8oh1kh8sh8ph0_iw8ow1kw8sw8pw0,0,1371
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1209
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x1536x1x1,0,1443
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x1536x1x1,0,1674
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x1x1:128x1536x1x1 128x1536x1x1,0,1957
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x384x1x1,0,1958
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x384x1x1,0,1369
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x1x1:128x384x1x1 128x384x1x1,0,755
dnnl_verbose,create,cpu,binary,ref:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_mul,128x1536x8x8:128x1536x1x1 128x1536x8x8,0,0088
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,256x1536x1x1,0,1768
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,256x1536x1x1,0,1659
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1651
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,forward_training,data_f32::blocked:aBcd8b:f0 diff_undef::undef::f0,,flags:,mb128ic256ih8iw8,0,4304
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,flags:,mb128ic256ih8iw8,0,3435
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1493
dnnl_verbose,create,cpu,sum,simple:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,,128x256x8x8,0,0145
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x256x1x1,0,1608
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x256x1x1,0,1471
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1676
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x3x3,0,1763
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x3x3,0,0552
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1491
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x5x5,0,3854
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x5x5,0,0149
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1389
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x7x7,0,2138
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x7x7,0,0176
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1558
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x9x9,0,4173
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcde:f0 dst_f32::blocked:Abcde8a:f0,,,384x1x1x9x9,0,0183
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x8x8:128x384x8x8 128x384x8x8,0,1356
dnnl_verbose,create,cpu,concat,simple:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,axis:1,128x384x8x8:128x384x8x8:128x384x8x8:128x384x8x8 128x1536x8x8,0,0189
dnnl_verbose,create,cpu,pooling,jit:avx,forward_training,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0 ws_undef::undef::f0,,alg:pooling_avg_exclude_padding,mb128ic1536_ih8oh1kh8sh8ph0_iw8ow1kw8sw8pw0,0,1329
dnnl_verbose,create,cpu,pooling,jit:avx,backward_data,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0 ws_undef::undef::f0,,alg:pooling_avg_exclude_padding,mb128ic1536_ih8oh1kh8sh8ph0_iw8ow1kw8sw8pw0,0,1338
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1174
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x1536x1x1,0,1419
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,384x1536x1x1,0,1632
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x1x1:128x1536x1x1 128x1536x1x1,0,1948
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x384x1x1,0,2006
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,1536x384x1x1,0,1356
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x384x1x1:128x384x1x1 128x384x1x1,0,2075
dnnl_verbose,create,cpu,binary,ref:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_mul,128x1536x8x8:128x1536x1x1 128x1536x8x8,0,00870001
dnnl_verbose,create,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,256x1536x1x1,0,1797
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:ABcd8b8a:f0,,,256x1536x1x1,0,1788
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x1536x8x8:128x1536x8x8 128x1536x8x8,0,1711
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,forward_training,data_f32::blocked:aBcd8b:f0 diff_undef::undef::f0,,flags:,mb128ic256ih8iw8,0,4283
dnnl_verbose,create,cpu,batch_normalization,bnorm_jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,flags:,mb128ic256ih8iw8,0,3406
dnnl_verbose,create,cpu,binary,jit:avx2,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,alg:binary_add,128x256x8x8:128x256x8x8 128x256x8x8,0,1528
dnnl_verbose,create,cpu,sum,simple:any,undef,src_f32::blocked:aBcd8b:f0 src_f32::blocked:aBcd8b:f0 dst_f32::blocked:aBcd8b:f0,,,128x256x8x8,0,0141
dnnl_verbose,create,cpu,reorder,simple:any,undef,src_f32::blocked:abcd:f0 dst_f32:p:blocked:ABcd8b8a:f0,,,10x256x1x1,0,0339
dnnl_verbose,exec,cpu,reorder,simple:any,undef,src_f32::blocked:abcd:f0 dst_f32:p:blocked:ABcd8b8a:f0,,,10x256x1x1,0,5078
&lt;/denchmark-code&gt;

(edited by &lt;denchmark-link:https://github.com/rsdubtso&gt;@rsdubtso&lt;/denchmark-link&gt;
 for formatting)
	</description>
	<comments>
		<comment id='1' author='ghost(ghost)' date='2019-12-22T04:53:48Z'>
		I think I see a ~10% degradation between the &lt;denchmark-link:https://github.com/oneapi-src/oneDNN/commit/2e27c61d8b2c5dd01339f86ecbb7ca8332a7c0a5&gt;2e27c61&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/oneapi-src/oneDNN/commit/d279b39d978b7d3d3f4f69a427f4cb91d754b9fe&gt;d279b39&lt;/denchmark-link&gt;
 (tip of master). The degradation seems to have been introduced in &lt;denchmark-link:https://github.com/oneapi-src/oneDNN/commit/25bca58efac0cc59cb245c3dd62f9d4b93b986cd&gt;25bca58&lt;/denchmark-link&gt;
.
However, I do not see any drastic degradation. Can you reproduce your issue with benchdnn? Here's the line I used for testing on my laptop:
&lt;denchmark-code&gt;.\tests\benchdnn\Release\benchdnn.exe --binary --mode=p --sdt=f32:f32 --ddt=f32 --alg=MUL --inplace=false --stag=nChw8c:nChw8c 256x256x32x32:256x256x1x1
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='ghost(ghost)' date='2019-12-22T05:06:08Z'>
		Unfortunately, 144f241bd3ba474afc9a495d9d312d8f5ed5ddfe does not resolve a hash within the DNNL repo.
I see two binary_mul lines in the verbose log with broadcast that are compute the same operation. For this case, I also see about 10% degradation. Is the data above for 'good' or 'bad' case?
		</comment>
		<comment id='3' author='ghost(ghost)' date='2019-12-22T07:16:32Z'>
		Sadly, there are no good ones, the two binary_mul in the log are both really bad performance wise.
&lt;denchmark-code&gt;benchdnn.exe --binary --mode=p --sdt=f32:f32 --ddt=f32 --alg=MUL --inplace=false --stag=nChw8c:nChw8c 256x256x32x32:256x256x1x1
Output template: perf,%engine%,%desc%,%-time%,%0time%
perf,cpu,--binary --stag=aBcd8b:aBcd8b --alg=MUL --inplace=false 256x256x32x32:256x256x1x1,299.79,300.945
tests:1 passed:0 skipped:0 mistrusted:0 unimplemented:0 failed:0 listed:0
total perf: min(ms):299.79 avg(ms):300.945
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='ghost(ghost)' date='2019-12-22T07:25:26Z'>
		Sorry, I should have worded my question better. Can you share a verbose log collected with DNNL from the revision when you observed good results?
Alternatively, can you try applying the following patch and see if it brings performance back?
diff --git a/src/cpu/ref_binary.cpp b/src/cpu/ref_binary.cpp
index 0261096d2..13e2f7ef8 100644
--- a/src/cpu/ref_binary.cpp
+++ b/src/cpu/ref_binary.cpp
@@ -68,9 +68,10 @@ void ref_binary_t&lt;data_type&gt;::execute_ref(const exec_ctx_t &amp;ctx) const {
         return src1_d.off_v(dims);
     };

+    const bool is_tensor_op = pd()-&gt;is_tensor_op();
     parallel_nd(nelems_A, [&amp;](dim_t i) {
         auto off_A = src0_d.off_l(i);
-        auto off_B = pd()-&gt;is_tensor_op() ? src1_d.off_l(i) : map_idx_B(i);
+        auto off_B = is_tensor_op ? src1_d.off_l(i) : map_idx_B(i);
         perform_op(&amp;dst[off_A], src0[off_A], src1[off_B]);
     });
 }
		</comment>
		<comment id='5' author='ghost(ghost)' date='2019-12-22T08:14:02Z'>
		The patch did give a +/- 10% increase in performance. But the timings are still very bad. About 10x slower than my own naive implementation. I will start looking for a revision without this behaviour.
		</comment>
		<comment id='6' author='ghost(ghost)' date='2019-12-22T16:22:47Z'>
		Thanks for the update. The code above is the reference version deals with arbitrary memory formats and thus is very slow. There was never an optimized version that supported broadcasting and that worked on blocked memory formats.
		</comment>
		<comment id='7' author='ghost(ghost)' date='2019-12-22T22:12:48Z'>
		My excuses in thinking this was something that worked fast and optimized in the past. I will use
my own implementation instead. Thanks anyway.
		</comment>
		<comment id='8' author='ghost(ghost)' date='2020-02-09T02:36:00Z'>
		Hi &lt;denchmark-link:https://github.com/zulma46&gt;@zulma46&lt;/denchmark-link&gt;
, we've promoted a patch to our internal repository where the broadcast problem performs on par with full tensor problem. The change is targeting DNNL v1.3 but will be available in master branch soon. Please try once commit is available. Thanks!
		</comment>
		<comment id='9' author='ghost(ghost)' date='2020-02-09T04:12:15Z'>
		Great news!
Thanks for the info.
		</comment>
	</comments>
</bug>