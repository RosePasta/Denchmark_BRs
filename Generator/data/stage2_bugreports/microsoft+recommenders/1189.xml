<bug id='1189' author='miguelgfierro' open_date='2020-08-22T09:42:06Z' closed_time='2020-09-11T15:16:59Z'>
	<summary>[BUG] DeepRec test failing</summary>
	<description>
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

There are some tests in DeepRec failing:
&lt;denchmark-code&gt;tests/unit/test_deeprec_model.py ..F.                                    [  7%]
tests/unit/test_deeprec_utils.py ......F                                 [ 10%]

=================================== FAILURES ===================================
_______________________ test_slirec_component_definition _______________________

resource_path = '/home/hoaphumanoid/notebooks/repos/recommenders/tests/unit'

    @pytest.mark.gpu
    def test_slirec_component_definition(resource_path):
        data_path = os.path.join(resource_path, "..", "resources", "deeprec", "slirec")
        yaml_file = os.path.join(
            resource_path,
            "..",
            "..",
            "reco_utils",
            "recommender",
            "deeprec",
            "config",
            "sli_rec.yaml",
        )
        yaml_file_nextitnet = os.path.join(
            resource_path,
            "..",
            "..",
            "reco_utils",
            "recommender",
            "deeprec",
            "config",
            "nextitnet.yaml",
        )
        train_file = os.path.join(data_path, r"train_data")

        if not os.path.exists(train_file):
            train_file = os.path.join(data_path, r"train_data")
            valid_file = os.path.join(data_path, r"valid_data")
            test_file = os.path.join(data_path, r"test_data")
            user_vocab = os.path.join(data_path, r"user_vocab.pkl")
            item_vocab = os.path.join(data_path, r"item_vocab.pkl")
            cate_vocab = os.path.join(data_path, r"category_vocab.pkl")

            reviews_name = "reviews_Movies_and_TV_5.json"
            meta_name = "meta_Movies_and_TV.json"
            reviews_file = os.path.join(data_path, reviews_name)
            meta_file = os.path.join(data_path, meta_name)
            valid_num_ngs = (
                4  # number of negative instances with a positive instance for validation
            )
            test_num_ngs = (
                9  # number of negative instances with a positive instance for testing
            )
            sample_rate = (
                0.01  # sample a small item set for training and testing here for example
            )

            input_files = [
                reviews_file,
                meta_file,
                train_file,
                valid_file,
                test_file,
                user_vocab,
                item_vocab,
                cate_vocab,
            ]
&gt;           download_and_extract(reviews_name, reviews_file)

tests/unit/test_deeprec_model.py:140:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
reco_utils/dataset/amazon_reviews.py:490: in download_and_extract
    _extract_reviews(file_path, dest_path)
reco_utils/dataset/amazon_reviews.py:523: in _extract_reviews
    shutil.copyfileobj(zf, f)
/anaconda/envs/reco_full/lib/python3.6/shutil.py:79: in copyfileobj
    buf = fsrc.read(length)
/anaconda/envs/reco_full/lib/python3.6/gzip.py:276: in read
    return self._buffer.read(size)
/anaconda/envs/reco_full/lib/python3.6/_compression.py:68: in readinto
    data = self.read(len(byte_view))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;gzip._GzipReader object at 0x7f47944772b0&gt;, size = 8192

    def read(self, size=-1):
        if size &lt; 0:
            return self.readall()
        # size=0 is special because decompress(max_length=0) is not supported
        if not size:
            return b""

        # For certain input data, a single
        # call to decompress() may not return
        # any data. In this case, retry until we get some data or reach EOF.
        while True:
            if self._decompressor.eof:
                # Ending case: we've come to the end of a member in the file,
                # so finish up this member, and read a new gzip header.
                # Check the CRC and file size, and set the flag so we read
                # a new member
                self._read_eof()
                self._new_member = True
                self._decompressor = self._decomp_factory(
                    **self._decomp_args)

            if self._new_member:
                # If the _new_member flag is set, we have to
                # jump to the next member, if there is one.
                self._init_read()
                if not self._read_gzip_header():
                    self._size = self._pos
                    return b""
                self._new_member = False

            # Read a chunk of data from the file
            buf = self._fp.read(io.DEFAULT_BUFFER_SIZE)

            uncompress = self._decompressor.decompress(buf, size)
            if self._decompressor.unconsumed_tail != b"":
                self._fp.prepend(self._decompressor.unconsumed_tail)
            elif self._decompressor.unused_data != b"":
                # Prepend the already read bytes to the fileobj so they can
                # be seen by _read_eof() and _read_gzip_header()
                self._fp.prepend(self._decompressor.unused_data)

            if uncompress != b"":
                break
            if buf == b"":
&gt;               raise EOFError("Compressed file ended before the "
                               "end-of-stream marker was reached")
E               EOFError: Compressed file ended before the end-of-stream marker was reached

/anaconda/envs/reco_full/lib/python3.6/gzip.py:482: EOFError
___________________________ test_Sequential_Iterator ___________________________

resource_path = '/home/hoaphumanoid/notebooks/repos/recommenders/tests/unit'

    @pytest.mark.gpu
    def test_Sequential_Iterator(resource_path):
        data_path = os.path.join(resource_path, "..", "resources", "deeprec", "slirec")
        yaml_file = os.path.join(
            resource_path,
            "..",
            "..",
            "reco_utils",
            "recommender",
            "deeprec",
            "config",
            "sli_rec.yaml",
        )
        train_file = os.path.join(data_path, r"train_data")

        if not os.path.exists(train_file):
            valid_file = os.path.join(data_path, r"valid_data")
            test_file = os.path.join(data_path, r"test_data")
            user_vocab = os.path.join(data_path, r"user_vocab.pkl")
            item_vocab = os.path.join(data_path, r"item_vocab.pkl")
            cate_vocab = os.path.join(data_path, r"category_vocab.pkl")

            reviews_name = "reviews_Movies_and_TV_5.json"
            meta_name = "meta_Movies_and_TV.json"
            reviews_file = os.path.join(data_path, reviews_name)
            meta_file = os.path.join(data_path, meta_name)
            valid_num_ngs = (
                4  # number of negative instances with a positive instance for validation
            )
            test_num_ngs = (
                9  # number of negative instances with a positive instance for testing
            )
            sample_rate = (
                0.01  # sample a small item set for training and testing here for example
            )

            input_files = [
                reviews_file,
                meta_file,
                train_file,
                valid_file,
                test_file,
                user_vocab,
                item_vocab,
                cate_vocab,
            ]
            download_and_extract(reviews_name, reviews_file)
            download_and_extract(meta_name, meta_file)
            data_preprocessing(
                *input_files,
                sample_rate=sample_rate,
                valid_num_ngs=valid_num_ngs,
&gt;               test_num_ngs=test_num_ngs
            )

tests/unit/test_deeprec_utils.py:156:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
reco_utils/dataset/amazon_reviews.py:39: in data_preprocessing
    reviews_output = _reviews_preprocessing(reviews_file)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

reviews_readfile = '/home/hoaphumanoid/notebooks/repos/recommenders/tests/unit/../resources/deeprec/slirec/reviews_Movies_and_TV_5.json'

    def _reviews_preprocessing(reviews_readfile):
        logger.info("start reviews preprocessing...")
        reviews_writefile = reviews_readfile + "_output"
        reviews_r = open(reviews_readfile, "r")
        reviews_w = open(reviews_writefile, "w")
        for line in reviews_r:
&gt;           line_new = eval(line.strip())
E             File "&lt;string&gt;", line 1
E               {"reviewerID": "A32M15RZXWZ5GS", "asin": "B0047S4UPW", "reviewerName": "Jacqueline M. Raines \"dtcooly\"", "helpful
E                                                                                                                                 ^
E           SyntaxError: EOL while scanning string literal

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;In which platform does it happen?&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;How do we replicate the issue?&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Expected behavior (i.e. solution)&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Other Comments&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='miguelgfierro' date='2020-08-22T09:43:25Z'>
		&lt;denchmark-link:https://github.com/Leavingseason&gt;@Leavingseason&lt;/denchmark-link&gt;
 it looks that one issue is with the unzip and another one with some data format? Let me know whether someone in your team can provide some idea of what might be happening
		</comment>
	</comments>
</bug>