<bug id='1125' author='miguelgfierro' open_date='2020-06-19T10:39:41Z' closed_time='2020-06-30T10:19:14Z'>
	<summary>[BUG] error in unit test nni</summary>
	<description>
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;$ pytest tests/unit/test_nni_utils.py

=========================================================================== test session starts ===========================================================================
platform linux -- Python 3.6.10, pytest-5.4.3, py-1.8.1, pluggy-0.13.1
rootdir: /home/miguel/repos/Recommenders
collected 11 items

tests/unit/test_nni_utils.py ..........F                                                                                                                            [100%]

================================================================================ FAILURES =================================================================================
_____________________________________________________________________________ test_get_trials _____________________________________________________________________________

    @pytest.mark.skipif(sys.platform == "win32", reason="nni not installable on windows")
    def test_get_trials():
        with TemporaryDirectory() as tmp_dir1, TemporaryDirectory() as tmp_dir2:
            mock_trials = [
                {
                    "finalMetricData": [{"data": '{"rmse":0.8,"default":0.3}'}],
                    "logPath": "file://localhost:{}".format(tmp_dir1),
                },
                {
                    "finalMetricData": [{"data": '{"rmse":0.9,"default":0.2}'}],
                    "logPath": "file://localhost:{}".format(tmp_dir2),
                },
            ]
            metrics1 = {"rmse": 0.8, "precision_at_k": 0.3}
            with open(os.path.join(tmp_dir1, "metrics.json"), "w") as f:
                json.dump(metrics1, f)
            params1 = {
                "parameter_id": 1,
                "parameter_source": "algorithm",
                "parameters": {"n_factors": 100, "reg": 0.1},
            }
            with open(os.path.join(tmp_dir1, "parameter.cfg"), "w") as f:
                json.dump(params1, f)
            metrics2 = {"rmse": 0.9, "precision_at_k": 0.2}
            with open(os.path.join(tmp_dir2, "metrics.json"), "w") as f:
                json.dump(metrics2, f)
            params2 = {
                "parameter_id": 2,
                "parameter_source": "algorithm",
                "parameters": {"n_factors": 50, "reg": 0.02},
            }
            with open(os.path.join(tmp_dir2, "parameter.cfg"), "w") as f:
                json.dump(params2, f)

            with patch(
                "requests.get", side_effect=lambda url: mocked_trials_get(url, mock_trials)
            ):
                trials, best_metrics, best_params, best_trial_path = get_trials(
&gt;                   optimize_mode="maximize"
                )

tests/unit/test_nni_utils.py:204:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
reco_utils/tuning/nni/nni_utils.py:117: in get_trials
    for trial in all_trials
reco_utils/tuning/nni/nni_utils.py:117: in &lt;listcomp&gt;
    for trial in all_trials
../../anaconda/envs/reco_full/lib/python3.6/ast.py:85: in literal_eval
    return _convert(node_or_string)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

node = {'default': 0.3, 'rmse': 0.8}

    def _convert(node):
        if isinstance(node, Constant):
            return node.value
        elif isinstance(node, (Str, Bytes)):
            return node.s
        elif isinstance(node, Num):
            return node.n
        elif isinstance(node, Tuple):
            return tuple(map(_convert, node.elts))
        elif isinstance(node, List):
            return list(map(_convert, node.elts))
        elif isinstance(node, Set):
            return set(map(_convert, node.elts))
        elif isinstance(node, Dict):
            return dict((_convert(k), _convert(v)) for k, v
                        in zip(node.keys, node.values))
        elif isinstance(node, NameConstant):
            return node.value
        elif isinstance(node, UnaryOp) and isinstance(node.op, (UAdd, USub)):
            operand = _convert(node.operand)
            if isinstance(operand, _NUM_TYPES):
                if isinstance(node.op, UAdd):
                    return + operand
                else:
                    return - operand
        elif isinstance(node, BinOp) and isinstance(node.op, (Add, Sub)):
            left = _convert(node.left)
            right = _convert(node.right)
            if isinstance(left, _NUM_TYPES) and isinstance(right, _NUM_TYPES):
                if isinstance(node.op, Add):
                    return left + right
                else:
                    return left - right
&gt;       raise ValueError('malformed node or string: ' + repr(node))
E       ValueError: malformed node or string: {'rmse': 0.8, 'default': 0.3}

../../anaconda/envs/reco_full/lib/python3.6/ast.py:84: ValueError


&lt;/denchmark-code&gt;

hey &lt;denchmark-link:https://github.com/seanytak&gt;@seanytak&lt;/denchmark-link&gt;
, I'm reviewing the unit test and there is an error with this one. Would you mind to take a look?
&lt;denchmark-h:h3&gt;In which platform does it happen?&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;How do we replicate the issue?&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Expected behavior (i.e. solution)&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Other Comments&lt;/denchmark-h&gt;

	</description>
	<comments>
	</comments>
</bug>