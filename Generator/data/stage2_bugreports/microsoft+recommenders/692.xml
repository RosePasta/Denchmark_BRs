<bug id='692' author='loomlike' open_date='2019-03-28T22:49:07Z' closed_time='2019-04-02T10:54:08Z'>
	<summary>[BUG] Databricks install failure if the egg file already exists</summary>
	<description>
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

Databricks installation fails when the egg file already exists in the cluster.
Here is the error:

Traceback (most recent call last):
File "/data/anaconda/envs/reco_pyspark/lib/python3.6/site-packages/databricks_cli/sdk/api_client.py", line 121, in perform_query
resp.raise_for_status()
File "/data/anaconda/envs/reco_pyspark/lib/python3.6/site-packages/requests/models.py", line 940, in raise_for_status
raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://eastus.azuredatabricks.net/api/2.0/dbfs/create


During handling of the above exception, another exception occurred:


Traceback (most recent call last):
File "scripts/databricks_install.py", line 275, in 
recursive=False, src=myegg, dst=upload_path, overwrite=args.overwrite
File "/data/anaconda/envs/reco_pyspark/lib/python3.6/site-packages/databricks_cli/dbfs/api.py", line 203, in cp
self._copy_to_dbfs_non_recursive(src, DbfsPath(dst), overwrite, headers=headers)
File "/data/anaconda/envs/reco_pyspark/lib/python3.6/site-packages/databricks_cli/dbfs/api.py", line 142, in _copy_to_dbfs_non_recursive
self.put_file(src, dbfs_path_dst, overwrite, headers=headers)
File "/data/anaconda/envs/reco_pyspark/lib/python3.6/site-packages/databricks_cli/dbfs/api.py", line 96, in put_file
handle = self.client.create(dbfs_path.absolute_path, overwrite, headers=headers)['handle']
File "/data/anaconda/envs/reco_pyspark/lib/python3.6/site-packages/databricks_cli/sdk/service.py", line 496, in create
return self.client.perform_query('POST', '/dbfs/create', data=_data, headers=headers)
File "/data/anaconda/envs/reco_pyspark/lib/python3.6/site-packages/databricks_cli/sdk/api_client.py", line 129, in perform_query
raise requests.exceptions.HTTPError(message, response=e.response)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://eastus.azuredatabricks.net/api/2.0/dbfs/create
Response from server:
{ 'error_code': 'RESOURCE_ALREADY_EXISTS',
'message': 'A file or directory already exists at the input path '
'dbfs:/FileStore/jars/Recommenders.egg.'}

It looks like there is another error shown in the top of the message, but tested and confirmed it goes through without any errors if remove the existing egg file from dbfs.
&lt;denchmark-h:h3&gt;In which platform does it happen?&lt;/denchmark-h&gt;


Azure Databricks

&lt;denchmark-h:h3&gt;How do we replicate the issue?&lt;/denchmark-h&gt;

Install egg twice.
&lt;denchmark-h:h3&gt;Expected behavior (i.e. solution)&lt;/denchmark-h&gt;

Overwrite the existing library file
&lt;denchmark-h:h3&gt;Other Comments&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='loomlike' date='2019-03-28T22:56:52Z'>
		You can use --overwrite when calling the python script. Perhaps the error should be caught by the script and appropriate options provided?
		</comment>
		<comment id='2' author='loomlike' date='2019-03-28T23:03:31Z'>
		that would be helpful, because the first part of the error is not very readable.
so, if the error code is RESOURCE_ALREADY_EXISTS, throw something like:
"the old-library already exists in the cluster. you may use '--overwrite' to force install"
		</comment>
		<comment id='3' author='loomlike' date='2019-03-29T10:28:11Z'>
		I need to update the databricks cli for accommodating the new version of MMLspark, therefore I will take a look into this
		</comment>
		<comment id='4' author='loomlike' date='2019-04-01T22:28:38Z'>
		Just fixed &lt;denchmark-link:https://github.com/microsoft/recommenders/issues/702&gt;#702&lt;/denchmark-link&gt;
 - will fix this in a little bit as well.
		</comment>
	</comments>
</bug>