<bug id='1207' author='yegorkryukov' open_date='2020-09-25T01:16:45Z' closed_time='2020-11-13T14:36:33Z'>
	<summary>[BUG]</summary>
	<description>
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

The default conda environment with pyspark 2.4.3. doesn't work on Java versions &gt;8.
Spark 2.4.3 works on Java version 8:

As of Spark 2.4.x
Spark runs on Java 8, Python 2.7+/3.4+ and R 3.1+. For the Scala API, Spark 2.4.4 uses Scala 2.12. You will need to use a compatible Scala version (2.12.x)

This isn't mentioned anywhere in the readme. So if you have the latest (&gt;8) Java version the notebook won't work. Took me three nights to figure it out.
&lt;denchmark-h:h3&gt;In which platform does it happen?&lt;/denchmark-h&gt;

macOS Catalina
&lt;denchmark-h:h3&gt;How do we replicate the issue?&lt;/denchmark-h&gt;

Create a conda environment for pyspark using &lt;denchmark-link:https://github.com/microsoft/recommenders/blob/master/SETUP.md#dependencies-setup&gt;this README&lt;/denchmark-link&gt;

Run als_movielens notebook
The cell with data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema) fails:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
Py4JError                                 Traceback (most recent call last)
&lt;ipython-input-3-5495a148a9c9&gt; in &lt;module&gt;
      1 # the following settings work well for debugging locally on VM - change when running on a cluster
      2 # set up a giant single executor with many threads and specify memory cap
----&gt; 3 spark = start_or_get_spark("ALS PySpark", memory="16g")

~/recommenders/reco_utils/common/spark_utils.py in start_or_get_spark(app_name, url, memory, config, packages, jars, repository)
     62 
     63     spark_opts.append("getOrCreate()")
---&gt; 64     return eval(".".join(spark_opts))

~/recommenders/reco_utils/common/spark_utils.py in &lt;module&gt;

~/conda/lib/python3.6/site-packages/pyspark/sql/session.py in getOrCreate(self)
    171                     for key, value in self._options.items():
    172                         sparkConf.set(key, value)
--&gt; 173                     sc = SparkContext.getOrCreate(sparkConf)
    174                     # This SparkContext may be an existing one.
    175                     for key, value in self._options.items():

~/conda/lib/python3.6/site-packages/pyspark/context.py in getOrCreate(cls, conf)
    365         with SparkContext._lock:
    366             if SparkContext._active_spark_context is None:
--&gt; 367                 SparkContext(conf=conf or SparkConf())
    368             return SparkContext._active_spark_context
    369 

~/conda/lib/python3.6/site-packages/pyspark/context.py in __init__(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)
    134         try:
    135             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
--&gt; 136                           conf, jsc, profiler_cls)
    137         except:
    138             # If an error occurs, clean up in order to allow future SparkContext creation:

~/conda/lib/python3.6/site-packages/pyspark/context.py in _do_init(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)
    205         self._accumulatorServer = accumulators._start_update_server(auth_token)
    206         (host, port) = self._accumulatorServer.server_address
--&gt; 207         self._javaAccumulator = self._jvm.PythonAccumulatorV2(host, port, auth_token)
    208         self._jsc.sc().register(self._javaAccumulator)
    209 

~/conda/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args)
   1523         answer = self._gateway_client.send_command(command)
   1524         return_value = get_return_value(
-&gt; 1525             answer, self._gateway_client, None, self._fqn)
   1526 
   1527         for temp_arg in temp_args:

~/conda/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
    330                 raise Py4JError(
    331                     "An error occurred while calling {0}{1}{2}. Trace:\n{3}\n".
--&gt; 332                     format(target_id, ".", name, value))
    333         else:
    334             raise Py4JError(

Py4JError: An error occurred while calling None.org.apache.spark.api.python.PythonAccumulatorV2. Trace:
py4j.Py4JException: Constructor org.apache.spark.api.python.PythonAccumulatorV2([class java.lang.String, class java.lang.Integer, class java.lang.String]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:179)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:196)
	at py4j.Gateway.invoke(Gateway.java:237)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior (i.e. solution)&lt;/denchmark-h&gt;

The notebook should run.
Solution:

This SO thread helped.


Install asdf and Java v8:

&lt;denchmark-code&gt;brew install asdf
asdf plugin add Java
asdf install java adoptopenjdk-8.0.265+1
asdf global java adoptopenjdk-8.0.265+1
. ~/.asdf/plugins/java/set-java-home.zsh
&lt;/denchmark-code&gt;


Run jupyter notebook

&lt;denchmark-h:h3&gt;Other Comments&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='yegorkryukov' date='2020-09-25T13:00:40Z'>
		Thanks for the feedback &lt;denchmark-link:https://github.com/yegorkryukov&gt;@yegorkryukov&lt;/denchmark-link&gt;
 , sorry you had so much pain here. There is a small note in the setup section for debugging installation issues on DSVMs that indicates Java 8 should be used. But I think you're right, this needs to be more predominantly described.
Would you be able to make some changes to clarify this and push a PR?
		</comment>
		<comment id='2' author='yegorkryukov' date='2020-09-25T14:42:48Z'>
		&lt;denchmark-link:https://github.com/gramhagen&gt;@gramhagen&lt;/denchmark-link&gt;
 Thanks Scott. I will submit tonight.
		</comment>
		<comment id='3' author='yegorkryukov' date='2020-09-29T22:51:49Z'>
		Took longer than I thought it would but created a &lt;denchmark-link:https://github.com/microsoft/recommenders/pull/1209&gt;PR&lt;/denchmark-link&gt;
. This is my first time doing it for the public repo, please let me know if I need to be fixing anything.
		</comment>
	</comments>
</bug>