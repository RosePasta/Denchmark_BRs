<bug id='871' author='miguelgfierro' open_date='2019-07-21T22:06:18Z' closed_time='2019-07-22T20:40:04Z'>
	<summary>[BUG] in load_spark_df</summary>
	<description>
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;tests/smoke/test_criteo.py .                                             [ 25%]
tests/smoke/test_movielens.py F                                          [ 50%]
tests/smoke/test_notebooks_pyspark.py ..                                 [100%]

=================================== FAILURES ===================================
_ test_load_spark_df[100k-100000-1682-1-Toy Story (1995)-Animation|Children's|Comedy-1995] _

size = '100k', num_samples = 100000, num_movies = 1682, movie_example = 1
title_example = 'Toy Story (1995)'
genres_example = "Animation|Children's|Comedy", year_example = '1995'
tmp = '/tmp/pytest-of-recocat/pytest-972/tmpisofmnln'
spark = &lt;pyspark.sql.session.SparkSession object at 0x7f8e787ecef0&gt;

    @pytest.mark.smoke
    @pytest.mark.spark
    @pytest.mark.parametrize(
        "size, num_samples, num_movies, movie_example, title_example, genres_example, year_example",
        [
            (
                "100k",
                100000,
                1682,
                1,
                "Toy Story (1995)",
                "Animation|Children's|Comedy",
                "1995",
            )
        ],
    )
    def test_load_spark_df(
        size,
        num_samples,
        num_movies,
        movie_example,
        title_example,
        genres_example,
        year_example,
        tmp,
        spark,
    ):
        """Test MovieLens dataset load into pySpark.DataFrame"""
    
        # Test if correct data are loaded
        header = ["1", "2", "3"]
        schema = StructType(
            [
                StructField("u", IntegerType()),
                StructField("m", IntegerType()),
            ]
        )
        with pytest.warns(Warning):
            df = load_spark_df(
                spark, size=size, local_cache_path=tmp, header=header, schema=schema
            )
            assert df.count() == num_samples
            # Test if schema is used when both schema and header are provided
            assert len(df.columns) == len(schema)
            # Test if raw-zip file, rating file, and item file are cached
            assert len(os.listdir(tmp)) == 3
    
        # Test title, genres, and released year load
        header = ["a", "b", "c", "d", "e"]
        with pytest.warns(Warning):
            df = load_spark_df(
                spark,
                size=size,
                local_cache_path=tmp,
                header=header,
                title_col="Title",
                genres_col="Genres",
                year_col="Year",
            )
            assert df.count() == num_samples
            assert (
                len(df.columns) == 7
            )  # 4 header columns (user, item, rating, timestamp) and 3 feature columns
            assert "e" not in df.columns  # only the first 4 header columns are used
            # Get two records of the same items and check if the item-features are the same.
            head = df.filter(col("b") == movie_example).limit(2)
            title = head.select("Title").collect()
            assert title[0][0] == title[1][0]
            assert title[0][0] == title_example
            genres = head.select("Genres").collect()
            assert genres[0][0] == genres[1][0]
            assert genres[0][0] == genres_example
            year = head.select("Year").collect()
            assert year[0][0] == year[1][0]
            assert year[0][0] == year_example
    
        # Test default arguments
&gt;       df = load_spark_df(spark, size)

tests/smoke/test_movielens.py:208: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

spark = &lt;pyspark.sql.session.SparkSession object at 0x7f8e787ecef0&gt;
size = '100k', header = None
schema = ('userID', 'itemID', 'rating', 'timestamp'), local_cache_path = None
dbutils = None, title_col = None, genres_col = None, year_col = None

    def load_spark_df(
        spark,
        size="100k",
        header=None,
        schema=None,
        local_cache_path=None,
        dbutils=None,
        title_col=None,
        genres_col=None,
        year_col=None,
    ):
        """Loads the MovieLens dataset as `pyspark.DataFrame`.
    
        Download the dataset from http://files.grouplens.org/datasets/movielens, unzip, and load as `pyspark.DataFrame`.
    
        To load movie information only, you can use `load_item_df` function.
    
        Args:
            spark (pyspark.SparkSession): Spark session.
            size (str): Size of the data to load. One of ("100k", "1m", "10m", "20m").
            header (list or tuple): Rating dataset header.
                If schema is provided, this argument is ignored.
            schema (pyspark.StructType): Dataset schema.
            local_cache_path (str): Path (directory or a zip file) to cache the downloaded zip file.
                If None, all the intermediate files will be stored in a temporary directory and removed after use.
            dbutils (Databricks.dbutils): Databricks utility object
            title_col (str): Title column name. If None, the column will not be loaded.
            genres_col (str): Genres column name. Genres are '|' separated string.
                If None, the column will not be loaded.
            year_col (str): Movie release year column name. If None, the column will not be loaded.
    
        Returns:
            pyspark.DataFrame: Movie rating dataset.
    
        **Examples**
    
        .. code-block:: python
    
            # To load just user-id, item-id, and ratings from MovieLens-1M dataset:
            spark_df = load_spark_df(spark, '1m', ('UserId', 'ItemId', 'Rating'))
    
            # The schema can be defined as well:
            schema = StructType([
                StructField(DEFAULT_USER_COL, IntegerType()),
                StructField(DEFAULT_ITEM_COL, IntegerType()),
                StructField(DEFAULT_RATING_COL, FloatType()),
                StructField(DEFAULT_TIMESTAMP_COL, LongType()),
                ])
            spark_df = load_spark_df(spark, '1m', ('UserId', 'ItemId', 'Rating'), schema=schema)
    
            # To load rating's timestamp together:
            spark_df = load_spark_df(spark, '1m', ('UserId', 'ItemId', 'Rating', 'Timestamp'))
    
            # To load movie's title, genres, and released year info along with the ratings data:
            spark_df = load_spark_df(spark, '1m', ('UserId', 'ItemId', 'Rating', 'Timestamp'),
                title_col='Title',
                genres_col='Genres',
                year_col='Year'
            )
    
            # On DataBricks, pass the dbutils argument as follows:
            spark_df = load_spark_df(spark, dbutils=dbutils)
        """
        size = size.lower()
        if size not in DATA_FORMAT:
            raise ValueError(ERROR_MOVIE_LENS_SIZE)
    
        schema = _get_schema(header, schema)
        if len(schema) &lt; 2:
            raise ValueError(ERROR_HEADER)
    
&gt;       movie_col = schema[1].name
E       AttributeError: 'str' object has no attribute 'name'

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;In which platform does it happen?&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;How do we replicate the issue?&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Expected behavior (i.e. solution)&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Other Comments&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='miguelgfierro' date='2019-07-21T22:07:59Z'>
		hey &lt;denchmark-link:https://github.com/loomlike&gt;@loomlike&lt;/denchmark-link&gt;
, do you think this is related to the latest changes in the headers?
		</comment>
		<comment id='2' author='miguelgfierro' date='2019-07-22T14:21:20Z'>
		I'll take a look
		</comment>
	</comments>
</bug>