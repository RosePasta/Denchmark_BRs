<bug id='1136' author='yjw1029' open_date='2020-07-03T18:32:10Z' closed_time='2020-07-09T13:33:31Z'>
	<summary>[BUG] LSTUR and NRMS in News Rec Module</summary>
	<description>
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;


Attention layer in LSTUR doesn't mask padding which will effect model performance
Can't save NRMS model

&lt;denchmark-h:h3&gt;How do we replicate the issue?&lt;/denchmark-h&gt;


Create a conda environment for gpu
run example/00_quick_start/nrms_synthetic.ipynb
run cell "model.model.save_model(path)"
run example/00_quick_start/lstur_synthetic.ipynb

&lt;denchmark-h:h3&gt;Expected behavior (i.e. solution)&lt;/denchmark-h&gt;


change get_config method of SelfAttention layer in reco_utils/recommender/newsrec/layers.py.
add masking attention weight in AttLayer2 layer.

	</description>
	<comments>
	</comments>
</bug>