<bug id='851' author='ThierryDeruyttere' open_date='2018-10-10T07:49:18Z' closed_time='2018-10-18T12:04:30Z'>
	<summary>Problem with semantic segmentation in carla 0.9.0</summary>
	<description>
Hi,
I'm trying to get the semantic segmentations from the carla simulator by using the Python API.
I'm using the following python code to create two camera's: one that captures the current RGB view and the other one should get the semantic segmentation of that view.
...

def save_to_disk(image, name):
    """Save this image to disk (requires PIL installed)."""

    filename = '{}/{:0&gt;6d}_{:s}.png'.format(name, image.frame_number, image.type)

    image = PImage.frombytes(
        mode="RGBA",
        size=(image.width, image.height),
        data=image.raw_data,
        decoder_name='raw')

    color = image.split()
    image = PImage.merge("RGB", color[2::-1])

    folder = os.path.dirname(filename)
    if not os.path.isdir(folder):
        os.makedirs(folder)
    image.save(filename)

def save_semantic_img(image, name):
    res = labels_to_cityscapes_palette(image)

    filename = '{}/{:0&gt;6d}_{:s}.png'.format(name, image.frame_number, image.type)

    image = PImage.fromarray(res)

    folder = os.path.dirname(filename)
    if not os.path.isdir(folder):
        os.makedirs(folder)
    image.save(filename)

bp = world.get_blueprint_library()
blueprint = bp.find('sensor.camera')
blueprint.set_attribute('post_processing', 'SceneFinal')
LOC = Location(x=155.5, y=55.8, z=39)
transform = Transform(LOC, Rotation(yaw=90))
cam1 = world.spawn_actor(blueprint, transform)
cam1.listen(lambda image: save_to_disk(image, "scene"))

blueprint2 = bp.find('sensor.camera')
blueprint.set_attribute('post_processing', 'SemanticSegmentation')
transform = Transform(LOC, Rotation(yaw=90))
cam2 = world.spawn_actor(blueprint, transform)
cam2.listen(lambda image: save_semantic_img(image, "semantic"))

time.sleep(4)
These are the images I get:
&lt;denchmark-link:https://user-images.githubusercontent.com/6353651/46720636-70c30580-cc71-11e8-8aae-9891158d5412.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/6353651/46721025-5e959700-cc72-11e8-8f96-a0822d39091f.png&gt;&lt;/denchmark-link&gt;

As you can see the semantic image looks really weird but I have no idea how this came to be. Did anyone have the same problem?
	</description>
	<comments>
		<comment id='1' author='ThierryDeruyttere' date='2018-10-11T10:46:05Z'>
		Interesting, I would expect the old image converter to work with the new API, it seems it's mixing columns and rows.
In any case, I recently ported these methods to the new API (PR &lt;denchmark-link:https://github.com/carla-simulator/carla/pull/855&gt;#855&lt;/denchmark-link&gt;
), if you can use that branch that works pretty well and fast. It will be included in the next release, probably ready by the end of next week.
		</comment>
		<comment id='2' author='ThierryDeruyttere' date='2018-10-16T19:21:44Z'>
		So I've tried the new API out (merged pr &lt;denchmark-link:https://github.com/carla-simulator/carla/pull/855&gt;#855&lt;/denchmark-link&gt;
 ). I try to get the semantic segmentation by using the following code.
...
i = 1
def save_semantic_img(image, name):
    global i
    image.convert(ColorConverter.CityScapesPalette)
    image.save_to_disk(name+"/{}.png".format(i))
    i+=1

blueprint2 = bp.find('sensor.camera.semantic_segmentation')
#blueprint.set_attribute('post_processing', 'SemanticSegmentation')
transform = Transform(LOC, Rotation(yaw=90))
cam2 = world.spawn_actor(blueprint, transform)
cam2.listen(lambda image: save_semantic_img(image, "semantic"))
gives me the following image:
&lt;denchmark-link:https://user-images.githubusercontent.com/6353651/47041574-75b01980-d189-11e8-809d-24b346025d8c.png&gt;&lt;/denchmark-link&gt;

The normal scene is:
&lt;denchmark-link:https://user-images.githubusercontent.com/6353651/47041749-ee16da80-d189-11e8-8951-fee1738a95dc.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='ThierryDeruyttere' date='2018-10-17T10:16:22Z'>
		Hi &lt;denchmark-link:https://github.com/ThierryDeruyttere&gt;@ThierryDeruyttere&lt;/denchmark-link&gt;
,
That looks familiar, it's a depth image converted to CityScapes palette. I'm guessing your blueprint variable is a depth camera ðŸ˜‰
blueprint2 = bp.find('sensor.camera.semantic_segmentation')
^~~~~~~~~~
cam2 = world.spawn_actor(blueprint, transform)
                         ^~~~~~~~~
And btw, if you convert the image when saving is slightly more efficient as it doesn't have to modify the image
image.save_to_disk('filename', ColorConverter.CityScapesPalette)
		</comment>
		<comment id='4' author='ThierryDeruyttere' date='2018-10-17T12:07:25Z'>
		Hi &lt;denchmark-link:https://github.com/nsubiron&gt;@nsubiron&lt;/denchmark-link&gt;
,
Oops that is quite embarrassing  ðŸ˜„.
I changed it to blueprint2 but now I just get a black image... (blueprint was a rgb sensor btw :p)
Also when i'm using the rgb sensor and I just save it (so no color conversion), I get a white image.
Also maybe a question about the API, will the different sensors remain as a blueprint in python? (thus sensor.camera.rgb, sensor.camera.depth, ...) Because I don't see why you would need to have the different blueprints and still have the option do to color conversions?
		</comment>
		<comment id='5' author='ThierryDeruyttere' date='2018-10-17T13:30:48Z'>
		Oh true, it's not depth is rgb :D
Are you talking only about the first frame? cause first one usually comes empty. Otherwise is strange, it works on all the tests I've made.
Having them as different sensors IMO is clearer as people usually struggled to find the post-processing attribute, plus internally it's easier to implement. But all of the cameras produce the same data, an "Image" object, then this images can be converted to anything, or use them as they come. In some cases, depth for instance, you have two conversions to choose from; and possibly in the future we have a different sem-seg palette for instance.
		</comment>
		<comment id='6' author='ThierryDeruyttere' date='2018-10-18T06:12:40Z'>
		Hi &lt;denchmark-link:https://github.com/nsubiron&gt;@nsubiron&lt;/denchmark-link&gt;
,
I just did some more tests. I can confirm that the segmentation camera works fine (check below). So thanks a lot for that! :D
&lt;denchmark-link:https://user-images.githubusercontent.com/6353651/47134107-db94c200-d2ab-11e8-9a87-c25e3c8207e9.png&gt;&lt;/denchmark-link&gt;

It only does weird things when I spawn static meshes through python (custom code). The semantic image remains black then. So I'll need to check my code out. On the other hand for the rgb sensor all images remain white (tested this on Town1 at x=155.5, y=55.8, z=39) not only the first one. It also stays white when spawning static meshes but this is more of a problem on my end.

Having them as different sensors IMO is clearer as people usually struggled to find the post-processing attribute, plus internally it's easier to implement. But all of the cameras produce the same data, an "Image" object, then this images can be converted to anything, or use them as they come. In some cases, depth for instance, you have two conversions to choose from; and possibly in the future we have a different sem-seg palette for instance.

Okay fair enough :)
		</comment>
		<comment id='7' author='ThierryDeruyttere' date='2018-10-18T08:30:07Z'>
		I did more tests and I found out that when using rgb camera with a color conversion gives me some output which you can see below.
Depth:
&lt;denchmark-link:https://user-images.githubusercontent.com/6353651/47141296-a181eb00-d2c0-11e8-9bf3-af03db1cf7cd.png&gt;&lt;/denchmark-link&gt;

LogarithmicDepth:
&lt;denchmark-link:https://user-images.githubusercontent.com/6353651/47141332-b5c5e800-d2c0-11e8-9ca6-c25a04a96859.png&gt;&lt;/denchmark-link&gt;

but if I use None, it remains white.
		</comment>
		<comment id='8' author='ThierryDeruyttere' date='2018-10-18T10:57:18Z'>
		Hi &lt;denchmark-link:https://github.com/ThierryDeruyttere&gt;@ThierryDeruyttere&lt;/denchmark-link&gt;
,
Hmm it looks like it could be the alpha of the image, we had issues with this in the past, but the approach we have now seemed to work fine on Linux and Windows, maybe not so much on Mac.
Could you please try applying these changes and recompiling PythonAPI? Basically I'm trying to force the saving methods to ignore the alpha channel.
diff --git a/LibCarla/source/carla/image/ImageView.h b/LibCarla/source/carla/image/ImageView.h
index ef1a57c..f04839e 100644
--- a/LibCarla/source/carla/image/ImageView.h
+++ b/LibCarla/source/carla/image/ImageView.h
@@ -48,11 +48,13 @@ namespace image {
     }
 
     static auto MakeView(sensor::data::ImageTmpl&lt;sensor::data::Color&gt; &amp;image) {
-      return MakeViewFromSensorImage&lt;boost::gil::bgra8_pixel_t&gt;(image);
+      return boost::gil::color_converted_view&lt;boost::gil::bgr8_pixel_t&gt;(
+          MakeViewFromSensorImage&lt;boost::gil::bgra8_pixel_t&gt;(image));
     }
 
     static auto MakeView(const sensor::data::ImageTmpl&lt;sensor::data::Color&gt; &amp;image) {
-      return MakeViewFromSensorImage&lt;boost::gil::bgra8c_pixel_t&gt;(image);
+      return boost::gil::color_converted_view&lt;boost::gil::bgr8c_pixel_t&gt;(
+          MakeViewFromSensorImage&lt;boost::gil::bgra8c_pixel_t&gt;(image));
     }
 
     template &lt;typename SrcViewT, typename DstPixelT, typename CC&gt;
		</comment>
		<comment id='9' author='ThierryDeruyttere' date='2018-10-18T11:16:54Z'>
		Hi &lt;denchmark-link:https://github.com/nsubiron&gt;@nsubiron&lt;/denchmark-link&gt;
,
I'm afraid this didn't work, all images are black now instead of white.
Even when using a color convertor, everything is black.
		</comment>
		<comment id='10' author='ThierryDeruyttere' date='2018-10-18T11:43:12Z'>
		Hi &lt;denchmark-link:https://github.com/nsubiron&gt;@nsubiron&lt;/denchmark-link&gt;
,
Thanks to your suggestion I got it to work (in a bit of a hack though).
I removed the change you proposed and just removed the alpha channel in python.
def save_to_disk(image, name):
    global j
    """Save this image to disk (requires PIL installed)."""
    #image.convert(ColorConverter.CityScapesPalette)
    #print image.raw_data
    array = np.frombuffer(image.raw_data, dtype=np.dtype("uint8"))
    array = np.reshape(array, (image.height, image.width, 4))
    array = array[:, :, :3]
    array = array[:, :, ::-1]
    scipy.misc.imsave(name+'/{}_rgb.png'.format(j), array)
    j+=1
This gives me the correct image.
&lt;denchmark-link:https://user-images.githubusercontent.com/6353651/47152000-aef89e80-d2db-11e8-8abb-ca1077ce1c02.png&gt;&lt;/denchmark-link&gt;

But you are right, apparently the alpha channel creates a problem on mac.
		</comment>
		<comment id='11' author='ThierryDeruyttere' date='2018-10-18T12:00:46Z'>
		Ok, well good to know that it's the alpha. I'll open an issue referencing this so we can investigate a solution that works on every platform.
		</comment>
		<comment id='12' author='ThierryDeruyttere' date='2018-10-18T12:01:29Z'>
		&lt;denchmark-link:https://github.com/nsubiron&gt;@nsubiron&lt;/denchmark-link&gt;
 Sounds good! I think we can close this for now then?
		</comment>
		<comment id='13' author='ThierryDeruyttere' date='2018-10-18T12:02:57Z'>
		Ok, perfect
		</comment>
		<comment id='14' author='ThierryDeruyttere' date='2018-12-19T15:00:06Z'>
		
Hi @nsubiron,
I just did some more tests. I can confirm that the segmentation camera works fine (check below). So thanks a lot for that! :D

It only does weird things when I spawn static meshes through python (custom code). The semantic image remains black then. So I'll need to check my code out. On the other hand for the rgb sensor all images remain white (tested this on Town1 at x=155.5, y=55.8, z=39) not only the first one. It also stays white when spawning static meshes but this is more of a problem on my end.

Having them as different sensors IMO is clearer as people usually struggled to find the post-processing attribute, plus internally it's easier to implement. But all of the cameras produce the same data, an "Image" object, then this images can be converted to anything, or use them as they come. In some cases, depth for instance, you have two conversions to choose from; and possibly in the future we have a different sem-seg palette for instance.

Okay fair enough :)

Hi &lt;denchmark-link:https://github.com/ThierryDeruyttere&gt;@ThierryDeruyttere&lt;/denchmark-link&gt;

Could you share the code or steps how to extract the semantic segmentation images from carla simulator.
		</comment>
		<comment id='15' author='ThierryDeruyttere' date='2018-12-19T19:33:17Z'>
		&lt;denchmark-link:https://github.com/Deepak3994&gt;@Deepak3994&lt;/denchmark-link&gt;

Hi there,
You can find the code that I was using at: &lt;denchmark-link:https://github.com/ThierryDeruyttere/carla-simulator-mac/blob/master/mesh.py&gt;https://github.com/ThierryDeruyttere/carla-simulator-mac/blob/master/mesh.py&lt;/denchmark-link&gt;

Though becareful there might be things that have changed with the new 0.9.1 release. I didn't upgrade to it as I'm currently working on something else.
		</comment>
		<comment id='16' author='ThierryDeruyttere' date='2019-11-03T03:29:49Z'>
		I have the same problem!
I use Carla 0.9.5 in linux,. I change the code in PythonAPI.examples.manual_control_steeringwheel.py to save semantic_segmentation image.
and I got this image:
&lt;denchmark-link:https://user-images.githubusercontent.com/32706937/68079906-76672c80-fe2c-11e9-9b65-0aa7ebd4b92f.png&gt;&lt;/denchmark-link&gt;

The normal scene is:
&lt;denchmark-link:https://user-images.githubusercontent.com/32706937/68079913-8d0d8380-fe2c-11e9-92c8-5e7b3bbf2f72.png&gt;&lt;/denchmark-link&gt;

I just use this code to save it:
image_semseg.convert(cc.CityScapesPalette)
image_semseg.save_to_disk('_out_seg/%08d' % image.frame_number)
Could you help me to solve it?
Very thanks!
		</comment>
		<comment id='17' author='ThierryDeruyttere' date='2020-01-25T07:44:23Z'>
		I have another issue with the semantic segmentation sensor... I'm just taking the image from the sensor and send it to the labels_to_cityscapes_palette() function and getting this..
&lt;denchmark-link:https://user-images.githubusercontent.com/27896633/73118059-3d37e780-3f57-11ea-8755-18114916ae17.png&gt;&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>