<bug id='2842' author='RyanHopkins7' open_date='2020-05-11T23:14:39Z' closed_time='2020-07-09T08:24:47Z'>
	<summary>Lidar attached to vehicle with SpringArm results in limited FOV</summary>
	<description>
Hello,
I was following the &lt;denchmark-link:https://carla.readthedocs.io/en/latest/tuto_G_retrieve_data/#lidar-raycast-sensor&gt;lidar raycast sensor guide&lt;/denchmark-link&gt;
 which suggests using the SpringArm attachment. Using SpringArm results in a non-rotating FOV limited to sight of the front-left and back-right sides of the vehicle as shown below:
&lt;denchmark-link:https://user-images.githubusercontent.com/20050820/81621059-73409080-93bb-11ea-9ac1-98a3b61f492b.png&gt;&lt;/denchmark-link&gt;

This is what the lidar output of the same scene using the Rigid attachment looks like:
&lt;denchmark-link:https://user-images.githubusercontent.com/20050820/81621070-7c316200-93bb-11ea-9ff8-2ffabbb95c42.png&gt;&lt;/denchmark-link&gt;

If I understand SpringArm correctly, it should cause the lidar sensor to avoid entering walls/obstructions and lag slightly behind the vehicle it's attached to rather than arbitrarily limiting the FOV like this. Is this behavior intentional?
	</description>
	<comments>
		<comment id='1' author='RyanHopkins7' date='2020-06-26T05:56:18Z'>
		&lt;denchmark-link:https://github.com/RyanHopkins7&gt;@RyanHopkins7&lt;/denchmark-link&gt;
 indeed, the springarm provides a very specific pose, which will limit the FOV. I guess, this is not the right tool for your needs. Just use the rigid one.
		</comment>
		<comment id='2' author='RyanHopkins7' date='2020-06-26T18:01:22Z'>
		&lt;denchmark-link:https://github.com/germanros1987&gt;@germanros1987&lt;/denchmark-link&gt;
 All I'm wondering is if this behavior is intentional. If it is, I'll close, but it did take me a little while to figure out the cause of this issue considering that the tutorial I mentioned used SpringArm without limiting the FOV. A note about this in the documentation might be helpful so people know what causes this.
		</comment>
		<comment id='3' author='RyanHopkins7' date='2020-06-26T23:37:29Z'>
		Hold on a second, I may have misunderstood the first screenshot. Is the first image supposed to be taken from a bird-eye-view? I thought the points on the left and right side of the pointcloud were from a wall. Could you further explain the setup, please?
		</comment>
		<comment id='4' author='RyanHopkins7' date='2020-06-27T15:35:43Z'>
		Yes, they were both taken from a bird's eye view using the same settings other than the attachment type. They were also taken in the same environment. The obstructions on the left and right in the first photo are not caused by walls.
		</comment>
		<comment id='5' author='RyanHopkins7' date='2020-06-27T17:52:54Z'>
		&lt;denchmark-link:https://github.com/RyanHopkins7&gt;@RyanHopkins7&lt;/denchmark-link&gt;
 please send over the sensor configuration/setup you have used for this so that we can reproduce it.
&lt;denchmark-link:https://github.com/DSantosO&gt;@DSantosO&lt;/denchmark-link&gt;
 once we get the sensor configuration, could you try to reproduce?
		</comment>
		<comment id='6' author='RyanHopkins7' date='2020-06-27T18:43:48Z'>
		This is the sensor configuration I was using:
&lt;denchmark-code&gt;lidar_cam = None
lidar_bp = world.get_blueprint_library().find('sensor.lidar.ray_cast')
lidar_bp.set_attribute('channels',str(32))
lidar_bp.set_attribute('points_per_second',str(300000))
lidar_bp.set_attribute('rotation_frequency',str(120))
lidar_bp.set_attribute('range',str(20))
lidar_bp.set_attribute('lower_fov',str(-40))

lidar_location = carla.Location(0,0,2)
lidar_rotation = carla.Rotation(0,0,0)
lidar_transform = carla.Transform(lidar_location,lidar_rotation)

lidar_sen = world.spawn_actor(lidar_bp,lidar_transform,attach_to=vehicle2,attachment_type=carla.AttachmentType.SpringArm)
lidar_sen.listen(lambda point_cloud: point_cloud.save_to_disk('sensor_output/lidar/f%.6d.ply' % point_cloud.frame))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='RyanHopkins7' date='2020-07-01T16:43:36Z'>
		&lt;denchmark-link:https://github.com/RyanHopkins7&gt;@RyanHopkins7&lt;/denchmark-link&gt;
 Thank you for the information. I am able to reproduce your result and yes, it seems to be something weird with the output when SpringArm is the attachment type. I will look into it and I will let you know when I find the reason.
		</comment>
		<comment id='8' author='RyanHopkins7' date='2020-07-06T16:57:42Z'>
		Hello,
Sorry for the late replay, we have looked into the specific of the case and there is couple of things to comment.
First, you need to take in account that the SpringArm is thought to have a better camera visualization so it should not be used in sensors like LiDAR. In this sense, please use always the Rigid mode.
Anyway, the SpringArm is doing something weird in your specific case because of the zero translation in the 'x' axis. This is a problem because this SprintArm is thought to see the car in 'third person' not directly in top of the car. We will add some safeguard about this problem soon.
Thank you very much for reporting the issue, I hope this information is helpful.
		</comment>
		<comment id='9' author='RyanHopkins7' date='2020-07-06T18:42:22Z'>
		&lt;denchmark-link:https://github.com/DSantosO&gt;@DSantosO&lt;/denchmark-link&gt;
 Thanks for getting back to me and I'm glad to help. If it's recommended not to use SpringArm for LiDAR, perhaps &lt;denchmark-link:https://carla.readthedocs.io/en/latest/tuto_G_retrieve_data/#lidar-raycast-sensor&gt;the documentation should be changed to demonstrate using the Rigid mode&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='10' author='RyanHopkins7' date='2020-07-07T07:57:20Z'>
		Hello &lt;denchmark-link:https://github.com/RyanHopkins7&gt;@RyanHopkins7&lt;/denchmark-link&gt;

Yes, that is mistake. Sorry about it. We will change it.
Thanks again!
		</comment>
	</comments>
</bug>