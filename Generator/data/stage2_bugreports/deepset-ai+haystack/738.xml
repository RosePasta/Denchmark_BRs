<bug id='738' author='Rob192' open_date='2021-01-15T09:49:33Z' closed_time='2021-01-22T14:03:19Z'>
	<summary>Pipeline retriever cannot find documents in custom index</summary>
	<description>
Hello !
I run into an issue for which I am not sure what to do. maybe you guys can help !
Many thanks,
Describe the bug
When using a pipeline to retrieve docs that are stored in a different index than the index used for the instanciation of the document_store : pipeline.run throws a elasticsearch.exceptions.NotFoundError exception.
Currently my workaround is to search with the same index as the one with with the document_store was created (e.g. 'document')
Error message
Traceback (most recent call last):
File "C:\Users\Utilisateur\PythonProjects\piaf-ml\src\evaluation\retriever\retriever_eval_squad.py", line 102, in 
run_results = single_run(param)
File "C:\Users\Utilisateur\PythonProjects\piaf-ml\src\evaluation\retriever\retriever_eval_squad.py", line 80, in single_run
retriever_eval_results = eval_retriever(document_store=document_store, pipeline=p, top_k=k, label_index=label_index, doc_index=doc_index)
File "C:\Users\Utilisateur\PythonProjects\piaf-ml\src\evaluation\utils\utils_eval.py", line 64, in eval_retriever
retrieved_docs_list =[pipeline.run(query=question["query"], top_k_retriever=top_k) for question in question_label_dict_list]
File "C:\Users\Utilisateur\PythonProjects\piaf-ml\src\evaluation\utils\utils_eval.py", line 64, in 
retrieved_docs_list =[pipeline.run(query=question["query"], top_k_retriever=top_k) for question in question_label_dict_list]
File "c:\users\utilisateur\pythonprojects\haystack\haystack\pipeline.py", line 89, in run
output_dict, stream_id = self.graph.nodes[current_node_id]["component"].run(**input_dict)
File "c:\users\utilisateur\pythonprojects\haystack\haystack\retriever\base.py", line 179, in run
documents = self.retrieve(query=query, filters=filters, top_k=top_k_retriever)
File "c:\users\utilisateur\pythonprojects\haystack\haystack\retriever\dense.py", line 462, in retrieve
documents = self.document_store.query_by_embedding(query_emb=query_emb[0], filters=filters,
File "c:\users\utilisateur\pythonprojects\haystack\haystack\document_store\elasticsearch.py", line 560, in query_by_embedding
result = self.client.search(index=index, body=body, request_timeout=300)["hits"]["hits"]
File "C:\Users\Utilisateur\anaconda3\envs\piaf-ml\lib\site-packages\elasticsearch\client\utils.py", line 152, in wrapped
return func(*args, params=params, headers=headers, **kwargs)
File "C:\Users\Utilisateur\anaconda3\envs\piaf-ml\lib\site-packages\elasticsearch\client_init.py", line 1658, in search
return self.transport.perform_request(
File "C:\Users\Utilisateur\anaconda3\envs\piaf-ml\lib\site-packages\elasticsearch\transport.py", line 392, in perform_request
raise e
File "C:\Users\Utilisateur\anaconda3\envs\piaf-ml\lib\site-packages\elasticsearch\transport.py", line 358, in perform_request
status, headers_response, data = connection.perform_request(
File "C:\Users\Utilisateur\anaconda3\envs\piaf-ml\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 269, in perform_request
self._raise_error(response.status, raw_data)
File "C:\Users\Utilisateur\anaconda3\envs\piaf-ml\lib\site-packages\elasticsearch\connection\base.py", line 312, in _raise_error
raise HTTP_EXCEPTIONS.get(status_code, TransportError)(
elasticsearch.exceptions.NotFoundError: NotFoundError(404, 'index_not_found_exception', 'no such index [document]', document, index_or_alias)
Process finished with exit code 1
Expected behavior
The pipeline should be able to take into account a 'index' parameter pointing to a custom index.
To Reproduce
&lt;denchmark-code&gt;from haystack.document_store.elasticsearch import ElasticsearchDocumentStore
from haystack.preprocessor.utils import fetch_archive_from_http
from haystack.retriever.sparse import ElasticsearchRetriever
from haystack.retriever.dense import DensePassageRetriever
from haystack.reader.farm import FARMReader
from haystack.finder import Finder
from farm.utils import initialize_device_settings
from pathlib import Path

import logging
import subprocess
import time

logger = logging.getLogger(__name__)

##############################################
# Settings
##############################################
LAUNCH_ELASTICSEARCH = False

# make sure these indices do not collide with existing ones, the indices will be wiped clean before data is inserted
doc_index = "tutorial5_docs"
label_index = "tutorial5_labels"
##############################################
# Code
##############################################
device, n_gpu = initialize_device_settings(use_cuda=True)
# Start an Elasticsearch server
# You can start Elasticsearch on your local machine instance using Docker. If Docker is not readily available in
# your environment (eg., in Colab notebooks), then you can manually download and execute Elasticsearch from source.
if LAUNCH_ELASTICSEARCH:
    logging.info("Starting Elasticsearch ...")
    status = subprocess.run(
        ['docker run -d -p 9200:9200 -e "discovery.type=single-node" elasticsearch:7.9.2'], shell=True
    )
    if status.returncode:
        raise Exception("Failed to launch Elasticsearch. If you want to connect to an existing Elasticsearch instance"
                        "then set LAUNCH_ELASTICSEARCH in the script to False.")
    time.sleep(30)

# Connect to Elasticsearch
document_store = ElasticsearchDocumentStore(host="localhost", username="", password="", index="document",
                                            create_index=False, embedding_field="emb",
                                            embedding_dim=768, excluded_meta_data=["emb"])


# Add evaluation data to Elasticsearch document store
# We first delete the custom tutorial indices to not have duplicate elements
document_store.delete_all_documents(index=doc_index)
document_store.delete_all_documents(index=label_index)
document_store.add_eval_data(filename=Path("../data/nq/nq_dev_subset_v2.json"), doc_index=doc_index, label_index=label_index)

# Initialize Retriever
retriever = ElasticsearchRetriever(document_store=document_store)

p = Pipeline()

p.add_node(component=retriever, name="ESRetriever", inputs=["Query"])

filters = {"origin": ['gold_label']}

labels = document_store.get_all_labels_aggregated(index=label_index, filters=filters)

# Collect questions and corresponding answers/document_ids in a dict
question_label_dict_list = []
for label in labels:
    deduplicated_doc_ids = list(set([str(x) for x in label.multiple_document_ids]))
    question_label_dict = {}
    question_label_dict['query'] = label.question
    question_label_dict['gold_ids'] = deduplicated_doc_ids
    question_label_dict_list.append(question_label_dict)

predictions = []

retrieved_docs_list = [p.run(query=question["query"], top_k_retriever=3, index=doc_index) for question in
                       question_label_dict_list]
&lt;/denchmark-code&gt;

System:

OS: Windows
Haystack version (commit or version number): commit 74b0868

	</description>
	<comments>
		<comment id='1' author='Rob192' date='2021-01-15T15:10:09Z'>
		Hi &lt;denchmark-link:https://github.com/Rob192&gt;@Rob192&lt;/denchmark-link&gt;
, thank you for raising the issue. I can reproduce this bug and will update here when it is resovled.
		</comment>
		<comment id='2' author='Rob192' date='2021-01-19T10:55:55Z'>
		Hey &lt;denchmark-link:https://github.com/Rob192&gt;@Rob192&lt;/denchmark-link&gt;
, could you please explain a bit your use case for running the pipeline against a different index than the one used for initializing the ? I am currently not sure if passing an  param to the pipeline is the most elegant solution here and understanding your use case would help us to brainstorm a few different design choices ...
		</comment>
		<comment id='3' author='Rob192' date='2021-01-19T11:36:54Z'>
		Hello &lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
,
This behavior basically occured when I tried to launch something similar to the Evaluation Tutorial (number 5) which is also using different indexes for testing the . That's why I though it was good practice to evaluate the performances of our Pipelines on a different index.
Honeslty in practice I am not sure what would be the use case. My initial though was that it could be used for a kind of release procedure to check if your stack is correctly running once launched. You would launch your docker with the production knowledge base in your standard index and one could imagine also using a test knowledge base with a special index. You would then use the API to assess that everything is running as expected. However as far as I understand, currently the API is not configured to pass a specific index for searching ...
In the end the issue might be related to a misunderstanding on my side regarding the necessity for using different indexes in the Tutorial 5 ...
Hope it makes sense.
		</comment>
		<comment id='4' author='Rob192' date='2021-01-22T13:54:43Z'>
		Ok got your use case. In most of our deployments, we do indeed have different stages (production, staging ...). We sometimes also configure different indices for them. However, we would normally do this by 1) configuring an environment variable for the chosen index name, 2) passing the environment variable to the init of the DocumentStore. This will require a restart of the API or at least reloading of the pipeline when you "change" indices, but if you are in different environments this is usually not a problem.
Maybe you can give this workflow a try and if you feel this is not really addressing your need, I am happy to re-open this issue and design a solution together :). Is that okay for you?
		</comment>
		<comment id='5' author='Rob192' date='2021-01-22T14:03:19Z'>
		Yes perfectly fine. I will try that.
		</comment>
	</comments>
</bug>