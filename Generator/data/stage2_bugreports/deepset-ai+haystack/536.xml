<bug id='536' author='antoniolanza1996' open_date='2020-11-02T17:18:22Z' closed_time='2020-11-05T12:34:48Z'>
	<summary>Fix retriever evaluation metrics</summary>
	<description>
In retriever evaluation you compute "mean avg precision" but this is correct only when open_domain=False. When open_domain=True, this measure isn't MAP but it is MRR because you're considering only the first correct hit.
Useful reference:

https://stats.stackexchange.com/questions/127041/mean-average-precision-vs-mean-reciprocal-rank (see answer, it's very well explained)
https://nlp.stanford.edu/IR-book/pdf/08eval.pdf (page 9-10)
https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision
https://en.wikipedia.org/wiki/Mean_reciprocal_rank

I see two possible scenarios:

just change its name in MRR;
implement also real MAP for open-domainÂ context.

However, in both these scenarios, the return values will differ based on whether you use open_domain=True or open_domain=False.
	</description>
	<comments>
		<comment id='1' author='antoniolanza1996' date='2020-11-04T21:39:56Z'>
		Hi &lt;denchmark-link:https://github.com/bogdankostic&gt;@bogdankostic&lt;/denchmark-link&gt;
 ,
when I have opened this issue I thought that:

open_domain=True ---&gt; you can have multiple documents which can answer your question;
open_domain=False ---&gt; only one document ID can answer your question (like SQuAD (i.e. reading comprehension task)).

For this reason, I've suggested that MAP is ok for open_domain=False because when you have only one possible relevant document, MAP == MRR.
However, as I can see from your first code in &lt;denchmark-link:https://github.com/deepset-ai/haystack/pull/547/files#diff-e89fbf9a7a9f7bb1d08741f97417d212c11c9a52cb1f1fc5378097da7d6f07cfR61-R62&gt;https://github.com/deepset-ai/haystack/pull/547/files#diff-e89fbf9a7a9f7bb1d08741f97417d212c11c9a52cb1f1fc5378097da7d6f07cfR61-R62&lt;/denchmark-link&gt;
 , you want to compute MAP and MRR for  and only MAP for . Why?
, I think with your implementation you'll have:

open_domain=True ---&gt; only MAP available... but MRR could also be useful here;
open_domain=False ---&gt; both MAP and MRR, but MAP == MRR.

Instead, IF what I've written at the beginning of this comment for open_domain parameter is NOT correct, can you please explain me the real behaviour of open_domain parameter?
		</comment>
		<comment id='2' author='antoniolanza1996' date='2020-11-05T08:09:37Z'>
		Hey &lt;denchmark-link:https://github.com/antoniolanza1996&gt;@antoniolanza1996&lt;/denchmark-link&gt;
,

open_domain=True ---&gt; you can have multiple documents which can answer your question;
open_domain=False ---&gt; only one document ID can answer your question (like SQuAD (i.e. reading comprehension task)).

Not exactly. We rather refer to "open domain" here as it is used in some recent open domain QA datasets where you just specify a answer string instead of the exact position (e.g. to allow generative QA):
 -&gt; Gold documents are  (e.g. in SQuAD),  but there could still be multiple gold docs
 -&gt; All docs that  are considered as gold documents (similar to &lt;denchmark-link:https://github.com/efficientqa/nq-open&gt;Open NQ&lt;/denchmark-link&gt;
 or the NQ variant used in the DPR paper).
So from my perspective MRR != MAP for open_domain=False, and we wanted to have one metric that you could compare between both variants.

...  only MAP for open_domain=True

MRR would require us to scan the whole document base for every query to identify the "gold docs". This can get very slow for datasets with millions of docs. We might still add it in the future but it didn't seem worth the effort at this point in time.
Does this make sense to you?
		</comment>
		<comment id='3' author='antoniolanza1996' date='2020-11-05T08:20:59Z'>
		
So from my perspective MRR != MAP for open_domain=False, and we wanted to have one metric that you could compare between both variants.

Yes, with your open_domain definition, I agree with you on that. It's worth add both MRR and MAP for open_domain=False.

MRR would require us to scan the whole document base for every query to identify the "gold docs".

Why? MRR considers only the first relevant doc in the top_k_retriever documents. You should check only in the first top_k_retriever documents and verify if there is one gold document there.
		</comment>
		<comment id='4' author='antoniolanza1996' date='2020-11-05T08:31:43Z'>
		Oh yes, sorry. The other way around of course: We only implemented MRR for open_domain=True - not MAP.
		</comment>
		<comment id='5' author='antoniolanza1996' date='2020-11-05T08:39:00Z'>
		
We only implemented MRR for open_domain=True - not MAP.

Yes, I see this from &lt;denchmark-link:https://github.com/bogdankostic&gt;@bogdankostic&lt;/denchmark-link&gt;
 PR. But at this point I think you can compute both measures also for . Because MAP consider only the retrieved  relevant documents. Thus, you should check only in the  documents and compute average precision.
The problem you describe (i.e. check in all document base) I think it will come up if you wanna compute recall in standard IR system because for the recall you have to know ALL relevant documents in document base.
		</comment>
		<comment id='6' author='antoniolanza1996' date='2020-11-05T08:49:57Z'>
		You are right. The retrieved docs should actually be enough for precision. I don't know what bug was in my head when I wrote the earlier comment :D
		</comment>
		<comment id='7' author='antoniolanza1996' date='2020-11-05T08:52:33Z'>
		Would you be interested in adding a separate PR for MAP in the case of ? If not &lt;denchmark-link:https://github.com/bogdankostic&gt;@bogdankostic&lt;/denchmark-link&gt;
 will work on it next week
		</comment>
		<comment id='8' author='antoniolanza1996' date='2020-11-05T08:56:14Z'>
		No problem :) . If you come up with your bug please let me know here. But at this point of time I think we can both compute MRR and MAP for both open_domain values.

Would you be interested in adding a separate PR for MAP in the case of open_domain=True?

Unfortunately I have some deadlines for the next two/three weeks and I have a lot of work to do. Hence I cannot work on this PR. Sorry for that.
		</comment>
		<comment id='9' author='antoniolanza1996' date='2020-11-05T09:30:34Z'>
		
Unfortunately I have some deadlines for the next two/three weeks and I have a lot of work to do. Hence I cannot work on this PR. Sorry for that.

Ok, no worries! We will probably tackle it then in a separate PR next week after the upcoming Haystack release of v0.5.0
		</comment>
	</comments>
</bug>