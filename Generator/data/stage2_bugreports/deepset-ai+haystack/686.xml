<bug id='686' author='juan541' open_date='2020-12-15T22:54:17Z' closed_time='2020-12-24T13:26:10Z'>
	<summary>Dense Passage Retriever Fails to run .eval(), elastic search document store with custom mapping</summary>
	<description>
The Bug
Currently, I switched from a vanilla ElasticSearch Retriever to a Dense Passage Retriever. The originally custom mapped ElasticSearch DocumentStore was kept.
The Dense Passage Retriever is working in terms of the QA pipeline, and retrieve operations. The problem arises when I try to evaluate the retriever independently, specifically in the document store call for query_by_embedding() in eval() .
The following is the line that caused the error:



haystack/haystack/document_store/elasticsearch.py


         Line 560
      in
      143da4c






 result = self.client.search(index=index, body=body, request_timeout=300)["hits"]["hits"] 





Error message
In this function, a search operation is executed by the ElasticSearch object. This search operation results in the following error:
RequestError: RequestError(400, 'search_phase_execution_exception', 'runtime error')
Expected behavior
Expected the retriever to complete the evaluation successfully.
Additional context
Direct search query to elastic search was done afterward in order to verify that the problem does not originate from the elasticsearch database and such resulted in a successful search.
Elastic Search has a custom mapping, such is as follows
pdf_custom_mapping = { "mappings": { "properties": { "chapter": { "type": "text" }, "context": { "fields": { "reverse": { "analyzer": "reverse", "type": "text" }, "trigram": { "analyzer": "trigram", "type": "text" } }, "type": "text" }, "page": { "type": "integer" }, "pdf_code": { "type": "keyword" }, "pdf_title": { "type": "text" }, "pdf_url": { "type": "text" }, "section": { "type": "text" }, "title": { "type": "text" }, "embedding": {"type": "dense_vector", "dims": 768} } }, "settings": { "index": { "analysis": { "analyzer": { "reverse": { "filter": [ "lowercase", "reverse" ], "tokenizer": "standard", "type": "custom" }, "trigram": { "filter": [ "lowercase", "shingle" ], "tokenizer": "standard", "type": "custom" } }, "filter": { "shingle": { "max_shingle_size": 3, "min_shingle_size": 2, "type": "shingle" } } }, "number_of_shards": 1 } } }
System:

Haystack version (commit or version number): v0.5.0
DocumentStore: ElasticSearch
Retriever: Dense Passage Retriever
GPU: Nvidia Tesla T4
Notebook instance on Google Cloud

	</description>
	<comments>
		<comment id='1' author='juan541' date='2020-12-16T14:46:02Z'>
		&lt;denchmark-link:https://github.com/juan541&gt;@juan541&lt;/denchmark-link&gt;
 Which version of Elasticsearch are you running?
		</comment>
		<comment id='2' author='juan541' date='2020-12-16T14:48:22Z'>
		&lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
 Hi, I'm using elasticsearch 7.8.1
		</comment>
		<comment id='3' author='juan541' date='2020-12-16T14:51:34Z'>
		We faced a similar problem recently with Elasticsearch 7.6.2.
Updating to 7.9.2 fixed it. Could you try if the same thing helps in your case?
		</comment>
		<comment id='4' author='juan541' date='2020-12-16T14:53:22Z'>
		I will try and follow up as soon as I test it out. Thanks for the suggestion!
		</comment>
		<comment id='5' author='juan541' date='2020-12-17T15:26:17Z'>
		I updated elastic search from 7.8.1 to 7.10.1 and the error still persists. Any other suggestions?
		</comment>
		<comment id='6' author='juan541' date='2020-12-17T15:46:41Z'>
		Ok sure, happy to dig deeper then.
I would suggest comparing the elastic queries that are executed during eval (which fail) vs. the ones during regular retrieval (you mentioned those work, right?). In order to do that you can set the logger in Haystack to debug level. You should then see logs originating from this line here containing the payload for the elasticsearch request:



haystack/haystack/document_store/elasticsearch.py


         Line 559
      in
      0e4eec9






 logger.debug(f"Retriever query: {body}") 





You can set the log level by calling logging.getLogger('haystack.document_store.elasticsearch').setLevel(logging.DEBUG)
		</comment>
		<comment id='7' author='juan541' date='2020-12-17T21:30:29Z'>
		I did some tests with the logger in debug level and both bodies are correctly structured and there is no difference between them. The error, I would assume, is not originating from the body of the query itself apparently.
The error still persists.
		</comment>
		<comment id='8' author='juan541' date='2020-12-18T06:10:03Z'>
		Can you maybe share a minimal script to reproduce this? Then I could help you debug more effectively.
If not, these are two further directions that I would explore:

Increase timeout for elasticsearch
Check if the docs during eval have been indexed correctly with the fields from your custom mapping

		</comment>
		<comment id='9' author='juan541' date='2020-12-23T15:04:31Z'>
		This is a minimal script that reproduces the error:
&lt;denchmark-code&gt;from haystack import Finder
from haystack.reader.farm import FARMReader
from haystack.document_store.elasticsearch import ElasticsearchDocumentStore
from haystack.retriever.dense import DensePassageRetriever
import json
docs = {"title":"ASCE_7_16-CHAPTER_4","sections":[{"context":"CHAPTER 4 LIVE LOADS","page":68,"section":"CHAPTER_4","chapter":"CHAPTER_4","title":"ASCE_7_16-CHAPTER_4","pdf_url":"someurl","pdf_code":"ASCE/SEI 7-16","pdf_title":"Minimum Design Loads and Associated Criteria for Buildings and Other Structures"},{"context":"4.1 DEFINITIONS The following definitions apply to the provisions of this chapter. FIXED LADDER: A ladder that is permanently attached to a structure, building, or equipment. GRAB BAR SYSTEM: A bar and associated anchorages and attachments to the structural system, for the support of body weight in locations such as toilets, showers, and tub enclosures. GUARDRAIL SYSTEM: A system of components, including anchorages and attachments to the structural system, near open sides of an elevated surface for the purpose of minimizing the possibility of a fall from the elevated surface by people, equipment, or material. HANDRAIL SYSTEM: A rail grasped by hand for guidance and support and associated anchorages and attachments to the structural system HELIPAD: A structural surface that is used for landing, taking off, taxiing, and parking of helicopters. LIVE LOAD: A load produced by the use and occupancy of the building or other structure that does not include construction or environmental loads, such as wind load, snow load, rain load, earthquake load, flood load, or dead load. ROOF LIVE LOAD: A load on a roof produced (1) during maintenance by workers, equipment, and materials, and (2) during the life of the structure by movable objects, such as planters or other similar small decorative appurtenances that are not occupancy related. An occupancy-related live load on a roof such as rooftop assembly areas, rooftop decks, and vegetative or landscaped roofs with occupiable areas, is considered to be a live load rather than a roof live load. SCREEN ENCLOSURE: A building or part thereof, in whole or in part self-supporting, having walls and a roof of insect or sun screening using fiberglass, aluminum, plastic, or similar lightweight netting material, which encloses an occupancy or use such as outdoor swimming pools, patios or decks, and horticultural and agricultural production facilities. VEHICLE BARRIER SYSTEM: A system of components, including anchorages and attachments to the structural system near open sides or walls of garage floors or ramps, that acts as a restraint for vehicles.","page":68,"section":"4.1_DEFINITIONS","chapter":"CHAPTER_4","title":"ASCE_7_16-CHAPTER_4","pdf_url":"someurl","pdf_code":"ASCE/SEI 7-16","pdf_title":"Minimum Design Loads and Associated Criteria for Buildings and Other Structures"}]}
eval_docs = {"data":[{"paragraphs":[{"context":"CHAPTER 4  LIVE LOADS","qas":[{"answers":[{"answer_start":0,"text":"CHAPTER 4 LIVE LOADS"}],"id":"990efb3e-b698-41d1-be3c-d4cd43f8446b","question":"Where do I find requirements for live loads?","is_impossible":False}]}]}]}
pdf_custom_mapping = { "mappings": { "properties": { "chapter": { "type": "text" }, "context": { "fields": { "reverse": { "analyzer": "reverse", "type": "text" }, "trigram": { "analyzer": "trigram", "type": "text" } }, "type": "text" }, "page": { "type": "integer" }, "pdf_code": { "type": "keyword" }, "pdf_title": { "type": "text" }, "pdf_url": { "type": "text" }, "section": { "type": "text" }, "title": { "type": "text" }, "embedding": {"type": "dense_vector", "dims": 768} } }, "settings": { "index": { "analysis": { "analyzer": { "reverse": { "filter": [ "lowercase", "reverse" ], "tokenizer": "standard", "type": "custom" }, "trigram": { "filter": [ "lowercase", "shingle" ], "tokenizer": "standard", "type": "custom" } }, "filter": { "shingle": { "max_shingle_size": 3, "min_shingle_size": 2, "type": "shingle" } } }, "number_of_shards": 1 } } }
host = "ec2-3-235-252-200.compute-1.amazonaws.com"
evaluation_index_name='eval_test'
eval_filename = 'eval-file.json'
label_index_name='label_test'
host = "localhost"
document_store = ElasticsearchDocumentStore(host=host, port=9200,index="document-small-test",
                                         username="some_user",
                                         search_fields = ["title", "context"],embedding_field="embedding",
                                         name_field="title", text_field="context", excluded_meta_data=["embedding"],
                                         embedding_dim=768, custom_mapping=pdf_custom_mapping, timeout=10000)
#add evaluation documents
document_store.write_documents(docs['sections'])
#create evaluation_file
with open(eval_filename, "w") as eval_file:
    eval_file.write(json.dumps(eval_docs))
document_store.add_eval_data(filename=eval_filename, doc_index=evaluation_index_name, label_index=label_index_name)
retriever = DensePassageRetriever(document_store=document_store,
                                  query_embedding_model="facebook/dpr-question_encoder-single-nq-base",
                                  passage_embedding_model="facebook/dpr-ctx_encoder-single-nq-base",
                                  max_seq_len_query=64,
                                  max_seq_len_passage=256,
                                  batch_size=16,
                                  use_gpu=True,
                                  embed_title=True,
                                  use_fast_tokenizers=True)
document_store.update_embeddings(retriever)
reader = FARMReader(model_name_or_path="deepset/roberta-base-squad2")
finder = Finder(reader, retriever)
# Evaluate Retriever on its own
retriever_eval_results = retriever.eval(top_k=10, label_index=label_index_name, doc_index=evaluation_index_name)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='juan541' date='2020-12-24T12:11:41Z'>
		Hi &lt;denchmark-link:https://github.com/juan541&gt;@juan541&lt;/denchmark-link&gt;
 ,
Thanks for the script. This is super helpful! I could reproduce your bug and trace down to two main reasons:


document_store.add_eval_data(filename=eval_filename, doc_index=evaluation_index_name, label_index=label_index_name)
=&gt; You are writing your eval documents to an index called "eval_test". A few lines later you call update_embeddings() to create the embeddings. However, this call is per default just updating the embeddings on your "main document index" (i.e. "document-small-test"). In order to update the embeddings in your eval index, just call document_store.update_embeddings(retriever, index=evaluation_index_name).


We now update the right index. However, the method will still fail because we've set embed_title=True when initializing the DPRRetriever and our eval docs don't contain any "title". Two options to fix this: 1) set embed_title=False or 2) add a "title" field in your SQuAD-style JSON. It should then look like this "data": [{"title": "my title",  "paragraphs": [...


Here's a code snippet to illustrate how it works. Hope this helps!
from haystack.document_store.elasticsearch import ElasticsearchDocumentStore
from haystack.retriever.dense import DensePassageRetriever
import json

eval_docs = {
  "data": [
    {
      "paragraphs": [
        {
          "context": "CHAPTER 4  LIVE LOADS",
          "qas": [
            {
              "answers": [
                {
                  "answer_start": 0,
                  "text": "CHAPTER 4 LIVE LOADS"
                }
              ],
              "id": "990efb3e-b698-41d1-be3c-d4cd43f8446b",
              "question": "Where do I find requirements for live loads?",
              "is_impossible": False
            }
          ]
        }
      ]
    }
  ]
}
pdf_custom_mapping = {
  "mappings": {
    "properties": {
      "chapter": {
        "type": "text"
      },
      "context": {
        "fields": {
          "reverse": {
            "analyzer": "reverse",
            "type": "text"
          },
          "trigram": {
            "analyzer": "trigram",
            "type": "text"
          }
        },
        "type": "text"
      },
      "page": {
        "type": "integer"
      },
      "pdf_code": {
        "type": "keyword"
      },
      "pdf_title": {
        "type": "text"
      },
      "pdf_url": {
        "type": "text"
      },
      "section": {
        "type": "text"
      },
      "title": {
        "type": "text"
      },
      "embedding": {
        "type": "dense_vector",
        "dims": 768
      }
    }
  },
  "settings": {
    "index": {
      "analysis": {
        "analyzer": {
          "reverse": {
            "filter": [
              "lowercase",
              "reverse"
            ],
            "tokenizer": "standard",
            "type": "custom"
          },
          "trigram": {
            "filter": [
              "lowercase",
              "shingle"
            ],
            "tokenizer": "standard",
            "type": "custom"
          }
        },
        "filter": {
          "shingle": {
            "max_shingle_size": 3,
            "min_shingle_size": 2,
            "type": "shingle"
          }
        }
      },
      "number_of_shards": 1
    }
  }
}

evaluation_index_name='eval_test'
eval_filename = 'eval-file.json'
label_index_name='label_test'
host = "localhost"
document_store = ElasticsearchDocumentStore(host=host, port=9200,index="document-small-test",
                                         username="some_user",
                                         search_fields = ["title", "context"],embedding_field="embedding",
                                         name_field="title", text_field="context", excluded_meta_data=["embedding"],
                                         embedding_dim=768, custom_mapping=pdf_custom_mapping, timeout=10000)

# Create evaluation_file
with open(eval_filename, "w") as eval_file:
    eval_file.write(json.dumps(eval_docs))

# Split your squad eval file into "docs" and "labels". Write docs to index "eval_test" and labels to "label_test"
document_store.add_eval_data(filename=eval_filename, doc_index=evaluation_index_name, label_index=label_index_name)
retriever = DensePassageRetriever(document_store=document_store,
                                  query_embedding_model="facebook/dpr-question_encoder-single-nq-base",
                                  passage_embedding_model="facebook/dpr-ctx_encoder-single-nq-base",
                                  max_seq_len_query=64,
                                  max_seq_len_passage=256,
                                  batch_size=16,
                                  use_gpu=True,
                                  embed_title=False, # Your SQuAD docs have no "title" information. Either disable this parameter here or add titles to your eval docs.
                                  use_fast_tokenizers=True)

# Update the embeddings for all docs in the index "eval_test"(!)
document_store.update_embeddings(retriever, index=evaluation_index_name)

# Evaluate Retriever on its own
retriever_eval_results = retriever.eval(top_k=10, label_index=label_index_name, doc_index=evaluation_index_name)
		</comment>
		<comment id='11' author='juan541' date='2020-12-24T13:26:10Z'>
		Hi &lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;

Thank you so much for the help, the issue has been resolved. The issue was the embeddings within the evaluation index, it wasn't being updated as required.
Again, Thanks for the help!
		</comment>
		<comment id='12' author='juan541' date='2020-12-25T08:15:57Z'>
		Glad to hear that it helped :)
		</comment>
	</comments>
</bug>