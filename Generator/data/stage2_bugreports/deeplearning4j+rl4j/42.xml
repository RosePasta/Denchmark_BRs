<bug id='42' author='ecthx' open_date='2017-06-30T22:46:54Z' closed_time='2017-07-24T12:37:45Z'>
	<summary>rl4j &amp; cuda</summary>
	<description>
Is it possible to enable cuda backend with rl4j? As far as I understand it it should be fairly straightforward for DQN but not so much for A3C.
	</description>
	<comments>
		<comment id='1' author='ecthx' date='2017-07-01T06:10:30Z'>
		It should work, yes. If you could try it out as it is now and report your
findings, it would help!
		</comment>
		<comment id='2' author='ecthx' date='2017-07-05T06:51:38Z'>
		I've just tried it with the CUDA backend, and it works fine, but very slowly because of getDouble() and putScalar() operations here:
&lt;denchmark-link:https://github.com/deeplearning4j/rl4j/blob/master/rl4j-core/src/main/java/org/deeplearning4j/rl4j/learning/sync/qlearning/discrete/QLearningDiscrete.java#L207&gt;https://github.com/deeplearning4j/rl4j/blob/master/rl4j-core/src/main/java/org/deeplearning4j/rl4j/learning/sync/qlearning/discrete/QLearningDiscrete.java#L207&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/rl4j/blob/master/rl4j-core/src/main/java/org/deeplearning4j/rl4j/learning/async/AsyncThreadDiscrete.java#L107&gt;https://github.com/deeplearning4j/rl4j/blob/master/rl4j-core/src/main/java/org/deeplearning4j/rl4j/learning/async/AsyncThreadDiscrete.java#L107&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/rl4j/blob/master/rl4j-core/src/main/java/org/deeplearning4j/rl4j/learning/async/a3c/discrete/A3CThreadDiscrete.java#L75&gt;https://github.com/deeplearning4j/rl4j/blob/master/rl4j-core/src/main/java/org/deeplearning4j/rl4j/learning/async/a3c/discrete/A3CThreadDiscrete.java#L75&lt;/denchmark-link&gt;

We'll need to do something about that...
		</comment>
		<comment id='3' author='ecthx' date='2017-07-05T07:04:20Z'>
		Actually, at the moment, most of the time seems to be spent in concat() operations...
		</comment>
		<comment id='4' author='ecthx' date='2017-07-05T13:15:12Z'>
		Ok, fixed, DQN works well now with this: &lt;denchmark-link:https://github.com/deeplearning4j/rl4j/commit/63adcf02980cf8baea395adf1bb333ec0ed57c21&gt;63adcf0&lt;/denchmark-link&gt;

I'm not sure if we can get async to work well at all, but it might work well just by setting the device affinity as with ParallelWrapper: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-scaleout/deeplearning4j-scaleout-parallelwrapper/src/main/java/org/deeplearning4j/parallelism/ParallelWrapper.java#L133&gt;https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-scaleout/deeplearning4j-scaleout-parallelwrapper/src/main/java/org/deeplearning4j/parallelism/ParallelWrapper.java#L133&lt;/denchmark-link&gt;

You would mind giving this a try?
		</comment>
		<comment id='5' author='ecthx' date='2017-07-05T19:37:11Z'>
		Side note: concat perf was improved, merge incoming: &lt;denchmark-link:https://github.com/deeplearning4j/nd4j/issues/1845&gt;deeplearning4j/nd4j#1845&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='ecthx' date='2017-07-06T02:59:12Z'>
		So I did couple of basic tests and it seems to work with both DQN and A3C.  I see less cpu load and more GPU utilization.
For reference I will post a link to a interesting paper about hybrid CPU&amp;GPU A3C. It takes a different approach and I'm not sure if its relevant to rl4j or dl4j.
&lt;denchmark-link:url&gt;https://arxiv.org/abs/1611.06256&lt;/denchmark-link&gt;

&lt;denchmark-link:url&gt;https://github.com/NVlabs/GA3C&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='ecthx' date='2017-07-06T07:08:50Z'>
		Hybrid, we'd first need to implement that in ND4J :)
		</comment>
		<comment id='8' author='ecthx' date='2017-07-06T07:12:47Z'>
		Although the architecture is different. It's training only one model, so it might be possible without any changes to ND4J.
		</comment>
		<comment id='9' author='ecthx' date='2017-07-24T07:34:19Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 you got this working didn't you?
		</comment>
		<comment id='10' author='ecthx' date='2017-07-24T11:41:15Z'>
		Yes, it basically works. I've also added the affinity bit in commit &lt;denchmark-link:https://github.com/deeplearning4j/rl4j/commit/bc1e6fb1bfac5e4d265412e751f4adacee5ab9ac&gt;bc1e6fb&lt;/denchmark-link&gt;
 so it'll work well as long as we have enough GPU devices.
		</comment>
	</comments>
</bug>