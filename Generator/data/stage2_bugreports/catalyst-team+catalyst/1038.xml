<bug id='1038' author='smivv' open_date='2020-12-18T14:49:53Z' closed_time='2020-12-18T17:36:37Z'>
	<summary>Bug in IoU function</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug Report&lt;/denchmark-h&gt;

Hello!
I think current implementation of IoU function is not correct and that's why:
If targets and outputs are empty (all zeros), IoU = 1. That's correct.
But if we set one pixel of outputs equal to 1, we will receive IoU = 0 which is wrong.
&lt;denchmark-h:h3&gt;How To Reproduce&lt;/denchmark-h&gt;

To reproduce just run this code in console.
&lt;denchmark-code&gt;import torch
from catalyst.metrics.iou import iou

outputs = torch.zeros(size=(32, 3, 224, 224))
targets = torch.zeros(size=(32, 3, 224, 224))

print(f"Result for empty targets and empty outputs: {iou(outputs, targets, activation='none')}")

outputs[0, 0, 0, 0] = torch.tensor(1)

print(f"Result for empty targets and almost empty outputs: {iou(outputs, targets, activation='none')}")

# output
# Result for empty targets and empty outputs: 1.0
# Result for empty targets and almost empty outputs: 0.0
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

I believe it should be ~ 1 in the second case too. So in my understanding we should compare zeros too.
Because currently if we try to apply this IoU function to binary classification which has zeros targets (empty mask) and output will be good, but with several points (some sort of noise), the result will be closer to 0 than to 1.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Catalyst version: 20.11
PyTorch version: 1.7.1
Is debug build: No
CUDA used to build PyTorch: None
TensorFlow version: N/A
TensorBoard version: 2.4.0

OS: Mac OSX 10.15.7
GCC version: Could not collect
CMake version: Could not collect

Python version: 3.8
Is CUDA available: No
CUDA runtime version: No CUDA
GPU models and configuration: No CUDA
Nvidia driver version: No CUDA
cuDNN version: No CUDA

Versions of relevant libraries:
[pip3] catalyst==20.11
[pip3] numpy==1.19.4
[pip3] tensorboard==2.4.0
[pip3] tensorboard-plugin-wit==1.7.0
[pip3] tensorboardX==2.1
[pip3] torch==1.7.1
[conda] Could not collect
&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Checklist&lt;/denchmark-h&gt;


 bug description.
 steps to reproduce.
 expected behavior.
 environment.
 code sample / screenshots.
 I know, that I could join Catalyst slack (#__questions channel) for issue discussion.

	</description>
	<comments>
		<comment id='1' author='smivv' date='2020-12-18T17:36:37Z'>
		Or seems like I've understood it wrongly, because now I think that we compare each object, not overall mask, so closing ü§î
		</comment>
	</comments>
</bug>