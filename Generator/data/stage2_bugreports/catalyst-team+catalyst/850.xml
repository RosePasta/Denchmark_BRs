<bug id='850' author='otherman16' open_date='2020-06-22T11:33:54Z' closed_time='2020-09-07T06:14:23Z'>
	<summary>catalyst.core.runner.IRunner._run_batch(...): batch_size finding bug</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug Report&lt;/denchmark-h&gt;

In the method catalyst.core.runner.IRunner._run_batch:
`
&lt;denchmark-code&gt;    ...

    if isinstance(batch, dict):
        self.batch_size = next(iter(batch.values())).shape[0]
    else:
        self.batch_size = len(batch[0])

    ...
&lt;/denchmark-code&gt;

`
If batch is instance of dict then batch_size equals to the first dimension of the first value in batch which means that the first value in batch dictionary must be torch.Tensor or numpy.ndarray. But if it's not (typeof(next(iter(batch.values()))) == list for example) then Exception will be raised.
Possible solution:
Replace self.batch_size = next(iter(batch.values())).shape[0] with self.batch_size = len(next(iter(batch.values()))).
&lt;denchmark-h:h3&gt;How To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

collate_fn for dataloader:

def collate_fn(batch):
    ...
    return {
        'path': ['1.jpg', '2.jpg'],
        'img': torch.randn((2, 3, 244, 244), dtype=torch.float32)
    }

Run catalyst-dl run --config=&lt;config-file-name&gt;.yml

Traceback (most recent call last):
  File "/home/aleksey/anaconda3/envs/retinaface/bin/catalyst-dl", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/dl/__main__.py", line 39, in main
    COMMANDS[args.command].main(args, uargs)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/dl/scripts/run.py", line 124, in main
    distributed_cmd_run(main_worker, args.distributed, args, unknown_args)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/utils/scripts.py", line 130, in distributed_cmd_run
    worker_fn(*args, **kwargs)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/dl/scripts/run.py", line 119, in main_worker
    runner.run_experiment(experiment)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/core/runner.py", line 934, in run_experiment
    self._run_event("on_exception")
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/core/runner.py", line 746, in _run_event
    getattr(callback, event)(self)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/core/callbacks/exception.py", line 22, in on_exception
    raise exception
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/core/runner.py", line 922, in run_experiment
    self._run_stage(stage)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/core/runner.py", line 898, in _run_stage
    self._run_epoch(stage=stage, epoch=self.epoch)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/core/runner.py", line 877, in _run_epoch
    self._run_loader(loader)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/core/runner.py", line 818, in _run_loader
    self._run_batch(batch)
  File "/home/aleksey/anaconda3/envs/retinaface/lib/python3.7/site-packages/catalyst/core/runner.py", line 788, in _run_batch
    self.batch_size = next(iter(batch.values())).shape[0]
AttributeError: 'list' object has no attribute 'shape'
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&lt;denchmark-h:h4&gt;Screenshots&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Successful batch_size finding regardless batch inside structure (tensor values or list values and so on).
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Catalyst version: 20.06
PyTorch version: 1.5.1
Is debug build: No
CUDA used to build PyTorch: 10.2
TensorFlow version: 2.2.0
TensorBoard version: 2.2.2

OS: Ubuntu 18.04.4 LTS
GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CMake version: Could not collect

Python version: 3.7
Is CUDA available: No
CUDA runtime version: No CUDA
GPU models and configuration: No CUDA
Nvidia driver version: No CUDA
cuDNN version: No CUDA

Versions of relevant libraries:
[pip3] alchemy-catalyst==20.3
[pip3] catalyst==20.6
[pip3] efficientnet-pytorch==0.6.3
[pip3] numpy==1.18.5
[pip3] segmentation-models-pytorch==0.1.0
[pip3] tensorboard==2.2.2
[pip3] tensorboard-plugin-wit==1.6.0.post3
[pip3] tensorboardX==2.0
[pip3] tensorflow==2.2.0
[pip3] tensorflow-estimator==2.2.0
[pip3] torch==1.5.1
[pip3] torch2trt==0.0.3
[pip3] torchvision==0.6.1
[conda] _pytorch_select           0.1                       cpu_0  
[conda] alchemy-catalyst          20.3                     pypi_0    pypi
[conda] blas                      1.0                         mkl  
[conda] catalyst                  20.6                     pypi_0    pypi
[conda] cudatoolkit               10.2.89              hfd86e86_1  
[conda] efficientnet-pytorch      0.6.3                    pypi_0    pypi
[conda] mkl                       2020.0                      166  
[conda] mkl-service               2.3.0            py37he904b0f_0  
[conda] mkl_fft                   1.0.15           py37ha843d7b_0  
[conda] mkl_random                1.1.0            py37hd6b4f25_0  
[conda] numpy                     1.18.5                   pypi_0    pypi
[conda] segmentation-models-pytorch 0.1.0                    pypi_0    pypi
[conda] tensorboard               2.2.2                    pypi_0    pypi
[conda] tensorboard-plugin-wit    1.6.0.post3              pypi_0    pypi
[conda] tensorboardx              2.0                      pypi_0    pypi
[conda] tensorflow                2.2.0                    pypi_0    pypi
[conda] tensorflow-estimator      2.2.0                    pypi_0    pypi
[conda] torch                     1.5.1                    pypi_0    pypi
[conda] torch2trt                 0.0.3                    pypi_0    pypi
[conda] torchvision               0.6.1                    pypi_0    pypi
&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='otherman16' date='2020-06-22T11:34:44Z'>
		Hi! Thank you for your contribution! Great first issue!
		</comment>
		<comment id='2' author='otherman16' date='2020-06-22T18:30:41Z'>
		Hi, thanks for the issue, it's a second time we face it with bath_size precessing already.
I have several possible workarounds... nevertheless, do you have any proposals to overcome this issue?
		</comment>
		<comment id='3' author='otherman16' date='2020-06-23T06:28:47Z'>
		Well, the most common way I think is to replace  by .
Another way is to use 3d-party module to determine size of  - &lt;denchmark-link:https://cardinality.readthedocs.io/en/latest/&gt;cardinality&lt;/denchmark-link&gt;
 for example: .
		</comment>
		<comment id='4' author='otherman16' date='2020-06-25T05:32:39Z'>
		Dear &lt;denchmark-link:https://github.com/otherman16&gt;@otherman16&lt;/denchmark-link&gt;
 ,
Would you like to talk into another thread &lt;denchmark-link:https://github.com/catalyst-team/catalyst/issues/846&gt;#846&lt;/denchmark-link&gt;
 - there is a proposed solution.
PS. we could also chat in slack if it suits you.
&lt;denchmark-link:https://join.slack.com/t/catalyst-team-core/shared_invite/zt-d9miirnn-z86oKDzFMKlMG4fgFdZafw&gt;https://join.slack.com/t/catalyst-team-core/shared_invite/zt-d9miirnn-z86oKDzFMKlMG4fgFdZafw&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='otherman16' date='2020-08-24T06:11:12Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>