<bug id='710' author='litvinich' open_date='2020-03-18T16:15:39Z' closed_time='2020-03-24T08:22:24Z'>
	<summary>20.03.1 Alchemy Logger bug</summary>
	<description>
Describe the bug
In the end if validation there is next error:
&lt;denchmark-code&gt; File "/home/andrii/anaconda3/envs/face/bin/catalyst-dl", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/dl/__main__.py", line 41, in main
    COMMANDS[args.command].main(args, uargs)
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/dl/scripts/run.py", line 117, in main
    distributed_run(args.distributed, main_worker, args, unknown_args)
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/utils/distributed.py", line 154, in distributed_run
    worker_fn(*args, **kwargs)
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/dl/scripts/run.py", line 112, in main_worker
    runner.run_experiment(experiment)
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/core/runner.py", line 376, in run_experiment
    self._run_event("on_exception")
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/core/runner.py", line 242, in _run_event
    getattr(callback, event)(self.state)
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/core/callbacks/exception.py", line 17, in on_exception
    raise exception
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/core/runner.py", line 363, in run_experiment
    self._run_stage(stage)
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/core/runner.py", line 345, in _run_stage
    self._run_event("on_epoch_end")
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/core/runner.py", line 242, in _run_event
    getattr(callback, event)(self.state)
  File "/home/andrii/anaconda3/envs/face/lib/python3.7/site-packages/catalyst/contrib/dl/callbacks/alchemy.py", line 127, in on_epoch_end
    metrics=splitted_epoch_metrics[extra_mode],
KeyError: '_base'
&lt;/denchmark-code&gt;

To Reproduce
I cannot share my data, but I am 100% sure it is not matter in data, because even in 20.03 my pipeline works. I attach my config under this message.
Config:
&lt;denchmark-code&gt;model_params:
  model: MixFace
  encoder_name: efficientnet_b0
  encoder_pretrained: True
  encoder_library: timm
  neck_transform: linear
  embeddings_size: 512
  classes: 4
  head_s: 12
  head_m1: 0.2
  head_m2: 0


runner_params:
  input_key: ["x", "labels"]


args:
  expdir: "./experiments/4classes"
  baselogdir: "./logs/4classes/version3_mixface_s12_effb0_cosine_ls_e01"
  seed: 8
  deterministic: True
  benchmark: True


stages:

  stage1:

    data_params:
      batch_size: 170
      num_workers: 12
      per_gpu_scaling: True
      drop_last: False
      shuffle: True
      loaders_params:
        valid:
          batch_size: 170

      train_dataset_params:
        image_folder_path: "/usr/local/FileStorage/data_training/glasses_classification/train"
        image_file_path: "/usr/local/FileStorage/data_training/glasses_classification/version_3/train.txt"

      valid_dataset_params:
        image_folder_path: "/usr/local/FileStorage/data_training/glasses_classification/valid"
        image_file_path: "/usr/local/FileStorage/data_training/glasses_classification/version_3/valid.txt"


    state_params:
      num_epochs: 70
      main_metric: &amp;main_metric f1
      minimize_metric: False
      valid_loader: valid


    criterion_params:
      criterion: CrossEntropyLossLabelSmoothing
      reduction: mean
      smooth_eps: 0.1


    scheduler_params:
      scheduler: CosineAnnealingWarmRestarts
      T_0: 900
      T_mult: 2
      eta_min: 0


    optimizer_params:
      optimizer: SGD
      lr: 0.1
      weight_decay: 0.001
      nesterov: True
      momentum: 0.9


    callbacks_params:
      loss:
        callback: CriterionCallback

      optimizer:
        callback: OptimizerCallback

      accuracy:
        callback: AccuracyCallback
        accuracy_args: [1, 2]

      f1_score:
        callback: F1ScoreMetricCallback
        n_classes: 4
        class_mapping: ['face_in_optical_glasses', 'face_in_protective_glasses', 'face_in_sunglasses', 'face_without_glasses']


      scheduler:
        callback: SchedulerCallback
        mode: batch

      logger:
        callback: AlchemyLogger
        token: "484b162171bce2dc5371f9acc09d9fd2"
        project: "glasses_classification"
        experiment: "version3_mixface_s12_effb0_cosine_ls_e01"
        group: "validation_version_2"
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='litvinich' date='2020-03-19T11:28:08Z'>
		I found how to fix this bug:
Change on_epoch_end method to:
&lt;denchmark-code&gt;def on_epoch_end(self, state: _State):
        """Translate epoch metrics to Alchemy"""
        if state.logdir is None:
            return

        extra_mode = "_base"
        splitted_epoch_metrics = utils.split_dict_to_subdicts(
            dct=state.epoch_metrics, prefixes=list(state.loaders.keys()), extra_key=extra_mode,
        )
        if self.log_on_epoch_end and splitted_epoch_metrics.get(extra_mode):
            self._log_metrics(
                metrics=splitted_epoch_metrics[extra_mode],
                step=state.global_epoch,
                mode=extra_mode,
                suffix=self.epoch_log_suffix,
            )
&lt;/denchmark-code&gt;

Because base_ key is not always in dict with metrics
If this solution is good and doesn't has corner cases, I can make pull request with this bug fix + LR logging bug (change SchedulerCallback order to 100 and LoggingCallback order to 120)
		</comment>
		<comment id='2' author='litvinich' date='2020-03-24T08:22:24Z'>
		Looks like we have already fixed this issue during 20.03.3 release :)
		</comment>
	</comments>
</bug>