<bug id='77' author='Liuxinyue521' open_date='2020-05-12T15:24:20Z' closed_time='2020-05-14T09:07:02Z'>
	<summary>[BUG]ValueError: data/vibe_db/mpii3d_train_db.pt do not exists</summary>
	<description>
Operating system: ubuntu 18.04
Python version: 3.7.5
Pytorch version: torch==1.4.0, torchvision==0.5.0, torchgeometry==0.1.2
When processing mhi_inf_3dhp dataset, it ended with 'Killed' notice:
&lt;denchmark-link:https://user-images.githubusercontent.com/57157406/81712280-01457580-94a7-11ea-8833-cf19cd748f2c.png&gt;&lt;/denchmark-link&gt;

and when start training, this error happens. And indeed, there is no mpii3d_train_db.pt in the vibe-db folder.
Lists of files in vibe_db are: 3dpw_test_db.pt   amass_db.pt        pennaction_train_db.pt
3dpw_train_db.pt  insta_train_db.h5  posetrack_train_db.pt
3dpw_val_db.pt    mpii3d_val_db.pt
If someone knows how to solve this, please tell me and I would really appreciate it. Thanks in advance.
	</description>
	<comments>
		<comment id='1' author='Liuxinyue521' date='2020-05-13T00:13:01Z'>
		&lt;denchmark-link:https://github.com/Liuxinyue521&gt;@Liuxinyue521&lt;/denchmark-link&gt;
 what is your RAM size? The mpii3d preprocessing script might be killed due to insufficient RAM.
		</comment>
		<comment id='2' author='Liuxinyue521' date='2020-05-13T02:06:42Z'>
		
@Liuxinyue521 what is your RAM size? The mpii3d preprocessing script might be killed due to insufficient RAM.

Thanks for your reply! I will free some space and try it again. My RAM size is 32G, is this enough for the processing?
		</comment>
		<comment id='3' author='Liuxinyue521' date='2020-05-13T02:36:18Z'>
		
@Liuxinyue521 what is your RAM size? The mpii3d preprocessing script might be killed due to insufficient RAM.
By the way, how much RAM needed for this processing?

		</comment>
		<comment id='4' author='Liuxinyue521' date='2020-05-13T13:26:55Z'>
		I don't know exactly but I tested the code on machines with 32 and 64GB RAM.
		</comment>
		<comment id='5' author='Liuxinyue521' date='2020-05-14T08:18:44Z'>
		&lt;denchmark-link:https://github.com/mkocabas&gt;@mkocabas&lt;/denchmark-link&gt;
  I've completed pre-processing of all mentioned datasets. When I start training I got this error   I checked the vibe_db folder and there is no exactly  file. There is  file. So if we rename the  to  then is it ok?
		</comment>
		<comment id='6' author='Liuxinyue521' date='2020-05-14T09:07:55Z'>
		@lan786 yes, that was a typo. Thanks for noting this!
		</comment>
		<comment id='7' author='Liuxinyue521' date='2020-05-16T01:11:23Z'>
		
I don't know exactly but I tested the code on machines with 32 and 64GB RAM.

Hi, I still get this error. Could you tell me how to do this processing in a not-that-large-RAM machine? Like reducing the batch size? Or alternatively, could you send me the processed datasets directly to me? I would appreciate it if you can help me about this.
		</comment>
		<comment id='8' author='Liuxinyue521' date='2020-05-20T07:54:27Z'>
		
@mkocabas I've completed pre-processing of all mentioned datasets. When I start training I got this error mpii3d_train_db.pt do not exists I checked the vibe_db folder and there is no exactly mpii3d_train_db.pt file. There is mpii3d_spin_db.pt file. So if we rename the mpii3d_spin_db.pt to mpii3d_train_db.pt then is it ok?

I download this dataset via &lt;denchmark-link:https://upenn.box.com/PennAction&gt;https://upenn.box.com/PennAction&lt;/denchmark-link&gt;
, but found it is invlid. How can you get PennAction?
		</comment>
	</comments>
</bug>