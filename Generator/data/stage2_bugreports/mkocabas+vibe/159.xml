<bug id='159' author='jiandandian2' open_date='2020-12-02T08:20:51Z' closed_time='2020-12-29T06:40:24Z'>
	<summary>train-bug</summary>
	<description>
Thanks for your interest in our research!
If you have problems running our code, please include;

your operating system and the version:
ubuntu18
your python version:
python3.6
your pytorch version:
pytorch1.4
the stack trace of the error that you see:

root@node6:~/data/wang_hao/SMPL/VIBE-master# python3 train?py --cfg configs/config.yaml
Namespace(cfg='configs/config.yaml')
GPU name -&gt; GeForce RTX 2080 Ti
GPU feat -&gt; _CudaDeviceProperties(name='GeForce RTX 2080 Ti', major=7, minor=5, total_memory=11019MB, multi_processor_count=68)
{'CUDNN': CfgNode({'BENCHMARK': True, 'DETERMINISTIC': False, 'ENABLED': True}),
'DATASET': CfgNode({'SEQLEN': 16, 'OVERLAP': 0.5}),
'DEBUG': False,
'DEBUG_FREQ': 5,
'DEVICE': 'cuda',
'EXP_NAME': 'vibe',
'LOGDIR': 'results/vibe_tests/02-12-2020_16-03-31_vibe',
'LOSS': {'D_MOTION_LOSS_W': 0.5,
'KP_2D_W': 300.0,
'KP_3D_W': 300.0,
'POSE_W': 60.0,
'SHAPE_W': 0.06},
'MODEL': {'TEMPORAL_TYPE': 'gru',
'TGRU': {'ADD_LINEAR': True,
'BIDIRECTIONAL': False,
'HIDDEN_SIZE': 1024,
'NUM_LAYERS': 2,
'RESIDUAL': True}},
'NUM_WORKERS': 8,
'OUTPUT_DIR': 'results/vibe_tests',
'SEED_VALUE': -1,
'TRAIN': {'BATCH_SIZE': 32,
'DATASETS_2D': ['Insta'],
'DATASETS_3D': ['MPII3D'],
'DATASET_EVAL': 'ThreeDPW',
'DATA_2D_RATIO': 0.6,
'END_EPOCH': 30,
'GEN_LR': 5e-05,
'GEN_MOMENTUM': 0.9,
'GEN_OPTIM': 'Adam',
'GEN_WD': 0.0,
'LR_PATIENCE': 5,
'MOT_DISCR': {'ATT': {'DROPOUT': 0.2,
'LAYERS': 3,
'SIZE': 1024},
'FEATURE_POOL': 'attention',
'HIDDEN_SIZE': 1024,
'LR': 0.0001,
'MOMENTUM': 0.9,
'NUM_LAYERS': 2,
'OPTIM': 'Adam',
'UPDATE_STEPS': 1,
'WD': 0.0001},
'NUM_ITERS_PER_EPOCH': 500,
'PRETRAINED': '',
'PRETRAINED_REGRESSOR': 'data/vibe_data/spin_model_checkpoint.pth.tar',
'RESUME': '',
'START_EPOCH': 0}}
InstaVariety number of dataset objects 130431
MPII3D Dataset overlap ratio:  0
Loaded mpii3d dataset from data/vibe_db/mpii3d_train_db.pt
mpii3d - number of dataset objects 59934
AMASS dataset number of videos: 1012067
3DPW Dataset overlap ratio:  0.0
Loaded 3dpw dataset from data/vibe_db/3dpw_val_db.pt
3dpw - number of dataset objects 635
=&gt; loaded pretrained model from 'data/vibe_data/spin_model_checkpoint.pth.tar'
is not a pretrained model!!!!
=&gt; no checkpoint found at ''
Epoch 1/30Traceback (most recent call last):
File "train.py", line 162, in 
main(cfg)
File "train.py", line 154, in main
debug_freq=cfg.DEBUG_FREQ,
File "/root/data/wang_hao/SMPL/VIBE-master/lib/core/trainer.py", line 318, in fit
self.train()
File "/root/data/wang_hao/SMPL/VIBE-master/lib/core/trainer.py", line 181, in train
preds = self.generator(inp)
File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 722, in _call_impl
result = self.forward(*input, **kwargs)
File "/root/data/wang_hao/SMPL/VIBE-master/lib/models/vibe.py", line 109, in forward
smpl_output = self.regressor(feature, J_regressor=J_regressor)
File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 722, in _call_impl
result = self.forward(*input, **kwargs)
File "/root/data/wang_hao/SMPL/VIBE-master/lib/models/spin.py", line 271, in forward
pose2rot=False
File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 722, in _call_impl
result = self.forward(*input, **kwargs)
File "/root/data/wang_hao/SMPL/VIBE-master/lib/models/smpl.py", line 73, in forward
smpl_output = super(SMPL, self).forward(*args, **kwargs)
File "/root/data/wang_hao/SMPL/VIBE-master/smplx/body_models.py", line 376, in forward
self.lbs_weights, pose2rot=pose2rot, dtype=self.dtype)
File "/root/data/wang_hao/SMPL/VIBE-master/smplx/lbs.py", line 205, in lbs
J_transformed, A = batch_rigid_transform(rot_mats, J, parents, dtype=dtype)
File "/root/data/wang_hao/SMPL/VIBE-master/smplx/lbs.py", line 347, in batch_rigid_transform
rel_joints.view(-1, 3, 1)).view(-1, joints.shape[1], 4, 4)
RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
	</description>
	<comments>
	</comments>
</bug>