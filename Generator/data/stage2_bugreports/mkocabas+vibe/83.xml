<bug id='83' author='Liuxinyue521' open_date='2020-05-21T08:36:49Z' closed_time='2020-05-27T10:54:13Z'>
	<summary>[BUG]Training getting killed</summary>
	<description>
Hi, here is some configuration of my machine:
Operating System: Ubuntu 18.04
Python: 3.7.5
Pytorch version: torch==1.4.0, torchvision==0.5.0, torchgeometry==0.1.2
After processing all the datasets, I try to run the train command, but it ends with Killed error again..
Here are some outputs:
&lt;denchmark-link:https://user-images.githubusercontent.com/57157406/82539749-89e7a400-9b80-11ea-89f4-0244a20d228b.png&gt;&lt;/denchmark-link&gt;

Output of nvidia-smi:
&lt;denchmark-link:https://user-images.githubusercontent.com/57157406/82539804-a1269180-9b80-11ea-8242-2bb1cff87bd2.png&gt;&lt;/denchmark-link&gt;

Output of running dmesg -T| grep -E -i -B100 'killed process':
&lt;denchmark-link:https://user-images.githubusercontent.com/57157406/82539888-c2877d80-9b80-11ea-878c-f810ddb0cf0f.png&gt;&lt;/denchmark-link&gt;

By the way, I have already tried batch_size=4 and NUM_WORKERS=0 and 1, still get killed. I will appreciate it if anyone can give some advice. Thanks in advance.
	</description>
	<comments>
		<comment id='1' author='Liuxinyue521' date='2020-05-27T10:54:45Z'>
		Solved by increasing RAM of the machine
		</comment>
		<comment id='2' author='Liuxinyue521' date='2020-08-12T13:55:05Z'>
		&lt;denchmark-link:https://github.com/Liuxinyue521&gt;@Liuxinyue521&lt;/denchmark-link&gt;
 Could you please tell how much RAM you were using initially when the error occurred and how much you increased for successful training ? Thanks.
		</comment>
		<comment id='3' author='Liuxinyue521' date='2020-10-17T03:17:24Z'>
		&lt;denchmark-link:https://github.com/Liuxinyue521&gt;@Liuxinyue521&lt;/denchmark-link&gt;
 Could you please tell how much RAM you were using initially when the error occurred and how much you increased for successful training ? Thanks.
		</comment>
	</comments>
</bug>