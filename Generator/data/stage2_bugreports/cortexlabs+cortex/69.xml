<bug id='69' author='deliahu' open_date='2019-04-19T16:54:48Z' closed_time='2019-05-17T05:21:05Z'>
	<summary>Not using an ingested column as a raw_column results in error</summary>
	<description>
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

It should be possible to have a column defined in env.data.schema that isn't used as a raw_column (CSV and Parquet).
&lt;denchmark-h:h3&gt;Application Configuration&lt;/denchmark-h&gt;

Start from Iris, and then completely remove one of the features (e.g. sepal_width)
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;


cx deploy

&lt;denchmark-h:h3&gt;Stack Trace&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Starting

INFO:cortex:Starting
INFO:cortex:Ingesting
INFO:cortex:Ingesting iris-1 data from s3a://cortex-examples/iris.csv
ERROR:cortex:An error occurred, see `cx logs raw_column sepal_width` for more details.
Traceback (most recent call last):
  File "/src/spark_job/spark_job.py", line 307, in run_job
    raw_df = ingest_raw_dataset(spark, ctx, cols_to_validate, should_ingest)
  File "/src/spark_job/spark_job.py", line 151, in ingest_raw_dataset
    ingest_df = spark_util.ingest(ctx, spark)
  File "/src/spark_job/spark_util.py", line 223, in ingest
    expected_schema = expected_schema_from_context(ctx)
  File "/src/spark_job/spark_util.py", line 117, in expected_schema_from_context
    for fname in expected_field_names
  File "/src/spark_job/spark_util.py", line 117, in &lt;listcomp&gt;
    for fname in expected_field_names
KeyError: 'petal_width'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Version&lt;/denchmark-h&gt;

master
&lt;denchmark-h:h3&gt;Additional Context&lt;/denchmark-h&gt;

It should also be possible to not ingest all of the columns in the dataset (just Parquet for now); we should test this.
	</description>
	<comments>
	</comments>
</bug>