<bug id='1648' author='nellaG' open_date='2020-12-02T07:50:01Z' closed_time='2020-12-23T15:25:20Z'>
	<summary>cortex job is terminated before executing api cause it cannot find SQS queue</summary>
	<description>
&lt;denchmark-h:h3&gt;Version&lt;/denchmark-h&gt;

0.22.1
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

Submitted cortex job but it is intermittently terminated because the cortex operator cannot find SQS queue.
The cortex operator's log looks like:
&lt;denchmark-code&gt;{
    "log": "terminating job 69b377c15a1314be (example-api api); sqs queue with url https://sqs.ap-northeast-2.amazonaws.com/{key}/9867795cbb-example-api-69b377c15a1314be.fifo was not found"
}
&lt;/denchmark-code&gt;

The same job id's api logging and downloader logging is not triggered.
&lt;denchmark-h:h3&gt;Configuration&lt;/denchmark-h&gt;

cortex.yaml
&lt;denchmark-code&gt;- name: 
  kind: BatchAPI
  predictor:
    type: python
    path: predictor.py
    image: cortexlabs/python-predictor-gpu:0.22.1
    env:
      DEVICE: '0'
      ENV: aws
      SQS_REGION: ap-northeast-2
  compute:
    mem: 2G
    gpu: 1
&lt;/denchmark-code&gt;

cluster.yaml
&lt;denchmark-code&gt;region: ap-northeast-2
instance_type: g4dn.xlarge
min_instances: 0
max_instances: 250
instance_volume_size: 30
instance_volume_type: gp2
subnet_visibility: public
nat_gateway: none
api_load_balancer_scheme: internet-facing
operator_load_balancer_scheme: internet-facing
spot: true

spot_config:
    instance_distribution: [g4dn.xlarge]
    on_demand_base_capacity: 1
    on_demand_percentage_above_base_capacity: 0
    on_demand_backup: true
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;


submit the job
intermittently the job is failed

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

(describe the behavior you expected)
&lt;denchmark-h:h3&gt;Actual behavior&lt;/denchmark-h&gt;

(describe the behavior you experienced)
&lt;denchmark-h:h3&gt;Screenshots&lt;/denchmark-h&gt;

(optional)
&lt;denchmark-h:h3&gt;Stack traces&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;cortex logs example-api 69b377c15a1314be       
using aws environment
terminating job 69b377c15a1314be (example-api api); sqs queue with url https://sqs.ap-northeast-2.amazonaws.com/{key}/9867795cbb-example-api-69b377c15a1314be.fifo was not found
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

(optional)
&lt;denchmark-h:h3&gt;Suggested solution&lt;/denchmark-h&gt;

(optional)
	</description>
	<comments>
		<comment id='1' author='nellaG' date='2020-12-02T15:09:05Z'>
		It sounds like this happens occasionally, is this correct? If this information isn't reliable reproducible, the following information may help us recreate this issue:

how frequently are the jobs being submitted every hour?
out of the jobs being submitted, how may run into this issue?

		</comment>
		<comment id='2' author='nellaG' date='2020-12-04T07:15:43Z'>
		&lt;denchmark-link:https://github.com/vishalbollu&gt;@vishalbollu&lt;/denchmark-link&gt;

Yes. It happens occasionally as you said, Here's our experimental condition for submitting jobs:
&lt;denchmark-code&gt;
* 576 jobs are requested within 2h 40m.
* Each request processes 300 images (`batch_size` : 60)
* 492 requests succeeded, 84 requests are failed


&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='nellaG' date='2020-12-04T17:45:04Z'>
		Thanks for providing the information.
While we investigate this issue, have you considered using the Realtime API rather than the Batch API?
The use case you've described above seems involve to frequents requests with each request containing a relatively small payload (300 images). The Realtime API may be better at handling this kind of traffic when compared the the Batch API.
		</comment>
		<comment id='4' author='nellaG' date='2020-12-07T06:00:25Z'>
		&lt;denchmark-link:https://github.com/vishalbollu&gt;@vishalbollu&lt;/denchmark-link&gt;
 No, we haven't used Realtime API yet. I will consider your suggestion while the investigation. Thanks for your help.
		</comment>
		<comment id='5' author='nellaG' date='2020-12-17T15:47:11Z'>
		&lt;denchmark-link:https://github.com/nellaG&gt;@nellaG&lt;/denchmark-link&gt;
 I have tried to reproduce the issue. I ran this script that submitted 576 jobs in total every 10 seconds. 573 jobs completed successfully. 3 jobs failed, 2 jobs failed because a queue was unable to be created and 1 failed because a log stream was not found. 3 failed jobs out of 576 submitted jobs is drastically different from your scenario with 84 failed requests from 576 submitted jobs
Is there any other information you can provide to help me set up a test that will reproduce your situation? My test script is below:
&lt;denchmark-code&gt;import requests
import time

items = list(range(300))

job_ids = []

# submit 576 jobs with a 10 second delay between each submission
for i in range(576):
    job = {
        "workers": 1,
        "item_list": {"items": items, "batch_size": 60},
        "config": {"dest_s3_dir": "&lt;S3 DIR&gt;"},
    }

    response = requests.post("http://endpoint", json=job)

    json_response = response.json()
    job_ids.append(json_response["job_id"])
    time.sleep(10)


time.sleep(180) # wait for jobs to complete

# verify job status after each one
for job_id in job_ids:
    status = requests.get(f"http://endpoint?jobID={job_id}").json()["job_status"]["status"]

    print(f"job id: {job_id}  status: {status}")
    time.sleep(0.2)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='nellaG' date='2020-12-18T05:54:51Z'>
		&lt;denchmark-link:https://github.com/vishalbollu&gt;@vishalbollu&lt;/denchmark-link&gt;
 Hello. During the investigation, my team tried to reproduce this issue that happens occasionally but it wasn't possible. So I just updated my team's cortex version to 0.23. I cannot sure the issue is resolved because of the update, but the occasional job termination is not occuring anymore after using 0.23 version. So I think you may close this issue. I'm so grateful for your help.
		</comment>
		<comment id='7' author='nellaG' date='2020-12-18T16:00:19Z'>
		Thanks for following up. Keep us posted!
		</comment>
	</comments>
</bug>