<bug id='185' author='lingvisa' open_date='2020-01-10T00:23:24Z' closed_time='2020-01-10T01:26:14Z'>
	<summary>CoreNLPClient doesn't produce valid characters for Chinese</summary>
	<description>
I tested CoreNLPClient with StanfordNLP and found that the object returned by the 'annotate' function doesn't produce valid Chinese characters, below:
text = "我吃苹果"
with CoreNLPClient(annotators=['tokenize', 'ssplit', 'pos'],
timeout=60000, memory='8G', properties='zh') as client:
# submit the request to the server
doc = client.annotate(text)
&lt;denchmark-code&gt;# get the first sentence
sentence = doc.sentence[0]

print('---')
print('first token of first sentence')
token = sentence.token[0]
print(token)
&lt;/denchmark-code&gt;

The output:
first token of first sentence
word: "\346\210\221"
pos: "PN"
value: "\346\210\221"
originalText: "\346\210\221"
ner: "O"
lemma: "\346\210\221"
beginChar: 0
endChar: 1
utterance: 0
speaker: "PER0"
tokenBeginIndex: 0
tokenEndIndex: 1
hasXmlContext: false
isNewline: false
coarseNER: "O"
fineGrainedNER: "O"
corefMentionIndex: 0
How to change that output to valid Chinese characters?
	</description>
	<comments>
		<comment id='1' author='lingvisa' date='2020-01-10T01:06:47Z'>
		Not sure how you output it, but this is probably an encoding problem.  Need
to set it to utf-8
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Jan 9, 2020, 6:23 PM lingvisa ***@***.***&gt; wrote:
 I tested CoreNLPClient with StanfordNLP and found that the object returned
 by the 'annotate' function doesn't produce valid Chinese characters, below:

 text = "我吃苹果"
 with CoreNLPClient(annotators=['tokenize', 'ssplit', 'pos'],
 timeout=60000, memory='8G', properties='zh') as client:
 # submit the request to the server
 doc = client.annotate(text)

 # get the first sentence

 sentence = doc.sentence[0]



 print('---')

 print('first token of first sentence')

 token = sentence.token[0]

 print(token)


 The output:
 first token of first sentence
 word: "\346\210\221"
 pos: "PN"
 value: "\346\210\221"
 originalText: "\346\210\221"
 ner: "O"
 lemma: "\346\210\221"
 beginChar: 0
 endChar: 1
 utterance: 0
 speaker: "PER0"
 tokenBeginIndex: 0
 tokenEndIndex: 1
 hasXmlContext: false
 isNewline: false
 coarseNER: "O"
 fineGrainedNER: "O"
 corefMentionIndex: 0

 How to change that output to valid Chinese characters?

 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub
 &lt;https://github.com/stanfordnlp/stanfordnlp/issues/185?email_source=notifications&amp;email_token=AA2AYWPHMYNYPP6DJQYUOVLQ465X3A5CNFSM4KFAPCY2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IFGW2IA&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AA2AYWJTWJGY2TOQDMCMOYDQ465X3ANCNFSM4KFAPCYQ&gt;
 .



		</comment>
		<comment id='2' author='lingvisa' date='2020-01-10T01:25:58Z'>
		I switched the output-format='json' and it works fine. Thanks.
		</comment>
		<comment id='3' author='lingvisa' date='2020-01-10T02:27:27Z'>
		&lt;denchmark-link:https://github.com/lingvisa&gt;@lingvisa&lt;/denchmark-link&gt;
 to answer your original question for completeness:
You can recover the words by decoding the binary string as &lt;denchmark-link:https://github.com/AngledLuffa&gt;@AngledLuffa&lt;/denchmark-link&gt;
 mentioned. For example,
b"\346\210\221".decode('utf-8')
# prints "我"
		</comment>
		<comment id='4' author='lingvisa' date='2020-01-10T19:57:48Z'>
		Thanks, qipeng.
		</comment>
	</comments>
</bug>