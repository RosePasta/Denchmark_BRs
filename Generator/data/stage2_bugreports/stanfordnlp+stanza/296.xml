<bug id='296' author='rithn' open_date='2020-05-07T18:31:56Z' closed_time='2020-08-06T18:28:51Z'>
	<summary>Dependency Parser module creating empty batch leading to AssertionError</summary>
	<description>
Describe the bug
In the file stanza/models/depparse/data.py:168, in the 'chunk_batches' method, the list 'res' contains the batches. However if the very first sentence is too long, then the condition in line 167 shall be true, and hence an empty 'current' list shall be appended to 'res'. Hence, when this function is called by the init method, this empty batch shall be at the front of the list 'self.data'. This shall lead to an AssertionError in the get_item method (line 102) where it checks length of the batch.
	</description>
	<comments>
		<comment id='1' author='rithn' date='2020-05-08T19:17:15Z'>
		Can you provide an example that'll trigger this error so that we can better diagnose our implementation?
Also &lt;denchmark-link:https://github.com/yuhui-zh15&gt;@yuhui-zh15&lt;/denchmark-link&gt;
 can you take a look at this issue?
		</comment>
		<comment id='2' author='rithn' date='2020-05-08T19:19:57Z'>
		Actually I can not reproduce this issue. I've tried to annotate a long sentence with 100k characters and it does not report any error.
		</comment>
		<comment id='3' author='rithn' date='2020-05-08T23:55:08Z'>
		&lt;denchmark-link:https://github.com/stanfordnlp/stanza/files/4602194/inp_83.txt&gt;inp_83.txt&lt;/denchmark-link&gt;

This file is part of IIT-Bombay Hindi-English Corpus.
I run the following script:
&lt;denchmark-code&gt;import stanza
import time
import sys

inputfile = sys.argv[1]
outfile = sys.argv[2]

stanza.download('hi') # download Hindi model
with open(inputfile,"r",encoding='utf-8') as f:
	l = f.readlines()
l = [line.strip() for line in l if line.strip() != ""]
inp = "\n".join(l)

st = time.time()
nlp = stanza.Pipeline(lang='hi', processors='tokenize,lemma,pos,depparse', use_gpu=True) # initialize Hindi neural pipeline
doc = nlp(inp) # run annotation over a sentence

sent_words = ["\n".join([f'id: {word.id}\tword: {word.text}\thead id: {word.head}\thead: {sent.words[word.head-1].text if word.head &gt; 0 else "root"}\tdeprel: {word.deprel}' for word in sent.words]) for sent in doc.sentences]
s = "\n\n".join(sent_words)
print(time.time() - st)

with open(outfile, "w",encoding='utf-8') as o:
	o.write(s)
&lt;/denchmark-code&gt;

I run it as python parse.py [inputfile] [outputfile]
Error does not occur when file is run line by line.
		</comment>
		<comment id='4' author='rithn' date='2020-05-09T00:00:45Z'>
		I am able to run this file after following change at &lt;denchmark-link:https://github.com/stanfordnlp/stanza/blob/master/stanza/models/depparse/data.py#L168&gt;https://github.com/stanfordnlp/stanza/blob/master/stanza/models/depparse/data.py#L168&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;        if len(current) &gt; 0:
            res.append(current)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='rithn' date='2020-05-09T00:17:06Z'>
		The error message:
&lt;denchmark-code&gt;Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 3.82MB/s]
2020-05-09 10:52:41 INFO: Downloading default packages for language: hi (Hindi)...
2020-05-09 10:52:42 INFO: File exists: /home/mxtrans/stanza_resources/hi/default.zip.
2020-05-09 10:52:44 INFO: Finished downloading models and saved to /home/mxtrans/stanza_resources.
2020-05-09 10:52:44 INFO: Loading these models for language: hi (Hindi):
=======================
| Processor | Package |
-----------------------
| tokenize  | hdtb    |
| pos       | hdtb    |
| lemma     | hdtb    |
| depparse  | hdtb    |
=======================

2020-05-09 10:52:45 INFO: Use device: gpu
2020-05-09 10:52:45 INFO: Loading: tokenize
2020-05-09 10:52:48 INFO: Loading: pos
2020-05-09 10:52:49 INFO: Loading: lemma
2020-05-09 10:52:49 INFO: Loading: depparse
2020-05-09 10:52:50 INFO: Done loading processors!
Traceback (most recent call last):
  File "parse.py", line 16, in &lt;module&gt;
    doc = nlp(inp) # run annotation over a sentence
  File "/home/mxtrans/anaconda3/lib/python3.6/site-packages/stanza/pipeline/core.py", line 176, in __call__
    doc = self.process(doc)
  File "/home/mxtrans/anaconda3/lib/python3.6/site-packages/stanza/pipeline/core.py", line 170, in process
    doc = self.processors[processor_name].process(doc)
  File "/home/mxtrans/anaconda3/lib/python3.6/site-packages/stanza/pipeline/depparse_processor.py", line 42, in process
    for i, b in enumerate(batch):
  File "/home/mxtrans/anaconda3/lib/python3.6/site-packages/stanza/models/depparse/data.py", line 149, in __iter__
    yield self.__getitem__(i)
  File "/home/mxtrans/anaconda3/lib/python3.6/site-packages/stanza/models/depparse/data.py", line 102, in __getitem__
    assert len(batch) == 9
AssertionError
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='rithn' date='2020-05-09T07:25:00Z'>
		Sorry but I still couldn't reproduce this issue. Could you fill the following information?
Environment (please complete the following information):

OS: [e.g. Windows, Ubuntu, CentOS, MacOS]
Python version: [e.g. Python 3.6.8 from Anaconda]
Stanza version: [e.g., 1.0.0]
GPU/CPU: [e.g., Nvidia Titan X]

		</comment>
		<comment id='7' author='rithn' date='2020-05-09T11:16:18Z'>
		OS: Ubuntu 16.04
Python: 3.6.6 from Anaconda
Stanza v1.0.1
GPU: Tesla T4
		</comment>
		<comment id='8' author='rithn' date='2020-08-06T18:28:51Z'>
		This might actually have been fixed while we were looking into some other related issues (in &lt;denchmark-link:https://github.com/stanfordnlp/stanza/pull/401&gt;#401&lt;/denchmark-link&gt;
). We'll include this fix in the next release!
		</comment>
	</comments>
</bug>