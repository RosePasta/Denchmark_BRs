<bug id='217' author='aryamccarthy' open_date='2020-03-24T19:53:29Z' closed_time='2020-04-27T07:28:01Z'>
	<summary>Vietnamese tokenizer fails on sentences beginning with punctuation.</summary>
	<description>
If there's leading punctuation in the string, the Vietnamese tokenizer raises an AssertionError.
To Reproduce
Steps to reproduce the behavior:
import stanza
stanza.download(lang="vi")
s = stanza.Pipeline(lang="vi")
s("- tuyệt vời!")
This gives:
&lt;denchmark-code&gt;Traceback (most recent call last):
    ...
    doc = self.nlp(s)
  File "/Users/arya/anaconda3/envs/staple/lib/python3.7/site-packages/stanza/pipeline/core.py", line 173, in __call__
    doc = self.process(doc)
  File "/Users/arya/anaconda3/envs/staple/lib/python3.7/site-packages/stanza/pipeline/core.py", line 167, in process
    doc = self.processors[processor_name].process(doc)
  File "/Users/arya/anaconda3/envs/staple/lib/python3.7/site-packages/stanza/pipeline/tokenize_processor.py", line 81, in process
    data = paras_to_chunks(text, dummy_labels)
  File "/Users/arya/anaconda3/envs/staple/lib/python3.7/site-packages/stanza/utils/postprocess_vietnamese_tokenizer_data.py", line 38, in paras_to_chunks
    return [para_to_chunks(re.sub('\s', ' ', pt.rstrip()), pc) for pt, pc in zip(text.split('\n\n'), char_level_pred.split('\n\n'))]
  File "/Users/arya/anaconda3/envs/staple/lib/python3.7/site-packages/stanza/utils/postprocess_vietnamese_tokenizer_data.py", line 38, in &lt;listcomp&gt;
    return [para_to_chunks(re.sub('\s', ' ', pt.rstrip()), pc) for pt, pc in zip(text.split('\n\n'), char_level_pred.split('\n\n'))]
  File "/Users/arya/anaconda3/envs/staple/lib/python3.7/site-packages/stanza/utils/postprocess_vietnamese_tokenizer_data.py", line 24, in para_to_chunks
    assert len(lastpred) &gt; 0
AssertionError

&lt;/denchmark-code&gt;

Expected behavior
Not crashing.
Environment (please complete the following information):

OS: macOS
Python version: Anaconda Python 3.7
Stanza version: latest

Additional context
The issue stems from lastpred being empty because you haven't ever reached this line: 


stanza/stanza/utils/postprocess_vietnamese_tokenizer_data.py


         Line 29
      in
      b73fb99






 lastpred = char_level_pred[idx] 





This issue also affects StanfordNLP.
	</description>
	<comments>
		<comment id='1' author='aryamccarthy' date='2020-03-24T22:33:36Z'>
		Thank you for reporting this bug, &lt;denchmark-link:https://github.com/aryamccarthy&gt;@aryamccarthy&lt;/denchmark-link&gt;
! I can reproduce it locally.
This fix &lt;denchmark-link:https://github.com/stanfordnlp/stanza/commit/5e2d0ef7a2f6735d0ab6d2488d7433179bc44614&gt;5e2d0ef&lt;/denchmark-link&gt;
 (on the  branch) seems to resolve this issue. This is probably some legacy code that checked for consistency of the CoNLL Shared Task data, which didn't happen to trigger this issue.
For now you can check out the code and apply this patch on master (we don't recommend using dev unless you're developing, as it could be unstable and/or contain undocumented changes) then pip install -e . to use it. We'll include this bugfix in a release in the near future!
		</comment>
		<comment id='2' author='aryamccarthy' date='2020-03-24T22:37:17Z'>
		Haha, deleting the assert seems straightforward enough. Thanks for wrapping this up! Hope all is well since our meeting at Disneyland.
		</comment>
		<comment id='3' author='aryamccarthy' date='2020-04-27T07:28:01Z'>
		This fix is now in our &lt;denchmark-link:https://github.com/stanfordnlp/stanza/releases/tag/1.0.1&gt;v1.0.1 release&lt;/denchmark-link&gt;
. Closing this issue now.
		</comment>
	</comments>
</bug>