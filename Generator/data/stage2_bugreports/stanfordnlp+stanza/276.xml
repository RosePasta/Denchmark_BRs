<bug id='276' author='KoichiYasuoka' open_date='2020-04-26T13:52:16Z' closed_time='2020-08-13T07:51:29Z'>
	<summary>Korean tokenizer does not separate punctuations</summary>
	<description>
I've tried Korean model of Stanza, but it failed in almost all cases.
&gt;&gt;&gt; import stanza
&gt;&gt;&gt; nlp=stanza.Pipeline("ko")
&gt;&gt;&gt; doc=nlp("종지부를 나눈다.")
&gt;&gt;&gt; print(doc)
[
  [
    {
      "id": "1",
      "text": "종지부를",
      "lemma": "종지부+를",
      "upos": "NOUN",
      "xpos": "ncn+jco",
      "head": 0,
      "deprel": "root",
      "misc": "start_char=0|end_char=4"
    },
    {
      "id": "2",
      "text": "나눈다.",
      "lemma": "나눈다.",
      "upos": "PUNCT",
      "xpos": "sf",
      "head": 1,
      "deprel": "punct",
      "misc": "start_char=5|end_char=9"
    }
  ]
]
The verb "나눈다" (divide) is labeled as PUNCT with the following fullstop.
	</description>
	<comments>
		<comment id='1' author='KoichiYasuoka' date='2020-04-26T17:28:22Z'>
		Thank you for pointing out! We can confirm this is indeed a bug for the default Korean model (Kaist). Can you try another package for Korean (GSD)? It seems this package works without this problem:
&gt;&gt;&gt; import stanza
&gt;&gt;&gt; stanza.download('ko', package='gsd')
&gt;&gt;&gt; nlp = stanza.Pipeline('ko', package='gsd')
&gt;&gt;&gt; doc=nlp("종지부를 나눈다.")
&gt;&gt;&gt; doc
[
  [
    {
      "id": "1",
      "text": "종지부를",
      "lemma": "종지부+를",
      "upos": "NOUN",
      "xpos": "NNG+JKO",
      "head": 2,
      "deprel": "obj",
      "misc": "start_char=0|end_char=4"
    },
    {
      "id": "2",
      "text": "나눈다",
      "lemma": "나누+ㄴ다",
      "upos": "VERB",
      "xpos": "VV+EF",
      "head": 0,
      "deprel": "root",
      "misc": "start_char=5|end_char=8"
    },
    {
      "id": "3",
      "text": ".",
      "lemma": ".",
      "upos": "PUNCT",
      "xpos": "SF",
      "head": 2,
      "deprel": "punct",
      "misc": "start_char=8|end_char=9"
    }
  ]
]

		</comment>
		<comment id='2' author='KoichiYasuoka' date='2020-05-12T17:23:33Z'>
		Reported the  issue in UD's Korean-Kaist treebank (&lt;denchmark-link:https://github.com/UniversalDependencies/UD_Korean-Kaist/issues/2&gt;UniversalDependencies/UD_Korean-Kaist#2&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='3' author='KoichiYasuoka' date='2020-08-13T07:19:40Z'>
		I'm very glad to hear the release of v1.1.1 of stanza. However, in my environment, the problem still occurs with default "ko"-model. Well, I will continue to use "ko-gsd"...
		</comment>
		<comment id='4' author='KoichiYasuoka' date='2020-08-13T07:28:11Z'>
		Have you tried to re-download the models?
		</comment>
		<comment id='5' author='KoichiYasuoka' date='2020-08-13T07:30:24Z'>
		Oh, my... but the download fails:
&lt;denchmark-code&gt;&gt;&gt;&gt; import stanza
&gt;&gt;&gt; stanza.download("ko")
Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 8.29MB/s]
2020-08-13 16:28:49 INFO: Downloading default packages for language: ko (Korean)...
2020-08-13 16:28:50 INFO: File exists: /home/yasuoka/stanza_resources/ko/default.zip.
2020-08-13 16:28:52 INFO: Finished downloading models and saved to /home/yasuoka/stanza_resources.
&lt;/denchmark-code&gt;

Well, may I remove the ko/default.zip by hand?
		</comment>
		<comment id='6' author='KoichiYasuoka' date='2020-08-13T07:33:47Z'>
		My mistake.  It would appear that change did not make it into the resources file.  We will try to correct that in the morning (PST)
		</comment>
		<comment id='7' author='KoichiYasuoka' date='2020-08-13T07:51:29Z'>
		Should be fixed now! Thank you for reporting this!
		</comment>
		<comment id='8' author='KoichiYasuoka' date='2020-08-13T08:01:24Z'>
		OK, I confirmed that default "ko"-model went "ko-gsd". Thank you, all.
		</comment>
	</comments>
</bug>