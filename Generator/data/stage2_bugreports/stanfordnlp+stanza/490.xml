<bug id='490' author='snakeztc' open_date='2020-10-20T15:01:34Z' closed_time='2020-10-23T16:54:23Z'>
	<summary>Korean tokenizer does not work</summary>
	<description>
I test multiple Korean examples using the 1.1.0 model. The performance seems really bad.
To Reproduce
import stanza
nlp = stanza.Pipeline(lang='ko')
doc = nlp("종지부를나눈다.")
Expected behavior
종지부[space]를[space]나눈다
Environment (please complete the following information):

OS: MacOS
Python version: 3.6
Stanza version: 1.1.0

	</description>
	<comments>
		<comment id='1' author='snakeztc' date='2020-10-20T16:46:08Z'>
		&lt;denchmark-link:https://github.com/snakeztc&gt;@snakeztc&lt;/denchmark-link&gt;
 The Korean tokenizer is trained with well-formatted Korean data, which is naturally separated with spaces. See &lt;denchmark-link:https://ko.wikipedia.org/wiki/%ED%83%9C%EC%96%91%EA%B3%84%EC%9D%98_%ED%98%95%EC%84%B1%EA%B3%BC_%EC%A7%84%ED%99%94&gt;https://ko.wikipedia.org/wiki/태양계의_형성과_진화&lt;/denchmark-link&gt;
, for example. Is this a specific use case where spaces are removed? Do you mind sharing a bit more background so we can understand how to best help?
		</comment>
		<comment id='2' author='snakeztc' date='2020-10-22T01:45:58Z'>
		I see. So it is bascially a white space splitter. For example, 종지부를나눈다, should be splitted into: 종지부//를//나누//ㄴ다
Now i found the lemma outputs seems give the desired tokenization.
My goal is to index korean text for full text search.
		</comment>
		<comment id='3' author='snakeztc' date='2020-10-22T02:27:50Z'>
		FWIW it would not be very difficult to reformat the training data from
universaldependencies.org to not have spaces, in which case you could
retrain the model as a segmenter.
		</comment>
		<comment id='4' author='snakeztc' date='2020-10-29T19:05:09Z'>
		Just out of curiosity - is it common to have Korean text all together like Chinese, so it needs to be segmented, or is it more common to have it already mostly separated like English?  I don't know if the technique I suggested above for making a Korean segmenter will give good results, but I can try if it's something that would be useful.
		</comment>
	</comments>
</bug>