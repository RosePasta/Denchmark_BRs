<bug id='338' author='unendin' open_date='2020-06-02T06:54:02Z' closed_time='2020-06-10T15:30:01Z'>
	<summary>LossySerializationException when running Quote annotator on some texts</summary>
	<description>
Describe the bug
Using stanza as CoreNLP client to run QuoteAnnotator, protobuf serialization often raises error:
stanza.server.client.AnnotationException: edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer$LossySerializationException: Keys are not being serialized: class edu.stanford.nlp.quoteattribution.QuoteAttributionUtils$EnhancedSentenceAnnotation
Setting outputFormat to json avoids the error. In the case I checked, the json quotes object includes a key, canonicalSpeaker, not defined in CoreNLP_pb2.py
Environment:

OS: MacOS
Python version: 3.8.3 homebrew
Stanza version: 1.0.1

	</description>
	<comments>
		<comment id='1' author='unendin' date='2020-06-02T23:49:22Z'>
		The proto annotations should include the speaker information in these fields:
&lt;denchmark-code&gt;  speaker: "He"
  speakerSieve: "automatic name"
  canonicalMention: "Mark"
  canonicalMentionBegin: 0
  canonicalMentionEnd: 0
&lt;/denchmark-code&gt;

I've been trying to reproduce this, and I can't.  What version stanza &amp; corenlp are you using?  The latest versions are corenlp 4.0 and stanza 1.0.1  If you are using the latest, would you recommend a modification to the following which will reproduce the error?
&lt;denchmark-code&gt;from stanza.server import CoreNLPClient

# example text
text = 'Mark said, "We need to ban Mox Opal because we\'re a bunch of jerks".  He added, "Lurrus is about to wreck everything anyway"'

# set up the client
print('---')
print('starting up Java Stanford CoreNLP Server...')

with CoreNLPClient(annotators=['tokenize','ssplit','pos','parse','coref','lemma','depparse','quote'],
                   #output_format = "json",
                   #classpath="$CLASSPATH",
                   be_quiet=False) as client:
    # submit the request to the server
    ann = client.annotate(text)
    print(ann)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='unendin' date='2020-06-06T05:44:19Z'>
		Yes. Sorry for the lack of repro. I am using the latest versions. Your example works for me. To break it, I need to make two modifications:

Set property  'ssplit.eolonly': 'true'
Change text (which aspects of the text are problematic I have no idea)

&lt;denchmark-code&gt;# example text
text = """
" Even as foreign powers step up pressure against Islamic State in Syria and Iraq , the militant group has expanded in Libya and established a new base close to Europe where it can generate oil revenue and plot terror attacks . "
( Tamer El - Ghobashy and Hassan Morajea , " Islamic State Tightens Grip On Libyan Stronghold Of Sirte , " The Wall Street Journal , 11/29/15 )
" This Burgeoning Operation In Libya Shows How Islamic State Is Able To Grow And Adapt " Despite The Numerous Airstrikes Campaigns And Ground Assaults .
""" 

# set up the client
print('---')
print('starting up Java Stanford CoreNLP Server...')

with CoreNLPClient(properties={'annotators':'tokenize,ssplit,pos,parse,coref,lemma,depparse,quote', 'ssplit.eolonly': 'true'},
                   #output_format = "json",
                   #classpath="$CLASSPATH",
                   be_quiet=False) as client:
    # submit the request to the server
    ann = client.annotate(text.strip())
    print(ann)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='unendin' date='2020-06-08T22:50:32Z'>
		The problem seems to be that when using ssplit.eolonly, certain sentences
get merged pieces of text from other sentences to make it easier to find
quotes.  (I don't actually know how or why that helps.)  The merged
sentence is then attached to the annotation, and it wasn't being sent back,
probably because this is a pretty obscure corner case and it was
forgotten.  I added code to send that back to the master branch of
corenlp.  You can try building from the source or just waiting for the next
release, whichever is more convenient for you.  Thanks for the report!
		</comment>
	</comments>
</bug>