<bug id='337' author='Y4rd13' open_date='2020-05-31T21:59:54Z' closed_time='2020-06-07T18:53:26Z'>
	<summary>Spacy.prefer_gpu() has conflict with Stanza use_gpu</summary>
	<description>
Describe the bug
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-20-c7cc905871af&gt; in &lt;module&gt;()
----&gt; 1 doc = stNLP('Todas las personas son las más inteligentes de mundo')
      2 
      3 print(*[f'word: {word.text+" "}\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\n')

7 frames
/usr/local/lib/python3.6/dist-packages/torch/nn/utils/rnn.py in pack_padded_sequence(input, lengths, batch_first, enforce_sorted)
    242 
    243     data, batch_sizes = \
--&gt; 244         _VF._pack_padded_sequence(input, lengths, batch_first)
    245     return _packed_sequence_init(data, batch_sizes, sorted_indices, None)
    246 

RuntimeError: 'lengths' argument should be a 1D CPU int64 tensor
To Reproduce
Steps to reproduce the behavior:

Go to google colab
Write the code:

!pip install stanza
import stanza

stanza.download('es', package='ancora', processors='tokenize,mwt,pos,lemma', verbose=True)
stNLP = stanza.Pipeline(processors='tokenize,mwt,pos,lemma',
                        lang='es',
                        use_gpu=True)

doc = nlp('Barack Obama nació en Hawaii.')
print(*[f'word: {word.text+" "}\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\n')

Error

Expected behavior
Should show the lemmatization of the sentences.
Environment (please complete the following information):

Google Colab
Stanza version: last version (31/05/2020)

	</description>
	<comments>
		<comment id='1' author='Y4rd13' date='2020-06-01T16:59:41Z'>
		@GUNTERMAXIMUS Just opened a new colab notebook and can run it without any problem. Maybe you should try to reset your environment.
&lt;denchmark-link:https://user-images.githubusercontent.com/17669473/83434022-9248a600-a3ee-11ea-9241-7448b4ae325e.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='Y4rd13' date='2020-06-02T02:35:07Z'>
		It seems the problem is the gpu preference used on spacy and stanza. But I'm not able to understand why. Otherwise, it will work perfectly.
# SpaCy
!pip install spacy
!spacy download es_core_news_sm # sm md
import spacy
spNLP = spacy.load('es_core_news_sm') #sm md
activated = spacy.prefer_gpu() # here
#spacy.require_gpu()

# Stanza NLP
!pip install stanza
import stanza

stanza.download('es', package='ancora', processors='tokenize,mwt,pos,lemma', verbose=True)
stNLP = stanza.Pipeline(processors='tokenize,mwt,pos,lemma',
                      lang='es',
                      use_gpu=True)  # and here

doc = stNLP('Barack Obama nació en Hawaii.')

print('\n')
print(*[f'word: {word.text+" "}\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\n')
&lt;denchmark-link:https://user-images.githubusercontent.com/13507900/83473676-226f0580-a458-11ea-9477-c0ccc72e22dc.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Y4rd13' date='2020-06-02T06:59:45Z'>
		It seems colab does not provide GPU?
		</comment>
		<comment id='4' author='Y4rd13' date='2020-06-04T18:34:15Z'>
		It does!
		</comment>
		<comment id='5' author='Y4rd13' date='2020-06-05T17:28:19Z'>
		I'm sorry I can not provide further information because I don't have access to GPU on colab. Will the problem occur if you only use Stanza (do not load spacy)?
		</comment>
		<comment id='6' author='Y4rd13' date='2020-06-05T19:37:08Z'>
		No, it will work fine, if I only use Stanza without loading SpaCy. The problem occur when I use:
on spacy
activated = spacy.prefer_gpu() # here
#spacy.require_gpu()
and on stanza
 use_gpu=True
If I only use  use_gpu=True on stanza and loading spacy but without spacy.prefer_gpu(), then will work fine.
		</comment>
		<comment id='7' author='Y4rd13' date='2020-06-07T18:53:26Z'>
		So this is a possible bug raised from spacy. I would recommend not using both on GPU for your processing. Closed now as we can not provide further information
		</comment>
	</comments>
</bug>