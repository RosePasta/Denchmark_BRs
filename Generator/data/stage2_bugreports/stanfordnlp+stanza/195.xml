<bug id='195' author='Nazliozum' open_date='2020-02-21T00:21:38Z' closed_time='2020-03-03T19:31:12Z'>
	<summary>Unable to change max_char_length</summary>
	<description>
I modify the max_char_length option within the CoreNLPClient object, but it des not seem to have an effect.
In my code, I specify the client as:
&lt;denchmark-code&gt;with CoreNLPClient(
        properties={
            "ner.applyFineGrained": "false",
            "annotators": "tokenize, ssplit, pos, lemma, ner, depparse",
        },
        memory=global_options.RAM_CORENLP,
        threads=global_options.N_CORES,
        timeout=12000000,
        max_char_length = 300000,
    ) as client:
&lt;/denchmark-code&gt;

but I keep getting the error:
&lt;denchmark-code&gt;stanfordnlp.server.client.AnnotationException: Request is too long to be handled by server: 201703 characters. Max length is 100000 characters.
&lt;/denchmark-code&gt;

Environment:

OS: MacOS
Python version: Python 3.7.3 from Anaconda
StanfordNLP version: 0.2.0

Thank you!
	</description>
	<comments>
		<comment id='1' author='Nazliozum' date='2020-02-21T21:30:54Z'>
		I'm not experiencing the same thing when I try it.  Would you set
`quiet=False` and let us know what the command line shows?

You should also be able to set max_char_length to -1 and not have a limit,
in case that's something that would help.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Feb 20, 2020 at 4:21 PM Özüm ***@***.***&gt; wrote:
 I modify the max_char_length option within the CoreNLPClient object, but
 it des not seem to have an effect.

 In my code, I specify the client as:

 with CoreNLPClient(
         properties={
             "ner.applyFineGrained": "false",
             "annotators": "tokenize, ssplit, pos, lemma, ner, depparse",
         },
         memory=global_options.RAM_CORENLP,
         threads=global_options.N_CORES,
         timeout=12000000,
         max_char_length = 300000,
     ) as client:

 but I keep getting the error:

 stanfordnlp.server.client.AnnotationException: Request is too long to be handled by server: 201703 characters. Max length is 100000 characters.

 *Environment:*

    - OS: MacOS
    - Python version: Python 3.7.3 from Anaconda
    - StanfordNLP version: 0.2.0

 Thank you!

 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub
 &lt;https://github.com/stanfordnlp/stanfordnlp/issues/195?email_source=notifications&amp;email_token=AA2AYWOMYTNP4FIRKT42UF3RD4NBJA5CNFSM4KYZTKF2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IPFCVPA&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AA2AYWM2OB26I36YLM44C3TRD4NBJANCNFSM4KYZTKFQ&gt;
 .



		</comment>
		<comment id='2' author='Nazliozum' date='2020-02-21T23:46:55Z'>
		Hi, here is what I get when I set be_quiet = False and max_char_length = -1:
&lt;denchmark-code&gt;Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 12000000 -threads 4 -maxCharLength -1 -quiet False -serverProperties corenlp_server-56b799255b7447e0.props -preload tokenize, ssplit, pos, lemma, ner, depparse
2020-02-21 15:45:57.384457
Processing 1000 lines.
Error: Could not find or load main class edu.stanford.nlp.pipeline.StanfordCoreNLPServer
Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.pipeline.StanfordCoreNLPServer
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/Users/nazliozum/anaconda3/lib/python3.7/site-packages/stanfordnlp/server/client.py", line 330, in _request
    r.raise_for_status()
  File "/Users/nazliozum/anaconda3/lib/python3.7/site-packages/requests/models.py", line 940, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http://localhost:9000/?properties=%7B%27outputFormat%27%3A+%27serialized%27%7D

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nazliozum/anaconda3/lib/python3.7/multiprocessing/pool.py", line 121, in worker
    result = (True, func(*args, **kwds))
  File "/Users/nazliozum/anaconda3/lib/python3.7/multiprocessing/pool.py", line 47, in starmapstar
    return list(itertools.starmap(args[0], args[1]))
  File "src/parse.py", line 27, in process_line
    sentences_processed, doc_sent_ids = corpus_preprocessor.process_document(line, lineID)
  File "/Users/nazliozum/Dropbox/cybersecurity-risk-disclosures/10K-reports/src/culture/preprocess.py", line 38, in process_document
    doc_ann = self.client.annotate(doc)
  File "/Users/nazliozum/anaconda3/lib/python3.7/site-packages/stanfordnlp/server/client.py", line 398, in annotate
    r = self._request(text.encode('utf-8'), request_properties, **kwargs)
  File "/Users/nazliozum/anaconda3/lib/python3.7/site-packages/stanfordnlp/server/client.py", line 336, in _request
    raise AnnotationException(r.text)
stanfordnlp.server.client.AnnotationException: Request is too long to be handled by server: 143262 characters. Max length is 100000 characters.
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "src/parse.py", line 134, in &lt;module&gt;
    function_name=process_line,
  File "src/parse.py", line 91, in process_largefile
    function_name, zip(next_n_lines, next_n_line_ids)
  File "/Users/nazliozum/anaconda3/lib/python3.7/multiprocessing/pool.py", line 276, in starmap
    return self._map_async(func, iterable, starmapstar, chunksize).get()
  File "/Users/nazliozum/anaconda3/lib/python3.7/multiprocessing/pool.py", line 657, in get
    raise self._value
stanfordnlp.server.client.AnnotationException: Request is too long to be handled by server: 143262 characters. Max length is 100000 characters.
&lt;/denchmark-code&gt;

Thank you for the help!
		</comment>
		<comment id='3' author='Nazliozum' date='2020-02-21T23:58:38Z'>
		Are you able to send smaller requests?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Feb 21, 2020 at 3:46 PM Özüm ***@***.***&gt; wrote:
 Hi, here is what I get when I set be_quiet = False and max_char_length =
 -1:

 Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 12000000 -threads 4 -maxCharLength -1 -quiet False -serverProperties corenlp_server-56b799255b7447e0.props -preload tokenize, ssplit, pos, lemma, ner, depparse
 2020-02-21 15:45:57.384457
 Processing 1000 lines.
 Error: Could not find or load main class edu.stanford.nlp.pipeline.StanfordCoreNLPServer
 Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.pipeline.StanfordCoreNLPServer
 multiprocessing.pool.RemoteTraceback:
 """
 Traceback (most recent call last):
   File "/Users/nazliozum/anaconda3/lib/python3.7/site-packages/stanfordnlp/server/client.py", line 330, in _request
     r.raise_for_status()
   File "/Users/nazliozum/anaconda3/lib/python3.7/site-packages/requests/models.py", line 940, in raise_for_status
     raise HTTPError(http_error_msg, response=self)
 requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http://localhost:9000/?properties=%7B%27outputFormat%27%3A+%27serialized%27%7D

 During handling of the above exception, another exception occurred:

 Traceback (most recent call last):
   File "/Users/nazliozum/anaconda3/lib/python3.7/multiprocessing/pool.py", line 121, in worker
     result = (True, func(*args, **kwds))
   File "/Users/nazliozum/anaconda3/lib/python3.7/multiprocessing/pool.py", line 47, in starmapstar
     return list(itertools.starmap(args[0], args[1]))
   File "src/parse.py", line 27, in process_line
     sentences_processed, doc_sent_ids = corpus_preprocessor.process_document(line, lineID)
   File "/Users/nazliozum/Dropbox/cybersecurity-risk-disclosures/10K-reports/src/culture/preprocess.py", line 38, in process_document
     doc_ann = self.client.annotate(doc)
   File "/Users/nazliozum/anaconda3/lib/python3.7/site-packages/stanfordnlp/server/client.py", line 398, in annotate
     r = self._request(text.encode('utf-8'), request_properties, **kwargs)
   File "/Users/nazliozum/anaconda3/lib/python3.7/site-packages/stanfordnlp/server/client.py", line 336, in _request
     raise AnnotationException(r.text)
 stanfordnlp.server.client.AnnotationException: Request is too long to be handled by server: 143262 characters. Max length is 100000 characters.
 """

 The above exception was the direct cause of the following exception:

 Traceback (most recent call last):
   File "src/parse.py", line 134, in &lt;module&gt;
     function_name=process_line,
   File "src/parse.py", line 91, in process_largefile
     function_name, zip(next_n_lines, next_n_line_ids)
   File "/Users/nazliozum/anaconda3/lib/python3.7/multiprocessing/pool.py", line 276, in starmap
     return self._map_async(func, iterable, starmapstar, chunksize).get()
   File "/Users/nazliozum/anaconda3/lib/python3.7/multiprocessing/pool.py", line 657, in get
     raise self._value
 stanfordnlp.server.client.AnnotationException: Request is too long to be handled by server: 143262 characters. Max length is 100000 characters.

 Thank you for the help!

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;https://github.com/stanfordnlp/stanfordnlp/issues/195?email_source=notifications&amp;email_token=AA2AYWMNQWVHLDLMLMHKNJ3REBRXBA5CNFSM4KYZTKF2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMUOTTI#issuecomment-589883853&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AA2AYWIUFF3OAKIBX26AMG3REBRXBANCNFSM4KYZTKFQ&gt;
 .



		</comment>
		<comment id='4' author='Nazliozum' date='2020-02-21T23:59:23Z'>
		Yes, the code works on smaller text pieces.
		</comment>
		<comment id='5' author='Nazliozum' date='2020-02-22T00:02:05Z'>
		Fair enough, but it's really bizarre that it would say "class not found"
when the text gets too long.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Feb 21, 2020 at 3:59 PM Özüm ***@***.***&gt; wrote:
 Yes, the code works on smaller text pieces.

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;https://github.com/stanfordnlp/stanfordnlp/issues/195?email_source=notifications&amp;email_token=AA2AYWN73A776JSSGA7HY73REBTFZA5CNFSM4KYZTKF2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMUPHNI#issuecomment-589886389&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AA2AYWLEG3UUMFIKU3TI7JDREBTFZANCNFSM4KYZTKFQ&gt;
 .



		</comment>
		<comment id='6' author='Nazliozum' date='2020-02-22T00:04:56Z'>
		Yeah, I agree. When I run the code on smaller text just to test, I get the result I expect, but it still gives me the following:
&lt;denchmark-code&gt;Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 12000000 -threads 4 -maxCharLength -1 -quiet False -serverProperties corenlp_server-c6f52d3a629d47ef.props -preload tokenize, ssplit, pos, lemma, ner, depparse
2020-02-21 16:03:29.053448
Processing 1000 lines.
Error: Could not find or load main class edu.stanford.nlp.pipeline.StanfordCoreNLPServer
Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.pipeline.StanfordCoreNLPServer
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='Nazliozum' date='2020-03-03T19:31:12Z'>
		I can no longer recreate the issue, it seems to be solved on my end. Thanks for your help.
		</comment>
	</comments>
</bug>