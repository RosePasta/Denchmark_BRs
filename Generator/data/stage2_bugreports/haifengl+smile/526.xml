<bug id='526' author='tuxdna' open_date='2020-03-22T11:08:37Z' closed_time='2020-04-01T13:06:52Z'>
	<summary>smile.regression.RandomForest::predict() sometimes returns NaN for very few samples</summary>
	<description>
&lt;denchmark-h:h2&gt;Expected behaviour&lt;/denchmark-h&gt;

I train a RandomForest regression model on my data which has ~ 3000 samples and 8 attributes, all attributes are double precision, with the predicted value being a double in the range 0 to 1 in the training dataset. After traning, when we make predict() call on all the samples from training data, sometimes one or two samples result in NaN, instead of a valid double prediction.
&lt;denchmark-h:h2&gt;Actual behaviour&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Found NaN
sampleNumber: 582
trueValue: 1.0
predictedValue: NaN
trueValue - predictedValue: NaN 

features: [17.0, 3.0, 0.058823529411764705, 0.7647058823529411, 1.5176745294625686, 0.19293206793206796, 1.0, 1.0]

&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Code snippet&lt;/denchmark-h&gt;

        int numTrees = 25;
        int nodeSize = 1;
        int maxDepth = 20;
        double sampleRate = 0.85;

        Properties props = new Properties();
        props.setProperty("smile.random.forest.trees", numTrees + "");
        props.setProperty("smile.random.forest.node.size", nodeSize + "");
        props.setProperty("smile.random.forest.max.depth", maxDepth + "");
        int maxLeafNodes = trainDataSet.size() / 3;
        props.setProperty("smile.random.forest.max.nodes", maxLeafNodes + "");
        props.setProperty("smile.random.forest.sample.rate", sampleRate + "");
        RandomForest rf = RandomForest.fit(formula, trainDataSet, props);
&lt;denchmark-h:h2&gt;Input data&lt;/denchmark-h&gt;

The data is described above. Can't share the actual dataset.
&lt;denchmark-h:h2&gt;Information&lt;/denchmark-h&gt;


Java

&lt;denchmark-code&gt;openjdk version "1.8.0_242"
OpenJDK Runtime Environment (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08)
OpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)
&lt;/denchmark-code&gt;


Smile version 2.2.2
Ubuntu 18.04 64bit

	</description>
	<comments>
		<comment id='1' author='tuxdna' date='2020-03-22T11:20:43Z'>
		On debugging the code, of all the RegressionTree instances in the forest ( obtained via tf.trees() ), one RegressionTree predict()'s a NaN value. This apparently happens because the path traversed on this tree doesn't correspond to any samples from training data i.e. the LeafNode -- new RegressionNode(n, out, mean, rss) will have n=0, out=Nan, mean=NaN and rss=0.0.
So a quick fix could be to just ignore this prediction and return  a mean of remaining RegressionTree's predictions:
diff --git a/core/src/main/java/smile/regression/RandomForest.java b/core/src/main/java/smile/regression/RandomForest.java
index 5afc9817..e344147c 100644
--- a/core/src/main/java/smile/regression/RandomForest.java
+++ b/core/src/main/java/smile/regression/RandomForest.java
@@ -366,11 +366,16 @@ public class RandomForest implements Regression&lt;Tuple&gt;, DataFrameRegression {
     public double predict(Tuple x) {
         Tuple xt = formula.x(x);
         double y = 0;
+        int nanCount = 0;
         for (RegressionTree tree : trees) {
-            y += tree.predict(xt);
+            double p = tree.predict(xt);
+            if(Double.isNaN(p)) {
+                nanCount ++ ;
+            } else {
+                y += p;
+            }
         }
-        
-        return y / trees.length;
+        return y / (trees.length - nanCount);
     }
 
     /**
		</comment>
		<comment id='2' author='tuxdna' date='2020-03-22T14:57:23Z'>
		Thanks for reporting the problem. Can you share the tree that makes NaN? You can do a System.out.println(tree). I would like to find the root cause rather than a workaround.
		</comment>
		<comment id='3' author='tuxdna' date='2020-03-23T12:57:33Z'>
		Your nodeSize (1) is too small. Try 5.
		</comment>
		<comment id='4' author='tuxdna' date='2020-03-24T12:52:40Z'>
		&lt;denchmark-link:https://github.com/haifengl&gt;@haifengl&lt;/denchmark-link&gt;
 When I try nodeSize=5, the precision drops significantly. Is there any way to prune those nodes which correspond to zero samples ?
Meanwhile I am trying to get a sample dataset that can help reproduce this issue.
		</comment>
		<comment id='5' author='tuxdna' date='2020-03-24T13:01:19Z'>
		

nodeSize = 1 generally overfits the data. Instead of reducing nodeSize, you should increase your sample size (300 is quite small).


Please print the tree with zero-sample leaf. It should not happen. I would like to find out why.


		</comment>
		<comment id='6' author='tuxdna' date='2020-03-24T13:44:34Z'>
		Actually the dataset contains 3000 ( 3k ) samples. Updated the description above.
Following file contains the the print()'ed version RegressTree causing NaN value on a sample ( also present in the file below ):
&lt;denchmark-link:https://github.com/haifengl/smile/files/4375554/smile-rfr-nan.txt&gt;smile-rfr-nan.txt&lt;/denchmark-link&gt;

Parameters:
        int numTrees = 25;
        int nodeSize = 1;
        int maxDepth = 50;
        double sampleRate = .85;
        int maxLeafNodes = trainDataSet.size() / 3;

        Properties props = new Properties();
        props.setProperty("smile.random.forest.trees", numTrees + "");
        props.setProperty("smile.random.forest.node.size", nodeSize + "");
        props.setProperty("smile.random.forest.max.depth", maxDepth + "");
        props.setProperty("smile.random.forest.max.nodes", maxLeafNodes + "");
        props.setProperty("smile.random.forest.sample.rate", sampleRate + "");
     
        final RandomForest rf = RandomForest.fit(formula, trainDataSet, props);
		</comment>
		<comment id='7' author='tuxdna' date='2020-03-24T13:50:38Z'>
		Some of your y are NaN. Note that the output of root is NaN. Otherwise, we should not get leaf of zero samples. Check how you read the data.
		</comment>
		<comment id='8' author='tuxdna' date='2020-03-24T14:41:44Z'>
		I checked that there are no NaN / empty values for output variable.
Here is code and data that reproduces the issue: &lt;denchmark-link:https://gist.github.com/tuxdna/c74befa1a9f85f0ed2ba4eaf2ad7263c/&gt;https://gist.github.com/tuxdna/c74befa1a9f85f0ed2ba4eaf2ad7263c/&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='tuxdna' date='2020-03-25T19:21:50Z'>
		Thanks for the data. I reproduce the problem with your data. The root cause that you have many values very close to each other such that floating number comparison is not stable. I harden the code to handle this case. The fix is in the master branch now.
		</comment>
		<comment id='10' author='tuxdna' date='2020-03-25T19:23:08Z'>
		BTW, you can run these two lines to train your model in smile shell:
&lt;denchmark-code&gt;val data = read.csv("randomized_train.csv", delimiter=',', header = true)

val rf = smile.regression.randomForest("A"~, data, ntrees = 25, mtry = 3, nodeSize = 1, maxDepth = 50, subsample = 0.85)
&lt;/denchmark-code&gt;

It is in scala. But you can do similar in Java. Check our website for examples.
		</comment>
		<comment id='11' author='tuxdna' date='2020-03-25T19:25:23Z'>
		Lastly, your hyperparameters are far from optimal for random forest. As said before, small nodeSize will overfit the data. Don't be fooled by the lower training error with nodeSize = 1. Similarly, maxDepth is too high (try &lt; 20 given you have only a few variables). Lastly, ntrees should be much large (try 500, at least 200).
		</comment>
		<comment id='12' author='tuxdna' date='2020-03-26T10:50:04Z'>
		&lt;denchmark-link:https://github.com/haifengl&gt;@haifengl&lt;/denchmark-link&gt;
 Thanks for fixing the issue and also suggesting a nicer way to load-csv/train the model.
Any idea when will the next release 2.3.0 or 2.2.3 will be available (hopefully containing this fix)?
		</comment>
		<comment id='13' author='tuxdna' date='2020-03-27T16:37:53Z'>
		&lt;denchmark-link:https://github.com/rayeaster&gt;@rayeaster&lt;/denchmark-link&gt;
 you have missing values in NHANES data.
BTW, you can do this to merge your X and Y files into one
&lt;denchmark-code&gt;paste -d, NHANESI_subset_y.csv NHANESI_subset_X.csv |cut -d, -f2,4-21 &gt; NHANESI_subset.csv
&lt;/denchmark-code&gt;

Then you can read it easily with Read.csv, which will infer the data type.
		</comment>
		<comment id='14' author='tuxdna' date='2020-04-01T13:06:51Z'>
		&lt;denchmark-link:https://github.com/tuxdna&gt;@tuxdna&lt;/denchmark-link&gt;
 2.3.0 is out.
		</comment>
		<comment id='15' author='tuxdna' date='2020-04-01T14:15:48Z'>
		&lt;denchmark-link:https://github.com/haifengl&gt;@haifengl&lt;/denchmark-link&gt;
 That's awesome, thank you!
		</comment>
	</comments>
</bug>