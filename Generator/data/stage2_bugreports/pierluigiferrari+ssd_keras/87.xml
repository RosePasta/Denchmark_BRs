<bug id='87' author='tadbeer' open_date='2018-03-20T12:09:08Z' closed_time='2018-04-02T20:02:57Z'>
	<summary>ValueError: cannot reshape array of size 0 into shape (0,newaxis,4)</summary>
	<description>
Error faced:
Epoch 00004: val_loss improved from 217.36631 to 104.59965, saving model to ssd300_weights_epoch-04_loss-137.3789_val_loss-104.5996.h5
Epoch 5/700
1/13 [=&gt;............................] - ETA: 17:50 - loss: 114.2628
2/13 [===&gt;..........................] - ETA: 16:58 - loss: 78.6937
3/13 [=====&gt;........................] - ETA: 15:14 - loss: 81.4181Traceback (most recent call last):
File "ssd_training.py", line 243, in 
validation_steps=ceil(n_val_samples / batch_size))
File "/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py", line 91, in wrapper
return func(*args, **kwargs)
File "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py", line 2192, in fit_generator
generator_output = next(output_generator)
File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 793, in get
six.reraise(value.class, value, value.traceback)
File "/usr/local/lib/python3.5/dist-packages/six.py", line 693, in reraise
raise value
File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 658, in _data_generator_task
generator_output = next(self._generator)
File "/home/ubuntu/SSD/ssd_batch_generator.py", line 909, in generate
batch_y_true = ssd_box_encoder.encode_y(batch_y, diagnostics=False) # Encode the labels into the y_true tensor that the SSD loss function needs.
File "/home/ubuntu/SSD/encode_decode_utils.py", line 858, in encode_y
y_encode_template = self.generate_encode_template(batch_size=len(ground_truth_labels), diagnostics=False)
File "/home/ubuntu/SSD/encode_decode_utils.py", line 803, in generate_encode_template
boxes = np.reshape(boxes, (batch_size, -1, 4))
File "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py", line 257, in reshape
return _wrapfunc(a, 'reshape', newshape, order=order)
File "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py", line 52, in _wrapfunc
return getattr(obj, method)(*args, **kwds)
ValueError: cannot reshape array of size 0 into shape (0,newaxis,4)`
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

During the 5th epoch of training, following error has surfaced. Please explain, that in the last line's error 'reshaping of size 0 into shape (0, newaxis, 4)', how does an array of size zero is being passed to be reshaped. Or any other issue..?
	</description>
	<comments>
		<comment id='1' author='tadbeer' date='2018-03-20T12:41:54Z'>
		My first guess would be that this happens because there is no ground truth box left in the entire batch, which is a situation that the SSDBoxEncoder doesn't account for. What batch size are you using?
		</comment>
		<comment id='2' author='tadbeer' date='2018-03-20T12:43:58Z'>
		Thanks, We have a training set of 380 images, val'n set of 34 images, and batch size of 32 was used.
		</comment>
		<comment id='3' author='tadbeer' date='2018-03-20T18:47:54Z'>
		Is it a possibility that a batch might end up with no ground truth boxes at all?
		</comment>
		<comment id='4' author='tadbeer' date='2018-03-21T05:13:20Z'>
		Each image in my training data has at-least one ground truth box labelled in PASCAL VOC format. That in my opinion should not result in any batch ending up with zero ground truth box.
I am running this on an AWS ubuntu EC2 instance.
		</comment>
		<comment id='5' author='tadbeer' date='2018-03-24T15:31:01Z'>
		I'm also getting the same error,
Please reply.
		</comment>
		<comment id='6' author='tadbeer' date='2018-03-26T10:05:18Z'>
		I've updated the data generator, please pull the latest master and try the new version. It's not very likely that this will solve your issue, but it might.
In order to narrow down the range of possible causes of the issue, once you pulled the latest master, add the following print statements to data_generator/object_detection_2d_data_generator.py. Add the line
print("before: ", len(batch_y))
right before &lt;denchmark-link:https://github.com/pierluigiferrari/ssd_keras/blob/52fef0f67a3b6fc6ae34635161135e45703100cc/data_generator/object_detection_2d_data_generator.py#L718-L729&gt;this code block&lt;/denchmark-link&gt;
 and the lines
&lt;denchmark-code&gt;print("after: ", len(batch_y))
print()
&lt;/denchmark-code&gt;

right after it. If the issue keeps occurring, let me know what it prints for the batch for which it fails.
If you don't mind sharing your dataset I can try to reproduce your issue myself.
		</comment>
		<comment id='7' author='tadbeer' date='2018-04-02T06:46:25Z'>
		Thanks &lt;denchmark-link:https://github.com/pierluigiferrari&gt;@pierluigiferrari&lt;/denchmark-link&gt;
 . The updated master is doing perfect training.
Could you explain what was the issue you fixed in that code update?
		</comment>
		<comment id='8' author='tadbeer' date='2018-04-02T20:01:40Z'>
		Great! The fix is a side effect of a quite drastic data generator redesign, so it's hard to say what fixed the issue because we never really figured out what exactly caused the issue. One possible reason is that the newly added SSD data augmentation chain (in case you're using that) makes it impossible for an image to end up with no ground truth boxes at all, so an empty batch becomes impossible. Another possible reason is that I cleaned up a few fragile parts in the generator code where some edge cases might have been overlooked previously and now they are handled correctly.
I'll close this issue as it appears to be fixed, let me know if anything else comes up.
		</comment>
	</comments>
</bug>