<bug id='645' author='jhuangcn' open_date='2019-02-15T09:18:33Z' closed_time='2019-07-24T23:18:37Z'>
	<summary>CreateTrainingJob operation (reached max retries: 4): Rate exceeded</summary>
	<description>
Please fill out the form below.
&lt;denchmark-h:h3&gt;System Information&lt;/denchmark-h&gt;


Framework (e.g. Sklearn) / Algorithm (e.g. Gradient boosting):
Framework Version: 0.19.2
Python Version: Python 3.6.6
CPU or GPU: CPU
Python SDK Version: 1.18.2
Are you using a custom image: No

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I come across the API exceed rate error frequently. I run multiple jobs in parallel on the instance which has a max-parallel job of 20. I use python Pool to trigger it with maximum process of 5, and I got the exception code like following:
botocore.exceptions.ClientError: An error occurred (ThrottlingException) when calling the CreateTrainingJob operation (reached max retries: 4): Rate exceeded
&lt;denchmark-h:h3&gt;Minimal repro / logs&lt;/denchmark-h&gt;

Please provide any logs and a bare minimum reproducible test case, as this will be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Traceback (most recent call last):
File "/usr/lib/python3.6/multiprocessing/pool.py", line 119, in worker
result = (True, func(*args, **kwds))
File "/usr/lib/python3.6/multiprocessing/pool.py", line 47, in starmapstar
return list(itertools.starmap(args[0], args[1]))
File "../sgmk_utils.py", line 225, in wait_sgmaker_job_success_description
job_name = sgmaker_train(config) if is_train else sgmaker_tune(config)
File "../sgmk_utils.py", line 163, in sgmaker_train
estimator.fit({'training': job_meta['input-path']}, wait)
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/sagemaker/estimator.py", line 236, in fit
self.latest_training_job = _TrainingJob.start_new(self, inputs)
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/sagemaker/estimator.py", line 578, in start_new
estimator.sagemaker_session.train(**train_args)
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/sagemaker/session.py", line 320, in train
self.sagemaker_client.create_training_job(**train_request)
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/botocore/client.py", line 320, in _api_call
return self._make_api_call(operation_name, kwargs)
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/botocore/client.py", line 624, in _make_api_call
raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (ThrottlingException) when calling the CreateTrainingJob operation (reached max retries: 4): Rate exceeded
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
File "learn_cli.py", line 28, in 
cli()
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/click/core.py", line 722, in call
return self.main(*args, **kwargs)
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/click/core.py", line 697, in main
rv = self.invoke(ctx)
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/click/core.py", line 1066, in invoke
return _process_result(sub_ctx.command.invoke(sub_ctx))
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/click/core.py", line 1066, in invoke
return _process_result(sub_ctx.command.invoke(sub_ctx))
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/click/core.py", line 895, in invoke
return ctx.invoke(self.callback, **ctx.params)
File "/home/secret/Documents/secret/env36/lib/python3.6/site-packages/click/core.py", line 535, in invoke
return callback(*args, **kwargs)
File "../run_sagemaker.py", line 60, in rolling_window_experiment
sgmk_utils.rolling_window_experiment_handler(config)
File "../sgmk_utils.py", line 398, in rolling_window_experiment_handler
job_metrics_estimator, train_jobs = rolling_window_experiment(estimator_config)
File "../sgmk_utils.py", line 382, in rolling_window_experiment
[(config, True, 30) for config in final_train_configs])
File "/usr/lib/python3.6/multiprocessing/pool.py", line 296, in starmap
return self._map_async(func, iterable, starmapstar, chunksize).get()
File "/usr/lib/python3.6/multiprocessing/pool.py", line 670, in get
raise self._value
botocore.exceptions.ClientError: An error occurred (ThrottlingException) when calling the CreateTrainingJob operation (reached max retries: 4): Rate exceeded

Exact command to reproduce:
with Pool(processes=min(5, len(final_train_configs))) as p:
results = p.starmap(wait_sgmaker_job_success_description,
[(config, True, 40) for config in final_train_configs])

	</description>
	<comments>
		<comment id='1' author='jhuangcn' date='2019-02-16T01:55:14Z'>
		Hello @JummyHuang,
Are the rate exceeded errors something you are running into very recently?
It looks like you're running at max 5 CreateTrainingJobs, which I doubt is enough to hit the limit. We don't seem to have &lt;denchmark-link:https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_sagemaker&gt;public documentation&lt;/denchmark-link&gt;
 on how many CreateTrainingJobs you can have.
I'm going to reach out to the respective SageMaker team to confirm whether or not it is actually the rate being exceeded or another issue.
Can you please provide a recent training job name? That way we can identify who you are.
If you are not comfortable with relaying that information feel free to &lt;denchmark-link:https://aws.amazon.com/contact-us/&gt;cut an AWS issue&lt;/denchmark-link&gt;
 referencing this issue.
Thanks!
		</comment>
		<comment id='2' author='jhuangcn' date='2020-02-05T11:14:37Z'>
		Why was the issue closed without a resolution explanation ?
we have the same issue - and have no idea how to solve this .
		</comment>
		<comment id='3' author='jhuangcn' date='2020-02-05T15:50:50Z'>
		&lt;denchmark-link:https://github.com/shlomiken&gt;@shlomiken&lt;/denchmark-link&gt;
 apologies for the inconvenience, but could you open a new issue? it will help with our internal tracking - thanks!
		</comment>
		<comment id='4' author='jhuangcn' date='2020-02-05T18:27:41Z'>
		we got response from AWS team about this - they said to use retry  mechanism as this is hard limit of API calls.
thanks
		</comment>
		<comment id='5' author='jhuangcn' date='2020-05-19T02:37:43Z'>
		
we got response from AWS team about this - they said to use retry mechanism as this is hard limit of API calls.
thanks

&lt;denchmark-link:https://github.com/shlomiken&gt;@shlomiken&lt;/denchmark-link&gt;
 Could you elaborate on how to use the retry mechanism? I'm facing the same issue. Thanks!
		</comment>
		<comment id='6' author='jhuangcn' date='2020-05-19T13:36:14Z'>
		&lt;denchmark-link:https://github.com/pfmeng&gt;@pfmeng&lt;/denchmark-link&gt;
 - you need to create your retry - with python its quite easy , just look for retying library .
		</comment>
	</comments>
</bug>