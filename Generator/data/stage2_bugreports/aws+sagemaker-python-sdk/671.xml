<bug id='671' author='jonsnowseven' open_date='2019-02-28T14:55:47Z' closed_time='2019-06-10T18:39:27Z'>
	<summary>Parser of framework and version from image URI does not work with TF script mode images</summary>
	<description>
&lt;denchmark-h:h3&gt;System Information&lt;/denchmark-h&gt;


Framework (e.g. TensorFlow) / Algorithm (e.g. KMeans): TensorFlow/Neural Network
Framework Version: 1.12
Python Version: 3.6
CPU or GPU: CPU
Python SDK Version: 1.16.3 (and 1.18.3 also)
Are you using a custom image: No

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;




sagemaker-python-sdk/src/sagemaker/fw_utils.py


         Line 223
      in
      2af36ad






 r'^sagemaker(?:-rl)?-(tensorflow|mxnet|chainer|pytorch|scikit-learn):(.*)-(.*?)-(py2|py3)$') 





This function does not parse container images in the form of "sagemaker-tensorflow-scriptmode".

Exact command to reproduce:

from sagemaker.fw_utils import framework_name_from_image

framework_name_from_image("520713654638.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-tensorflow-scriptmode:1.12-cpu-py3")
&lt;denchmark-code&gt;(None, None, None)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='jonsnowseven' date='2019-02-28T23:18:27Z'>
		Hi &lt;denchmark-link:https://github.com/jonsnowseven&gt;@jonsnowseven&lt;/denchmark-link&gt;

Thanks for reporting this issue. We add a fix for this to our backlog, other than calling it directly have you identified any other case within the SDK that is affected by this?
		</comment>
		<comment id='2' author='jonsnowseven' date='2019-03-01T08:17:17Z'>
		Hello &lt;denchmark-link:https://github.com/iquintero&gt;@iquintero&lt;/denchmark-link&gt;
.
Thank you for answering.
Yes, this parse causes, for instance,  TensorFlow.attach(trainingJob) to not work because when initializing the parameters, the image is parsed using that until and the object does not have the correct attributes comparing with the training job.
		</comment>
		<comment id='3' author='jonsnowseven' date='2019-03-05T23:51:43Z'>
		Adding bug label and leaving the issue open for further references.
To clarify - attach should work correctly, except it would change the logic to treat the image as 'custom' image and would cause issues for deployment (it would try to use the same script mode image instead of correct TFS image). More details in: &lt;denchmark-link:https://github.com/aws/sagemaker-python-sdk/issues/663&gt;#663&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='jonsnowseven' date='2019-03-06T09:22:08Z'>
		Hello &lt;denchmark-link:https://github.com/nadiaya&gt;@nadiaya&lt;/denchmark-link&gt;
.
Thank you for your answer.
I'll be waiting for a solution then.
Best regards,
Jo√£o Neves
		</comment>
		<comment id='5' author='jonsnowseven' date='2019-04-30T14:02:44Z'>
		Hi, I've been working with a SageMaker Hyperparameter Tuning Job and I'm running into a problem that seems to be based on this issue as well. The training jobs run without issue, but when calling the .deploy() method, I get a similar error as mentioned in &lt;denchmark-link:https://github.com/aws/sagemaker-python-sdk/issues/663&gt;#663&lt;/denchmark-link&gt;
, which links to here, showing in the Endpoint logs:
FileNotFoundError: [Errno 2] No such file or directory: 'nginx': 'nginx'.
The deployment fails with the message:
The primary container for production variant default-variant-name did not pass the ping health check.
I am also using custom entrypoint scripts, so I am wondering can I attribute this to the same error as listed here, given that the .attach() method is called inside of the .deploy() method for the HyperparameterTuner? If so, is there any estimate on when a fix could be available for this or what would be the best way to get the deployment working here? Thanks.
		</comment>
		<comment id='6' author='jonsnowseven' date='2019-05-05T18:29:43Z'>
		Hello &lt;denchmark-link:https://github.com/cbreathnach&gt;@cbreathnach&lt;/denchmark-link&gt;
.
I believe so. That error occurs because the container image string is wrongly parsed! After all, the Hyperparameter Tuning Job is a set of Training Jobs so it is only natural that you experience the same behaviour. But it is probably better if some developer from Sagemaker Python SDK team can confirm this.
		</comment>
		<comment id='7' author='jonsnowseven' date='2019-06-05T17:03:45Z'>
		Is there a workaround? I'm hitting this today as well.
		</comment>
		<comment id='8' author='jonsnowseven' date='2019-06-06T18:28:55Z'>
		apologies for the inconvenience. we do have an open item in our backlog for working on this issue.
In the meantime, there are a couple workarounds:

set the image name explicitly to 520713654638.dkr.ecr.&lt;region&gt;.amazonaws.com/sagemaker-tensorflow-serving:1.12.0-&lt;cpu|gpu&gt;, specifying your desired region and processor type (cpu or gpu)
use the TFS Model class: https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html#tensorflow-serving-model

edit: it looks like this should have been fixed in &lt;denchmark-link:https://github.com/aws/sagemaker-python-sdk/pull/692&gt;#692&lt;/denchmark-link&gt;
. To those seeing the error, are you on version 1.18.6 or higher?
		</comment>
		<comment id='9' author='jonsnowseven' date='2019-06-07T09:00:42Z'>
		Increasing the version was the solution in my case for the deployment of an endpoint from a Hyperparameter Tuning job. I had been previously using version 1.16.1, but swapping to test in an environment with version 1.18.14.post0 has fixed the problem.
In the case it's relevant for any trouble-shooting, the error was only occurring for me while using script mode for training scripts, for example: &lt;denchmark-link:https://sagemaker.readthedocs.io/en/stable/using_tf.html#preparing-a-script-mode-training-script&gt;https://sagemaker.readthedocs.io/en/stable/using_tf.html#preparing-a-script-mode-training-script&lt;/denchmark-link&gt;

The deployment in my case worked as expected when using an older approach with the older sdk version, eg: &lt;denchmark-link:https://github.com/aws/sagemaker-python-sdk/tree/v1.12.0/src/sagemaker/tensorflow#tensorflow-sagemaker-estimators-and-models&gt;https://github.com/aws/sagemaker-python-sdk/tree/v1.12.0/src/sagemaker/tensorflow#tensorflow-sagemaker-estimators-and-models&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='jonsnowseven' date='2020-03-29T09:09:03Z'>
		I'm having similar problems still with sagemaker version 1.51.4.
My training image name is 763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.14.0-gpu-py3 and when doing an attach and deploy, I get the same the error:
FileNotFoundError: [Errno 2] No such file or directory: 'nginx': 'nginx'
Is there a reason why my training image name is "tensorflow-training..." and not "sagemaker-tensorflow-training..."? The regex in the fw_utils doesn't extract the image name correctly in this instance.
		</comment>
		<comment id='11' author='jonsnowseven' date='2020-03-30T16:19:38Z'>
		&lt;denchmark-link:https://github.com/aninoy&gt;@aninoy&lt;/denchmark-link&gt;
 the training image name comes from the AWS Deep Learning Containers: &lt;denchmark-link:https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html&gt;https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html&lt;/denchmark-link&gt;

could you open a new issue and include the code you're using to fit, attach, and deploy? (opening a new issue will help with our internal tracking)
		</comment>
		<comment id='12' author='jonsnowseven' date='2020-03-31T07:22:22Z'>
		Yes, will do, thank you for your response.
		</comment>
		<comment id='13' author='jonsnowseven' date='2020-04-01T10:52:56Z'>
		Linking the related issue &lt;denchmark-link:https://github.com/aws/sagemaker-python-sdk/issues/1379&gt;here&lt;/denchmark-link&gt;
 for reference.
		</comment>
	</comments>
</bug>