<bug id='716' author='andremoeller' open_date='2019-03-21T21:15:29Z' closed_time='2019-07-24T22:47:50Z'>
	<summary>s3_input with "compression='Gzip', input_mode='Pipe'" fails with ValidationError</summary>
	<description>
Please fill out the form below.
&lt;denchmark-h:h3&gt;System Information&lt;/denchmark-h&gt;


Python Version: 3.6
Python SDK Version: 1.18

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I'm trying to fit with an Estimator on Gzipped data with Pipe mode. I don't have input_mode set on the Estimator, but I do have it set in the s3_input, which should override the Estimator's input_mode:



sagemaker-python-sdk/src/sagemaker/session.py


        Lines 1329 to 1336
      in
      c2bac8f






             input_mode (str): Optional override for this channel's input mode (default: None). By default, channels will 



                 use the input mode defined on ``sagemaker.estimator.EstimatorBase.input_mode``, but they will ignore 



                 that setting if this parameter is set. 



  



                     * None - Amazon SageMaker will use the input mode specified in the ``Estimator``. 



                     * 'File' - Amazon SageMaker copies the training dataset from the S3 location to a local directory. 



                     * 'Pipe' - Amazon SageMaker streams data directly from S3 to the container via a Unix-named pipe. 



  





My s3_input is:
training_s3_input = s3_input('s3://my_training_data', compression='Gzip', input_mode='Pipe', shuffle_config=ShuffleConfig(1))
Trying to fit on an Estimator gives me back this ValidationError, even though I specify Pipe, not File:
An error occurred (ValidationException) when calling the CreateTrainingJob operation: Invalid compression type for channel training: File mode only supports NONE, got Gzip instead
Setting input_mode='Pipe' directly on the Estimator works as expected.
	</description>
	<comments>
		<comment id='1' author='andremoeller' date='2019-04-17T00:27:23Z'>
		thanks for the bug report! it does seem like there's something smarter the code can do around this. I'll add it to our backlog.
		</comment>
		<comment id='2' author='andremoeller' date='2019-05-05T13:00:13Z'>
		Hey &lt;denchmark-link:https://github.com/laurenyu&gt;@laurenyu&lt;/denchmark-link&gt;
 ! I'd like to work on this issue
I was testing some stuff around this.
I could notice that the CreateTrainingJob API call is made with the following request
&lt;denchmark-code&gt;{
     ....
     'InputDataConfig': [
         {
             'CompressionType': 'Gzip', 
             'ChannelName': 'training', 
             'InputMode': 'Pipe', 
             'DataSource': {
                  'S3DataSource': {
                       'S3DataType': 'S3Prefix', 
                       'S3DataDistributionType': 'FullyReplicated', 
                       'S3Uri': 's3://xxxxxx/data.tar.gz'
                  }
             }, 
             'ShuffleConfig': {'Seed': 1}
         }
     ], 
     'AlgorithmSpecification': {
         'TrainingInputMode': 'File', 
         'TrainingImage': 'xxxx'         
     }, 
    .....
 }
&lt;/denchmark-code&gt;

It seems that s3_input sets the InputMode but does not address the TrainingInputMode which is set to File by default. I guess the Exception is validating the CompressionType with TrainingInputMode. Is this expected?
		</comment>
		<comment id='3' author='andremoeller' date='2019-05-30T08:25:38Z'>
		Close this?
		</comment>
	</comments>
</bug>