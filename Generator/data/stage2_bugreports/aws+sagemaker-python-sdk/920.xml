<bug id='920' author='shanedonburke' open_date='2019-07-10T19:05:12Z' closed_time='2019-07-15T15:52:13Z'>
	<summary>DataProcessing object not supported when creating a batch transform job</summary>
	<description>
Please fill out the form below.
&lt;denchmark-h:h3&gt;System Information&lt;/denchmark-h&gt;


Framework (e.g. TensorFlow) / Algorithm (e.g. KMeans): SageMaker / XGBoost
Framework Version: Unknown
Python Version: Lambda 3.6
CPU or GPU: Lambda
Python SDK Version: Lambda
Are you using a custom image: No

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

When using client.create_transform_job(...), the "DataProcessing" object that is mentioned in the documentation doesn't seem to be accepted. Even with the default values, the object is not accepted.
&lt;denchmark-h:h3&gt;Minimal repro / logs&lt;/denchmark-h&gt;

Parameter validation failed:
Unknown parameter in input: "DataProcessing", must be one of: TransformJobName, ModelName, MaxConcurrentTransforms, MaxPayloadInMB, BatchStrategy, Environment, TransformInput, TransformOutput, TransformResources, Tags: ParamValidationError
Traceback (most recent call last):
File "/var/task/lambda_function.py", line 19, in lambda_handler
sm_response = batch_transform(s3_info, job_info, resources)
File "/var/task/lambda_function.py", line 56, in batch_transform
'JoinSource': 'None'
File "/var/runtime/botocore/client.py", line 314, in _api_call
return self._make_api_call(operation_name, kwargs)
File "/var/runtime/botocore/client.py", line 586, in _make_api_call
api_params, operation_model, context=request_context)
File "/var/runtime/botocore/client.py", line 621, in _convert_to_request_dict
api_params, operation_model)
File "/var/runtime/botocore/validate.py", line 291, in serialize_to_request
raise ParamValidationError(report=report.generate_report())
botocore.exceptions.ParamValidationError: Parameter validation failed:
Unknown parameter in input: "DataProcessing", must be one of: TransformJobName, ModelName, MaxConcurrentTransforms, MaxPayloadInMB, BatchStrategy, Environment, TransformInput, TransformOutput, TransformResources, Tags

Exact command to reproduce:

    response = resources[SAGEMAKER].create_transform_job(
        TransformJobName=job_info[JOB_ID],
        ModelName=MODEL_NAME,
        MaxConcurrentTransforms=5,
        MaxPayloadInMB=5,
        BatchStrategy='MultiRecord',
        TransformInput={
            'DataSource': {
                'S3DataSource': {
                    'S3DataType': 'S3Prefix',
                    'S3Uri': s3_info[PARAMS_BASE_URI]
                }
            },
            'ContentType': 'text/csv',
            'SplitType': 'Line'
        },
        TransformOutput={
            'S3OutputPath': s3_info[DEST_URI],
            'AssembleWith': 'Line',
            'Accept': 'text/csv'
        },
        TransformResources={
            'InstanceType': 'ml.m5.large',
            'InstanceCount': 3
        },
        DataProcessing={
            'InputFilter': "$[1:]",
            'OutputFilter': "$",
            'JoinSource': 'None'
        }
    )
	</description>
	<comments>
		<comment id='1' author='shanedonburke' date='2019-07-10T21:05:26Z'>
		Hello &lt;denchmark-link:https://github.com/shanedonburke&gt;@shanedonburke&lt;/denchmark-link&gt;
,
Can you update your boto3 and botocore version and try again?
This doesn't seem to be a problem with the Python SDK, however botocore potentially.
Let me reach out to the team as well.
Thanks!
		</comment>
		<comment id='2' author='shanedonburke' date='2019-07-15T15:52:22Z'>
		That worked. Thank you!
		</comment>
	</comments>
</bug>