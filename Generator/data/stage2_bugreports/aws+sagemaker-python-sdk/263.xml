<bug id='263' author='WuyangLI' open_date='2018-06-27T20:58:12Z' closed_time='2018-06-29T21:00:35Z'>
	<summary>tensorflow:1.8-gpu-py2 image doesn't utilize GPU</summary>
	<description>
Please fill out the form below.
&lt;denchmark-h:h3&gt;System Information&lt;/denchmark-h&gt;


Framework (e.g. TensorFlow) / Algorithm (e.g. KMeans): Tensorflow
Framework Version: 1.8
Python Version: 2
CPU or GPU: GPU
Python SDK Version: 1.5.1
Are you using a custom image: no

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I started a tensorflow job, which uses tensorflow:1.8-gpu-py2 image for training. Full tag of the image is :
520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow:1.8-gpu-py2
I used ml.p2.xlarge for training, on which GPU is available.
However, as the metrics on cloud watch shows, for both of the workers, GPU utilization stays zero.
&lt;denchmark-h:h3&gt;Minimal repro / logs&lt;/denchmark-h&gt;

Metrics on cloud watch indicates that GPU is not used
&lt;denchmark-h:h3&gt;Code&lt;/denchmark-h&gt;

code for starting training job
&lt;denchmark-code&gt;import sagemaker

from sagemaker.tensorflow import TensorFlow
from sagemaker.session import s3_input
from sagemaker import get_execution_role

sagemaker_session = sagemaker.Session()
role = get_execution_role()
training_steps = 100
evaluation_steps = 10

estimator = TensorFlow(
    entry_point='keras_distributed_transfer_learning.py',
    source_dir='./',
    role=role,
    training_steps=100,
    evaluation_steps=10,
    train_instance_count=2,
    train_instance_type='ml.p2.xlarge',
    input_mode='File')

input_dataset = s3_input('s3://xxxx/cats_and_dogs/')
estimator.fit(input_dataset)
&lt;/denchmark-code&gt;

keras_distributed_transfer_learning.py
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.python.estimator.model_fn import ModeKeys as Modes

INPUT_TENSOR_NAME = "input_1"
NUM_CLASSES = 2
BATCH_SIZE = 10


def model_fn(features, labels, mode, params):
    """The model_fn argument for creating an Estimator."""
    backend = tf.keras.applications.vgg16.VGG16(weights=None, 
                                                include_top=False,
                                                input_shape=(224, 224, 3))
    x = backend.output
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)
    model = tf.keras.models.Model(inputs=backend.input, outputs=x)
    image = tf.keras.layers.Input(tensor=features[INPUT_TENSOR_NAME])
    # Define operations
    if mode in (Modes.PREDICT, Modes.EVAL):
        logits = model(image, training=False)
        predicted_indices = tf.argmax(input=logits, axis=1)
        probabilities = tf.nn.softmax(logits, name='softmax_tensor')

    if mode in (Modes.TRAIN):
        logits = model(image, training=True)
        global_step = tf.train.get_or_create_global_step()
        loss = tf.losses.softmax_cross_entropy(
            onehot_labels=labels, logits=logits)
        tf.summary.scalar('OptimizeLoss', loss)
        
    if mode in (Modes.EVAL):
        logits = model(image, training=False)
        global_step = tf.train.get_or_create_global_step()
        loss = tf.losses.softmax_cross_entropy(
            onehot_labels=labels, logits=logits)
        tf.summary.scalar('OptimizeLoss', loss)

    if mode == Modes.PREDICT:
        predictions = {
            'classes': predicted_indices,
            'probabilities': probabilities
        }
        export_outputs = {
            'predictions': tf.estimator.export.PredictOutput(predictions)
        }
        return tf.estimator.EstimatorSpec(
            mode, predictions=predictions, export_outputs=export_outputs)

    if mode == Modes.TRAIN:
        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(loss, global_step=global_step)
        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)

    if mode == Modes.EVAL:
        eval_metric_ops = {
            'accuracy': tf.metrics.accuracy(tf.argmax(labels, 1), predicted_indices)
        }
        return tf.estimator.EstimatorSpec(
            mode, loss=loss, eval_metric_ops=eval_metric_ops)


def _input_fn(training_dir, input_shape, batch_size):
    generator = tf.keras.preprocessing.image.ImageDataGenerator().flow_from_directory(training_dir, target_size=input_shape, batch_size=batch_size)

    tensor_shapes = (tf.TensorShape([None, input_shape[0], input_shape[1], 3]), tf.TensorShape([None, NUM_CLASSES]))
    tensor_types = (tf.float32, tf.float32)
    dataset = tf.data.Dataset.from_generator(lambda: generator, tensor_types, tensor_shapes)
    features, labels = dataset.make_one_shot_iterator().get_next()
    return {INPUT_TENSOR_NAME: features}, labels


def train_input_fn(training_dir, hyperparameters):
    return _input_fn(training_dir + '/train/', (224, 224), BATCH_SIZE)


def eval_input_fn(training_dir, hyperparameters):
    return _input_fn(training_dir + '/test/', (224, 224), BATCH_SIZE)


def serving_input_fn(hyperparameters):
    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [None, 224, 224, 3])}
    return tf.estimator.export.ServingInputReceiver(inputs, inputs)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='WuyangLI' date='2018-06-28T20:48:19Z'>
		Can confirm.
&lt;denchmark-code&gt;algo-1-PFZTU_1  | ---------------------------------------------------------------------------------------
algo-1-PFZTU_1  | https://www.tensorflow.org/programmers_guide/using_gpu
algo-1-PFZTU_1  | Device placement.
algo-1-PFZTU_1  | 2018-06-28 20:43:52.537325: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
algo-1-PFZTU_1  | Device mapping: no known devices.
algo-1-PFZTU_1  | 2018-06-28 20:43:52.540033: I tensorflow/core/common_runtime/direct_session.cc:284] Device mapping:
algo-1-PFZTU_1  | 
algo-1-PFZTU_1  | MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0
algo-1-PFZTU_1  | 2018-06-28 20:43:52.540460: I tensorflow/core/common_runtime/placer.cc:886] MatMul: (MatMul)/job:localhost/replica:0/task:0/device:CPU:0
algo-1-PFZTU_1  | b: (Const): /job:localhost/replica:0/task:0/device:CPU:0
algo-1-PFZTU_1  | 2018-06-28 20:43:52.540493: I tensorflow/core/common_runtime/placer.cc:886] b: (Const)/job:localhost/replica:0/task:0/device:CPU:0
algo-1-PFZTU_1  | a: (Const): /job:localhost/replica:0/task:0/device:CPU:0
algo-1-PFZTU_1  | 2018-06-28 20:43:52.540513: I tensorflow/core/common_runtime/placer.cc:886] a: (Const)/job:localhost/replica:0/task:0/device:CPU:0
algo-1-PFZTU_1  | [[22. 28.]
algo-1-PFZTU_1  |  [49. 64.]]
algo-1-PFZTU_1  | ---------------------------------------------------------------------------------------
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='WuyangLI' date='2018-06-28T20:48:41Z'>
		Investigating how did that happen and how we can fix it.
		</comment>
		<comment id='3' author='WuyangLI' date='2018-06-29T02:44:09Z'>
		Fix is in PR: &lt;denchmark-link:https://github.com/aws/sagemaker-tensorflow-training-toolkit/pull/51&gt;aws/sagemaker-tensorflow-training-toolkit#51&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='WuyangLI' date='2018-06-29T21:00:34Z'>
		The container with a fix has been deployed to all regions.
		</comment>
	</comments>
</bug>