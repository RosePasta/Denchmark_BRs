<bug id='20' author='xuf12' open_date='2018-07-31T15:23:12Z' closed_time='2018-08-21T03:04:14Z'>
	<summary>Unable to load cnn_dailymail</summary>
	<description>
I ran the following command just to train on cnn_dailymail:
nvidia-docker run -it --rm -v `pwd`:/decaNLP/ -u $(id -u):$(id -g) decanlp bash -c "python /decaNLP/train.py --train_tasks cnn_dailymail --train_iterations 1 --gpu 0"
and I got the following error message:
&lt;denchmark-code&gt;process_main - Loading cnn_dailymail
process_main - Adding cnn_dailymail to training datasets
Traceback (most recent call last):
  File "/decaNLP/train.py", line 365, in &lt;module&gt;
    main()
  File "/decaNLP/train.py", line 352, in main
    field, train_sets, val_sets = prepare_data(args, field, logger)
  File "/decaNLP/train.py", line 67, in prepare_data
    split = get_splits(args, task, FIELD, **kwargs)[0]
  File "/decaNLP/util.py", line 161, in get_splits
    fields=FIELD, root=args.data, **kwargs)
  File "/decaNLP/text/torchtext/datasets/generic.py", line 426, in splits
    os.path.join(path, 'training.jsonl'), fields, **kwargs)
  File "/decaNLP/text/torchtext/datasets/generic.py", line 353, in __init__
    examples = torch.load(cache_name)
  File "/opt/conda/lib/python3.6/site-packages/torch/serialization.py", line 267, in load
    return _load(f, map_location, pickle_module)
  File "/opt/conda/lib/python3.6/site-packages/torch/serialization.py", line 420, in _load
    result = unpickler.load()
EOFError: Ran out of input
&lt;/denchmark-code&gt;

I tried running cnn only without any issue. However, when I train for dailymail only, I ran out of RAM (I have 32GB). So the 2 questions I have are:

How much RAM do we need to load dailymail alone?
How to load the cnn_dailymail data without EOFError?

Thank you.
	</description>
	<comments>
		<comment id='1' author='xuf12' date='2018-08-09T00:11:38Z'>
		There seems to be something in torchtext that blows up the memory requirements. I'm looking into this though. Are you able to run other tasks okay?
		</comment>
		<comment id='2' author='xuf12' date='2018-08-09T00:42:42Z'>
		Yeah I tried every other task in the round-robin without any issue. I used cnn dailymail instead of cnn-dailymail in the task parameter, and the CNN part worked without any issue.
		</comment>
		<comment id='3' author='xuf12' date='2018-08-21T02:58:01Z'>
		&lt;denchmark-link:https://github.com/xuf12&gt;@xuf12&lt;/denchmark-link&gt;
 This was a problem with the memory consumption of the tokenizer we were using (revtok). It was creating too many short strings during tokenization. For now, a quick fix (&lt;denchmark-link:https://github.com/salesforce/decaNLP/commit/1f83b7a739502d2d826a0a2a95452a66dbf58273&gt;1f83b7a&lt;/denchmark-link&gt;
), but we'll get this fixed in revtok (update: &lt;denchmark-link:https://github.com/jekbradbury/revtok/commit/f1998b72a941d1e5f9578a66dc1c20b01913caab&gt;jekbradbury/revtok@f1998b7&lt;/denchmark-link&gt;
).
Let me know if this fixes your issue!
		</comment>
		<comment id='4' author='xuf12' date='2018-08-21T02:58:45Z'>
		Same problem at &lt;denchmark-link:https://github.com/salesforce/decaNLP/issues/13&gt;#13&lt;/denchmark-link&gt;
. Should be resolved now.
		</comment>
		<comment id='5' author='xuf12' date='2018-08-21T03:20:05Z'>
		Make sure to delete your cache for these datasets if you have one. For example, if you have .data/dailymail/dailyail/.cache/  and .data/dailymail/dailyail/.cache/ , you'll need to remove those directories.
		</comment>
	</comments>
</bug>