<bug id='183' author='f-kretschmer' open_date='2020-02-04T16:18:08Z' closed_time='2020-02-11T17:21:21Z'>
	<summary>TypeError in gelu when using different float precision</summary>
	<description>
Describe the Bug
When changing the float precision tensorflow uses, e.g., to float16 (can be done by setting "floatx" in ~/.keras/config or with keras.backend.set_floatx('float16')), using the get_model function results in a TypeError (truncated traceback):
File "/site-packages/keras_bert/activations/gelu_tensorflow.py", line 7, in gelu return 0.5 * x * (1.0 + erf(x / sqrt(2.0))) File "/site-packages/tensorflow_core/python/ops/math_ops.py", line 899, in binary_op_wrapper return func(x, y, name=name) File "/site-packages/tensorflow_core/python/ops/math_ops.py", line 997, in _truediv_python3 (x_dtype, y_dtype)) TypeError: x and y must have the same dtype, got tf.float16 != tf.float32
Version Info

 I'm using the latest version

Minimal Codes To Reproduce
import keras_bert

keras.backend.set_floatx('float16')
model = get_model()
This can be fixed by changing the implementation of gelu_tensorflow to
from tensorflow.python.ops.math_ops import erf, sqrt
from tensorflow.keras.backend import floatx
from tensorflow import cast

__all__ = ['gelu']


def gelu(x):
    return 0.5 * x * (1.0 + erf(x / cast(sqrt(2.0), floatx())))
I'm wondering whether there is a more elegant solution to this.
	</description>
	<comments>
		<comment id='1' author='f-kretschmer' date='2020-02-09T16:30:47Z'>
		Is this still relevant? If so, what is blocking it? Is there anything you can do to help move it forward?
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs.
		</comment>
	</comments>
</bug>