<bug id='4081' author='fanyangCS' open_date='2019-12-28T09:01:57Z' closed_time='2020-05-28T07:25:36Z'>
	<summary>storage manager crashed for unknown reason</summary>
	<description>
the storage manager restarts for unknown reason, and the restart didn't succeed due to a failed apt update install. &lt;denchmark-link:https://github.com/Microsoft/pai/blob/master/src/storage-manager/deploy/scripts/entrypoint.sh#L38&gt;https://github.com/Microsoft/pai/blob/master/src/storage-manager/deploy/scripts/entrypoint.sh#L38&lt;/denchmark-link&gt;


 we need the watchdog to watch for the storage manager and send alerts when it is unhealthy
 fix the apt install issue. we should lock the samba version and avoid apt update (include the pkg in the docker image) #4086
 after the pod restart, the original mount point cannot be used. it seems that the previous resource didn't get released. need a way to fix it.
 set the pod qos class of the storage manager to high, assign the right amount of resource (memory, CPU, etc.) to it
 persist the log to host file system #4088

	</description>
	<comments>
		<comment id='1' author='fanyangCS' date='2019-12-30T11:38:19Z'>
		For issue 2: Already fixed in PR  &lt;denchmark-link:https://github.com/microsoft/pai/pull/4086&gt;#4086&lt;/denchmark-link&gt;

For issue 3: User could try flowing commands:

umount /data and umount /home.  If executed successfully, redo the mount command, then nfs will mount into the container.
If encounter the error umount.nfs4: /home: device is busy Please run:
apt-get install lsof
lsof | grep /home
Find the process which occupy this handle, for example  bash 1114  root cwd unknown                                       /home/ kill the process. Then run umount /home again
Retry the mount command. Then the nfs will mount into the container successfully.

It doesn't umount the previous mount point, remount nfs will failed, and error message is: Reason given by server: No such file or directory.
If user can not umount the previous mount point. User still can mount the nfs but need to notice the nfs path is changed.
		</comment>
		<comment id='2' author='fanyangCS' date='2019-12-31T05:00:25Z'>
		For issue 5: Will persist samba log for future debugging: &lt;denchmark-link:https://github.com/microsoft/pai/pull/4088&gt;#4088&lt;/denchmark-link&gt;

After checking the source code, maybe  k8s  cause the pod restart. Here is a service healthy check every 10 second:


Maybe samba service down for a while and cause pod restarts. So persist samba log here.
Persist stdout/stderr will not help us debug this problem, since main process will go to infinity sleep after pods starts.



pai/src/storage-manager/deploy/scripts/entrypoint.sh


        Lines 62 to 64
      in
      1201799






 # sleep 



 echo "sleep infinity ----------" 



 sleep infinity 





		</comment>
		<comment id='3' author='fanyangCS' date='2020-05-28T07:24:49Z'>
		
  we need the watchdog to watch for the storage manager and send alerts when it is unhealthy

~(work around available, won't fix now) after the pod restart, the original mount point cannot be used. it seems that the previous resource didn't get released. need a way to fix it. ~
(work around available, won't fix now) set the pod qos class of the storage manager to high, assign the right amount of resource (memory, CPU, etc.) to it
		</comment>
	</comments>
</bug>