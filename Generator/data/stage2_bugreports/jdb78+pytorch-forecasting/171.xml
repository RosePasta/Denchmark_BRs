<bug id='171' author='ooghry' open_date='2020-11-24T12:31:13Z' closed_time='2020-11-24T16:11:45Z'>
	<summary>TypeError: 'str' object cannot be interpreted as an integer</summary>
	<description>

PyTorch-Forecasting version: 0.6.0
PyTorch version: 1.7.0+cu101
Python version: 3.6.9
Google Colab

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

I'm trying to create algorithmic trading system, In the very two months I have only 30%-40% win rate, It's not ML system. But I would like to predict possible target for any of found items with PyTorch and TFT model based on previous results.
My normalized data looks like &lt;denchmark-link:http://www.sharecsv.com/s/a08efd0677d449542fd98e2b390101a1/file.csv&gt;this&lt;/denchmark-link&gt;
 (I remove some feature column for simplicity,  column is my target).
&lt;denchmark-h:h3&gt;Actual behavior&lt;/denchmark-h&gt;

I got this and I could not find out the reason for the error.
&lt;denchmark-code&gt;TypeError                                 Traceback (most recent call last)
&lt;ipython-input-10-329c6f2b973b&gt; in &lt;module&gt;()
     16     add_target_scales=True,
     17     add_encoder_length=True,
---&gt; 18     allow_missings=True
     19 )
     20 

1 frames
/usr/local/lib/python3.6/dist-packages/pytorch_forecasting/data/timeseries.py in _construct_index(self, data, predict_mode)
    809                     f"First 10 removed groups: {list(missing_groups.iloc[:10].to_dict(orient='index').values())}",
    810                 ),
--&gt; 811                 UserWarning,
    812             )
    813         assert len(df_index) &gt; 0, "filters should not remove entries"

TypeError: 'str' object cannot be interpreted as an integer
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Code to reproduce the problem&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;!pip install pytorch-lightning
!pip install pytorch-forecasting
import warnings
from pathlib import Path
import pandas as pd
import numpy as np
import torch
import copy


import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger

from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline
from pytorch_forecasting.data import GroupNormalizer

from pytorch_forecasting.metrics import PoissonLoss, QuantileLoss, SMAPE
from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters

data = pd.read_csv("http://www.sharecsv.com/dl/a08efd0677d449542fd98e2b390101a1/file.csv")
data["directory"] = data.directory.astype('str').astype('category')
data["strategy"] = data.strategy.astype('str').astype('category')
data["order_type"] = data.order_type.astype('str').astype('category')
data["new_york"] = data.new_york.astype('str').astype('category')
data["london"] = data.london.astype('str').astype('category')
data["tokyo"] = data.tokyo.astype('str').astype('category')
data["sydney"] = data.sydney.astype('str').astype('category')
data["wellington"] = data.wellington.astype('str').astype('category')
data["singapore"] = data.singapore.astype('str').astype('category')
data["hong_kong"] = data.hong_kong.astype('str').astype('category')
data["shanghai"] = data.shanghai.astype('str').astype('category')
data["pair"] = data.pair.astype('str').astype('category')
data["currency1"] = data.currency1.astype('str').astype('category')
data["currency2"] = data.currency2.astype('str').astype('category')
data["date"] = pd.to_datetime(data.date, utc=True)

max_prediction_length = 6
max_encoder_length = 24
training_cutoff = data["time_idx"].max() - max_prediction_length

training = TimeSeriesDataSet(
    data[lambda x: x.time_idx &lt;= training_cutoff],
    time_idx="time_idx",
    target="best_target",
    group_ids=["time_idx"],
    min_encoder_length=max_encoder_length // 2, 
    max_encoder_length=max_encoder_length,
    min_prediction_length=1,
    max_prediction_length=max_prediction_length,
    time_varying_unknown_categoricals=[],
    add_relative_time_idx=True,
    add_target_scales=True,
    add_encoder_length=True,
    allow_missings=True
)
#I got stuck at this point and did not get to the point of using TFT.

validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)

batch_size = 128 
train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)
val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)
&lt;/denchmark-code&gt;

I have some questions:

Is this problem fit to TFT model?
My system scan the market periodically and returns the result, I increase time_idx for every new batch results, Is it right approach?
What is the reason for that error?

	</description>
	<comments>
		<comment id='1' author='ooghry' date='2020-11-24T16:11:35Z'>
		Just released 0.6.1. It should fix the issue.
		</comment>
	</comments>
</bug>