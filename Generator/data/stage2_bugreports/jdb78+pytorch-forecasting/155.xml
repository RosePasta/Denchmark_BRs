<bug id='155' author='dnwldnwl2' open_date='2020-11-13T20:53:46Z' closed_time='2020-11-14T18:28:57Z'>
	<summary>KeyError: 'module name can\'t contain "."'</summary>
	<description>
while following tutorial with my own dataset error occured.
baseline model was ok but TFT not working
&lt;denchmark-h:h2&gt;code&lt;/denchmark-h&gt;

pl.seed_everything(42) ##
trainer = pl.Trainer(
gpus=0,
# clipping gradients is a hyperparameter and important to prevent divergance
# of the gradient for recurrent neural networks
gradient_clip_val=0.1,
)
tft = TemporalFusionTransformer.from_dataset(
training,
# not meaningful for finding the learning rate but otherwise very important
learning_rate=0.03,
hidden_size=16,  # most important hyperparameter apart from learning rate
# number of attention heads. Set to up to 4 for large datasets
attention_head_size=1,
dropout=0.1,  # between 0.1 and 0.3 are good values
hidden_continuous_size=8,  # set to &lt;= hidden_size
output_size=7,  # 7 quantiles by default
loss=QuantileLoss(),
# reduce learning rate if no improvement in validation loss after x epochs
reduce_on_plateau_patience=4
)
print(f"Number of parameters in network: {tft.size()/1e3:.1f}k")
&lt;denchmark-h:h2&gt;error&lt;/denchmark-h&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

KeyError                                  Traceback (most recent call last)
 in 
24     loss=QuantileLoss(),
25     # reduce learning rate if no improvement in validation loss after x epochs
---&gt; 26     reduce_on_plateau_patience=4, ## patience after which learning rate is reduced by a factor of 10
27 )
28 print(f"Number of parameters in network: {tft.size()/1e3:.1f}k")
/kaggle/working/pytorch_forecasting/models/temporal_fusion_transformer/init.py in from_dataset(cls, dataset, allowed_encoder_known_variable_names, **kwargs)
341         # create class and return
342         return super().from_dataset(
--&gt; 343             dataset, allowed_encoder_known_variable_names=allowed_encoder_known_variable_names, **new_kwargs
344         )
345
/kaggle/working/pytorch_forecasting/models/base_model.py in from_dataset(cls, dataset, allowed_encoder_known_variable_names, **kwargs)
887         )
888         new_kwargs.update(kwargs)
--&gt; 889         return super().from_dataset(dataset, **new_kwargs)
890
891     def calculate_prediction_actual_by_variable(
/kaggle/working/pytorch_forecasting/models/base_model.py in from_dataset(cls, dataset, **kwargs)
534         if "output_transformer" not in kwargs:
535             kwargs["output_transformer"] = dataset.target_normalizer
--&gt; 536         net = cls(**kwargs)
537         net.dataset_parameters = dataset.get_parameters()
538         return net
/kaggle/working/pytorch_forecasting/models/temporal_fusion_transformer/init.py in init(self, hidden_size, lstm_layers, dropout, output_size, loss, attention_head_size, max_encoder_length, static_categoricals, static_reals, time_varying_categoricals_encoder, time_varying_categoricals_decoder, categorical_groups, time_varying_reals_encoder, time_varying_reals_decoder, x_reals, x_categoricals, hidden_continuous_size, hidden_continuous_sizes, embedding_sizes, embedding_paddings, embedding_labels, learning_rate, log_interval, log_val_interval, log_gradient_flow, reduce_on_plateau_patience, monotone_constaints, share_single_variable_networks, logging_metrics, **kwargs)
144             embedding_paddings=self.hparams.embedding_paddings,
145             x_categoricals=self.hparams.x_categoricals,
--&gt; 146             max_embedding_size=self.hparams.hidden_size,
147         )
148
/kaggle/working/pytorch_forecasting/models/nn/embeddings.py in init(self, embedding_sizes, categorical_groups, embedding_paddings, x_categoricals, max_embedding_size)
43         self.x_categoricals = x_categoricals
44
---&gt; 45         self.init_embeddings()
46
47     def init_embeddings(self):
/kaggle/working/pytorch_forecasting/models/nn/embeddings.py in init_embeddings(self)
66                     self.embedding_sizes[name][0],
67                     embedding_size,
---&gt; 68                     padding_idx=padding_idx,
69                 )
70
/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py in setitem(self, key, module)
285
286     def setitem(self, key: str, module: Module) -&gt; None:
--&gt; 287         self.add_module(key, module)
288
289     def delitem(self, key: str) -&gt; None:
/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in add_module(self, name, module)
345             raise KeyError("attribute '{}' already exists".format(name))
346         elif '.' in name:
--&gt; 347             raise KeyError("module name can't contain "."")
348         elif name == '':
349             raise KeyError("module name can't be empty string """)
KeyError: 'module name can't contain "."'
	</description>
	<comments>
		<comment id='1' author='dnwldnwl2' date='2020-11-13T21:24:07Z'>
		To narrow down the problem, what are your pytorch and pytorch forecasting versions? If you install the latest, does the problem persist?
		</comment>
		<comment id='2' author='dnwldnwl2' date='2020-11-14T04:06:19Z'>
		
To narrow down the problem, what are your pytorch and pytorch forecasting versions? If you install the latest, does the problem persist?

Torch 1.6.0 and pytorch_forcasting latest. Both worked well on stallion data. It persisted after updating torch 1.7.0. I think there is something wrong with the data processing.
		</comment>
		<comment id='3' author='dnwldnwl2' date='2020-11-14T08:09:36Z'>
		Could you post your dataset definition and if possible a first couple of rows of the pandas dataframe itself?
		</comment>
		<comment id='4' author='dnwldnwl2' date='2020-11-14T18:35:56Z'>
		
Could you post your dataset definition and if possible a first couple of rows of the pandas dataframe itself?

Embarrassingly, I renamed all columns and now it works... Thanks for your helping.
		</comment>
	</comments>
</bug>