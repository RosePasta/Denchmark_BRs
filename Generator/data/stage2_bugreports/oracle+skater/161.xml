<bug id='161' author='aikramer2' open_date='2017-06-01T17:46:53Z' closed_time='2017-10-10T21:14:29Z'>
	<summary>model type inference breaks if classifier probabilities are all 0/1s</summary>
	<description>
Currently we infer whether a model provides probability scores by looking at model.predict(examples). We assume that if a model only is returning 0s and 1s, then its a classifier that does not return probability scores. This is false if the model perhaps overfit the data. The short term workaround for this (hopefully rare) issue is to provide as many examples to the model as possible, with the goal of observing at least one non 0 or 1 prediction.
I think the way this should be handled is by making the classifier type be explicitly stated (probability=True/False).
	</description>
	<comments>
		<comment id='1' author='aikramer2' date='2017-10-10T21:14:29Z'>
		solved by &lt;denchmark-link:https://github.com/oracle/Skater/pull/190&gt;#190&lt;/denchmark-link&gt;
, closing
		</comment>
	</comments>
</bug>