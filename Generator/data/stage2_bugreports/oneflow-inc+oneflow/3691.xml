<bug id='3691' author='MARD1NO' open_date='2020-10-16T10:42:00Z' closed_time='2020-10-20T03:42:48Z'>
	<summary>A temporary fix about inferring batch axis</summary>
	<description>
&lt;denchmark-h:h1&gt;问题引入&lt;/denchmark-h&gt;

思考以下代码片段
&lt;denchmark-code&gt;A = flow.broadcast_like(A, like=shape_tensor, broadcast_axes=[1])
A = math.add(A, flow.transpose(A, perm=(1, 0)))
&lt;/denchmark-code&gt;

构建的图如下 ()
&lt;denchmark-link:https://user-images.githubusercontent.com/42901638/96244999-6a429380-0fd9-11eb-8997-59623951b5f6.png&gt;&lt;/denchmark-link&gt;

反向传播构建的图如下
&lt;denchmark-link:https://user-images.githubusercontent.com/42901638/96245041-775f8280-0fd9-11eb-97e7-3f5d55cb3766.png&gt;&lt;/denchmark-link&gt;

注：math.add 对应的反向是 clone，transpose的反向还是transpose，broadcast_like的反向是 reduce_sum_like
由于 A 这个 Blob分别进入了两个OP，分别是 transpose 和 math.add，因此反向传播回来，两者的梯度是要被相加的,也就是反向图的add_n 这个OP
&lt;denchmark-h:h1&gt;问题发生&lt;/denchmark-h&gt;

问题出在反向的transpose, 因为做了transpose，此时grad3的 batch_axis 变为 1. 而左边grad1的 batch_axis 为0 。进而导致 batchaxis 不一致报错。
&lt;denchmark-h:h1&gt;问题分析&lt;/denchmark-h&gt;

类似的过程为什么前向能正确，而问题出现在后向？
&lt;denchmark-h:h2&gt;前向forward&lt;/denchmark-h&gt;

因为经过了 flow.broadcast_like，A的batchaxis是 None，而后面经过transpose操作，batch_axis 也是 None。当调用math.add的时候，因满足
&lt;denchmark-code&gt;elif x.shape == y.shape and x.batch_axis == y.batch_axis:
        return element_wise_add(x, y, name)
&lt;/denchmark-code&gt;

调用elementwise_add，该算子的batch_axis推导采用的是 NaiveInferBatchAxis
&lt;denchmark-code&gt;if (cur_in_batch_axis-&gt;has_value() == false) { 
      continue; 
    }
&lt;/denchmark-code&gt;

它会跳过，因此前向过程正确
&lt;denchmark-h:h2&gt;后向backward&lt;/denchmark-h&gt;

由于后向传播时候，后向transpose_grad 的来源是 grad2，它有确定的batch_axis，因此transpose后，batch_axis 仍是确定的，进而导致错误发生
&lt;denchmark-h:h1&gt;问题原因&lt;/denchmark-h&gt;

鬼畜的batch_axis概念，让前后向的推导变的不确定
	</description>
	<comments>
	</comments>
</bug>