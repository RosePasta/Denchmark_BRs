<bug id='1520' author='many-hats' open_date='2020-12-04T17:40:22Z' closed_time='2020-12-04T18:21:10Z'>
	<summary>Broken tokenizer ref in AbstractRNNTDecoding in rnnt_wer.py</summary>
	<description>
Describe the bug
On &lt;denchmark-link:https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/asr/metrics/rnnt_wer.py#L209&gt;line 209 of rnnt_wer.py&lt;/denchmark-link&gt;
 there is a reference to  which errors out because there is no tokenizer. This blocks the example script in speech_to_text_rnnt.py below at the validation/sanity check stage. Possibly an artifact of refactoring for BPE? What is the intended NeMo way of incorporating the tokenizer?
I changed self.tokenizer to an explicitly defined CharTokenizer and it fixed the error.
Steps/Code to reproduce bug
&lt;denchmark-code&gt;        python examples/asr/speech_to_text_rnnt.py \
        model.train_ds.manifest_filepath="&lt;path to train dataset&gt;" \
        model.validation_ds.manifest_filepath="&lt;path to validation dataset&gt;" \
        trainer.gpus=0 \
        trainer.max_epochs=50
&lt;/denchmark-code&gt;

Expected behavior
Sanity check run of RNN-T.
	</description>
	<comments>
		<comment id='1' author='many-hats' date='2020-12-04T17:42:55Z'>
		Yup that's a bug during the refactor, I'll send a patch in sometime.
		</comment>
		<comment id='2' author='many-hats' date='2020-12-04T18:15:31Z'>
		Added a PR &lt;denchmark-link:https://github.com/NVIDIA/NeMo/pull/1521&gt;#1521&lt;/denchmark-link&gt;
, it might take some time to get merged so you could update the code locally in the mean time (its a one liner at the end of the PR).
Btw, just a heads up. The configs for RNNT are just template references for Librispeech - they were not trained nor validated on Librispeech. AN4 has a different token set compared to librispeech (no special characters, no numbers etc) so the model.labels would need to be updated for AN4.
		</comment>
		<comment id='3' author='many-hats' date='2020-12-04T18:21:10Z'>
		Great! Thanks for the heads up.
		</comment>
	</comments>
</bug>