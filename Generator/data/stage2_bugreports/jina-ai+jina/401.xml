<bug id='401' author='xiongma' open_date='2020-05-09T15:32:21Z' closed_time='2020-05-10T05:49:17Z'>
	<summary>nlp transformer cls token embedding just support two model names in transformers hub</summary>
	<description>
Describe the bug
this code in  BaseTransformerEncoder:
&lt;denchmark-code&gt;if self.pooling_strategy == 'cls':
    if self.model_name in ('bert-base-uncased', 'roberta-base'):
        output = self.tensor2array(extra_output[0])
    else:
        output = reduce_cls(_seq_output, _mask_ids_batch, self.cls_pos)
&lt;/denchmark-code&gt;

the cls embedding just support 2 models, if I implement a model inherit from BaseTransformerEncoder and set hfl/chinese-roberta-wwm-ext as the model, use cls token embedding as output embedding. it will use this code as output embedding.
&lt;denchmark-code&gt;output = reduce_cls(_seq_output, _mask_ids_batch, self.cls_pos)
&lt;/denchmark-code&gt;

but, in parctice, hfl/chinese-roberta-wwm-ext with roberta-base are same model.
Describe how you solve it
change this code
&lt;denchmark-code&gt;if self.model_name in ('bert-base-uncased', 'roberta-base'):
&lt;/denchmark-code&gt;

to this code
&lt;denchmark-code&gt;if getattr(self.tokenizer, 'cls_token', None) is not None:
&lt;/denchmark-code&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Environment
Screenshots
	</description>
	<comments>
	</comments>
</bug>