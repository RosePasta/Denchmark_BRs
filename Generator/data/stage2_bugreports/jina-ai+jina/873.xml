<bug id='873' author='JoanFM' open_date='2020-08-25T15:56:58Z' closed_time='2020-09-07T08:55:22Z'>
	<summary>Problem when pickling indexer</summary>
	<description>

Related to &lt;denchmark-link:https://github.com/jina-ai/jina/issues/867&gt;#867&lt;/denchmark-link&gt;

When indexing data twice, the indexer does not properly close the index files
Steps to reproduce
Please run this using 
&lt;denchmark-link:https://github.com/jina-ai/jina/files/5124878/867.tar.gz&gt;867.tar.gz&lt;/denchmark-link&gt;

Download and untar the file here,
Run twice python app.py -t index
and then when you do
python app.py -t query
An error occurs because index vectors where not properly flushed and closed
â”†Issue is synchronized with this &lt;denchmark-link:https://jinaai.atlassian.net/browse/JINACORE-194&gt;Jira Task&lt;/denchmark-link&gt;
 by &lt;denchmark-link:https://www.unito.io/learn-more&gt;Unito&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='JoanFM' date='2020-08-25T17:48:15Z'>
		At the second saving time, the indexer does not manage to pickle itself:
Here I print the differences of attributes I see the first time I index compared to the second. The only difference in content is that the first time there is init_from_yaml  and the second int2ext_key.
&lt;denchmark-code&gt;pickle NumpyIndexer to file ./data/doc_indexer-0/vecidx.bin with ['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_attached_pea', '_check_on_gpu', '_drivers', '_dump_instance_to_yaml', '_fill_metas', '_fill_requests', '_get_dump_path_from_config', '_get_instance_from_yaml', '_init_kwargs_dict', '_last_snapshot_ts', '_load_gzip', '_post_init_vars', '_post_init_wrapper', '_query_handler', '_raw_ndarray', '_ref_index_abspath', '_registered_class', '_size', '_snapshot_files', '_validate_key_vector_shapes', '_write_handler', 'add', 'attach', 'backend', 'batch_size', 'build_advanced_index', 'close', 'compress_level', 'config_abspath', 'current_workspace', 'dtype', 'flush', 'from_yaml', 'get_add_handler', 'get_create_handler', 'get_file_from_workspace', 'get_query_handler', 'index_abspath', 'index_filename', 'init_from_yaml', 'is_trained', 'is_updated', 'key_bytes', 'key_dtype', 'load', 'load_config', 'logger', 'max_snapshot', 'metric', 'name', 'num_dim', 'on_gpu', 'post_init', 'pre_init', 'py_modules', 'query', 'query_handler', 'raw_ndarray', 'replica_id', 'replica_workspace', 'save', 'save_abspath', 'save_config', 'separated_workspace', 'size', 'store_args_kwargs', 'to_yaml', 'touch', 'train', 'warn_unnamed', 'workspace', 'write_handler']
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;pickle NumpyIndexer to file ./data/doc_indexer-0/vecidx.bin with ['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_attached_pea', '_check_on_gpu', '_drivers', '_dump_instance_to_yaml', '_fill_metas', '_fill_requests', '_get_dump_path_from_config', '_get_instance_from_yaml', '_init_kwargs_dict', '_last_snapshot_ts', '_load_gzip', '_post_init_vars', '_post_init_wrapper', '_query_handler', '_raw_ndarray', '_ref_index_abspath', '_registered_class', '_size', '_snapshot_files', '_validate_key_vector_shapes', '_write_handler', 'add', 'attach', 'backend', 'batch_size', 'build_advanced_index', 'close', 'compress_level', 'config_abspath', 'current_workspace', 'dtype', 'flush', 'from_yaml', 'get_add_handler', 'get_create_handler', 'get_file_from_workspace', 'get_query_handler', 'index_abspath', 'index_filename', 'int2ext_key', 'is_trained', 'is_updated', 'key_bytes', 'key_dtype', 'load', 'load_config', 'logger', 'max_snapshot', 'metric', 'name', 'num_dim', 'on_gpu', 'post_init', 'pre_init', 'py_modules', 'query', 'query_handler', 'raw_ndarray', 'replica_id', 'replica_workspace', 'save', 'save_abspath', 'save_config', 'separated_workspace', 'size', 'store_args_kwargs', 'to_yaml', 'touch', 'train', 'warn_unnamed', 'workspace', 'write_handler']
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='JoanFM' date='2020-08-26T07:26:13Z'>
		It seems to be a pickling problem, I do not know  why but sometimes it fails silently. There must be some fields that we need to ignore.
		</comment>
		<comment id='3' author='JoanFM' date='2020-08-26T08:40:26Z'>
		I have the suspicion that the issue is not anymore in jina because _raw_ndarray_ was removed as attribute
		</comment>
		<comment id='4' author='JoanFM' date='2020-08-26T11:55:34Z'>
		I have been investigating this issue &lt;denchmark-link:https://github.com/jina-ai/jina/issues/867&gt;#867&lt;/denchmark-link&gt;
.
It is quite an interesting one, it seems that at some point, when we pickle our indexer, it just fails without raising an error , and this silent failing forces the skip of the flushing of the indexer data and the proper closing of the file handlers.
For what the user claims, I think that the problem is that we are serializing key_bytes and potentially (if reindexing or querying int2ext_key and ext2int_key).
key_bytes can become large and I suspect pickle is not handling it correctly. If I am right, we need to rethink the query_by_id functionality that was recently added to handle some subgroup searching. Actually these key_bytes are just used by query_by_id
Do you think this can be a problem?
Right now key_bytes is only used to fill int2ext_key which is only used for sanity check before querying , and int2ext_key is then used to fill ext2int_key  which can be used by query_by_id. And this query_by_id is an extra functionality added recently.
Maybe we can remove these attributes for the moment, or think about putting this keys in an another file, so maybe pickle won't have an issue with?
		</comment>
		<comment id='5' author='JoanFM' date='2020-08-26T15:14:32Z'>
		If you try to reproduce this issue using jina current master version, in the app.py of the example provided (the .tar), remember to cast the batch_size coming from enviroment variable to an integer.
		</comment>
		<comment id='6' author='JoanFM' date='2020-08-26T18:20:00Z'>
		I'm digging into this tmr
		</comment>
		<comment id='7' author='JoanFM' date='2020-09-02T16:05:03Z'>
		Some updates:


I realized that what I could replicate did not happen on master, but it did in 0.4.1. So I started from 0.4.1 and increased the version tag of jina until I could not reproduce the issue with my toy example. I found that in version 0.4.3 this does not fail.


So what is in v0.4.3 with respect to 0.4.2? It includes the logic of deleting in get_state_ the cached  properties. And after observation it seems that the problematic attribute that was being pickled and shouldn't was _raw_ndarray. I confirmed this by doing a small hack removing CACHED_raw_ndarray from the attributes to delete from the pickle dictionary. (When this key is not removed, the toy example fails as in v0.4.2)


I think this enforces the theory that some expensive attribute was having problems being pickled. But it still does not clarify why pickle does not complain about it or if process is simply shut down too early (which should be looked into).


This update explains that pickle fails to dump on time large attributes, but it did not explain why the user was experiencing the issue since he was not reindexing (when u index for the first time _raw_ndarray is None).
So going back to v0.4.1:


Therefore, I started to think of the only indexer attribute that can grow at simple indexing time. And I concluded that key_bytes is the only candidate.


To prove that this can pose problem at certain size I added these lines to the get_state code:


&lt;denchmark-code&gt;import numpy as np
if 'key_bytes' in d.keys():
    fake_array = np.random.random([300000, 1])
     d['key_bytes'] = b''
     for vec in fake_array:
         d['key_bytes'] += vec.tobytes()
&lt;/denchmark-code&gt;

This code simulates the problem stated by the user (he tries to index 30M documents in 10 shards (so that every key_bytes could grow to index 300k keys). When adding these lines, the pickle fails to dump and the files are not properly closed.
		</comment>
		<comment id='8' author='JoanFM' date='2020-09-03T13:11:29Z'>
		The reason of the issue is not about pickle but about Flow closing the Pods before they are properly closed. It would correlate with the size of the Pickle object because pickling large files may take long enough for the issue to arise
Prove:
Just adapting the closure in finally of a Pea in pea.py by adding some sleep time makes the closing fail:
        finally:
            time.sleep(5)
            self.loop_teardown()
            self.unset_ready()
            self.is_shutdown.set()
		</comment>
		<comment id='9' author='JoanFM' date='2020-09-03T18:18:36Z'>
		this is interesting will try to reserve some time tomorrow for that
		</comment>
	</comments>
</bug>