<bug id='818' author='kekeblom' open_date='2018-07-26T07:26:54Z' closed_time='2020-10-07T10:07:36Z'>
	<summary>Shape issues with multioutput kernels</summary>
	<description>
I have some questions regarding the independent_interdomain_conditional function in the multioutput module.
I'm dealing with a case where I have a multiple output kernel and several independent GPs with separate inducing points. In this case the variables will have the following shapes:
Kmn: M x L x N x P
Kmm: L x M x M
Knn: N x P (or P x N x N for full_cov case)
f: M x L
q_sqrt: L x M x M
If full_cov = False and full_ouput_cov = False and white = False, Ar will have shape (L, M, N, P) as explicitly reshaped on line 311. Now on line 327 (link below) the code will crash as Lm will have rank 3 and Ar rank 4. The comment seems to be wrong as well.



GPflow/gpflow/multioutput/conditionals.py


         Line 327
      in
      54a276a






 A = tf.matrix_triangular_solve(Lm, Ar)  # L x M x M  *  L x M x NP  -&gt;  L x M x NP 





The problem might be fixed by replacing Ar with A on that line. However, then the output will have shape (N * L, P). Shouldn't the mean and variance have shape (N, L * P) in this case?
Am I thinking about this the wrong way?
	</description>
	<comments>
		<comment id='1' author='kekeblom' date='2018-07-29T21:51:20Z'>
		&lt;denchmark-link:https://github.com/kekeblom&gt;@kekeblom&lt;/denchmark-link&gt;
, could you post MWE?
		</comment>
		<comment id='2' author='kekeblom' date='2018-07-30T13:17:08Z'>
		&lt;denchmark-code&gt;import gpflow
import tensorflow as tf
import numpy as np
import observations
from gpflow.multioutput.conditionals import independent_interdomain_conditional

(Xtrain, Ytrain), _ = observations.mnist('/tmp/mnist')
Xtrain -= Xtrain.mean(axis=0)

Zs = [np.random.randn(32, 392) for _ in range(2)]
rbf = gpflow.kernels.RBF(392)

def compute_Kmn(Z, X):
    X1 = X[:, 0:392]
    X2 = X[:, 392:]
    return tf.stack([
        rbf.K(Z, X1),
        rbf.K(Z, X2)
    ])

def compute_Knn(X):
    X1 = X[:, 0:392]
    X2 = X[:, 392:]
    return tf.stack([
        rbf.Kdiag(X1),
        rbf.Kdiag(X2)
    ])

batch = Xtrain[0:10]
# L = 2, P = 2, N = 10, M = 32
Kmm = tf.stack([rbf.K(Z) for Z in Zs]) # L x M x M
Kmn = tf.stack([compute_Kmn(Z, batch) for Z in Zs]) # L x P x M x N
Kmn = tf.transpose(Kmn, [2, 0, 3, 1]) # -&gt; M x L x N x P
Knn = tf.transpose(compute_Knn(batch)) # N x P
q_mu = np.zeros((32, 2))
q_sqrt = np.stack([np.eye(32) for _ in range(2)])

mean, var = independent_interdomain_conditional(Kmn, Kmm, Knn, q_mu, q_sqrt=q_sqrt, full_cov=False, full_output_cov=False)
&lt;/denchmark-code&gt;

So in this case we have two independent gps with separate inducing points. Two kernels which use different subsets of the input.
This will crash with "InvalidArgumentError: Shapes must be equal rank".
&lt;denchmark-link:https://github.com/awav&gt;@awav&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='kekeblom' date='2018-08-09T00:01:13Z'>
		&lt;denchmark-link:https://github.com/awav&gt;@awav&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/kekeblom&gt;@kekeblom&lt;/denchmark-link&gt;
 This is a repeat (or very similar to) of &lt;denchmark-link:https://github.com/GPflow/GPflow/issues/819&gt;#819&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='kekeblom' date='2020-10-02T15:40:21Z'>
		&lt;denchmark-link:https://github.com/kekeblom&gt;@kekeblom&lt;/denchmark-link&gt;
 thanks for bringing this to our attention, and apologies for the long delay - it turned out to be a bug in our code indeed! I had to slightly edit your example to make it "work" (fail for the right reason), and fixed it in &lt;denchmark-link:https://github.com/GPflow/GPflow/pull/1583&gt;#1583&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='5' author='kekeblom' date='2020-10-07T10:08:28Z'>
		&lt;denchmark-link:https://github.com/kekeblom&gt;@kekeblom&lt;/denchmark-link&gt;
 thanks again for the bug report, late but better late than never, it's finally fixed!
		</comment>
		<comment id='6' author='kekeblom' date='2020-10-09T12:45:36Z'>
		Kudos on having a watertight process! Most other projects would have probably dropped the ball at some point during those couple years.
		</comment>
	</comments>
</bug>