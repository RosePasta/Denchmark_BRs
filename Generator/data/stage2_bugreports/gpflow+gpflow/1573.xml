<bug id='1573' author='pg2455' open_date='2020-09-23T02:03:45Z' closed_time='2020-09-23T08:57:26Z'>
	<summary>GPMC optimization throws error about missing argument in tf.log_prob</summary>
	<description>
&lt;denchmark-h:h1&gt;Bug / performance issue / build issue&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

Minimal, reproducible example
import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow_probability import distributions as tfd

gpflow.config.set_default_float(np.float64)
gpflow.config.set_default_jitter(1e-4)
gpflow.config.set_default_summary_fmt("notebook")
# convert to float64 for tfp to play nicely with gpflow in 64
f64 = gpflow.utilities.to_default_float

tf.random.set_seed(123)
X = np.random.normal(0.5, 5, size=10).reshape(-1, 1)
Y = 0.5 * np.random.normal(X, 1.0) + np.random.normal(.5,5)

l = gpflow.likelihoods.StudentT
model = gpflow.models.GPMC(data=(X, Y), kernel=k, likelihood=l)
optimizer = gpflow.optimizers.Scipy()
optimizer.minimize(model.training_loss, model.trainable_variables)
Stack trace, or error message
&lt;denchmark-code&gt;---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-135-d619e5e4a9bd&gt; in &lt;module&gt;
      2 model = gpflow.models.GPMC(data=(X, Y), kernel=k, likelihood=l)
      3 optimizer = gpflow.optimizers.Scipy()
----&gt; 4 optimizer.minimize(model.training_loss, model.trainable_variables)

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/gpflow/optimizers/scipy.py in minimize(self, closure, variables, method, step_callback, compile, **scipy_kwargs)
     86             scipy_kwargs.update(dict(callback=callback))
     87 
---&gt; 88         return scipy.optimize.minimize(
     89             func, initial_params, jac=True, method=method, **scipy_kwargs
     90         )

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/optimize/_minimize.py in minimize(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)
    607                                   **options)
    608     elif meth == 'l-bfgs-b':
--&gt; 609         return _minimize_lbfgsb(fun, x0, args, jac, bounds,
    610                                 callback=callback, **options)
    611     elif meth == 'tnc':

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py in _minimize_lbfgsb(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)
    343             # until the completion of the current minimization iteration.
    344             # Overwrite f and g:
--&gt; 345             f, g = func_and_grad(x)
    346         elif task_str.startswith(b'NEW_X'):
    347             # new iteration

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py in func_and_grad(x)
    293     else:
    294         def func_and_grad(x):
--&gt; 295             f = fun(x, *args)
    296             g = jac(x, *args)
    297             return f, g

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/optimize/optimize.py in function_wrapper(*wrapper_args)
    325     def function_wrapper(*wrapper_args):
    326         ncalls[0] += 1
--&gt; 327         return function(*(wrapper_args + args))
    328 
    329     return ncalls, function_wrapper

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/scipy/optimize/optimize.py in __call__(self, x, *args)
     63     def __call__(self, x, *args):
     64         self.x = numpy.asarray(x).copy()
---&gt; 65         fg = self.fun(x, *args)
     66         self.jac = fg[1]
     67         return fg[0]

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/gpflow/optimizers/scipy.py in _eval(x)
    109 
    110         def _eval(x: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
--&gt; 111             loss, grad = _tf_eval(tf.convert_to_tensor(x))
    112             return loss.numpy().astype(np.float64), grad.numpy().astype(np.float64)
    113 

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = "nonXla"
--&gt; 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    821       # This is the first call of __call__, so we have to initialize.
    822       initializers = []
--&gt; 823       self._initialize(args, kwds, add_initializers_to=initializers)
    824     finally:
    825       # At this point we know that the initialization is complete (or less

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    694     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    695     self._concrete_stateful_fn = (
--&gt; 696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    697             *args, **kwds))
    698 

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2853       args, kwargs = None, None
   2854     with self._lock:
-&gt; 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2856     return graph_function
   2857 

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3211 
   3212       self._function_cache.missed.add(call_context_key)
-&gt; 3213       graph_function = self._create_graph_function(args, kwargs)
   3214       self._function_cache.primary[cache_key] = graph_function
   3215       return graph_function, args, kwargs

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3063     arg_names = base_arg_names + missing_arg_names
   3064     graph_function = ConcreteFunction(
-&gt; 3065         func_graph_module.func_graph_from_py_func(
   3066             self._name,
   3067             self._python_function,

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--&gt; 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    599         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    601     weak_wrapped_fn = weakref.ref(wrapped_fn)
    602 

~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    971           except Exception as e:  # pylint:disable=broad-except
    972             if hasattr(e, "ag_error_metadata"):
--&gt; 973               raise e.ag_error_metadata.to_exception(e)
    974             else:
    975               raise

TypeError: in user code:

    /Users/mac/opt/miniconda3/envs/py3/lib/python3.8/site-packages/gpflow/optimizers/scipy.py:104 _tf_eval  *
        loss, grads = _compute_loss_and_gradients(closure, variables)
    /Users/mac/opt/miniconda3/envs/py3/lib/python3.8/site-packages/gpflow/optimizers/scipy.py:165 _compute_loss_and_gradients  *
        loss = loss_closure()
    /Users/mac/opt/miniconda3/envs/py3/lib/python3.8/site-packages/gpflow/models/training_mixins.py:64 training_loss  *
        return self._training_loss()
    /Users/mac/opt/miniconda3/envs/py3/lib/python3.8/site-packages/gpflow/models/gpmc.py:72 _training_loss  *
        return -self.log_posterior_density()
    /Users/mac/opt/miniconda3/envs/py3/lib/python3.8/site-packages/gpflow/models/gpmc.py:69 log_posterior_density  *
        return self.log_likelihood() + self.log_prior_density()
    /Users/mac/opt/miniconda3/envs/py3/lib/python3.8/site-packages/gpflow/models/gpmc.py:92 log_likelihood  *
        return tf.reduce_sum(self.likelihood.log_prob(F, Y_data))

    TypeError: tf__log_prob() missing 1 required positional argument: 'Y'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

It seems like this is a bug. I might be wrong. It's my first time using GP library of any kind. GPR optimization works, but GPMC throws this error which is on the side of tensorflow.
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;


GPflow version: 2.1.1 
GPflow installed from: pip 
TensorFlow version: 2.3.0 
Python version 3.8  
Operating system Mac

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='pg2455' date='2020-09-23T08:57:25Z'>
		Hi &lt;denchmark-link:https://github.com/pg2455&gt;@pg2455&lt;/denchmark-link&gt;
, you erroneously assigned to  the : . Instead, you need to  an object: if you change it to , it all works. (NB- to make it a fully reproducible example, you also need to include  and construct a kernel; e.g. .)
		</comment>
		<comment id='2' author='pg2455' date='2020-09-23T14:15:26Z'>
		Great, Thanks! I will keep in mind about imports the next time.
		</comment>
	</comments>
</bug>