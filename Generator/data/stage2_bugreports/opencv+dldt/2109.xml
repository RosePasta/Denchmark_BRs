<bug id='2109' author='alrzmshy' open_date='2020-09-07T12:50:37Z' closed_time='2020-11-03T17:12:52Z'>
	<summary>VPU optimization and MYRIAD inference results</summary>
	<description>
Hi,
I have two question on inference using MYRIAD. It is explained &lt;denchmark-link:https://www.intel.com/content/www/us/en/support/articles/000056285/boards-and-kits/neural-compute-sticks.html&gt;here&lt;/denchmark-link&gt;
 that   should be set off for getting the right results.
What is the purpose of having VPU_HW_STAGES_OPTIMIZATION if setting it to 'YES' leads to poor performance?
Also, I have seen these lines in the code:
Disable HW pooling
std::map&lt;std::string, std::string&gt; networkConfig;
networkConfig["VPU_HW_STAGES_OPTIMIZATION"] = "NO";
What does HW pooling do?
	</description>
	<comments>
		<comment id='1' author='alrzmshy' date='2020-09-08T13:07:59Z'>
		&lt;denchmark-link:https://github.com/alrzmshy&gt;@alrzmshy&lt;/denchmark-link&gt;

This is being considered as a bug and we might expect this to be fixed soon later.
The option VPU_HW_STAGES_OPTIMIZATION exists for debug purposes. When you turn it off, all the hardware acceleration gets disabled for the model. It might affect various characteristics like accuracy, memory requirements, and performance.
As for the HW pooling, where did you get these lines from?
		</comment>
		<comment id='2' author='alrzmshy' date='2020-09-08T13:13:55Z'>
		Thank you for your response.
When I tried to look for a documentation on VPU_HW_STAGES_OPTIMIZATION, I found those lines &lt;denchmark-link:https://github.com/openvinotoolkit/openvino/blob/7566e8202fa6c00f27de27889e7bf99d7ddf2636/inference-engine/tests_deprecated/functional/vpu/common/layers/myriad_layers_rfcn_test.cpp#L691&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='alrzmshy' date='2020-09-09T12:06:50Z'>
		&lt;denchmark-link:https://github.com/alrzmshy&gt;@alrzmshy&lt;/denchmark-link&gt;

Looking at the code it should simply disable VPU hardware acceleration as a network configuration.
		</comment>
		<comment id='4' author='alrzmshy' date='2020-09-10T12:01:26Z'>
		OK. Thank you. The name is a bit confusing though. Especially when we are in the context of deep learning pooling layers and the usual notation for height and width (HW).
		</comment>
		<comment id='5' author='alrzmshy' date='2020-09-14T17:33:03Z'>
		Seemingly a duplicate of &lt;denchmark-link:https://github.com/openvinotoolkit/openvino/issues/1822&gt;#1822&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='alrzmshy' date='2020-10-13T23:25:15Z'>
		&lt;denchmark-link:https://github.com/maxlytkin&gt;@maxlytkin&lt;/denchmark-link&gt;
 Do you have any timeframe for a bugfix?
		</comment>
		<comment id='7' author='alrzmshy' date='2020-10-15T12:36:17Z'>
		&lt;denchmark-link:https://github.com/mhkabir&gt;@mhkabir&lt;/denchmark-link&gt;

The result is inaccurate when HW optimization is enabled because there might be a half precision overflow on MatMul layer. We were informed that we can't make any workaround or fixes because of data sensitivity and possible impacts on other models.
We would recommend to regenerate IR using MO with --scale parameter (scale 4, 8, 16, etc.). In this case, data values and weights will be analyzed by the myriad plugin correctly and there will be no overflow.
And then you would be able to accurately infer your model with enabled VPU_HW_STAGES_OPTIMIZATION.
		</comment>
		<comment id='8' author='alrzmshy' date='2020-10-27T13:47:35Z'>
		Hi &lt;denchmark-link:https://github.com/alrzmshy&gt;@alrzmshy&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/mhkabir&gt;@mhkabir&lt;/denchmark-link&gt;

Where you able to test your model by converting to IR using the model optimizer with --scale parameter? Please let me know the results.
Regards,
Jesus
		</comment>
		<comment id='9' author='alrzmshy' date='2020-11-03T17:12:52Z'>
		Closing, please re-open if additional assistance is needed.
		</comment>
	</comments>
</bug>