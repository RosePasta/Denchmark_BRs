<bug id='1441' author='bani-intelaipg' open_date='2020-07-22T19:30:42Z' closed_time='2021-01-05T16:49:18Z'>
	<summary>ReduceSum error on some reduction axes</summary>
	<description>
In 2020.4 branch (commit# &lt;denchmark-link:https://github.com/openvinotoolkit/openvino/commit/a9c6e7269fdc92ca327166bdd5d255a012d71006&gt;a9c6e72&lt;/denchmark-link&gt;
), while invoking ReduceSum with tensor-shape=[2,4,3], axis=1, keep_dims=0, I see a mismatch between result from InferenceEngine (IE) compared to TensorFlow.
Try with input tensor = {1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6} &amp; make it of shape (2,4,3).
TF results (correct): [10, 14, 18]
CNN/IE result (incorrect): [8, 16, 16]
The IE is invoked with ngraph-function: unit_test_Sum.json
&lt;denchmark-link:https://github.com/openvinotoolkit/openvino/files/4962097/opv_reducesum_files.tar.gz&gt;opv_reducesum_files.tar.gz&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='bani-intelaipg' date='2020-07-23T02:27:29Z'>
		I tried with few more axes combinations. It appears the issue happens only for the last-minus-1 axis. For example, in a {2,1,2,3} rank-4 shape, issue happens only for axis 2 (0 based index)
		</comment>
		<comment id='2' author='bani-intelaipg' date='2020-07-23T07:37:16Z'>
		Not sure about the failure pattern.. here are more cases...
Status * FAIL -&gt; tensor-shape=[2,3], axis=0, keep_dims=1
Status * FAIL -&gt; tensor-shape=[2,3], axis=0, keep_dims=0
Status   PASS -&gt; tensor-shape=[2,3], axis=1, keep_dims=1
Status   PASS -&gt; tensor-shape=[2,3], axis=1, keep_dims=0
Status   PASS -&gt; tensor-shape=[2,2,3], axis=0, keep_dims=1
Status   PASS -&gt; tensor-shape=[2,2,3], axis=0, keep_dims=0
Status * FAIL -&gt; tensor-shape=[2,2,3], axis=1, keep_dims=1
Status * FAIL -&gt; tensor-shape=[2,2,3], axis=1, keep_dims=0
Status   PASS -&gt; tensor-shape=[2,2,3], axis=2, keep_dims=1
Status   PASS -&gt; tensor-shape=[2,2,3], axis=2, keep_dims=0
Status   PASS -&gt; tensor-shape=[6,2], axis=0, keep_dims=1
Status   PASS -&gt; tensor-shape=[6,2], axis=0, keep_dims=0
Status * FAIL -&gt; tensor-shape=[6,2], axis=1, keep_dims=1
Status * FAIL -&gt; tensor-shape=[6,2], axis=1, keep_dims=0
Status   PASS -&gt; tensor-shape=[2,4,3], axis=0, keep_dims=1
Status   PASS -&gt; tensor-shape=[2,4,3], axis=0, keep_dims=0
Status * FAIL -&gt; tensor-shape=[2,4,3], axis=1, keep_dims=1
Status * FAIL -&gt; tensor-shape=[2,4,3], axis=1, keep_dims=0
Status   PASS -&gt; tensor-shape=[2,4,3], axis=2, keep_dims=1
Status   PASS -&gt; tensor-shape=[2,4,3], axis=2, keep_dims=0
Status   PASS -&gt; tensor-shape=[4,3,2,1], axis=0, keep_dims=1
Status   PASS -&gt; tensor-shape=[4,3,2,1], axis=0, keep_dims=0
Status   PASS -&gt; tensor-shape=[4,3,2,1], axis=1, keep_dims=1
Status   PASS -&gt; tensor-shape=[4,3,2,1], axis=1, keep_dims=0
Status * FAIL -&gt; tensor-shape=[4,3,2,1], axis=2, keep_dims=1
Status * FAIL -&gt; tensor-shape=[4,3,2,1], axis=2, keep_dims=0
Status   PASS -&gt; tensor-shape=[4,3,2,1], axis=3, keep_dims=1
Status   PASS -&gt; tensor-shape=[4,3,2,1], axis=3, keep_dims=0
Status   PASS -&gt; tensor-shape=[1,2,3,4], axis=0, keep_dims=1
Status   PASS -&gt; tensor-shape=[1,2,3,4], axis=0, keep_dims=0
Status   PASS -&gt; tensor-shape=[1,2,3,4], axis=1, keep_dims=1
Status   PASS -&gt; tensor-shape=[1,2,3,4], axis=1, keep_dims=0
Status   PASS -&gt; tensor-shape=[1,2,3,4], axis=2, keep_dims=1
Status   PASS -&gt; tensor-shape=[1,2,3,4], axis=2, keep_dims=0
Status * FAIL -&gt; tensor-shape=[1,2,3,4], axis=3, keep_dims=1
Status * FAIL -&gt; tensor-shape=[1,2,3,4], axis=3, keep_dims=0
Status   PASS -&gt; tensor-shape=[3,1,2,4,1], axis=0, keep_dims=1
Status   PASS -&gt; tensor-shape=[3,1,2,4,1], axis=0, keep_dims=0
Status   PASS -&gt; tensor-shape=[3,1,2,4,1], axis=1, keep_dims=1
Status   PASS -&gt; tensor-shape=[3,1,2,4,1], axis=1, keep_dims=0
Status   PASS -&gt; tensor-shape=[3,1,2,4,1], axis=2, keep_dims=1
Status   PASS -&gt; tensor-shape=[3,1,2,4,1], axis=2, keep_dims=0
Status * FAIL -&gt; tensor-shape=[3,1,2,4,1], axis=3, keep_dims=1
Status * FAIL -&gt; tensor-shape=[3,1,2,4,1], axis=3, keep_dims=0
Status   PASS -&gt; tensor-shape=[3,1,2,4,1], axis=4, keep_dims=1
Status   PASS -&gt; tensor-shape=[3,1,2,4,1], axis=4, keep_dims=0
		</comment>
		<comment id='3' author='bani-intelaipg' date='2020-07-24T16:27:15Z'>
		Hi &lt;denchmark-link:https://github.com/bani-intelaipg&gt;@bani-intelaipg&lt;/denchmark-link&gt;
 when you say "", do you mean you are using the &lt;denchmark-link:https://docs.openvinotoolkit.org/latest/ie_python_api/classie__api_1_1IENetwork.html#detailed_description&gt;IENetwork&lt;/denchmark-link&gt;
 constructor? If so please note such constructor is deprecated in recent releases, try to use &lt;denchmark-link:https://docs.openvinotoolkit.org/latest/ie_python_api/classie__api_1_1IECore.html#a0d69c298618fab3a08b855442dca430f&gt;IECore.read_network()&lt;/denchmark-link&gt;
 method instead. Also which version of OpenVINO are you using? I see you attached the IR files and a .json, could you provide a code snippet enough to reproduce the issue you are facing? Or if it can be reproduced with one of our sample/demo, please let me know which one.
Best Regards,
Luis
		</comment>
		<comment id='4' author='bani-intelaipg' date='2020-07-24T17:18:17Z'>
		I used C++ nGraph based interface. Here is the pseudo-code / steps:
&lt;denchmark-link:https://docs.openvinotoolkit.org/latest/classInferenceEngine_1_1CNNNetwork.html#ad436e9351bb26cf664bd7941658ee6b7&gt;https://docs.openvinotoolkit.org/latest/classInferenceEngine_1_1CNNNetwork.html#ad436e9351bb26cf664bd7941658ee6b7&lt;/denchmark-link&gt;

Used code in 2020.4 branch (commit# &lt;denchmark-link:https://github.com/openvinotoolkit/openvino/commit/a9c6e7269fdc92ca327166bdd5d255a012d71006&gt;a9c6e72&lt;/denchmark-link&gt;
)
&lt;denchmark-code&gt;  shared_ptr&lt;ngraph::Function&gt; func;
  // then set func object from the json content (not shown here)
  m_network = InferenceEngine::CNNNetwork(func);
  if(debug) {
    auto&amp; name = m_network.getName();
    m_network.serialize(name + ".xml", name + ".bin");
  }
  InferenceEngine::Core ie;
  InferenceEngine::ExecutableNetwork exe_network =
      ie.LoadNetwork(m_network, m_device);
  m_infer_req = exe_network.CreateInferRequest();
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='bani-intelaipg' date='2020-07-27T03:36:13Z'>
		Hi &lt;denchmark-link:https://github.com/bani-intelaipg&gt;@bani-intelaipg&lt;/denchmark-link&gt;
 ,
Can you check that you generate right  operations which are compatible with OpenVINO spec?
The last spec version is &lt;denchmark-link:https://github.com/openvinotoolkit/openvino/blob/f90f242626f38af773059e0d90c47a74ce416948/docs/ops/reduction/ReduceMax_1.md&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='6' author='bani-intelaipg' date='2020-07-27T05:58:05Z'>
		Corrected the title to ReduceSum. I am using ngraph Opset3 interface to create ReduceSum Op v1, and it seems to be complying with OPV spec. I have the ngraph dump json file in my previous attachment. It would help if you can check that json and see if the params are following spec. Also, in the same test run, some sub-test examples do pass and IE infer() does give back correct results (as in TF) in those cases. Only some examples fail. Please see my test report in previous comment. Example:
Status * FAIL -&gt; tensor-shape=[2,3], axis=0, keep_dims=0
Status PASS -&gt; tensor-shape=[2,3], axis=1, keep_dims=0
** One other observation is that, CNN is converting the ngraph ReduceSum graph to a bunch of Reshaep/Pooling/Eltwise Ops after the graph is handed off to CNNNetwork.
		</comment>
		<comment id='7' author='bani-intelaipg' date='2020-08-05T16:38:26Z'>
		Ref. 35955
		</comment>
		<comment id='8' author='bani-intelaipg' date='2021-01-05T16:49:18Z'>
		This has been addressed, closing issue.
&lt;denchmark-link:https://github.com/openvinotoolkit/openvino/pull/3263&gt;#3263&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>