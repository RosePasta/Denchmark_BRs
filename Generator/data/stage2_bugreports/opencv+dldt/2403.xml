<bug id='2403' author='G2020sudo' open_date='2020-09-23T20:10:40Z' closed_time='2020-10-21T13:35:38Z'>
	<summary>[Bug] Remote Blob - SetBlob</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenVINO=&gt; ❔ 2020.3.194
Operating System / Platform =&gt; ❔ Linux Ubuntu 18 LTS / Docker Ubuntu 18
Compiler =&gt; ❔ gcc 9.3.0
Problem classification =&gt; ❔

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;

I am trying to build a Media SDK sample with OpenVINO that uses GPU remote blob feature. In my sample I can succesfully:
auto shared_va_context = make_shared_context(ie, "GPU", getVADevice());
ExecutableNetwork execNet = ie.loadnetwork(network, shared_va_context, {{ CLDNNConfigParams::KEYCLDNN_NV12_TWO_INPUTS, PluginConfigParams::YES }});
InferRequest inferRequest = execNet.CreateInferRequest();
...
auto nv12_compound_blob = make_shared_blob_nv12(height, width, shared_va_context, vaSurface); // VaSurfaceID* LInux
However, when I inferRequest.SetBlob(blobName, nv12_compound_blob);   I get
"terminate called after throwing an instance of 'InferenceEngine::details::InferenceEngineException'
what():  [NOT_IMPLEMENTED] cannot set compound blob: supported only for input pre-processing"
I traced error in the OpenVINO source: &lt;denchmark-link:https://github.com/openvinotoolkit/openvino/blob/acc9a41c62e91072e39d31bfab2ac61801c09161/inference-engine/src/plugin_api/cpp_interfaces/impl/ie_infer_request_internal.hpp&gt;https://github.com/openvinotoolkit/openvino/blob/acc9a41c62e91072e39d31bfab2ac61801c09161/inference-engine/src/plugin_api/cpp_interfaces/impl/ie_infer_request_internal.hpp&lt;/denchmark-link&gt;
 to preProcessingRequired (see below). This function expects BGR but remote blob only works with NV12.
Is this a bug or is there another way to set the nv12 compound blob I need to perform MSDK Decode GPU with OpenVINO GPU Inference with zero copy?
const bool preProcRequired = preProcessingRequired(foundInput, data);
if (compoundBlobPassed &amp;&amp; !preProcRequired) {
THROW_IE_EXCEPTION &lt;&lt; NOT_IMPLEMENTED_str
&lt;&lt; "cannot set compound blob: supported only for input pre-processing";
}
bool preProcessingRequired(const InputInfo::Ptr&amp; info, const Blob::Ptr&amp; blob) {
// pre-processing is required if:
// 1. resize algorithm is specified (resize required)
// 2. color format specified:
// 2.a. color format is not equal to network's expected (color conversion required)
// 2.b. network's layout != blob's layout (reorder required)
const auto&amp; preProcessInfo = info-&gt;getPreProcess();
const auto inputColorFormat = preProcessInfo.getColorFormat();
// FIXME: support other network's input formats once the API is ready. Assuming input is in
// the BGR format by default
const auto networkColorFormat = ColorFormat::BGR;
&lt;denchmark-code&gt;    const bool colorFormatSpecified = inputColorFormat != ColorFormat::RAW;
    return preProcessInfo.getResizeAlgorithm() != ResizeAlgorithm::NO_RESIZE ||
           (colorFormatSpecified &amp;&amp; inputColorFormat != networkColorFormat) ||
           (colorFormatSpecified &amp;&amp; info-&gt;getLayout() != blob-&gt;getTensorDesc().getLayout());
}
&lt;/denchmark-code&gt;

&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;

// make compound blob
auto nv12_compound_blob = make_shared_blob_nv12(height, width, shared_va_context, vaSurface); // VaSurfaceID* LInux
// call setBlob on inferrequest with the compound blob
inferRequest.SetBlob(blobName, nv12_compound_blob);
&lt;denchmark-h:h5&gt;Issue submission checklist&lt;/denchmark-h&gt;


[x ] I report the issue, it's not a question
[x ] I checked the problem with documentation, FAQ, open issues, Stack Overflow, etc and have not found solution
[x ] There is reproducer code and related data files: images, videos, models, etc.

	</description>
	<comments>
		<comment id='1' author='G2020sudo' date='2020-09-23T21:53:11Z'>
		I found the issue. It appears that when calling inferRequest.GetBlob() before creating nv12 compound and then calling inferRequest.SetBlob(..) will cause the preProcessing error (this is a false error and IE is confused) (like below).
auto shared_va_context = make_shared_context(ie, "GPU", getVADevice());
ExecutableNetwork execNet = ie.loadnetwork(network, shared_va_context, {{ CLDNNConfigParams::KEYCLDNN_NV12_TWO_INPUTS, PluginConfigParams::YES }});
InferRequest inferRequest = execNet.CreateInferRequest();
...
inferRequest.GetBlob() and get dimensions from it so dimensions can be used for make_shared_blob_nv12 call below.
auto nv12_compound_blob = make_shared_blob_nv12(height, width, shared_va_context, vaSurface); // VaSurfaceID* LInux
inferRequest.SetBlob(blobName, nv12_compound_blob);
"terminate called after throwing an instance of 'InferenceEngine::details::InferenceEngineException'
what(): [NOT_IMPLEMENTED] cannot set compound blob: supported only for input pre-processing"
However, even if I remove the GetBlob call and pass dimensions manually to make_shared_blob_nv12 setBlob will now throw a segmentation fault with no error message.
Is there a remote blob example I can reference...(any sample will do)?
		</comment>
		<comment id='2' author='G2020sudo' date='2020-09-25T03:21:33Z'>
		&lt;denchmark-link:https://github.com/G2020sudo&gt;@G2020sudo&lt;/denchmark-link&gt;
 I wonder how generic implementation is called? GPU plugin has its own  implementation, see &lt;denchmark-link:https://github.com/openvinotoolkit/openvino/blob/master/inference-engine/src/cldnn_engine/cldnn_infer_request.cpp#L433-L557&gt;https://github.com/openvinotoolkit/openvino/blob/master/inference-engine/src/cldnn_engine/cldnn_infer_request.cpp#L433-L557&lt;/denchmark-link&gt;
 and such case with remoteBlob is handled.
		</comment>
		<comment id='3' author='G2020sudo' date='2020-09-28T17:14:58Z'>
		Hi Ilya, I've run out of time to debug. If there isn't a sample to use/start from I will close for now until I can try again.
		</comment>
		<comment id='4' author='G2020sudo' date='2020-10-21T13:35:38Z'>
		Closing, feel free to re-open if additional assistance is needed.
		</comment>
	</comments>
</bug>