<bug id='35' author='rocketbear' open_date='2018-11-19T12:42:01Z' closed_time='2020-09-29T16:44:24Z'>
	<summary>Inference Engine crash when using Activation layer with type="sigmoid"</summary>
	<description>
Using the latest 2018R4 release of Intel's OpenVINO, a very simple network with a Convolution layer and a Activation layer crashes at run time with the following error:
&lt;denchmark-code&gt;Illegal instruction (core dumped)
&lt;/denchmark-code&gt;

But the network is ok if the activation type is changed from sigmoid to tanh.
The net is defined as follows in the IR xml:
&lt;denchmark-code&gt;&lt;layers&gt;
	&lt;layer id="0" name="data" precision="FP32" type="Input"&gt;
		&lt;output&gt;
			&lt;port id="0"&gt;
				&lt;dim&gt;16&lt;/dim&gt;
				&lt;dim&gt;32&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
			&lt;/port&gt;
		&lt;/output&gt;
	&lt;/layer&gt;
	&lt;layer id="1" name="conv_fwd" precision="FP32" type="Convolution"&gt;
		&lt;data dilations="1,1" group="1" kernel="3,3" output="32" pads_begin="1,1" pads_end="1,1" strides="1,1"/&gt;
		&lt;input&gt;
			&lt;port id="0"&gt;
				&lt;dim&gt;16&lt;/dim&gt;
				&lt;dim&gt;32&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
			&lt;/port&gt;
		&lt;/input&gt;
		&lt;output&gt;
			&lt;port id="2"&gt;
				&lt;dim&gt;16&lt;/dim&gt;
				&lt;dim&gt;32&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
			&lt;/port&gt;
		&lt;/output&gt;
		&lt;blobs&gt;
			&lt;weights offset="0" size="36864"/&gt;
		&lt;/blobs&gt;
	&lt;/layer&gt;
	&lt;layer id="2" name="act_fwd" precision="FP32" type="Activation"&gt;
		&lt;data type="sigmoid"/&gt;
		&lt;input&gt;
			&lt;port id="0"&gt;
				&lt;dim&gt;16&lt;/dim&gt;
				&lt;dim&gt;32&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
			&lt;/port&gt;
		&lt;/input&gt;
		&lt;output&gt;
			&lt;port id="1"&gt;
				&lt;dim&gt;16&lt;/dim&gt;
				&lt;dim&gt;32&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
				&lt;dim&gt;8&lt;/dim&gt;
			&lt;/port&gt;
		&lt;/output&gt;
	&lt;/layer&gt;
&lt;/layers&gt;
&lt;edges&gt;
	&lt;edge from-layer="0" from-port="0" to-layer="1" to-port="0"/&gt;
	&lt;edge from-layer="1" from-port="2" to-layer="2" to-port="0"/&gt;
&lt;/edges&gt;
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='rocketbear' date='2018-11-19T15:02:16Z'>
		Hi,
Could you provide more information (command line or something like that)?
Illegal instruction
It looks like you are using CPU plugin. Am I right?
Could you provide your hardware configuration? I mean the CPU model if you are using the CPU plugin.
		</comment>
		<comment id='2' author='rocketbear' date='2018-11-20T01:52:42Z'>
		My CPU model is E5-2650v2. It's not on the supported list of OpenVINO. This could be the problem.
But the odd thing is, if the positions of the two layers are exchanged, i.e. from conv-act(sigmoid) to act(sigmoid)-conv, the inference engine has no problem running the net.
		</comment>
		<comment id='3' author='rocketbear' date='2018-11-20T06:23:06Z'>
		Yes, the root cause of this issue is your CPU. It supports only AVX instructions.
Inference Engine doesn't fully support CPUs which haven't as least AVX2 or SSE4.2 instruction sets.
Sigmoid to Convolution works fine because the Inference Engine executes these layers as two different primitives. The Sigmoid primitive fallbacks to gemm or ref implementation and Convolution fallbacks to jit implementation which supports AVX instructions.
In the case of Convolution -&gt; Sigmoid the situation is different. The Inference Engine applies an optimization and replaces Convolution and Sigmoid layers to Convolution+Sigmoid layer. And for this optimization on your CPU the Inference Engine selects the jit implementation.
It looks like a bug in the Inference Engine and in your case jit implementation shouldn't be selected because jit implementation for Sigmoid layer does not support AVX instructions. This issue will be investigated and fixed in future versions.
As a WA you will be able to disable Convololution+Activation optimization when R4 will be available in the open source.
		</comment>
	</comments>
</bug>