<bug id='83' author='cioroianudenis' open_date='2020-06-25T17:25:24Z' closed_time='2020-06-29T12:25:39Z'>
	<summary>Potential bug when partially training a Gaussian Naive Bayes model</summary>
	<description>
So I have the following code:
$estimator = new PersistentModel(
    new Pipeline([
        new TextNormalizer(),
        new StopWordFilter(StopWords::$words),
        new WordCountVectorizer(10000, 1, new NGram(1, 2, new WordStemmer('romanian'))),
        new TfIdfTransformer(),
        new ZScaleStandardizer(),
    ], new GaussianNB()),
    new Filesystem($this-&gt;path.'/categorization.model', true)
);

$categories = Category::has('variants')-&gt;with('variants')-&gt;get();

$samples = [];
$labels = [];
foreach ($categories as $category) {
    foreach ($category-&gt;variants as $variant) {
        $samples[] = [$variant-&gt;title];
        $labels[] = $category-&gt;slug;
    }
}

$foldsNo = 10;
$dataset = new Labeled($samples, $labels);
$folds = $dataset-&gt;fold($foldsNo);

$estimator-&gt;train($folds[0]);
for($i = 1; $i &lt; $foldsNo; $i++) {
    $estimator-&gt;partial($folds[$i]);
}

$estimator-&gt;save();
which tries to train a GaussianNB model on 26 thousand products and their associated labels, but for some reason I get the following error:
&lt;denchmark-code&gt;
ErrorException
Undefined offset: 0
&lt;/denchmark-code&gt;

in rubix\ml\src\Classifiers\GaussianNB.php:267 which corresponds to the following code: $means[$column] = (($n * $mean) + ($oldWeight * $oldMeans[$column])) / ($oldWeight + $n); , the problem seems to be here $oldMeans[$column] when trying to access a property which doesn't exist, but I have no idea why that property doesn't exist.
I don't suspect that the training data has any errors since if I fully train the same model with $estimator-&gt;train($dataset) works as expected (Batch learning in one single session).
When I tried to debug the code I have the following:
I see that lines 256, 257 and 259 have this code:
$means = $oldMeans = $this-&gt;means[$class] ?? [];
$variances = $oldVariances = $this-&gt;variances[$class] ?? [];

$oldWeight = $this-&gt;weights[$class] ?? 0;
which assigns [] empty array if $this-&gt;means[$class] , $this-&gt;variances[$class] and $this-&gt;weights[$class] don't exist, but if $oldMeans  is empty array I think $oldMeans[$column] would throw out that error. So a fix would be to put ($oldMeans[$column] ?? 0) in rubix\ml\src\Classifiers\GaussianNB.php:267 instead of $oldMeans[$column] I think. I am not 100% how that would affect the training of the model tho.
I hope that I am not mistaken.
Thank you!
	</description>
	<comments>
		<comment id='1' author='cioroianudenis' date='2020-06-26T05:13:59Z'>
		Hey &lt;denchmark-link:https://github.com/cioroianudenis&gt;@cioroianudenis&lt;/denchmark-link&gt;
 when doing online training, the first training set will determine the classes that the learner learns. Looks like I tried to adapt to new class labels but that's not working properly. If the first fold does not contain all the class labels, you may run into this problem. Instead of  try  on the &lt;denchmark-link:https://docs.rubixml.com/en/latest/datasets/labeled.html#stratification&gt;Labeled&lt;/denchmark-link&gt;
 dataset object to ensure that each fold contains all the class labels.
Example
foreach ($dataset-&gt;stratifiedFold(10) as $fold) {
    $estimator-&gt;partial($fold);
}
Let me know if that fixes the issue and we'll go from there
(Bear in mind that folding in this way offers no benefit over batch learning as you're just breaking a dataset that's already in memory into multiple smaller ones and still training on all of them in the same session. In fact, you pay the penalty of having to recompute means and variances this way.)
		</comment>
		<comment id='2' author='cioroianudenis' date='2020-06-26T05:53:44Z'>
		Should be fixed in this commit &lt;denchmark-link:https://github.com/RubixML/ML/commit/3d868cfb38eabc5cdeea7768c95e66c0690ae515&gt;3d868cf&lt;/denchmark-link&gt;

You can install the latest dev-master to test
Could you please also test stratifiedFold() just to confirm that indeed unseen class labels was the issue?
Thanks for the great bug report! Feel free to join our channel on Telegram &lt;denchmark-link:https://t.me/RubixML&gt;https://t.me/RubixML&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='cioroianudenis' date='2020-06-26T16:49:45Z'>
		Hello &lt;denchmark-link:https://github.com/andrewdalpino&gt;@andrewdalpino&lt;/denchmark-link&gt;
, the  indeed works as intended.
Didn't get the chance to test the new fix, once I test it, I'll come back and post the results.
Thank you for telegram invitation, I will most certainly join, I'm happy to help.
		</comment>
		<comment id='4' author='cioroianudenis' date='2020-06-27T02:44:02Z'>
		Thank you &lt;denchmark-link:https://github.com/cioroianudenis&gt;@cioroianudenis&lt;/denchmark-link&gt;
 let me know if the new  works even without using stratified folds
See you in the channel!
		</comment>
		<comment id='5' author='cioroianudenis' date='2020-06-27T12:31:51Z'>
		&lt;denchmark-link:https://github.com/andrewdalpino&gt;@andrewdalpino&lt;/denchmark-link&gt;
 I have managed to test it, it doesn't give the same error anymore, but now it runs out of memory (i gave it 8GB of ram), just like what happend when I tried to test  or full train (with still 8GB of ram), which is to be expected since it is alot of data for the memory to manage.
I tested the following code
$categories = Category::has('variants')-&gt;with('variants')-&gt;get();

$samples = [];
$labels = [];
foreach ($categories as $category) {
    foreach ($category-&gt;variants as $variant) {
        $samples[] = [$variant-&gt;title];
        $labels[] = $category-&gt;slug;
    }
}

$foldsNo = 10;
$dataset = new Labeled($samples, $labels);
$folds = $dataset-&gt;fold($foldsNo);

for($i = 0; $i &lt; $foldsNo; $i++) {
    $estimator-&gt;partial($folds[$i]);
}

$estimator-&gt;save();
after it ran out of memory, I tried another approach to partially train the model which worked, it didn't give any errors or run out of memory but the resulting trained model has only 6 MB of data, which leads me to believe that it didn't train on the whole data, the reason I think this is I have another model that was trained on 14.000 products with batch training(in a single run) and had 43 MB of data.
This time I have 26.000 products and the model only has 6 MB with partial training on all of them.
This is the other alternative which worked but gave the 6 MB model:
$start = 1;
$limit = 2;
$categories = Category::has('variants')-&gt;with('variants')-&gt;skip($start)-&gt;limit($limit)-&gt;get();

while($categories-&gt;count()) {
    $samples = [];
    $labels = [];

    foreach ($categories as $category) {
        foreach ($category-&gt;variants as $variant) {
            $samples[] = [$variant-&gt;title];
            $labels[] = $category-&gt;slug;
        }
    }

    $dataset = new Labeled($samples, $labels);
    $estimator-&gt;partial($dataset);

    $start += $limit;
    $categories = Category::has('variants')-&gt;with('variants')-&gt;skip($start)-&gt;limit($limit)-&gt;get();
}

$estimator-&gt;save();
Basically all it does is loading from the database only 2 categories at a time which have a maximum of 1000 products associated with them, and I create a new $dataset in a while loop and I feed it to the estimator with partial($dataset).
I also tested some predictions on the 6 MB model vs the 43 MB model, and the 43 MB was returning correct every time, while the 6 MB one wasn't.
I hope my explanation is clear enough.
Thank you!
Edit 1:
I made it kinda work with folding by increasing the number of folds, I first gave it $folds = $dataset-&gt;fold(10); which resulted in 8 GB out of memory.
I then gave it $folds = $dataset-&gt;fold(20); which worked and compiled a 27 MB of data model but used around 6.5 GB of ram - the predictions weren't good for some tests that I made.
After that I gave it $folds = $dataset-&gt;fold(60); which was half the number of $categories fetched form the database and I saw it using around 2.5 GB of ram at maximum but compiled a 9.3 MB data model that again still predicted wrong on testing products.
		</comment>
		<comment id='6' author='cioroianudenis' date='2020-06-27T18:44:24Z'>
		&lt;denchmark-link:https://github.com/cioroianudenis&gt;@cioroianudenis&lt;/denchmark-link&gt;
 It's likely that the vocabulary built by &lt;denchmark-link:https://docs.rubixml.com/en/latest/transformers/word-count-vectorizer.html&gt;Word Count Vecotorizer&lt;/denchmark-link&gt;
 is not suitable as it's being fitted with less data now.
echo count(current($transformer-&gt;vocabulary()));
will give you the size of the vocabulary of the first feature column. If it's set to 10,000 and your vocab contains alot less or has junk features, this may explain the issue. Instead you can fit Word Count Vectorizer on the full dataset or a larger portion at least and THEN inject it into the Pipeline.
use Rubix\ML\Transformers\WordCountVectorizer;
use Rubix\ML\Other\Tokenizers\NGram;
use Rubix\ML\Other\Tokenizers\WordStemmer;

$transformer = new WordCountVectorizer(10000, 1, new NGram(1, 2, new WordStemmer('romanian')));

$transformer-&gt;fit($dataset); // Fitted with a dataset large enough to build a good vocabulary

$estimator = new PersistentModel(
    new Pipeline([
        new TextNormalizer(),
        new StopWordFilter(StopWords::$words),
        $transformer,
        new TfIdfTransformer(),
        new ZScaleStandardizer(),
    ], new GaussianNB()),
    new Filesystem($this-&gt;path.'/categorization.model', true)
);
Calling partial() on Pipeline will not refit WordCountVectorizer so you can use it with the custom fittings but as soon as you call train() Pipeline will refit it just a heads up. Note that you'll probably want to normalize and stop word filter before fitting WordCountVectorizer.
		</comment>
		<comment id='7' author='cioroianudenis' date='2020-06-27T19:29:48Z'>
		&lt;denchmark-link:https://github.com/andrewdalpino&gt;@andrewdalpino&lt;/denchmark-link&gt;
 I tried it like this, but now it uses so much ram, 8 GB is not enough, it gives out of memory error.
		</comment>
		<comment id='8' author='cioroianudenis' date='2020-06-27T19:35:49Z'>
		Ok, you can either try filtering your dataset so that it fits into memory or getting more RAM
Were you able to confirm that indeed a poor vocabulary was the issue?
		</comment>
		<comment id='9' author='cioroianudenis' date='2020-06-27T19:45:14Z'>
		&lt;denchmark-link:https://github.com/andrewdalpino&gt;@andrewdalpino&lt;/denchmark-link&gt;
 not quite, I can't compute the model on all the products, even with using the new solution. Probably that would be the case for it not predicting like the one trained in batch mode that has 14k products, but I can't test it.
Thing is, if this chugs on 26k products, then my dream of training for on 1-2 million products goes straight to the trash on a normal laptop hahaha, I'll see what I can do to minimize the product count and make it work.
		</comment>
		<comment id='10' author='cioroianudenis' date='2020-06-27T19:49:52Z'>
		Sounds good &lt;denchmark-link:https://github.com/cioroianudenis&gt;@cioroianudenis&lt;/denchmark-link&gt;

The issue is that Word Count Vectorizer needs to build a vocabulary somehow and it does so using all the words contained in the dataset used to fit it. This cannot be done partially (Word Count Vectorizer does not implement the &lt;denchmark-link:https://docs.rubixml.com/en/latest/transformers/api.html#elastic&gt;Elastic&lt;/denchmark-link&gt;
 interface for this reason). Having that said, you do not need to build a vocabulary from  your training samples, you only need  and once fitted you can train on as many samples as you like as Gaussian NB tends to scale well and can be partially trained.
		</comment>
		<comment id='11' author='cioroianudenis' date='2020-06-27T20:52:51Z'>
		&lt;denchmark-link:https://github.com/andrewdalpino&gt;@andrewdalpino&lt;/denchmark-link&gt;
 yeah that's what I was thinking.
I tested it again, I built the word count vectorizer on only 1k products, and tried training the model on all the training samples (26k items), but I still get out of memory when the model begins to train.
I think there still is a memory leak somewhere when calling .
		</comment>
		<comment id='12' author='cioroianudenis' date='2020-06-27T20:56:11Z'>
		Are you using dev-master or another version?
		</comment>
		<comment id='13' author='cioroianudenis' date='2020-06-27T20:59:37Z'>
		&lt;denchmark-link:https://github.com/andrewdalpino&gt;@andrewdalpino&lt;/denchmark-link&gt;
 i'm using the branch  from &lt;denchmark-link:https://github.com/RubixML/RubixML&gt;https://github.com/RubixML/RubixML&lt;/denchmark-link&gt;
, cloned it on local.
		</comment>
		<comment id='14' author='cioroianudenis' date='2020-06-27T21:06:16Z'>
		Ok you can also try limiting your vocabulary to a size that is a power of 2 (or slightly less if you have other features) to reduce the amount of wasted memory since that's how PHP allocates memory under the hood
I'll profile GaussianNB asap
		</comment>
		<comment id='15' author='cioroianudenis' date='2020-06-27T21:06:41Z'>
		&lt;denchmark-link:https://github.com/andrewdalpino&gt;@andrewdalpino&lt;/denchmark-link&gt;
 nvm, I think it's a problem of fine tuning, went with 3000 words in tokenzier, and it works. Kinda getting the hang of it.
		</comment>
	</comments>
</bug>