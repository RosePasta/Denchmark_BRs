<bug id='639' author='mjpost' open_date='2019-02-07T18:13:57Z' closed_time='2019-08-29T12:56:42Z'>
	<summary>Wrong scores from sockeye.translate in test cases</summary>
	<description>
I have encountered an issue when trying to debug &lt;denchmark-link:https://github.com/awslabs/sockeye/pull/593&gt;the new scorer&lt;/denchmark-link&gt;
. Tests seem to randomly fail when the scorer is used to evaluate translator output. I think this may relate to &lt;denchmark-link:https://github.com/awslabs/sockeye/issues/545&gt;#545&lt;/denchmark-link&gt;
.
I've attached a model generated by the integration tests (&lt;denchmark-link:https://github.com/awslabs/sockeye/files/2842146/example.zip&gt;example.zip&lt;/denchmark-link&gt;
). If you unpack it, and then run
&lt;denchmark-code&gt;echo '{"text": "4 0 6 2 9 0 4"}' | PYTHONPATH=$(pwd) python3 -m sockeye.translate -m model --beam-size 3 --output-type translation_with_score --length-penalty-alpha 1 --use-cpu --batch-size 1 --json-input
&lt;/denchmark-code&gt;

You get this output:
&lt;denchmark-code&gt;2.249	5 6 2 5 5 5 6 5
&lt;/denchmark-code&gt;

Now, if you run again, with that same output as a constraint:
&lt;denchmark-code&gt;echo '{"text": "4 0 6 2 9 0 4", "constraints": ["&lt;s&gt; 5 6 2 5 5 5 6 5 &lt;/s&gt;"]}' | PYTHONPATH=$(pwd) python3 -m sockeye.translate -m model --beam-size 3 --output-type translation_with_score --length-penalty-alpha 1 --use-cpu --batch-size 1 --json-input
&lt;/denchmark-code&gt;

You get a different output:
&lt;denchmark-code&gt;2.262	5 6 2 5 5 5 6 5
&lt;/denchmark-code&gt;

Note that this different output (with a score of 2.262) is the same you get from scoring. So scoring and forced decoding produce the same result, and unconstrained decoding produces a different one.
I am investigating, but my guess is that the &lt;/s&gt; character is not being generated in the first output.
	</description>
	<comments>
		<comment id='1' author='mjpost' date='2019-02-07T18:51:42Z'>
		My hypothesis was correct: in this simple test case, the unconstrained system produces C.PAD_ID without ever producing &lt;/s&gt;. Here is a trace. At each timestep, this produces:

the accumulated score
whether each hypothesis is finished
the hyp IDS
the word IDS

both before (a) and after (b) normalization. You can see in step 9a that the third hypothesis selects 0 and then normalizes, without ever having generated &lt;/s&gt;.
&lt;denchmark-code&gt;STEP 1a ACCUM [2.0751374, 2.1165216, 2.3479793] FINISHED [0 0 0] HYPS [0 0 0] WORDS [10  3  4]
STEP 1b ACCUM [2.0751374, inf, 2.3479793] FINISHED [0 1 0] HYPS [0 0 0] WORDS [10  3  4]
STEP 2a ACCUM [4.0901737, 4.245805, 4.3240795] FINISHED [0 0 0] HYPS [0 0 2] WORDS [11  3 10]
STEP 2b ACCUM [4.0901737, 4.245805, 4.3240795] FINISHED [0 1 0] HYPS [0 0 2] WORDS [11  3 10]
STEP 3a ACCUM [4.245805, 6.1991305, 6.2728653] FINISHED [1 0 0] HYPS [1 0 0] WORDS [ 0 10  4]
STEP 3b ACCUM [4.245805, 6.1991305, 6.2728653] FINISHED [1 0 0] HYPS [1 0 0] WORDS [ 0 10  4]
STEP 4a ACCUM [4.245805, 7.936099, 8.1894655] FINISHED [1 0 0] HYPS [0 2 1] WORDS [ 0 10  0]
STEP 4b ACCUM [4.245805, 7.936099, 2.729822] FINISHED [1 0 1] HYPS [0 2 1] WORDS [ 0 10  0]
STEP 5a ACCUM [2.729822, 4.245805, 9.972357] FINISHED [1 1 0] HYPS [2 0 1] WORDS [ 0  0 10]
STEP 5b ACCUM [2.729822, 4.245805, 9.972357] FINISHED [1 1 0] HYPS [2 0 1] WORDS [ 0  0 10]
STEP 6a ACCUM [2.729822, 4.245805, 12.064625] FINISHED [1 1 0] HYPS [0 1 2] WORDS [ 0  0 10]
STEP 6b ACCUM [2.729822, 4.245805, 12.064625] FINISHED [1 1 0] HYPS [0 1 2] WORDS [ 0  0 10]
STEP 7a ACCUM [2.729822, 4.245805, 13.989123] FINISHED [1 1 0] HYPS [0 1 2] WORDS [ 0  0 11]
STEP 7b ACCUM [2.729822, 4.245805, 13.989123] FINISHED [1 1 0] HYPS [0 1 2] WORDS [ 0  0 11]
STEP 8a ACCUM [2.729822, 4.245805, 15.929425] FINISHED [1 1 0] HYPS [0 1 2] WORDS [ 0  0 10]
STEP 8b ACCUM [2.729822, 4.245805, 15.929425] FINISHED [1 1 0] HYPS [0 1 2] WORDS [ 0  0 10]
STEP 9a ACCUM [2.729822, 4.245805, 17.995995] FINISHED [1 1 0] HYPS [0 1 2] WORDS [0 0 0]
STEP 9b ACCUM [2.729822, 4.245805, 2.2494993] FINISHED [1 1 1] HYPS [0 1 2] WORDS [0 0 0]
BEST 0 [0]
2.249	5 6 2 5 5 5 6 5
&lt;/denchmark-code&gt;

This is a problem for scoring against translation output, because scoring always scores . Pursuant to the discussion in &lt;denchmark-link:https://github.com/awslabs/sockeye/issues/545&gt;#545&lt;/denchmark-link&gt;
, it seems that inference should do the same.
As a temporary workaround for the scoring branch, I'll take the translation outputs, force decode them (so as to get &lt;/s&gt; included in the score), and check sockeye.score against those numbers.
		</comment>
		<comment id='2' author='mjpost' date='2019-02-07T21:03:54Z'>
		Yeah, we've also talked about something related to this: depending on the batch-size you also might get different results because we break out of beam search earlier in batch-size 1 situations than in batch-size &gt; 1 cases (where longer sentences in the batch can cause beam search to run for more iterations). In the latter case the shorter sentence is properly ended with &lt;/s&gt;, but in the former case not. Our beam search logic on finished hypotheses (newly finished, somehow finished, finished but not normalized, finished but not sorted etc) has become way too complicated. This is something we will have to address at some point, probably by making sure again that all hypotheses are normalized at all times.
		</comment>
		<comment id='3' author='mjpost' date='2019-02-07T22:35:13Z'>
		I agree the logic is becoming unwieldy. Always normalizing could help. Constraints are responsible for a lot of the complexity; maybe we should branch on that instead of trying to have a single general solution.
		</comment>
		<comment id='4' author='mjpost' date='2019-02-12T14:32:36Z'>
		For the problem with scoring and batching this would be solved by making sure by making sure that the final token always is &lt;/s&gt; in beam search in the maximum iteration, right?
		</comment>
		<comment id='5' author='mjpost' date='2019-02-12T14:34:30Z'>
		I think it would, yes.
		</comment>
		<comment id='6' author='mjpost' date='2019-02-26T11:14:05Z'>
		Could this issue be related to the following: attention weight matrix output (&lt;denchmark-link:https://github.com/awslabs/sockeye/blob/master/sockeye/output_handler.py#L230&gt;https://github.com/awslabs/sockeye/blob/master/sockeye/output_handler.py#L230&lt;/denchmark-link&gt;
) does not output valid probability distributions:
&lt;denchmark-code&gt;4 ||| system Organ Class &lt;/s&gt; ||| 1.107796 ||| Kl@@ assen@@ hier@@ ar@@ ch@@ ie ||| 6 ||| 4
0.250257 0.085057 0.068153 0.022506
0.390398 0.122760 0.126535 0.135602
0.097477 0.170234 0.149181 0.042531
0.058781 0.013876 0.028575 0.016816
0.004925 0.000685 0.001663 0.011022
0.011384 0.011746 0.009078 0.019487
&lt;/denchmark-code&gt;

Vertically, weights do not sum to 1 because attention on &lt;/s&gt; in the source sentence is not included.
		</comment>
		<comment id='7' author='mjpost' date='2019-02-26T13:53:38Z'>
		I think you mean to tag &lt;denchmark-link:https://github.com/awslabs/sockeye/issues/637&gt;#637&lt;/denchmark-link&gt;
. I think these issues are independentâ€”this deals with target sequences, and &lt;denchmark-link:https://github.com/awslabs/sockeye/issues/637&gt;#637&lt;/denchmark-link&gt;
 with attentions over source sequences.
		</comment>
		<comment id='8' author='mjpost' date='2019-02-27T09:21:30Z'>
		Yes, it should have been &lt;denchmark-link:https://github.com/awslabs/sockeye/issues/637&gt;#637&lt;/denchmark-link&gt;
 - sorry, I should have read more carefully!
		</comment>
		<comment id='9' author='mjpost' date='2019-02-28T10:29:16Z'>
		yeah, I think these are two different issues. Once we just truncate the attention matrix too much, but the scores + translations should be correct (&lt;denchmark-link:https://github.com/awslabs/sockeye/issues/637&gt;#637&lt;/denchmark-link&gt;
) and for the other issue we do not terminate the target sentence with a  when running into the maximum sentence length.
		</comment>
		<comment id='10' author='mjpost' date='2019-08-29T12:56:42Z'>
		Sockeye 2 addresses this issue, see &lt;denchmark-link:https://github.com/awslabs/sockeye/pull/719&gt;#719&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='11' author='mjpost' date='2019-08-29T16:57:47Z'>
		Shouldn't we leave this open until we release Sockeye 2? ;)
		</comment>
	</comments>
</bug>