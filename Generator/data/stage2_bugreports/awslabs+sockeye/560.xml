<bug id='560' author='lambdaofgod' open_date='2018-10-12T08:34:38Z' closed_time='2019-02-24T13:52:05Z'>
	<summary>Image captioning target</summary>
	<description>
I was trying to run image captioning model, but I get (latest error)
&lt;denchmark-code&gt;
line 618, in get_data_statistics
    buck_idx, buck = get_target_bucket(buckets, len(target))
TypeError: object of type 'NoneType' has no len()
&lt;/denchmark-code&gt;

My target looks like this when I do head on it:
&lt;denchmark-code&gt;Closeup of bins of food that include broccoli and bread.
A giraffe eating food from the top of the tree.
A flower vase is sitting on a porch stand.
A zebra grazing on lush green grass in a field.
Woman in swim suit holding parasol on sunny day.
A couple of men riding horses on top of a green field.
They are brave for riding in the jungle on those elephants.
a black and silver clock tower at an intersection near a tree
A train coming to a stop on the tracks out side.
A couple of giraffe snuggling each other in a forest.
&lt;/denchmark-code&gt;

As a side note, it would be nice to provide some small example for image captioning that would actually work.
	</description>
	<comments>
		<comment id='1' author='lambdaofgod' date='2018-10-16T16:55:39Z'>
		&lt;denchmark-link:https://github.com/lorisbaz&gt;@lorisbaz&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='lambdaofgod' date='2018-10-17T07:48:25Z'>
		Can you please add more on the command that you are running? It is hard to extrapolate from that error.
Also, make sure you have the latest version of Sockeye (I do not see that line at 618 in the current version).
		</comment>
		<comment id='3' author='lambdaofgod' date='2018-10-17T09:07:13Z'>
		After extracting features in features/resnet-101, I tried the following training command (using your provided target):
&lt;denchmark-code&gt;python -m sockeye.image_captioning.train \
        --source-root features/resnet-101 --source source --target target \
        --validation-source-root features/resnet-101 --validation-source source --validation-target target \
        --batch-size 64 --initial-learning-rate 0.0003 --gradient-clipping-threshold 1.0 \
        --bucket-width 5 --max-seq-len 1:60 --fill-up replicate \
        --output models/ --encoder image-pretrain-cnn --rnn-num-hidden 512 \
        --rnn-decoder-state-init zero  --checkpoint-frequency 200 --weight-normalization
&lt;/denchmark-code&gt;

Maybe there is some hidden bug, can you please attach here the commands (including feature extraction and training) and full logs?
		</comment>
		<comment id='4' author='lambdaofgod' date='2018-10-17T09:48:45Z'>
		I run this command from Ipython: ( DATA_DIR is directory with features (I've checked it and I think it's correct since feature extraction works) )
&lt;denchmark-code&gt;!python -m sockeye.image_captioning.train \
        --source-root {DATA_DIR}/coco/train2014_features \
        --source train_features \
        --target captions_train2014 \
        --validation-source-root {DATA_DIR}/coco/val2014_features \
        --validation-source val_features \
        --validation-target captions_val2014 \
        --batch-size 64 \
        --initial-learning-rate 0.0003 \
        --gradient-clipping-threshold 1.0 \
        --bucket-width 5 \
        --max-seq-len 1:60 \
        --fill-up replicate \
        --output models/ \
        --encoder image-pretrain-cnn \
        --rnn-num-hidden 512 \
        --rnn-decoder-state-init zero \
        --checkpoint-frequency 200 \
        --weight-normalization
&lt;/denchmark-code&gt;

Also train and valid caption files are correct (I posted results of running head on one of them earlier).
I use sockeye version 1.18.56.
		</comment>
		<comment id='5' author='lambdaofgod' date='2018-10-17T12:14:30Z'>
		Do you also have the full log and error?
Also make sure that you delete the folder model/ if the command previously failed.
		</comment>
		<comment id='6' author='lambdaofgod' date='2018-10-18T07:57:19Z'>
		Full log:
&lt;denchmark-code&gt;[INFO:sockeye.train] The output folder /home/ubuntu/Projects/ml-sandbox/47lining-ml-sandbox/notebooks/image-search/models already exists, but no training state or parameter file was found. Will start training from scratch.
[INFO:sockeye.utils] Sockeye version 1.18.56, commit 5144d25e6af3ca45baa33eb2c5c1ce7369364c61, path /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sockeye/__init__.py
[INFO:sockeye.utils] MXNet version 1.3.0, path /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/__init__.py
[INFO:sockeye.utils] Command: /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sockeye/image_captioning/train.py --source-root ../../data/image-search/coco/train2014_features --source train_features --target captions_train2014 --validation-source-root ../../data/image-search/coco/val2014_features --validation-source val_features --validation-target captions_val2014 --batch-size 64 --initial-learning-rate 0.0003 --gradient-clipping-threshold 1.0 --bucket-width 5 --max-seq-len 1:60 --fill-up replicate --output models/ --encoder image-pretrain-cnn --rnn-num-hidden 512 --rnn-decoder-state-init zero --checkpoint-frequency 200 --weight-normalization
[INFO:sockeye.utils] Arguments: Namespace(allow_missing_params=False, batch_size=64, batch_type='word', bucket_width=5, checkpoint_frequency=200, cnn_activation_type='glu', cnn_hidden_dropout=0.2, cnn_kernel_width=(3, 3), cnn_num_hidden=512, cnn_positional_embedding_type='learned', cnn_project_qkv=False, config=None, conv_embed_add_positional_encodings=False, conv_embed_dropout=0.0, conv_embed_max_filter_width=8, conv_embed_num_filters=(200, 200, 250, 250, 300, 300, 300, 300), conv_embed_num_highway_layers=4, conv_embed_output_dim=None, conv_embed_pool_stride=5, decode_and_evaluate=500, decode_and_evaluate_device_id=None, decode_and_evaluate_use_cpu=False, decoder='transformer', decoder_only=False, device_ids=[-1], disable_device_locking=False, dry_run=False, embed_dropout=(0.0, 0.0), embed_weight_init='default', encoder='image-pretrain-cnn', extract_image_features=False, fill_up='replicate', fixed_param_names=[], gradient_clipping_threshold=1.0, gradient_clipping_type='none', gradient_compression_threshold=0.5, gradient_compression_type=None, image_encoder_conv_map_size=49, image_encoder_layer='stage4_unit3_conv3', image_encoder_model_epoch=0, image_encoder_model_path='/path/to/mxnet/image/model/', image_encoder_num_hidden=512, image_positional_embedding_type='none', image_preextracted_features=True, initial_learning_rate=0.0003, keep_last_params=-1, kvstore='device', label_smoothing=0.1, layer_normalization=False, learning_rate_decay_optimizer_states_reset='off', learning_rate_decay_param_reset=False, learning_rate_half_life=10, learning_rate_reduce_factor=0.7, learning_rate_reduce_num_not_improved=8, learning_rate_schedule=None, learning_rate_scheduler_type='plateau-reduce', learning_rate_warmup=0, lhuc=None, load_all_features_to_memory=False, lock_dir='/tmp', loss='cross-entropy', loss_normalization_type='valid', max_num_checkpoint_not_improved=32, max_num_epochs=None, max_output_length=None, max_samples=None, max_seq_len=(1, 60), max_updates=None, metrics=['perplexity'], min_num_epochs=None, min_samples=None, min_updates=None, momentum=None, monitor_pattern=None, monitor_stat_func='mx_default', no_bucketing=False, no_image_encoder_global_descriptor=True, num_embed=(512, 512), num_layers=(6, 6), num_words=(0, 0), optimized_metric='perplexity', optimizer='adam', optimizer_params=None, output='models/', overwrite_output=False, pad_vocab_to_multiple_of=None, params=None, prepared_data=None, quiet=False, rnn_attention_coverage_num_hidden=1, rnn_attention_coverage_type='count', rnn_attention_in_upper_layers=False, rnn_attention_mhdot_heads=None, rnn_attention_num_hidden=None, rnn_attention_type='mlp', rnn_attention_use_prev_word=False, rnn_cell_type='lstm', rnn_context_gating=False, rnn_decoder_hidden_dropout=0.2, rnn_decoder_state_init='zero', rnn_dropout_inputs=(0.0, 0.0), rnn_dropout_recurrent=(0.0, 0.0), rnn_dropout_states=(0.0, 0.0), rnn_enc_last_hidden_concat_to_embedding=False, rnn_encoder_reverse_input=False, rnn_first_residual_layer=2, rnn_forget_bias=0.0, rnn_h2h_init='orthogonal', rnn_num_hidden=512, rnn_residual_connections=False, rnn_scale_dot_attention=False, seed=13, shared_vocab=False, source='train_features', source_factor_vocabs=[], source_factors=[], source_factors_num_embed=[], source_root='../../data/image-search/coco/train2014_features', source_vocab=None, target='captions_train2014', target_vocab=None, transformer_activation_type='relu', transformer_attention_heads=(8, 8), transformer_dropout_act=0.1, transformer_dropout_attention=0.1, transformer_dropout_prepost=0.1, transformer_feed_forward_num_hidden=(2048, 2048), transformer_model_size=(512, 512), transformer_positional_embedding_type='fixed', transformer_postprocess=('dr', 'dr'), transformer_preprocess=('n', 'n'), use_cpu=False, validation_source='val_features', validation_source_factors=[], validation_source_root='../../data/image-search/coco/val2014_features', validation_target='captions_val2014', weight_decay=0.0, weight_init='xavier', weight_init_scale=3.0, weight_init_xavier_factor_type='avg', weight_init_xavier_rand_type='uniform', weight_normalization=True, weight_tying=False, weight_tying_type='trg_softmax', word_min_count=(1, 1))
[INFO:__main__] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (2, 61)
[INFO:sockeye.utils] Attempting to acquire 1 GPUs of 1 GPUs. The requested devices are: [-1]
[INFO:sockeye.utils] Acquired GPU master_lock.
[INFO:sockeye.utils] Acquired GPU 0.
[INFO:sockeye.utils] Releasing GPU master_lock.
[INFO:__main__] Training Device(s): gpu(0)
[INFO:sockeye.vocab] Building vocabulary from dataset(s): ['captions_train2014']
[INFO:sockeye.vocab] Vocabulary: types: 19212/19212/19212/19216 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=None]
[INFO:sockeye.image_captioning.data_io] ===============================
[INFO:sockeye.image_captioning.data_io] Creating training data iterator
[INFO:sockeye.image_captioning.data_io] ===============================
[INFO:sockeye.utils] Releasing GPU 0.
[ERROR:__main__] Uncaught exception
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sockeye/image_captioning/train.py", line 392, in &lt;module&gt;
    main()
  File "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sockeye/image_captioning/train.py", line 266, in main
    train(args)
  File "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sockeye/image_captioning/train.py", line 315, in train
    output_folder=output_folder)
  File "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sockeye/image_captioning/train.py", line 168, in create_data_iters_and_vocab
    preload_features=args.load_all_features_to_memory
  File "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sockeye/image_captioning/data_io.py", line 229, in get_training_image_text_data_iters
    target_vocab=vocab_target)
  File "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sockeye/data_io.py", line 618, in get_data_statistics
    buck_idx, buck = get_target_bucket(buckets, len(target))
TypeError: object of type 'NoneType' has no len()
&lt;/denchmark-code&gt;

BTW I'm using EC2 with Deep Learning AMI. I run this command using mxnet_36 virtual env.
		</comment>
		<comment id='7' author='lambdaofgod' date='2018-10-18T09:00:45Z'>
		I couldn't reproduce this error, but I am trying to understand why you get that error.
It looks like target is None, however it shouldn't be empty since you were able to create the vocabulary with the same file captions_train2014 .
It seems that the  is not able to parse correctly the file and the iterator  generates  sentences: &lt;denchmark-link:https://github.com/awslabs/sockeye/blob/master/sockeye/data_io.py#L1091&gt;https://github.com/awslabs/sockeye/blob/master/sockeye/data_io.py#L1091&lt;/denchmark-link&gt;

Can you check if this function is working for you? &lt;denchmark-link:https://github.com/awslabs/sockeye/blob/master/sockeye/data_io.py#L998&gt;https://github.com/awslabs/sockeye/blob/master/sockeye/data_io.py#L998&lt;/denchmark-link&gt;

Maybe put a checkpoint on that line or print the output of .
		</comment>
		<comment id='8' author='lambdaofgod' date='2018-10-18T09:01:34Z'>
		&lt;denchmark-link:https://github.com/tdomhan&gt;@tdomhan&lt;/denchmark-link&gt;
 Any hint?
		</comment>
		<comment id='9' author='lambdaofgod' date='2018-10-19T11:13:11Z'>
		&lt;denchmark-link:https://github.com/lorisbaz&gt;@lorisbaz&lt;/denchmark-link&gt;
 it seems like this function works OK
&lt;denchmark-code&gt;from sockeye import data_io
from itertools import islice

text_file_content = data_io.read_content('captions_train2014')

list(islice(text_file_content, 5))
&lt;/denchmark-code&gt;

Gives
&lt;denchmark-code&gt;[['Closeup',
  'of',
  'bins',
  'of',
  'food',
  'that',
  'include',
  'broccoli',
  'and',
  'bread.'],
 ['A',
  'giraffe',
  'eating',
  'food',
  'from',
  'the',
  'top',
  'of',
  'the',
  'tree.'],
 ['A', 'flower', 'vase', 'is', 'sitting', 'on', 'a', 'porch', 'stand.'],
 ['A',
  'zebra',
  'grazing',
  'on',
  'lush',
  'green',
  'grass',
  'in',
  'a',
  'field.'],
 ['Woman', 'in', 'swim', 'suit', 'holding', 'parasol', 'on', 'sunny', 'day.']]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='lambdaofgod' date='2018-10-22T07:58:11Z'>
		Another reason why  is empty in &lt;denchmark-link:https://github.com/awslabs/sockeye/blob/master/sockeye/data_io.py#L1091&gt;https://github.com/awslabs/sockeye/blob/master/sockeye/data_io.py#L1091&lt;/denchmark-link&gt;

can be because the word is not in the dictionary.
I just saw that you keep the punctuation "." and upper-case, e.g.,  "Woman". You should remove punctuation and lower-case every word. Maybe the problem is due to this.
		</comment>
		<comment id='11' author='lambdaofgod' date='2018-10-23T14:45:45Z'>
		Still doesn't work. I changed input, now the earlier snippet outputs
[['closeup', 'of', 'bins', 'of', 'food', 'that', 'include', 'broccoli', 'and', 'bread'], ['a', 'giraffe', 'eating', 'food', 'from', 'the', 'top', 'of', 'the', 'tree'], ['a', 'flower', 'vase', 'is', 'sitting', 'on', 'a', 'porch', 'stand'], ['a', 'zebra', 'grazing', 'on', 'lush', 'green', 'grass', 'in', 'a', 'field'], ['woman', 'in', 'swim', 'suit', 'holding', 'parasol', 'on', 'sunny', 'day']]
		</comment>
		<comment id='12' author='lambdaofgod' date='2018-10-29T14:43:26Z'>
		You'd probably also want to check the output of  in &lt;denchmark-link:https://github.com/awslabs/sockeye/blob/master/sockeye/data_io.py#L1087&gt;https://github.com/awslabs/sockeye/blob/master/sockeye/data_io.py#L1087&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='lambdaofgod' date='2019-02-24T13:52:05Z'>
		Closing due to inactivity. Feel free to reopen for more questions.
		</comment>
	</comments>
</bug>