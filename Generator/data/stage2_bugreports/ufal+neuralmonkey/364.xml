<bug id='364' author='kocmitom' open_date='2017-03-20T13:57:18Z' closed_time='2018-01-31T11:17:06Z'>
	<summary>report_gpu_memory_consumption=True is broken</summary>
	<description>
This parameter makes training impossible since it only loads model into GPU and then it waits indefinitely.
	</description>
	<comments>
		<comment id='1' author='kocmitom' date='2017-03-21T08:23:15Z'>
		Works for me.
		</comment>
		<comment id='2' author='kocmitom' date='2017-03-24T18:53:01Z'>
		@tomkocmi would you provide more details (e.g. log, config file and commit id?)
		</comment>
		<comment id='3' author='kocmitom' date='2017-03-27T10:52:20Z'>
		we have examined it with &lt;denchmark-link:https://github.com/jlibovicky&gt;@jlibovicky&lt;/denchmark-link&gt;
 ... I have run machine training task config on new monkey (commit from two weeks ago). And it didnt' train and was only in a look. It can be a problem with our architecture, but I am not an expert in it. With Jindra we traced it into a call to the outside of NM.
		</comment>
		<comment id='4' author='kocmitom' date='2017-03-30T16:14:13Z'>
		I have found another clue for this. The problem appears only when the model is too big and cannot get into the GPU. In that case it just freeze instead of falling down.
		</comment>
		<comment id='5' author='kocmitom' date='2017-04-15T18:37:05Z'>
		I would just remove the report_gpu_memory_consumption feature. The memory consumption does not change during training anyway and it makes problem under unknown circumstances.
		</comment>
		<comment id='6' author='kocmitom' date='2017-04-17T20:01:48Z'>
		seconded..
		</comment>
		<comment id='7' author='kocmitom' date='2017-04-18T09:38:15Z'>
		&lt;denchmark-link:https://github.com/obo&gt;@obo&lt;/denchmark-link&gt;
 go for it :D (I myself do not use it and therefore I don't mind removing)
		</comment>
	</comments>
</bug>