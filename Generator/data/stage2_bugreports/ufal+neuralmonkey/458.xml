<bug id='458' author='kocmitom' open_date='2017-06-01T13:21:46Z' closed_time='2018-01-27T21:18:53Z'>
	<summary>At least linear projection automatically reuses variables</summary>
	<description>
Following code will create only two set of variables, one for scope "first", second for scope "second". And none of the asserts will throw exception.
assert not tf.get_variable_scope().reuse
b = linear(a, 600, scope="first")
c = linear(b, 600, scope="second")
d = linear(c, 600, scope="second")
assert not tf.get_variable_scope().reuse
In case that 'c' and 'd' had a different size, it will break on an error similar to this:
Error while loading 'runners': Trying to share variable encoder/input_projection/LinearProjection/LinearProjection/weights, but specified shape (2048, 600) and found shape (2048, 2048).
The variable sharing will hapen no matter of the scope.reuse, which is quite a huge problem. It is either problem with contrib.fully_connected or some weird behavior of TF.
	</description>
	<comments>
		<comment id='1' author='kocmitom' date='2017-06-01T14:25:52Z'>
		Co s touhle issue? Já bych to rovnou zavřel, protože s tím nemůžeme nic dělat kromě toho, že se na to dáme pozor.
		</comment>
		<comment id='2' author='kocmitom' date='2017-06-02T08:49:35Z'>
		Pockej tohle je zasadni problem ... tohle muze rozbijet celou opici, nikde nevis kde vsude tahle chyba nastava dokud se nezjisti, co za ni stoji, to nemusi byt pouze v linear.
		</comment>
		<comment id='3' author='kocmitom' date='2017-06-02T10:50:54Z'>
		jediná rozumná věc, co se s tim dá dělat, je udělat parametr scope funkce linear povinnej. Potom když to dáš dvakrát za sebe se stejnou scope, tak musíš zjistit, jestli to funguje tak, jak má.
		</comment>
		<comment id='4' author='kocmitom' date='2017-06-05T09:32:00Z'>
		No me nejde uplne o tu funkci linear, ale bojim se toho jestli to neni nejake divne chovani TF a tim padem by to mohlo byt i u jinych casti (napriklad konvolucky)
		</comment>
		<comment id='5' author='kocmitom' date='2018-01-27T21:18:53Z'>
		closing as no longer relevant (linear -&gt; tf layers dense)
		</comment>
	</comments>
</bug>