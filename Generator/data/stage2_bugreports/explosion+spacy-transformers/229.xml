<bug id='229' author='justindavies' open_date='2020-11-09T11:51:01Z' closed_time='2020-11-12T06:32:03Z'>
	<summary>Textcat with transformer - IndexError: index out of range in self</summary>
	<description>
With the latest nightly release of spacy and transformers (this also happened with the previous releases) I keep on getting the following error:
File "/anaconda/envs/py37_default/lib/python3.7/site-packages/transformers/modeling_roberta.py", line 68, in forward
input_ids, token_type_ids=token_type_ids, position_ids=position_ids, inputs_embeds=inputs_embeds
File "/anaconda/envs/py37_default/lib/python3.7/site-packages/transformers/modeling_bert.py", line 179, in forward
position_embeddings = self.position_embeddings(position_ids)
File "/anaconda/envs/py37_default/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
result = self.forward(*input, **kwargs)
File "/anaconda/envs/py37_default/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 126, in forward
self.norm_type, self.scale_grad_by_freq, self.sparse)
File "/anaconda/envs/py37_default/lib/python3.7/site-packages/torch/nn/functional.py", line 1852, in embedding
return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
IndexError: index out of range in self
I thought this was initially to do with the fact that my sequences were rather large (over 256 and less than 500 tokens), and have tried to reduce my train and dev datasets but am still receiving the error.
My config is below:
[paths]
train = "corpus/train.spacy"
dev = "corpus/dev.spacy"
raw = null
init_tok2vec = null
vectors = null
[system]
seed = 0
gpu_allocator = null
[corpora]
[corpora.train]
&lt;denchmark-link:https://github.com/readers&gt;@readers&lt;/denchmark-link&gt;
 = "spacy.Corpus.v1"
path = ${paths:train}
gold_preproc = false
max_length = 500
limit = 0
augmenter = null
[corpora.dev]
&lt;denchmark-link:https://github.com/readers&gt;@readers&lt;/denchmark-link&gt;
 = "spacy.Corpus.v1"
path = ${paths.dev}
gold_preproc = ${corpora.train.gold_preproc}
max_length = ${corpora.train.max_length}
limit = 0
augmenter = null
[training]
train_corpus = "corpora.train"
dev_corpus = "corpora.dev"
seed = ${system.seed}
gpu_allocator = ${system.gpu_allocator}
patience = 10000
eval_frequency = 400
dropout = 0.1
max_epochs = 0
max_steps = 0
accumulate_gradient = 3
frozen_components = []
before_to_disk = null
[training.batcher]
@batchers = "spacy.batch_by_sequence.v1"
size = 256
get_length = null
[training.logger]
&lt;denchmark-link:https://github.com/loggers&gt;@loggers&lt;/denchmark-link&gt;
 = "spacy.ConsoleLogger.v1"
progress_bar = true
[training.optimizer]
&lt;denchmark-link:https://github.com/optimizers&gt;@optimizers&lt;/denchmark-link&gt;
 = "Adam.v1"
beta1 = 0.9
beta2 = 0.999
eps = 1e-8
L2_is_weight_decay = true
L2 = 0.01
grad_clip = 1.0
use_averages = false
[training.optimizer.learn_rate]
&lt;denchmark-link:https://github.com/schedules&gt;@schedules&lt;/denchmark-link&gt;
 = "warmup_linear.v1"
warmup_steps = 250
total_steps = 20000
initial_rate = 0.00005
[training.score_weights]
speed = 0
cats_macro_f = 1.0
[components]
[components.transformer]
factory = "transformer"
max_batch_items = 4096
set_extra_annotations = {"@annotation_setters":"spacy-transformers.null_annotation_setter.v1"}
[components.transformer.model]
@architectures = "spacy-transformers.TransformerModel.v1"
name = "roberta-base"
[components.transformer.model.tokenizer_config]
use_fast = true
[components.transformer.model.get_spans]
@span_getters = "spacy-transformers.strided_spans.v1"
window = 128
stride = 96
[components.textcat]
factory = "textcat"
threshold = 0.5
[components.textcat.model]
@architectures = "spacy.TextCatCNN.v1"
exclusive_classes = false
nO = null
[components.textcat.model.tok2vec]
@architectures = "spacy-transformers.TransformerListener.v1"
grad_factor = 1.0
[components.textcat.model.tok2vec.pooling]
&lt;denchmark-link:https://github.com/layers&gt;@layers&lt;/denchmark-link&gt;
 = "reduce_mean.v1"
[nlp]
lang = "en"
pipeline = ["transformer","textcat"]
tokenizer = {"&lt;denchmark-link:https://github.com/Tokenizers&gt;@Tokenizers&lt;/denchmark-link&gt;
":"spacy.Tokenizer.v1"}
disabled = []
before_creation = null
after_creation = null
after_pipeline_creation = null
[pretraining]
[initialize]
vectors = ${paths.vectors}
init_tok2vec = ${paths.init_tok2vec}
vocab_data = null
lookups = null
[initialize.components]
[initialize.tokenizer]
	</description>
	<comments>
		<comment id='1' author='justindavies' date='2020-11-12T06:32:03Z'>
		This was a data issue.  I removed all non-alphanumeric data from my examples and managed to train
		</comment>
		<comment id='2' author='justindavies' date='2020-11-12T22:54:18Z'>
		Thanks for reporting back! This is still a little mysterious to me. I saw the same error message when I tested another issue on CPU today. I also assumed at first (like you) that this is about large sequences, but it looks like certain weird characters cause this instead?
		</comment>
		<comment id='3' author='justindavies' date='2020-11-13T07:14:53Z'>
		I regexed out all non alpha, numeric and spaces and I was able to train on the data. Is there a way to print out the batch on a backtrace so I can see what input is causing this and I can report back?
		</comment>
		<comment id='4' author='justindavies' date='2020-11-13T10:31:04Z'>
		In the &lt;denchmark-link:https://github.com/explosion/spaCy/issues/6321&gt;other issue&lt;/denchmark-link&gt;
, it seems that removing  (or replacing with an actual space) solves things, but I'm not sure whether that's the only outlier case. Any chance you can try on your texts, replace just the  and see if it runs?
		</comment>
	</comments>
</bug>