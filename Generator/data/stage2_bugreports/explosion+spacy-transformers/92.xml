<bug id='92' author='koustuvsinha' open_date='2019-10-22T15:42:48Z' closed_time='2019-10-28T23:20:55Z'>
	<summary>spacy-transformers example throws "IndexError: too many indices for array" error</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

When running the &lt;denchmark-link:https://explosion.ai/blog/spacy-transformers&gt;example provided in the blog post&lt;/denchmark-link&gt;
, the step fails at  with the following error:
&lt;denchmark-code&gt;IndexError                                Traceback (most recent call last)
&lt;ipython-input-7-a409c91815f1&gt; in &lt;module&gt;
----&gt; 1 doc = nlp("Here is some text to encode.")

~/miniconda3/envs/lgw/lib/python3.7/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg)
    436             if not hasattr(proc, "__call__"):
    437                 raise ValueError(Errors.E003.format(component=type(proc), name=name))
--&gt; 438             doc = proc(doc, **component_cfg.get(name, {}))
    439             if doc is None:
    440                 raise ValueError(Errors.E005.format(name=name))

~/miniconda3/envs/lgw/lib/python3.7/site-packages/spacy_transformers/pipeline/tok2vec.py in __call__(self, doc)
    104         self.require_model()
    105         outputs = self.predict([doc])
--&gt; 106         self.set_annotations([doc], outputs)
    107         return doc
    108 

~/miniconda3/envs/lgw/lib/python3.7/site-packages/spacy_transformers/pipeline/tok2vec.py in set_annotations(self, docs, activations)
    196             # to do in one shot without blowing up the memory?
    197             for i, word_piece_slice in enumerate(wp_rows):
--&gt; 198                 doc.tensor[i] = wp_weighted[word_piece_slice].sum(0)
    199             doc.user_hooks["vector"] = get_doc_vector_via_tensor
    200             doc.user_span_hooks["vector"] = get_span_vector_via_tensor

cupy/core/core.pyx in cupy.core.core.ndarray.__getitem__()

cupy/core/_routines_indexing.pyx in cupy.core._routines_indexing._ndarray_getitem()

cupy/core/_routines_indexing.pyx in cupy.core._routines_indexing._prepare_slice_list()

IndexError: too many indices for array
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 2.2.1
Platform: Linux-4.15.0-29-generic-x86_64-with-debian-buster-sid
Python version: 3.7.3

	</description>
	<comments>
		<comment id='1' author='koustuvsinha' date='2019-10-23T11:52:27Z'>
		I've got the same:
&lt;denchmark-code&gt;spacy                           2.2.1           
spacy-transformers              0.5.0
package   en-trf-distilbertbaseuncased-lg   en_trf_distilbertbaseuncased_lg   2.2.0   âœ”
cuda100
python 3.7.4
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='koustuvsinha' date='2019-10-25T14:40:59Z'>
		me too , please can someone help with this error . I cannot run the demo example ???
		</comment>
		<comment id='3' author='koustuvsinha' date='2019-10-28T22:42:38Z'>
		Damn, sorry about that, and thanks for the patch &lt;denchmark-link:https://github.com/ssavvi&gt;@ssavvi&lt;/denchmark-link&gt;
 . Pushing the fix now.
		</comment>
		<comment id='4' author='koustuvsinha' date='2019-10-28T23:20:55Z'>
		Okay, v0.5.1 should be up now.
		</comment>
	</comments>
</bug>