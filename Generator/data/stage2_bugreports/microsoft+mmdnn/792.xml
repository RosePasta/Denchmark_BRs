<bug id='792' author='mciprian13' open_date='2020-02-25T08:12:22Z' closed_time='2020-03-15T23:28:14Z'>
	<summary>[TensorFlow -&amp;gt; ONNX] BiasAdd layer after DepthwiseConv2dNative is ommited</summary>
	<description>
Platform (like ubuntu 16.04/win10): 
Python version: 
Source framework with version (like Tensorflow 1.4.1 with GPU): 
Destination framework with version (like CNTK 2.3 with GPU): 
Pre-trained model path (webpath or webdisk path):
&lt;denchmark-link:https://github.com/ARM-software/ML-KWS-for-MCU/blob/master/Pretrained_models/DS_CNN/DS_CNN_L.pb&gt;https://github.com/ARM-software/ML-KWS-for-MCU/blob/master/Pretrained_models/DS_CNN/DS_CNN_L.pb&lt;/denchmark-link&gt;

Running scripts:
mmconvert                                      --srcFramework tensorflow                    --inputWeight DS_CNN_L.pb                    --inNodeName Reshape_1                       --inputShape 49,10,1                         --dstNodeName labels_softmax                --dstFramework onnx                         --outputModel DS_CNN_L_mmdnn.onnx 
When converting the above model, where the following groups are encountered (TensorFlow pb):
&lt;denchmark-link:https://user-images.githubusercontent.com/29785908/75227380-c17bc580-57b6-11ea-8c0e-cda055d9b4dd.png&gt;&lt;/denchmark-link&gt;

the BiasAdd layer is ommited and the resulting layer is this (ONNX):
&lt;denchmark-link:https://user-images.githubusercontent.com/29785908/75227437-dc4e3a00-57b6-11ea-89c2-81264afc8325.png&gt;&lt;/denchmark-link&gt;

You can see the bias operand of the convolution (B) is missing.
I actually verified the numerical behavior of the resulting ONNX model is NOT correct (using some actual input data and comparing to the original TensorFlow model).
I manually edited the ONNX proto in order to put the missing bias operands, after which the numerical behavior became correct.
	</description>
	<comments>
		<comment id='1' author='mciprian13' date='2020-03-09T03:26:38Z'>
		&lt;denchmark-link:https://github.com/mciprian13&gt;@mciprian13&lt;/denchmark-link&gt;
 , thank you very much for the feedback. We will look into the issue.
		</comment>
		<comment id='2' author='mciprian13' date='2020-03-13T16:29:21Z'>
		&lt;denchmark-link:https://github.com/mciprian13&gt;@mciprian13&lt;/denchmark-link&gt;
 , it seems that function rename_DepthwiseConv2dNative() forgets to handle the BiasAdd. You may take the following workaround:

Go to the installation directory of MMdnn. E.g.  ~/.local/lib/pythonX.Y/site-packages/mmdnn , or /usr/lib/python3/dist-packages/mmdnn
Open file "conversion/tensorflow/tensorflow_frozenparser.py" .
Locate the rename_DepthwiseConv2dNative() function.
Add "self._get_bias(source_node, IR_node)" to the end.

Please have a try and verify whether the issue is fixed.
Thanks.
		</comment>
		<comment id='3' author='mciprian13' date='2020-03-15T23:28:13Z'>
		Fixed in the pull request &lt;denchmark-link:https://github.com/microsoft/MMdnn/pull/800&gt;#800&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>