<bug id='4516' author='natangold85' open_date='2020-07-15T13:50:52Z' closed_time='2020-07-20T15:08:34Z'>
	<summary>loading a model in ort throws error: onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node (Reshape_46) Op (Reshape) [ShapeInferenceError] Invalid position of 0</summary>
	<description>
i'm trying to convert a model from pytorch to onnxruntime. one part of the model is roi align algorithm.
i converted the roi align function to onnx and its also pass onnx.checker.
when i'm trying to load this model using onnxruntime i get this error:
Traceback (most recent call last):
File "/home/vzqgyc/projects/uc_workspace/ultracruise/nn_product/python_converter/roi_align_test.py", line 91, in 
ort_model = onnxruntime.InferenceSession(path)
File "/usr/local/lib/python3.6/dist-packages/onnxruntime/capi/session.py", line 158, in init
self._load_model(providers)
File "/usr/local/lib/python3.6/dist-packages/onnxruntime/capi/session.py", line 177, in _load_model
self._sess.load_model(providers)
onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node (Reshape_29) Op (Reshape) [ShapeInferenceError] Invalid position of 0
i'm on linux os with python 3.6.8, pytorch 1.5, onnx 1.3.0, onnxruntime 1.7.0
this is my roi align class:
`class RoIAlignTensorOpImp(torch.nn.Module):
def init(self, aligned_height, aligned_width, spatial_scale):
super(RoIAlignTensorOpImp, self).init()
&lt;denchmark-code&gt;    self.aligned_width = int(aligned_width)
    self.aligned_height = int(aligned_height)
    self.spatial_scale = float(spatial_scale)

    self.pw_all = torch.arange(self.aligned_width)
    self.ph_all = torch.arange(self.aligned_height)

def get_slice(self, ten: torch.Tensor, n: int, h_idx: torch.Tensor, w_idx: torch.Tensor):
    d4t_tmp = ten[n, :, h_idx, :]
    return d4t_tmp[:, :, :, w_idx]

def forward(self, features: torch.Tensor, rois: torch.Tensor) -&gt; torch.Tensor:
    num_rois = rois.size(0)
    # Number of channels
    channels = features.size(1)

    output = torch.zeros((num_rois, channels, self.aligned_height, self.aligned_width))

    for n in range(num_rois):
        roi_batch_ind = int(rois[n, 0].item())
        roi_start_w = rois[n, 1].item() * self.spatial_scale
        roi_start_h = rois[n, 2].item() * self.spatial_scale
        roi_end_w = rois[n, 3].item() * self.spatial_scale
        roi_end_h = rois[n, 4].item() * self.spatial_scale
        roi_width = max(roi_end_w - roi_start_w, 1.0)
        roi_height = max(roi_end_h - roi_start_h, 1.0)

        bin_size_h = roi_height / float(self.aligned_height)
        bin_size_w = roi_width / float(self.aligned_width)

        hstart = self.ph_all * bin_size_h + roi_start_h
        hend = hstart + bin_size_h

        hsize = (hend - hstart).int()

        hlow_start = hstart.int()
        hhigh_start = hstart.ceil().int()

        wstart = self.pw_all * bin_size_w + roi_start_w
        wend = wstart + bin_size_w
        wsize = (wend - wstart).int()

        wleft_start = wstart.int()
        wright_start = wstart.ceil().int()

        beta = ((wstart - wstart.floor()) / (wstart.ceil() - wstart.floor()))
        beta_nan = ((wstart.ceil() - wstart.floor()) == 0).nonzero().squeeze(0).long()
        beta[beta_nan] = torch.tensor(0.5, dtype=torch.float32)


        alpha = (hstart - hstart.floor()) / (hstart.ceil() - hstart.floor())
        alpha_nan = ((hstart.ceil() - hstart.floor()) == 0).nonzero().squeeze(0).long()
        alpha[alpha_nan.long()] = torch.tensor(0.5, dtype=torch.float32)

        # todo see what needs to do for different sizes of wsize or hsize
        h_base = torch.arange(hsize[0] + 1).unsqueeze(0).repeat(self.aligned_height, 1)
        w_base = torch.arange(wsize[0] + 1).unsqueeze(0).repeat(self.aligned_width, 1)

        hlow_idx = h_base + hlow_start.unsqueeze(1)
        hhigh_idx = h_base + hhigh_start.unsqueeze(1)

        wleft_idx = w_base + wleft_start.unsqueeze(1)
        wright_idx = w_base + wright_start.unsqueeze(1)

        d1_all = self.get_slice(features, roi_batch_ind, hlow_idx, wleft_idx)
        d2_all = self.get_slice(features, roi_batch_ind, hhigh_idx, wleft_idx)
        d3_all = self.get_slice(features, roi_batch_ind, hlow_idx, wright_idx)
        d4_all = self.get_slice(features, roi_batch_ind, hhigh_idx, wright_idx)

        alpha_all = alpha.reshape(1, alpha.size()[0], 1, 1, 1)
        beta_all = beta.reshape(1, 1, 1, beta.size()[0], 1)
        values_all = (1 - alpha_all) * (1 - beta_all) * d1_all + \
                     alpha_all * (1 - beta_all) * d2_all + \
                     (1 - alpha_all) * beta_all * d3_all + \
                     alpha_all * beta_all * d4_all

        out_sum_all = values_all.sum(4).sum(2)
        bin_area = bin_size_h * bin_size_w

        output[n, :, :, :] = out_sum_all / bin_area

    return output`
&lt;/denchmark-code&gt;

and this is the code to convert it and load it:
`width = 7
height = 7
scale = 0.125
roi_align = RoIAlignTensorOpImp(height, width, scale)
features = torch.rand((1,16,96,170))
rois = torch.rand((9,5))
path = "/tmp/t.onnx"
output_keys = ["outputs"]
torch.onnx.export(roi_align, (features, rois), path,
do_constant_folding=False,
opset_version=12,
input_names=["features", "rois"],
output_names=output_keys)
model = onnx.load_model(path)
onnx.shape_inference.infer_shapes(model)
onnx.checker.check_model(model)
print("finish check onnx model")
ort_model = onnxruntime.InferenceSession(path)`
	</description>
	<comments>
		<comment id='1' author='natangold85' date='2020-07-16T18:29:20Z'>
		Can you please attach the onnx model?
		</comment>
		<comment id='2' author='natangold85' date='2020-07-17T04:17:14Z'>
		&lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/4935716/roi_align.zip&gt;roi_align.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='natangold85' date='2020-07-17T07:43:34Z'>
		&lt;denchmark-link:https://github.com/jcwchen&gt;@jcwchen&lt;/denchmark-link&gt;
 can you please take a look? thx.
		</comment>
		<comment id='4' author='natangold85' date='2020-07-18T03:53:07Z'>
		Hi &lt;denchmark-link:https://github.com/natangold85&gt;@natangold85&lt;/denchmark-link&gt;
,
I suppose your environment should be  and ?
I am able to reproduce your error. I think the problem is here:
&lt;denchmark-code&gt;beta[beta_nan] = torch.tensor(0.5, dtype=torch.float32)
# ...
alpha[alpha_nan.long()] = torch.tensor(0.5, dtype=torch.float32)
&lt;/denchmark-code&gt;

Currently using the following code is better:
&lt;denchmark-code&gt;for nan in beta_nan:
  beta[nan] = torch.tensor(0.5, dtype=torch.float32)
# ...
for nan in alpha_nan:
  alpha[nan] = torch.tensor(0.5, dtype=torch.float32)
&lt;/denchmark-code&gt;

After some experiments, I found a gap between pytorch and onnxruntime.
onnxruntime cannot pass this because it does not allow list as index.
In contrast, pytorch and onnx allow list as index, but the graph looks weird to me.
&lt;denchmark-link:https://github.com/pranavsharma&gt;@pranavsharma&lt;/denchmark-link&gt;
 is it true that onnxruntime has this limitation?
If not, the problem is probably on the  side.
BTW, please note that while using , you need to get the inferred model like:
.
&lt;denchmark-link:https://github.com/onnx/onnx/blob/master/docs/PythonAPIOverview.md&gt;https://github.com/onnx/onnx/blob/master/docs/PythonAPIOverview.md&lt;/denchmark-link&gt;
 might be helpful.
		</comment>
		<comment id='5' author='natangold85' date='2020-07-19T05:19:41Z'>
		That's indeed solved the problem. There is still one thing i don't understand.
beta_nan is not a list, its a tensor of type long. as far as i understand this should be supported using it for indexing no?
Another question, after creating an inferred model its better to save it and use it as my onnx model or use pytorch created onnx model?
		</comment>
		<comment id='6' author='natangold85' date='2020-07-19T14:28:49Z'>
		In my experiments, if beta_nan is a tensor of scalar (single value), it can be passed by onnxruntime.
On the contrary, if beta_nan is a tensor of list (like your original code), currently onnxruntime will fail.
I would say feel free to use the inferred model, but please note that shape inference is optional for onnxruntime. You can still use onnxruntime without doing onnx.shape_inference (actually onnxrutime is also doing some shape inference).
		</comment>
		<comment id='7' author='natangold85' date='2020-07-19T14:48:09Z'>
		thanks for the response.
this is how i create beta_nan:
beta_nan = ((wstart.ceil() - wstart.floor()) == 0).nonzero().squeeze(0).long()
beta[beta_nan] = torch.tensor(0.5, dtype=torch.float32)
wstart is float tensor
this is not translated as a tensor of int64?
		</comment>
		<comment id='8' author='natangold85' date='2020-07-19T15:09:57Z'>
		Since wstart is a tensor list of 7 float elements, beta_nan is tensor([], size=(tensor(0), tensor(1)), dtype=torch.int64) instead.
		</comment>
		<comment id='9' author='natangold85' date='2020-07-19T15:29:51Z'>
		what is a tensor list?
i created a tensor with torch.arange() its torch.Tensor.
than multiple it by float and adding float. the result should be torch.Tensor no?
		</comment>
		<comment id='10' author='natangold85' date='2020-07-19T15:39:11Z'>
		Sorry that I might be unclear.
wstart is something like this: tensor([0.0460, 0.1889, 0.3317, 0.4746, 0.6174, 0.7603, 0.9031]). So is self.pw_all by torch.arange.
They are indeed the torch.Tensor, but they are a list (e.g., [1]) intead of a single value (e.g., 1) of torch.Tensor.
		</comment>
		<comment id='11' author='natangold85' date='2020-07-20T03:57:19Z'>
		ok, so tensor of type int64 with size more than 1 cannot be use for indexing. a tensor of bool with the size of the tensor i'm indexing would be ok?
for example:
a = torch.arange(5)
b = a &gt; 2
a[b] = -1
if not, there is any other way to do it without for loops?
		</comment>
		<comment id='12' author='natangold85' date='2020-07-20T15:04:01Z'>
		As far as I know, I am afraid currently there's no such thing...
pytorch itself should allow using list as index. Therefore, this problem is more likely to exist in torch.onnx.export, onnx or onnxruntime. I will update here if I find something useful. Thank you for reporting this.
		</comment>
		<comment id='13' author='natangold85' date='2020-07-20T15:08:34Z'>
		thanks for all the detailed responses
		</comment>
	</comments>
</bug>