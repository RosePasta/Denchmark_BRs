<bug id='1585' author='shirazzaman' open_date='2019-08-08T01:49:52Z' closed_time='2019-09-20T08:49:29Z'>
	<summary>Different results with xgboost and onnxruntime when n_estimators &amp;gt; 1</summary>
	<description>
Describe the bug
Converted a simple (7 float32 predictors) xgboost model to onnx format using onnxmltools.
Loaded the onnx file using onnxruntime and called inference (sess.run) on a test dataframe.
The result from onnxruntime matches original prediction when n_estimators = 1 but widely differs when n_estimators &gt; 1
Urgency
If there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.
none
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.6
ONNX Runtime installed from (source or binary):  python binary (pip install)
ONNX Runtime version: 0.5.0
Python version:   3.6.7
Visual Studio version (if applicable):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

To Reproduce
Describe steps/code to reproduce the behavior:

Generate a random dataframe (i used 1000 records with 7 float32 predictors)
train xgboost.XBRegressor with n_estimators = 2
use onnxmltools.convert_xgboost to convert to onnx format
save the model using onnxmtools.save_model
sess = rt.InferenceSession('onnxg_demo_new.onnx', None)
input_name = sess.get_inputs()[0].name
label_name = sess.get_outputs()[0].name
pred_onx = sess.run([label_name], {input_name: test.to_numpy()})[0]

Expected behavior
A clear and concise description of what you expected to happen.
I printed the prediction from xgboost before converting to onnx format and the score was 0.4967, and i uses sess.run to predict the score with the same test set with onnxruntime and i got 0.5028. I expect the results to be the same if they are same model.
Screenshots
If applicable, add screenshots to help explain your problem.
Additional context
Add any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.
	</description>
	<comments>
		<comment id='1' author='shirazzaman' date='2019-09-18T00:38:49Z'>
		&lt;denchmark-link:https://github.com/onnx/onnx/issues/2228&gt;onnx/onnx#2228&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='shirazzaman' date='2019-09-18T16:42:47Z'>
		&lt;denchmark-link:https://github.com/onnx/onnxmltools/pull/336&gt;onnx/onnxmltools#336&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='shirazzaman' date='2019-09-20T08:49:29Z'>
		Closing this as issue explained in &lt;denchmark-link:https://github.com/onnx/onnx/issues/2228&gt;onnx/onnx#2228&lt;/denchmark-link&gt;
 has been fixed. If you still see the issue related to n_estimators, feel free to reopen the issue with a sample of the script you used.
		</comment>
	</comments>
</bug>