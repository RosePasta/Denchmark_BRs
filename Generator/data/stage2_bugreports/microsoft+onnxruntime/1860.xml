<bug id='1860' author='maxwillzq' open_date='2019-09-17T16:25:51Z' closed_time='2019-10-10T07:16:45Z'>
	<summary>Graph resolve function was fail at vgg19 model</summary>
	<description>

Model is from onnx model zoo: vgg &lt;denchmark-link:https://github.com/onnx/models/tree/master/vision/classification/vgg&gt;https://github.com/onnx/models/tree/master/vision/classification/vgg&lt;/denchmark-link&gt;

The op set version is 7.
I want to use onnxruntime c++ api to do shape inference on this model.  I try 2 ways, both fails
method 1: use resolve function
  string model_path = "./vgg19/model.onnx";  
  std::shared_ptr&lt;onnxruntime::Model&gt; p_model;
  onnxruntime::Model::Load(model_path.c_str(), p_model); 
  auto status = p_model-&gt;MainGraph().Resolve();  	
  if(!status.IsOK()) {
    LOG(ERROR) &lt;&lt; "Graph resolve failed: " &lt;&lt; status.ErrorMessage();
    std::abort();
  }
It will give me error message:
&lt;denchmark-code&gt;Graph resolve failed: This is an invalid model. Error in Node: : No Op registered for Relu with domain_version of 9
&lt;/denchmark-code&gt;

method 2:
I directly to call those functions from onnx lib
  onnx::ModelProto proto = p_model-&gt;ToProto();
  onnx::shape_inference::InferShapes(proto);
It can run through, but no valueInfoProto was generated in modelProto.  Where I can get the generated value info ?
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentoOS
ONNX Runtime installed from (source or binary):  source
ONNX Runtime version:  0.4
Python version:
Visual Studio version (if applicable):
GCC/Compiler version (if compiling from source): gcc 5.4
CUDA/cuDNN version:
GPU model and memory:

	</description>
	<comments>
		<comment id='1' author='maxwillzq' date='2019-09-20T21:47:54Z'>
		Hi,
Can you please try with ORT 0.5.0 ? I don't see why 0.4.0 wouldn't work, but better to try with the latest version.
Based on your info, I downloada the opset 7 version of the model from here (&lt;denchmark-link:https://github.com/onnx/models/tree/master/vision/classification/vgg/vgg19)-&gt;https://github.com/onnx/models/tree/master/vision/classification/vgg/vgg19)-&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/9969784/65360554-2eaa7f80-dbb5-11e9-8347-219e8d591782.png&gt;&lt;/denchmark-link&gt;

I was able to load the model fine using the Python package -
&lt;denchmark-code&gt;import onnxruntime as rt
model = rt.InferenceSession(r'F:\downloads\vgg19\vgg19\model.onnx')
print ("Model loaded successfully")
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='maxwillzq' date='2019-09-20T21:51:40Z'>
		Btw - This was on Windows 10. I don't believe ORT is supported on CentOS. For supported Build platforms/environments, you may please take a look here - &lt;denchmark-link:https://github.com/microsoft/onnxruntime/blob/master/BUILD.md#supported-architectures-and-build-environments&gt;https://github.com/microsoft/onnxruntime/blob/master/BUILD.md#supported-architectures-and-build-environments&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='maxwillzq' date='2019-09-22T04:34:16Z'>
		Have you try c++ version api?
		</comment>
		<comment id='4' author='maxwillzq' date='2019-09-23T19:01:42Z'>
		I believe the Resolve() method is part of the internal class. They are not part of the public API.
Have you tried using the C++ public APIs to load and score the model ?
You may find samples here - &lt;denchmark-link:https://github.com/microsoft/onnxruntime/#cc&gt;https://github.com/microsoft/onnxruntime/#cc&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='maxwillzq' date='2019-10-08T00:39:24Z'>
		&lt;denchmark-link:https://github.com/maxwillzq&gt;@maxwillzq&lt;/denchmark-link&gt;
 do you still need assistance with this issue?
		</comment>
		<comment id='6' author='maxwillzq' date='2019-10-10T07:16:45Z'>
		Closing this out. Please reopen in case you need more clarification, the link shared above contains the sample c++ code needed to load a model.
		</comment>
		<comment id='7' author='maxwillzq' date='2019-10-13T03:15:52Z'>
		
https://github.com/microsoft/onnxruntime/#cc

Could you point which c++ api we can use for shape inference?
		</comment>
	</comments>
</bug>