<bug id='4742' author='tsaizhenling' open_date='2020-08-10T13:16:28Z' closed_time='2020-10-22T04:26:39Z'>
	<summary>Error in Float16 inference</summary>
	<description>
Describe the bug
Error in Float16 inference
Urgency
Float16 deployment is blocked
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
ONNX Runtime installed from (source or binary): binary
ONNX Runtime version: tried both 1.3.0 and 1.4.0
Python version: N/A
Visual Studio version (if applicable): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: CUDA Version 10.2.89 cuDNN 7.6.5
GPU model and memory: GeForce RTX 2070 SUPER 8GB
same observation on xavier nx

To Reproduce
I trained a yolov5s model and exported it to onnx.
This model works fine in full precision.
I am trying to see if we can get inference speed ups on fp16 on gpu
I've converted the model with , and performed some manual neural surgery to make a working model &lt;denchmark-link:&gt;model_fp16.zip&lt;/denchmark-link&gt;

I'm seeing the following errors with linux-gpu-onnxruntime 1.4.0 and 1.3.0
on GPU only:
&lt;denchmark-code&gt;2020-08-10 19:52:33.943355170 [E:onnxruntime:, sequential_executor.cc:281 Execute] Non-zero status code returned while running Resize node. Name:'Resize_164' Status Message: /onnxruntime_src/onnxruntime/core/common/safeint.h:17 static void SafeIntExceptionHandler&lt;onnxruntime::OnnxRuntimeException&gt;::SafeIntOnOverflow() Integer overflow
&lt;/denchmark-code&gt;

^ this happens consistenly only on some inputs, when this error does not occur, output looks sane.
on both GPU and CPU:
&lt;denchmark-code&gt;2020-08-10 12:46:18.486946228 [E:onnxruntime:, sequential_executor.cc:281 Execute] Non-zero status code returned while running Cast node. Name:'Cast_1214' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/cast_op.cc:57 void onnxruntime::CastFloat16Data(const onnxruntime::Tensor*, onnxruntime::Tensor*, const onnxruntime::TensorShape&amp;, const AllocatorPtr&amp;) [with SrcType = long int; DstType = onnxruntime::MLFloat16; onnxruntime::AllocatorPtr = std::shared_ptr&lt;onnxruntime::IAllocator&gt;] len &gt; 0 was false.
&lt;/denchmark-code&gt;

of the 2 errors the first is more serious as the second seems to only happen when there is no predictions
Expected behavior
no errors
	</description>
	<comments>
		<comment id='1' author='tsaizhenling' date='2020-08-10T18:50:57Z'>
		For the first error, I saw that the graph using float16 to manipulate shape:
The logic is like:
new_height = (int64) (float16) ((float16) shape[2] * (float16) 2)
new_width  = (int64) (float16) ((float16) shape[3] * (float16) 2)
If shape[2] is very large (like &gt; 64K), float16 value could be "infinity".
I think it is better to avoid those unnecessary Cast nodes. I think manually restore the subgraph (between LeakyRelu and Concat, use int64 only and not float16) might avoid the issue.
&lt;denchmark-link:https://user-images.githubusercontent.com/30328909/89817338-d77b0980-dafc-11ea-813a-a8fd0a6f24ab.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='tsaizhenling' date='2020-08-11T04:35:59Z'>
		thanks! the original graph had the Casts with full precision. I restored that same behaviour for that part, and the 1st error went away
		</comment>
		<comment id='3' author='tsaizhenling' date='2020-08-11T05:03:13Z'>
		For the second error - do you have an sample input to trigger it ?
		</comment>
		<comment id='4' author='tsaizhenling' date='2020-08-11T07:23:04Z'>
		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
  I can replicate the second error by just passing in all zeros as input
on a side note:
I tried running my new fp16 model with the CUDA execution provider as I do with full precision, and I observe no speedup on my RTX 2070 or on my xavier nx compared to full precision. Should I expect fp16 compute to work out of the box? or am I missing some setting? I am using the c++ API
		</comment>
		<comment id='5' author='tsaizhenling' date='2020-08-12T18:19:46Z'>
		Thanks I ll take a look at the second issue when I get some time.
I see that you have opened another issue for tracking the half precision perf issue.
		</comment>
		<comment id='6' author='tsaizhenling' date='2020-10-12T00:21:55Z'>
		This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.
		</comment>
		<comment id='7' author='tsaizhenling' date='2020-10-22T04:26:35Z'>
		This issue has been automatically closed due to inactivity. Please reactivate if further support is needed.
		</comment>
	</comments>
</bug>