<bug id='1610' author='kzmogi' open_date='2019-08-13T07:14:17Z' closed_time='2019-08-15T18:41:12Z'>
	<summary>In case of batch_index&amp;gt;0, NonMaxSuppression returns unexpected results.</summary>
	<description>
Describe the bug
In case of batch_index&gt;0, NonMaxSuppression returns wrong results.
Urgency
none.
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10 (1803)
ONNX Runtime installed from (source or binary): binary
ONNX Runtime version: 0.5
Python version: 3.6

I saw this behavior in the above environment, but it probably happens in all environment.
To Reproduce
Following python script outputs wrong result.
import sys
import numpy
import onnx
import onnx.helper as oh
import onnxruntime.backend as backend

def test_non_max_suppression() : 

    num_batch = 2
    num_class = 2
    num_box = 5

    # create graph
    nodes = []
    nodes.append(oh.make_node("NonMaxSuppression", ["boxes", "scores", "max_output_per_class"], ["out"]))

    in_tensor = [
        oh.make_tensor_value_info("scores", onnx.TensorProto.FLOAT, [num_batch, num_class, num_box]),
    ]
    boxes_data = numpy.array([[
        # batch_index=0
        [0.0, 0.0, 0.3, 0.3],
        [0.0, 0.0, 0.4, 0.4],
        [0.0, 0.0, 0.5, 0.5],
        [0.5, 0.5, 0.9, 0.9],
        [0.5, 0.5, 1.0, 1.0],
    ],[ # batch_index=1, same data of batch_index==0
        [0.0, 0.0, 0.3, 0.3],
        [0.0, 0.0, 0.4, 0.4],
        [0.0, 0.0, 0.5, 0.5],
        [0.5, 0.5, 0.9, 0.9],
        [0.5, 0.5, 1.0, 1.0],
    ]], dtype=float)
    prm_tensor = [
        oh.make_tensor("boxes", onnx.TensorProto.FLOAT, boxes_data.shape, boxes_data.flatten()),
        oh.make_tensor("max_output_per_class", onnx.TensorProto.INT64, [], [2]),
    ]
    out_tensor = [
        oh.make_tensor_value_info("out", onnx.TensorProto.INT64, ["x", 3]),
    ]

    graph = oh.make_graph(nodes, "test NonMaxSupression", in_tensor, out_tensor, initializer=prm_tensor)

    # create model with graph
    model = oh.make_model(graph)

    # prepare backend
    rt = backend.prepare(model, 'CPU')

    # create input data
    data = numpy.arange(1, num_batch*num_class*num_box+1, dtype=numpy.float32)
    data = numpy.reshape( data, (num_batch, num_class, num_box) )

    # run model 
    out = rt.run(data)

    # show result 
    print('out={}'.format(out))

if __name__ == '__main__' : 
    test_non_max_suppression()
above code outputs following result.
&lt;denchmark-code&gt;out=[array([[0, 0, 4],
       [0, 0, 2],
       [0, 1, 4],
       [0, 1, 2],
       [1, 0, 4],
       [1, 0, 3],
       [1, 1, 4],
       [1, 1, 3]], dtype=int64)]
&lt;/denchmark-code&gt;

both batch_index=0/1 has same input boxes, therefore selected box_indices should be same. however current selected box_indices are difference.
Expected behavior
following is expected output.
&lt;denchmark-code&gt;out=[array([[0, 0, 4],
       [0, 0, 2],
       [0, 1, 4],
       [0, 1, 2],
       [1, 0, 4],
       [1, 0, 2],
       [1, 1, 4],
       [1, 1, 2]], dtype=int64)]
&lt;/denchmark-code&gt;

Cause of this behavior
&lt;denchmark-link:https://github.com/microsoft/onnxruntime/blob/a50a63aa9ee501bbf8236ab44a07d7e53d2cb12b/onnxruntime/core/providers/cpu/object_detection/non_max_suppression.cc#L144&gt;non_max_suppression.cc:(144)&lt;/denchmark-link&gt;

int64_t box_offset = batch_index * pc.num_classes_ * pc.num_boxes_ * 4;
above code seems wrong.  following (remove '* pc.num_classes_') is correct.
int64_t box_offset = batch_index * pc.num_boxes_ * 4;
	</description>
	<comments>
		<comment id='1' author='kzmogi' date='2019-08-14T19:20:31Z'>
		Hi &lt;denchmark-link:https://github.com/kzmogi&gt;@kzmogi&lt;/denchmark-link&gt;
,
Spot on. Thank you :). Fix coming up.
Thanks
EDIT: What were you box scores &lt;denchmark-link:https://github.com/kzmogi&gt;@kzmogi&lt;/denchmark-link&gt;
 ?
		</comment>
	</comments>
</bug>