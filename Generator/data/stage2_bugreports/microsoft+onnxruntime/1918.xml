<bug id='1918' author='samirHED' open_date='2019-09-25T12:42:04Z' closed_time='2019-12-05T20:02:28Z'>
	<summary>Using Onnxruntime on python and with C++ API give different ouput results</summary>
	<description>
Describe the bug
I have transformed a model from keras (with tensorflow as backend) to ONNX. When I am evaluating the '.onnx' model I obtain the same results than using model.predict (keras model). But when using the C++ API the code is running but the ouput results is wrong.
Urgency
Very urgent.
System information

OS Platform and Distribution Linux Ubuntu 18.04)
ONNX Runtime installed from source
ONNX Runtime version:
Python version: 3.6
GCC/Compiler version (if compiling from source): 7.4.0
CUDA/cuDNN version:
GPU model and memory:

To Reproduce
Describe steps/code to reproduce the behavior:
In python I am running this:
&lt;denchmark-code&gt;    x = new_input.astype(np.float32)
    x = x if isinstance(x, list) else [x]
    feed = dict([(input.name, x[n]) for n, input in enumerate(sess.get_inputs())])
    poutNewONNX[count_fr_tot,:] = np.array(sess.run(None, feed))
&lt;/denchmark-code&gt;

The model summary is:
=================================================================
input_10 (InputLayer)        (None, 738, 20)           0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

max_pooling1d_12 (MaxPooling (None, 246, 20)           0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

layer_normalization_12 (Laye (None, 246, 20)           40
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

leaky_re_lu_16 (LeakyReLU)   (None, 246, 20)           0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

conv1d_5 (Conv1D)            (None, 242, 20)           2020
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

max_pooling1d_13 (MaxPooling (None, 80, 20)            0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

layer_normalization_13 (Laye (None, 80, 20)            40
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

leaky_re_lu_17 (LeakyReLU)   (None, 80, 20)            0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

flatten_5 (Flatten)          (None, 1600)              0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

dense_9 (Dense)              (None, 128)               204928
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

batch_normalization_5 (Batch (None, 128)               512
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

leaky_re_lu_18 (LeakyReLU)   (None, 128)               0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

dense_10 (Dense)             (None, 12)                1548
In C++ I have the same input as I have checked but I have two problems:


dim1 = -1 creates a problem; I think that -1 corresponds to None in python and it is used for batch size; but to make the program runs I had to add a workaround and changed dim1 to 1 as follows:
 for (int j = 0; j &lt; input_node_dims.size(); j++) 
 {
     if (input_node_dims[j] == -1) 
     {
         input_node_dims[j] = 1;
     }
     printf("Input %d : dim %d=%jd\n", i, j, input_node_dims[j]);
 }



To make an inference to the model I have the following code:


auto memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);
&lt;denchmark-code&gt;        Ort::Value input_tensor = Ort::Value::CreateTensor&lt;float&gt;(memory_info, input_tensor_values.data(), input_tensor_size,  input_node_dims.data(), 3);
	
        assert(input_tensor.IsTensor());

        // score model &amp; input tensor, get back output tensor
        auto output_tensors =     session.Run(Ort::RunOptions{nullptr}, input_node_names.data(),     &amp;input_tensor, 1, output_node_names.data(), 1);
        assert(output_tensors.size() == 1 &amp;&amp;  output_tensors.front().IsTensor());
	
    
        // Get pointer to output tensor float values
        float *floatarr =  output_tensors.front().GetTensorMutableData&lt;float&gt;();
    cpt++;

        // score the model, and print scores for first 12 classes
        for (int i = 0; i &lt; 12; i++)
        	printf("Score for class [%d] =  %f\n", i, floatarr[i]);
    }
&lt;/denchmark-code&gt;

Which is inspired from &lt;denchmark-link:https://github.com/Microsoft/onnxruntime/blob/master/csharp/test/Microsoft.ML.OnnxRuntime.EndToEndTests.Capi/CXX_Api_Sample.cpp&gt;https://github.com/Microsoft/onnxruntime/blob/master/csharp/test/Microsoft.ML.OnnxRuntime.EndToEndTests.Capi/CXX_Api_Sample.cpp&lt;/denchmark-link&gt;
.
The code is running but the ouput is wrong while in python it is correct.
Can I get some help for this issue? Is someone else facing with the same problem.
Thanks
	</description>
	<comments>
		<comment id='1' author='samirHED' date='2019-10-31T21:41:22Z'>
		

dim1 = -1 creates a problem; I think that -1 corresponds to None in python and it is used for batch size; but to make the program runs I had to add a workaround and changed dim1 to 1 as follows:


The dimension value in the model and the input are two different things.
In the model a symbolic dimension (e.g. the batch size dimension) will not have a concrete value. It could have a name, or nothing other than an empty entry to indicate the rank. The actual value is not known until an inference is run and the input for that inference is received.
When you're creating input to run the model however that input does have a concrete value (as you have the actual input data with a known size) for the dimension, so using -1 is not valid.
Are the dimension values for the actual input created in python the same as in C++?
		</comment>
		<comment id='2' author='samirHED' date='2019-11-18T12:43:38Z'>
		&lt;denchmark-link:https://github.com/samirHED&gt;@samirHED&lt;/denchmark-link&gt;
 do you still need help with this? if so, can you please provide the clarifications mentioned above?
		</comment>
		<comment id='3' author='samirHED' date='2019-12-05T20:02:28Z'>
		Closing this out. Please re-open if you need more help. Thanks!
		</comment>
	</comments>
</bug>