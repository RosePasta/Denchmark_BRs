<bug id='3372' author='zjd1988' open_date='2020-03-31T03:36:40Z' closed_time='2020-04-08T05:58:33Z'>
	<summary>use onnx shape_inference.infer_shapes check model success,but use onnxruntime-gpu InferenceSession check model fail</summary>
	<description>
Describe the bug
A clear and concise description of what the bug is.
when I use onnx shape_inference.infer_shapes to check model（opset 11） success,but use onnxruntime-gpu InferenceSession to check model fail.
Urgency
If there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04
ONNX Runtime installed from (source or binary): pip install
ONNX Runtime version:1.2
Python version:3.5.2
Visual Studio version (if applicable):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:10.1/7.6
GPU model and memory:

To Reproduce

Describe steps/code to reproduce the behavior.
Attach the ONNX model to the issue (where applicable) to expedite investigation.

import onnxruntime
import numpy as np
import datetime
session = onnxruntime.InferenceSession("./model.onnx")
session.get_modelmeta()
first_input_name = session.get_inputs()[0].name
indata1 = np.random.random((1,721,1281,1)).astype(np.float32)
starttime = datetime.datetime.now()
for i in range(500):
print("index {}\n".format(i))
results = session.run([], {first_input_name : indata1})
print("results num is {}".format(len(results)))
endtime = datetime.datetime.now()
print((endtime - starttime).seconds)
Expected behavior
A clear and concise description of what you expected to happen.
Screenshots
If applicable, add screenshots to help explain your problem.

&lt;denchmark-link:https://user-images.githubusercontent.com/7134030/77984316-d2829e00-7343-11ea-9da6-e8effc2e7e80.png&gt;&lt;/denchmark-link&gt;

Add any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.
	</description>
	<comments>
		<comment id='1' author='zjd1988' date='2020-03-31T23:28:52Z'>
		Is the model shareable ? Does the model load in the CPU version of Onnxruntime ?
		</comment>
		<comment id='2' author='zjd1988' date='2020-04-01T02:47:15Z'>
		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
  Thans for your reply. My model is large than 10M .so I have to tail my model and then upload it. Besides i have not test my model in cpu version.
		</comment>
		<comment id='3' author='zjd1988' date='2020-04-01T03:28:08Z'>
		Hi &lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
  , I have tail my model, you can test it.
&lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/4412623/model.tar.gz&gt;model.tar.gz&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='zjd1988' date='2020-04-07T01:54:26Z'>
		Hi,
I took a look at this model. The model seems strange. It has  couple of 'pad' nodes which by definition need to have atleast 2 inputs - (&lt;denchmark-link:https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad&gt;https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad&lt;/denchmark-link&gt;
). But, it only has one input which is 'data'. I inspected the GraphProto and the Pad nodes actually have 2 inputs in the NodeProto inputs field but the second input doesn't seem to be an initializer or an output from another node. Even in netron, it seems to ignore the second input as it is not an initializer nor an output of another node.
&lt;denchmark-link:https://user-images.githubusercontent.com/9969784/78621519-a8474980-7837-11ea-8237-f5a8e733d1c3.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/9969784/78621540-b4330b80-7837-11ea-9f4a-f51ba6ff10ff.png&gt;&lt;/denchmark-link&gt;

Can you check with the producer of the model about this peculiarity ? By definition, this is an invalid model if Pad doesn't have atleast 2 inputs. (Not sure why ONNX doesn't reject this model and performs shape inference, that is another aspect to be investigated).
		</comment>
		<comment id='5' author='zjd1988' date='2020-04-07T06:03:49Z'>
		Hi &lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
 ,appreciate it. I have checked that link &lt;denchmark-link:https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad&gt;https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad&lt;/denchmark-link&gt;

in opset11 pad op need 2~3 inputs, data and pads
&lt;denchmark-link:https://user-images.githubusercontent.com/7134030/78635085-f744bb80-78d7-11ea-991a-3fcc91f39430.png&gt;&lt;/denchmark-link&gt;

while in opset 2 pad op need 1 input "data", "pads" was given by attribute
&lt;denchmark-link:https://user-images.githubusercontent.com/7134030/78635173-2d823b00-78d8-11ea-9c36-4f106aca52c6.png&gt;&lt;/denchmark-link&gt;

So, I think that tf2onnx tool cause the pad op did not works very well.
		</comment>
		<comment id='6' author='zjd1988' date='2020-04-07T06:08:37Z'>
		Yes, that was exactly my thoughts as well. I immediately checked if it had the attributes. It doesn’t have any attributes as well. So, we can’t even hand-compute the output shape as we don’t know the pads.
The other mystery is why (and how) does shape inference even run in this model ? Seems like this is an ONNX issue (not an ORT issue).
Can you check with tf2onnx please ? I am guessing once the Pad node is fixed, things should run smoothly.
		</comment>
		<comment id='7' author='zjd1988' date='2020-04-07T06:10:39Z'>
		Also the fact that the NodeProto itself has 2 input names but the fact that the second input isn’t findable points to a conversion issue. But I am really stumped as to why shape inference even gets to the final stage.
		</comment>
		<comment id='8' author='zjd1988' date='2020-04-07T06:11:35Z'>
		Hi &lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
 ,thanks again. I will check tf2onnx tool source code lately.
		</comment>
		<comment id='9' author='zjd1988' date='2020-04-07T06:19:22Z'>
		hi &lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
 . I have checked this link &lt;denchmark-link:https://github.com/onnx/tensorflow-onnx/blob/master/support_status.md&gt;https://github.com/onnx/tensorflow-onnx/blob/master/support_status.md&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/7134030/78636360-c3b76080-78da-11ea-8efe-5d3c93acfe72.png&gt;&lt;/denchmark-link&gt;

tf2onnx doesn't support PAD(opset 11).
		</comment>
		<comment id='10' author='zjd1988' date='2020-04-07T06:22:20Z'>
		Sorry &lt;denchmark-link:https://github.com/zjd1988&gt;@zjd1988&lt;/denchmark-link&gt;
  - I spoke too soon - I found the pads in the initializers (previously I was looking in the wrong field for initializers). The reason why it doesn't show up in netron is that it seems to contain raw bytes. I ll dig a little bit more into this.
		</comment>
		<comment id='11' author='zjd1988' date='2020-04-07T06:45:22Z'>
		
hi @hariharans29 . I have checked this link https://github.com/onnx/tensorflow-onnx/blob/master/support_status.md

tf2onnx doesn't support PAD(opset 11).

Oh, I see. Can you try converting to opset-10 and then try loading again ?
		</comment>
		<comment id='12' author='zjd1988' date='2020-04-07T06:46:57Z'>
		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
  I have installed netron, and check the model and turn out that tf2onnx tool works well.
&lt;denchmark-link:https://user-images.githubusercontent.com/7134030/78638173-6b825d80-78de-11ea-8048-bd3a91623300.png&gt;&lt;/denchmark-link&gt;

it's wired!!!
		</comment>
		<comment id='13' author='zjd1988' date='2020-04-07T07:39:10Z'>
		Hi, I ll have some findings by tomorrow.
		</comment>
		<comment id='14' author='zjd1988' date='2020-04-08T05:58:33Z'>
		Hi,
I figured this one out. Details below -
I think the problem is with the Pad values are not what they are meant to be -
&lt;denchmark-link:https://user-images.githubusercontent.com/9969784/78749084-60512100-7922-11ea-97c7-0907f962e6c7.png&gt;&lt;/denchmark-link&gt;

The clue comes from the third pad value from the end and the fact that shape inference error message which claims that a dimension is off by 1. That dimension corresponds to the channel dimension (please see Pad spec and the input to the Pad node and you' ll understand). Usually, the channel dimension is not padded and only the feature dimensions are padded, so I would expect the pad values to be [0, 0, 0, 0, 0, 0, 1, 1] so in the model I swapped the values of the second last and the value before it and the new model loaded fine with no errors.
If you see below - the original model 'model.onnx' fails to load with a message similar to your screenshot (I think the difference is because you just shared the tail model) and the 'new_model.onnx' loads without error.
&lt;denchmark-link:https://user-images.githubusercontent.com/9969784/78749369-f2f1c000-7922-11ea-8d9b-5bf46bc70e61.png&gt;&lt;/denchmark-link&gt;

This is how I mutated your model. Remember that the value is a raw little endian raw byte string (i.e.)  there are 8 * 8 bytes (since each is int64 val) and I swapped out the penultimate 8 bytes with the 8 bytes before it and added it back to the initializer.
&lt;denchmark-code&gt;import onnx

model = onnx.load(r'model.onnx')

graph = model.graph

initializers = graph.initializer
for init in initializers:
	if "depthwise_pad__38" in init.name:
		init.raw_data = b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00'
		break

onnx.save_model(model, r'new_model.onnx')
&lt;/denchmark-code&gt;

I think this is a conversion bug (Not sure if you can report it to tf2onnx as they never claimed support for Pad opset 11). Closing this out as this is not an ORT issue. Thanks!
		</comment>
		<comment id='15' author='zjd1988' date='2020-04-08T06:32:25Z'>
		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
  appreciate it. I think you are right, I will check the tf2onnx code lately.
		</comment>
	</comments>
</bug>