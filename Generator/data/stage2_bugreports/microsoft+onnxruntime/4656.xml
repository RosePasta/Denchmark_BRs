<bug id='4656' author='xkszltl' open_date='2020-07-29T10:49:01Z' closed_time='2020-12-21T01:56:54Z'>
	<summary>CUDA test hang without GPU.</summary>
	<description>
Describe the bug
AllocatorTest.CUDAAllocatorTest hangs forever if build machine does not have GPU available (but with CUDA toolchain installed).
I think in this case CUDA test should be skipped or at least failed, hanging is not the right way.
&lt;denchmark-code&gt;[----------] 5 tests from AllocatorTest
[ RUN      ] AllocatorTest.CPUAllocatorTest
[       OK ] AllocatorTest.CPUAllocatorTest (0 ms)
[ RUN      ] AllocatorTest.MakeUniquePtrTest
[       OK ] AllocatorTest.MakeUniquePtrTest (0 ms)
[ RUN      ] AllocatorTest.TestOverflowChecks
2020-07-29 10:33:20.7040916 [E:onnxruntime:Default, allocator.cc:28 onnxruntime::IAllocator::CalcMemSizeForArrayWithAlignment] D:\roaster-scratch\onnxruntime\onnxruntime\core/common/safeint.h:17 SafeIntExceptionHandler&lt;class onnxruntime::OnnxRuntimeException&gt;::SafeIntOnOverflow Integer overflow

2020-07-29 10:33:20.7048544 [E:onnxruntime:Default, allocator.cc:28 onnxruntime::IAllocator::CalcMemSizeForArrayWithAlignment] D:\roaster-scratch\onnxruntime\onnxruntime\core/common/safeint.h:17 SafeIntExceptionHandler&lt;class onnxruntime::OnnxRuntimeException&gt;::SafeIntOnOverflow Integer overflow

2020-07-29 10:33:20.7055700 [E:onnxruntime:Default, allocator.cc:28 onnxruntime::IAllocator::CalcMemSizeForArrayWithAlignment] D:\roaster-scratch\onnxruntime\onnxruntime\core/common/safeint.h:17 SafeIntExceptionHandler&lt;class onnxruntime::OnnxRuntimeException&gt;::SafeIntOnOverflow Integer overflow

2020-07-29 10:33:20.7063018 [E:onnxruntime:Default, allocator.cc:28 onnxruntime::IAllocator::CalcMemSizeForArrayWithAlignment] D:\roaster-scratch\onnxruntime\onnxruntime\core/common/safeint.h:17 SafeIntExceptionHandler&lt;class onnxruntime::OnnxRuntimeException&gt;::SafeIntOnOverflow Integer overflow

[       OK ] AllocatorTest.TestOverflowChecks (3 ms)
[ RUN      ] AllocatorTest.CUDAAllocatorTest
&lt;/denchmark-code&gt;

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win Server 2019
ONNX Runtime installed from (source or binary): source
ONNX Runtime version: 1.4.0
Python version: 3.8.5
Visual Studio version (if applicable): 2019
CUDA/cuDNN version: 11.0 (10.2 also have this issue)
GPU model and memory: N/A

	</description>
	<comments>
		<comment id='1' author='xkszltl' date='2020-07-30T04:22:05Z'>
		Isn't this somewhat equivalent to cross-compiling? You're building something that can't run on the current machine.
Is there a viable way to detect this scenario from a unit test?
Even if there is a way, having to update lots of tests to handle this sort of thing doesn't really add value to the product.
You can skip the tests by passing the --skip_tests flag to the build script.
		</comment>
		<comment id='2' author='xkszltl' date='2020-07-31T15:39:57Z'>
		We do rely on unit test to make sure our build quality is good and no missing dll dependency.
I understand your point, but we don't want to skip CPU test as well when building CUDA.
Since GPU is pluggable device, should any CUDA test start with a cudaGetDevice(), also to set the correct device id?
		</comment>
		<comment id='3' author='xkszltl' date='2020-07-31T15:45:59Z'>
		Also, to clarify, the problematic part is not "it doesn't work", but "it doesn't quit".
IMO even segfault is a test result.
		</comment>
		<comment id='4' author='xkszltl' date='2020-07-31T23:53:07Z'>
		So, you're saying, you build onnxruntime with CUDA, then run it on a machine with CUDA installed, but without Nvidia driver because the machine doesn't have the hardware, and you expect when you run the tests they should pass?
		</comment>
		<comment id='5' author='xkszltl' date='2020-08-01T01:29:46Z'>
		No, I said they can fail, but not hang.
		</comment>
		<comment id='6' author='xkszltl' date='2020-08-03T22:09:40Z'>
		I did a build on a VM with no CUDA device (Ubuntu 18.04) and the test fails for me with a reasonable error message. Not sure why it hangs for you.
I tested with CUDA 10.2 with CUDNN 7.6.5 installed.

[ RUN      ] AllocatorTest.CUDAAllocatorTest
unknown file: Failure
C++ exception with description "/home/scott/src/github/onnxruntime/onnxruntime/core/providers/cuda/cuda_call.cc:123 bool onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true] /home/scott/src/github/onnxruntime/onnxruntime/core/providers/cuda/cuda_call.cc:117 bool onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true] CUDA failure 100: no CUDA-capable device is detected ; GPU=0 ; hostname=Ubuntu1804 ; expr=cuda_err;

		</comment>
		<comment id='7' author='xkszltl' date='2020-08-05T14:55:55Z'>
		Are you testing master or 1.4.0?
On Windows I get this from other tests, but not AllocatorTest.CUDAAllocatorTest
&lt;denchmark-code&gt;Provider:CUDAExecutionProvider
unknown file: error: C++ exception with description "D:\roaster-scratch\onnxruntime\onnxruntime\core\providers\cuda\cuda_call.cc:123 onnxruntime::CudaCall D:\roaster-scratch\onnxruntime\onnxruntime\core\providers\cuda\cuda_call.cc:117 onnxruntime::CudaCall CUDA failure 35: CUDA driver version is insufficient for CUDA runtime version ; GPU=-679215104 ; hostname=Roaster-Win ; expr=cudaSetDevice(device_id_);

" thrown in the test body.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='xkszltl' date='2020-08-05T14:56:47Z'>
		And that's the only one hang.
		</comment>
		<comment id='9' author='xkszltl' date='2020-08-05T21:13:55Z'>
		Are you able to step through AllocatorTest.CUDAAllocatorTest in a debugger (can be done via Test Explorer) and identify the call where it hangs?
		</comment>
		<comment id='10' author='xkszltl' date='2020-08-06T23:34:59Z'>
		Not really....RDP experience from China to Azure VM is too bad recently...
		</comment>
		<comment id='11' author='xkszltl' date='2020-08-21T09:10:25Z'>
		&lt;denchmark-link:https://github.com/skottmckay&gt;@skottmckay&lt;/denchmark-link&gt;

I got a stack trace on Linux about where is hang:
&lt;denchmark-code&gt;root@64e141d47b68:/tmp/scratch/onnxruntime/build#  gdb --ex 'r' --args ./onnxruntime_test_all --gtest_filter='AllocatorTest.CUDAAllocatorTest'
GNU gdb (Ubuntu 8.1-0ubuntu3.2) 8.1.0.20180409-git
Copyright (C) 2018 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
&lt;http://www.gnu.org/software/gdb/bugs/&gt;.
Find the GDB manual and other documentation resources online at:
&lt;http://www.gnu.org/software/gdb/documentation/&gt;.
For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from ./onnxruntime_test_all...done.
Starting program: /tmp/scratch/onnxruntime/build/onnxruntime_test_all --gtest_filter=AllocatorTest.CUDAAllocatorTest
warning: Error disabling address space randomization: Operation not permitted
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Note: Google Test filter = AllocatorTest.CUDAAllocatorTest
[==========] Running 1 test from 1 test suite.
[----------] Global test environment set-up.
[----------] 1 test from AllocatorTest
[ RUN      ] AllocatorTest.CUDAAllocatorTest
^C
Program received signal SIGINT, Interrupt.
0x00007fda9d3ab412 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
(gdb) bt
#0  0x00007fda9d3ab412 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#1  0x00007fda9d3ab469 in std::locale::locale() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#2  0x00007fda9d3a8d8b in std::ios_base::_M_init() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#3  0x00007fda9d3fdf11 in std::basic_ios&lt;char, std::char_traits&lt;char&gt; &gt;::init(std::basic_streambuf&lt;char, std::char_traits&lt;char&gt; &gt;*) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#4  0x000055b05832fc7e in std::__cxx11::basic_ostringstream&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::basic_ostringstream (__mode=std::_S_out, this=0x7fffdaa6b580, __in_chrg=&lt;optimized out&gt;, __vtt_parm=&lt;optimized out&gt;)
    at /usr/include/c++/8/bits/char_traits.h:287
#5  onnxruntime::OnnxRuntimeException::OnnxRuntimeException (this=0x55b05e561ea0, location=..., failed_condition=0x0, 
    msg="../onnxruntime/core/providers/cuda/cuda_call.cc:117 bool onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true] CUDA failure 35: CU"...)
    at ../include/onnxruntime/core/common/exceptions.h:44
#6  0x000055b05894cf55 in onnxruntime::OnnxRuntimeException::OnnxRuntimeException (
    msg="../onnxruntime/core/providers/cuda/cuda_call.cc:117 bool onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true] CUDA failure 35: CU"..., location=..., this=0x55b05e561ea0)
    at ../include/onnxruntime/core/common/exceptions.h:31
#7  onnxruntime::CudaCall&lt;cudaError, true&gt; (retCode=&lt;optimized out&gt;, exprString=exprString@entry=0x55b05959bb71 "cudaMalloc((void**)&amp;p, size)", libName=libName@entry=0x55b0594bcfde "CUDA", successCode=successCode@entry=cudaSuccess, 
    msg=msg@entry=0x55b059671b29 "") at ../onnxruntime/core/providers/cuda/cuda_call.cc:123
#8  0x000055b058949209 in onnxruntime::CUDAAllocator::Alloc (this=&lt;optimized out&gt;, size=2304) at ../onnxruntime/core/providers/cuda/cuda_allocator.cc:40
#9  0x000055b0591ded66 in onnxruntime::BFCArena::&lt;lambda(size_t)&gt;::operator() (__closure=&lt;synthetic pointer&gt;, alloc_bytes=2304) at /usr/include/c++/8/bits/unique_ptr.h:345
#10 onnxruntime::BFCArena::Extend(unsigned long) () at ../onnxruntime/core/framework/bfc_arena.cc:140
#11 0x000055b0591e47ef in onnxruntime::BFCArena::AllocateRawInternal(unsigned long, bool) () at ../onnxruntime/core/framework/bfc_arena.cc:267
#12 0x000055b05842a3ed in onnxruntime::test::AllocatorTest_CUDAAllocatorTest_Test::TestBody() () at /usr/include/c++/8/bits/shared_ptr_base.h:1018
#13 0x00007fda9db7452a in testing::internal::HandleSehExceptionsInMethodIfSupported&lt;testing::Test, void&gt; (location=0x7fda9db75992 "the test body", method=&lt;optimized out&gt;, object=0x55b05e55dd00) at ../googletest/src/gtest.cc:2414
#14 testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test, void&gt; (object=object@entry=0x55b05e55dd00, method=&lt;optimized out&gt;, location=location@entry=0x7fda9db75992 "the test body") at ../googletest/src/gtest.cc:2469
#15 0x00007fda9db6a3a3 in testing::Test::Run (this=0x55b05e55dd00) at ../googletest/src/gtest.cc:2508
#16 testing::Test::Run (this=0x55b05e55dd00) at ../googletest/src/gtest.cc:2498
#17 0x00007fda9db6a505 in testing::TestInfo::Run (this=0x55b05e23cfd0) at ../googletest/src/gtest.cc:2684
#18 testing::TestInfo::Run (this=0x55b05e23cfd0) at ../googletest/src/gtest.cc:2657
#19 0x00007fda9db6a5e5 in testing::TestSuite::Run (this=0x55b05e23bb60) at ../googletest/src/gtest.cc:2816
#20 testing::TestSuite::Run (this=0x55b05e23bb60) at ../googletest/src/gtest.cc:2795
#21 0x00007fda9db6ab03 in testing::internal::UnitTestImpl::RunAllTests() () at /usr/include/c++/8/bits/stl_vector.h:930
#22 0x00007fda9db6ad21 in testing::internal::HandleSehExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt; (location=0x7fda9db77be0 "auxiliary test code (environments or event listeners)", method=&lt;optimized out&gt;, object=0x55b05e21e1f0)
    at ../googletest/src/gtest.cc:2414
#23 testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt; (location=0x7fda9db77be0 "auxiliary test code (environments or event listeners)", 
    method=(bool (testing::internal::UnitTestImpl::*)(testing::internal::UnitTestImpl * const)) 0x7fda9db6a680 &lt;testing::internal::UnitTestImpl::RunAllTests()&gt;, object=0x55b05e21e1f0) at ../googletest/src/gtest.cc:2469
#24 testing::UnitTest::Run() () at ../googletest/src/gtest.cc:4925
#25 0x000055b0582f00e6 in RUN_ALL_TESTS () at /usr/local/include/gtest/gtest.h:2473
#26 main () at ../onnxruntime/test/providers/test_main.cc:50
#27 0x00007fda9c97fb97 in __libc_start_main (main=0x55b0582f0060 &lt;main&gt;, argc=2, argv=0x7fffdaa6c5d8, init=&lt;optimized out&gt;, fini=&lt;optimized out&gt;, rtld_fini=&lt;optimized out&gt;, stack_end=0x7fffdaa6c5c8) at ../csu/libc-start.c:310
#28 0x000055b0583130fa in _start () at /usr/include/c++/8/bits/char_traits.h:322
&lt;/denchmark-code&gt;

And from cuda-gdb:
&lt;denchmark-code&gt;root@64e141d47b68:/tmp/scratch/onnxruntime/build# cuda-gdb --ex 'r' --args ./onnxruntime_test_all --gtest_filter='AllocatorTest.CUDAAllocatorTest'
NVIDIA (R) CUDA Debugger
11.0 release
Portions Copyright (C) 2007-2020 NVIDIA Corporation
GNU gdb (GDB) 8.2
Copyright (C) 2018 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type "show copying" and "show warranty" for details.
This GDB was configured as "x86_64-pc-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
&lt;http://www.gnu.org/software/gdb/bugs/&gt;.
Find the GDB manual and other documentation resources online at:
    &lt;http://www.gnu.org/software/gdb/documentation/&gt;.

For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from ./onnxruntime_test_all...done.
Starting program: /tmp/scratch/onnxruntime/build/onnxruntime_test_all --gtest_filter=AllocatorTest.CUDAAllocatorTest
warning: Error disabling address space randomization: Operation not permitted
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
Note: Google Test filter = AllocatorTest.CUDAAllocatorTest
[==========] Running 1 test from 1 test suite.
[----------] Global test environment set-up.
[----------] 1 test from AllocatorTest
[ RUN      ] AllocatorTest.CUDAAllocatorTest
^C
Program received signal SIGINT, Interrupt.
0x00007f5324ab7f28 in ?? () from /lib/x86_64-linux-gnu/libc.so.6
(cuda-gdb) bt
#0  0x00007f5324ab7f28 in ?? () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f53253fa51b in std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::find(char const*, unsigned long, unsigned long) const () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#2  0x000055586901bb58 in std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::find (__pos=0, __s=0x55586a4472c5 "cudaMalloc", this=0x7fff23fba8a0) at /usr/include/c++/8/bits/char_traits.h:322
#3  onnxruntime::BFCArena::&lt;lambda(size_t)&gt;::operator() (__closure=&lt;synthetic pointer&gt;, alloc_bytes=2304) at ../onnxruntime/core/framework/bfc_arena.cc:90
#4  onnxruntime::BFCArena::Extend (this=0x55586fedf7f0, rounded_bytes=1024) at ../onnxruntime/core/framework/bfc_arena.cc:140
#5  0x0000555869fd77ef in onnxruntime::BFCArena::AllocateRawInternal (this=0x55586fedf7f0, num_bytes=1024, dump_log_on_failure=&lt;optimized out&gt;) at ../onnxruntime/core/framework/bfc_arena.cc:267
#6  0x000055586921d3ed in onnxruntime::test::AllocatorTest_CUDAAllocatorTest_Test::TestBody (this=&lt;optimized out&gt;) at /usr/include/c++/8/bits/shared_ptr_base.h:1018
#7  0x00007f5325b4352a in testing::internal::HandleSehExceptionsInMethodIfSupported&lt;testing::Test, void&gt; (location=0x7f5325b44992 "the test body", method=&lt;optimized out&gt;, object=0x55586fedbd00) at ../googletest/src/gtest.cc:2414
#8  testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test, void&gt; (object=object@entry=0x55586fedbd00, method=&lt;optimized out&gt;, location=location@entry=0x7f5325b44992 "the test body") at ../googletest/src/gtest.cc:2469
#9  0x00007f5325b393a3 in testing::Test::Run (this=0x55586fedbd00) at ../googletest/src/gtest.cc:2508
#10 testing::Test::Run (this=0x55586fedbd00) at ../googletest/src/gtest.cc:2498
#11 0x00007f5325b39505 in testing::TestInfo::Run (this=0x55586fbbafd0) at ../googletest/src/gtest.cc:2684
#12 testing::TestInfo::Run (this=0x55586fbbafd0) at ../googletest/src/gtest.cc:2657
#13 0x00007f5325b395e5 in testing::TestSuite::Run (this=0x55586fbb9b60) at ../googletest/src/gtest.cc:2816
#14 testing::TestSuite::Run (this=0x55586fbb9b60) at ../googletest/src/gtest.cc:2795
#15 0x00007f5325b39b03 in testing::internal::UnitTestImpl::RunAllTests (this=0x55586fb9c1f0) at /usr/include/c++/8/bits/stl_vector.h:930
#16 0x00007f5325b39d21 in testing::internal::HandleSehExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt; (location=0x7f5325b46be0 "auxiliary test code (environments or event listeners)", method=&lt;optimized out&gt;, object=0x55586fb9c1f0)
    at ../googletest/src/gtest.cc:2414
#17 testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt; (location=0x7f5325b46be0 "auxiliary test code (environments or event listeners)", 
    method=(bool (testing::internal::UnitTestImpl::*)(class testing::internal::UnitTestImpl * const)) 0x7f5325b39680 &lt;testing::internal::UnitTestImpl::RunAllTests()&gt;, object=0x55586fb9c1f0) at ../googletest/src/gtest.cc:2469
#18 testing::UnitTest::Run (this=0x7f5325d58100 &lt;testing::UnitTest::GetInstance()::instance&gt;) at ../googletest/src/gtest.cc:4925
#19 0x00005558690e30e6 in RUN_ALL_TESTS () at /usr/local/include/gtest/gtest.h:2473
#20 main (argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;) at ../onnxruntime/test/providers/test_main.cc:50
(cuda-gdb) 
&lt;/denchmark-code&gt;

It ends up at different places every time so probably something is slowly moving forward (or trapped in a infinite loop).
		</comment>
		<comment id='12' author='xkszltl' date='2020-08-21T14:31:05Z'>
		Here's where it is after several hours:
&lt;denchmark-code&gt;#0  0x00007fa29f8af87d in ?? () from /lib/x86_64-linux-gnu/libgcc_s.so.1
#1  0x00007fa29f8b0440 in ?? () from /lib/x86_64-linux-gnu/libgcc_s.so.1
#2  0x00007fa29f8b198b in _Unwind_RaiseException () from /lib/x86_64-linux-gnu/libgcc_s.so.1
#3  0x00007fa29fee9d47 in __cxa_throw () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#4  0x00005601359a5f8e in onnxruntime::CudaCall&lt;cudaError, true&gt; (retCode=&lt;optimized out&gt;, exprString=exprString@entry=0x5601365f4b71 "cudaMalloc((void**)&amp;p, size)", libName=libName@entry=0x560136515fde "CUDA", 
    successCode=successCode@entry=cudaSuccess, msg=msg@entry=0x5601366cab29 "") at /usr/include/c++/8/ext/new_allocator.h:86
#5  0x00005601359a2209 in onnxruntime::CUDAAllocator::Alloc (this=&lt;optimized out&gt;, size=2304) at ../onnxruntime/core/providers/cuda/cuda_allocator.cc:40
#6  0x0000560136237d66 in onnxruntime::BFCArena::&lt;lambda(size_t)&gt;::operator() (__closure=&lt;synthetic pointer&gt;, alloc_bytes=2304) at /usr/include/c++/8/bits/unique_ptr.h:345
#7  onnxruntime::BFCArena::Extend (this=0x56013b1a37f0, rounded_bytes=1024) at ../onnxruntime/core/framework/bfc_arena.cc:140
#8  0x000056013623d7ef in onnxruntime::BFCArena::AllocateRawInternal (this=0x56013b1a37f0, num_bytes=1024, dump_log_on_failure=&lt;optimized out&gt;) at ../onnxruntime/core/framework/bfc_arena.cc:267
#9  0x00005601354833ed in onnxruntime::test::AllocatorTest_CUDAAllocatorTest_Test::TestBody (this=&lt;optimized out&gt;) at /usr/include/c++/8/bits/shared_ptr_base.h:1018
#10 0x00007fa2a06c652a in testing::internal::HandleSehExceptionsInMethodIfSupported&lt;testing::Test, void&gt; (location=0x7fa2a06c7992 "the test body", method=&lt;optimized out&gt;, object=0x56013b19fd00) at ../googletest/src/gtest.cc:2414
#11 testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test, void&gt; (object=object@entry=0x56013b19fd00, method=&lt;optimized out&gt;, location=location@entry=0x7fa2a06c7992 "the test body") at ../googletest/src/gtest.cc:2469
#12 0x00007fa2a06bc3a3 in testing::Test::Run (this=0x56013b19fd00) at ../googletest/src/gtest.cc:2508
#13 testing::Test::Run (this=0x56013b19fd00) at ../googletest/src/gtest.cc:2498
#14 0x00007fa2a06bc505 in testing::TestInfo::Run (this=0x56013ae7efd0) at ../googletest/src/gtest.cc:2684
#15 testing::TestInfo::Run (this=0x56013ae7efd0) at ../googletest/src/gtest.cc:2657
#16 0x00007fa2a06bc5e5 in testing::TestSuite::Run (this=0x56013ae7db60) at ../googletest/src/gtest.cc:2816
#17 testing::TestSuite::Run (this=0x56013ae7db60) at ../googletest/src/gtest.cc:2795
#18 0x00007fa2a06bcb03 in testing::internal::UnitTestImpl::RunAllTests (this=0x56013ae601f0) at /usr/include/c++/8/bits/stl_vector.h:930
#19 0x00007fa2a06bcd21 in testing::internal::HandleSehExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt; (location=0x7fa2a06c9be0 "auxiliary test code (environments or event listeners)", method=&lt;optimized out&gt;, object=0x56013ae601f0)
    at ../googletest/src/gtest.cc:2414
#20 testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl, bool&gt; (location=0x7fa2a06c9be0 "auxiliary test code (environments or event listeners)", 
    method=(bool (testing::internal::UnitTestImpl::*)(class testing::internal::UnitTestImpl * const)) 0x7fa2a06bc680 &lt;testing::internal::UnitTestImpl::RunAllTests()&gt;, object=0x56013ae601f0) at ../googletest/src/gtest.cc:2469
#21 testing::UnitTest::Run (this=0x7fa2a08db100 &lt;testing::UnitTest::GetInstance()::instance&gt;) at ../googletest/src/gtest.cc:4925
#22 0x00005601353490e6 in RUN_ALL_TESTS () at /usr/local/include/gtest/gtest.h:2473
#23 main (argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;) at ../onnxruntime/test/providers/test_main.cc:50

&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='xkszltl' date='2020-12-14T08:30:21Z'>
		I hit the same issue, the test case hang in AllocatorTest.CUDAAllocatorTest.
Machine Environment:

OS: Windows Server 2019, OS Build 177763
VM size: DS12v3 (No GPU avaliable)
Source commit: 718ca7f
VS: VS2019 Community Edition
CUDA: CUDA v11.1 installed

Here's my call stack:
&lt;denchmark-code&gt;&gt;	onnxruntime_test_all.exe!`onnxruntime::CudaCall&lt;enum cudaError,1&gt;'::`1'::catch$57() Line 123	C++
 	[External Code]	
 	onnxruntime_test_all.exe!onnxruntime::CudaCall&lt;enum cudaError,1&gt;(cudaError retCode, const char * exprString, const char * libName, cudaError successCode, const char * msg) Line 117	C++
 	onnxruntime_test_all.exe!onnxruntime::CUDAAllocator::Alloc(unsigned __int64 size) Line 42	C++
 	onnxruntime_test_all.exe!onnxruntime::BFCArena::Extend::__l2::&lt;lambda&gt;(unsigned __int64 alloc_bytes) Line 89	C++
 	onnxruntime_test_all.exe!onnxruntime::BFCArena::Extend(unsigned __int64 rounded_bytes) Line 150	C++
 	onnxruntime_test_all.exe!onnxruntime::BFCArena::AllocateRawInternal(unsigned __int64 num_bytes, bool) Line 277	C++
 	onnxruntime_test_all.exe!onnxruntime::test::AllocatorTest_CUDAAllocatorTest_Test::TestBody() Line 28	C++
 	onnxruntime_test_all.exe!testing::internal::HandleSehExceptionsInMethodIfSupported&lt;testing::TestSuite,void&gt;(testing::TestSuite * object, void(testing::TestSuite::*)() method, const char * location) Line 2418	C++
 	onnxruntime_test_all.exe!testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::Test,void&gt;(testing::Test * object, void(testing::Test::*)() method, const char * location) Line 2469	C++
 	onnxruntime_test_all.exe!testing::Test::Run() Line 2515	C++
 	onnxruntime_test_all.exe!testing::TestInfo::Run() Line 2687	C++
 	onnxruntime_test_all.exe!testing::TestSuite::Run() Line 2815	C++
 	onnxruntime_test_all.exe!testing::internal::UnitTestImpl::RunAllTests() Line 5337	C++
 	onnxruntime_test_all.exe!testing::internal::HandleSehExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl,bool&gt;(testing::internal::UnitTestImpl * object, bool(testing::internal::UnitTestImpl::*)()) Line 2418	C++
 	onnxruntime_test_all.exe!testing::internal::HandleExceptionsInMethodIfSupported&lt;testing::internal::UnitTestImpl,bool&gt;(testing::internal::UnitTestImpl * object, bool(testing::internal::UnitTestImpl::*)()) Line 2469	C++
 	onnxruntime_test_all.exe!testing::UnitTest::Run() Line 4925	C++
 	[Inline Frame] onnxruntime_test_all.exe!RUN_ALL_TESTS() Line 2473	C++
 	onnxruntime_test_all.exe!main(int argc, char * * argv) Line 67	C++

&lt;/denchmark-code&gt;

		</comment>
		<comment id='14' author='xkszltl' date='2020-12-14T14:27:59Z'>
		Some update:
The test is stuck in this line of code:



onnxruntime/onnxruntime/core/providers/cuda/cuda_call.cc


         Line 117
      in
      156368b






 ORT_THROW(str); 





And this issue only repos for Release build, Debug build works fine.
		</comment>
		<comment id='15' author='xkszltl' date='2020-12-15T02:45:44Z'>
		Found the root cause:


BFCArena has the logic to swallow exception from a failed cudaMalloc call:



onnxruntime/onnxruntime/core/framework/bfc_arena.cc


        Lines 96 to 103
      in
      9810b9e






 // swallow if exception is our throw from a failed cudaMalloc call. 



 // re-throw otherwise. 



 ORT_HANDLE_EXCEPTION([&amp;ort_exception]() { 



 if (std::string(ort_exception.what()).find("cudaMalloc") == std::string::npos &amp;&amp; 



 std::string(ort_exception.what()).find("hipMalloc") == std::string::npos) { 



     ORT_RETHROW; 



   } 



 }); 







BFCArena has the retry logic on memory allocation failure:



onnxruntime/onnxruntime/core/framework/bfc_arena.cc


        Lines 145 to 151
      in
      9810b9e






 while (mem_addr == nullptr) { 



   bytes = RoundedBytes(static_cast&lt;size_t&gt;(bytes * kBackpedalFactor)); 



 if (bytes &lt; rounded_bytes) 



 break; 



 



   mem_addr = safe_alloc(bytes); 



 } 







In Debug Build, exception throws in CUDAAllocator::CheckDevice. However, in Release Build, it simply does nothing.



onnxruntime/onnxruntime/core/providers/cuda/cuda_allocator.cc


        Lines 19 to 33
      in
      9810b9e






 void CUDAAllocator::CheckDevice(bool throw_when_fail) const { 



 #ifndef NDEBUG 



 // check device to match at debug build 



 // if it's expected to change, call cudaSetDevice instead of the check 



 int current_device; 



 auto cuda_err = cudaGetDevice(&amp;current_device); 



 if (cuda_err == cudaSuccess) { 



 ORT_ENFORCE(current_device == Info().id); 



   } else if (throw_when_fail) { 



 CUDA_CALL_THROW(cuda_err); 



   } 



 #else 



 ORT_UNUSED_PARAMETER(throw_when_fail); 



 #endif 



 } 







		</comment>
		<comment id='16' author='xkszltl' date='2020-12-15T03:11:48Z'>
		&lt;denchmark-link:https://github.com/skottmckay&gt;@skottmckay&lt;/denchmark-link&gt;
 , any suggestion to fix this issue?
		</comment>
		<comment id='17' author='xkszltl' date='2020-12-15T05:27:55Z'>
		In normal usage the CUDA Execution Provider calls cudaSetDevice in its ctor before creating the CUDA Allocator so this prevents the issue. In the test we don't go through that path, so the simplest may be to call cudaSetDevice in the unit test and check that is successful before proceeding.
		</comment>
		<comment id='18' author='xkszltl' date='2020-12-15T06:31:07Z'>
		
In normal usage the CUDA Execution Provider calls cudaSetDevice in its ctor before creating the CUDA Allocator so this prevents the issue. In the test we don't go through that path, so the simplest may be to call cudaSetDevice in the unit test and check that is successful before proceeding.

Thanks! I have submitted a PR according to your suggestion.
		</comment>
		<comment id='19' author='xkszltl' date='2020-12-15T17:20:17Z'>
		&lt;denchmark-link:https://github.com/toothache&gt;@toothache&lt;/denchmark-link&gt;
 Thanks a lot! Finally this issue can be fixed.
&lt;denchmark-link:https://github.com/skottmckay&gt;@skottmckay&lt;/denchmark-link&gt;
 Do you know why it is disabled with ? Does this check has noticeable performance impact?
		</comment>
		<comment id='20' author='xkszltl' date='2020-12-15T21:46:52Z'>
		Sorry - I don't know the history. It looks like a check that the device doesn't change unexpectedly, and may not even be needed at all. &lt;denchmark-link:https://github.com/KeDengMS&gt;@KeDengMS&lt;/denchmark-link&gt;
 might know more.
		</comment>
		<comment id='21' author='xkszltl' date='2020-12-15T23:18:06Z'>
		If I read the thread correctly, it seems the problem is inside BFC arena when it assumes all cudaMalloc failure to be OOM and keeps shrink size and retry. IMO, a better fix would be changing BFC arena to check exactly OOM failures if possible.
Adding CheckDevice for NDEBUG should not add too much overhead, as most allocations are in BFC arena, but we'd better have some tests to confirm.
		</comment>
		<comment id='22' author='xkszltl' date='2020-12-16T01:44:09Z'>
		&lt;denchmark-link:https://github.com/KeDengMS&gt;@KeDengMS&lt;/denchmark-link&gt;
 I don't think we should get to the point where the BFCArena is created with a CUDA allocator if there's no CUDA device, so I would prefer not to make any check there more expensive. The issue only occurred in a unit test as BFCArena was being tested directly without checking there was a CUDA device first.
My question was more about whether we need CheckDevice at all. Assumably the assert there doesn't fire in any CI runs so the device isn't changing unexpectedly there. Not sure if when we test with multiple GPUs that we run models in parallel using multiple CUDA EPs tied to different devices in order to check that the cudaSetDevice call in CUDAExecutionProvider::OnRunStart doesn't break an existing concurrent run using a different device. That said, if unexpected device changes was a real problem I would have expected to have seen it show up in Issues.
		</comment>
		<comment id='23' author='xkszltl' date='2020-12-16T01:59:00Z'>
		The current behavior of BFC arena could be faulty in large scale distributed training if there's hardware failure, where error from cudaMalloc is ignored and the code keeps trying. We probably have been lucky not hitting hang in cudaMalloc though.
As for CheckDevice, I checked the history and didn't find any issues associated with it. However, most of our tests are single GPU with release build, so the error probably won't trigger. cudaSetDevice could be called from user thread, and if there's no much cost of enabling it for Release (as most allocation is from BFC arena), maybe we should consider enable it for all builds.
		</comment>
		<comment id='24' author='xkszltl' date='2020-12-16T03:46:45Z'>
		The code retries with a backoff in the requested size until it fails to allocate the originally requested size, so it should in general cope with a hardware failure.
The unit test hangs because of the unusually small requested allocation size of 1024 bytes. Usually the arena grows in chunks of 1MB or more that are then split up so we would typically get a much larger requested allocation.
&lt;denchmark-code&gt;  static constexpr float kBackpedalFactor = 0.9f;
  // Try allocating less memory.
  while (mem_addr == nullptr) {
    bytes = RoundedBytes(static_cast&lt;size_t&gt;(bytes * kBackpedalFactor));
    if (bytes &lt; rounded_bytes)
      break;

    mem_addr = safe_alloc(bytes);
  }
&lt;/denchmark-code&gt;

When the requested bytes is so small, the backpedal of 10% results in a reduction that is undone by the rounding to a 256 byte boundary in RoundedBytes when bytes is reduced to 2304.
I'll send a PR to address that edge case.
		</comment>
		<comment id='25' author='xkszltl' date='2020-12-21T01:56:54Z'>
		Closing as I believe the root issue (BFCArena allocation backoff hit inifinite loop) and related issue (attempting to test CUDA allocator on machine with no CUDA device) are both fixed.
		</comment>
		<comment id='26' author='xkszltl' date='2020-12-22T19:52:28Z'>
		I also got the same problem when I was building an ONNXRuntime Docker container. I guess it is not a good idea to turn on the test during the Docker image building process.
		</comment>
	</comments>
</bug>