<bug id='5646' author='amanpreet692' open_date='2020-10-30T12:01:10Z' closed_time='2020-11-30T20:13:37Z'>
	<summary>Runtime error when converting T5 decoder with multiple dynamic axes inputs</summary>
	<description>
Describe the bug
I have been trying to convert a T5 model. The encoder works as expected but decoder expects two inputs:
i) encoder states (Works fine)
ii) past states from each layer(This is a list(12)-&gt;tuple(4)-&gt;Tensor collection which is converted into 48 separate inputs.  A similar structure is output as well which works fine but input is causing the problem.
On running inference, get the following error:
[E:onnxruntime:, sequential_executor.cc:318 Execute] Non-zero status code returned while running Transpose node.
Name:'Transpose_207' Status Message: /Users/runner/work/1/s/onnxruntime/core/framework/op_kernel.cc:62 
OrtValue *onnxruntime::OpKernelContext::OutputMLValue(int, const onnxruntime::TensorShape &amp;, size_t) status.IsOK() was false. 
Shape mismatch attempting to re-use buffer. {1,12,64,2} != {1,12,64,933}. 
Validate usage of dim_value (values should be &gt; 0) and dim_param (all values with the same string should equate 
to the same size) in shapes in the model.
Model definition:
    input_ids = torch.tensor([[42] * 10])
    past_state_input_pre = torch.rand((1,12,1,64))
    past_state_input_post = torch.rand((1, 12, 10, 64))
    past_key_value_states = [(past_state_input_pre, past_state_input_pre, past_state_input_post, past_state_input_post) for i in range(12)]

    past_val_outputs = {'past_states_op_'+str(i): {0:'batch', 2: 'sequence'} for i in range(48)}
    past_val_inputs = {'past_states_ip' + str(i): {0: 'batch', 2: 'sequence'} for i in range(48)}
    dynamix_axes_dict = {
                              'input_ids': {0:'batch', 1: 'sequence'},
                              'encoder_hidden_states': {0:'batch', 1: 'sequence'}
                            }
    dynamix_axes_dict.update(past_val_inputs)
    dynamix_axes_dict.update({'logits': {0:'batch', 1: 'sequence'}})
    dynamix_axes_dict.update(past_val_outputs)
    output_names_list = ['logits'] + ['past_states_op_' + str(i) for i in range(48)]
    input_names_list = ['input_ids', 'encoder_hidden_states'] + ['past_states_ip' + str(i) for i in range(48)]
    # Exports to ONNX
    _ = torch.onnx.export(
                            decoder_with_lm_head,
                            (torch.tensor([[42]]), simplified_encoder(input_ids), past_key_value_states),
                                   f"{output_prefix}-decoder-with-lm-head.onnx",
                                   export_params=True,
                            opset_version=12,
                            input_names=input_names_list,
                            output_names=output_names_list,
                            dynamic_axes= dynamix_axes_dict, do_constant_folding=False, verbose=True)
Please let me know if I am missing anything. Sharing the model file as
Urgency
None
System information

OS Platform and Distribution Mac 10.15.7:
ONNX Runtime installed from (source or binary): pip
ONNX Runtime version: 1.4.0
Python version: 3.7
Visual Studio version (if applicable): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: &gt;10 (inferring on CPU though)
GPU model and memory: N/A

To Reproduce


Describe steps/code to reproduce the behavior.
Passing the input while running inference:
i) 2-d tensor with 1 element eg. [[42]]
ii) 3-d tensor with shape (1,sequence, 768)
iii) past_state_input_pre = torch.rand((1,12,1,64))
past_state_input_post = torch.rand((1, 12, 10, 64))
48 tensors using the above with a sequence of 2 past_state_input_pre, 2 past_state_input_post


Attach the ONNX model to the issue (where applicable) to expedite investigation.
Model
Expected behavior
Should get back 2 outputs: logits of shape (batch, sequence, 32168), 48 tensors with shapes as above


Screenshots
If applicable, add screenshots to help explain your problem.

Model:  &lt;denchmark-link:https://huggingface.co/t5-base&gt;T5- HuggingFace&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='amanpreet692' date='2020-11-04T05:23:44Z'>
		&lt;denchmark-link:https://github.com/wangyems&gt;@wangyems&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tianleiwu&gt;@tianleiwu&lt;/denchmark-link&gt;
 , please help to take a look.
		</comment>
		<comment id='2' author='amanpreet692' date='2020-11-04T07:13:30Z'>
		Thank you for picking it up...plz post here if more info is needed from my end!
		</comment>
		<comment id='3' author='amanpreet692' date='2020-11-15T19:08:43Z'>
		Guys, any updates? We have been stuck on this for a while now.
		</comment>
		<comment id='4' author='amanpreet692' date='2020-11-16T19:36:34Z'>
		Hi &lt;denchmark-link:https://github.com/amanpreet692&gt;@amanpreet692&lt;/denchmark-link&gt;
, sorry for the late response. I just took a quick look at your attached model and I didn't see the problematic node "Transpose_207" in that model which cause the runtime error. Could you check if the uploaded model is the one you ran inference upon?
		</comment>
		<comment id='5' author='amanpreet692' date='2020-11-16T20:15:12Z'>
		Hey &lt;denchmark-link:https://github.com/wangyems&gt;@wangyems&lt;/denchmark-link&gt;
 thanks for getting back.
With the uploaded model I get the following error:
onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero 

status code returned while running Transpose node. Name:'Transpose_216' Status Message: 

/Users/runner/work/1/s/onnxruntime/core/framework/op_kernel.cc:62 OrtValue 

*onnxruntime::OpKernelContext::OutputMLValue(int, const onnxruntime::TensorShape &amp;, size_t) status.IsOK() was false. 

Shape mismatch attempting to re-use buffer. {5,12,64,2} != {5,12,64,933}. Validate usage of dim_value (values should be &gt; 0) 

and dim_param (all values with the same string should equate to the same size) in shapes in the model.
Transpose_216 should be present in the model. Hope this helps!
		</comment>
		<comment id='6' author='amanpreet692' date='2020-11-18T03:18:06Z'>
		Hi &lt;denchmark-link:https://github.com/amanpreet692&gt;@amanpreet692&lt;/denchmark-link&gt;
, the transpose node looks good to me as it requires the correct shape from the input. How is your ort_inputs organized? Could you provide the part of code that you run inference so that I can investigate further?
		</comment>
		<comment id='7' author='amanpreet692' date='2020-11-18T05:28:08Z'>
		Hey &lt;denchmark-link:https://github.com/wangyems&gt;@wangyems&lt;/denchmark-link&gt;
, thanks for checking that!
This is the inference code:
past_state_list = []
[past_state_list.extend(list(tup)) for tup in past_key_value_states] #past_key_value_states is the input here
past_state_list = [tensor.numpy() for tensor in past_state_list]
input_dict = {"input_ids": input_ids[:, -1:].cpu().numpy(), "encoder_hidden_states": 
encoder_hidden_states.cpu().numpy()}
input_names = decoder_sess.get_inputs()   #decoder_sess is the InferenceSession object
input_dict.update({input_names[i+2].name:past_state_list[i] for i in range(len(past_state_list))})
decoder_outputs = decoder_sess.run(None, input_dict)
You can use the following pickle file as sample input for the encoder_hidden_states and past_key_value_states:
&lt;denchmark-link:https://drive.google.com/file/d/1tSvd7RkZC9YtOr-gI4hifwWQfaHDwsV9/view?usp=sharing&gt;sample encoder_hidden_states&lt;/denchmark-link&gt;

&lt;denchmark-link:https://drive.google.com/file/d/1FfuAk83UbuDmHTsc_6__wv-FhmkI2fIY/view?usp=sharing&gt;sample past_key_value_states&lt;/denchmark-link&gt;

Let me know if anything else is needed.
		</comment>
		<comment id='8' author='amanpreet692' date='2020-11-18T19:49:24Z'>
		Thank you for providing the code &lt;denchmark-link:https://github.com/amanpreet692&gt;@amanpreet692&lt;/denchmark-link&gt;
. After looking at the way you preparing the input, I think the cause is that the input shape is not align with what onnx model requires. e.g. There are a couple of inputs that require float32[batch, 12, sequence, 64], you need to make sure that the actual inputs share the same batch number and sequence number. This seems not a framework issue.
		</comment>
		<comment id='9' author='amanpreet692' date='2020-11-20T21:22:44Z'>
		Hey &lt;denchmark-link:https://github.com/wangyems&gt;@wangyems&lt;/denchmark-link&gt;
 Thanks again for checking.
Can you please elaborate a bit on your investigation? coz I am still confused as to what's wrong here.
If you look @ the input shapes in the errors, {5,12,64,2} != {5,12,64,933}, here when passing the inputs the shapes are actually {5,12,2,64} and {5,12,933,64}. My assumption was that due to the transpose operation the shapes are re-arranged and as mentioned in the error a buffer with the previously used shape is attempted to be re-used which is causing the error.
Is that not so?
		</comment>
		<comment id='10' author='amanpreet692' date='2020-11-20T23:59:01Z'>
		Hi &lt;denchmark-link:https://github.com/amanpreet692&gt;@amanpreet692&lt;/denchmark-link&gt;
, According to your code given &lt;denchmark-link:https://github.com/microsoft/onnxruntime/issues/5646#issue-733116902&gt;here&lt;/denchmark-link&gt;
, the inputs do not have the same sequence value, they are sometimes 1 and others are 10. If you fix this, the buffer reuse issue may still occur but it's non-blocking. It may be due to that your model have some initializers serving as both input and output. Please check if your model looks as you expected.
		</comment>
		<comment id='11' author='amanpreet692' date='2020-11-21T08:35:14Z'>
		Ok, but that is the reason the sequence values have been declared in dynamic axis because the sequence shape is not fixed. I am afraid I am nt aware of any other way to prevent/fix this. It would be great if you could point me in the right direction. The same thing works while getting the output btw.
Thanks
		</comment>
		<comment id='12' author='amanpreet692' date='2020-11-26T00:59:59Z'>
		Hey &lt;denchmark-link:https://github.com/wangyems&gt;@wangyems&lt;/denchmark-link&gt;
, I was able to get this to work today by removing the 48 numpy arrays from dynamic axes along with their output names as it didn't seem to matter if I mentioned dynamic axes for the output or not.
But every 3rd and 4th of those output nodes were being used again as input nodes(presumably due to same values) and their shape was not being considered as dynamic. This is all a theory which might actually point to a bug in the exporting code where the output shape doesn't matter for dynamic axes.
It would be great if you could comment on this!
Thanks
		</comment>
		<comment id='13' author='amanpreet692' date='2020-11-30T20:13:37Z'>
		Hi &lt;denchmark-link:https://github.com/amanpreet692&gt;@amanpreet692&lt;/denchmark-link&gt;
, great to hear that you made it work. The concept of dynamic axis is like a variable - any inputs shapes that use this variable will share the same value during inferencing. So if those values are not the same then the dynamic variable shall not be considered. Regarding your export question, you may want to take a look at &lt;denchmark-link:https://pytorch.org/docs/stable/onnx.html&gt;https://pytorch.org/docs/stable/onnx.html&lt;/denchmark-link&gt;
 and see if it answers your question.
		</comment>
	</comments>
</bug>