<bug id='2247' author='mgkeeley' open_date='2019-10-24T03:54:16Z' closed_time='2019-10-31T17:12:00Z'>
	<summary>ReduceMin/ReduceMax do not reduce axes on Cuda provider</summary>
	<description>
Describe the bug
When using the Reduce operators (e.g. ReduceMin) with no axes sepcified, and keep_dims==0, the dimensions of the input tensor are not reduced when running via the Cuda provider.  If the exact same Onnx model is used with the CPU provider, the axes are reduced as expected.
Urgency
A workaround is possible: instead of
m = data.min()
you can write
m, _ = data.view(-1).min(dim = 0, keepdim = True)
System information

OS Platform and Distribution: Windows 7 x64
ONNX Runtime installed from: NuGet (C#)
ONNX Runtime version: 0.5.0, 0.5.1
Python version: 3.7
Visual Studio version (if applicable): 2019 (16.3.1)
CUDA/cuDNN version: 10.0
GPU model and memory: RTX 2080 Ti

To Reproduce

Create a pytorch model that uses the .min() operator on a tensor with more than one dimension
data = torch.randn(2, 2) data_min = data.min()
Export the model to onnx, import in OnnxRuntime for C#
Run the model via CPU e.g.
new InferenceSession(pathToOnnxFile, SessionOptions.Default);
Check the output is a single scalar tensor.
Run the model via GPU e.g.
new InferenceSession(pathToOnnxFile, SessionOptions.MakeSessionOptionWithCudaProvider());
The output has the same dimensions as the input

Expected behavior
The results should be the same for both providers; and the number of dimensions should be reduced.
Additional context
I'm not a CUDA programmer, but looking at the code in 


onnxruntime/onnxruntime/core/providers/cuda/reduction/reduction_ops.cc


         Line 91
      in
      90858b7






 squeezed_output_dims.push_back(input_dims[i]); 




 it seems the reduced dimensions are correctly calculated from output_dims and stored in squeezed_output_dims, but then later, these reduced dimensions are ignored when creating the output tensor 


onnxruntime/onnxruntime/core/providers/cuda/reduction/reduction_ops.cc


         Line 109
      in
      90858b7






 std::vector&lt;int64_t&gt; output_dims_cudnn = output_dims; 





	</description>
	<comments>
		<comment id='1' author='mgkeeley' date='2019-10-25T20:58:31Z'>
		Hello,
I tried to repro this in current master but couldn't repro it. (I ll check to see if there was a fix committed for this since 0.5.0/0.5.1).
Since we didn't have a case covering this exact combination, I added some tests in &lt;denchmark-link:https://github.com/microsoft/onnxruntime/pull/2268&gt;#2268&lt;/denchmark-link&gt;
 (reduce on default axes (all axes) with keep_dims == 0) and the result was a scalar as you correctly described. These tests pass for the CUDA EP.
Also,



onnxruntime/onnxruntime/core/providers/cuda/reduction/reduction_ops.cc


         Line 95
      in
      90858b7






 Tensor* Y = ctx-&gt;Output(0, TensorShape(squeezed_output_dims)); 




, we do create an output tensor using the correct dims (squeezed_output_dims as you rightly pointed out).
Please let me know if I have made a mistake. You can check one of the tests added.
		</comment>
		<comment id='2' author='mgkeeley' date='2019-10-25T22:57:48Z'>
		OK, let me make a minimal reproduction my side, I will attach it here. Thanks for your time.
		</comment>
		<comment id='3' author='mgkeeley' date='2019-10-25T23:32:00Z'>
		See attached for a python script that reproduces the issue my side.
Also the min.onnx file that has the issue.
&lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/3774136/onnx-reduce.zip&gt;onnx-reduce.zip&lt;/denchmark-link&gt;

Output:
&lt;denchmark-code&gt;Onnx info:
ir_version = 4
producer_name = pytorch
producer_version = 1.2
opset_import = [version: 9
]
Onnx graph:
graph torch-jit-export (
  %input[FLOAT, batchxheight]
) {
  %minimum = ReduceMin[keepdims = 0](%input)
  return %minimum
}
Input: tensor([[ 0.3182, -0.2890,  0.9320],
        [ 1.8208, -0.0751, -1.1916]])
Output: [[ 0.31817138 -0.28902754  0.9320159 ]
 [ 1.820803   -0.07514615 -1.191623  ]]
Output shape: (2, 3)
&lt;/denchmark-code&gt;


pip list

&lt;denchmark-code&gt;Package              Version
-------------------- ---------------
absl-py              0.7.1
apex                 0.1
astor                0.8.0
attrs                19.1.0
Automat              0.7.0
certifi              2019.9.11
cffi                 1.12.3
characteristic       14.3.0
cloudpickle          0.8.1
constantly           15.1.0
cycler               0.10.0
cytoolz              0.9.0.1
dask                 1.2.0
decorator            4.4.0
future               0.17.1
gast                 0.2.2
google-pasta         0.1.7
graphviz             0.11
grpcio               1.22.0
h5py                 2.9.0
hyperlink            19.0.0
idna                 2.8
imageio              2.5.0
incremental          17.5.0
Keras-Applications   1.0.8
Keras-Preprocessing  1.1.0
kiwisolver           1.0.1
klein                19.6.0
Markdown             3.1.1
matplotlib           3.0.3
mkl-fft              1.0.10
mkl-random           1.0.2
networkx             2.3
numpy                1.16.3
olefile              0.46
onnx                 1.5.0
onnxruntime-gpu      0.5.0
Pillow               6.0.0
pip                  19.1
protobuf             3.9.0
py-lz4framed         0.13.0
pycparser            2.19
PyHamcrest           1.9.0
pyparsing            2.4.0
pypiwin32            223
python-dateutil      2.8.0
pytz                 2019.1
PyWavelets           1.0.3
pywin32              224
scikit-image         0.15.0
scipy                1.2.1
setuptools           41.0.0
six                  1.12.0
tb-nightly           1.15.0a20190726
tensorflow-estimator 1.14.0
termcolor            1.1.0
toolz                0.9.0
torch                1.2.0
torchvision          0.4.0
torchviz             0.0.1
tornado              6.0.2
tqdm                 4.32.2
Tubes                0.2.0
Twisted              19.2.1
typing               3.6.6
typing-extensions    3.7.4
Werkzeug             0.15.5
wheel                0.33.1
wincertstore         0.2
wrapt                1.11.2
yappi                0.98
zope.interface       4.6.0
&lt;/denchmark-code&gt;

If i run pip uninstall onnx-runtime-gpu and pip install onnx-runtime:
&lt;denchmark-code&gt;Input: tensor([[-0.3735,  0.4288, -0.1181],
        [-0.8469, -0.0080,  0.3052]])
Output: -0.8469265103340149
Output shape: ()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='mgkeeley' date='2019-10-25T23:43:01Z'>
		Can you try building from master ? I think it is probably fixed in master since I don't see it reproing. I can try your script meanwhile.
		</comment>
		<comment id='5' author='mgkeeley' date='2019-10-26T03:05:09Z'>
		OK, after a bit of struggle I compiled the onnxruntime from the master branch.
I then created a C# project that used the built assemblies, and found the same issue.
When running with the default sessions, there is actually an error as the C# runtime doesn't seem to like 0-dimension outputs, but changing the settings to SessionOptions.MakeSessionOptionWithCudaProvider() then the output is the same as the input.
Maybe it is a problem parsing the onnx file correctly?
&lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/3774386/ReduceTest.zip&gt;ReduceTest.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='mgkeeley' date='2019-10-26T04:19:49Z'>
		Thanks for your reply. C# might have that limitation, yes. It doesn't allow creating scalars (0 dim outputs). We will address that in the near future. Python, c/c++ can handle them.
Let me try reproing with your attached model.
By any chance, did you take a look at any test added via &lt;denchmark-link:https://github.com/microsoft/onnxruntime/pull/2268&gt;#2268&lt;/denchmark-link&gt;
 ? Is it along the lines of your expectation ? Just making sure there is no gap in expectation.
Thanks !
		</comment>
		<comment id='7' author='mgkeeley' date='2019-10-26T07:43:54Z'>
		Yes, I had a look, the new tests seem to be what I would expect to be happening from the onnx file dump i.e.
%minimum = ReduceMin[keepdims = 0](%input)
		</comment>
		<comment id='8' author='mgkeeley' date='2019-10-28T18:09:44Z'>
		I took a look at the model - It looks alright. Strange. Let me investigate further...
		</comment>
		<comment id='9' author='mgkeeley' date='2019-10-28T20:15:19Z'>
		You are right - when I tried running your model after building from master, I got the input back as an output (almost like passing it through an Identity node). This looks like a bug somewhere. I have a feeling this is a corner case failure (input rank &lt; 3). I know that there is some special casing of this case based on this comment -



onnxruntime/onnxruntime/core/providers/cuda/reduction/reduction_ops.cc


         Line 107
      in
      90858b7






 // CUDNN requires at least 3D input, so pad 1s if needed 





That would explain why the new tests pass and this model doesn't work as expected. I ll dig into this. Thanks for bringing this up.
		</comment>
		<comment id='10' author='mgkeeley' date='2019-10-28T23:33:16Z'>
		&lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/3781036/min4d.zip&gt;min4d.zip&lt;/denchmark-link&gt;

Thanks, I'm not so sure about the 3d being a bug, I see the same with e.g. a 4D tensor (see attached model).
It's almost like it is doing Min instead of ReduceMin; but as there is only one tensor, the element-wise minimum of the elements just returns the same values as the input.
		</comment>
		<comment id='11' author='mgkeeley' date='2019-10-29T01:17:21Z'>
		I see, thanks for the update. I took a look - I haven't been able to zero-in on the cause yet. There is nothing obvious that jumps out as being wrong and given that it passes similar unit tests, this will require some more investigation as to why it breaks this single node model. I will keep you updated.
		</comment>
		<comment id='12' author='mgkeeley' date='2019-10-30T19:06:13Z'>
		Found the issue and fixed via &lt;denchmark-link:https://github.com/microsoft/onnxruntime/pull/2268&gt;#2268&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='mgkeeley' date='2019-10-30T20:34:25Z'>
		Built a Py wheel and made sure the output is correct using your sample model. Thanks for bringing this to our attention.
		</comment>
	</comments>
</bug>