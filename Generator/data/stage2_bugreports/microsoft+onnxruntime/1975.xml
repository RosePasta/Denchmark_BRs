<bug id='1975' author='brantPTS' open_date='2019-10-02T16:19:25Z' closed_time='2019-10-19T21:02:04Z'>
	<summary>Inference fails when running Faster RCNN model from ONNX model zoo</summary>
	<description>
Describe the bug
Running an inference with the Faster RCNN model from onnx model zoo fails
Urgency
We are blocked from using the ONNX runtime until this is fixed
System information

OS Platform and Distribution: Windows 10 Pro
ONNX Runtime installed from source (built locally with Sep 27, 2019 source code)
Visual Studio version (if applicable): 2019
CUDA/cuDNN version: 10.0 / 7.3
GPU model and memory: nVidia GTX 1080ti

To Reproduce
Get latest source code (we used Sep 27 version)
Build locally with cuda similar to:
.\build.bat --msvc_toolset 14.11 --use_cuda --cuda_home "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0" --cudnn_home C:\local\cudnn-7.3\cuda --build_csharp
Download the Faster RCNN model from onnx model zoo (&lt;denchmark-link:https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/faster-rcnn&gt;https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/faster-rcnn&lt;/denchmark-link&gt;
).
Ensure this file is on disk here: (or alter source code in unit test appropriately if file is in a different location):
D:\modelsfrcnn\frcnn\faster_rcnn_R_50_FPN_1x.onnx
Open the following solution in VS 2019:
C:\local\onnx\onnxruntime\csharp\OnnxRuntime.CSharp.sln
Add a unit test to InferenceTest.cs (see code below) and run in debug mode:
C:\local\onnx\onnxruntime\csharp\test\Microsoft.ML.OnnxRuntime.Tests\InferenceTest.cs
The unit test code to add to InferenceTest.cs:
&lt;denchmark-code&gt;[Fact]
private void frcnnTest()
{

	string modelsDir;
	// expect this file: D:\modelsfrcnn\frcnn\faster_rcnn_R_50_FPN_1x.onnx from https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/faster-rcnn
	modelsDir = @"D:\modelsfrcnn";
	var modelRoot = new DirectoryInfo(Path.Combine(modelsDir));
	foreach (var modelDir in modelRoot.EnumerateDirectories())
	{
		var onnxModelNames = modelDir.GetFiles("*.onnx");

		var onnxModelFileName = Path.Combine(modelsDir, modelDir.Name, onnxModelNames[0].Name);
		SessionOptions opts = new SessionOptions();
		//SessionOptions opts = SessionOptions.MakeSessionOptionWithCudaProvider(0);
		using (var session = new InferenceSession(onnxModelFileName, opts))
		{
			float[] dataIn;
			dataIn = new float[3 * 416 * 416];

			///// Create Inputs
			var nov = new List&lt;NamedOnnxValue&gt;();
			nov.Add(
				NamedOnnxValue.CreateFromTensor&lt;float&gt;
					("image", new DenseTensor&lt;float&gt;(dataIn, new int[] { 3, 416, 416 })));

			int count = 3;
			List&lt;double&gt; timesMs = new List&lt;double&gt;(count);
			Stopwatch sw = new Stopwatch();

			for (int i = 0; i &lt; count; i++)
			{

				sw.Restart();
				///// Run Session
				using (var resnov = session.Run(nov))
				{
					timesMs.Add(sw.ElapsedMilliseconds);
					var res = resnov.ToArray()[0].AsTensor&lt;float&gt;().ToArray&lt;float&gt;();
				}
			}
			timesMs.Sort();
			double medianTime = timesMs[count / 2];
			Console.Out.WriteLine($"Median time: {medianTime:0.00} ms");
			Debug.WriteLine($"Median time: {medianTime:0.00} ms");

		}
	} //model
}
&lt;/denchmark-code&gt;

Expected behavior
The unit test should run without error or memory leaks. See screenshots below:
&lt;denchmark-link:https://user-images.githubusercontent.com/34780180/66062061-891cd780-e4f5-11e9-9ff1-cf56d6aff1b1.JPG&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/34780180/66062071-8e7a2200-e4f5-11e9-94e1-601d87bec827.JPG&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='brantPTS' date='2019-10-02T19:36:59Z'>
		Hi,
I think there are 2 dimensions to this issue:

I think when you feed it random data, the model is unable to make any detections
When the C# layer tries to create a tensor with no elements (number of detection boxes = 0), it throws. In Python, I get back an empty array of shape [0, 4].

So, please try following the demo in the link you pasted and try inferencing on an image where the model is sure to detect something. In legitimate cases when there is an image with no objects (or one that the model isn't able to detect), the C# layer must be able to handle it (addressed by &lt;denchmark-link:https://github.com/microsoft/onnxruntime/pull/1976&gt;#1976&lt;/denchmark-link&gt;
 )
		</comment>
		<comment id='2' author='brantPTS' date='2019-10-02T22:46:31Z'>
		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
  Thank you for working this so promptly.  I will work on preparing some real data and also will look forward to your fix for the zero dimension tensor.
		</comment>
		<comment id='3' author='brantPTS' date='2019-10-02T23:35:16Z'>
		Sure. The 0 dimension value tensor problem should be limited to just the c# layer (Python and C/C++ should be ok) - just FYI :)
		</comment>
		<comment id='4' author='brantPTS' date='2019-10-19T21:02:04Z'>
		Closing out this issue as the only takeaway for ORT was that the C# layer didn't handle creation of empty tensors (fixed via &lt;denchmark-link:https://github.com/microsoft/onnxruntime/pull/1976&gt;#1976&lt;/denchmark-link&gt;
) and for the provided input an empty tensor is the right output. So, the result is correct.
		</comment>
	</comments>
</bug>