<bug id='463' author='rth' open_date='2019-02-11T10:10:43Z' closed_time='2019-03-13T21:45:11Z'>
	<summary>Segfault with scikit-learn LogisticRegression model</summary>
	<description>
Describe the bug
I get a segfault with running inference on the logistic regression model generated with sklearn-onnx
System information

OS Platform and Distribution: Ubuntu 18.10"
ONNX Runtime installed from (source or binary): binary (conda)
ONNX Runtime version: 0.2.1
Python version: 3.7
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: None
GPU model and memory: None

Full versions can be found below,

conda list
# packages in environment at /home/rth/miniconda3/envs/onnx:
#
# Name                    Version                   Build  Channel
blas                      1.0                         mkl  
ca-certificates           2019.1.23                     0  
certifi                   2018.11.29               py37_0  
intel-openmp              2019.1                      144  
libedit                   3.1.20181209         hc058e9b_0  
libffi                    3.2.1                hd88cf55_4  
libgcc-ng                 8.2.0                hdf63c60_1  
libgfortran-ng            7.3.0                hdf63c60_0  
libprotobuf               3.6.1                hd408876_0  
libstdcxx-ng              8.2.0                hdf63c60_1  
mkl                       2019.1                      144  
mkl_fft                   1.0.10           py37ha843d7b_0  
mkl_random                1.0.2            py37hd81dba3_0  
ncurses                   6.1                  he6710b0_1  
numpy                     1.15.4           py37h7e9f1db_0  
numpy-base                1.15.4           py37hde5b4d6_0  
onnx                      1.4.1            py37hf2d0322_0    conda-forge
onnxruntime               0.2.1                    pypi_0    pypi
openssl                   1.1.1a               h7b6447c_0  
pip                       19.0.1                   py37_0  
protobuf                  3.6.1            py37he6710b0_0  
python                    3.7.2                h0371630_0  
readline                  7.0                  h7b6447c_5  
scikit-learn              0.20.2           py37hd81dba3_0  
scipy                     1.2.0            py37h7c811a0_0  
setuptools                40.7.3                   py37_0  
six                       1.12.0                   py37_0  
skl2onnx                  1.4.2                    pypi_0    pypi
sqlite                    3.26.0               h7b6447c_0  
tk                        8.6.8                hbc83047_0  
typing                    3.6.6                    pypi_0    pypi
typing-extensions         3.7.2                    pypi_0    pypi
wheel                     0.32.3                   py37_0  
xz                        5.2.4                h14c3975_4  
zlib                      1.2.11               h7b6447c_3



Loosely adapted from &lt;denchmark-link:http://onnx.ai/sklearn-onnx/&gt;http://onnx.ai/sklearn-onnx/&lt;/denchmark-link&gt;
 example
import numpy as np

from sklearn.linear_model import LogisticRegression

import onnxruntime as rt

from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

rng = np.random.RandomState(42)

n_features = 20
X = rng.rand(1000, n_features)
y = rng.randint(2, size=(1000,))

estimator = LogisticRegression(solver="lbfgs")
estimator.fit(X, y)

initial_type = [('float_input', FloatTensorType([1, n_features]))]
onx = convert_sklearn(estimator, initial_types=initial_type)
with open('./estimator.onnx', "wb") as f:
    f.write(onx.SerializeToString())

sess = rt.InferenceSession("estimator.onnx")
input_name = sess.get_inputs()[0].name
label_name = sess.get_outputs()[0].name
pred_onx = sess.run([label_name], {input_name: X.astype(np.float32)})[0]
Expected behavior
Some predictions no segfault.
Additional context
The obtained stacktrace can be found below,

gdb --args python example.py 
GNU gdb (Ubuntu 8.2-0ubuntu1) 8.2
Copyright (C) 2018 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type "show copying" and "show warranty" for details.
This GDB was configured as "x86_64-linux-gnu".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
&lt;http://www.gnu.org/software/gdb/bugs/&gt;.
Find the GDB manual and other documentation resources online at:
    &lt;http://www.gnu.org/software/gdb/documentation/&gt;.

For help, type "help".
Type "apropos word" to search for commands related to "word"...
Reading symbols from python...done.
(gdb) run
Starting program: /home/rth/miniconda3/envs/onnx/bin/python example.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
[Detaching after fork from child process 20658]
[Detaching after fork from child process 20659]
[Detaching after fork from child process 20661]
ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
The maximum opset needed by this model is only 1.
The maximum opset needed by this model is only 7.

Program received signal SIGSEGV, Segmentation fault.
0x00007fffe6b6c11f in onnxruntime::python::AddTensorAsPyObj(onnxruntime::MLValue&amp;, std::vector&lt;pybind11::object, std::allocator&lt;pybind11::object&gt; &gt;&amp;) ()
   from /home/rth/miniconda3/envs/onnx/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_pybind11_state.so
(gdb) bt
#0  0x00007fffe6b6c11f in onnxruntime::python::AddTensorAsPyObj(onnxruntime::MLValue&amp;, std::vector&lt;pybind11::object, std::allocator&lt;pybind11::object&gt; &gt;&amp;) ()
   from /home/rth/miniconda3/envs/onnx/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_pybind11_state.so
#1  0x00007fffe6b71b1e in pybind11::cpp_function::initialize&lt;onnxruntime::python::addObjectMethods(pybind11::module&amp;)::{lambda(onnxruntime::InferenceSession*, std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, pybind11::object, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, pybind11::object&gt; &gt; &gt;, OrtRunOptions*)#6}, std::vector&lt;pybind11::object, std::allocator&lt;pybind11::object&gt; &gt;, onnxruntime::InferenceSession*, std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, pybind11::object, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, pybind11::object&gt; &gt; &gt;, OrtRunOptions*, pybind11::name, pybind11::is_method, pybind11::sibling&gt;(onnxruntime::python::addObjectMethods(pybind11::module&amp;)::{lambda(onnxruntime::InferenceSession*, std::vector&lt;std--Type &lt;RET&gt; for more, q to quit, c to continue without paging--
::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, pybind11::object, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, pybind11::object&gt; &gt; &gt;, OrtRunOptions*)#6}&amp;&amp;, std::vector&lt;pybind11::object, std::allocator&lt;pybind11::object&gt; &gt; (*)(onnxruntime::InferenceSession*, std::vector&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::allocator&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt;, std::map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, pybind11::object, std::less&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, pybind11::object&gt; &gt; &gt;, OrtRunOptions*), pybind11::name const&amp;, pybind11::is_method const&amp;, pybind11::sibling const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::_FUN(pybind11::detail::function_call) ()
   from /home/rth/miniconda3/envs/onnx/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_pybind11_state.so
#2  0x00007fffe6b8aeee in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) ()
   from /home/rth/miniconda3/envs/onnx/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_pybind11_state.so
--Type &lt;RET&gt; for more, q to quit, c to continue without paging--
#3  0x00005555556cde24 in _PyMethodDef_RawFastCallKeywords (
    method=0x555556585970, self=0x7fffe7479660, args=0x7fffe4e815a8, 
    nargs=&lt;optimized out&gt;, kwnames=&lt;optimized out&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Objects/call.c:690
#4  0x00005555556cdf41 in _PyCFunction_FastCallKeywords (func=0x7fffe7478ca8, 
    args=&lt;optimized out&gt;, nargs=&lt;optimized out&gt;, kwnames=&lt;optimized out&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Objects/call.c:730
#5  0x0000555555728d26 in call_function (kwnames=0x0, oparg=&lt;optimized out&gt;, 
    pp_stack=&lt;synthetic pointer&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Python/ceval.c:4619
#6  _PyEval_EvalFrameDefault (f=&lt;optimized out&gt;, throwflag=&lt;optimized out&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Python/ceval.c:3093
#7  0x00005555556690d9 in _PyEval_EvalCodeWithName (_co=0x7fffe7469c00, 
    globals=&lt;optimized out&gt;, locals=&lt;optimized out&gt;, args=&lt;optimized out&gt;, 
    argcount=&lt;optimized out&gt;, kwnames=0x0, kwargs=0x7ffff6dd8b80, 
    kwcount=&lt;optimized out&gt;, kwstep=1, defs=0x7fffe76fb8e8, defcount=1, 
    kwdefs=0x0, closure=0x0, name=0x7ffff6dbba40, qualname=0x7fffe74713d8)
    at /tmp/build/80754af9/python_1546061345851/work/Python/ceval.c:3930
#8  0x00005555556cd0f5 in _PyFunction_FastCallKeywords (func=&lt;optimized out&gt;, 
    stack=0x7ffff6dd8b68, nargs=3, kwnames=&lt;optimized out&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Objects/call.c:433
#9  0x0000555555723ff0 in call_function (kwnames=0x0, oparg=&lt;optimized out&gt;, 
    pp_stack=&lt;synthetic pointer&gt;)
--Type &lt;RET&gt; for more, q to quit, c to continue without paging--
    at /tmp/build/80754af9/python_1546061345851/work/Python/ceval.c:4616
#10 _PyEval_EvalFrameDefault (f=&lt;optimized out&gt;, throwflag=&lt;optimized out&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Python/ceval.c:3110
#11 0x00005555556690d9 in _PyEval_EvalCodeWithName (_co=0x7ffff6d666f0, 
    globals=&lt;optimized out&gt;, locals=&lt;optimized out&gt;, args=&lt;optimized out&gt;, 
    argcount=&lt;optimized out&gt;, kwnames=0x0, kwargs=0x0, 
    kwcount=&lt;optimized out&gt;, kwstep=2, defs=0x0, defcount=0, kwdefs=0x0, 
    closure=0x0, name=0x0, qualname=0x0)
    at /tmp/build/80754af9/python_1546061345851/work/Python/ceval.c:3930
#12 0x0000555555669fa4 in PyEval_EvalCodeEx (_co=&lt;optimized out&gt;, 
    globals=&lt;optimized out&gt;, locals=&lt;optimized out&gt;, args=&lt;optimized out&gt;, 
    argcount=&lt;optimized out&gt;, kws=&lt;optimized out&gt;, kwcount=0, defs=0x0, 
    defcount=0, kwdefs=0x0, closure=0x0)
    at /tmp/build/80754af9/python_1546061345851/work/Python/ceval.c:3959
#13 0x0000555555669fcc in PyEval_EvalCode (co=&lt;optimized out&gt;, 
    globals=&lt;optimized out&gt;, locals=&lt;optimized out&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Python/ceval.c:524
#14 0x0000555555783664 in run_mod (mod=&lt;optimized out&gt;, 
    filename=&lt;optimized out&gt;, globals=0x7ffff6d2d0d8, locals=0x7ffff6d2d0d8, 
    flags=&lt;optimized out&gt;, arena=&lt;optimized out&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Python/pythonrun.c:1035
#15 0x000055555578d881 in PyRun_FileExFlags (fp=0x55555590cb50, 
    filename_str=&lt;optimized out&gt;, start=&lt;optimized out&gt;, 
--Type &lt;RET&gt; for more, q to quit, c to continue without paging--
    globals=0x7ffff6d2d0d8, locals=0x7ffff6d2d0d8, closeit=1, 
    flags=0x7fffffffdac0)
    at /tmp/build/80754af9/python_1546061345851/work/Python/pythonrun.c:988
#16 0x000055555578da73 in PyRun_SimpleFileExFlags (fp=0x55555590cb50, 
    filename=&lt;optimized out&gt;, closeit=1, flags=0x7fffffffdac0)
    at /tmp/build/80754af9/python_1546061345851/work/Python/pythonrun.c:429
#17 0x000055555578eb2f in pymain_run_file (p_cf=0x7fffffffdac0, 
    filename=0x5555558c6870 L"example.py", fp=0x55555590cb50)
    at /tmp/build/80754af9/python_1546061345851/work/Modules/main.c:427
#18 pymain_run_filename (cf=0x7fffffffdac0, pymain=0x7fffffffdbd0)
    at /tmp/build/80754af9/python_1546061345851/work/Modules/main.c:1627
#19 pymain_run_python (pymain=0x7fffffffdbd0)
    at /tmp/build/80754af9/python_1546061345851/work/Modules/main.c:2876
#20 pymain_main (pymain=0x7fffffffdbd0)
    at /tmp/build/80754af9/python_1546061345851/work/Modules/main.c:3037
#21 0x000055555578ec4c in _Py_UnixMain (argc=&lt;optimized out&gt;, 
    argv=&lt;optimized out&gt;)
    at /tmp/build/80754af9/python_1546061345851/work/Modules/main.c:3072
#22 0x00007ffff7dd109b in __libc_start_main (main=0x555555649540 &lt;main&gt;, 
    argc=2, argv=0x7fffffffdd28, init=&lt;optimized out&gt;, fini=&lt;optimized out&gt;, 
    rtld_fini=&lt;optimized out&gt;, stack_end=0x7fffffffdd18)
    at ../csu/libc-start.c:308
#23 0x0000555555733982 in _start () at ../sysdeps/x86_64/elf/start.S:103


	</description>
	<comments>
		<comment id='1' author='rth' date='2019-02-11T19:42:52Z'>
		On my machine, it didn't crash.
		</comment>
		<comment id='2' author='rth' date='2019-02-19T19:05:24Z'>
		Could you try to build onnxruntime python package from source?
Sometimes it's due to numpy version mismatch, that onnxruntime was built with numpy version A but you installed numpy version B.
		</comment>
		<comment id='3' author='rth' date='2019-02-24T20:35:44Z'>
		I had the same problem. Uninstalling numpy 1.15.3 and installing numpy 1.16.1 solved it for me.
		</comment>
		<comment id='4' author='rth' date='2019-02-24T20:47:15Z'>
		
Sometimes it's due to numpy version mismatch, that onnxruntime was built with numpy version A but you installed numpy version B.

Is numpy a build or runtime dependency then? I couldn't find anything about it in setup.py or readme. If that is the case building wheels with the oldest supported numpy version might avoid this? It would be nice to indicate supported numpy versions.
As to onnx package that I installed from conda (conda-forge channel), it looks like  numpy is only needed at runtime, it doesn't link to it during build &lt;denchmark-link:https://github.com/conda-forge/onnx-feedstock/blob/master/recipe/meta.yaml#L37&gt;https://github.com/conda-forge/onnx-feedstock/blob/master/recipe/meta.yaml#L37&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='rth' date='2019-02-24T20:49:52Z'>
		(sklearn-onnx does depend on numpy but that's a pure python wheel so it shouldn't segfault I imagine?)
		</comment>
		<comment id='6' author='rth' date='2019-03-13T21:04:38Z'>
		Tested with new generated whl (available soon (likely within today)) with proper numpy version (built with 1.15.0), tested with 1.16.1 and 1.15.1, (with onnx and skl2onnx from pypi (latest)) and the scripts provided is working.
		</comment>
		<comment id='7' author='rth' date='2019-03-13T21:35:19Z'>
		Thanks for investigating!

with proper numpy version (built with 1.15.0),  tested with 1.16.1 and 1.15.1

What do you mean by "proper"; is the minimal numpy dependency documented somewhere ? (cf my previous comment &lt;denchmark-link:https://github.com/microsoft/onnxruntime/issues/463#issuecomment-466815324&gt;#463 (comment)&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='8' author='rth' date='2019-03-13T21:40:12Z'>
		We are introducing it in this release: &lt;denchmark-link:https://github.com/Microsoft/onnxruntime/blob/master/setup.py#L74&gt;https://github.com/Microsoft/onnxruntime/blob/master/setup.py#L74&lt;/denchmark-link&gt;

also see &lt;denchmark-link:https://github.com/microsoft/onnxruntime/issues/510&gt;#510&lt;/denchmark-link&gt;
 for discussion on that.
Again thanks for reporting this to us.
		</comment>
		<comment id='9' author='rth' date='2019-03-13T21:45:10Z'>
		Great, thanks! Closing this issue then.
		</comment>
	</comments>
</bug>