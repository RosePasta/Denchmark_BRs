<bug id='1400' author='xgirones' open_date='2019-07-13T19:15:31Z' closed_time='2019-07-19T19:10:01Z'>
	<summary>Wrong result when evaluating a batch of padded sequences with varying lengths on GPU</summary>
	<description>
Describe the bug
When supplying the attached model with a batch of padded sequences with varying lengths the results on GPU are incorrect:
&lt;denchmark-code&gt;Discrepancy between CPU and GPU evaluations.
Number of sequences in batch: 16
Sequence lengths: [12 32  4 52  8 64 20 36 48 40 24 60 44 16 28 56]
Maximum absolute pairwise difference: 0.9621068835258484
Average absolute pairwise difference: 0.019491384112097738
&lt;/denchmark-code&gt;

On the other hand, the results on CPU are fine:
&lt;denchmark-code&gt;Discrepancy between CPU and PyTorch evaluations.
Number of sequences in batch: 16
Sequence lengths: [12 32  4 52  8 64 20 36 48 40 24 60 44 16 28 56]
Maximum absolute pairwise difference: 1.2218952178955078e-06
Average absolute pairwise difference: 1.330953997859751e-08
&lt;/denchmark-code&gt;

Urgency
Stuck on this
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
ONNX Runtime installed from (source or binary): Source
ONNX Runtime version: Code pulled from the master branch in 13/7/2019
Python version: 3.6
Visual Studio version (if applicable): 2017
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.1/7.6
GPU model and memory: NVIDA Quadro K1200 with 4GB


Unzip the attached &lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/3389130/discrepancy_CPU_GPU.zip&gt;discrepancy_CPU_GPU.zip&lt;/denchmark-link&gt;
 file and run the model  in the  folder on both CPU and GPU using  and  as inputs (all  and  in the folder  are the same).
Expected behavior
Results on GPU and CPU should be the same.
Screenshots
If applicable, add screenshots to help explain your problem.

&lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/3389130/discrepancy_CPU_GPU.zip&gt;discrepancy_CPU_GPU.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='xgirones' date='2019-07-16T19:09:35Z'>
		Our cuda implementation for LSTM uses cudnn libray, it has some limitation: the sequences in the mini-batch need to be sorted in descending order according to length. refers to
&lt;denchmark-link:https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnRNNForwardInferenceEx&gt;https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnRNNForwardInferenceEx&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='xgirones' date='2019-07-16T20:49:35Z'>
		Hi Hector,
Thanks for your answer. I tried with sorted sequences as you suggested but the problem did not go away:
&lt;denchmark-code&gt;Discrepancy between CPU and GPU evaluations.
Number of sequences in batch: 16
Sequence lengths: [64 60 56 52 48 44 40 36 32 28 24 20 16 12  8  4]
Total non zero elements: 21216
Maximum absolute pairwise difference: 0.9727079272270203
Average absolute pairwise difference: 0.018673043804830376
&lt;/denchmark-code&gt;

Here you can find the model and the input/output tensors in case you need to take a look at them:
&lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/3399061/discrepancy_CPU_GPU_sorted.zip&gt;discrepancy_CPU_GPU_sorted.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='xgirones' date='2019-07-17T21:35:34Z'>
		Root cause addressed, will send a PR.
&lt;denchmark-link:https://github.com/xgirones&gt;@xgirones&lt;/denchmark-link&gt;
 By they way, Is it possible for us to put your model in our build pipeline to make sure no regression in future?
		</comment>
		<comment id='4' author='xgirones' date='2019-07-17T22:47:06Z'>
		This is great news, thanks!

@xgirones By they way, Is it possible for us to put your model in our build pipeline to make sure no regression in future?

Yes, of course. You can use it freely if you find it convenient. It is just a toy model I created to learn more about the best loss functions for sequences.
		</comment>
		<comment id='5' author='xgirones' date='2019-07-18T16:28:30Z'>
		The fix is merged. Also sorted sequence_lengths is not a limitation any more. Your first model also works. I'll add them to our test pipeline.
Great thanks for your findings!
		</comment>
		<comment id='6' author='xgirones' date='2019-07-19T18:10:10Z'>
		&lt;denchmark-link:https://github.com/xgirones&gt;@xgirones&lt;/denchmark-link&gt;
 Do you mind to close the issue or you still need some verification?
		</comment>
		<comment id='7' author='xgirones' date='2019-07-19T19:10:01Z'>
		Closing it... Thanks for your help!
		</comment>
	</comments>
</bug>