<bug id='2132' author='Exlsunshine' open_date='2019-10-15T04:08:59Z' closed_time='2020-07-11T01:41:20Z'>
	<summary>Pytorch model cannot be served by ORT 0.5.0 + ONNX 1.6.0</summary>
	<description>
Describe the bug
Pytorch model can be converted, but the converted onnx model could not be loaded by onnxruntime. Keeps telling me:
&lt;denchmark-code&gt;File "C:\Users\x\AppData\Local\Programs\Python\Python36\lib\site-packages\onnxruntime\capi\session.py", line 29, in __init__
    self._sess.load_model(path_or_bytes)
RuntimeError: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from test.onnx failed:This is an invalid model. Error in Node: : Node () has input size 4 not in range [min=2, max=2].
&lt;/denchmark-code&gt;

Urgency
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10
ONNX Runtime installed from (source or binary): pip
ONNX Runtime version: 0.5.0
Python version: 3.6
Visual Studio version (if applicable): None
GCC/Compiler version (if compiling from source): None
CUDA/cuDNN version: None
GPU model and memory: None

To Reproduce
Describe steps/code to reproduce the behavior:
&lt;denchmark-code&gt;import torch.onnx
from torchvision import models
import onnxruntime as rt
import os

fcn = models.segmentation.deeplabv3_resnet101(pretrained=True).eval()

path = os.path.join(os.path.dirname(__file__), "test.onnx")
input = torch.randn([1, 3, 244, 244])
torch.onnx.export(fcn, input, path, opset_version=11)

sess = rt.InferenceSession(path)
print("sess is ok")
&lt;/denchmark-code&gt;

Expected behavior
A clear and concise description of what you expected to happen.
the code should print: sess is ok
Screenshots
If applicable, add screenshots to help explain your problem.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "ort.py", line 12, in &lt;module&gt;
    sess = rt.InferenceSession(path)
  File "C:\Users\x\AppData\Local\Programs\Python\Python36\lib\site-packages\onnxruntime\capi\session.py", line 29, in __init__
    self._sess.load_model(path_or_bytes)
RuntimeError: [ONNXRuntimeError] : 10 : INVALID_GRAPH : Load model from test.onnx failed:This is an invalid model. Error in Node: : Node () has input size 4 not in range [min=2, max=2].
&lt;/denchmark-code&gt;

Additional context
Add any other context about the problem here. If the issue is about a particular model, please share the model details as well to facilitate debugging.
	</description>
	<comments>
		<comment id='1' author='Exlsunshine' date='2019-10-15T23:58:04Z'>
		This is opset11, you should try ORT from master or wait for the release, or export with opset10 for now. A better error message would have been great.
		</comment>
		<comment id='2' author='Exlsunshine' date='2019-10-16T08:59:33Z'>
		
This is opset11, you should try ORT from master or wait for the release, or export with opset10 for now. A better error message would have been great.

Hi &lt;denchmark-link:https://github.com/dashesy&gt;@dashesy&lt;/denchmark-link&gt;
 , thanks for the tips, opset10 does work for me, but opset10 leads to low precision, the onnx output is barely the same with original output. Maybe I should pip install latest ORT later.
		</comment>
		<comment id='3' author='Exlsunshine' date='2019-10-17T07:32:45Z'>
		Please try &lt;denchmark-link:https://test.pypi.org/project/ort-nightly&gt;https://test.pypi.org/project/ort-nightly&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Exlsunshine' date='2019-10-25T06:27:02Z'>
		
Please try https://test.pypi.org/project/ort-nightly

Hey Faith, thanks for the info, I'd like to try it, at the meantime, do we have any rough EAT about releasing those features to pip install?
		</comment>
		<comment id='5' author='Exlsunshine' date='2019-10-30T21:27:47Z'>
		&lt;denchmark-link:https://github.com/Exlsunshine&gt;@Exlsunshine&lt;/denchmark-link&gt;
 : onnxruntime release 1.0 is now available with ONNX 1.6 version support (supporting opset 11).
		</comment>
		<comment id='6' author='Exlsunshine' date='2019-11-05T19:41:42Z'>
		&lt;denchmark-link:https://github.com/Exlsunshine&gt;@Exlsunshine&lt;/denchmark-link&gt;
 have you been able to verify it works with the released 1.0 version?
		</comment>
		<comment id='7' author='Exlsunshine' date='2019-11-06T06:27:29Z'>
		
@Exlsunshine have you been able to verify it works with the released 1.0 version?

Hi &lt;denchmark-link:https://github.com/faxu&gt;@faxu&lt;/denchmark-link&gt;
 &amp; &lt;denchmark-link:https://github.com/askhade&gt;@askhade&lt;/denchmark-link&gt;
,
I have tried the same code with onnxruntime==1.0.0, but it doesn't work either, I got the following error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "a.py", line 12, in &lt;module&gt;
    sess = rt.InferenceSession(path)
  File "D:\Program\anaconda3.201907\envs\test_new_ort\lib\site-packages\onnxruntime\capi\session.py", line 23, in __init__
    self._load_model()
  File "D:\Program\anaconda3.201907\envs\test_new_ort\lib\site-packages\onnxruntime\capi\session.py", line 35, in _load_model
    self._sess.load_model(self._path_or_bytes, providers)
onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node: Output:1082 [ShapeInferenceError] Can't merge shape info. Both source and target dimension have values but they differ. Source=1 Target=21 Dimension=1
&lt;/denchmark-code&gt;

Env:
&lt;denchmark-code&gt;onnx                      1.6.0
onnxruntime               1.0.0
torch                     1.3.0+cpu
torchvision               0.4.1+cpu
&lt;/denchmark-code&gt;

but I can convert the same model by specifying opset_version = 10.
		</comment>
		<comment id='8' author='Exlsunshine' date='2019-11-07T19:04:15Z'>
		&lt;denchmark-link:https://github.com/Exlsunshine&gt;@Exlsunshine&lt;/denchmark-link&gt;
 : Can you please share the model?
		</comment>
		<comment id='9' author='Exlsunshine' date='2019-11-08T06:35:48Z'>
		
@Exlsunshine : Can you please share the model?

It's a built-in model in torchvision, you can reproduce the error by executing(try opset_version 11 and 10, 10 works but 11 not):
&lt;denchmark-code&gt;import torch.onnx
from torchvision import models
import onnxruntime as rt
import os

fcn = models.segmentation.deeplabv3_resnet101(pretrained=True).eval()

path = os.path.join(os.path.dirname(__file__), "test.onnx")
input = torch.randn([1, 3, 244, 244])
torch.onnx.export(fcn, input, path, opset_version=11)

sess = rt.InferenceSession(path)
print("sess is ok")
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='Exlsunshine' date='2020-01-28T18:44:21Z'>
		&lt;denchmark-link:https://github.com/Exlsunshine&gt;@Exlsunshine&lt;/denchmark-link&gt;
 sorry for the delay; checking back on this...is the issue still reproducible with the latest 1.1 ORT release?
		</comment>
		<comment id='11' author='Exlsunshine' date='2020-07-03T04:58:21Z'>
		This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.
		</comment>
		<comment id='12' author='Exlsunshine' date='2020-07-11T01:40:54Z'>
		This issue has been automatically closed due to inactivity. Please reactivate if further support is needed.
		</comment>
	</comments>
</bug>