<bug id='3735' author='katrasnikj' open_date='2020-04-28T14:49:56Z' closed_time='2020-05-11T02:08:38Z'>
	<summary>Loading float16 model fails</summary>
	<description>
When constructing Ort::Session with a float16 ONNX model I get the following error
&lt;denchmark-code&gt;Exception during initialization: C:\...\onnxruntime\onnxruntime\core\optimizer\optimizer_execution_frame.cc:73 onnxruntime::OptimizerExecutionFrame::Info::Info [ONNXRuntimeError] : 1 : FAIL : Failed to find kernel for Sub
&lt;/denchmark-code&gt;

System information

OS: Windows 10
ONNX Runtime build from source (6b3b4fe)
Visual Studio version 2019
CUDA 10.2, cuDNN 7.6.5
GPU model and memory: NVIDIA GeForce RTX 2080 Ti 11GB

	</description>
	<comments>
		<comment id='1' author='katrasnikj' date='2020-04-28T20:40:08Z'>
		Additional note. ONNX model of type float32 works on the aforementioned configuration.
Both ONNX models are exported using pytorch 1.4.0 and opset version 11.
Might be related to &lt;denchmark-link:https://github.com/dotnet/machinelearning/issues/4795&gt;dotnet/machinelearning#4795&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='katrasnikj' date='2020-05-04T21:23:05Z'>
		Are you using the CPU binary or the CUDA binary ? We do not yet have a CPU kernel implemented yet for Sub (for float16 type) but the CUDA binary should have it -



onnxruntime/onnxruntime/core/providers/cuda/cuda_execution_provider.cc


         Line 392
      in
      156368b






 class ONNX_OPERATOR_TYPED_KERNEL_CLASS_NAME(kCudaExecutionProvider, kOnnxDomain, 7, MLFloat16, Sub); 





		</comment>
		<comment id='3' author='katrasnikj' date='2020-05-05T06:31:46Z'>
		We use the CUDA binary. The following code shows how we create the Ort::Session
  auto memory_info =
    Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeCPU);

  environment_ = std::make_unique&lt;Ort::Env&gt;(ORT_LOGGING_LEVEL_FATAL);
  Ort::SessionOptions options;
  options.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_ALL);
  OrtSessionOptionsAppendExecutionProvider_CUDA(options, 0);
  session_ = std::make_unique&lt;Ort::Session&gt;(*environment_, onnx_model, model_size, options);
		</comment>
		<comment id='4' author='katrasnikj' date='2020-05-05T09:13:57Z'>
		Could you share the model or a minimalistic model that can repro it ? CUDA should have a Sub kernel
		</comment>
		<comment id='5' author='katrasnikj' date='2020-05-05T09:26:51Z'>
		You can find a minimalistic model of type float16 (reuploaded the right model) &lt;denchmark-link:https://github.com/donrax/onnxbug/blob/master/mfp16.onnx&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='6' author='katrasnikj' date='2020-05-06T01:57:04Z'>
		&lt;denchmark-link:https://github.com/donrax&gt;@donrax&lt;/denchmark-link&gt;
  - &lt;denchmark-link:https://github.com/microsoft/onnxruntime/pull/3836&gt;#3836&lt;/denchmark-link&gt;
 will get you past the model loading stage
		</comment>
		<comment id='7' author='katrasnikj' date='2020-05-06T05:04:24Z'>
		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
 Thank you for the assistance
		</comment>
	</comments>
</bug>