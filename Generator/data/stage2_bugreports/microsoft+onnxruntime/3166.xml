<bug id='3166' author='qiuqiangkong' open_date='2020-03-07T12:50:06Z' closed_time='2020-04-17T21:50:55Z'>
	<summary>onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running BatchNormalization node</summary>
	<description>
My error: onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running BatchNormalization node.
I came across this error in onnxruntime-gpu==1.1.2. My cuda is 10.0. Python version: 3.7. Ubuntu. My model is like:
x = x.transpose(1, 3)
x = self.bn0(x)
self.bn0 is BatchNorm1d. If I remove x = x.transpose(1, 3) then it works fine. I think the problem came from the BatchNorm1d. When I use onnxruntime and CPU it works fine. But it does not work when I use onnxruntime-gpu and cuda.
	</description>
	<comments>
		<comment id='1' author='qiuqiangkong' date='2020-03-09T22:16:53Z'>
		Can you share the onnx model please ?
		</comment>
		<comment id='2' author='qiuqiangkong' date='2020-03-11T07:36:24Z'>
		
Can you share the onnx model please ?

Here is the model! It works well with onnxruntime, but not onnxruntime-gpu.
&lt;denchmark-code&gt;class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()

        self.bn0 = nn.BatchNorm2d(1024)

        self.conv1 = nn.Conv1d(in_channels=1, out_channels=1024, kernel_size=1024, stride=1024)

        self.conv2 = nn.Conv2d(in_channels=1, 
                              out_channels=32,
                              kernel_size=(3, 3), stride=(1, 1),
                              padding=(1, 1))

    def forward(self, input):
        x = input[:, None, :]
        x = self.conv1(x).transpose(1, 2)
        x = x[:, None, :, :]

        x = x.transpose(1, 3)
        x = self.bn0(x)
        x = x.transpose(1, 3)
        x = self.conv2(x)

        return torch.mean(x)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='qiuqiangkong' date='2020-03-11T07:51:45Z'>
		Thanks. But I meant - the onnx model file that you get after exporting to onnx
		</comment>
		<comment id='4' author='qiuqiangkong' date='2020-03-11T23:22:29Z'>
		
Thanks. But I meant - the onnx model file that you get after exporting to onnx
I see! I have attached the onnx file here: https://drive.google.com/open?id=1zmHi1WljtlbelN-cuoeiTzB58PK2PAA3

		</comment>
		<comment id='5' author='qiuqiangkong' date='2020-03-16T06:33:17Z'>
		Hi hariharans29, sorry for reminder! do you have any updates?
		</comment>
		<comment id='6' author='qiuqiangkong' date='2020-03-17T00:43:36Z'>
		Hi &lt;denchmark-link:https://github.com/qiuqiangkong&gt;@qiuqiangkong&lt;/denchmark-link&gt;
,
Sorry - I haven't been able to run this model yet. I took a look at the model. It seems simple enough. Can you share the script you use to run the model ? I ll try to have some finding in a day or two.
		</comment>
		<comment id='7' author='qiuqiangkong' date='2020-03-17T02:20:26Z'>
		Thanks &lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
! My script to run the model is:
import numpy as np
import onnxruntime as ort
model = onnx.load('test.onnx')   # 'test.onnx' is the saved onnx
ort_session = ort.InferenceSession(onnx_path)
audio = np.random.randn(1, segment_samples).astype(np.float32)
output = ort_session.run(None, {'input': audio})[0]
Then I got "return self._sess.run(output_names, input_feed, run_options)
onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running BatchNormalization node. Name:'' Status Message: "
		</comment>
		<comment id='8' author='qiuqiangkong' date='2020-03-17T03:54:49Z'>
		Thanks, I ll try running it on a machine that supports CUDA and get back.
		</comment>
		<comment id='9' author='qiuqiangkong' date='2020-03-18T23:52:37Z'>
		Hi &lt;denchmark-link:https://github.com/qiuqiangkong&gt;@qiuqiangkong&lt;/denchmark-link&gt;
  - Sorry, I haven't been able to try this yet. I ll have something by Friday hopefully.
		</comment>
		<comment id='10' author='qiuqiangkong' date='2020-03-19T00:07:08Z'>
		Sure! no worries!
		</comment>
		<comment id='11' author='qiuqiangkong' date='2020-03-19T03:56:06Z'>
		I have the same problem in onnxruntime-gpu==1.0.0, onnxruntime-gpu==1.1.2
		</comment>
		<comment id='12' author='qiuqiangkong' date='2020-03-27T03:02:33Z'>
		Hi &lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
, any updates?
		</comment>
		<comment id='13' author='qiuqiangkong' date='2020-04-07T04:26:41Z'>
		Hi &lt;denchmark-link:https://github.com/qiuqiangkong&gt;@qiuqiangkong&lt;/denchmark-link&gt;
 ,
Sorry for the delayed response. I couldn't get to this as I was focused on something else.
I started looking into this. It doesn't look to be an issue beccause BatchNorm is 1D. This is from th model file you shared -
&lt;denchmark-link:https://user-images.githubusercontent.com/9969784/78629868-2235fd80-784d-11ea-8102-01cfee79e2c8.png&gt;&lt;/denchmark-link&gt;

The BatchNorm is 2D (2D features + channel + batch dim = 4D). There is a permutation before the BatchNorm which applies to 4D input only and notice the unsqueeze op adding a new dimension a little before.
The issue must be something else. I am looking into it.
		</comment>
		<comment id='14' author='qiuqiangkong' date='2020-04-07T04:28:33Z'>
		Btw - could you try running it using the latest release ? v1.2 ? And please share the version of CUDA/ CuDNN on your machine along with the graphics card info.
		</comment>
		<comment id='15' author='qiuqiangkong' date='2020-04-08T02:17:13Z'>
		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
 Thanks for your reply! When using onnxruntime-gpu=1.1.2 and CUDA=10.0, in the past few days I found a tricky way to let this error disappear, that is, by always adding a Conv layer before a BN layer.
I tried your suggested onnxruntime-gpu=1.2.0 and CUDA 10.1, the bug seems disappeared without changing any code! What is changed?
		</comment>
		<comment id='16' author='qiuqiangkong' date='2020-04-08T05:22:02Z'>
		Hi &lt;denchmark-link:https://github.com/qiuqiangkong&gt;@qiuqiangkong&lt;/denchmark-link&gt;
 ,
Thanks for giving it a try with the new release! Glad that it worked. I took a look at the model and it is not very big and so I hand-computed the shape at each step and it seems fine. There is no reason why it should have failed with 1.1.2. The only change between the releases is the CUDA/CuDNN upgrade. For BatchNorm, internally CuDNN BatchNorm method is called. Unless there was a bug previously which got fixed with the newer CUDA/CuDNN, I don't have any other explanation.
Can you share the model after you added the Conv layer? Maybe that will give a clue.
		</comment>
		<comment id='17' author='qiuqiangkong' date='2020-04-08T15:28:33Z'>
		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
 Sure! Here is the onnx model: &lt;denchmark-link:https://drive.google.com/open?id=1t5UMJKuFjbI7Sz7ukwRd62JPwtZEO4tH&gt;https://drive.google.com/open?id=1t5UMJKuFjbI7Sz7ukwRd62JPwtZEO4tH&lt;/denchmark-link&gt;
. It works well with onnxruntime-gpu=1.1.2 and CUDA=10.0. PyTorch code looks like:
class MyModel(nn.Module):
"""Wrapper of source separation model.
"""
def init(self):
super(MyModel, self).init()
self.bn0 = nn.BatchNorm2d(1024)
self.conv1 = nn.Conv1d(in_channels=1, out_channels=1024, kernel_size=1024, stride=1024)
self.identity = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=1, stride=1)
&lt;denchmark-code&gt;    self.conv2 = nn.Conv2d(in_channels=1, 
                          out_channels=32,
                          kernel_size=(3, 3), stride=(1, 1),
                          padding=(1, 1))

def forward(self, input):
    x = input[:, None, :]
    x = self.conv1(x).transpose(1, 2)
    x = x[:, None, :, :]

    x = x.transpose(1, 3)
    x = self.identity(x)
    x = self.bn0(x)
    x = x.transpose(1, 3)
    x = self.conv2(x)

    return torch.mean(x)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='18' author='qiuqiangkong' date='2020-04-17T21:50:54Z'>
		Took a look. Not sure why the Conv node helped before. My guess is the values previously triggered some sort of numerical instability and probably that ot fixed in  the newer version of CuDNN. Either way, closing this issue out for now since it is working with current release. Thanks!
		</comment>
	</comments>
</bug>