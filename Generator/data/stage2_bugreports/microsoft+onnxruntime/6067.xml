<bug id='6067' author='jiafatom' open_date='2020-12-07T21:41:35Z' closed_time='2021-01-11T10:58:41Z'>
	<summary>ConvTranspose output_shape seems wrong for dynamic input shape when auto_pad='SAME_LOWER'</summary>
	<description>
Describe the bug
ConvTranspose output_shape seems wrong for dynamic input shape when auto_pad='SAME_LOWER'
Urgency
none
System information
master

I have a keras model and convert to ONNX. See attached please remove 'zip' at the end.
&lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/5654778/conv_transpose.onnx.zip&gt;conv_transpose.onnx.zip&lt;/denchmark-link&gt;

The python code running ORT:
import numpy as np
import onnxruntime
sess = onnxruntime.InferenceSession('conv_transpose.onnx')
data1 = np.random.rand(2 * 3 * 4 * 5).astype(np.float32).reshape(2, 3, 4, 5)
data = [data1]
input_names = sess.get_inputs()
feed = zip(sorted(i_.name for i_ in input_names), data)
feed_input = dict(feed)
actual = sess.run(None, feed_input)
The output shape is (2,3,6,8), but keras output shape is (2,2,2,8). With some debug, the issue is that output_shape in ComputePadsAndOutputShape() is unknown for auto_pad='SAME_LOWER'. In this case, it seems wrong to apply out_size = (in_size - 1) * stride + adj + (kernel - 1) * dilation + 1; because there is no guarantee that input_size=output_size which is suggested by SAME_LOWER.
	</description>
	<comments>
		<comment id='1' author='jiafatom' date='2020-12-07T21:46:32Z'>
		Any chance this will solve it ? - &lt;denchmark-link:https://github.com/microsoft/onnxruntime/pull/4271&gt;#4271&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='jiafatom' date='2020-12-08T05:05:51Z'>
		Yes it does resolve the issue for  case. For , need onnx spec change, so raise an issue &lt;denchmark-link:https://github.com/onnx/onnx/issues/3153&gt;there&lt;/denchmark-link&gt;
. We can close this onnxruntime issue once the above mentioned PR gets checked in.
		</comment>
		<comment id='3' author='jiafatom' date='2020-12-08T18:13:56Z'>
		Makes sense, thank David. Btw - do all the new 4 keras models need stride &gt; 1 ? Or is there s a model that uses stride == 1 ? If there is a real model that uses stride == 1 and auto_pad attribute, we can run a final verification and merge that fix in.
		</comment>
		<comment id='4' author='jiafatom' date='2020-12-08T18:30:55Z'>
		These four models don't use stride=1. They use strides=2 (this is the most common case)
&lt;denchmark-link:https://github.com/MrGiovanni/UNetPlusPlus/blob/master/keras/segmentation_models/unet/blocks.py#L49&gt;unet_plusplus&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/yu4u/noise2noise/blob/master/model.py#L107&gt;unet&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/xuannianz/keras-CenterNet/blob/master/models/resnet.py#L151&gt;center-net&lt;/denchmark-link&gt;
 (this include actually two models when enable nms or not)
		</comment>
		<comment id='5' author='jiafatom' date='2020-12-08T23:05:39Z'>
		Quick clarification though - do we need the auto_pad attribute ? Can we use explicit padding or is it because the model consumes dynamic shaped inputs ?
		</comment>
		<comment id='6' author='jiafatom' date='2020-12-08T23:34:49Z'>
		Yes it is because the model consumes dynamic shaped inputs, so we have to use auto_pad.
		</comment>
		<comment id='7' author='jiafatom' date='2021-01-11T10:58:41Z'>
		Closing as the ORT change supporting auto_pad in ConvTranspose is checked-in
		</comment>
	</comments>
</bug>