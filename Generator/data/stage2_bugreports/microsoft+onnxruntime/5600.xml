<bug id='5600' author='zhuxiaoxuhit' open_date='2020-10-27T08:39:24Z' closed_time='2020-11-13T08:43:11Z'>
	<summary>Unstable inference results with c++</summary>
	<description>
Describe the bug
I converted tensorflow model (tacotron) to onnx with c++ on cpu. Everything is going well. But a phenomenon puzzled me : I created session once, then made inferences with same input repeatedly, but got different results.
Is there something random somewhere in onnxruntime?
ps: I used dropout in inference, but set a fixed seed value in advance.
System information

OS Platform and Distribution:CentOS Linux release 7.5.1804
ONNX Runtime installed from (source or binary): source
ONNX Runtime version: master
Python version: 3.6

Expected behavior
Get same results everytime inference.

&lt;denchmark-link:https://user-images.githubusercontent.com/32813150/97276987-de4f2800-1872-11eb-98c9-dbb38159f99e.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='zhuxiaoxuhit' date='2020-10-28T17:45:48Z'>
		Would you be able to share the model and the commit you used to build the product off?
		</comment>
		<comment id='2' author='zhuxiaoxuhit' date='2020-10-29T04:25:30Z'>
		&lt;denchmark-link:https://github.com/yuslepukhin&gt;@yuslepukhin&lt;/denchmark-link&gt;

Met the same problem.
I have tested ORT-1.3.0, 1.4.0 and 1.5.2 with python &amp; c++.
Here is my model and image. &lt;denchmark-link:https://drive.google.com/file/d/1XpLTfNpqEdBVi1glnHFtMDvdDT38C7Tn/view?usp=sharing&gt;https://drive.google.com/file/d/1XpLTfNpqEdBVi1glnHFtMDvdDT38C7Tn/view?usp=sharing&lt;/denchmark-link&gt;

Here is my python code.
&lt;denchmark-code&gt;import onnxruntime
import cv2
import torch
sess = onnxruntime.InferenceSession('./test.onnx')
inputs = cv2.imread('1.jpg')
inputs = cv2.resize(inputs, (800,1067))
inputs = torch.as_tensor(inputs.astype('float32').transpose(2,0,1))
inputs = inputs.unsqueeze(0)
for i in range(100):
    res = sess.run(None, {sess.get_inputs()[0].name:inputs.numpy()})
    print (res[0].shape[0])
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='zhuxiaoxuhit' date='2020-10-31T02:47:34Z'>
		&lt;denchmark-link:https://github.com/yuslepukhin&gt;@yuslepukhin&lt;/denchmark-link&gt;
 Is this bug fixed? I want to share some information. I compared params ’Training‘ in tensorflow dropout,



params/results
Run 1 times with 1 session
Run many times with 1 session




Training=True
diff
diff


Training=False
same
diff



		</comment>
		<comment id='4' author='zhuxiaoxuhit' date='2020-11-02T17:34:00Z'>
		&lt;denchmark-link:https://github.com/zhuxiaoxuhit&gt;@zhuxiaoxuhit&lt;/denchmark-link&gt;
 Thank you for this datapoint.
		</comment>
		<comment id='5' author='zhuxiaoxuhit' date='2020-11-02T19:34:43Z'>
		&lt;denchmark-link:https://github.com/zhuxiaoxuhit&gt;@zhuxiaoxuhit&lt;/denchmark-link&gt;
 The issue title uses the term , however, later in the comment you mention the same results. We can't guarantee the latter with the floating point arithmetic. Looking at the chart you published it looks very similar with some time shift. What is your tolerance? We often can not produce more precision than 3 digits after decimal point.
Some output examples would be helpful.
		</comment>
		<comment id='6' author='zhuxiaoxuhit' date='2020-11-03T07:09:22Z'>
		&lt;denchmark-link:https://github.com/yuslepukhin&gt;@yuslepukhin&lt;/denchmark-link&gt;

Thank u ^-^
"STABLE" means that:
"create session one time, then do inference many times with the same input -&gt; get same results."
but now we got different results, I want to konw y. I read source code and didn't find the reason, this is the first question.
The second is aboout dropout. When I use dropout in inference,    I find method "RandomUniform::Compute()" in "onnxruntime/core/providers/cpu/generator/random.cc" is called, but  "onnxruntime/core/providers/cpu/nn/dropout_op.h"  is not called.  I wnat to know how dropout_op works and how to modify the value of seed in c++ api.
sess = onnxruntime.InferenceSession('./test.onnx')
inputs = cv2.imread('1.jpg')
inputs = cv2.resize(inputs, (800,1067))
inputs = torch.as_tensor(inputs.astype('float32').transpose(2,0,1))
inputs = inputs.unsqueeze(0)
for i in range(100):
    res = sess.run(None, {sess.get_inputs()[0].name:inputs.numpy()})
		</comment>
		<comment id='7' author='zhuxiaoxuhit' date='2020-11-03T22:32:19Z'>
		Here is the documentation for &lt;denchmark-link:https://github.com/onnx/onnx/blob/master/docs/Operators.md#Dropout&gt;Dropout&lt;/denchmark-link&gt;
.
If you run it in training mode, there will be a randomized dropout.  In inference mode  where output is a copy of the input nothing is dropped out and our optimizer eliminates Dropout node from the execution graph. So if you are running an inference, the issue is probably not in the dropout.
		</comment>
		<comment id='8' author='zhuxiaoxuhit' date='2020-11-03T23:17:57Z'>
		I have not answered your question fully. Seed is an attribute of Dropout and as such it is a part of the serialized model, which is protobuf. At runtime, attributes are const. If you want to modify it you would have to edit the model and protobuf has many APIs to accomplish that, including python and C++.
		</comment>
		<comment id='9' author='zhuxiaoxuhit' date='2020-11-04T01:49:07Z'>
		I just built a Debug build on Windows  off &lt;denchmark-link:https://github.com/microsoft/onnxruntime/commit/c9f44276da0919c4c7e7409210142beb61c8ab11&gt;c9f4427&lt;/denchmark-link&gt;
 master. And ran the above script and the model. I have got 100 identical results.  I have not tried Linux yet as I was short on time.
6
[[ 87.6838  807.0981  229.68369 942.5767 ]
[442.69327 282.0529  538.2384  343.02744]
[381.2425  297.12918 426.899   317.2443 ]
[268.38806 454.03195 299.77087 547.7364 ]
[381.59628 275.90866 424.5983  343.25797]
[444.21994 284.96368 490.20328 344.88654]]
6
[[ 87.6838  807.0981  229.68369 942.5767 ]
[442.69327 282.0529  538.2384  343.02744]
[381.2425  297.12918 426.899   317.2443 ]
[268.38806 454.03195 299.77087 547.7364 ]
[381.59628 275.90866 424.5983  343.25797]
[444.21994 284.96368 490.20328 344.88654]]
6
[[ 87.6838  807.0981  229.68369 942.5767 ]
[442.69327 282.0529  538.2384  343.02744]
[381.2425  297.12918 426.899   317.2443 ]
[268.38806 454.03195 299.77087 547.7364 ]
[381.59628 275.90866 424.5983  343.25797]
[444.21994 284.96368 490.20328 344.88654]]
...
		</comment>
		<comment id='10' author='zhuxiaoxuhit' date='2020-11-04T02:10:27Z'>
		&lt;denchmark-link:https://github.com/yuslepukhin&gt;@yuslepukhin&lt;/denchmark-link&gt;
 have you tried this on gpu? It is stable on cpu. The problem will be happen only under gpu mode.
		</comment>
		<comment id='11' author='zhuxiaoxuhit' date='2020-11-04T17:42:23Z'>
		&lt;denchmark-link:https://github.com/freedenS&gt;@freedenS&lt;/denchmark-link&gt;
 This specific ticket talks about differences on CPU. Although the example is yours, I would appreciate the feedback from &lt;denchmark-link:https://github.com/zhuxiaoxuhit&gt;@zhuxiaoxuhit&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='12' author='zhuxiaoxuhit' date='2020-11-04T19:38:52Z'>
		Tested optimized build on CPU, works the same.
Tested Debug build on GPU, shows identical results to the 3rd decimal.
6
[[ 87.68379 807.0981  229.68367 942.5767 ]
[442.69327 282.05286 538.2384  343.0274 ]
[381.2425  297.12918 426.899   317.2443 ]
[268.38806 454.03192 299.77087 547.7363 ]
[381.59628 275.90866 424.5983  343.25797]
[444.21994 284.96368 490.20328 344.88654]]
GPU Optimized build windows:
6
[[ 87.68381 807.0981  229.68362 942.5767 ]
[442.69327 282.05286 538.2384  343.0274 ]
[381.2425  297.12918 426.899   317.2443 ]
[268.38806 454.03192 299.77087 547.7364 ]
[381.59628 275.90866 424.5983  343.25797]
[444.21994 284.96368 490.20328 344.88654]]
I have a suggestion. Perhaps, the issue was fixed? Happens all the time. Try that commit for yourself especially on Linux.
python  --version
Python 3.6.8 :: Anaconda, Inc.
		</comment>
		<comment id='13' author='zhuxiaoxuhit' date='2020-11-05T02:12:53Z'>
		&lt;denchmark-link:https://github.com/yuslepukhin&gt;@yuslepukhin&lt;/denchmark-link&gt;
 Thanks for your help! I'll take a try.
		</comment>
	</comments>
</bug>