<bug id='1056' author='Legorock' open_date='2019-05-17T10:09:37Z' closed_time='2019-05-28T23:38:40Z'>
	<summary>Onnx Backend API 'run_model' is broken</summary>
	<description>
Describe the bug
A clear and concise description of what the bug is.
Trying to run an Onnx model with Onnx Backend API raises TypeError exception
because it cannot call 'rep.run()' with 2 arguments (inputs, options).
I can invoke rep.run manually with 1 argument however, 'run_model' tries to have 'options' argument as well.
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
ONNX Runtime installed from (source or binary): pip install onnxruntime
ONNX Runtime version:  0.4.0
Python version: 3.6
CUDA/cuDNN version, GPU model and memory: no GPU

To Reproduce
Describe steps/code to reproduce the behavior:

Load an onnx model with onnx.load
create numpy arrays according to the model input dimensions
import ONNX Runtime backend such as
"from onnxruntime.backend.backend import OnnxRuntimeBackend as backend"
run "backend.run_model(onnx_model, inputs)"

Expected behavior
A clear and concise description of what you expected to happen.
Run  a simple Onnx Model in a runtime agnostic way given the model inputs.

If applicable, add screenshots to help explain your problem.
In the screenshot, it is not shown but 'rep' object is created with 'cls.prepare' using the onnx model/
&lt;denchmark-link:https://user-images.githubusercontent.com/6500946/57920756-1986b280-789c-11e9-9d76-02df23007613.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Legorock' date='2019-05-17T19:04:02Z'>
		&lt;denchmark-link:https://github.com/Legorock&gt;@Legorock&lt;/denchmark-link&gt;
 Would you, please, share your script?
		</comment>
		<comment id='2' author='Legorock' date='2019-05-21T07:39:40Z'>
		I am not at work until Thursday, I will be able to share my script when I will be in my office.
		</comment>
		<comment id='3' author='Legorock' date='2019-05-23T07:51:17Z'>
		&lt;denchmark-code&gt;import sys
import pathlib

import onnx
import numpy as np
from onnxruntime.backend.backend import OnnxRuntimeBackend as backend
# import caffe2.python.onnx.backend as backend

def gen_inputs(ttypes):
	return [np.random.rand(*[d.dim_value for d in tt.dim])  for tt in ttypes]

def main():
	model_path = sys.argv[1]
	model_path = pathlib.Path(model_path)
	assert model_path.exists()

	model = onnx.load(str(model_path))

	o_inputs = [x for x in model.graph.input 
				if not x.name in [y.name for y in model.graph.initializer]]

	cm_inputs = gen_inputs([i.type.tensor_type.shape for i in o_inputs])
	cm_inputs = [n.astype(np.float32) for n in cm_inputs]

	backend.run_model(model, cm_inputs)

if __name__ == "__main__":
	assert len(sys.argv) == 2, "invalid number of arguments!"
	main()
&lt;/denchmark-code&gt;

Above is my script. It is supposed to be launched with onnx model as the 1st commad-line argument.
If you replace  with , it works.
Output:
&lt;denchmark-link:https://user-images.githubusercontent.com/6500946/58234793-abc90380-7d3f-11e9-8f97-dfd3c3794d59.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Legorock' date='2019-05-28T23:38:40Z'>
		&lt;denchmark-link:https://github.com/Legorock&gt;@Legorock&lt;/denchmark-link&gt;
 I hope this addresses the issue. Pls, reopen if you feel that something more is needed.
		</comment>
	</comments>
</bug>