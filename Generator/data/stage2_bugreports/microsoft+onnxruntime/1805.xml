<bug id='1805' author='jinfagang' open_date='2019-09-11T06:33:16Z' closed_time='2019-09-26T21:49:25Z'>
	<summary>bool onnxruntime::TransformerMemcpyImpl::ProcessInitializers(const onnxruntime::KernelRegistryManager&amp;, const InitializedTensorSet&amp;) status.IsOK() was false. Failed to find kernel for MemcpyFromHost (node Memcpy_1)</summary>
	<description>
&lt;denchmark-code&gt;"""
Verified against

    pytorch-nightly: 1.2.0.dev20190604-py3.7_cuda10.0.130_cudnn7.5.1_0 pytorch
    torchvision:     from source 04188377c54aa9073e4c2496ddd9996da9fda629
    onnx:            1.5.0
    onnxruntime:     0.4.0
"""
import onnxruntime

from PIL import Image
import numpy as np

import matplotlib.pyplot as plt
import matplotlib.patches as patches
from alfred.vis.image.get_dataset_label_map import coco_label_map_list
from alfred.utils.log import logger as logging
import cv2
import time


def preprocess(image):
    # Resize
    ratio = 800.0 / min(image.shape[0], image.shape[1])
    # image = image.resize(
    #     (int(ratio * image.shape[0]), int(ratio * image.shape[1])),
    #     Image.BILINEAR)
    image = cv2.resize(image, (int(ratio * image.shape[1]), int(ratio * image.shape[0])))
    # HWC -&gt; CHW
    image = np.transpose(image, [2, 0, 1])
    # Normalize
    mean_vec = np.array([102.9801, 115.9465, 122.7717])
    for i in range(image.shape[0]):
        image[i, :, :] = image[i, :, :] - mean_vec[i]

    # Pad to be divisible of 32
    import math
    padded_h = int(math.ceil(image.shape[1] / 32) * 32)
    padded_w = int(math.ceil(image.shape[2] / 32) * 32)

    padded_image = np.zeros((3, padded_h, padded_w), dtype=np.float32)
    padded_image[:, :image.shape[1], :image.shape[2]] = image
    image = padded_image
    return image


classes = coco_label_map_list

session = onnxruntime.InferenceSession('models/faster_rcnn_R_50_FPN_1x.onnx')
logging.info('onnx session loaded.')

img = cv2.imread('images/17790319373_bd19b24cfc_k.jpg')
img = np.array(img, dtype=np.float32)
img_data = preprocess(img)
tic = time.time()
boxes, labels, scores = session.run(None,
                                    {session.get_inputs()[0].name: img_data})
logging.info('finished in: {}'.format(time.time() - tic))
print(boxes.shape)
print(labels.shape)
print(scores.shape)


def display_objdetect_image(image, boxes, labels, scores, score_threshold=0.7):
    # Resize boxes
    image = np.array(image, dtype=np.uint8)
    ratio = 800.0 / min(image.shape[0], image.shape[1])
    boxes /= ratio
    # Showing boxes with score &gt; 0.7
    for box, label, score in zip(boxes, labels, scores):
        if score &gt; score_threshold:
            box = np.array(box, dtype=np.int)
            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (255, 255, 0), 2)
            cv2.putText(image, classes[label], (box[0], box[1]),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255))
    cv2.imshow('res', image)
    cv2.waitKey(0)

display_objdetect_image(img, boxes, labels, scores)

&lt;/denchmark-code&gt;

this code runs successfully on CPU onnxruntime. But with ort build with CUDA and TensorRT, I got this error:
&lt;denchmark-code&gt;Found dynamic input: image
Marking entire graph as unsupported.
2019-09-11 14:26:39.288644099 [E:onnxruntime:Default, inference_session.cc:554 Initialize] Exception during initialization: /onnxruntime/core/optimizer/transformer_memcpy.cc:333 bool onnxruntime::TransformerMemcpyImpl::ProcessInitializers(const onnxruntime::KernelRegistryManager&amp;, const InitializedTensorSet&amp;) status.IsOK() was false. Failed to find kernel for MemcpyFromHost (node Memcpy_1)
Stacktrace:

Traceback (most recent call last):
  File "demo_onnxrt_fasterrcnn.py", line 49, in &lt;module&gt;
    session = onnxruntime.InferenceSession('models/faster_rcnn_R_50_FPN_1x.onnx')
  File "/usr/local/lib/python3.5/dist-packages/onnxruntime/capi/session.py", line 29, in __init__
    self._sess.load_model(path_or_bytes)
RuntimeError: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: onnxruntime/core/optimizer/transformer_memcpy.cc:333 bool onnxruntime::TransformerMemcpyImpl::ProcessInitializers(const onnxruntime::KernelRegistryManager&amp;, const InitializedTensorSet&amp;) status.IsOK() was false. Failed to find kernel for MemcpyFromHost (node Memcpy_1)
Stacktrace:

&lt;/denchmark-code&gt;

What else should I do to make it inference on GPU with TensorRT? Does it related with transform?Should I move data to GPU first before I call sess.run??
	</description>
	<comments>
		<comment id='1' author='jinfagang' date='2019-09-11T06:54:59Z'>
		Run onnxruntime_pref_test result:
&lt;denchmark-code&gt;./onnxruntime_perf_test -e tensorrt -r 10 /models/faster_rcnn_R_50_FPN_1x.onnx a.txt 
Setting thread pool size to -1
Found dynamic input: image
Marking entire graph as unsupported.
2019-09-11 14:53:44.169916923 [E:onnxruntime:Default, inference_session.cc:554 Initialize] Exception during initialization: /onnxruntime/onnxruntime/core/optimizer/transformer_memcpy.cc:333 bool onnxruntime::TransformerMemcpyImpl::ProcessInitializers(const onnxruntime::KernelRegistryManager&amp;, const InitializedTensorSet&amp;) status.IsOK() was false. Failed to find kernel for MemcpyFromHost (node Memcpy_1)
Stacktrace:

Exception during initialization: onnxruntime/onnxruntime/core/optimizer/transformer_memcpy.cc:333 bool onnxruntime::TransformerMemcpyImpl::ProcessInitializers(const onnxruntime::KernelRegistryManager&amp;, const InitializedTensorSet&amp;) status.IsOK() was false. Failed to find kernel for MemcpyFromHost (node Memcpy_1)
Stacktrace:

&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='jinfagang' date='2019-09-13T05:24:19Z'>
		Is this issue same with &lt;denchmark-link:https://github.com/microsoft/onnxruntime/issues/1786&gt;#1786&lt;/denchmark-link&gt;
 ?
		</comment>
	</comments>
</bug>