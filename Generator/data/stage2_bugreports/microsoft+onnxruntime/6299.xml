<bug id='6299' author='zr1161309493' open_date='2021-01-11T03:40:04Z' closed_time='2021-01-18T07:44:10Z'>
	<summary>Why does a custom OP that only supports cpu will insert memcpytohost before OP, but not insert memcpyfromhost after op, which will cause subsequent ops to run on cpu</summary>
	<description>

When I implemented a custom OP's cpu version, and then run the whole model on the gpu, according to the official documentation&lt;denchmark-link:https://github.com/intel/onnxruntime/blob/master/docs/AddingCustomOp.md&gt;(AddingCustomOp.md)&lt;/denchmark-link&gt;
,memcpytohost will be added before the op, and memcpyfromhost will be added after the op to ensure automatic data conversion, but in actual testing , I found that the data will not be copied back to the gpu, and all subsequent operations will be run on the cpu, resulting in the running time not meeting expectations.
&lt;denchmark-link:https://user-images.githubusercontent.com/33832771/104145937-dfb8d700-5403-11eb-800e-89f695ab9a7f.png&gt;&lt;/denchmark-link&gt;

Urgency
If there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.
System information

OS Platform and Distribution : CentOs Linux release 7.4.1708
ONNX Runtime installed from (source or binary): source
ONNX Runtime version: 1.4.0
Python version: 3.7.0
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 5.4
GPU model and memory: Tesla P40

To Reproduce

Build an onnx, one of the op is an OP implemented by only the cpu (regardless of whether it is a custom op), set the session_option to run on the gpu, use the log printing function of onnxruntime, you can see what device the op is running on.

Expected behavior
Memcpytohost should be added before the op, and memcpyfromhost should be added after the op to ensure automatic data conversion.
	</description>
	<comments>
		<comment id='1' author='zr1161309493' date='2021-01-11T05:09:29Z'>
		Can you please share the full log ?
Can you share a minimal model and your code to run the model (the one in the screenshot should do) ?
Can you upgrade to a newer ORT version and try ?
		</comment>
		<comment id='2' author='zr1161309493' date='2021-01-11T07:02:38Z'>
		I used the ort 1.5.1 version, and this problem still occurs, but I find that the latest version 1.6.0 seems to have made relevant changes to this, I will re-test it on the latest version.
I will upload follow-up results and specific information here.  Thanks a lot.
		</comment>
		<comment id='3' author='zr1161309493' date='2021-01-18T07:44:10Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/33832771/104885927-cf749f00-59a3-11eb-9a0d-6fdd23171e56.png&gt;&lt;/denchmark-link&gt;


I used the new version of onnxruntime1.6.0 to test and found that this problem has been fixed, and the memcpy operation mentioned in the document can be done.
Thanks a lot.
      
		</comment>
	</comments>
</bug>