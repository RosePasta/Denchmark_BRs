<bug id='3417' author='vuvko' open_date='2020-04-03T11:41:07Z' closed_time='2020-04-13T22:02:19Z'>
	<summary>Segmentation fault on loading quantized model</summary>
	<description>
Describe the bug
Onnxruntime raises SIGSEGV signal on loading the quantized model.
Urgency
If there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
ONNX Runtime installed from (source or binary): binary
ONNX Runtime version: 1.2.0
Python version: 3.6.9
Visual Studio version (if applicable): not applicable
GCC/Compiler version (if compiling from source): not applicable
CUDA/cuDNN version: not applicable
GPU model and memory: not applicable


Google Colab &lt;denchmark-link:https://colab.research.google.com/drive/1mk9b-_5dlAiSsMYqWvxcYfqxjhi4juRq&gt;link&lt;/denchmark-link&gt;
 for reproduction.
Github Gist &lt;denchmark-link:https://gist.github.com/vuvko/e5fa172387f9a12b6936e8505cded394&gt;link&lt;/denchmark-link&gt;
 for the reference (&lt;denchmark-link:https://drive.google.com/open?id=1HJP28RcVym3bj70pK_k4LMUQnBj6uoQN&gt;model file&lt;/denchmark-link&gt;
).
Run all cells for the colab notebook, or run the script from Gist with a saved model file as .
Expected behavior
Expected to see an input0 to be printed (it's an input layer's name).

The original model is a modified face detector in PyTorch (&lt;denchmark-link:https://drive.google.com/open?id=1Ni8WfR1gdhvz-T2fdfuC5gc_E_7xo6B3&gt;params file&lt;/denchmark-link&gt;
). It was converted using  (&lt;denchmark-link:https://drive.google.com/open?id=1lje7hI0Eiatk_SjHGk5lyjADQU-YMVMG&gt;converted model&lt;/denchmark-link&gt;
). The converted model can be used as it is but after quantization with &lt;denchmark-link:https://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/quantization&gt;quantization tool&lt;/denchmark-link&gt;
 it cannot be loaded with onnxruntime.
This was tested on google colab, and ArchLinux machine (python 3.8, gcc 9.3, building from source and binary provided by PyPi).
Running this with gdb shows this stack:
&lt;denchmark-code&gt;[New Thread 0x7fffe2ffd700 (LWP 669857)]
[New Thread 0x7fffe27fc700 (LWP 669858)]
[New Thread 0x7fffe1ffb700 (LWP 669859)]
[New Thread 0x7fffe17fa700 (LWP 669860)]
[New Thread 0x7fffe0ff9700 (LWP 669861)]

Thread 1 "python" received signal SIGSEGV, Segmentation fault.
onnxruntime::DequantizeLinear&lt;unsigned char&gt;::Compute (this=0x55555607f5e0, 
    ctx=0x7fffffffc5b0)
    at /home/andrey/libs/onnxruntime/include/onnxruntime/core/framework/tensor_shape.h:47
47	    return std::vector&lt;int64_t&gt;::operator[](static_cast&lt;int&gt;(idx));

&lt;/denchmark-code&gt;

I tested loading other quantized models, and everything works with &lt;denchmark-link:https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/quantization/E2E_example_model/resnet50_v1.onnx&gt;resnet50_v1&lt;/denchmark-link&gt;
 model.
	</description>
	<comments>
		<comment id='1' author='vuvko' date='2020-04-03T12:24:27Z'>
		Apparently, switching the optimization off with GraphOptimizationLevel::ORT_DISABLE_ALL  allow to load the model, but sess.run raises SIGSEGV.
Code to reproduce:
&lt;denchmark-code&gt;import numpy as np
import onnxruntime as rt


sess_options = rt.SessionOptions()
sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_DISABLE_ALL
sess = rt.InferenceSession('model_q.onnx', sess_options)
input_name = sess.get_inputs()[0].name

print(input_name)

np_inputs = np.zeros((1, 3, 320, 320), dtype=np.float32)

onnx_res = sess.run(None, {input_name: np_inputs})
print(np.max(onnx_res[0]))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='vuvko' date='2020-04-03T17:06:20Z'>
		&lt;denchmark-link:https://github.com/yufenglee&gt;@yufenglee&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/zhanghuanrong&gt;@zhanghuanrong&lt;/denchmark-link&gt;
 The implementation of DequantizeLinear is overly complicated: it has support for an axis attribute that doesn't exist in the ONNX spec. This is probably based on the old QuantizeLinear implementation in the com.ms namespace that also had an axis attribute. In this case, the input tensor is a scalar and the "broadcastDim=x_shape[axis]" faults. This could be fixed by stripping out all the axis code. Something one of you wants to fix?
		</comment>
		<comment id='3' author='vuvko' date='2020-04-13T22:02:19Z'>
		&lt;denchmark-link:https://github.com/vuvko&gt;@vuvko&lt;/denchmark-link&gt;
 A fix for this has been checked into master. Thanks for reporting the problem!
A couple comments about your model: you may want to run the model through an ONNX optimizer before quantizing. This will allow the Conv+BatchNormalization nodes to be fused. Also, you may now see better performance using QLinearOps as the quantization mode.
As things currently stand, the model will be switching between quantized and float formats to do LeakyRelu. The runtime still needs to implement a quantized LeakyRelu to further streamline the model.
		</comment>
		<comment id='4' author='vuvko' date='2020-04-22T08:19:37Z'>
		Thank you for your fix and the comments!
		</comment>
	</comments>
</bug>