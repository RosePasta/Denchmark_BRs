<bug id='3746' author='Chmielok' open_date='2020-04-29T08:44:52Z' closed_time='2020-07-11T01:41:03Z'>
	<summary>[C# API] InferenceSession throws CUDA exception when used in a different thread</summary>
	<description>
Describe the bug
When you reuse the same InferenceSession in different threads (not at the same time of course), CUDA will throw an exception - CUDA error 700, illegal memory access. Digging deeper it turns out NativeMethods.OrtRun causes it.
This may seem like a rare case, but keep in mind just using Task.Run() can cause this exception.
Urgency
Low, a workaround is possible (not using .NET ThreadPool).
System information

OS Platform and Distribution: Windows 10
ONNX Runtime installed from: NuGet
ONNX Runtime version: 1.2.0 (same thing happens in 1.0.0)
Visual Studio version: 2019
CUDA/cuDNN version: 10.2 (same thing happens in 10.0)
GPU model and memory: GTX 1060 (6GB) + GTX 1070 (8GB)

To Reproduce

Create an InferenceSession on GPU. Model is irrelevant, but I used SegNet.
Create a dummy model input.
In a loop try to var task = Task.Run(() =&gt; session.Run(...)) and wait for the task to finish. You can also expand the task function to include thread id logging (Thread.CurrentThread.ManagedThreadId).
One loop run will always succeed, the success of next runs depend on whether they get the same thread from thread pool. If not, the program crashes.

Expected behavior
The method call should proceed as if it was run in a single-threaded environment.
	</description>
	<comments>
		<comment id='1' author='Chmielok' date='2020-07-03T20:57:56Z'>
		This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.
		</comment>
		<comment id='2' author='Chmielok' date='2020-07-11T01:40:37Z'>
		This issue has been automatically closed due to inactivity. Please reactivate if further support is needed.
		</comment>
	</comments>
</bug>