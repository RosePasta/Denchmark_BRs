<bug id='3740' author='jpcenteno80' open_date='2020-04-28T20:39:05Z' closed_time='2020-07-25T06:40:39Z'>
	<summary>Resize operator runtime exception when using torch.nn.functional.interpolate mode='trilinear'</summary>
	<description>
Describe the bug
torch.nn.functional.interpolate mode='trilinear' throws RUNTIME_EXCEPTION in onnxruntime
Urgency
Moderate... Would like to port my 3d segmentation network to ONNX. Already tried mode='nearest' but results are sub-optimal.
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
ONNX Runtime installed from (source or binary): binary (pip install onnx onnxruntime)
ONNX Runtime version: 1.2.0
Python version: 3.7.6
Visual Studio version (if applicable): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: Cuda compilation tools, release 10.1, V10.1.243
GPU model and memory: Nvidia Quadro M5000M 8GB

To Reproduce
Most from a pytorch tutorial:
&lt;denchmark-code&gt;import torch.nn as nn
import torch.nn.functional as F
import onnx, onnxruntime, torch

class InterpTri(nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, x):
        return F.interpolate(x, (192,192,192), mode='trilinear', align_corners=True)

interp_mod = InterpTri()
batch_size = 1
x = torch.randn(batch_size, 3, 128, 128, 128, requires_grad=True)
out = interp_mod(x.cuda())
interp_mod.eval()

torch.onnx.export(interp_mod, 
                  x.cuda(),
                  "super_resolution.onnx",
                  export_params=True,
                  opset_version=11,
                  do_constant_folding=True,
                  input_names = ['input'],
                  output_names = ['output'],
                  dynamic_axes={'input' : {0 : 'batch_size'},
                                'output' : {0 : 'batch_size'}})

onnx_model = onnx.load("super_resolution.onnx")
onnx.checker.check_model(onnx_model)

ort_session = onnxruntime.InferenceSession("super_resolution.onnx")

def to_numpy(tensor):
    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()

# compute ONNX Runtime output prediction
ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}
ort_outs = ort_session.run(None, ort_inputs)

# compare ONNX Runtime and PyTorch results
np.testing.assert_allclose(to_numpy(out), ort_outs[0], rtol=1e-03, atol=1e-05)

print("Exported model has been tested with ONNXRuntime, and the result looks good!")
&lt;/denchmark-code&gt;

Returns following exception:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
RuntimeException                          Traceback (most recent call last)
&lt;ipython-input-90-d6c78bfb11eb&gt; in &lt;module&gt;
      8 # compute ONNX Runtime output prediction
      9 ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}
---&gt; 10 ort_outs = ort_session.run(None, ort_inputs)
     11 
     12 # compare ONNX Runtime and PyTorch results

~/miniconda3/envs/qiltoolkit/lib/python3.7/site-packages/onnxruntime/capi/session.py in run(self, output_names, input_feed, run_options)
    140             output_names = [output.name for output in self._outputs_meta]
    141         try:
--&gt; 142             return self._sess.run(output_names, input_feed, run_options)
    143         except C.EPFail as err:
    144             if self._enable_fallback:

RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running Resize node. Name:'Resize_8' Status Message: /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/upsample.h:281 void onnxruntime::UpsampleBase::ScalesValidation(const std::vector&lt;float&gt;&amp;, onnxruntime::UpsampleMode) const scales.size() == 2 || (scales.size() == 4 &amp;&amp; scales[0] == 1 &amp;&amp; scales[1] == 1) was false. 'Linear' mode and 'Cubic' mode only support 2-D inputs ('Bilinear', 'Bicubic') or 4-D inputs with the corresponding outermost 2 scale values being 1 in the Resize operator
&lt;/denchmark-code&gt;

Expected behavior
Be able to run the onnxruntime session with this type of interpolation. Using mode='nearest' runs ok in onnxruntime, but results are not good (the above code is just to reproduce the error, the actual code to run is a 3d segmentation network).
Screenshots
N/A
Additional context
The trilinear interpolation is used in a U-net style network for 3d segmentation.
	</description>
	<comments>
		<comment id='1' author='jpcenteno80' date='2020-05-04T20:34:57Z'>
		Currently for the 'linear' mode, we only support 2D inputs (i.e.) "bilinear" (or) a special case of "quadrilinear" with no scaling required for the outermost 2 dimensions (for batched multi-channel inputs). "Trilinear" (linear with 3D inputs) are still to be supported.
		</comment>
		<comment id='2' author='jpcenteno80' date='2020-05-04T22:14:57Z'>
		Thanks &lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
. Do you have any links to some documentation (or tips) to see if I could try to fix this myself?
		</comment>
		<comment id='3' author='jpcenteno80' date='2020-05-07T03:04:51Z'>
		You can try and see if hooking this up works -


onnxruntime/onnxruntime/core/providers/cpu/tensor/upsample.cc


         Line 216
      in
      c222ed6






 Status UpsampleLinear(const T* input, 




. This was the original "generic" (i.e.) N-D linear interpolation method, but as you can see it is not called and in the same file we have UpsampleBilinear which does the 2-D interpolation, if 3-D is what you need specifically, you can see if you can adapt the 2-D implementation. We didn't find a model that requires more than a 2-D interpolation at this point...
		</comment>
		<comment id='4' author='jpcenteno80' date='2020-07-18T06:15:57Z'>
		This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.
		</comment>
		<comment id='5' author='jpcenteno80' date='2020-07-25T06:40:14Z'>
		This issue has been automatically closed due to inactivity. Please reactivate if further support is needed.
		</comment>
		<comment id='6' author='jpcenteno80' date='2020-09-28T08:18:45Z'>
		I have been getting the same issue. Did anyone solve this or found an alternative?
		</comment>
	</comments>
</bug>