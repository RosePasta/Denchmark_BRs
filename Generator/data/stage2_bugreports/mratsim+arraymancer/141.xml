<bug id='141' author='mratsim' open_date='2017-11-01T13:04:02Z' closed_time='2017-11-05T00:12:59Z'>
	<summary>Bottleneck: 30% time spent in genericSeqAssign in slicer and sigmoid_cross_entropy</summary>
	<description>
Following &lt;denchmark-link:https://github.com/mratsim/Arraymancer/commit/9834ad0212d5a53c702cf2abfd628dff61828391&gt;9834ad0&lt;/denchmark-link&gt;
 the xor benchmark is now spending 3 sec out of 11s doing GenericSeqAssign.
&lt;denchmark-link:https://user-images.githubusercontent.com/22738317/32275867-1d0e6924-bf0d-11e7-8361-3137a232483a.png&gt;&lt;/denchmark-link&gt;

Culprits:

slicers

proc slicer[T](t: AnyTensor[T],
                slices: varargs[SteppedSlice],
                ellipsis: Ellipsis): AnyTensor[T] {.noInit,noSideEffect.}=
  ## Take a Tensor, SteppedSlices and Ellipsis
  ## Returns:
  ##    A copy of the original Tensor
  ##    Offset and strides are changed to achieve the desired effect.

  result = t
  let full_slices = @slices &amp; newSeqWith(t.rank - slices.len, span)
  slicerT(result, full_slices)

proc slicer[T](t: AnyTensor[T],
                ellipsis: Ellipsis,
                slices: varargs[SteppedSlice]
                ): AnyTensor[T] {.noInit,noSideEffect.}=
  ## Take a Tensor, Ellipsis and SteppedSlices
  ## Returns:
  ##    A copy of the original Tensor
  ##    Offset and strides are changed to achieve the desired effect.

  result = t
  let full_slices = newSeqWith(t.rank - slices.len, span) &amp; @slices
  slicerT(result, full_slices)

proc slicer[T](t: AnyTensor[T],
                slices1: varargs[SteppedSlice],
                ellipsis: Ellipsis,
                slices2: varargs[SteppedSlice]
                ): AnyTensor[T] {.noInit,noSideEffect.}=
  ## Take a Tensor, Ellipsis and SteppedSlices
  ## Returns:
  ##    A copy of the original Tensor
  ##    Offset and strides are changed to achieve the desired effect.

  result = t
  let full_slices = concat(@slices1,
                            newSeqWith(t.rank - slices1.len - slices2.len, span),
                            @slices2)
  slicerT(result, full_slices)
And sigmoid_cross_entropy from nn:
N_NIMCALL(tyObject_VariablecolonObjectType__V9arbGi37a9bYRP6noahxnkg*, sigmoid_cross_entropy_JUee17nUtwwG9crOhwAktAw)(tyObject_VariablecolonObjectType__V9arbGi37a9bYRP6noahxnkg* a, tyObject_Tensor_YVEir6VZKk3q2MAtip9aD6w* target) {
	tyObject_VariablecolonObjectType__V9arbGi37a9bYRP6noahxnkg* result;
	tyObject_SigmoidCrossEntropyLosscolonObjectType__UFgVZehjkS6ZKN0TA9bM9a6Q* gate;
	tyObject_NodecolonObjectType__p32yf8YodYmaGoPmH50AWw* node;
	NI T1_;
	tyObject_LosscolonObjectType__AuSc1kjvf0sy9bIrj0fYzpQ* T2_;
	result = (tyObject_VariablecolonObjectType__V9arbGi37a9bYRP6noahxnkg*)0;
	gate = (tyObject_SigmoidCrossEntropyLosscolonObjectType__UFgVZehjkS6ZKN0TA9bM9a6Q*)0;
	gate = (tyObject_SigmoidCrossEntropyLosscolonObjectType__UFgVZehjkS6ZKN0TA9bM9a6Q*) newObj((&amp;NTI_HqKVGU8O1Eg0L2tk6CR9bTA_), sizeof(tyObject_SigmoidCrossEntropyLosscolonObjectType__UFgVZehjkS6ZKN0TA9bM9a6Q));
	(*gate).Sup.Sup.m_type = (&amp;NTI_UFgVZehjkS6ZKN0TA9bM9a6Q_);
	(*gate).Sup.Sup.arity = ((NI) 1);
	asgnRef((void**) (&amp;(*gate).cache), a);
	(*gate).Sup.target.shape = (*target).shape;
	(*gate).Sup.target.strides = (*target).strides;
	(*gate).Sup.target.offset = (*target).offset;
	genericSeqAssign((&amp;(*gate).Sup.target.data), (*target).data, (&amp;NTI_4Xyxy0Om14N6K1l5e9bUPSQ_));   // &lt;&lt;&lt;----------------- HERE
	node = (tyObject_NodecolonObjectType__p32yf8YodYmaGoPmH50AWw*)0;
	node = (tyObject_NodecolonObjectType__p32yf8YodYmaGoPmH50AWw*) newObj((&amp;NTI_u2b9cqonYlV8r9bWdpfPYhKQ_), sizeof(tyObject_NodecolonObjectType__p32yf8YodYmaGoPmH50AWw));
	asgnRef((void**) (&amp;(*node).gate), gate);
	asgnRef((void**) (&amp;(*node).parents[(((NI) 0))- 0]), a);
	(*(*a).tape).nodes = (tySequence_vShYhtvHQtyhCu8g2tVy6Q*) incrSeqV2(&amp;((*(*a).tape).nodes)-&gt;Sup, sizeof(tyObject_NodecolonObjectType__p32yf8YodYmaGoPmH50AWw*));
	T1_ = (*(*a).tape).nodes-&gt;Sup.len++;
	asgnRef((void**) (&amp;(*(*a).tape).nodes-&gt;data[T1_]), node);
	T2_ = (tyObject_LosscolonObjectType__AuSc1kjvf0sy9bIrj0fYzpQ*)0;
	T2_ = &amp;gate-&gt;Sup;
	result = forward_qAuDJ4FSE2zIoYPtuAdhHg(T2_, a, target);
	asgnRef((void**) (&amp;(*result).ancestor), node);
	asgnRef((void**) (&amp;(*node).child), result);
	return result;
}
	</description>
	<comments>
		<comment id='1' author='mratsim' date='2017-11-01T13:15:37Z'>
		Sigmoid_cross_entropy useless alloc fixed in &lt;denchmark-link:https://github.com/mratsim/Arraymancer/commit/aa7a803822572ee2de7d836ae84a15deebb81832&gt;aa7a803&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/22738317/32276356-1e7b644a-bf0f-11e7-86f8-d844d3617660.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='mratsim' date='2017-11-03T21:50:37Z'>
		The previous implementation of sparse_softmax_cross_entropy was also heavily affected.
&lt;denchmark-link:https://user-images.githubusercontent.com/22738317/32397222-0f458416-c0e9-11e7-9837-e556b340f8b6.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='mratsim' date='2017-11-03T22:54:26Z'>
		&lt;denchmark-h:h2&gt;The plan:&lt;/denchmark-h&gt;

Similar to metadataArray introduce a sliceArray type allocated on the stack.
Note: varargs[SteppedSlices] should not catch a sliceArray.
&lt;denchmark-h:h2&gt;How?&lt;/denchmark-h&gt;

Modify metadataArray to be derived from a generic base type and slice Array should be the same:
type
  FooArray*[T] = object
    data*: array[MAXRANK, T]
    len*: int

  MetadataArray = FooArray[int]
  SliceArray = FooArray[SteppedSlices]
		</comment>
		<comment id='4' author='mratsim' date='2017-11-05T00:12:59Z'>
		In fine, the main issue in softmax_cross_entropy was forgetting to use unsafeSlice.
In any case heap allocated / GC-managed memory has been reduced to just the Tensor data. Everything else is allocated on the stack, it is now possible to use unsafeSlicing within an OpenMP loop. Memory usage is also more predictable and there is much less risk of fragmentation due to allocating/free small seq (2 or 3 elements slices) in rapid succession.
Gains in terms of performance is inconclusive. At least there is no loss.
Closed by &lt;denchmark-link:https://github.com/mratsim/Arraymancer/commit/d553685f5d30c7ed7192615e897467732e9695ab&gt;d553685&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>