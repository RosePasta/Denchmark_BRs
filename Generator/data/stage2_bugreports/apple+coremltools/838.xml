<bug id='838' author='gilevir' open_date='2020-08-04T13:38:29Z' closed_time='2020-08-04T15:00:52Z'>
	<summary>Context ValueError when using custom convert function for replication_pad2d layer</summary>
	<description>
&lt;denchmark-h:h2&gt;üêûDescribe the bug&lt;/denchmark-h&gt;

I need to convert a TorchScript that uses a replication_pad2d layer. Since the convert function for this op doesn't exist, I did a custom one, following the &lt;denchmark-link:https://coremltools.readme.io/docs/composite-operators&gt;Composite Operators documentation&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;@register_torch_op
def replication_pad2d(context, node):
    inp = context[node.inputs[0]]
    pad = context[node.inputs[1]]

    x = mb.pad(x=inp, pad=pad, mode='replicate', name=node.name)
    
    context.add(node.name, x)
&lt;/denchmark-code&gt;

But got the following error when converting this particular node : ValueError: Torch var input0.1 not found in context
&lt;denchmark-h:h2&gt;Trace&lt;/denchmark-h&gt;

End of stack trace:
&lt;denchmark-code&gt;/usr/local/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/ops.py in convert_nodes(context, graph)
     52             )
     53         else:
---&gt; 54             _add_op(context, node)
     55 
     56         # We've generated all the outputs the graph needs, terminate conversion.

/usr/local/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/ops.py in _convolution(context, node)
    343 @register_torch_op(torch_alias=["conv2d"])
    344 def _convolution(context, node):
--&gt; 345     inputs = _get_inputs(context, node)
    346 
    347     x = inputs[0]

/usr/local/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/ops.py in _get_inputs(context, node, expected)
    119         value of @expcted.
    120     """
--&gt; 121     inputs = [context[name] for name in node.inputs]
    122     if expected is not None and len(inputs) != expected:
    123         raise ValueError(

/usr/local/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/ops.py in &lt;listcomp&gt;(.0)
    119         value of @expcted.
    120     """
--&gt; 121     inputs = [context[name] for name in node.inputs]
    122     if expected is not None and len(inputs) != expected:
    123         raise ValueError(

/usr/local/lib/python3.7/site-packages/coremltools/converters/mil/frontend/torch/converter.py in __getitem__(self, torch_name)
     70                 return self._current_graph[idx][torch_name]
     71         raise ValueError(
---&gt; 72             "Torch var {} not found in context {}".format(torch_name, self.name)
     73         )
     74 

ValueError: Torch var input0.1 not found in context 
&lt;/denchmark-code&gt;

The PyTorch model definition is as simple as that:
&lt;denchmark-code&gt;class Net(nn.Module):
    def __init__(self):
        super(ThinningNet, self).__init__()
        self.layers = nn.Sequential(
            nn.ReplicationPad2d(4),
            Conv(1, 64, 1, 9, 0),
            Conv(64, 64),
            Conv(64, 64),
            Conv(64, 64),
            Conv(64, 64),
            Conv(64, 64),
            Conv(64, 64),
            Conv(64, 64),
            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)
        )

    def forward(self, x):
        return torch.sigmoid(self.layers(x - 0.7))
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;System environment (please complete the following information):&lt;/denchmark-h&gt;


coremltools version  4.0.b2
macOS version : 10.15.5
XCode version : 11.6
python version 3.7
PyTorch version : 1.5.0

	</description>
	<comments>
		<comment id='1' author='gilevir' date='2020-08-04T14:59:26Z'>
		Did you flip the arguments at
context.add(node.name, x)
Should be ?
context.add(x, node.name)
		</comment>
		<comment id='2' author='gilevir' date='2020-08-04T15:00:51Z'>
		Indeed, just found it out. Runs smoothly now üëç
The code snippet in the documentation should be corrected accordingly though
		</comment>
	</comments>
</bug>