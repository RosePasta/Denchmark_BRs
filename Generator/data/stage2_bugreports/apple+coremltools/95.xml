<bug id='95' author='corneel' open_date='2017-12-21T22:38:16Z' closed_time='2019-11-13T22:29:53Z'>
	<summary>"ValueError: No outputs can be identified" when converting Keras Tensorflow model with coremltools</summary>
	<description>
The latest changes ( &lt;denchmark-link:https://github.com/apple/coremltools/commit/5b9ca1a2a58ebe169f91bc0ea3f30e1cc4c62bc0&gt;5b9ca1a&lt;/denchmark-link&gt;
 ), to &lt;denchmark-link:https://github.com/apple/coremltools/blob/master/coremltools/converters/keras/_topology2.py&gt;_topology2.py&lt;/denchmark-link&gt;
, has fixed the index out of range issue but it seems that there is still a problem with detecting the input and output layers/names.
The conversion script:
&lt;denchmark-code&gt;import sys
sys.path.insert(0, r'/Users/corneel/GitHub/KerasTests2')
import coremltools
from keras.models import load_model
model = load_model('final_model.h5')
print("Loaded")

coreml_model = coremltools.converters.keras.convert(model,
    input_names="input_1",
    image_input_names="input_1",
    output_names="sequential_1",
    add_custom_layers=True)

coreml_model.save('final3.mlmodel')
&lt;/denchmark-code&gt;

Traceback (most recent call last):
&lt;denchmark-code&gt;File "Convert.py", line 15, in &lt;module&gt; add_custom_layers=True)
File "/Users/corneel/GitHub/KerasTests2/coremltools/converters/keras/_keras_converter.py" line 745, in convert custom_conversion_functions=custom_conversion_functions)
File "/Users/corneel/GitHub/KerasTests2/coremltools/converters/keras/_keras_converter.py", line 543, in convertToSpec custom_objects=custom_objects)
File "/Users/corneel/GitHub/KerasTests2/coremltools/converters/keras/_keras2_converter.py", line 191, in _convert graph.build()
File "/Users/corneel/GitHub/KerasTests2/coremltools/converters/keras/_topology2.py", line 704, in build self.make_output_layers()
File "/Users/corneel/GitHub/KerasTests2/coremltools/converters/keras/_topology2.py", line 185, in make_output_layers raise ValueError("No outputs can be identified")
ValueError: No outputs can be identified
&lt;/denchmark-code&gt;

The failure is as a result of this piece of code in &lt;denchmark-link:https://github.com/apple/coremltools/blob/master/coremltools/converters/keras/_topology2.py&gt;_topology2.py&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/356575/34276364-bcdbcbce-e666-11e7-9a6a-8b14a335781d.png&gt;&lt;/denchmark-link&gt;

I was following the guidance in the article: "&lt;denchmark-link:https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html&gt;https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html&lt;/denchmark-link&gt;
" by &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 (author of Keras). The model is a &lt;denchmark-link:https://faroit.github.io/keras-docs/2.0.6/getting-started/sequential-model-guide/&gt;VGG-like convnet &lt;/denchmark-link&gt;
, seeded with a pretrained network (imagenet). As far as I can see my network behaves perfectly, the extra images I loaded is detected (predicted) and any report I run on this network, completes without any problem. I was also careful to use the versions of software you prescribed (&lt;denchmark-link:https://github.com/apple/coremltools/files/1580675/pip_freeze.txt&gt;pip_freeze.txt&lt;/denchmark-link&gt;
 (coremltools does not show there because I use a compiled version)).
I attached a &lt;denchmark-link:https://user-images.githubusercontent.com/356575/34275555-778c5d0c-e663-11e7-8f34-7373395dcfcd.png&gt;visual display&lt;/denchmark-link&gt;
 of the network, as well as the  and  reports. &lt;denchmark-link:https://github.com/apple/coremltools/files/1580777/GitHub_Issue_No-outputs-can-be-identified.zip&gt;GitHub_Issue_No-outputs-can-be-identified.zip&lt;/denchmark-link&gt;

Here is the Keras summary of the model
&lt;denchmark-link:https://github.com/apple/coremltools/files/1580690/Keras_model_summary.txt&gt;Keras_model_summary.txt&lt;/denchmark-link&gt;

This model was created using the following script as provided by &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;from keras import applications
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential
from keras.models import Model
from keras.layers import Dropout, Flatten, Dense

# path to the model weights files.
weights_path = '../keras/examples/vgg16_weights.h5'
top_model_weights_path = 'bottleneck_fc_model.h5'
# dimensions of our images.
img_width, img_height = 150, 150

train_data_dir = 'data/train'
validation_data_dir = 'data/validation'
nb_train_samples = 2000
nb_validation_samples = 800
epochs = 50
batch_size = 16

# build the VGG16 network
base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))
print('Model loaded.')

# build a classifier model to put on top of the convolutional model
top_model = Sequential()
top_model.add(Flatten(input_shape=base_model.output_shape[1:]))
top_model.add(Dense(256, activation='relu'))
top_model.add(Dropout(0.5))
top_model.add(Dense(1, activation='sigmoid'))

# note that it is necessary to start with a fully-trained
# classifier, including the top classifier,
# in order to successfully do fine-tuning
top_model.load_weights(top_model_weights_path)

# add the model on top of the convolutional base
# model.add(top_model)
model = Model(inputs=base_model.input, outputs=top_model(base_model.output))

# set the first 25 layers (up to the last conv block)
# to non-trainable (weights will not be updated)
for layer in model.layers[:15]:
    layer.trainable = False

# compile the model with a SGD/momentum optimizer
# and a very slow learning rate.
model.compile(loss='binary_crossentropy',
              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),
              metrics=['accuracy'])

# prepare data augmentation configuration
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary')

model.summary()

# fine-tune the model
model.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_samples // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=nb_validation_samples // batch_size,
    verbose=2)

model.predict_function

model.save
&lt;/denchmark-code&gt;

In the script the output is distinctly identified:

model = Model(inputs=base_model.input, outputs=top_model(base_model.output))

Why would the convertor not recognize the output? (Sequential) layer?
	</description>
	<comments>
		<comment id='1' author='corneel' date='2018-01-18T00:02:12Z'>
		No news or comments on this issue?
		</comment>
		<comment id='2' author='corneel' date='2018-01-23T05:48:01Z'>
		Thanks for reporting. We will look into this.
		</comment>
		<comment id='3' author='corneel' date='2019-11-13T22:29:53Z'>
		Closing this issue as the PR has been merged. Please feel free to reopen or file a new bug if you are still experiencing issues. Thanks!
		</comment>
	</comments>
</bug>