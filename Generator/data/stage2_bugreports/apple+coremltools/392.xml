<bug id='392' author='frankschlegel' open_date='2019-07-04T09:19:42Z' closed_time='2019-12-08T23:25:26Z'>
	<summary>ActivationThresholdedReLU uses wrong default alpha</summary>
	<description>
When adding a THRESHOLDEDRELU activation layer using the neural network builder's add_activation method and passing an alpha value of 0.0, the alpha value does not get written to the spec, probably because 0.0 is treated as the default value internally.
However, it appears the actual default value assumed by the runtime is 1.0.
The coremlc compiler in Xcode 10 translates the missing alpha parameter to alpha: 0.0 in the compiled model. However, the Xcode 11 coremlc does not, leaving it blank. Which causes the runtime to use its default of 1.0 instead.
The default value for alpha should be consistent across builder, compiler and runtime.
	</description>
	<comments>
		<comment id='1' author='frankschlegel' date='2019-07-04T19:15:47Z'>
		Thank you for reporting the error.
This is indeed a bug in the compiler stage of Core ML. We are tracking it now and will be fixed in an upcoming seed.
Thanks!
		</comment>
		<comment id='2' author='frankschlegel' date='2019-12-08T23:25:25Z'>
		&lt;denchmark-link:https://github.com/aseemw&gt;@aseemw&lt;/denchmark-link&gt;
 Is this fixed in the latest iOS?
		</comment>
	</comments>
</bug>