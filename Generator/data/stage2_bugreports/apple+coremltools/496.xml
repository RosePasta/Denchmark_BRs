<bug id='496' author='ZhengPhoenix' open_date='2019-10-18T09:10:52Z' closed_time='2019-12-09T10:18:55Z'>
	<summary>Invalid dst shape when converting from Keras to Coreml</summary>
	<description>
&lt;denchmark-h:h2&gt;Keras model convert failure with Embedding layer&lt;/denchmark-h&gt;

Hello, I was trying to convert a Keras model to coreml,
but got an error as

RuntimeWarning: You will not be able to run predict() on this Core ML model. Underlying exception message was: Error compiling model: "compiler error:  Invalid dst shape1 x 1 x 64 x 1-&gt;399-&gt;64 x 400 x 1 x 0 x 1 x ".

by the way, the Keras model run normally in h5 or even converted to tensorflow model.
it turns out the failure has something to do with the input length of Input layer
Here is the code which will run successfully,
&lt;denchmark-code&gt;input_text = layers.Input(shape=(399, ), name='input_text')  &lt;&lt; focus on this
emb = layers.Embedding(1000, 64, name='embedding')(input_text)
emb = layers.Reshape([399, 64, 1], name='reshape')(emb)

model = keras.models.Model(inputs=[input_text], outputs=[emb])


model.save('test.h5')

converted = coremltools.converters.keras.convert(model,
                                                 input_names='input_text',
                                                 output_names='reshape')
converted.save('coreml.mlmodel')
&lt;/denchmark-code&gt;

please focus on the input layer,
when I try to modify param with any number bigger than 399, it will throw the issue.
bellow is the code which can caused the issue,
&lt;denchmark-code&gt;input_text = layers.Input(shape=(400, ), name='input_text')  &lt;&lt; modify here from 399 to 400
emb = layers.Embedding(1000, 64, name='embedding')(input_text)
emb = layers.Reshape([400, 64, 1], name='reshape')(emb) &lt;&lt; modify shape as well

model = keras.models.Model(inputs=[input_text], outputs=[emb])


model.save('test.h5')

converted = coremltools.converters.keras.convert(model,
                                                 input_names='input_text',
                                                 output_names='reshape')
converted.save('coreml.mlmodel')
&lt;/denchmark-code&gt;

please help check this issue,
the length of input should has nothing to do with model converting progress...I guess.
	</description>
	<comments>
		<comment id='1' author='ZhengPhoenix' date='2019-11-01T07:50:19Z'>
		I found a solution, it's all about dimension converting.
just add a reshape layer after input layer, the issue can be fixed.
&lt;denchmark-code&gt;sequence_length = 400
input_text = layers.Input(shape=(sequence_length, ), name='input_text')
reshape_1 = layers.Reshape(input_shape=(sequence_length, ), target_shape=(sequence_length, 1, ))(input_text)
emb = layers.Embedding(1000, 64, name='embedding')(reshape_1)
reshape = layers.Reshape([sequence_length, 64, 1], name='reshape')(emb)
model = keras.models.Model(inputs=[input_text], outputs=[reshape])
converted = coremltools.converters.keras.convert(model,
                                                 input_names='input_text',
                                                 output_names='reshape')
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>