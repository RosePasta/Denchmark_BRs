<bug id='953' author='BKHC' open_date='2020-10-03T23:20:06Z' closed_time='2020-12-23T00:54:02Z'>
	<summary>Converted MLModel and Pytorch model produce different result</summary>
	<description>
I have converted the pretrained mobilenetv2 model according to &lt;denchmark-link:https://coremltools.readme.io/docs/model-tracing&gt;https://coremltools.readme.io/docs/model-tracing&lt;/denchmark-link&gt;
. But the classification result produced by the mlmodel is incorrect. Below is the code that I used, any idea why this might be the case?
I have also tried other ways to convert pytorch model to mlmodel e.g. pytorch -&gt; onnx -&gt; mlmodel, and there seems to be the same consistent problem with the conversions. I have been stuck with this problem for a few days already, it would also be great if someone can advise another approach that actually works.
Also, why is add the snippit -----is_bgr=True, image_scale=scale, red_bias=-123.68scale, green_bias=-116.78scale, blue_bias=-103.94*scale----- in the convert function doesnt change the classification result at all?
&lt;denchmark-h:h1&gt;The Code&lt;/denchmark-h&gt;

import torch
import torchvision
import torch.nn as nn
scale = 0.017
torch_model = torchvision.models.mobilenet_v2(pretrained=True)
torch_model = nn.Sequential(torch_model, nn.Softmax())
torch_model.eval()
example_input = torch.rand(1, 3, 224, 224) # after test, will get 'size mismatch' error message with size 256x256
traced_model = torch.jit.trace(torch_model, example_input)
import urllib
label_url = '&lt;denchmark-link:https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt&gt;https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt&lt;/denchmark-link&gt;
'
class_labels = urllib.request.urlopen(label_url).read().decode("utf-8").splitlines()
class_labels = class_labels[1:] # remove the first class which is background
assert len(class_labels) == 1000
import coremltools as ct
model = ct.convert(
traced_model,
inputs=[ct.ImageType(name="input_1", shape=example_input.shape)], #name "input_1" is used in 'quickstart'
classifier_config = ct.ClassifierConfig(class_labels), # provide only if step 4 was performed
is_bgr=True, image_scale=scale,
red_bias=-123.68*scale, green_bias=-116.78*scale, blue_bias=-103.94*scale
)
model.save('mobilenet_v2.mlmodel')
print("Success")
from PIL import Image
example_image = Image.open("cat.jpg").resize((224, 224))
out_dict = model.predict({"input_1": example_image})
print(out_dict["classLabel"])
&lt;denchmark-h:h1&gt;mlmodel classification&lt;/denchmark-h&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/16622469/95003337-f2f02580-0610-11eb-85f4-82193f66fb4f.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='BKHC' date='2020-10-06T04:50:00Z'>
		Hi,
What I usually do is:
mlmodel = ct.convert(
    traced_model,
    inputs=[ct.ImageType(name="image", shape=ct.Shape(shape=(1, 3, 256, 256,)), bias=[-1,-1,-1], scale=1/127.5)]
)
This has worked out pretty well for me. I think if you go this way, it'll work
		</comment>
		<comment id='2' author='BKHC' date='2020-12-22T22:22:57Z'>
		Hi &lt;denchmark-link:https://github.com/BKHC&gt;@BKHC&lt;/denchmark-link&gt;
, are you still facing this issue, or was vidursatija's fix able to help you out? Please let us know, and if resolved feel free to close the issue.
		</comment>
	</comments>
</bug>