<bug id='891' author='lunixbochs' open_date='2020-08-30T01:07:32Z' closed_time='2020-10-07T06:51:32Z'>
	<summary>Having trouble doing SAME convolution with flexible input shape</summary>
	<description>
I've been trying to make a model work that has both SAME padding convolution and flexible input shape.
Here's a repro based on the MIL example:
&lt;denchmark-code&gt;from coremltools.converters.mil import Builder as mb
from coremltools.converters.mil.converter import _convert
import coremltools as ct
import numpy as np

flexible = ct.RangeDim()
@mb.program(input_specs=[mb.TensorSpec(shape=(1, 100, 100, flexible.symbol)),])
def prog(x):
    weight = np.zeros((1, 100, 5, 2))
    bias = np.zeros(5)
    x = mb.conv(x=x, weight=weight, bias=bias, strides=(1, 5), dilations=(1, 1), pad_type='same')
    return x

proto = _convert(prog, convert_from="mil")
model = models.MLModel(proto)
prediction = model.predict({
  'x': np.random.rand(1, 100, 100, 3).astype(np.float32),
})
assert len(prediction) == 1
&lt;/denchmark-code&gt;

It throws this error:
&lt;denchmark-code&gt;WARNING:root:TensorFlow version 2.3.0 detected. Last version known to be fully compatible is 2.2.0 .
WARNING:root:Keras version 2.4.3 detected. Last version known to be fully compatible of Keras is 2.2.4 .
Traceback (most recent call last):
  File "test.py", line 9, in &lt;module&gt;
    def prog(x):
  File "Python/3.8/lib/python/site-packages/coremltools/converters/mil/mil/builder.py", line 231, in wrapper
    outputs = main_block(*input_vars)
  File "test.py", line 12, in prog
    x = mb.conv(x=x, weight=weight, bias=bias, strides=(1, 5), dilations=(1, 1), pad_type='same')
  File "Python/3.8/lib/python/site-packages/coremltools/converters/mil/mil/ops/registry.py", line 62, in add_op
    return cls._add_op(op_cls, **kwargs)
  File "Python/3.8/lib/python/site-packages/coremltools/converters/mil/mil/builder.py", line 192, in _add_op
    new_op.type_value_inference()
  File "Python/3.8/lib/python/site-packages/coremltools/converters/mil/mil/operation.py", line 178, in type_value_inference
    output_types = self.type_inference()
  File "Python/3.8/lib/python/site-packages/coremltools/converters/mil/mil/ops/defs/conv.py", line 131, in type_inference
    d_out_shape = spatial_dimensions_out_shape(
  File "Python/3.8/lib/python/site-packages/coremltools/converters/mil/mil/ops/defs/_utils.py", line 225, in spatial_dimensions_out_shape
    pad = aggregated_pad(
  File "Python/3.8/lib/python/site-packages/coremltools/converters/mil/mil/ops/defs/_utils.py", line 159, in aggregated_pad
    return [
  File "Python/3.8/lib/python/site-packages/coremltools/converters/mil/mil/ops/defs/_utils.py", line 160, in &lt;listcomp&gt;
    int(max(0, s * math.ceil(float(i) / float(s)) - i + k - s))
  File "Python/3.8/lib/python/site-packages/sympy/core/expr.py", line 327, in __float__
    raise TypeError("can't convert expression to float")
TypeError: can't convert expression to float
&lt;/denchmark-code&gt;

If I either replace flexible.symbol with 3, or change pad_type to valid, the error goes away.
The error makes sense to me, you seem to pre-calculate the SAME padding based on a fixed input size. However, I'm doing convolution on variable size inputs, and I've been having a lot of trouble figuring out how to have both flexible input size and do SAME padding with MIL.
How can I calculate SAME padding size at runtime with the MIL builder?
	</description>
	<comments>
		<comment id='1' author='lunixbochs' date='2020-10-07T06:40:58Z'>
		&lt;denchmark-link:https://github.com/lunixbochs&gt;@lunixbochs&lt;/denchmark-link&gt;
 I believe this bug has been fixed in coremltools 4.0b4.
Please give it a try! thanks!
		</comment>
		<comment id='2' author='lunixbochs' date='2020-10-07T06:51:31Z'>
		Please reopen the issue if you still the same error :)
		</comment>
		<comment id='3' author='lunixbochs' date='2020-10-08T02:30:12Z'>
		Seems better, thanks!
		</comment>
	</comments>
</bug>