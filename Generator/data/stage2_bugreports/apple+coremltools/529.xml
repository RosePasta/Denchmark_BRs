<bug id='529' author='jamesonthecrow' open_date='2019-11-23T21:09:59Z' closed_time='2020-01-17T18:03:02Z'>
	<summary>Converting models with tf.keras.layers.Upsampling2D layers fails due to shape inference.</summary>
	<description>
&lt;denchmark-h:h2&gt;üêûDescribe the bug&lt;/denchmark-h&gt;

Converting models with an upsampling layer followed by a convolution layer (and perhaps others), fails due to input shape inference. This seems to be because the graph_def created from the keras model does not impute the output shape of the upsampling output.
&lt;denchmark-h:h2&gt;Trace&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
0 assert nodes deleted
['model/up_sampling2d/strided_slice/stack_2:0', 'model/up_sampling2d/Const:0', 'model/up_sampling2d/strided_slice/stack:0', 'model/conv2d/Conv2D/ReadVariableOp/resource:0', 'model/conv2d/Conv2D/ReadVariableOp:0', 'model/conv2d/BiasAdd/ReadVariableOp:0', 'model/conv2d/BiasAdd/ReadVariableOp/resource:0', 'model/up_sampling2d/strided_slice/stack_1:0']
2 nodes deleted
[TypeInference] Failed to infer type of node "model/conv2d/Conv2D" (Conv2D)
[TypeInference] Error fetching padding values: can't convert expression to float
Traceback (most recent call last):
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/graph_pass/type_inference.py", line 24, in get_conv_outdim
    return math.floor((in_dim - ks_dilated) / stride) + 1
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/sympy/core/expr.py", line 280, in __float__
    raise TypeError("can't convert expression to float")
TypeError: can't convert expression to float

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/graph_pass/type_inference.py", line 86, in visit
    ret = visitor(node)
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/graph_pass/type_inference.py", line 504, in visit_Conv2D
    strides[1], dilations[1], padding)
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/graph_pass/type_inference.py", line 30, in get_conv_outdim
    raise ValueError('[TypeInference] Error fetching padding values: {}'.format(e))
ValueError: [TypeInference] Error fetching padding values: can't convert expression to float

[TypeInference] Unable to infer type of node "model/conv2d/Conv2D" (Conv2D)
[TypeInference] Failed to infer type of node "model/conv2d/Conv2D" (Conv2D)
[TypeInference] Error fetching padding values: can't convert expression to float
Traceback (most recent call last):
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/graph_pass/type_inference.py", line 24, in get_conv_outdim
    return math.floor((in_dim - ks_dilated) / stride) + 1
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/sympy/core/expr.py", line 280, in __float__
    raise TypeError("can't convert expression to float")
TypeError: can't convert expression to float

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/graph_pass/type_inference.py", line 86, in visit
    ret = visitor(node)
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/graph_pass/type_inference.py", line 504, in visit_Conv2D
    strides[1], dilations[1], padding)
  File "/Users/jameson/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/graph_pass/type_inference.py", line 30, in get_conv_outdim
    raise ValueError('[TypeInference] Error fetching padding values: {}'.format(e))
ValueError: [TypeInference] Error fetching padding values: can't convert expression to float

[TypeInference] Unable to infer type of node "model/conv2d/Conv2D" (Conv2D)
5 nodes deleted
0 nodes deleted
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
~/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/tensorflow/_tf_converter.py in convert(filename, inputs, outputs, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions, custom_shape_functions, **kwargs)
     68         from ..nnssa.frontend.tensorflow import load as frontend_load
---&gt; 69         ssa = frontend_load(filename, resume_on_errors=False, inputs=inputs, outputs=outputs, **kwargs)
     70     except ImportError as e:

~/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/tensorflow/load.py in load(tfgraph, resume_on_errors, **kwargs)
     84             for n in f.graph.values():
---&gt; 85                 assert n.datatype is not None
     86     return ssa

AssertionError: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-2-c9336be91bac&gt; in &lt;module&gt;
     11     input_names="image",
     12     output_names="output",
---&gt; 13     image_input_names="image",
     14 )

~/.pyenv/versions/3.7.5/envs/fritzml/lib/python3.7/site-packages/coremltools/converters/tensorflow/_tf_converter.py in convert(filename, inputs, outputs, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions, custom_shape_functions, **kwargs)
     71         raise ImportError('frontend converter not found. {}'.format(e))
     72     except Exception as e:
---&gt; 73         raise RuntimeError('failed to convert from TensorFlow to IR. {}'.format(e))
     74 
     75     # convert from SSA IR to Core ML

RuntimeError: failed to convert from TensorFlow to IR.
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;inpt = tf.keras.Input(shape=(128, 128, 32))
out = tf.keras.layers.UpSampling2D()(inpt)
out = tf.keras.layers.Conv2D(10, 3)(out)
model = tf.keras.models.Model(inpt, out)

temp = tempfile.NamedTemporaryFile(suffix=".h5")
model.save(temp.name, save_format="h5")

coremltools.converters.tensorflow.convert(
    temp.name,
    input_names="image",
    output_names="output",
    image_input_names="image",
)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;System environment (please complete the following information):&lt;/denchmark-h&gt;


coremltools version: 3.1
OS (e.g., MacOS, Linux): MacOS
macOS version (if applicable): 1.15.1
How you install python (anaconda, virtualenv, system): pyenv virtualenv
python version (e.g. 3.7): 3.7.5
tensorflow: 2.0.0

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

Digging into this the output shape of the resize layer is [-1, -1, -1, 32]. This causes _get_type_from_attr(self, node): to return strings for those first three dimensions which in turn causes the input dimensions in the subsequent convolution layer to include strings which throws an error when used to compute the output dimension.
	</description>
	<comments>
		<comment id='1' author='jamesonthecrow' date='2019-11-27T12:29:16Z'>
		Ping, since I have the same problem during conversion on a Deeplabv3/MobileNetV2 model.
		</comment>
		<comment id='2' author='jamesonthecrow' date='2019-12-05T16:09:38Z'>
		I'm also running into this.  Is there a timeline for this being fixed or addressed?
		</comment>
		<comment id='3' author='jamesonthecrow' date='2019-12-11T06:27:14Z'>
		I am also seeing this issue with the Conv2DTranspose layer.
		</comment>
		<comment id='4' author='jamesonthecrow' date='2020-01-17T18:03:02Z'>
		This bug fix should be included in coremltools 3.2 release. Please upgrade your coremltools(pip install --upgrade coremltools) to verify. Feel free to re-open if you still encountering this issue. Thanks!
		</comment>
	</comments>
</bug>