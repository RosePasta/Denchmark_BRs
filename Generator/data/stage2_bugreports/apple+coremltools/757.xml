<bug id='757' author='leovinus2001' open_date='2020-07-07T16:38:01Z' closed_time='2020-07-09T18:49:38Z'>
	<summary>A PyTorch LSTM with batch_first==True cannot be converted to .mlmodel</summary>
	<description>
The bug trace says:
Bug ValueError: CoreML does not support LSTM layer with batch_first==True.
Python 3.7.6
PyTorch 1.5.0
CoreML tools version : 4.0b1
macOS Catalina latest
Rational:
The model and code are much cleaner if the input shape dimensions are consistently (batch size x seqLen x num features)
Expected behavior:
CoreML tools v4 should handle conversion of PyTorch LSTM with batchFirst == true
Reproducible:
yes, just change 'lstmBatchFirstFlag' in test case from False to True
Traceback (most recent call last):
File "testLstmVar.py", line 112, in 
inputs=[ ct.TensorType(name="input1", shape=dummy_input.shape) ],
File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/_converters_entry.py", line 299, in convert
**kwargs
File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/converter.py", line 120, in _convert
prog = frontend_converter(model, **kwargs)
File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/converter.py", line 62, in call
return load(*args, **kwargs)
File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/frontend/torch/load.py", line 86, in load
raise e
File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/frontend/torch/load.py", line 76, in load
prog = converter.convert()
File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/frontend/torch/converter.py", line 302, in convert
convert_nodes(self.context, self.graph)
File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/frontend/torch/ops.py", line 55, in convert_nodes
_add_op(context, node)
File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/frontend/torch/ops.py", line 952, in lstm
raise ValueError("CoreML does not support LSTM layer with batch_first==True.")
ValueError: CoreML does not support LSTM layer with batch_first==True.
&lt;denchmark-link:https://github.com/apple/coremltools/files/4886035/testLstmVar.txt&gt;testLstmVar.txt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='leovinus2001' date='2020-07-08T02:54:40Z'>
		&lt;denchmark-link:https://github.com/leovinus2001&gt;@leovinus2001&lt;/denchmark-link&gt;
 This PR &lt;denchmark-link:https://github.com/apple/coremltools/pull/761&gt;#761&lt;/denchmark-link&gt;
 enables  mode for LSTM cells.
		</comment>
		<comment id='2' author='leovinus2001' date='2020-07-08T14:15:03Z'>
		Thanks, I'll have a look and get back to you asap
		</comment>
		<comment id='3' author='leovinus2001' date='2020-07-08T14:34:02Z'>
		While I could not 'pull' your changes via git, I can confirm that your 3 line changes in
coremltools/converters/mil/frontend/torch/ops.py
from
&lt;denchmark-link:https://github.com/apple/coremltools/commit/dc4ef28ac0999d437b36020d66478a951f899b7b&gt;dc4ef28&lt;/denchmark-link&gt;

make the PyTorch to CoreML conversion work for an LSTM with batch_first=True.
The error message:
ValueError: CoreML does not support LSTM layer with batch_first==True.
is gone.
Model spec for the test case generated model looks good with batch_first.
multiArrayType {
shape: 1
shape: 5
shape: 28
dataType: FLOAT32
PS: And Inference on the CoreML model is correct as well :)
		</comment>
		<comment id='4' author='leovinus2001' date='2020-07-09T18:49:38Z'>
		&lt;denchmark-link:https://github.com/leovinus2001&gt;@leovinus2001&lt;/denchmark-link&gt;
 Thanks for verifying. Closing it.
		</comment>
	</comments>
</bug>