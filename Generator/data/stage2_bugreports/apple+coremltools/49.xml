<bug id='49' author='G-mel' open_date='2017-10-16T14:03:47Z' closed_time='2017-10-16T20:22:29Z'>
	<summary>Invalid dst shape</summary>
	<description>
In my model, I'm attempting to mimick a tf.image.resize_nearest_neighbor operation in TensorFlow (which reshapes a layer from (512, 6, 8) to (512, 5, 8), where shape is (C,H,W)) with the builder.add_reshape(..., target_shape=(1, 512, 5, 8)) function in CoreMLTools.
I get the error RuntimeError: Error compiling model: "compiler error:  Invalid dst shape8 x 6 x 512 x 1-&gt;1-&gt;8 x 5 x 512 x 0 x 1 x ". when the line model = MLModel(builder.spec) is executing.
Any idea what this error message means?
	</description>
	<comments>
		<comment id='1' author='G-mel' date='2017-10-16T15:42:37Z'>
		Also, using builder.add_upsample with mode='NN' can't accept float scaling factors for me to reshape from (512, 6, 8) to (512, 5, 8). I need to reshape to (512, 5, 8) in order to concat with another layer with shape (512, 5, 8)
		</comment>
		<comment id='2' author='G-mel' date='2017-10-16T18:29:13Z'>
		(1) Reshaping. The reshape layers in CoreML requires the total number of elements does not change. This means np.prod(np.array(input_shape)) == np.prod(np.array(output_shape)). In your case, height is reduced from 6 to 5, so reshaping layer cannot handle this case.
(2) CoreML's upsampling layer and downsampling layer currently restricts the scaling factors in be integers.
(3) As a memory-unfriendly workaround, you might try upsampling your blob by 5 then downsampling it by 6.
		</comment>
		<comment id='3' author='G-mel' date='2017-10-16T19:40:15Z'>
		&lt;denchmark-link:https://github.com/slin07&gt;@slin07&lt;/denchmark-link&gt;
 The upsampling and downsampling work-around did it for me! Does it matter if my downsampling is of type  or ?
		</comment>
		<comment id='4' author='G-mel' date='2017-10-16T20:18:14Z'>
		&lt;denchmark-link:https://github.com/G-mel&gt;@G-mel&lt;/denchmark-link&gt;
 I'm not so sure which is better in this case. Neither option can give you the same output that truly follows nearest neighbor behavior. For example, resizing a length 3 array [2,1,3] to length 4 by nearest neighbor rule is [2,1,1,3], however,

using the workaround with average pooling gives you [2,1.33,1.67, 3]
using the workaround with max pooling gives you [2,2,3,3]
Therefore I would prefer average over max.

		</comment>
		<comment id='5' author='G-mel' date='2017-10-16T20:22:29Z'>
		&lt;denchmark-link:https://github.com/slin07&gt;@slin07&lt;/denchmark-link&gt;
 Thanks for the great answer, I'll go with Average for now and test out the performance of both.
		</comment>
	</comments>
</bug>