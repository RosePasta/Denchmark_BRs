<bug id='736' author='jbmaxwell' open_date='2020-06-24T20:23:49Z' closed_time='2020-07-13T17:18:34Z'>
	<summary>Error reporting that leaky ReLU is not yet implemented for PyTorch conversion</summary>
	<description>
I was trying to convert a ClusterGAN from PyTorch to CoreML yesterday and got an error about leaky_relu not being implemented yet. Is there a projected timeline for this? It seems to me leaky ReLU is a very popular activation function.
As a workaround, is there a reasonably simple way to write my own for the converter to use?
Any thoughts appreciated.
	</description>
	<comments>
		<comment id='1' author='jbmaxwell' date='2020-06-24T20:35:16Z'>
		Hi &lt;denchmark-link:https://github.com/jbmaxwell&gt;@jbmaxwell&lt;/denchmark-link&gt;
 thanks for reporting the issue!
Yes it does seem the leaky relu mapping function is not implemented yet. I see the one for &lt;denchmark-link:https://github.com/apple/coremltools/blob/725da3556ff3f4e703025382c834e257e10fe92f/coremltools/converters/mil/frontend/torch/ops.py#L459&gt;relu&lt;/denchmark-link&gt;
 but not for leaky relu.
It should be added in the upcoming beta releases of coremltools.
As for the timeline, generally coremltools is aligned with the Core ML framework which is aligned with the rest of the Apple OS software.
		</comment>
		<comment id='2' author='jbmaxwell' date='2020-06-24T21:14:24Z'>
		Okay, fingers crossed that we'll see it in the next betaâ€”and that it will drop relatively soon! :)
I have the model running using LibTorch for now, but I'm curious about performance and have a feeling that the CoreML version will be better optimized for the hardware (correct me if I'm wrong).
		</comment>
		<comment id='3' author='jbmaxwell' date='2020-06-25T06:57:56Z'>
		&lt;denchmark-link:https://github.com/jbmaxwell&gt;@jbmaxwell&lt;/denchmark-link&gt;
 To clarify, this implementation is a good reference right? (&lt;denchmark-link:https://github.com/zhampel/clusterGAN&gt;https://github.com/zhampel/clusterGAN&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='4' author='jbmaxwell' date='2020-06-25T15:01:10Z'>
		Yes, that's the one.
		</comment>
		<comment id='5' author='jbmaxwell' date='2020-06-25T16:43:04Z'>
		Hitting the same issue
RuntimeError: PyTorch convert function for op leaky_relu_ not implemented
with a non GAN model.
Hence +1 for please add it in the next beta
		</comment>
		<comment id='6' author='jbmaxwell' date='2020-06-25T16:58:05Z'>
		Here a small test case for your convenience. &lt;denchmark-link:https://github.com/aseemw&gt;@aseemw&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;

Change bool 'showBug' for testing on/off.
&lt;denchmark-link:https://github.com/apple/coremltools/files/4832727/testLeakyRelu.jun25.txt&gt;testLeakyRelu.jun25.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='jbmaxwell' date='2020-06-30T21:19:02Z'>
		Running in the same issue when converting YOLO Object Detection models to CoreML.
I am using ReLU as a work-around for now, could we also supply custom activation functions instead of LeakyReLU?
Thanks
		</comment>
		<comment id='8' author='jbmaxwell' date='2020-07-02T02:29:59Z'>
		&lt;denchmark-link:https://github.com/dlawrences&gt;@dlawrences&lt;/denchmark-link&gt;
 Were you able to switch ReLU out for LeakyReLU after training, or did you need to re-train the model from scratch after you did that?  If so, how did you change this?
		</comment>
		<comment id='9' author='jbmaxwell' date='2020-07-02T04:46:59Z'>
		
@dlawrences Were you able to switch ReLU out for LeakyReLU after training, or did you need to re-train the model from scratch after you did that? If so, how did you change this?

I have changed the model architecture to use nn.ReLU (&lt;denchmark-link:https://pytorch.org/docs/master/generated/torch.nn.ReLU.html&gt;https://pytorch.org/docs/master/generated/torch.nn.ReLU.html&lt;/denchmark-link&gt;
) instead of nn.LeakyReLU (&lt;denchmark-link:https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html&gt;https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html&lt;/denchmark-link&gt;
). I don't think the weights trained for the LeakyReLU activation function would have worked that well on plain ReLU tbh - I would expect some gradients would go to zero really fast for the latter one.
		</comment>
		<comment id='10' author='jbmaxwell' date='2020-07-07T19:22:56Z'>
		This PR &lt;denchmark-link:https://github.com/apple/coremltools/pull/758&gt;#758&lt;/denchmark-link&gt;
 adds  and  layers. Can you please try converting this model using the change in this PR?
		</comment>
		<comment id='11' author='jbmaxwell' date='2020-07-07T21:02:50Z'>
		Pulled coremltools, rebuilt coremltools from TOT, reran the testcase I provided above, and that passes now. Seems like LeakyRelu works. Thanks.
		</comment>
	</comments>
</bug>