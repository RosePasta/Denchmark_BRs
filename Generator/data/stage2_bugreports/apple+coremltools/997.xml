<bug id='997' author='ZackPashkin' open_date='2020-11-19T10:28:59Z' closed_time='2020-12-03T10:53:45Z'>
	<summary>PyTorch convert function for op 'constant_pad_nd while converting effnetlite</summary>
	<description>
Facing this issue PyTorch convert function for op 'constant_pad_nd' not implemented  while trying to convert effnetlite
&lt;denchmark-h:h2&gt;System Information:&lt;/denchmark-h&gt;

macos 10.15.7
pytorch 1.6.0
coremltools 4.0b4
python 3.8.5
&lt;denchmark-h:h2&gt;Trace&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;
Converting Frontend ==&gt; MIL Ops:   2%|▏         | 12/564 [00:00&lt;00:00, 3677.60 ops/s]
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-6-48baae8c011e&gt; in &lt;module&gt;
     26 
     27 # Convert to Core ML using the Unified Conversion API
---&gt; 28 model = ct.convert(
     29     traced_model,
     30     inputs=[ct.ImageType(name="input", shape=example_input.shape)], #name "input_1" is used in 'quickstart'

~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/coremltools/converters/_converters_entry.py in convert(model, source, inputs, outputs, classifier_config, minimum_deployment_target, **kwargs)
    301             raise ValueError("outputs must not be specified for PyTorch")
    302 
--&gt; 303         proto_spec = _convert(
    304             model,
    305             convert_from="torch",

~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/coremltools/converters/mil/converter.py in _convert(model, convert_from, convert_to, converter_registry, **kwargs)
    132     frontend_converter = frontend_converter_type()
    133 
--&gt; 134     prog = frontend_converter(model, **kwargs)
    135     common_pass(prog)
    136 

~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/coremltools/converters/mil/converter.py in __call__(self, *args, **kwargs)
     82         from .frontend.torch import load
     83 
---&gt; 84         return load(*args, **kwargs)
     85 
     86 

~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/coremltools/converters/mil/frontend/torch/load.py in load(model_spec, debug, **kwargs)
     82             print("the following model ops are MISSING:")
     83             print("\n".join(["  " + str(x) for x in sorted(missing)]))
---&gt; 84         raise e
     85     except Exception as e:
     86         raise e

~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/coremltools/converters/mil/frontend/torch/load.py in load(model_spec, debug, **kwargs)
     74 
     75     try:
---&gt; 76         prog = converter.convert()
     77     except RuntimeError as e:
     78         if debug and "convert function" in str(e):

~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/coremltools/converters/mil/frontend/torch/converter.py in convert(self)
    222 
    223             # Add the rest of the operations
--&gt; 224             convert_nodes(self.context, self.graph)
    225 
    226             graph_outputs = [self.context[name] for name in self.graph.outputs]

~/opt/anaconda3/envs/torch/lib/python3.8/site-packages/coremltools/converters/mil/frontend/torch/ops.py in convert_nodes(context, graph)
     49         _logging.info("Converting op {} : {}".format(node.name, node.kind))
     50         if _add_op is None:
---&gt; 51             raise RuntimeError(
     52                 "PyTorch convert function for op '{}' not implemented.".format(node.kind)
     53             )

RuntimeError: PyTorch convert function for op 'constant_pad_nd' not implemented.

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ZackPashkin' date='2020-11-25T14:54:22Z'>
		you can try this &lt;denchmark-link:https://github.com/apple/coremltools/issues/899&gt;#899&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='ZackPashkin' date='2020-12-03T11:07:50Z'>
		
you can try this #899

Thank you &lt;denchmark-link:https://github.com/shiron8bit&gt;@shiron8bit&lt;/denchmark-link&gt;
 , it helped!
So, the solution is to change the code this way:
&lt;denchmark-code&gt;
# For ios13+

# Effnetlite

import torch
from coremltools.converters.mil import Builder as mb
from coremltools.converters.mil import register_torch_op
from coremltools.converters.mil.frontend.torch.ops import _get_inputs, _np



# Load torch model
torch_model_path = "model.pt"
torch_model = torch.load(torch_model_path ,map_location=torch.device('cpu'))


# Set the model in evaluation mode
torch_model.eval()

# Trace with random data
example_input = torch.rand(1, 3, 224, 224) 

traced_model = torch.jit.trace(torch_model, example_input)


@register_torch_op
def constant_pad_nd(context, node):
    inputs = _get_inputs(context, node, expected=3)
    # print(inputs[1].val, inputs[0].shape)
    new_pad = inputs[1].val.reshape((-1, 2))[::-1].reshape(-1).tolist()
    new_pad = [0]*(2*len(inputs[0].shape)-len(new_pad)) + new_pad
    print(new_pad, inputs[0].shape)
    padded = mb.pad(x=inputs[0], pad=_np.array(new_pad), mode="constant", constant_val=float(0), name=node.name)
    context.add(padded)

class_labels=list(LABELS.values())

# Convert to Core ML using the Unified Conversion API
model = ct.convert(
    traced_model,
    inputs=[ct.ImageType(name="input", shape=example_input.shape)], #name "input_1" is used in 'quickstart'
    classifier_config = ct.ClassifierConfig(class_labels) #optional line
)


# Save model
model.save("PT_MODEL_PATH255.mlmodel")
&lt;/denchmark-code&gt;

output is
&lt;denchmark-code&gt;
Converting Frontend ==&gt; MIL Ops:  60%|██████    | 339/564 [00:00&lt;00:00, 1760.44 ops/s]
[0, 0, 0, 0, 0, 1, 0, 1] (1, 3, 224, 224)
[0, 0, 0, 0, 1, 1, 1, 1] (1, 32, 112, 112)
[0, 0, 0, 0, 0, 1, 0, 1] (1, 96, 112, 112)
[0, 0, 0, 0, 1, 1, 1, 1] (1, 144, 56, 56)
[0, 0, 0, 0, 1, 2, 1, 2] (1, 144, 56, 56)
[0, 0, 0, 0, 2, 2, 2, 2] (1, 240, 28, 28)
[0, 0, 0, 0, 0, 1, 0, 1] (1, 240, 28, 28)
[0, 0, 0, 0, 1, 1, 1, 1] (1, 480, 14, 14)
[0, 0, 0, 0, 1, 1, 1, 1] (1, 480, 14, 14)
[0, 0, 0, 0, 2, 2, 2, 2] (1, 480, 14, 14)
[0, 0, 0, 0, 2, 2, 2, 2] (1, 672, 14, 14)
[0, 0, 0, 0, 2, 2, 2, 2] (1, 672, 14, 14)
[0, 0, 0, 0, 1, 2, 1, 2] (1, 672, 14, 14)
[0, 0, 0, 0, 2, 2, 2, 2]
Converting Frontend ==&gt; MIL Ops:  92%|█████████▏| 520/564 [00:00&lt;00:00, 1121.41 ops/s]
 (1, 1152, 7, 7)
[0, 0, 0, 0, 2, 2, 2, 2] (1, 1152, 7, 7)
[0, 0, 0, 0, 2, 2, 2, 2] (1, 1152, 7, 7)
[0, 0, 0, 0, 1, 1, 1, 1] (1, 1152, 7, 7)
Converting Frontend ==&gt; MIL Ops: 100%|█████████▉| 563/564 [00:00&lt;00:00, 1051.58 ops/s]
Running MIL optimization passes: 100%|██████████| 17/17 [00:00&lt;00:00, 105.39 passes/s]
Translating MIL ==&gt; MLModel Ops: 100%|██████████| 711/711 [00:00&lt;00:00, 1938.44 ops/s]
Model is loaded input {
  name: "input"
  type {
    imageType {
      width: 224
      height: 224
      colorSpace: RGB
    }
  }
}
output {
  name: "811"
  type {
    dictionaryType {
      stringKeyType {
      }
    }
  }
}
output {
  name: "classLabel"
  type {
    stringType {
    }
  }
}
predictedFeatureName: "classLabel"
predictedProbabilitiesName: "811"
metadata {
  userDefined {
    key: "com.github.apple.coremltools.source"
    value: "torch==1.6.0"
  }
  userDefined {
    key: "com.github.apple.coremltools.version"
    value: "4.0b4"
  }
}
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>