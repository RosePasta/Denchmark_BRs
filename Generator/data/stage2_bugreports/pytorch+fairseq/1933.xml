<bug id='1933' author='14H034160212' open_date='2020-03-29T02:53:43Z' closed_time='2020-04-14T07:03:28Z'>
	<summary>RoBERTa-large model fine-tuning RACE dataset with RuntimeError: CUDA out of memory</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Hi, Does anyone have tried fine-tuning the RoBERTa-large model with RACE dataset on the Colab GPU K80 with 7.43 GiB total capacity? I have run it, but with the RuntimeError: CUDA out of memory issue.
I have tries to change the MAX_SENTENCES to 1 and UPDATE_FREQ to 16, but still have the same issue. I have also tried run that on my own GTX-1660Ti GPU with 6 GiB total capacity. The result is the same. So, Does anyone have any suggestion? Thanks a lot.
&lt;denchmark-code&gt;RuntimeError: CUDA out of memory. Tried to allocate 1.33 GiB (GPU 0; 7.43 GiB total capacity; 5.98 GiB already allocated; 952.94 MiB free; 5.98 GiB reserved in total by PyTorch)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='14H034160212' date='2020-03-29T13:13:46Z'>
		Can you please post the full training command? There's a good chance you'll need to decrease the batch size tremendously with such a small memory allowance.
		</comment>
		<comment id='2' author='14H034160212' date='2020-03-29T13:33:53Z'>
		Hi &lt;denchmark-link:https://github.com/erip&gt;@erip&lt;/denchmark-link&gt;
, Thank you so much for your feedback. Exactly, I agree with you. Here is the full training command.
&lt;denchmark-code&gt;MAX_EPOCH=5           # Number of training epochs.
LR=1e-05              # Peak LR for fixed LR scheduler.
NUM_CLASSES=4
MAX_SENTENCES=1       # Batch size per GPU.
UPDATE_FREQ=16         # Accumulate gradients to simulate training on 8 GPUs.
DATA_DIR='RACE_final_output'
ROBERTA_PATH='/RoBERTa_base/model.pt'

! CUDA_VISIBLE_DEVICES=0,1 fairseq-train $DATA_DIR --ddp-backend=no_c10d \
  --restore-file $ROBERTA_PATH \
  --reset-optimizer --reset-dataloader --reset-meters \
  --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \
  --task sentence_ranking \
  --num-classes $NUM_CLASSES \
  --init-token 0 --separator-token 2 \
  --max-option-length 128 \
  --max-positions 512 \
  --truncate-sequence \
  --arch roberta_large \
  --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \
  --criterion sentence_ranking \
  --optimizer adam --adam-betas '(0.9, 0.98)' --adam-eps 1e-06 \
  --clip-norm 0.0 \
  --lr-scheduler fixed --lr $LR \
  --fp16 --fp16-init-scale 4 --threshold-loss-scale 1 --fp16-scale-window 128 \
  --max-sentences $MAX_SENTENCES \
  --required-batch-size-multiple 1 \
  --update-freq $UPDATE_FREQ \
  --max-epoch $MAX_EPOCH
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='14H034160212' date='2020-03-29T14:04:01Z'>
		This is kicking the can down the road, but what happens if you use --memory-efficient-fp16 instead of --fp16? I'm not sure how much of a savings that will be. Also try cutting --update-freq in half (though I'm not sure this actually impacts memory usage). Worst case scenario you could clear the cache regularly, but that'll slow down training.
		</comment>
		<comment id='4' author='14H034160212' date='2020-03-29T14:12:13Z'>
		Thanks &lt;denchmark-link:https://github.com/erip&gt;@erip&lt;/denchmark-link&gt;
, I will have a try.
		</comment>
		<comment id='5' author='14H034160212' date='2020-03-30T04:36:00Z'>
		Many thanks &lt;denchmark-link:https://github.com/erip&gt;@erip&lt;/denchmark-link&gt;
. The code is running on the Colab with K80 GPU (7 GB total memory) by using  to replace the  and cutting  in half. Only one issue is that the speed of the running is quite slow. Do you have any suggestion? Appreciate a lot.
		</comment>
		<comment id='6' author='14H034160212' date='2020-04-02T08:30:33Z'>
		Hi &lt;denchmark-link:https://github.com/erip&gt;@erip&lt;/denchmark-link&gt;
, I have try to use Tesla V100 to fine-tuning the model. The speed is quite fast. But the final result is like a random selection. I seemly find the solution from that link. &lt;denchmark-link:https://github.com/pytorch/fairseq/issues/1114&gt;#1114&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>