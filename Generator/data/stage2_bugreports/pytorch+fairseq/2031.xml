<bug id='2031' author='akhileshgotmare' open_date='2020-04-20T10:44:30Z' closed_time='2020-04-22T02:54:31Z'>
	<summary>Runtime error Missing key(s) in state_dict: "decoder.output_projection.weight".  when loading NMT models from torch.hub</summary>
	<description>
Getting this error when trying to load Transformer NMT models from torch.hub
Have tried running it on Google Colab shared at &lt;denchmark-link:https://pytorch.org/hub/pytorch_fairseq_translation/&gt;https://pytorch.org/hub/pytorch_fairseq_translation/&lt;/denchmark-link&gt;
 - (&lt;denchmark-link:https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/pytorch_fairseq_translation.ipynb&gt;https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/pytorch_fairseq_translation.ipynb&lt;/denchmark-link&gt;
) and also with pytorch latest docker image.
&lt;denchmark-code&gt;pip install fastBPE regex requests sacremoses subword_nmt
import torch

# Load an En-Fr Transformer model trained on WMT'14 data :
en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;Downloading: "https://github.com/pytorch/fairseq/archive/master.zip" to /root/.cache/torch/hub/master.zip

No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
running build_ext
cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp
cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp
building 'fairseq.libbleu' extension
creating build
creating build/temp.linux-x86_64-3.6
creating build/temp.linux-x86_64-3.6/fairseq
creating build/temp.linux-x86_64-3.6/fairseq/clib
creating build/temp.linux-x86_64-3.6/fairseq/clib/libbleu
x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0
x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0
creating build/lib.linux-x86_64-3.6
creating build/lib.linux-x86_64-3.6/fairseq
x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so
building 'fairseq.data.data_utils_fast' extension
creating build/temp.linux-x86_64-3.6/fairseq/data
x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-3.6/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0
creating build/lib.linux-x86_64-3.6/fairseq/data
x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.6/fairseq/data/data_utils_fast.cpython-36m-x86_64-linux-gnu.so
building 'fairseq.data.token_block_utils_fast' extension
x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-3.6/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0
x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.6/fairseq/data/token_block_utils_fast.cpython-36m-x86_64-linux-gnu.so
building 'fairseq.libnat' extension
creating build/temp.linux-x86_64-3.6/fairseq/clib/libnat
x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11
x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/clib/libnat/edit_dist.o -o build/lib.linux-x86_64-3.6/fairseq/libnat.cpython-36m-x86_64-linux-gnu.so
copying build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so -&gt; fairseq
copying build/lib.linux-x86_64-3.6/fairseq/data/data_utils_fast.cpython-36m-x86_64-linux-gnu.so -&gt; fairseq/data
copying build/lib.linux-x86_64-3.6/fairseq/data/token_block_utils_fast.cpython-36m-x86_64-linux-gnu.so -&gt; fairseq/data
copying build/lib.linux-x86_64-3.6/fairseq/libnat.cpython-36m-x86_64-linux-gnu.so -&gt; fairseq

100%|██████████| 2316140317/2316140317 [01:19&lt;00:00, 29277581.40B/s]

---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

&lt;ipython-input-2-b7fac14eceab&gt; in &lt;module&gt;()
      2 
      3 # Load an En-Fr Transformer model trained on WMT'14 data :
----&gt; 4 en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')

5 frames

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict)
    828         if len(error_msgs) &gt; 0:
    829             raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
--&gt; 830                                self.__class__.__name__, "\n\t".join(error_msgs)))
    831         return _IncompatibleKeys(missing_keys, unexpected_keys)
    832 

RuntimeError: Error(s) in loading state_dict for TransformerModel:
	Missing key(s) in state_dict: "decoder.output_projection.weight". 
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='akhileshgotmare' date='2020-04-20T11:34:41Z'>
		Was able to bypass this by replacing  at  to the one before this commit - &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/6379573c9e56620b6b4ddeb114b030a0568ce7fe&gt;6379573&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='akhileshgotmare' date='2020-04-20T21:33:50Z'>
		Thanks, we're reverting &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/6379573c9e56620b6b4ddeb114b030a0568ce7fe&gt;6379573&lt;/denchmark-link&gt;
 (revert in &lt;denchmark-link:https://github.com/pytorch/fairseq/pull/2032&gt;#2032&lt;/denchmark-link&gt;
).
Besides breaking backwards compatibility, it also doesn't tie weights properly.
		</comment>
		<comment id='3' author='akhileshgotmare' date='2020-04-20T22:45:27Z'>
		
Was able to bypass this by replacing transformer.py at /root/.cache/torch/hub/pytorch_fairseq_master/fairseq/models/ to the one before this commit - 6379573

I am having the same issue and I don't understand how you fixed it
		</comment>
		<comment id='4' author='akhileshgotmare' date='2020-04-21T13:00:02Z'>
		This should now be resolved by &lt;denchmark-link:https://github.com/pytorch/fairseq/pull/2032&gt;#2032&lt;/denchmark-link&gt;
.  &lt;denchmark-link:https://github.com/akhileshgotmare&gt;@akhileshgotmare&lt;/denchmark-link&gt;
 can you confirm if you pull ?
		</comment>
		<comment id='5' author='akhileshgotmare' date='2020-04-22T02:54:31Z'>
		Yes, I can load the models after the revert, thanks!
		</comment>
		<comment id='6' author='akhileshgotmare' date='2020-07-08T17:03:41Z'>
		Hi, do you guys have plans to publish a new pip version package since that package still has this problem.
		</comment>
		<comment id='7' author='akhileshgotmare' date='2020-07-08T18:05:39Z'>
		Hopefully soon, but in the meantime, you can do pip install git+https://github.com/pytorch/fairseq.git to install master via pip
		</comment>
	</comments>
</bug>