<bug id='1616' author='mohammadKhalifa' open_date='2020-01-13T17:17:13Z' closed_time='2020-01-13T17:42:47Z'>
	<summary>Sentencepiece error during calling XLMR model.encode()</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

when running
from fairseq.models.roberta import XLMRModel
xlmr = XLMRModel.from_pretrained('/path/to/xlmr.large', checkpoint_file='model.pt')

ids = xlmr.encode('Hello world!')
I get the following error
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/home/add/anaconda3/envs/py35/lib/python3.6/site-packages/fairseq/models/roberta/hub_interface.py", line 57, in encode
    bpe_sentence = '&lt;s&gt; ' + self.bpe.encode(sentence) + ' &lt;/s&gt;'
  File "/home/add/anaconda3/envs/py35/lib/python3.6/site-packages/fairseq/data/encoders/sentencepiece_bpe.py", line 30, in encode
    return ' '.join(self.sp.EncodeAsPieces(x))
TypeError: sequence item 0: expected str instance, bytes found
&lt;/denchmark-code&gt;

I am using fairseq 0.9.0 and sentencepiece 0.1.85
	</description>
	<comments>
		<comment id='1' author='mohammadKhalifa' date='2020-01-13T17:25:19Z'>
		Hmm, can you check if the published XLM-R models work?
I just tried with the same sentencepiece version and this worked for me:
&lt;denchmark-code&gt;&gt;&gt;&gt; import torch
&gt;&gt;&gt; xlmr = torch.hub.load('pytorch/fairseq', 'xlmr.large', force_reload=True)
&gt;&gt;&gt; xlmr.encode('Hello world')
tensor([    0, 35378,  8999,     2])
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='mohammadKhalifa' date='2020-01-13T17:42:47Z'>
		I run into the same problem when loading models from torch.hub. It turned out I had the wrong version of sentencepiece. Closing this isssue now.
		</comment>
	</comments>
</bug>