<bug id='1791' author='mgaido91' open_date='2020-03-06T16:27:03Z' closed_time='2020-03-10T18:51:18Z'>
	<summary>Sequence generation fails if the encoder outputs a sequence with lenght different from input</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

The problem is present when there is a model in which the encoder outputs a sequence having a length different from the input one. This is very common in speech processing models which contain convolutions reducing the size of the input.
With such a model, the following command fails:
&lt;denchmark-code&gt;python generate.py  $DATA_DIR \
    --gen-subset test \
    --path $MY_MODEL_PATH \
    --max-source-positions 2000 --max-target-positions 1000 \
    --task speech_recognition --user-dir examples/speech_recognition \
    --skip-invalid-size-inputs-valid-test
&lt;/denchmark-code&gt;

with the following stacktrace:
&lt;denchmark-code&gt;  File ".../fairseq/tasks/fairseq_task.py", line 317, in inference_step
    return generator.generate(models, sample, prefix_tokens=prefix_tokens)
  File ".../python3.7/site-packages/torch/autograd/grad_mode.py", line 49, in decorate_no_grad
    return func(*args, **kwargs)
  File ".../fairseq/sequence_generator.py", line 92, in generate
    return self._generate(model, sample, **kwargs)
  File ".../python3.7/site-packages/torch/autograd/grad_mode.py", line 49, in decorate_no_grad
    return func(*args, **kwargs)
  File .../fairseq/sequence_generator.py", line 335, in _generate
    attn[:, :, step + 1].copy_(avg_attn_scores)
RuntimeError: The size of tensor a (1069) must match the size of tensor b (268) at non-singleton dimension 1
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

A very simple reproducer is provided as unit test in the PR related to this issue.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The expected behavior is that the generation works fine without failures.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


fairseq Version (e.g., 1.0 or master): master
PyTorch Version (e.g., 1.0): 1.4
OS (e.g., Linux): Linux
How you installed fairseq (pip, source): source
Build command you used (if compiling from source): pip install -e .
Python version: 3.7
CUDA/cuDNN version: 10.0
GPU models and configuration: K80
Any other relevant information:

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

In the failure described in the command above I am using an implementation of &lt;denchmark-link:https://www.aclweb.org/anthology/W19-6603.pdf&gt;https://www.aclweb.org/anthology/W19-6603.pdf&lt;/denchmark-link&gt;
.
	</description>
	<comments>
	</comments>
</bug>