<bug id='2654' author='sooftware' open_date='2020-09-25T17:33:34Z' closed_time='2020-10-15T05:09:12Z'>
	<summary>Wav2vec Decoding with KenLM</summary>
	<description>
When I try evaluating the wav2vec-2.0 model with Ken-LM, I encounter a Segmentation fault error.
By debugging, I found the location that this error occurs.
In examples/speech_recognition/w2l_decoder.py  145-153 line (W2lKenLMDecoder Class)
for i, (word, spellings) in enumerate(self.lexicon.items()):
        word_idx = self.word_dict.get_index(word)
        _, score = self.lm.score(start_state, word_idx)
        for spelling in spellings:
            spelling_idxs = [tgt_dict.index(token) for token in spelling]
            assert (
                tgt_dict.unk() not in spelling_idxs
            ), f"{spelling} {spelling_idxs}"
            self.trie.insert(spelling_idxs, word_idx, score)
I download lexicon from &lt;denchmark-link:https://dl.fbaipublicfiles.com/fairseq/wav2vec/librispeech_lexicon.lst&gt;https://dl.fbaipublicfiles.com/fairseq/wav2vec/librispeech_lexicon.lst&lt;/denchmark-link&gt;

and I download kenlm from &lt;denchmark-link:https://dl.fbaipublicfiles.com/wav2letter/lexicon_free/librispeech/models/lm/lm_librispeech_kenlm_word_4g_200kvocab.bin&gt;https://dl.fbaipublicfiles.com/wav2letter/lexicon_free/librispeech/models/lm/lm_librispeech_kenlm_word_4g_200kvocab.bin&lt;/denchmark-link&gt;

I don't know what I did wrong. Please let me know.
Thank You !!

Command

&lt;denchmark-code&gt;python examples/speech_recognition/infer.py $MANIFEST_PATH --task audio_pretraining \
--nbest 1 --path /data/project/rw/kaki/model/wav2vec/wav2vec2_vox_960h.pt --gen-subset test-other \
--results-path /root/ --w2l-decoder kenlm \
--lm-model /data/project/rw/kaki/model/wav2vec/lm_librispeech_kenlm_word_4g_200kvocab.bin  \
--lm-weight 2 --word-score -1 --sil-weight 0 --criterion ctc --labels ltr --max-tokens 4000000 \
--post-process letter --lexicon /data/project/rw/kaki/model/wav2vec/librispeech_lexicon.lst
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='sooftware' date='2020-10-01T12:07:51Z'>
		Looks like lexicon is correct (from &lt;denchmark-link:https://github.com/pytorch/fairseq/issues/2502&gt;#2502&lt;/denchmark-link&gt;
), but lm model that I finally succeeded to use with that lexicon is just standard 4-gram one from openslr: &lt;denchmark-link:http://www.openslr.org/resources/11/4-gram.arpa.gz&gt;http://www.openslr.org/resources/11/4-gram.arpa.gz&lt;/denchmark-link&gt;

So you need to download it, convert to trie with kenlm binary as ./build_binary trie 4-gram.arpa.gz 4-gram.bin and launch it with --lm-model 4-gram.bin --lexicon librispeech_lexicon.lst --w2l-decoder kenlm
Hopefully it will be stated clear in readme one day
		</comment>
		<comment id='2' author='sooftware' date='2020-10-01T13:45:45Z'>
		&lt;denchmark-link:https://github.com/nosyrev&gt;@nosyrev&lt;/denchmark-link&gt;
 Thank you!! I don't understand what  is. Can you explain more specifically??
		</comment>
		<comment id='3' author='sooftware' date='2020-10-01T13:54:31Z'>
		&lt;denchmark-link:https://github.com/sooftware&gt;@sooftware&lt;/denchmark-link&gt;
 sure it's one of kenlm binaries. You just need to build &lt;denchmark-link:https://github.com/kpu/kenlm&gt;https://github.com/kpu/kenlm&lt;/denchmark-link&gt;
 , it will be in  folder after it
		</comment>
		<comment id='4' author='sooftware' date='2020-10-01T14:12:20Z'>
		&lt;denchmark-link:https://github.com/nosyrev&gt;@nosyrev&lt;/denchmark-link&gt;
 Thank you!! I`ll try it.
		</comment>
		<comment id='5' author='sooftware' date='2020-10-01T14:40:44Z'>
		&lt;denchmark-link:https://github.com/nosyrev&gt;@nosyrev&lt;/denchmark-link&gt;
 I encounter . I use the following command
&lt;denchmark-code&gt;python examples/speech_recognition/infer.py $MANIFEST_PATH --task audio_pretraining \
--nbest 1 --path wav2vec2_vox_960h.pt --gen-subset test-other --results-path $RESULT_PATH \
--w2l-decoder kenlm --word-score -1 --sil-weight 0 --criterion ctc --labels ltr --max-tokens 4000000 \
--post-process letter --lm-model 4-gram.bin --lexicon librispeech_lexicon.lst
&lt;/denchmark-code&gt;

Did I do anything wrong?
		</comment>
		<comment id='6' author='sooftware' date='2020-10-01T14:54:33Z'>
		&lt;denchmark-link:https://github.com/sooftware&gt;@sooftware&lt;/denchmark-link&gt;
 unfortunately have no idea, haven't experienced segfault myself (fortunately). Maybe it could be memory issue and model just doesn't fit in? Is it failing during loading or during processing? Will it work with single file? If I'd needed to debug this myself I'd went through that stages first, but it's obvious anyway. Sorry, can't help more here
		</comment>
		<comment id='7' author='sooftware' date='2020-10-01T15:06:04Z'>
		&lt;denchmark-link:https://github.com/nosyrev&gt;@nosyrev&lt;/denchmark-link&gt;
 Thank you. I'll debug T.T
		</comment>
		<comment id='8' author='sooftware' date='2020-10-17T00:11:06Z'>
		
@nosyrev I encounter Segmentation fault. I use the following command
python examples/speech_recognition/infer.py $MANIFEST_PATH --task audio_pretraining \
--nbest 1 --path wav2vec2_vox_960h.pt --gen-subset test-other --results-path $RESULT_PATH \
--w2l-decoder kenlm --word-score -1 --sil-weight 0 --criterion ctc --labels ltr --max-tokens 4000000 \
--post-process letter --lm-model 4-gram.bin --lexicon librispeech_lexicon.lst

Did I do anything wrong?

I think the problem related in kenlm, try watch the video in &lt;denchmark-link:https://www.youtube.com/watch?v=NtZipf0BxKg&gt;here&lt;/denchmark-link&gt;
, Tilman Kemp show to us the step by step procedural to reproduce the language model that build with kenLM.
look it, start from minutes 19:54.
even the video talk about deepspeech that use kenlm for the language model, I think what you try to build is related if that use kenlm, I mean all the procedure that Tilman Kemp show is own by kenlm not deepspeech.
Hope it help you..cheers
		</comment>
	</comments>
</bug>