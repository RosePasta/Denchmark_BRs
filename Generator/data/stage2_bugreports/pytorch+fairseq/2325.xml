<bug id='2325' author='rupjyotiBaruah' open_date='2020-07-14T11:13:06Z' closed_time='2020-07-14T15:47:17Z'>
	<summary>BPE fairseq-interactive: error</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Run the Inference switch from this link:
&lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/examples/byte_level_bpe/README.md&gt;https://github.com/pytorch/fairseq/blob/master/examples/byte_level_bpe/README.md&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Run the Command:&lt;/denchmark-h&gt;

"fairseq-interactive "data/bin_bbpe2048" --task translation --user-dir gru_transformer --path "checkpoints/bbpe2048/checkpoint_last.pt" --input data/test.hi --tokenizer moses --moses-source-lang hi --moses-target-lang mr --bpe byte_bpe --sentencepiece-model-path data/spm_bbpe2048.model --buffer-size 1000 --max-tokens 10000"
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Error&lt;/denchmark-h&gt;

usage: fairseq-interactive [-h] [--no-progress-bar] [--log-interval N]
[--log-format {json,none,simple,tqdm}]
[--tensorboard-logdir DIR] [--seed N] [--cpu]
[--fp16] [--memory-efficient-fp16]
[--fp16-init-scale FP16_INIT_SCALE]
[--fp16-scale-window FP16_SCALE_WINDOW]
[--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
[--min-loss-scale D]
[--threshold-loss-scale THRESHOLD_LOSS_SCALE]
[--user-dir USER_DIR]
[--empty-cache-freq EMPTY_CACHE_FREQ]
[--criterion {sentence_ranking,sentence_prediction,binary_cross_entropy,legacy_masked_lm_loss,adapt                               ive_loss,composite_loss,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,nat_loss,masked_lm,cross_entr                               opy}]
[--tokenizer {space,moses,nltk}]
[--bpe {subword_nmt,bert,gpt2,fastbpe,sentencepiece}]
[--optimizer {adam,nag,sgd,adamax,adadelta,adafactor,adagrad}]
[--lr-scheduler {polynomial_decay,cosine,triangular,tri_stage,reduce_lr_on_plateau,inverse_sqrt,fix                               ed}]
[--task TASK] [--num-workers N]
[--skip-invalid-size-inputs-valid-test]
[--max-tokens N] [--max-sentences N]
[--required-batch-size-multiple N]
[--dataset-impl FORMAT] [--gen-subset SPLIT]
[--num-shards N] [--shard-id ID] [--path FILE]
[--remove-bpe [REMOVE_BPE]] [--quiet]
[--model-overrides DICT] [--results-path RESDIR]
[--beam N] [--nbest N] [--max-len-a N]
[--max-len-b N] [--min-len N] [--match-source-len]
[--no-early-stop] [--unnormalized]
[--no-beamable-mm] [--lenpen LENPEN]
[--unkpen UNKPEN] [--replace-unk [REPLACE_UNK]]
[--sacrebleu] [--score-reference]
[--prefix-size PS] [--no-repeat-ngram-size N]
[--sampling] [--sampling-topk PS]
[--sampling-topp PS] [--temperature N]
[--diverse-beam-groups N]
[--diverse-beam-strength N] [--print-alignment]
[--print-step] [--iter-decode-eos-penalty N]
[--iter-decode-max-iter N]
[--iter-decode-force-max-iter]
[--retain-iter-history]
[--decoding-format {unigram,ensemble,vote,dp,bs}]
[--buffer-size N] [--input FILE]
fairseq-interactive: error: argument --bpe: invalid choice: 'byte_bpe' (choose from 'subword_nmt', 'bert', 'gpt2', 'fastbpe',                                'sentencepiece')
	</description>
	<comments>
		<comment id='1' author='rupjyotiBaruah' date='2020-07-14T15:47:17Z'>
		You need to use the latest version of fairseq (master), it won't work with 0.9.0 unfortunately. Please follow instructions here and reopen the task if it still doesn't work: &lt;denchmark-link:https://github.com/pytorch/fairseq#requirements-and-installation&gt;https://github.com/pytorch/fairseq#requirements-and-installation&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>