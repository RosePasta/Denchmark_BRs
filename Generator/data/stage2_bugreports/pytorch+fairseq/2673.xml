<bug id='2673' author='senarvi' open_date='2020-09-29T07:51:05Z' closed_time='2020-10-01T19:37:30Z'>
	<summary>Full-context alignment is broken in transformer_align model</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

transformer_align model, which implements the "Jointly Learning to Align and Translate" paper, supports full-context alignment, meaning that the auto-regressive mask is not applied to decoder self-attention. This feature is broken in the current master. When the --full-context-alignment flag is given to the model, it produces the error message
&lt;denchmark-code&gt;TypeError: forward() got an unexpected keyword argument 'full_context_alignment'
&lt;/denchmark-code&gt;

in the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/fairseq/models/transformer_align.py#L69&gt;forward_decoder() method of TransformerAlignModel&lt;/denchmark-link&gt;
. As far as I can see, this happens because the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/fairseq/models/transformer.py#L638&gt;forward() method of TransformerDecoder&lt;/denchmark-link&gt;
 doesn't have the  argument anymore, that was passed to the extract_features() method by the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/1c6679294848f303a361cba7b306b760e299bd9c/fairseq/models/transformer.py#L514&gt;version of the code at the time the transformer_align model was merged&lt;/denchmark-link&gt;
.
Ideally the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/tests/test_binaries.py#L428&gt;test_alignment() unit test&lt;/denchmark-link&gt;
 would also be updated to test this feature.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Follow the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/examples/joint_alignment_translation/README.md&gt;instructions&lt;/denchmark-link&gt;
, but additionally give the  flag to fairseq-train. It produces the following error message and stack trace:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File ".../bin/fairseq-train", line 11, in &lt;module&gt;
    load_entry_point('fairseq', 'console_scripts', 'fairseq-train')()
  File ".../fairseq_cli/train.py", line 351, in cli_main
    distributed_utils.call_main(args, main)
  File ".../fairseq/distributed_utils.py", line 254, in call_main
    main(args, **kwargs)
  File ".../fairseq_cli/train.py", line 125, in main
    valid_losses, should_stop = train(args, trainer, task, epoch_itr)
  File "/usr/lib64/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File ".../fairseq_cli/train.py", line 207, in train
    log_output = trainer.train_step(samples)
  File "/usr/lib64/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File ".../fairseq/trainer.py", line 479, in train_step
    ignore_grad=is_dummy_batch,
  File ".../fairseq/tasks/fairseq_task.py", line 408, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File ".../lib64/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File ".../fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py", line 36, in forward
    net_output = model(**sample['net_input'])
  File ".../lib64/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File ".../fairseq/models/transformer_align.py", line 51, in forward
    return self.forward_decoder(prev_output_tokens, encoder_out)
  File ".../fairseq/models/transformer_align.py", line 75, in forward_decoder
    **extra_args,
  File ".../lib64/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
TypeError: forward() got an unexpected keyword argument 'full_context_alignment'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

I expect fairseq-train to start training the model, like it does when I don't give the --full-context-alignment flag, but alignment supervised conditioned on the full target context.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


fairseq Version (e.g., 1.0 or master): master
PyTorch Version (e.g., 1.0): 1.6.0
OS (e.g., Linux): Linux
How you installed fairseq (pip, source): pip
Python version: 3.6.8

	</description>
	<comments>
		<comment id='1' author='senarvi' date='2020-09-29T17:00:20Z'>
		I assume this is how to fix it: &lt;denchmark-link:https://github.com/pytorch/fairseq/pull/2675&gt;#2675&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>