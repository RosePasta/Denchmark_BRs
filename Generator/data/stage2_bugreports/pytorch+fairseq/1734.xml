<bug id='1734' author='slusarczyk41' open_date='2020-02-21T12:48:18Z' closed_time='2020-02-23T09:27:20Z'>
	<summary>sqrt(): argument 'input' (position 1) must be Tensor, not int</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When using fairseq-train with RoBERTa model after 37 CUDA OOM's I get this error:
TypeError: sqrt(): argument 'input' (position 1) must be Tensor, not int
&lt;denchmark-h:h3&gt;Cmd I used&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;fairseq-train 'data-bin/agora' \
    --task masked_lm --criterion masked_lm \
    --arch roberta_base --sample-break-mode complete --tokens-per-sample 512 \
    --optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \
    --lr-scheduler polynomial_decay --lr 0.0005 --warmup-updates 50 \
    --total-num-update 100 \
    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \
    --max-sentences 6 --update-freq 40 \
    --max-update 100 --log-format simple --log-interval 1 \
    --restore-file 'roberta/checkpoint_best.pt' --save-dir 'my_models/agora' \
    --skip-invalid-size-inputs-valid-test --reset-optimizer
&lt;/denchmark-code&gt;


pretrained model downloaded from: https://github.com/sdadas/polish-nlp-resources/releases/download/roberta/roberta.zip

&lt;denchmark-h:h3&gt;Traceback I got&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;2020-02-21 13:40:23 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
Traceback (most recent call last):
  File "/home/jacek/anaconda3/envs/py36/bin/fairseq-train", line 11, in &lt;module&gt;
    load_entry_point('fairseq', 'console_scripts', 'fairseq-train')()
  File "/home/jacek/Projects/fairseq/fairseq_cli/train.py", line 307, in cli_main
    main(args)
  File "/home/jacek/Projects/fairseq/fairseq_cli/train.py", line 102, in main
    train(args, trainer, task, epoch_itr)
  File "/home/jacek/anaconda3/envs/py36/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/home/jacek/Projects/fairseq/fairseq_cli/train.py", line 171, in train
    log_output = trainer.train_step(samples)
  File "/home/jacek/anaconda3/envs/py36/lib/python3.6/contextlib.py", line 52, in inner
    return func(*args, **kwds)
  File "/home/jacek/Projects/fairseq/fairseq/trainer.py", line 369, in train_step
    grad_norm = self.optimizer.clip_grad_norm(self.args.clip_norm)
  File "/home/jacek/Projects/fairseq/fairseq/optim/fairseq_optimizer.py", line 91, in clip_grad_norm
    return utils.clip_grad_norm_(self.params, max_norm)
  File "/home/jacek/Projects/fairseq/fairseq/utils.py", line 243, in clip_grad_norm_
    sum(p.grad.data.norm()**2 for p in params if p.grad is not None)
TypeError: sqrt(): argument 'input' (position 1) must be Tensor, not int
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


fairseq Version (e.g., 1.0 or master): master
PyTorch Version (e.g., 1.0) 1.4.0
OS (e.g., Linux): Ubuntu 18.04
How you installed fairseq (pip, source): pip install --editable .
Python version: 3.6.9 Anaconda
CUDA/cuDNN version: ?
GPU models and configuration: 750 TI

	</description>
	<comments>
		<comment id='1' author='slusarczyk41' date='2020-02-21T14:53:21Z'>
		Your training command works for me. Are you sure you're on pytorch 1.4?
		</comment>
		<comment id='2' author='slusarczyk41' date='2020-02-21T19:54:09Z'>
		Yes it is 1.4. I will add tomorrow data needed to reproduce it. The thing is that command works, it trains model for about a minute and then throws an exception.
		</comment>
		<comment id='3' author='slusarczyk41' date='2020-02-21T21:43:41Z'>
		You mentioned seeing numerous OOMs. Does it work if you reduce the batch size so you don't OOM?
		</comment>
		<comment id='4' author='slusarczyk41' date='2020-02-23T09:27:20Z'>
		After changing to better GPU I didn't have any OOMs, and that problem vanished as well.
		</comment>
	</comments>
</bug>