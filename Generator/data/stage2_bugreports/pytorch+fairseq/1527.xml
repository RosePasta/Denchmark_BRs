<bug id='1527' author='felix-schneider' open_date='2019-12-19T13:58:17Z' closed_time='2019-12-19T16:56:21Z'>
	<summary>Multihead attention without bias still tries to initalize the bias</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

If you create a MultiheadAttention with bias=False, you get the following:
&lt;denchmark-code&gt;Traceback (most recent call last):
File "xxx/fairseq/fairseq/modules/multihead_attention.py", line 56, in __init__
    self.reset_parameters()
  File "xxx/fairseq/fairseq/modules/multihead_attention.py", line 82, in reset_parameters
    nn.init.constant_(self.out_proj.bias, 0.)
  File "xxx/torch/nn/init.py", line 120, in constant_
    return _no_grad_fill_(tensor, val)
  File "xxx/torch/nn/init.py", line 24, in _no_grad_fill_
    return tensor.fill_(val)
AttributeError: 'NoneType' object has no attribute 'fill_'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

from fairseq.modules import MultiheadAttention
a = MultiheadAttention(1, 1, bias=False)
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


fairseq Version: master
PyTorch Version: 1.3.1
OS: Linux
How you installed fairseq: source
Build command you used: pip install -e .
Python version: 3.7.4
CUDA/cuDNN version: 10.1
GPU models and configuration: N/A

	</description>
	<comments>
	</comments>
</bug>