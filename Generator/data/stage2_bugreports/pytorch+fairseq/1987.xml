<bug id='1987' author='14H034160212' open_date='2020-04-09T13:55:25Z' closed_time='2020-04-14T07:01:04Z'>
	<summary>Fine-tuning another dataset based on the intermediate training (RoBERTa-large + RACE)</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Hi, I am doing fine-tuning another dataset based on the intermediate training model (RoBERTa-large + RACE). The issue that I met is the train and valid accuracy floating around 50% cause the dataset is a binary classification task. Here is a simple example of the dataset "ParaRule". The dataset is from the paper from Allen AI "Transformers as Soft Reasoners over Language" (&lt;denchmark-link:https://rule-reasoning.apps.allenai.org/about&gt;https://rule-reasoning.apps.allenai.org/about&lt;/denchmark-link&gt;
).
&lt;denchmark-link:https://user-images.githubusercontent.com/23516191/78901510-87e3ed00-7acc-11ea-9616-50ac731caacb.png&gt;&lt;/denchmark-link&gt;

You can see the task is a binary classification task. But in this paper, it mentioned the accuracy can reach nearly 100%. You can see the difference between ParaRule and RACE is the former is a binary classification task and the second one is a classical machine reading comprehension task. To be specifically, the later one has the options for each question, while the former does not have.
By the way, I have got the intermediate training model (RoBERTa-large + RACE) successfully and the test accuracy is about 86.8% and then I choose the best checkpoint model as the fine-tuning model on the ParaRule dataset.
Here is the part of the result when I am doing the fine-tuning on ParaRule dataset. You can see the loss is floating around 1.03-1.04 and the accuracy is floating around 50.0. (P.S. One possible reason can be also the initial starting points. But do you know why in the RACE case, it is working by using UPDATE_FREQ=16 rather than UPDATE_FREQ=8? I guess that can be a possible way to solve my issue in this case.)
&lt;denchmark-code&gt;epoch 002:   3%| | 126/3721 [08:34&lt;3:48:09,  3.81s/it, loss=1.039, nll_loss=0.009, accuracy=49.2
epoch 002:  13%|\u258f| 476/3721 [30:54&lt;3:48:22,  4.22s/it, loss=1.039, nll_loss=0.009, accuracy=49.9
epoch 002:  13%|\u258f| 477/3721 [31:19&lt;3:47:49,  4.21s/it, loss=1.039, nll_loss=0.009, accuracy=49.9
epoch 002:  13%|\u258f| 478/3721 [31:24&lt;3:48:39,  4.23s/it, loss=1.039, nll_loss=0.009, accuracy=49.9
epoch 002:  24%|\u258f| 898/3721 [59:14&lt;3:06:09,  3.96s/it, loss=1.028, nll_loss=0.008, accuracy=52.4
epoch 002:  33%|\u258e| 1245/3721 [1:23:07&lt;2:45:00,  4.00s/it, loss=1.028, nll_loss=0.008, accuracy=50.4
&lt;/denchmark-code&gt;

Here is the fine-tuning command that I am using on the ParaRule dataset.
&lt;denchmark-code&gt;MAX_EPOCH=5           # Number of training epochs.
LR=1e-05              # Peak LR for fixed LR scheduler.
NUM_CLASSES=4
MAX_SENTENCES=1       # Batch size per GPU.
UPDATE_FREQ=16         # Accumulate gradients to simulate training on 16 GPUs. The original is 8 which is not work in my case.
DATA_DIR=/path/to/race-output-dir
ROBERTA_PATH=/path/to/roberta/model.pt

CUDA_VISIBLE_DEVICES=0,1 fairseq-train $DATA_DIR --ddp-backend=no_c10d \
    --restore-file $ROBERTA_PATH \
    --reset-optimizer --reset-dataloader --reset-meters \
    --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \
    --task sentence_ranking \
    --num-classes $NUM_CLASSES \
    --init-token 0 --separator-token 2 \
    --max-option-length 128 \
    --max-positions 512 \
    --truncate-sequence \
    --arch roberta_large \
    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \
    --criterion sentence_ranking \
    --optimizer adam --adam-betas '(0.9, 0.98)' --adam-eps 1e-06 \
    --clip-norm 0.0 \
    --lr-scheduler fixed --lr $LR \
    --fp16 --fp16-init-scale 4 --threshold-loss-scale 1 --fp16-scale-window 128 \
    --max-sentences $MAX_SENTENCES \
    --required-batch-size-multiple 1 \
    --update-freq $UPDATE_FREQ \
    --max-epoch $MAX_EPOCH
&lt;/denchmark-code&gt;

It will be great if you have any suggestion! Many thanks in advance.
	</description>
	<comments>
		<comment id='1' author='14H034160212' date='2020-04-13T12:18:06Z'>
		For BERT finetuning, the parameters are really important. I suggest tuning your parameters more.
		</comment>
		<comment id='2' author='14H034160212' date='2020-04-13T12:53:19Z'>
		Thanks &lt;denchmark-link:https://github.com/huihuifan&gt;@huihuifan&lt;/denchmark-link&gt;
. It is quite no sense of direction for tuning the parameters. I have tried fix the max-sentences (larger batch size, faster training speed), update-freq and max-option-length, but got the random results as well. Do you have any direction suggestions for the parameters setting? Many thanks.
		</comment>
		<comment id='3' author='14H034160212' date='2020-04-14T07:01:04Z'>
		
remove or reduce weight decay
switch to an annealing lr scheduler, e.g. cosine
sweep on combinations of lr/batch size

		</comment>
		<comment id='4' author='14H034160212' date='2020-04-14T08:43:14Z'>
		&lt;denchmark-link:https://github.com/alexeib&gt;@alexeib&lt;/denchmark-link&gt;
 Many thanks for your suggestion!
		</comment>
	</comments>
</bug>