<bug id='1827' author='villmow' open_date='2020-03-12T10:10:00Z' closed_time='2020-05-04T16:22:41Z'>
	<summary>Validation with sacrebleu tokenizes escaped UNK-tokens</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I'm on a translation task and do validation with BLEU during training. If --eval-tokenized-bleu is not set, scoring is done using the sacrebleu.DEFAULT_TOKENIZER. See these lines:



fairseq/fairseq/tasks/translation.py


        Lines 348 to 357
      in
      d7b0bf7






 hyps.append(decode(gen_out[i][0]['tokens'])) 



 refs.append(decode( 



 utils.strip_pad(sample['target'][i], self.tgt_dict.pad()), 



 escape_unk=True,  # don't count &lt;unk&gt; as matches to the hypo 



     )) 



 if self.args.eval_bleu_print_samples: 



 logger.info('example hypothesis: ' + hyps[0]) 



 logger.info('example reference: ' + refs[0]) 



 tokenize = sacrebleu.DEFAULT_TOKENIZER if not self.args.eval_tokenized_bleu else 'none' 



 return sacrebleu.corpus_bleu(hyps, [refs], tokenize=tokenize) 





UNK-tokens in references are escaped with &lt;&lt;UNK&gt;&gt; before scoring (line 351). This may produce a reference like this This is a new &lt;&lt;UNK&gt;&gt;.. In hypos the UNK-tokens are not escaped, leaving a hypothesis like this This is a new &lt;UNK&gt;.
Bug: The default tokenizer of sacrebleu breaks the UNK-tokens (which is probably not wanted behaviour) and scores each token separately, altering the bleu scores.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Follow any translation example.
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

This is whats currently implemented:
&gt;&gt;&gt; hypo = "This is a new &lt;UNK&gt;."
&gt;&gt;&gt; ref = "This is a new &lt;&lt;UNK&gt;&gt;."
&gt;&gt;&gt; from sacrebleu import TOKENIZERS, DEFAULT_TOKENIZER
&gt;&gt;&gt; TOKENIZERS[DEFAULT_TOKENIZER](hypo)
'This is a new &lt; UNK &gt; .'
&gt;&gt;&gt; TOKENIZERS[DEFAULT_TOKENIZER](ref)
'This is a new &lt; &lt; UNK &gt; &gt; .'
&gt;&gt;&gt; sacrebleu.corpus_bleu([hypo], [[ref]], tokenize=DEFAULT_TOKENIZER).score
55.96526475152516
This is how I think these sequences should be scored:
&gt;&gt;&gt; hypo = "This is a new ABC."
&gt;&gt;&gt; ref = "This is a new UNK."
&gt;&gt;&gt; TOKENIZERS[DEFAULT_TOKENIZER](ref)
'This is a new UNK .'
&gt;&gt;&gt; TOKENIZERS[DEFAULT_TOKENIZER](hypo)
'This is a new ABC .'
&gt;&gt;&gt; sacrebleu.corpus_bleu([hypo], [[ref]], tokenize=DEFAULT_TOKENIZER).score
53.7284965911771
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The bleu score should not be influenced by the unknown token.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


fairseq Version (e.g., 1.0 or master): master
PyTorch Version (e.g., 1.0): 1.2
OS (e.g., Linux): linux
How you installed fairseq (pip, source): source

	</description>
	<comments>
		<comment id='1' author='villmow' date='2020-05-04T16:22:40Z'>
		Fixed by &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/b2ee110c853c5effdd8d21f50a8437485bafb285&gt;b2ee110&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='villmow' date='2020-05-31T14:55:34Z'>
		I also see that after fairseq.preprocess, some tokens are not there in the dicts for both the languages. What might be the reason?
		</comment>
	</comments>
</bug>