<bug id='2705' author='DoubleVII' open_date='2020-10-07T08:43:05Z' closed_time='2020-10-17T16:39:07Z'>
	<summary>The registries update forces the "--remove-bpe" option to require an argument</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

After the commit &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/5e82514d687289a73a6dec33b555217acd97cb0d&gt;update registries&lt;/denchmark-link&gt;
, the option "--remove-bpe" needs an argument to declare the BPE decoder, which can be omitted according to the document. The &lt;denchmark-link:https://github.com/pytorch/fairseq/tree/master/examples/translation&gt;translation examples&lt;/denchmark-link&gt;
 also gives the omitted format.
Further more, giving the argument 'subword_nmt', which is used to apply BPE at the preprocessing stage of the translation examples, the BLEU socre is still higher than the ture value. I have tried a couple of possible candidates, but they don't work.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;


Run the given cmd of the translation examples

&lt;denchmark-code&gt;fairseq-generate data-bin/iwslt14.tokenized.de-en \
    --path checkpoints/checkpoint_best.pt \
    --batch-size 128 --beam 5 --remove-bpe
&lt;/denchmark-code&gt;


See error

&lt;denchmark-code&gt;usage: fairseq-generate [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                        [--log-format {json,none,simple,tqdm}]
                        [--tensorboard-logdir TENSORBOARD_LOGDIR]
                        [--seed SEED] [--cpu] [--tpu] [--bf16]
                        [--memory-efficient-bf16] [--fp16]
                        [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                        [--fp16-init-scale FP16_INIT_SCALE]
                        [--fp16-scale-window FP16_SCALE_WINDOW]
                        [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                        [--min-loss-scale MIN_LOSS_SCALE]
                        [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                        [--user-dir USER_DIR]
                        [--empty-cache-freq EMPTY_CACHE_FREQ]
                        [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                        [--model-parallel-size MODEL_PARALLEL_SIZE]
                        [--checkpoint-suffix CHECKPOINT_SUFFIX]
                        [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                        [--profile]
                        [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,example_criterion,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,legacy_masked_lm_loss,masked_lm,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                        [--tokenizer {moses,nltk,space}]
                        [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                        [--optimizer {adadelta,adafactor,adagrad,adam,adamax,lamb,nag,sgd}]
                        [--lr-scheduler {cosine,fixed,inverse_sqrt,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage}]
                        [--scoring {sacrebleu,bleu,wer}] [--task TASK]
                        [--num-workers NUM_WORKERS]
                        [--skip-invalid-size-inputs-valid-test]
                        [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                        [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                        [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                        [--dataset-impl {raw,lazy,cached,mmap,fasta}]
                        [--data-buffer-size DATA_BUFFER_SIZE]
                        [--train-subset TRAIN_SUBSET]
                        [--valid-subset VALID_SUBSET]
                        [--validate-interval VALIDATE_INTERVAL]
                        [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                        [--validate-after-updates VALIDATE_AFTER_UPDATES]
                        [--fixed-validation-seed FIXED_VALIDATION_SEED]
                        [--disable-validation]
                        [--max-tokens-valid MAX_TOKENS_VALID]
                        [--batch-size-valid BATCH_SIZE_VALID]
                        [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                        [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                        [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                        [--distributed-rank DISTRIBUTED_RANK]
                        [--distributed-backend DISTRIBUTED_BACKEND]
                        [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                        [--distributed-port DISTRIBUTED_PORT]
                        [--device-id DEVICE_ID] [--local-rank LOCAL_RANK]
                        [--distributed-no-spawn]
                        [--ddp-backend {c10d,no_c10d}]
                        [--bucket-cap-mb BUCKET_CAP_MB]
                        [--fix-batches-to-gpus] [--find-unused-parameters]
                        [--fast-stat-sync] [--broadcast-buffers]
                        [--distributed-wrapper {DDP,SlowMo}]
                        [--slowmo-momentum SLOWMO_MOMENTUM]
                        [--slowmo-algorithm SLOWMO_ALGORITHM]
                        [--localsgd-frequency LOCALSGD_FREQUENCY]
                        [--nprocs-per-node NPROCS_PER_NODE]
                        [--pipeline-model-parallel]
                        [--pipeline-balance PIPELINE_BALANCE]
                        [--pipeline-devices PIPELINE_DEVICES]
                        [--pipeline-chunks PIPELINE_CHUNKS]
                        [--pipeline-checkpoint {always,never,except_last}]
                        [--zero-sharding {none,os}] [--path PATH]
                        [--remove-bpe REMOVE_BPE] [--quiet]
                        [--model-overrides MODEL_OVERRIDES]
                        [--results-path RESULTS_PATH] [--beam N] [--nbest N]
                        [--max-len-a N] [--max-len-b N] [--min-len N]
                        [--match-source-len] [--no-early-stop]
                        [--unnormalized] [--no-beamable-mm] [--lenpen LENPEN]
                        [--unkpen UNKPEN] [--replace-unk [REPLACE_UNK]]
                        [--sacrebleu] [--score-reference] [--prefix-size PS]
                        [--no-repeat-ngram-size N] [--sampling]
                        [--sampling-topk PS] [--sampling-topp PS]
                        [--constraints [{ordered,unordered}]]
                        [--temperature N] [--diverse-beam-groups N]
                        [--diverse-beam-strength N] [--diversity-rate N]
                        [--print-alignment] [--print-step]
                        [--iter-decode-eos-penalty N]
                        [--iter-decode-max-iter N]
                        [--iter-decode-force-max-iter]
                        [--iter-decode-with-beam N]
                        [--iter-decode-with-external-reranker]
                        [--retain-iter-history] [--retain-dropout]
                        [--retain-dropout-modules RETAIN_DROPOUT_MODULES [RETAIN_DROPOUT_MODULES ...]]
                        [--decoding-format {unigram,ensemble,vote,dp,bs}]
fairseq-generate: error: argument --remove-bpe: expected one argument
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

No error when the argument is omitted, or correct BLEU socre when the argument is specified.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


fairseq Version: master
PyTorch Version: 1.6.0
OS : Linux or Windows
How you installed fairseq: source
Build command you used (if compiling from source): pip install --editable ./
Python version: 3.6.9

	</description>
	<comments>
		<comment id='1' author='DoubleVII' date='2020-10-10T19:17:34Z'>
		please provide "@@ " as argument. going forward it will not be possible to have implicit argument values. open to suggestions though. perhaps we can split this argument into "--post-process" (which enables "removing bpe" and other post processing options) and then "--bpe-symbol" for bpe removal, which we can default to "@@ "?
		</comment>
	</comments>
</bug>