<bug id='1632' author='freewym' open_date='2020-01-19T21:44:08Z' closed_time='2020-01-21T00:34:41Z'>
	<summary>Training loss is mixed with valid loss</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

After the latest introduction of metrics, the training loss printed as log is different from before, which I suspect is because  its value is somewhat mixed with valid loss
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior (always include the command you ran):
You can reproduce it by observing the difference of training losses before/after setting --disable-validation
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


fairseq Version (e.g., 1.0 or master): master
PyTorch Version (e.g., 1.0): 1.1
OS (e.g., Linux):
How you installed fairseq (pip, source):
Build command you used (if compiling from source):
Python version:
CUDA/cuDNN version:
GPU models and configuration:
Any other relevant information:

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='freewym' date='2020-01-20T05:01:24Z'>
		Good catch, this bug was actually introduced in &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/60fbf64f302a825eee77637a0b7de54fde38fb2c&gt;60fbf64&lt;/denchmark-link&gt;
, with the switching of lines 166/167 in train.py. Will merge a fix soon.
		</comment>
	</comments>
</bug>