<bug id='2083' author='eshaan-pathak' open_date='2020-04-30T20:33:44Z' closed_time='2020-05-11T19:43:25Z'>
	<summary>"argument --distributed-world-size: conflicting option string: --distributed-world-size" Error</summary>
	<description>
&lt;denchmark-h:h2&gt;‚ùì Questions and Help&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Before asking:&lt;/denchmark-h&gt;


search the issues.
search the docs.

&lt;denchmark-h:h4&gt;What is your question?&lt;/denchmark-h&gt;

After training my model, I would like to evaluate it; however, I run into an argument parse error, as seen below. I am using the command lines from &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/examples/language_model/README.md&gt;here&lt;/denchmark-link&gt;
 and have slightly modified them where I am using a patience of 3, no-epoch-checkpoints, removed fp16, and distributed-world-size of 1 when training. I also changed the paths to reflect my own directory structure. These are the only changes I have made from the link, and I am sure that they are properly formatted. Any help is appreciated. :)
&lt;denchmark-h:h4&gt;Code&lt;/denchmark-h&gt;

Traceback (most recent call last):
File "/home/e/miniconda3/envs/eshaan/bin/fairseq-eval-lm", line 11, in 
load_entry_point('fairseq', 'console_scripts', 'fairseq-eval-lm')()
File "/srv/home/e/eshaan/fairseq/fairseq_cli/eval_lm.py", line 251, in cli_main
add_distributed_training_args(parser)
File "/srv/home/e/eshaan/fairseq/fairseq/options.py", line 356, in add_distributed_training_args
help='total number of GPUs across all nodes (default: all visible GPUs)')
File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1352, in add_argument
return self._add_action(action)
File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1556, in _add_action
action = super(_ArgumentGroup, self)._add_action(action)
File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1366, in _add_action
self._check_conflict(action)
File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1505, in _check_conflict
conflict_handler(action, confl_optionals)
File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1514, in _handle_conflict_error
raise ArgumentError(action, message % conflict_string)
argparse.ArgumentError: argument --distributed-world-size: conflicting option string: --distributed-world-size
&lt;denchmark-h:h4&gt;What have you tried?&lt;/denchmark-h&gt;

I have tried retraining my model in case it was an issue with how my checkpoints were stored, despite how the output always said my distributed world size is 1. I have also looked at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/8389&gt;this similar error&lt;/denchmark-link&gt;
 to make sure that no other python processes are running.
&lt;denchmark-h:h4&gt;What's your environment?&lt;/denchmark-h&gt;


fairseq Version (e.g., 1.0 or master): 0.9.0
PyTorch Version (e.g., 1.0): 1.4.0
OS (e.g., Linux): Ubuntu 16.04.6 LTS (Xenial Xerus)
How you installed fairseq (pip, source): source
Build command you used (if compiling from source): pip install -e fairseq/
Python version: 3.6.10
CUDA/cuDNN version: CUDA release 10.1, V10.1.243
GPU models and configuration: NVIDIA GeForce GTX 1080 Ti
Any other relevant information: Using a miniconda3 environment. There are 8 GPUs on the server that I am SSH'd into, but I am only connected to 1.

	</description>
	<comments>
		<comment id='1' author='eshaan-pathak' date='2020-05-02T05:09:33Z'>
		I encountered this bug as well. Seems like commenting out line 251 (add_distributed_training_args(parser)) in fairseq_cli/eval_lm.py fixes it.
		</comment>
		<comment id='2' author='eshaan-pathak' date='2020-05-04T16:21:50Z'>
		Fixed by &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/b2ee110c853c5effdd8d21f50a8437485bafb285&gt;b2ee110&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='eshaan-pathak' date='2020-05-05T21:51:23Z'>
		Hi Myle!
I think there might still be an issue here. When I run eval_lm with the argument "--distributed-world-size 1" it fails:
File "eval_lm.py", line 11, in 
cli_main()
File "fairseq_cli/eval_lm.py", line 252, in cli_main
distributed_utils.call_main(args, main)
File "fairseq/distributed_utils.py", line 173, in call_main
main(args, kwargs)
TypeError: main() takes 1 positional argument but 2 were given
		</comment>
		<comment id='4' author='eshaan-pathak' date='2020-05-12T14:19:54Z'>
		This should actually be fixed now :)
		</comment>
	</comments>
</bug>