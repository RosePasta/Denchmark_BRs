<bug id='2678' author='RobertLucian' open_date='2020-09-30T16:04:45Z' closed_time='2020-10-03T15:09:56Z'>
	<summary>Omegaconf &amp; hydra-core missing dependencies</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

After installing torch, trying to load a model will fail due to two missing dependencies: omegaconf and hydra-core.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Running the following code block doesn't work:
import torch
roberta = torch.hub.load("pytorch/fairseq", "roberta.large")
roberta.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"using device: {device}")
roberta.to(device)
The traceback I get is:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/src/cortex/lib/type/predictor.py", line 111, in initialize_impl
    return class_impl(**args)
  File "/mnt/project/predictor.py", line 10, in __init__
    roberta = torch.hub.load("pytorch/fairseq", "roberta.large")
  File "/opt/conda/envs/env/lib/python3.6/site-packages/torch/hub.py", line 349, in load
    hub_module = import_module(MODULE_HUBCONF, repo_dir + '/' + MODULE_HUBCONF)
  File "/opt/conda/envs/env/lib/python3.6/site-packages/torch/hub.py", line 71, in import_module
    spec.loader.exec_module(module)
  File "&lt;frozen importlib._bootstrap_external&gt;", line 678, in exec_module
  File "&lt;frozen importlib._bootstrap&gt;", line 219, in _call_with_frames_removed
  File "/root/.cache/torch/hub/pytorch_fairseq_master/hubconf.py", line 8, in &lt;module&gt;
    from fairseq.hub_utils import BPEHubInterface as bpe  # noqa
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/__init__.py", line 17, in &lt;module&gt;
    import fairseq.criterions  # noqa
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/criterions/__init__.py", line 26, in &lt;module&gt;
    importlib.import_module('fairseq.criterions.' + module)
  File "/opt/conda/envs/env/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/criterions/adaptive_loss.py", line 12, in &lt;module&gt;
    from fairseq.dataclass.data_class import DDP_BACKEND_CHOICES
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/dataclass/data_class.py", line 12, in &lt;module&gt;
    from fairseq.tasks import TASK_DATACLASS_REGISTRY
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/tasks/__init__.py", line 73, in &lt;module&gt;
    importlib.import_module('fairseq.tasks.' + task_name)
  File "/opt/conda/envs/env/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/tasks/language_modeling.py", line 36, in &lt;module&gt;
    from omegaconf import II
ModuleNotFoundError: No module named 'omegaconf'
&lt;/denchmark-code&gt;

Then, if I add omegaconf to the requirements.txt file, the next error I get is:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/src/cortex/lib/type/predictor.py", line 111, in initialize_impl
    return class_impl(**args)
  File "/mnt/project/predictor.py", line 10, in __init__
    roberta = torch.hub.load("pytorch/fairseq", "roberta.large")
  File "/opt/conda/envs/env/lib/python3.6/site-packages/torch/hub.py", line 349, in load
    hub_module = import_module(MODULE_HUBCONF, repo_dir + '/' + MODULE_HUBCONF)
  File "/opt/conda/envs/env/lib/python3.6/site-packages/torch/hub.py", line 71, in import_module
    spec.loader.exec_module(module)
  File "&lt;frozen importlib._bootstrap_external&gt;", line 678, in exec_module
  File "&lt;frozen importlib._bootstrap&gt;", line 219, in _call_with_frames_removed
  File "/root/.cache/torch/hub/pytorch_fairseq_master/hubconf.py", line 8, in &lt;module&gt;
    from fairseq.hub_utils import BPEHubInterface as bpe  # noqa
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/__init__.py", line 17, in &lt;module&gt;
    import fairseq.criterions  # noqa
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/criterions/__init__.py", line 26, in &lt;module&gt;
    importlib.import_module('fairseq.criterions.' + module)
  File "/opt/conda/envs/env/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/criterions/adaptive_loss.py", line 12, in &lt;module&gt;
    from fairseq.dataclass.data_class import DDP_BACKEND_CHOICES
  File "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/dataclass/data_class.py", line 18, in &lt;module&gt;
    from hydra.core.config_store import ConfigStore
ModuleNotFoundError: No module named 'hydra'
&lt;/denchmark-code&gt;

Adding hydra-core to the requirementst.txt fixes the issue. With both of them in, torch works as expected - one thing I've noticed is that when installing them, they go through a complex-looking stage of compiling stuff with g++ (takes some time).
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Expected it to work without having to install omegaconf and hydra-core. The provided example worked without these a couple of months ago - maybe something did change in torch?
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Installed torch the following way:
&lt;denchmark-code&gt;pip install --no-cache-dir --find-links https://download.pytorch.org/whl/torch_stable.html torch==1.6.0+cu101 torchvision==0.7.0+cu101
&lt;/denchmark-code&gt;


OS (e.g., Linux): Linux.
Python version: 3.6.9.
CUDA/cuDNN version: 10.1
GPU models and configuration: A single T4 GPU.

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

As fixed in &lt;denchmark-link:https://github.com/cortexlabs/cortex/pull/1402&gt;cortexlabs/cortex#1402&lt;/denchmark-link&gt;
. Suggested by &lt;denchmark-link:https://github.com/omry&gt;@omry&lt;/denchmark-link&gt;
 to post here.
	</description>
	<comments>
		<comment id='1' author='RobertLucian' date='2020-09-30T16:31:13Z'>
		&lt;denchmark-link:https://github.com/RobertLucian&gt;@RobertLucian&lt;/denchmark-link&gt;
, the stack trace suggests that you do have version of fairseq installed that depends on Hydra.
Can you show a complete repro including how you create the environment?
(say, a clean conda environment).
		</comment>
		<comment id='2' author='RobertLucian' date='2020-09-30T16:43:51Z'>
		Thanks for flagging,  uses its own mechanism for specifying dependencies, and we need to add hydra there: &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/hubconf.py#L13-L18&gt;https://github.com/pytorch/fairseq/blob/master/hubconf.py#L13-L18&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='RobertLucian' date='2020-09-30T16:48:55Z'>
		Thanks &lt;denchmark-link:https://github.com/myleott&gt;@myleott&lt;/denchmark-link&gt;
, I spotted it at the repo root and I thought it might be the case.
		</comment>
		<comment id='4' author='RobertLucian' date='2020-10-01T15:50:01Z'>
		&lt;denchmark-link:https://github.com/myleott&gt;@myleott&lt;/denchmark-link&gt;
 thanks a lot for your quick resolution on this!
&lt;denchmark-link:https://github.com/omry&gt;@omry&lt;/denchmark-link&gt;
 in this case, is a complete repro including the process of creating the environment still necessary?
		</comment>
		<comment id='5' author='RobertLucian' date='2020-10-01T17:32:20Z'>
		No need, as we have identified the root cause.
		</comment>
		<comment id='6' author='RobertLucian' date='2020-10-02T06:11:00Z'>
		&lt;denchmark-link:https://github.com/RobertLucian&gt;@RobertLucian&lt;/denchmark-link&gt;
, that that we are clearing the unneeded dependency of Hydra in Cortex - I recommend that you take a look anyway and consider using it.
&lt;denchmark-link:https://hydra.cc&gt;https://hydra.cc&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='RobertLucian' date='2020-10-02T09:38:58Z'>
		Thanks &lt;denchmark-link:https://github.com/omry&gt;@omry&lt;/denchmark-link&gt;
, I'll have a look at it.
		</comment>
		<comment id='8' author='RobertLucian' date='2020-10-02T20:24:02Z'>
		This should be fixed by &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/f902a363abc578906f29239f995cacce5e93a807&gt;f902a36&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='RobertLucian' date='2020-10-02T21:06:00Z'>
		&lt;denchmark-link:https://github.com/myleott&gt;@myleott&lt;/denchmark-link&gt;
 thanks for the fix.
Any idea when this is gonna land (or is it just a patch and is already available)?
Also, is there an ETA of when this will make it in torch (as a dependency)?
		</comment>
		<comment id='10' author='RobertLucian' date='2020-10-02T22:55:48Z'>
		Actually that didn't totally fix it üòï Just to clarify, it seems hydra-core will be a required dependency for torch.hub usage going forward.

Any idea when this is gonna land (or is it just a patch and is already available)?
Also, is there an ETA of when this will make it in torch (as a dependency)?

When it lands it will take effect immediately, you'll just need to do torch.hub.load(..., force_reload=True).
		</comment>
		<comment id='11' author='RobertLucian' date='2020-10-03T13:24:29Z'>
		This should be fixed. Please use torch.hub.load(..., force_reload=True). Note that dataclasses and hydra-core are now required dependencies, so you'll need to pip install them if you haven't already.
		</comment>
	</comments>
</bug>