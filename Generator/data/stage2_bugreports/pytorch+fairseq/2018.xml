<bug id='2018' author='davkovacs' open_date='2020-04-15T10:19:27Z' closed_time='2020-05-04T16:25:34Z'>
	<summary>Learning rate changes when restarting training from checkpoint</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When training a Levensthein Transformer model and trying to restart training from a checkpoint the learning rate, that should be fixed changes to a small value.
This is the log for writing the checkpoint:
&lt;denchmark-code&gt;2020-04-08 05:30:58 | INFO | train_inner | epoch 774:     87 / 181 loss=0.524, nll_loss=0.118, mask_ins=0.392, word_ins=0.118, word_del=0.014, ppl=1.44, wps=10375.3, ups=4.6, wpb=2256.7, bsz=51, num_updates=140000, lr=0.0005, gnorm=1.151, clip=0, train_wall=444, wall=29522

2020-04-08 05:31:00 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 1.979 | nll_loss 1.104 | mask_ins 0.634 | word_ins 1.104 | word_del 0.242 | ppl 3.94 | wps 38870.5 | wpb 2070.1 | bsz 47.4 | num_updates 140000 | best_loss 1.513
2020-04-08 05:31:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/dpk25/rds/hpc-work/lev_transformer/USPTO-15k_5/checkpoints/checkpoint_774_140000.pt (epoch 774 @ 140000 updates, score 1.979) (writing took 1.704027434810996 seconds)
&lt;/denchmark-code&gt;

The learning rate is 0.005 as is set in the input file. but when restarting training using the --restore-file checkpoint_774_140000.pt The learning rate is not fixed any more and goes to very small values even though the checkpoint is successfully loaded.
&lt;denchmark-code&gt;2020-04-08 14:02:38 | INFO | fairseq.trainer | loaded checkpoint /home/dpk25/rds/hpc-work/lev_transformer/USPTO-15k_5/checkpoints/checkpoint_774_140000.pt (epoch 774 @ 140000 updates)

2020-04-08 14:02:58 | INFO | train | epoch 774 | loss 0.526 | nll_loss 0.12 | mask_ins 0.392 | word_ins 0.12 | word_del 0.014 | ppl 1.44 | wps 9996.3 | ups 4.43 | wpb 2254.3 | bsz 51 | num_updates 140094 | lr 6.25e-08 | gnorm 1.135 | clip 0 | train_wall 33 | wall 0
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior (always include the command you ran):
Train a Levensthein Transformer model with fixed learning rate:

Run

&lt;denchmark-code&gt;CUDA_VISIBLE_DEVICES=0 fairseq-train $TEXT/data-bin \
    --save-dir  $SAVE_DIR \
    --tensorboard-logdir $LOG_DIR \
    --ddp-backend=no_c10d \
    --task translation_lev \
    --criterion nat_loss \
    --arch levenshtein_transformer \
    --noise random_delete \
    --share-all-embeddings \
    --optimizer adam --adam-betas '(0.9,0.98)' \
    --clip-norm 25 \
    --lr 0.0005 --lr-scheduler fixed \
    --warmup-updates 8000 \
    --label-smoothing 0 \
    --dropout 0.15  \
    --encoder-layers 4 --encoder-attention-heads 8 \
    --encoder-embed-dim 256 --encoder-ffn-embed-dim 2048 \
    --encoder-normalize-before \
    --decoder-layers 4 --decoder-attention-heads 8 \
    --decoder-normalize-before --early-exit "4,4,4" \
    --attention-dropout 0.15 --activation-dropout 0.15 \
    --log-format 'simple' --log-interval 2500 \
    --fixed-validation-seed 7 \
    --max-tokens 4096 \
    --save-interval-updates 10000 \
    --keep-interval-updates 0 --keep-last-epochs 0 \
    --max-update 400000 --seed 42
&lt;/denchmark-code&gt;

And then run the same command just adding to the end
&lt;denchmark-code&gt;--restore-file $SAVE_DIR/checkpoint_774_140000.pt 
&lt;/denchmark-code&gt;


See error
The learning rate in the restarted training will change to some very small value. (and remain fixed for the rest of the training at that small value)

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

I am hoping to be able to continue the training with the same learning rate
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


fairseq Version git cloned from here
PyTorch Version 1.4.0
OS (e.g., Linux): Linux
How you installed fairseq (pip, source): git clone and then setup following instructions inlcuding the apex.
Build command you used (if compiling from source):  python setup.py build_ext --inplace
Python version: 3.6.10
CUDA/cuDNN version: CUDA 10.1
GPU models and configuration:
Any other relevant information:

	</description>
	<comments>
		<comment id='1' author='davkovacs' date='2020-05-04T16:25:34Z'>
		Fixed by &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/7a6519f84fed06947bbf161c7b66c9099bc4ce53&gt;7a6519f&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>