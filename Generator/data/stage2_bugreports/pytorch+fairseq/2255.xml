<bug id='2255' author='hury07' open_date='2020-06-20T03:17:36Z' closed_time='2020-06-22T18:08:03Z'>
	<summary>memory leakage caused by logging_output in criterion "masked_lm"</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I found memory (not GPU memory) leakage event when trying masked language modeling task.
The memory usage was increasing when the trainning proceeded.
The bug was caused by 'loss' item in logging_output in the file criterions/masked_lm.py.
The original code is,
64         logging_output = {
65             'loss': loss,
66             'ntokens': sample['ntokens'],
67             'nsentences': sample['nsentences'],
68             'sample_size': sample_size,
69         }
The bug could be fixed with the following code.
64         logging_output = {
65             'loss': loss.data,
66             'ntokens': sample['ntokens'],
67             'nsentences': sample['nsentences'],
68             'sample_size': sample_size,
69         }
	</description>
	<comments>
		<comment id='1' author='hury07' date='2020-06-22T14:00:52Z'>
		Interesting, can you confirm that using .detach() instead of .data works as well? I believe detach() is the preferred way of doing this now.
		</comment>
		<comment id='2' author='hury07' date='2020-06-22T16:29:17Z'>
		&lt;denchmark-link:https://github.com/joshim5&gt;@joshim5&lt;/denchmark-link&gt;
 has a fix for this
		</comment>
		<comment id='3' author='hury07' date='2020-06-22T18:08:03Z'>
		Landed in &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/8eb9123f560d32940f96a01369d61c1684dce085&gt;8eb9123&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://github.com/hury07&gt;@hury07&lt;/denchmark-link&gt;
 please reopen this issue if you still encounter problems.
		</comment>
	</comments>
</bug>