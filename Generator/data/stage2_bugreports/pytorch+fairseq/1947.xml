<bug id='1947' author='tuhinjubcse' open_date='2020-03-31T10:02:29Z' closed_time='2020-03-31T21:04:42Z'>
	<summary>BART generation results for top k differ in each run</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Every time I do Bart.sample for topk the results are different. For reproducibility is there a way to fix this?
               hypotheses_batch = bart.sample(slines, sampling=True, sampling_topk=5, temperature=0.7, lenpen=2.0, max_len_b=30, min_len=7, no_repeat_ngram_size=3)
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Environment

fairseq Version (e.g., 1.0 or master): 0.9.0
PyTorch Version (e.g., 1.0) 1.3.1
OS (e.g., Linux): Linux
How you installed fairseq (pip, source):
Build command you used (if compiling from source):
Python version: 3.7.3
CUDA/cuDNN version: 10.1.243
GPU models and configuration: RTX 2080 ( 4 gpus)

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='tuhinjubcse' date='2020-03-31T10:02:47Z'>
		&lt;denchmark-link:https://github.com/myleott&gt;@myleott&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='tuhinjubcse' date='2020-03-31T14:22:09Z'>
		Did you run bart.eval() first? If not, bart is in training mode and dropout will still be enabled leading to non-deterministic results.
		</comment>
		<comment id='3' author='tuhinjubcse' date='2020-03-31T16:49:36Z'>
		Yes I did put bart.eval()
&lt;denchmark-code&gt;bart = BARTModel.from_pretrained('checkpoint-similenew/',checkpoint_file='checkpoint_best.pt',data_name_or_path='similenew')

bart.cuda()
bart.eval()
#bart.half()
count = 1
bsz = 128
print("done")
t = 0.7
for val in [5]:
    with open('similenew/test.source') as source, open('similenew/testtopk5_0.7.hypo', 'w') as fout:
        sline = source.readline().strip()
        slines = [sline]
        for sline in source:
            if count % bsz == 0:
                with torch.no_grad():
                    hypotheses_batch = bart.sample(slines, sampling=True, sampling_topk=val  ,temperature=t ,lenpen=2.0, max_len_b=30, min_len=7, no_repeat_ngram_size=3)
                for hypothesis in hypotheses_batch:
                    fout.write(hypothesis.replace('\n','') + '\n')
                    fout.flush()
                slines = []

            slines.append(sline.strip())
            count += 1
        if slines != []:
            hypotheses_batch = bart.sample(slines, sampling=True,   sampling_topk=val  ,temperature=t ,lenpen=2.0, max_len_b=30, min_len=7, no_repeat_ngram_size=3)
            for hypothesis in hypotheses_batch:
                fout.write(hypothesis.replace('\n','') + '\n')
                fout.flush()

&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='tuhinjubcse' date='2020-03-31T17:20:23Z'>
		I'm a bit confused by your code. You're saying that if you run this script twice, the output file contains different hypotheses?
		</comment>
		<comment id='5' author='tuhinjubcse' date='2020-03-31T17:32:49Z'>
		&lt;denchmark-code&gt;import torch
from fairseq.models.bart import BARTModel

bart = BARTModel.from_pretrained(
    'checkpoints/',
    checkpoint_file='checkpoint_best.pt',
    data_name_or_path='cnn_dm-bin'
)

bart.cuda()
bart.eval()

Nothing confusing its the same as fairseq repo 
Yes I get different hypothesis in each run
bart.half()
count = 1
bsz = 32
with open('cnn_dm/test.source') as source, open('cnn_dm/test.hypo', 'w') as fout:
    sline = source.readline().strip()
    slines = [sline]
    for sline in source:
        if count % bsz == 0:
            with torch.no_grad():
                hypotheses_batch = bart.sample(slines, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)

            for hypothesis in hypotheses_batch:
                fout.write(hypothesis + '\n')
                fout.flush()
            slines = []

        slines.append(sline.strip())
        count += 1
    if slines != []:
        hypotheses_batch = bart.sample(slines, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)
        for hypothesis in hypotheses_batch:
            fout.write(hypothesis + '\n')
            fout.flush()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='tuhinjubcse' date='2020-03-31T18:38:21Z'>
		This is with a pre-trained model or a fine-tuned model? I wasn't able to reproduce with a pre-trained model. Details below:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

$ cat test.source
hello
my
name
is
erip
$ cat test.py
import torch

bart = torch.hub.load('pytorch/fairseq', 'bart.large.cnn')

bart.eval()

count = 1
bsz = 32
with open('test.source') as source, open('test.hypo2', 'w') as fout: # changed from 'test.hypo' to 'test.hypo2' between runs
    sline = source.readline().strip()
    slines = [sline]
    for sline in source:
        if count % bsz == 0:
            with torch.no_grad():
                hypotheses_batch = bart.sample(slines, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)

            for hypothesis in hypotheses_batch:
                fout.write(hypothesis + '\n')
                fout.flush()
            slines = []

        slines.append(sline.strip())
        count += 1
    if slines != []:
        hypotheses_batch = bart.sample(slines, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)
        for hypothesis in hypotheses_batch:
            fout.write(hypothesis + '\n')
            fout.flush()
$ diff test.hypo test.hypo2 | wc -l
       0
		</comment>
		<comment id='7' author='tuhinjubcse' date='2020-03-31T19:38:37Z'>
		fine-tuned model
Also, why do you have one-word sentences  ??
		</comment>
		<comment id='8' author='tuhinjubcse' date='2020-03-31T19:43:08Z'>
		Shouldn't matter from a reproducibility standpoint. I just created some junk data.
		</comment>
		<comment id='9' author='tuhinjubcse' date='2020-03-31T19:51:19Z'>
		How are you reproducing ?
I see you do not use sampling but beam reproduce with my code ?
		</comment>
		<comment id='10' author='tuhinjubcse' date='2020-03-31T20:02:38Z'>
		Fix your random seed at the beginning of your script:
import torch
import numpy as np

bart = torch.hub.load('pytorch/fairseq', 'bart.large.cnn')

bart.eval()

torch.manual_seed(0)
np.random.seed(0)


count = 1
bsz = 32
with open('test.source') as source, open('test.hypo2', 'w') as fout:
    sline = source.readline().strip()
    slines = [sline]
    for sline in source:
        if count % bsz == 0:
            with torch.no_grad():
                hypotheses_batch = bart.sample(slines, sampling=True, beam=4, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)

            for hypothesis in hypotheses_batch:
                fout.write(hypothesis + '\n')
                fout.flush()
            slines = []

        slines.append(sline.strip())
        count += 1
    if slines != []:
        hypotheses_batch = bart.sample(slines, beam=4, sampling=True, lenpen=2.0, max_len_b=140, min_len=55, no_repeat_ngram_size=3)
        for hypothesis in hypotheses_batch:
            fout.write(hypothesis + '\n')
            fout.flush()
		</comment>
		<comment id='11' author='tuhinjubcse' date='2020-03-31T21:04:36Z'>
		Resolved thanks
		</comment>
	</comments>
</bug>