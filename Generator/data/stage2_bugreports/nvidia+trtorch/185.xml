<bug id='185' author='zhanjw' open_date='2020-09-15T19:07:02Z' closed_time='2020-11-13T21:21:08Z'>
	<summary>üêõ [Bug]  (Found IValue containing object of type int @ at::sum) Encountered bug when using TRTorch</summary>
	<description>
&lt;denchmark-h:h2&gt;Bug Description&lt;/denchmark-h&gt;

Pytorch
&lt;denchmark-code&gt;        x_float = x.float()
        x_mul = x_float.mul(x_float)
        print("x_mul.shape",x_mul.shape)
        norm = x_mul.sum(1, keepdim=True)
        norm = norm.sqrt()
        norm = norm.add(self.eps)
&lt;/denchmark-code&gt;

Output:
x_mul.shape torch.Size([1, 512, 160, 100])
Compiling:
‚Ä¶‚Ä¶
DEBUG: [TRTorch - Debug Build] - Output tensor shape: [1, 256, 1, 1]
DEBUG: [TRTorch Conversion Context] - Evaluating %x_mul.1 : Tensor = aten::mul(%133, %133) # /run/media/eric/DATA/industrial/mmdetection/mmdet/models/backbones/ssd_vgg.py:173:0
DEBUG: [TRTorch Conversion Context] - Found the value to be: 36
INFO: [TRTorch Conversion Context] - Adding Layer %norm.1 : Tensor = aten::sum(%x_mul.1, %135, %7, %134) # /run/media/eric/DATA/industrial/mmdetection/mmdet/models/backbones/ssd_vgg.py:175:0 (ctx.AddLayer)
DEBUG: [TRTorch Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [TRTorch Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [TRTorch Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [TRTorch Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [TRTorch Conversion Context] - Found IValue containing object of type int
terminate called after throwing an instance of 'trtorch::Error'
what():  [enforce fail at core/conversion/var/Var.cpp:94] Expected isITensor() || (isIValue() &amp;&amp; ptr_.ivalue-&gt;isTensor()) to be true but got false
Requested either IValue containing a Tensor, or ITensor, however Var type is c10::IValue
Found IValue containing object of type int?
But my output[0] is a torch::tensor, how can I solve this problem?
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Relevant code
&lt;denchmark-code&gt;        self.l2_norm = L2Norm(
            self.features[out_feature_indices[0] - 1].out_channels,
            l2_norm_scale)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;outs[0] = self.l2_norm(outs[0])
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;class L2Norm(nn.Module):

    def __init__(self, n_dims, scale=20., eps=1e-10):
        """L2 normalization layer.

        Args:
            n_dims (int): Number of dimensions to be normalized
            scale (float, optional): Defaults to 20..
            eps (float, optional): Used to avoid division by zero.
                Defaults to 1e-10.
        """
        super(L2Norm, self).__init__()
        self.n_dims = n_dims
        self.weight = nn.Parameter(torch.Tensor(self.n_dims))
        self.eps = eps
        self.scale = scale

    def forward(self, x):
        """Forward function."""
        # normalization layer convert to FP32 in FP16 training
        x_float = x.float()
        norm = torch.sum(x_float*x_float, 1, keepdim=True).sqrt() + self.eps
        # norm = x_float.pow(2).sum(1, keepdim=True).sqrt() + self.eps

        # x_float = x.float()
        # x_mul = x_float.mul(x_float)
        # print("x_mul.shape",x_mul.shape)
        # norm = x_mul.sum(1, keepdim=True)
        # norm = norm.sqrt()
        # norm = norm.add(self.eps)

        return (self.weight[None, :, None, None].float().expand_as(x_float) *
                x_float / norm).type_as(x)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

Complete the compilation
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


Build information about the TRTorch compiler can be found by turning on debug messages


PyTorch Version (e.g., 1.0): 1.5.1
CPU Architecture: x86
OS (e.g., Linux): Linux(arch)
How you installed PyTorch (conda, pip, libtorch, source): conda
Build command you used (if compiling from source): bazel build //:libtrtorch --compilation_mode dbg --config=pre_cxx11_abi --distdir third_party/dist_dir/x86_64-linux-gnu --verbose_failures
Are you using local sources or building from archives: building from archives
Python version: 3.7.3
CUDA version: 10.2
GPU models and configuration: 1050Ti
Any other relevant information:

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='zhanjw' date='2020-10-16T00:06:33Z'>
		This issue has not seen activity for 30 days, Remove stale label or comment or this will be closed in 5 days
		</comment>
		<comment id='2' author='zhanjw' date='2020-11-01T21:53:31Z'>
		I'm unable to reproduce this issue. Infact, I see a different error. The graph that I used to generate the jit file is
&lt;denchmark-code&gt;x_float = x.float()
x_mul = x_float.mul(x_float)
norm = x_mul.sum(1, keepdim=True)
norm = norm.sqrt()
norm = norm.add(self.eps)
&lt;/denchmark-code&gt;

The graph looks like
&lt;denchmark-code&gt;graph(%self.1 : __torch__.L2Norm,
      %x.1 : Tensor):
  %12 : None = prim::Constant() # :0:0
  %11 : bool = prim::Constant[value=1]() # bug.py:38:36
  %3 : bool = prim::Constant[value=0]() # :0:0
  %9 : int = prim::Constant[value=1]() # bug.py:38:25
  %x_float.1 : Tensor = aten::_cast_Float(%x.1, %3) # bug.py:36:18
  %x_mul.1 : Tensor = aten::mul(%x_float.1, %x_float.1) # bug.py:37:16
  %10 : int[] = prim::ListConstruct(%9)
  %norm.1 : Tensor = aten::sum(%x_mul.1, %10, %11, %12) # bug.py:38:15
  %norm0.1 : Tensor = aten::sqrt(%norm.1) # bug.py:39:15
  %18 : float = prim::GetAttr[name="eps"](%self.1)
  %19 : Tensor = aten::add(%norm0.1, %18, %9) # bug.py:40:15
  return (%19)
&lt;/denchmark-code&gt;

The error that I see is due to a lack of converter.
&lt;denchmark-code&gt;ERROR: [TRTorch - Debug Build] - Method requested cannot be compiled by TRTorch.
Unsupported operators listed below:
  -  aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; (Tensor)
&lt;/denchmark-code&gt;


Did you implement this converter yourself ?
Can you share your jit graph ? You can paste the output of torch.jit.load('JIT_FILE').graph to reproduce the error.

		</comment>
		<comment id='3' author='zhanjw' date='2020-11-02T16:45:30Z'>
		&lt;denchmark-code&gt;    norm = torch.sum(x_float*x_float, 1, keepdim=True).sqrt() + self.eps
    # norm = x_float.pow(2).sum(1, keepdim=True).sqrt() + self.eps
&lt;/denchmark-code&gt;

-&gt;
(Found IValue containing object of type int @ at::sum)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;    x_float = x.float()
    x_mul = x_float.mul(x_float)
    norm = x_mul.sum(1, keepdim=True)
    norm = norm.sqrt()
    norm = norm.add(self.eps)
&lt;/denchmark-code&gt;

-&gt;
Unsupported operators listed below:
  -  aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; (Tensor)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

model torchscript file:
&lt;denchmark-link:https://drive.google.com/file/d/1jYRgr7ALEfCjhJbpW-d0Fsmu7eB82osJ/view?usp=sharing&gt;https://drive.google.com/file/d/1jYRgr7ALEfCjhJbpW-d0Fsmu7eB82osJ/view?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='zhanjw' date='2020-11-11T05:04:24Z'>
		In torch 1.6 and 1.7, I see the unsupported error with both graph variants you mentioned above
&lt;denchmark-code&gt;Unsupported operators listed below:
- aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; (Tensor)
&lt;/denchmark-code&gt;

I've raised a PR which fixes this issue &lt;denchmark-link:url&gt;https://github.com/NVIDIA/TRTorch/pull/221&lt;/denchmark-link&gt;
. I've verified both variants of your graph in Torch 1.6 and 1.7 and they work fine now.
We have moved from torch 1.5. But I think the JIT graph with   might work with torch 1.5 (not verified). Let me know if this resolves your issue.
		</comment>
	</comments>
</bug>