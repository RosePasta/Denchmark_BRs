<bug id='5' author='sliedes' open_date='2017-06-21T14:13:35Z' closed_time='2017-06-24T16:41:10Z'>
	<summary>nan loss when training</summary>
	<description>
Training and validation loss is nan (using commit &lt;denchmark-link:https://github.com/jadore801120/attention-is-all-you-need-pytorch/commit/e21800a65bca079d243debfbb30c6c1738870e32&gt;e21800a&lt;/denchmark-link&gt;
):
&lt;denchmark-code&gt;$ python3 preprocess.py -train_src data/multi30k/train.en -train_tgt data/multi30k/train.de -valid_src data/multi30k/val.en -valid_tgt data/multi30k/val.de -output data/multi30k/data.pt
$ python3 train.py -data data/multi30k/data.pt -save_model trained -save_model best
[ Epoch 0 ]
  - (Training)   loss:      nan, accuracy: 3.7 %
  - (Validation) loss:      nan, accuracy: 10.0 %
    - [Info] The checkpoint file has been updated.
[ Epoch 1 ]
  - (Training)   loss:      nan, accuracy: 9.09 %
  - (Validation) loss:      nan, accuracy: 9.87 %
[ Epoch 2 ]
  - (Training)   loss:      nan, accuracy: 9.09 %
  - (Validation) loss:      nan, accuracy: 9.83 %
[ Epoch 3 ]
  - (Training)   loss:      nan, accuracy: 9.1 %
  - (Validation) loss:      nan, accuracy: 9.92 %
[ Epoch 4 ]
  - (Training)   loss:      nan, accuracy: 9.09 %
  - (Validation) loss:      nan, accuracy: 9.91 %
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='sliedes' date='2017-06-22T13:55:57Z'>
		Hi &lt;denchmark-link:https://github.com/sliedes&gt;@sliedes&lt;/denchmark-link&gt;
 ,
Thanks for report. I am also facing the same problem.
Once I fix it, I will update the info here.
Any further inspection about it will be appreciated!
		</comment>
		<comment id='2' author='sliedes' date='2017-06-22T20:57:42Z'>
		While I understand neither the code or the theory fully yet, I think the problem is in ScaledDotProductAttention.forward(). It sets the masked values to -Inf before passing them to nn.SoftMax. I think nn.SoftMax does not deal well with -Inf. Indeed, while I got nan loss most of the time already during the first epoch, when I modify ScaledDotProductAttention.forward() to set the masked values to -100.0 instead of -Inf, I have now trained for five epochs without seeing nans.
		</comment>
		<comment id='3' author='sliedes' date='2017-06-24T16:37:58Z'>
		Hi &lt;denchmark-link:https://github.com/sliedes&gt;@sliedes&lt;/denchmark-link&gt;
 ,
Sorry for the late update!
You are right. The wrong part is about the softmax function, but it is not because of the -Inf value.
I misplace the k/q pair in the attention mask calculation routine. (see &lt;denchmark-link:https://github.com/jadore801120/attention-is-all-you-need-pytorch/commit/94aae682ff0224d167796f2d697ce7f39f2a4dde&gt;94aae68&lt;/denchmark-link&gt;
)
Please pull the newest commit to fix this bug. Thanks you!
		</comment>
		<comment id='4' author='sliedes' date='2017-06-24T16:41:01Z'>
		I think this fix will eliminate the NaN error, and I am sorry for the confusion so far.
Let me close this issue now.
However, if there emerges other fatal NaN error, feel free to open another issue.
		</comment>
		<comment id='5' author='sliedes' date='2019-11-15T22:34:13Z'>
		Hi, it seems that the problem still exist when using the solution above.
		</comment>
	</comments>
</bug>