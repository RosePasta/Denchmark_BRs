<bug id='75' author='keerthanvasist' open_date='2020-05-25T17:10:21Z' closed_time='2020-06-05T21:01:36Z'>
	<summary>Multi-GPU training fails with CUDA illegal memory access for some examples</summary>
	<description>
When running training examples in multi-GPU, I came across CUDA illegal memory access for examples with LSTM operators
&lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;        at ai.djl.examples.training.TrainSeq2Seq.runExample(TrainSeq2Seq.java:107)
        at ai.djl.examples.training.TrainSeq2Seq.main(TrainSeq2Seq.java:64)
        Suppressed: java.lang.IllegalArgumentException: Metric name not found: step
                at ai.djl.metric.Metrics.percentile(Metrics.java:135)
                at ai.djl.training.listener.LoggingTrainingListener.onTrainingEnd(LoggingTrainingListener.java:167)
                at ai.djl.training.Trainer.lambda$close$5(Trainer.java:348)
                at java.util.ArrayList.forEach(ArrayList.java:1257)
                at ai.djl.training.Trainer.close(Trainer.java:348)
                at ai.djl.examples.training.TrainSeq2Seq.runExample(TrainSeq2Seq.java:119)
                ... 1 more
        Suppressed: ai.djl.engine.EngineException: MXNet engine call failed: cuDNN: Check failed: e == CUDNN_STATUS_SUCCESS (4 vs. 0) : CUDNN_STATUS_INTERNAL_ERROR
Stack trace:
  File "src/operator/./rnn-inl.h", line 768

                at ai.djl.mxnet.jna.JnaUtils.checkCall(JnaUtils.java:1788)
                at ai.djl.mxnet.jna.JnaUtils.waitAll(JnaUtils.java:466)
                at ai.djl.mxnet.engine.MxModel.close(MxModel.java:161)
                at ai.djl.examples.training.TrainSeq2Seq.runExample(TrainSeq2Seq.java:122)
                ... 1 more
[18:23:19] src/resource.cc:230: Ignore CUDA Error [18:23:19] /codebuild/output/src546137840/src/git-codecommit.us-west-2.amazonaws.com/v1/repos/AWS-MXNet/3rdparty/mshadow/mshadow/./tensor_gpu-inl.h:73: Check failed: e == cudaSuccess: CUDA: an illegal memory access was encountered


[18:23:19] src/resource.cc:279: Ignore CUDA Error [18:23:19] src/storage/./pooled_storage_manager.h:97: CUDA: an illegal memory access was encountered


[18:23:19] src/resource.cc:279: Ignore CUDA Error [18:23:19] src/storage/./pooled_storage_manager.h:97: CUDA: an illegal memory access was encountered


[18:23:19] src/engine/threaded_engine_perdevice.cc:275: Ignore CUDA Error [18:23:19] /codebuild/output/src546137840/src/git-codecommit.us-west-2.amazonaws.com/v1/repos/AWS-MXNet/3rdparty/mshadow/mshadow/./stream_gpu-inl.h:203: Check failed: e == cudaSuccess: CUDA: an illegal memory access was encountered
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;How to Reproduce?&lt;/denchmark-h&gt;

We can reproduce by running the TrainSeq2Seq example on a machine with more than 1 GPU.
&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;

(Paste the commands you ran that produced the error.)

./gradlew :examples:run -Dmain=ai.djl.examples.training.TrainSeq2Seq

	</description>
	<comments>
		<comment id='1' author='keerthanvasist' date='2020-05-30T18:46:02Z'>
		It seems the root cause is related to NDManager.create(..., Device dev) APIs, In many places (e.g. MXNDArrayEx), the temporary NDArray is created like: array.getNDManager.create(data), it doesn't explicitly passing device to the function, it will inherit from NDManager rather then the array. In multi GPU cause, NDArray operation across difference device will cause exception.
A proper fix would be, make sure NDArray and it's NDManager's device always in sync.
		</comment>
		<comment id='2' author='keerthanvasist' date='2020-06-05T21:01:36Z'>
		I verified the crash no longer shows up. closed the issue. &lt;denchmark-link:https://github.com/awslabs/djl/commit/f1270989a2631905b2a3325c882a3dc83b43dbb3&gt;f127098&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>