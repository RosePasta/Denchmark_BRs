<bug id='84' author='chenkelmann' open_date='2020-06-08T13:09:51Z' closed_time='2021-01-15T22:10:01Z'>
	<summary>Multiple GPUs are used sequentially, not parallel</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

When using more than one GPU for training, the GPUs are used one after the other, not both at the same time.
&lt;denchmark-h:h3&gt;Expected Behavior&lt;/denchmark-h&gt;

Both GPUs work under full capacity the whole time.
&lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h2&gt;How to Reproduce?&lt;/denchmark-h&gt;

If a model is very memory intensive, it needs to clean up used memory, e.g. after processing a transformer layer. The way to do this is to create a sub manager to collect the intermediate results and close them once the calculations are done. However, due to the lazy nature of the mxnet engine (and probably other engines), calculations are not guaranteed to finish by the time NDArray.close() is called. To prevent crashes and memory curruption it is hence necessary to block on the resulting NDArray with LazyNDArray.waitToRead(). As this will also block the current Java Thread, processing is halted until the GPU had time to "catch up". That in turn prevents the for-loop in the Trainer to send the split batch to the next GPU.
To test this, simply add one waitToRead call at the end of a stack of layers.
&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;

see above
&lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;

This can only be solved by fixing the training loop in Trainer.java l.157. The split batches are send to the individual GPUs with a for-loop. This only works if every call in the model is non-blocking. I.e. it requires an engine only using LazyNDArrays and requires the whole model never to call waitToRead or waitAll. The correct way to allow Multi-GPU usage would be no use something like a ThreadPool here to issue the forward pass to each GPU in parallel. The for-loop needs to start a new Thread for each iteration and wait for all threads to finish before continuing to the backwards pass.
&lt;denchmark-h:h2&gt;Environment Info&lt;/denchmark-h&gt;

N/A
	</description>
	<comments>
		<comment id='1' author='chenkelmann' date='2020-06-17T16:35:35Z'>
		The class ParallelTrain in PR &lt;denchmark-link:https://github.com/awslabs/djl/pull/105&gt;#105&lt;/denchmark-link&gt;
 contains a sketch on how to fix this issue.
		</comment>
	</comments>
</bug>