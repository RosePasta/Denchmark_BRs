<bug id='468' author='RXY3832' open_date='2019-11-20T15:21:07Z' closed_time='2019-11-21T02:57:00Z'>
	<summary>Error when Predicting with use_feat_dynamic_real</summary>
	<description>
When I train a model with use_feat_dynamic_real=True and provide it with values in the following format: [[[1, 2, 3, 4], [5, 6, 7]]] Where each record gets an array of dynamic features and each dynamic feature corresponding with each target item, I get the following error:
&lt;denchmark-code&gt;ValueError: all the input array dimensions except for the concatenation axis must match exactly
&lt;/denchmark-code&gt;

Here's is an example of the 1st row of training data:
&lt;denchmark-code&gt;{'target': array([1783., 1978., 1484., ..., 2001., 2632., 3002.], dtype=float32), 'start': Timestamp('2016-01-01 00:00:00', freq='D'), 'feat_static_cat': array([1999], dtype=int32), 'feat_dynamic_real': array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'source': SourceContext(source='list_data', row=1)}
&lt;/denchmark-code&gt;

The training data and test data are the same, with the exception that the test data has prediction_length removed (28 days) from the target and feat_static_cat fields of each row in the the test data.
	</description>
	<comments>
		<comment id='1' author='RXY3832' date='2019-11-20T15:24:02Z'>
		Hi &lt;denchmark-link:https://github.com/RXY3832&gt;@RXY3832&lt;/denchmark-link&gt;
,
do you get that error at train or test time? Can you post a minimal example that produces the issue?
Also, feat_static_cat fields should not be removed during prediction. Also the test data still needs to have the feat_dynamic_real values for the complete forecast horizon.
		</comment>
		<comment id='2' author='RXY3832' date='2019-11-20T16:45:45Z'>
		It happens at testing time.
I don't remove feat_static_cat for predictions (sorry that was a typo) and I do keep feat_dynamic_real values for the complete forecast horizon when creating the test data, but remove the prediction days when creating the training data.
Below is me creating the training and test data:
&lt;denchmark-code&gt;train_ds = ListDataset([{FieldName.TARGET: target, 
                             FieldName.START: start,
                             FieldName.FEAT_STATIC_CAT: fsc,
                             FieldName.FEAT_DYNAMIC_REAL: fdr} 
                            for (target, start, fsc, fdr) in zip(mask_prediction_length(target, prediction_length, 'target'), 
                                                                 start_dates,
                                                                 feat_static_cat,
                                                                 mask_prediction_length(feat_dynamic_real, prediction_length, 'feat_dynamic_real'))],
                          freq='1D')

    test_ds = ListDataset([{FieldName.TARGET: target, 
                             FieldName.START: start,
                             FieldName.FEAT_STATIC_CAT: fsc,
                             FieldName.FEAT_DYNAMIC_REAL: fdr} 
                            for (target, start, fsc, fdr) in zip(target, 
                                                                 start_dates, 
                                                                 feat_static_cat,
                                                                 feat_dynamic_real)],
                          freq='1D')
&lt;/denchmark-code&gt;

The mask_prediction_length remove the number of prediction steps for both target and feature dynamic category. See the code below:
&lt;denchmark-code&gt;def mask_prediction_length(l, prediction_length, feature_type='target'):
    new_l = []
    if  feature_type=='target':
        for i in l:
            new_l.append(i[:-prediction_length])
    else:
        for i in l[0]:
            new_l.append([i[:-prediction_length]])
                
    return new_l
&lt;/denchmark-code&gt;

Then run the prediction on test data set:
&lt;denchmark-code&gt;    #Get mean predictions and generate graph
    prediction = next(predictor.predict(test_ds))
    print(prediction.mean)
    prediction.plot(output_file='graph_{0}.png'.format(target_predictor))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='RXY3832' date='2019-11-20T16:58:07Z'>
		I think the issue is that when you run on the test in the way above, the predict method would expect that your target has some length n and the dynamic features n + prediction length.
You are currently trying to forecast starting with the last time point in your test, while you actually want to look at the forecast of target[:-prediction_length].
Can you try applying the mask to the target in the test data and check whether that solves the issue?
		</comment>
		<comment id='4' author='RXY3832' date='2019-11-20T17:12:13Z'>
		Ok. By doing that I was able to move on. However, when I then run the make_evaluation_predictions (see below code) I get a similar error. The full error is below too.
&lt;denchmark-code&gt;  forecast_it, ts_it = make_evaluation_predictions(
   dataset=test_ds,  # test dataset
   predictor=predictor,  # predictor
   num_samples=100,  # number of sample paths we want for evaluation
   )
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-41-08ae464d226e&gt; in &lt;module&gt;()
      3 
      4     predictor = joblib.load("predictor_{}.joblib".format(target_predictor))
----&gt; 5     agg_metrics, item_metrics, df, wmapes = get_performance_information(target_predictor, predictor)
      6 
      7     mean_wmape = np.array(wmapes).mean()

&lt;ipython-input-40-f63835941782&gt; in get_performance_information(target_predictor, predictor)
    158     )
    159 
--&gt; 160     forecasts = list(forecast_it)
    161     tss = list(ts_it)
    162 

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/model/predictor.py in predict(self, dataset, num_samples)
    307             freq=self.freq,
    308             output_transform=self.output_transform,
--&gt; 309             num_samples=num_samples,
    310         )
    311 

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/model/forecast_generator.py in __call__(self, inference_data_loader, prediction_net, input_names, freq, output_transform, num_samples, **kwargs)
    193         **kwargs
    194     ) -&gt; Iterator[Forecast]:
--&gt; 195         for batch in inference_data_loader:
    196             inputs = [batch[k] for k in input_names]
    197             outputs = prediction_net(*inputs).asnumpy()

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/dataset/loader.py in __iter__(self)
    229     def __iter__(self) -&gt; Iterator[DataBatch]:
    230         buffer = BatchBuffer(self.batch_size, self.ctx, self.dtype)
--&gt; 231         for data_entry in self.transform(iter(self.dataset), is_train=False):
    232             buffer.add(data_entry)
    233             if len(buffer) &gt;= self.batch_size:

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/transform.py in __call__(self, data_it, is_train)
    322     ) -&gt; Iterator:
    323         num_idle_transforms = 0
--&gt; 324         for data_entry in data_it:
    325             num_idle_transforms += 1
    326             try:

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/transform.py in __call__(self, data_it, is_train)
    277                 yield self.map_transform(data_entry.copy(), is_train)
    278             except Exception as e:
--&gt; 279                 raise e
    280 
    281     @abc.abstractmethod

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/transform.py in __call__(self, data_it, is_train)
    275         for data_entry in data_it:
    276             try:
--&gt; 277                 yield self.map_transform(data_entry.copy(), is_train)
    278             except Exception as e:
    279                 raise e

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/transform.py in map_transform(self, data, is_train)
    290 
    291     def map_transform(self, data: DataEntry, is_train: bool) -&gt; DataEntry:
--&gt; 292         return self.transform(data)
    293 
    294     @abc.abstractmethod

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/transform.py in transform(self, data)
    524             if data[fname] is not None
    525         ]
--&gt; 526         output = np.vstack(r)
    527         data[self.output_field] = output
    528         for fname in self.cols_to_drop:

~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/numpy/core/shape_base.py in vstack(tup)
    232 
    233     """
--&gt; 234     return _nx.concatenate([atleast_2d(_m) for _m in tup], 0)
    235 
    236 def hstack(tup):

ValueError: all the input array dimensions except for the concatenation axis must match exactly
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='RXY3832' date='2019-11-20T17:20:03Z'>
		Cool!
make_evaluation_predictions slices and dices the data for you (it basically does the same as your masking code). In removing the last prediction_length from target, you will end up with target[:-prediction_length *2]. make_evaluation_predictions should take the original test dataset (without removing prediction_length).
		</comment>
		<comment id='6' author='RXY3832' date='2019-11-20T23:06:32Z'>
		Got it! Ok cool. I got it worked out now. Thank you for your help!
		</comment>
	</comments>
</bug>