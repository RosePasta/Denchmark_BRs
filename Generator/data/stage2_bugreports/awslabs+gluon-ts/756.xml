<bug id='756' author='lostella' open_date='2020-04-15T16:11:24Z' closed_time='2020-04-17T13:58:56Z'>
	<summary>Training fails with num_workers=1</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Training fails when num_workers is set to 1
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

import numpy as np

from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator
from gluonts.dataset.common import ListDataset
from gluonts.trainer import Trainer

dataset = ListDataset(
    data_iter=[{
        "target": np.random.normal(loc=100, scale=10, size=(10000)),
        "start": "2020-01-01 00:00:00",
    }],
    freq="5min",
)

estimator = SimpleFeedForwardEstimator(
    freq="5min",
    prediction_length=4,
    context_length=100,
    trainer = Trainer(
        epochs=2, num_batches_per_epoch=3, batch_size=16, hybridize=False
    ),
)

predictor = estimator.train(
    dataset,
    num_workers=1
)
&lt;denchmark-h:h2&gt;Error message or code output&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/spawn.py", line 114, in _main
    prepare(preparation_data)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/spawn.py", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/spawn.py", line 277, in _fixup_main_from_path
    run_name="__mp_main__")
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/runpy.py", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/runpy.py", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/Users/stellalo/gluon-ts/issues/issue_frozen.py", line 26, in &lt;module&gt;
    num_workers=1
  File "/Users/stellalo/gluon-ts/src/gluonts/model/estimator.py", line 240, in train
    training_data, validation_data, num_workers, num_prefetch, **kwargs
  File "/Users/stellalo/gluon-ts/src/gluonts/model/estimator.py", line 194, in train_model
    **kwargs,
  File "/Users/stellalo/gluon-ts/src/gluonts/dataset/loader.py", line 165, in __init__
    **kwargs,
  File "/Users/stellalo/gluon-ts/src/gluonts/dataset/loader.py", line 96, in __init__
    **kwargs,
  File "/Users/stellalo/gluon-ts/src/gluonts/dataset/parallelized_loader.py", line 538, in __init__
    self.worker_id_queue,
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/context.py", line 119, in Pool
    context=self.get_context())
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/pool.py", line 174, in __init__
    self._repopulate_pool()
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/pool.py", line 239, in _repopulate_pool
    w.start()
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/context.py", line 284, in _Popen
    return Popen(process_obj)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/popen_spawn_posix.py", line 42, in _launch
    prep_data = spawn.get_preparation_data(process_obj._name)
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/spawn.py", line 143, in get_preparation_data
    _check_not_importing_main()
  File "/Users/stellalo/.pyenv/versions/3.6.6/lib/python3.6/multiprocessing/spawn.py", line 136, in _check_not_importing_main
    is not going to be frozen to produce an executable.''')
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


Operating system: macOS 10.14.6
Python version: 3.6.6
GluonTS version: 928283d

(Add as much information about your environment as possible, e.g. dependencies versions.)
	</description>
	<comments>
		<comment id='1' author='lostella' date='2020-04-16T08:26:14Z'>
		I cannot reproduce this error, not in the latest version of GluonTS, neither in the version you provided.
But I think nonetheless this issue could be fixed by &lt;denchmark-link:https://github.com/awslabs/gluon-ts/pull/742&gt;#742&lt;/denchmark-link&gt;
 since there we are switching to the default child creation method of .
Other than that, It could be an issue in the dependencies of your environment.
		</comment>
		<comment id='2' author='lostella' date='2020-04-16T08:54:11Z'>
		
I cannot reproduce this error, not in the latest version of GluonTS, neither in the version you provided.
But I think nonetheless this issue could be fixed by #742 since there we are switching to the default child creation method of Pool.
Other than that, It could be an issue in the dependencies of your environment.

Yes, thanks for looking into it. I‚Äôll try again in a fresh environment and let you know üëç
		</comment>
		<comment id='3' author='lostella' date='2020-04-16T08:54:23Z'>
		I think it might be that you need to add the following in your python file (as described by the error message and as discussed here: &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/5858&gt;pytorch/pytorch#5858&lt;/denchmark-link&gt;
):
&lt;denchmark-code&gt;def run():
    multiprocessing.freeze_support()

if __name__ == '__main__':
    run()
&lt;/denchmark-code&gt;

Can you confirm?
		</comment>
		<comment id='4' author='lostella' date='2020-04-16T10:28:22Z'>
		
Can you confirm?

Yes, that fixes it. So what should we do here? Is this a problem?
Edit: maybe let's wait until &lt;denchmark-link:https://github.com/awslabs/gluon-ts/pull/742&gt;#742&lt;/denchmark-link&gt;
 is merged
		</comment>
		<comment id='5' author='lostella' date='2020-04-16T10:45:14Z'>
		

Can you confirm?

Yes, that fixes it. So what should we do here? Is this a problem?
Edit: maybe let's wait until #742 is merged

Yeah, I think &lt;denchmark-link:https://github.com/awslabs/gluon-ts/pull/742&gt;#742&lt;/denchmark-link&gt;
 should be merged first.
Also, something is fishy about this fix:
&lt;denchmark-code&gt;multiprocessing.freeze_support()
Add support for when a program which uses multiprocessing has been frozen to produce a Windows executable. (Has been tested with py2exe, PyInstaller and cx_Freeze.)

One needs to call this function straight after the if __name__ == '__main__' line of the main module. For example:

from multiprocessing import Process, freeze_support

def f():
    print('hello world!')

if __name__ == '__main__':
    freeze_support()
    Process(target=f).start()
If the freeze_support() line is omitted then trying to run the frozen executable will raise RuntimeError.

Calling freeze_support() has no effect when invoked on any operating system other than Windows. In addition, if the module is being run normally by the Python interpreter on Windows (the program has not been frozen), then freeze_support() has no effect.
&lt;/denchmark-code&gt;

It clearly states: "Calling freeze_support() has no effect when invoked on any operating system other than Windows."
		</comment>
		<comment id='6' author='lostella' date='2020-04-17T13:56:57Z'>
		We could add this in parallelized_loader.py, which we probably should rename  multiprocessing?loader (since its not multithreading anymore). At some point we cloud merge loader.py into it too.
&lt;denchmark-code&gt;if __name__ == '__main__':
    multiprocessing.freeze_support()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='lostella' date='2020-04-17T13:58:55Z'>
		&lt;denchmark-link:https://github.com/awslabs/gluon-ts/pull/766&gt;#766&lt;/denchmark-link&gt;
 appears to have solved it
		</comment>
	</comments>
</bug>