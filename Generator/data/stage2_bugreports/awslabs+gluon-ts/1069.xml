<bug id='1069' author='lostella' open_date='2020-10-01T16:08:46Z' closed_time='2020-10-03T13:18:45Z'>
	<summary>MQCNNEstimator behaves strangely results when constructed with distr_output</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

I'm getting NaN loss, or inconsistent shapes in the forecast object, when training a MQCNNEstimator with the distr_output option instead of quantiles.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

(Please provide minimal example of code snippet that reproduces the error. For existing examples, please provide link.)
from gluonts.dataset.repository.datasets import get_dataset
from gluonts.distribution import StudentTOutput
from gluonts.model.seq2seq import MQCNNEstimator
from gluonts.trainer import Trainer

dataset = get_dataset("m4_hourly")
estimator = MQCNNEstimator(freq="H", prediction_length=1, distr_output=StudentTOutput(), trainer=Trainer(epochs=1, learning_rate=1e-4))
predictor = estimator.train(dataset.train)

for forecast in predictor.predict(dataset.test):
    print(forecast.distribution)
    break
&lt;denchmark-h:h2&gt;Error message or code output&lt;/denchmark-h&gt;

Often times the above results in NaN loss at the first training iteration (this often happens when putting e.g. prediction_length=24, if not always). Otherwise I get the following prediction
&lt;denchmark-code&gt;gluonts.mx.distribution.transformed_distribution.TransformedDistribution(base_distribution=gluonts.mx.distribution.student_t.StudentT(F=None, mu=mxnet.nd.array([52.238128662109375], dtype=numpy.float32), nu=mxnet.nd.array([2.0], dtype=numpy.float32), sigma=mxnet.nd.array([302.1168518066406], dtype=numpy.float32)), transforms=[gluonts.mx.distribution.bijection.AffineTransformation(loc=mxnet.nd.array([[0.0]], dtype=numpy.float32), scale=mxnet.nd.array([[1.0]], dtype=numpy.float32))])
&lt;/denchmark-code&gt;

Note that the loc and scale of the AffineTransformation have one additional axis which shouldn't be there. (They should have the same shape as mu, nu, sigma.)
	</description>
	<comments>
		<comment id='1' author='lostella' date='2020-10-01T18:49:37Z'>
		The occurrence of nans is probably due to scaling being disabled by default; the shape issue is likely due to the scaler being initialized with keepdims=True
		</comment>
	</comments>
</bug>