<bug id='1056' author='elenaehrlich' open_date='2020-09-28T13:09:22Z' closed_time='2020-09-30T07:34:09Z'>
	<summary>NaN handling of distributions' log_prob() for samples outside distribution's support</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

MixtureDistribution with components [Gaussian(..), Gamma(..)]) returns a NaN instead a real-value log-prob for x&lt;=0 (see MWE-1). MixtureDistributionOutput with components [GaussianOutput(..), GammaOutput(..)]) results in a NaN gradient for x&lt;=0 (see MWE-2).
&lt;denchmark-h:h2&gt;MWE-1&lt;/denchmark-h&gt;

import mxnet as mx
from scipy import stats
from gluonts.mx.distribution.mixture import *
from gluonts.mx.distribution.gaussian import *
from gluonts.mx.distribution.gamma import *

p = 0.5
mu, sigma = 0., 2.
alpha, beta = 0.9, 2.

# The log-prob of x=-1 should return a real-value and not NaN
x = -1.

scipy_logprob = np.log(p * stats.norm(mu, sigma).pdf(x) + (1-p) * stats.gamma(alpha, 1./beta).pdf(x))
print('scipy_logprob', scipy_logprob)

gaussian = Gaussian(mx.nd.array([mu]), mx.nd.array([sigma]))
gamma = Gamma(mx.nd.array([alpha]), mx.nd.array([beta]))
mixed_dist = MixtureDistribution(mx.nd.array([p,1-p]), [gaussian, gamma])
gluonts_logprob = mixed_dist.log_prob(mx.nd.array([x]))
print('gluonts_logprob', gluonts_logprob.asscalar())

assert np.abs(scipy_logprob-gluonts_logprob.asscalar())&lt;1e-6
&lt;denchmark-h:h2&gt;Error message or code output&lt;/denchmark-h&gt;

AssertionError
&lt;denchmark-h:h2&gt;MWE-2&lt;/denchmark-h&gt;

import mxnet as mx, numpy as np
from gluonts.gluonts_tqdm import tqdm
from gluonts.model.common import Tensor
from gluonts.mx.distribution.mixture import *
from gluonts.mx.distribution.mixture import *
from gluonts.mx.distribution.gaussian import *
from gluonts.mx.distribution.gamma import *


def fit_mixture_distribution(x: Tensor, mdo: MixtureDistributionOutput, variate_dimensionality: int = 1, epochs: Optional[int]=1_000):

    args_proj = mdo.get_args_proj()
    args_proj.initialize()
    args_proj.hybridize()

    input = mx.nd.ones((variate_dimensionality, 1))


    trainer = mx.gluon.Trainer(
        args_proj.collect_params(), "sgd", {"learning_rate": 0.02}
    )
    print('trainer.learning_rate',trainer.learning_rate)

    t = tqdm(list(range(epochs)))
    for _ in t:
        with mx.autograd.record():
            distr_args = args_proj(input)
            d = mdo.distribution(distr_args)
            loss = d.loss(x).mean()
        loss.backward()
        loss_value = loss.asnumpy()
        t.set_postfix({"loss": loss_value})
        trainer.step(1)

    distr_args = args_proj(input)
    d = mdo.distribution(distr_args)
    return d

fit_mixture = fit_mixture_distribution(mx.nd.array([x]), MixtureDistributionOutput([GaussianOutput(), GammaOutput()]), 1, epochs=3)

for ci, c in enumerate(fit_mixture.components):
    for ai, a in enumerate(c.args):
        assert ~np.isnan(a.asnumpy()), \
            f"NaN gradients led to {c}"
&lt;denchmark-h:h2&gt;Error message or code output&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;AssertionError: NaN gradients led to gluonts.mx.distribution.gamma.Gamma(alpha=mxnet.nd.array([float("{x}")], dtype=numpy.float32), beta=mxnet.nd.array([float("{x}")], dtype=numpy.float32))
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


Operating system: MacOS 10.14.6
Python version: Python 3.8.5
GluonTS version: 0.5.1.dev102+g88a9832.d20200924
MXNet version: 1.6.0

	</description>
	<comments>
		<comment id='1' author='elenaehrlich' date='2020-09-29T18:58:20Z'>
		&lt;denchmark-link:https://github.com/elenaehrlich&gt;@elenaehrlich&lt;/denchmark-link&gt;
 solved?
		</comment>
		<comment id='2' author='elenaehrlich' date='2020-09-30T07:34:09Z'>
		&lt;denchmark-link:https://github.com/lostella&gt;@lostella&lt;/denchmark-link&gt;
 many thanks
		</comment>
	</comments>
</bug>