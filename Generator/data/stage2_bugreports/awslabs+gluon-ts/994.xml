<bug id='994' author='skybullet1987' open_date='2020-08-20T00:31:34Z' closed_time='2020-09-04T14:41:58Z'>
	<summary>NBEATS doesn't work properly</summary>
	<description>
NBEATS doesn't work with parameters that I described here:
&lt;denchmark-link:https://github.com/awslabs/gluon-ts/issues/988&gt;#988&lt;/denchmark-link&gt;

I have tried to use other estimators such as DeepARE - it works fine. Only NBEATS is causing issues.
System Windows 10
GluonTS 0.5.1
MXnet 1.6
Python 3.7.7
	</description>
	<comments>
		<comment id='1' author='skybullet1987' date='2020-08-29T12:31:27Z'>
		Hey &lt;denchmark-link:https://github.com/skybullet1987&gt;@skybullet1987&lt;/denchmark-link&gt;
 ,
thank you for the bug report.
Could you please provide a minimal example code that reproduces the bug?
I do not experience issues using your hyperparameters like this:
&lt;denchmark-code&gt;import mxnet as mx
from gluonts.dataset.common import ListDataset
from gluonts.model.n_beats import NBEATSEstimator

dataset = ListDataset(
    [{"start": "2020-01-01", "target": list(range(50))}],
    freq="1D"
)
estimator = NBEATSEstimator(freq="D", prediction_length=1, context_length = 5,trainer=Trainer(epochs=10,ctx="gpu"))
predictor = estimator.train(training_data=dataset)

predictor.predict(dataset)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='skybullet1987' date='2020-09-01T04:31:44Z'>
		Hi!
Code example:
&lt;denchmark-code&gt;test_data = ListDataset([{"start": df.index[0], 
                              "target": df.Close[:prediction_date]}], 
                            freq="D")

    estimator1 = NBEATSEstimator(freq="D", prediction_length=1, trainer=Trainer(epochs=120,ctx="gpu"))
    predictor1 = estimator1.train(training_data=test_data)
&lt;/denchmark-code&gt;

Let's suppose I do a 1 day prediction (Sep 1) based on all the data that I have (Aug 31 and earlier).
prediction_date = Sep 1
My dataset structure is:
Jan 1  100
Jan 2  80
...
Aug 31 105
Sep 1 NaN
The error that I am getting:
&lt;denchmark-h:h2&gt;Epoch[0] gave nan loss
16%|█▌        | 8/50 [00:01&lt;00:08,  5.09it/s, epoch=1/120, avg_epoch_loss=557]&lt;/denchmark-h&gt;

GluonTSUserError                          Traceback (most recent call last)
 in 
117
118     estimator1 = NBEATSEstimator(freq="D", prediction_length=1, trainer=Trainer(epochs=120,ctx="gpu"))
--&gt; 119     predictor1 = estimator1.train(training_data=test_data)
120
121     predictions = list(predictor1.predict(test_data))
C:\Anaconda3\lib\site-packages\gluonts\model\estimator.py in train(self, training_data, validation_data, num_workers, num_prefetch, shuffle_buffer_length, **kwargs)
269             num_prefetch,
270             shuffle_buffer_length,
--&gt; 271             **kwargs,
272         ).predictor
C:\Anaconda3\lib\site-packages\gluonts\model\estimator.py in train_model(self, training_data, validation_data, num_workers, num_prefetch, shuffle_buffer_length, **kwargs)
242             input_names=get_hybrid_forward_input_names(trained_net),
243             train_iter=training_data_loader,
--&gt; 244             validation_iter=validation_data_loader,
245         )
246
C:\Anaconda3\lib\site-packages\gluonts\mx\trainer_base.py in call(self, net, input_names, train_iter, validation_iter)
372                         if best_epoch_info["epoch_no"] == -1:
373                             raise GluonTSUserError(
--&gt; 374                                 "Got NaN in first epoch. Try reducing initial learning rate."
375                             )
376
GluonTSUserError: Got NaN in first epoch. Try reducing initial learning rate.
If I use same parameters (same dataset), but DeepAREstimator - everything works.
Sometimes, it gets through several epochs:
100%|██████████| 50/50 [00:03&lt;00:00, 12.93it/s, epoch=1/120, avg_epoch_loss=79.7]
100%|██████████| 50/50 [00:02&lt;00:00, 17.68it/s, epoch=2/120, avg_epoch_loss=2.44]
100%|██████████| 50/50 [00:02&lt;00:00, 17.67it/s, epoch=3/120, avg_epoch_loss=2.13]
0%|          | 0/50 [00:00&lt;?, ?it/s]Epoch[3] gave nan loss
2%|▏         | 1/50 [00:00&lt;00:05,  8.29it/s, epoch=4/120, avg_epoch_loss=1.65]
0%|          | 0/50 [00:00&lt;?, ?it/s]Epoch[4] gave nan loss
2%|▏         | 1/50 [00:00&lt;00:05,  8.72it/s, epoch=5/120, avg_epoch_loss=0.974]
0%|          | 0/50 [00:00&lt;?, ?it/s]Epoch[5] gave nan loss
2%|▏         | 1/50 [00:00&lt;00:05,  8.57it/s, epoch=6/120, avg_epoch_loss=1.69]
0%|          | 0/50 [00:00&lt;?, ?it/s]Epoch[6] gave nan loss
2%|▏         | 1/50 [00:00&lt;00:05,  8.22it/s, epoch=7/120, avg_epoch_loss=1.47]
0%|          | 0/50 [00:00&lt;?, ?it/s]Epoch[7] gave nan loss
2%|▏         | 1/50 [00:00&lt;00:05,  8.43it/s, epoch=8/120, avg_epoch_loss=1.46]
0%|          | 0/50 [00:00&lt;?, ?it/s]Epoch[8] gave nan loss
2%|▏         | 1/50 [00:00&lt;00:06,  8.09it/s, epoch=9/120, avg_epoch_loss=1.25]
WARNING:gluonts.dataset.parallelized_loader:You have set num_workers to a non zero value, however, currently multiprocessing is not supported on windows and therefore`num_workers will be set to 0.
		</comment>
		<comment id='3' author='skybullet1987' date='2020-09-01T14:42:17Z'>
		Thank you.

Are you sure there are no NaN target values in the training data? The DeepAR transformations handle missing values, but NBEATS does not do this by default. If there are any, you can replace them yourself as a quick fix.
If there are no missing values, can you try to reduce the learning rate, by adjusting learning_rate parameter of the Trainer?

		</comment>
		<comment id='4' author='skybullet1987' date='2020-09-01T15:01:07Z'>
		Thank you for clarifications.
1)Could you pleas tell - if my dataset doesn't have a specific target value (for e.g. sales for tomorrow, and I don't know what they are, but I want to predict them with NBEATS), what should I use instead of NaN for that 1 day into the future prediction that I described?
If I use existing data point (for e.g. Aug 31 with some sales value) and use Aug 31 as prediction_date (all same code as above) - I can see that NBEATS produces very accurate results (very close to Aug 31).
2)The only missing value is the target value (which I don't know, because that is exactly what I am trying to predict). What learning rate parameter should I try?
I am just trying to use NBEATS to produce a 1 day prediction into the future.
		</comment>
		<comment id='5' author='skybullet1987' date='2020-09-02T09:39:21Z'>
		If you want to predict a specific date of a time series, this time point should not be in the training dataset. Create a training and a test dataset. For the test dataset, you have to provide the context for your prediction (note the context_length parameter, which defaults to 2*prediction_length for the NBEATSEstimator)
Here is a toy example on how to do a one day prediction:
from gluonts.dataset.common import ListDataset
import pandas as pd
import numpy as np
from gluonts.model.n_beats import NBEATSEstimator
from gluonts.mx.trainer import Trainer
from datetime import timedelta
start = pd.Timestamp("01-01-2019", freq='D')
end = pd.Timestamp("01-01-2019", freq='D') + timedelta(days=100)
timerange = pd.date_range(start=start, end=end, freq="D")
target = np.append(np.random.randn(99), np.nan)

training_data = ListDataset([{"start": start,
                              "target": target[:-1]}],
                            freq="D")

estimator = NBEATSEstimator(freq="D", context_length=2, prediction_length=1, trainer=Trainer(epochs=10, ctx="cpu"))
predictor = estimator.train(training_data=training_data)

test_data = ListDataset([{"start": timerange[-3],
                              "target": target[-3:-1]}],
                            freq="D")
s = predictor.predict(test_data)
sf = next(s)
print(sf)
		</comment>
		<comment id='6' author='skybullet1987' date='2020-09-03T13:06:25Z'>
		Awesome!
Checked on my dataset - it works just as intended! Thank you!
		</comment>
		<comment id='7' author='skybullet1987' date='2020-09-04T08:24:25Z'>
		Great! Could you please close the issue?
		</comment>
	</comments>
</bug>