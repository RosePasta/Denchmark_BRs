<bug id='1222' author='hero78119' open_date='2019-07-14T16:26:47Z' closed_time='2019-07-29T16:27:56Z'>
	<summary>horovod spark toy example got hang on CDH 5.14.0 cluster</summary>
	<description>
Environment:

Framework: (TensorFlow, Keras, PyTorch, MXNet): Tensorflow
Framework version:1.13.1
Horovod version: 0.16.4
MPI version: 4.0.1
CUDA version: N/A
NCCL version: N/A
Python version: 2.7.12
OS and version: ubuntu 16.04
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0

Hi,
I try to run horovod spark toy example (follow &lt;denchmark-link:https://github.com/horovod/horovod/blob/master/docs/spark.rst&gt;https://github.com/horovod/horovod/blob/master/docs/spark.rst&lt;/denchmark-link&gt;
) on an existing yarn cluster to experiment CPUs trainings but unfortunately not work on my side. (with 1 driver and 2 executors, 2 executor got allocated on same host with different port, CDH 5.14.0, spark version 2.2.0)
Below is the error I got on spark driver
&lt;denchmark-code&gt;Exception happened during processing of request from ('127.0.0.1', 44334)
Traceback (most recent call last):
  File "/usr/lib/python2.7/SocketServer.py", line 596, in process_request_thread
    self.finish_request(request, client_address)
  File "/usr/lib/python2.7/SocketServer.py", line 331, in finish_request
    self.RequestHandlerClass(request, client_address, self)
  File "/usr/lib/python2.7/SocketServer.py", line 652, in __init__
    self.handle()
  File "/data23/yarn/nm/usercache/ld-wusm/appcache/application_1547982120377_497782/container_1547982120377_497782_01_000001/Python/lib/python2.7/site-packages/horovod/run/common/util/network.py", line 117, in handle
    resp = server._handle(req, self.client_address)
  File "/data23/yarn/nm/usercache/ld-wusm/appcache/application_1547982120377_497782/container_1547982120377_497782_01_000001/Python/lib/python2.7/site-packages/horovod/spark/driver/driver_service.py", line 77, in _handle
    return TaskHostHashIndicesResponse(self._task_host_hash_indices[req.host_hash])
KeyError: 'yarn-node-1'
&lt;/denchmark-code&gt;

I try to add debug log to print _task_host_hash_indices
&lt;denchmark-code&gt;{'yarn-node-1.mydomain.com-3f1b8d32ce24bc926c4f2c7726cd9d81': [0, 1]}
&lt;/denchmark-code&gt;

So apparently yarn-node-1 not a valid key, seems hostname got trim toyarn-node-1.
After reading related issue and I manually applied &lt;denchmark-link:https://github.com/horovod/horovod/pull/1201&gt;#1201&lt;/denchmark-link&gt;
 fix (cause it haven't bump to horovod 0.16.5), the spark job then just got hang. After changing verbose level, on spark  I notice the mpirun command looks like below
&lt;denchmark-code&gt;+ mpirun --allow-run-as-root --tag-output -np 2 -H yarn-node-1-eb5f156d4c844f36de9cfc251398d421:2 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca btl_tcp_if_include lo,bond0.1148 -x NCCL_DEBUG=INFO -x NCCL_SOCKET_IFNAME=lo,bond0.1148 -x CMF_PACKAGE_DIR -x CM_STATUS_CODES -x CGROUP_ROOT_CPUACCT -x SHELL -x CDH_VERSION -x CDH_SQOOP2_HOME -x KEYTRUSTEE_SERVER_HOME -x YARN_RESOURCEMANAGER_OPTS -x JSVC_HOME -x SUPERVISOR_ENABLED -x CLOUDERA_POSTGRESQL_JDBC_JAR -x CGROUP_GROUP_CPUACCT -x JAVA_HOME -x YARN_ROOT_LOGGER -x IS_KERBERIZED -x CDH_ZOOKEEPER_HOME -x XDG_RUNTIME_DIR -x CONF_DIR -x PYTHONPATH -x CLOUDERA_MYSQL_CONNECTOR_JAR -x HADOOP_CONF_DIR -x XDG_SESSION_ID -x MAX_APP_ATTEMPTS -x CGROUP_ROOT_BLKIO -x CDH_HTTPFS_HOME -x WEBHCAT_DEFAULT_XML -x CDH_KAFKA_HOME -x SCM_DEFINES_SCRIPTS -x PARCELS_ROOT -x PYSPARK_PYTHON -x HADOOP_HOME_WARN_SUPPRESS -x CDH_PARQUET_HOME -x CMF_CONF_DIR -x MGMT_HOME -x SPARK_USER -x NM_LOCAL_DIRS -x NM_HTTP_PORT -x SUPERVISOR_GROUP_NAME -x CDH_HDFS_HOME -x PYTHONUNBUFFERED -x CDH_HUE_PLUGINS_HOME -x CLOUDERA_ORACLE_CONNECTOR_JAR -x LANGUAGE -x HADOOP_PREFIX -x SHLVL -x CDH_MR2_HOME -x HADOOP_YARN_HOME -x PYSPARK_DRIVER_PYTHON -x CDH_KMS_HOME -x CDH_HBASE_HOME -x _HOROVOD_SECRET_KEY -x NM_PORT -x SPARK_YARN_MODE -x JVM_PID -x CGROUP_ROOT_MEMORY -x LOCAL_DIRS -x CLASSPATH -x LOG_DIRS -x SUPERVISOR_PROCESS_NAME -x YARN_LOGFILE -x APPLICATION_WEB_PROXY_BASE -x MAIL -x NM_AUX_SERVICE_spark_shuffle -x HADOOP_HDFS_HOME -x _ -x YARN_CONF_DIR -x CDH_LLAMA_HOME -x CDH_HIVE_HOME -x CDH_SENTRY_HOME -x CDH_SPARK_HOME -x CDH_SOLR_HOME -x HADOOP_JOB_HISTORYSERVER_OPTS -x YARN_NODEMANAGER_OPTS -x CDH_MR1_HOME -x _SYSTEMCTL_SKIP_REDIRECT -x CGROUP_GROUP_CPU -x HOME -x HADOOP_CLIENT_CONF_DIR -x LD_LIBRARY_PATH -x LANG -x KEYTRUSTEE_KP_HOME -x HADOOP_COMMON_HOME -x HIVE_DEFAULT_XML -x PYTHONHASHSEED -x CDH_IMPALA_HOME -x CDH_SQOOP_HOME -x HADOOP_TOKEN_FILE_LOCATION -x HADOOP_MAPRED_HOME -x CGROUP_GROUP_BLKIO -x CDH_AVRO_HOME -x SPARK_YARN_STAGING_DIR -x CDH_CRUNCH_HOME -x CDH_HADOOP_HOME -x CONTAINER_ID -x YARN_LOG_DIR -x SPARK_DIST_CLASSPATH -x USER -x HADOOP_CLASSPATH -x CDH_HADOOP_BIN -x CGROUP_ROOT_CPU -x LOGNAME -x APP_SUBMIT_TIME_ENV -x PATH -x PARCEL_DIRNAMES -x CDH_KUDU_HOME -x CDH_YARN_HOME -x PYSPARK_GATEWAY_PORT -x MALLOC_ARENA_MAX -x CDH_HCAT_HOME -x CDH_OOZIE_HOME -x CDH_HUE_HOME -x CGROUP_GROUP_MEMORY -x SUPERVISOR_SERVER_URL -x HADOOP_LIBEXEC_DIR -x CDH_PIG_HOME -x NM_AUX_SERVICE_mapreduce_shuffle -x YARN_OPTS -x SEARCH_HOME -x ORACLE_HOME -x NM_HOST -x PWD -x CDH_HBASE_INDEXER_HOME -x TOMCAT_HOME -x CDH_FLUME_HOME -mca plm_rsh_agent "/usr/bin/python -m horovod.spark.driver.mpirun_rsh {base64 encode message} {base64}" /usr/bin/python -m horovod.spark.task.mpirun_exec_fn {base64 encode message} {base64}
&lt;/denchmark-code&gt;

where the hostname yarn-node-1-eb5f156d4c844f36de9cfc251398d421 is executors hostname.
and spark job got hang forever without error, and NO print('Hello, rank = %d, local_rank = %d, size = %d, local_size = %d, magic_number = %d' % (hvd.rank(), hvd.local_rank(), hvd.size(), hvd.local_size(), magic_number)) output, seems it stuck at hvd.init()
After inserting some debug log on mpirun_rsh.py and mpirun_exec_fn.pymanually, I notice that mpirun  only invoked mpirun_rsh.py on driver node itself, and none of executors get invoked.
My question is,


how mpirun recognize hostname after apply #1201 ? because https://github.com/horovod/horovod/blob/master/horovod/spark/__init__.py#L200 still use host_hash as hostname and mpirun do not specify hostfile.


Does this hang related to openmpi 4.0.1 ?


Do I miss other un-release changes other than #1201 ?


any parameters I should add to show more debug log ?


Thanks!
	</description>
	<comments>
		<comment id='1' author='hero78119' date='2019-07-19T20:07:38Z'>
		&lt;denchmark-link:https://github.com/hero78119&gt;@hero78119&lt;/denchmark-link&gt;
, thanks for debugging this issue!
I believe &lt;denchmark-link:https://github.com/horovod/horovod/pull/1201&gt;#1201&lt;/denchmark-link&gt;
 is helping in your case, precisely because of dots in the hostname.
Can you add debug messages in mpirun_rsh.py to see if it ends up executing task_client.run_command(command, os.environ), or whether it fails beforehand?
Also, can you share the output of ps auxww on the server, filtering out any sensitive info?
Lastly, can you share the output of ifconfig -a?
		</comment>
		<comment id='2' author='hero78119' date='2019-07-20T15:47:53Z'>
		Hi &lt;denchmark-link:https://github.com/alsrgv&gt;@alsrgv&lt;/denchmark-link&gt;

Thanks for your kindly reply :)
After insert more debug message, task_client.run_command(command, os.environ) has invoked below command on executor (hostname: yarn-node-22.mydomain.com)
&lt;denchmark-code&gt;orted -mca ess "env" -mca ess_base_jobid "4149477376" -mca ess_base_vpid 1 -mca ess_base_num_procs "2" -mca orte_node_regex "yarn-node-[3:151],yarn-node-[2:22]-7a0bb581d1a7a0fd97f3f8088e59384d@0(2)" -mca orte_hnp_uri "4149477376.0;tcp://10.65.249.87:55871" -mca pml "ob1" -mca btl "^openib" -mca btl_tcp_if_include "lo,bond0.1148" -mca plm "rsh" --tree-spawn -mca orte_parent_uri "4149477376.0;tcp://10.65.249.87:55871" -mca plm_rsh_agent "python -m horovod.spark.driver.mpirun_rsh &lt;base64 message&gt; &lt;base64 message&gt;" -mca orte_tag_output "1" -mca hwloc_base_binding_policy "none" -mca rmaps_base_mapping_policy "slot" -mca pmix "^s1,s2,cray,isolated"
&lt;/denchmark-code&gt;

And it just hang on this command, later I append --debug flag to above command, on executer console it show below message
&lt;denchmark-code&gt;[yarn-node-22.mydomain.com:44526] procdir: /tmp/ompi.yarn-node-22.990/jf.63316/0/1
[yarn-node-22.mydomain.com:44526] jobdir: /tmp/ompi.yarn-node-22.990/jf.63316/0
[yarn-node-22.mydomain.com:44526] top: /tmp/ompi.yarn-node-22.990/jf.63316
[yarn-node-22.mydomain.com:44526] top: /tmp/ompi.yarn-node-22.990
[yarn-node-22.mydomain.com:44526] tmp: /tmp
[yarn-node-22.mydomain.com:44526] sess_dir_cleanup: job session dir does not exist
[yarn-node-22.mydomain.com:44526] sess_dir_cleanup: top session dir does not exist
[yarn-node-22.mydomain.com:44526] procdir: /tmp/ompi.yarn-node-22.990/jf.63316/0/1
[yarn-node-22.mydomain.com:44526] jobdir: /tmp/ompi.yarn-node-22.990/jf.63316/0
[yarn-node-22.mydomain.com:44526] top: /tmp/ompi.yarn-node-22.990/jf.63316
[yarn-node-22.mydomain.com:44526] top: /tmp/ompi.yarn-node-22.990
[yarn-node-22.mydomain.com:44526] tmp: /tmp
&lt;/denchmark-code&gt;

without other errors but still hang. I have add some debug message on mpirun_rsh so pretty assure mpirun_rsh not invoked on this executor.
Beside, on same executor it stuck at
&lt;denchmark-link:https://github.com/horovod/horovod/blob/master/horovod/run/common/service/task_service.py#L148-L155&gt;https://github.com/horovod/horovod/blob/master/horovod/run/common/service/task_service.py#L148-L155&lt;/denchmark-link&gt;

and I guess the root cause is because  the  command hang so the while loop never break.
For ifconfig -a output
&lt;denchmark-code&gt;bond0     Link encap:Ethernet  HWaddr 88:86:03:3d:b4:c5  
          inet6 addr: fe80::8a86:3ff:fe3d:b4c5/64 Scope:Link
          UP BROADCAST RUNNING MASTER MULTICAST  MTU:1500  Metric:1
          RX packets:146272250955 errors:2 dropped:0 overruns:0 frame:2
          TX packets:129802856589 errors:0 dropped:19 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:189145884527315 (189.1 TB)  TX bytes:176206105532218 (176.2 TB)

bond0.1148 Link encap:Ethernet  HWaddr 88:86:03:3d:b4:c5  
          inet addr:10.65.249.82  Bcast:10.65.249.127  Mask:255.255.255.192
          inet6 addr: fe80::8a86:3ff:fe3d:b4c5/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:30783542241 errors:0 dropped:0 overruns:0 frame:0
          TX packets:20981776481 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:181718771420353 (181.7 TB)  TX bytes:169481461308758 (169.4 TB)

eno1      Link encap:Ethernet  HWaddr 88:86:03:3d:b4:c5  
          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1
          RX packets:72900822689 errors:2 dropped:0 overruns:0 frame:2
          TX packets:65019355926 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:94611710461618 (94.6 TB)  TX bytes:88293949256632 (88.2 TB)

eno2      Link encap:Ethernet  HWaddr 88:86:03:3d:b4:c5  
          UP BROADCAST RUNNING SLAVE MULTICAST  MTU:1500  Metric:1
          RX packets:73371428266 errors:0 dropped:0 overruns:0 frame:0
          TX packets:64783500663 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:94541463411773 (94.5 TB)  TX bytes:87912156275586 (87.9 TB)

eno3      Link encap:Ethernet  HWaddr 88:86:03:3d:b4:c6  
          BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)

eno4      Link encap:Ethernet  HWaddr 88:86:03:3d:b4:c7  
          BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:5081650281 errors:0 dropped:0 overruns:0 frame:0
          TX packets:5081650281 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:112515762649654 (112.5 TB)  TX bytes:112515762649654 (112.5 TB)
&lt;/denchmark-code&gt;

and ps result
&lt;denchmark-code&gt;yarn     25624  0.0  0.0   4568   844 ?        S    23:37   0:00 /bin/sh -c orted -mca ess "env" -mca ess_base_jobid "4149477376" -mca ess_base_vpid 1 -mca ess_base_num_procs "2" -mca orte_node_regex "yarn-node-[3:151],yarn-node-[2:22]-7a0bb581d1a7a0fd97f3f8088e59384d@0(2)" -mca orte_hnp_uri "4149477376.0;tcp://10.65.249.87:55871" -mca pml "ob1" -mca btl "^openib" -mca btl_tcp_if_include "lo,bond0.1148" -mca plm "rsh" --tree-spawn -mca orte_parent_uri "4149477376.0;tcp://10.65.249.87:55871" -mca plm_rsh_agent "python -m horovod.spark.driver.mpirun_rsh &lt;base64 message&gt; &lt;base64 message&gt;" -mca orte_tag_output "1" -mca hwloc_base_binding_policy "none" -mca rmaps_base_mapping_policy "slot" -mca pmix "^s1,s2,cray,isolated" --debug
yarn     25627  0.0  0.0 186760  8468 ?        Sl   23:37   0:00 orted -mca ess "env" -mca ess_base_jobid "4149477376" -mca ess_base_vpid 1 -mca ess_base_num_procs "2" -mca orte_node_regex "yarn-node-[3:151],yarn-node-[2:22]-7a0bb581d1a7a0fd97f3f8088e59384d@0(2)" -mca orte_hnp_uri "4149477376.0;tcp://10.65.249.87:55871" -mca pml "ob1" -mca btl "^openib" -mca btl_tcp_if_include "lo,bond0.1148" -mca plm "rsh" --tree-spawn -mca orte_parent_uri "4149477376.0;tcp://10.65.249.87:55871" -mca plm_rsh_agent "python -m horovod.spark.driver.mpirun_rsh &lt;base64 message&gt; &lt;base64 message&gt;" -mca orte_tag_output "1" -mca hwloc_base_binding_policy "none" -mca rmaps_base_mapping_policy "slot" -mca pmix "^s1,s2,cray,isolated" --debug
yarn     25654  8.6  0.0 5872344 235660 ?      Sl   23:37   0:25 python -m horovod.spark.task.mpirun_exec_fn &lt;base64 message&gt; &lt;base64 message&gt;
yarn     25655  9.5  0.0 5872792 235692 ?      Sl   23:37   0:27 python -m horovod.spark.task.mpirun_exec_fn &lt;base64 message&gt; &lt;base64 message&gt;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='hero78119' date='2019-07-21T14:17:12Z'>
		Hi &lt;denchmark-link:https://github.com/alsrgv&gt;@alsrgv&lt;/denchmark-link&gt;

Also, here is my toy example.
&lt;denchmark-code&gt;def fn(magic_number):
    import horovod.tensorflow as hvd
    hvd.init()
    print("done init")
    return

horovod.spark.run(fn, args=(42,), verbose=4)
&lt;/denchmark-code&gt;

If comment out hvd.init() then the whole job successfully finished.
Any suggestion to go further from that ?
		</comment>
		<comment id='4' author='hero78119' date='2019-07-29T16:27:56Z'>
		I used gdb to debug and finally find the root cause.
It's because in our system there are two openmpi versions (one is 1.xx which is quite old, the other is 4.0.1) co-exist.
Even already set the runtime PATH/LD_LIBRARY_PATH, the horovod c library still refer to old libmpi.so.
The key-point to note is, when install horovod, environment variable OPAL_PREFIX should be assigned to openmpi home once it install on some custom path. So pip installation command should be
&lt;denchmark-code&gt;OPAL_PREFIX=&lt;path to custom openmpi directory&gt; pip install horovod --upgrade --no-cache-dir
&lt;/denchmark-code&gt;

After that, everything got to work, thanks!
		</comment>
	</comments>
</bug>