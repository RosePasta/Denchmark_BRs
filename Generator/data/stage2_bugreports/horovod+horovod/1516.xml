<bug id='1516' author='vilmara' open_date='2019-11-15T17:33:55Z' closed_time='2019-11-15T19:01:33Z'>
	<summary>mca_btl_tcp_endpoint_recv_connect_ack] received unexpected process identifier</summary>
	<description>
Environment:

Framework: (TensorFlow, Keras, PyTorch, MXNet): TensorFlow
Framework version: TensorFlow 1.14.0
Horovod version: horovod-0.18.2
MPI version: openmpi-4.0.0
CUDA version: 10.0
NCCL version: 2.4.7-1
Python version: 2.7
OS and version:  Ubunto18.04
GCC version: 4.8
Mellanox: MLNX_OFED_LINUX-4.7-1.0.0.1

Bug report:
Hi, I am running TensorFlow benchmarks in multi-node mode over InfiniBand with, running via Horovod docker with Mellanox support, and the master node hangs, see below:
Command-line to replicate:
mpirun -np 8 -H &lt;ib0 master node&gt;:4,&lt;ib0 second node&gt;:4 --allow-run-as-root -x NCCL_IB_DISABLE=0 -x NCCL_IB_CUDA_SUPPORT=1 -x NCCL_SOCKET_IFNAME=ib0 -x NCCL_DEBUG=INFO --bind-to none --map-by slot --mca plm_rsh_args "-p 50000" python tf_cnn_benchmarks.py --variable_update=horovod --model=resnet50 --batch_size=128
Error:
[second-node][[22157,1],4][btl_tcp_endpoint.c:626:mca_btl_tcp_endpoint_recv_connect_ack] received unexpected process identifier [[22157,1],7]
	</description>
	<comments>
		<comment id='1' author='vilmara' date='2019-11-15T19:01:33Z'>
		Fixed, I just added the flag specifying the interface to include ib0: -mca btl_tcp_if_include ib0. My command ended as:
mpirun -np 8 -H &lt;ib0 master node&gt;:4,&lt;ib0 second node&gt;:4 --allow-run-as-root -x NCCL_IB_DISABLE=0 -x NCCL_IB_CUDA_SUPPORT=1 -mca btl_tcp_if_include ib0 -x NCCL_SOCKET_IFNAME=ib0 -x NCCL_DEBUG=INFO --bind-to none --map-by slot --mca plm_rsh_args "-p 50000" python tf_cnn_benchmarks.py --variable_update=horovod --model=resnet50 --batch_size=128 
		</comment>
	</comments>
</bug>