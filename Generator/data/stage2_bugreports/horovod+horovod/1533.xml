<bug id='1533' author='eric-haibin-lin' open_date='2019-11-24T18:48:53Z' closed_time='2020-01-09T15:48:57Z'>
	<summary>mxnet crashes</summary>
	<description>
Environment:

Framework: (TensorFlow, Keras, PyTorch, MXNet): mxnet
Framework version: mxnet-cu100 20191123
Horovod version: 0.18.2
MPI version: 3.1.4
CUDA version: 10.0
NCCL version:
Python version: 3.7
OS and version: amazon linux
GCC version:

Checklist:

Did you search issues to find if somebody asked this question before?
If your question is about hang, did you read this doc?
If your question is about docker, did you read this doc?
Did you check if you question is answered in the troubleshooting guide?

Bug report:
&lt;denchmark-code&gt;(base) [ec2-user@ip-172-31-4-79 bert]$ mpirun -np 8 python -c "import mxnet as mx; import horovod.mxnet as hvd; hvd.init(); a = mx.nd.ones((1),ctx=mx.gpu(hvd.rank())); b = hvd.allreduce(a * 1, average=False); mx.nd.waitall(); import time; time.sleep(10); print(b)"

Segmentation fault: 11

Stack trace:
  [bt] (0) /home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3a14c70) [0x7f137e617c70]
  [bt] (1) /lib64/libc.so.6(+0x362f0) [0x7f145e91b2f0]
  [bt] (2) /lib64/libc.so.6(+0x156680) [0x7f145ea3b680]
  [bt] (3) /opt/amazon//openmpi/lib64/libopen-pal.so.40(+0x456b3) [0x7f1321a416b3]
  [bt] (4) /opt/amazon//openmpi/lib64/libmpi.so.40(ompi_coll_base_allreduce_intra_recursivedoubling+0x125) [0x7f1322050b85]
  [bt] (5) /opt/amazon//openmpi/lib64/libmpi.so.40(PMPI_Allreduce+0x14f) [0x7f13220111af]
  [bt] (6) /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(horovod::common::MPIAllreduce::Execute(std::vector&lt;horovod::common::TensorTableEntry, std::allocator&lt;horovod::common::TensorTableEntry&gt; &gt;&amp;, horovod::common::Response const&amp;)+0x1ad) [0x7f1309fb38dd]
  [bt] (7) /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(horovod::common::OperationManager::ExecuteAllreduce(std::vector&lt;horovod::common::TensorTableEntry, std::allocator&lt;horovod::common::TensorTableEntry&gt; &gt;&amp;, horovod::common::Response const&amp;) const+0x61) [0x7f1309f9a8f1]
  [bt] (8) /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(horovod::common::OperationManager::ExecuteOperation(std::vector&lt;horovod::common::TensorTableEntry, std::allocator&lt;horovod::common::TensorTableEntry&gt; &gt;&amp;, horovod::common::Response const&amp;) const+0x81) [0x7f1309f9acc1]
terminate called after throwing an instance of 'std::system_error'
  what():  Resource deadlock avoided
[ip-172-31-4-79:34873] *** Process received signal ***
[ip-172-31-4-79:34873] Signal: Aborted (6)
[ip-172-31-4-79:34873] Signal code:  (-6)
[ip-172-31-4-79:34873] [ 0] /lib64/libpthread.so.0(+0xf5e0)[0x7f145ecc15e0]
[ip-172-31-4-79:34873] [ 1] /lib64/libc.so.6(gsignal+0x37)[0x7f145e91b277]
[ip-172-31-4-79:34873] [ 2] /lib64/libc.so.6(abort+0x148)[0x7f145e91c968]
[ip-172-31-4-79:34873] [ 3] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xbc)[0x7f14547ba3df]
[ip-172-31-4-79:34873] [ 4] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(+0x9cb16)[0x7f14547b8b16]
[ip-172-31-4-79:34873] [ 5] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(+0x9bf91)[0x7f14547b7f91]
[ip-172-31-4-79:34873] [ 6] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(__gxx_personality_v0+0x33e)[0x7f14547b879d]
[ip-172-31-4-79:34873] [ 7] /home/ec2-user/anaconda3/bin/../lib/libgcc_s.so.1(+0xcf56)[0x7f14546edf56]
[ip-172-31-4-79:34873] [ 8] /home/ec2-user/anaconda3/bin/../lib/libgcc_s.so.1(_Unwind_RaiseException+0xe6)[0x7f14546ee244]
[ip-172-31-4-79:34873] [ 9] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(__cxa_throw+0x42)[0x7f14547b8d1b]
[ip-172-31-4-79:34873] [10] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(_ZSt20__throw_system_errori+0x73)[0x7f14547d43bd]
[ip-172-31-4-79:34873] [11] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(_ZNSt6thread4joinEv+0x25)[0x7f14547d4541]
[ip-172-31-4-79:34873] [12] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZN7horovod6common18HorovodGlobalStateD1Ev+0x548)[0x7f1309f86388]
[ip-172-31-4-79:34873] [13] /lib64/libc.so.6(+0x39bd9)[0x7f145e91ebd9]
[ip-172-31-4-79:34873] [14] /lib64/libc.so.6(+0x39c27)[0x7f145e91ec27]
[ip-172-31-4-79:34873] [15] /home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3a14ca8)[0x7f137e617ca8]
[ip-172-31-4-79:34873] [16] /lib64/libc.so.6(+0x362f0)[0x7f145e91b2f0]
[ip-172-31-4-79:34873] [17] /lib64/libc.so.6(+0x156680)[0x7f145ea3b680]
[ip-172-31-4-79:34873] [18] /opt/amazon//openmpi/lib64/libopen-pal.so.40(+0x456b3)[0x7f1321a416b3]
[ip-172-31-4-79:34873] [19] /opt/amazon//openmpi/lib64/libmpi.so.40(ompi_coll_base_allreduce_intra_recursivedoubling+0x125)[0x7f1322050b85]
[ip-172-31-4-79:34873] [20] /opt/amazon//openmpi/lib64/libmpi.so.40(PMPI_Allreduce+0x14f)[0x7f13220111af]
[ip-172-31-4-79:34873] [21] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZN7horovod6common12MPIAllreduce7ExecuteERSt6vectorINS0_16TensorTableEntryESaIS3_EERKNS0_8ResponseE+0x1ad)[0x7f1309fb38dd]
[ip-172-31-4-79:34873] [22] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZNK7horovod6common16OperationManager16ExecuteAllreduceERSt6vectorINS0_16TensorTableEntryESaIS3_EERKNS0_8ResponseE+0x61)[0x7f1309f9a8f1]
[ip-172-31-4-79:34873] [23] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(_ZNK7horovod6common16OperationManager16ExecuteOperationERSt6vectorINS0_16TensorTableEntryESaIS3_EERKNS0_8ResponseE+0x81)[0x7f1309f9acc1]
[ip-172-31-4-79:34873] [24] /home/ec2-user/.local/lib/python3.7/site-packages/horovod/mxnet/mpi_lib.cpython-37m-x86_64-linux-gnu.so(+0x595f2)[0x7f1309f805f2]
[ip-172-31-4-79:34873] [25] /home/ec2-user/anaconda3/bin/../lib/libstdc++.so.6(+0xb8678)[0x7f14547d4678]
[ip-172-31-4-79:34873] [26] /lib64/libpthread.so.0(+0x7de5)[0x7f145ecb9de5]
[ip-172-31-4-79:34873] [27] /lib64/libc.so.6(clone+0x6d)[0x7f145e9e2f1d]
[ip-172-31-4-79:34873] *** End of error message ***
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun noticed that process rank 3 with PID 0 on node ip-172-31-4-79 exited on signal 6 (Aborted).
--------------------------------------------------------------------------
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='eric-haibin-lin' date='2019-11-24T19:28:30Z'>
		after i add: hvd.shutdown()
&lt;denchmark-code&gt;(base) [ec2-user@ip-172-31-4-79 bert]$ mpirun -np 8 python -c "import mxnet as mx; import horovod.mxnet as hvd; hvd.init(); a = mx.nd.ones((1),ctx=mx.gpu(hvd.rank())); b = hvd.allreduce(a * 1, average=False); mx.nd.waitall(); import time; time.sleep(10); print(b); hvd.shutdown()"
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py", line 188, in waitall
    check_call(_LIB.MXNDArrayWaitAll())
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/base.py", line 254, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: array::at
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py", line 188, in waitall
    check_call(_LIB.MXNDArrayWaitAll())
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/base.py", line 254, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: array::at
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py", line 188, in waitall
    check_call(_LIB.MXNDArrayWaitAll())
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/base.py", line 254, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: array::at
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py", line 188, in waitall
    check_call(_LIB.MXNDArrayWaitAll())
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/base.py", line 254, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: array::at
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py", line 188, in waitall
    check_call(_LIB.MXNDArrayWaitAll())
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/base.py", line 254, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: array::at
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py", line 188, in waitall
    check_call(_LIB.MXNDArrayWaitAll())
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/base.py", line 254, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: array::at
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py", line 188, in waitall
    check_call(_LIB.MXNDArrayWaitAll())
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/base.py", line 254, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: array::at
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py", line 188, in waitall
    check_call(_LIB.MXNDArrayWaitAll())
  File "/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/base.py", line 254, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: array::at
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[6881,1],6]
  Exit code:    1
--------------------------------------------------------------------------
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='eric-haibin-lin' date='2019-11-25T19:17:22Z'>
		&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 So I just tried this out and the issue seems to be this line here . If I change the line to this , it seems to work without error.
Your first case without hvd.shutdown() shows that the program segfaults while attempting to perform the MPI_Allreduce, which suggests that in the case where an expression is passed to hvd.allreduce, the memory address for the tensor being passed into Horovod from MXNet is somehow invalid.
&lt;denchmark-link:https://github.com/apeforest&gt;@apeforest&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://github.com/yuxihu&gt;@yuxihu&lt;/denchmark-link&gt;
, any thoughts on this one?
		</comment>
		<comment id='3' author='eric-haibin-lin' date='2019-11-25T21:44:10Z'>
		I was trying to reproduce this error but it seems I didn't get core dump with &lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 command.
&lt;denchmark-code&gt;mpirun -np 8 -H localhost:8 python -c "import mxnet as mx; import horovod.mxnet as hvd; hvd.init(); a = mx.nd.ones((1),ctx=mx.gpu(hvd.rank())); b = hvd.allreduce(a * 1, average=False); mx.nd.waitall(); import time; time.sleep(10); print(b)"
&lt;/denchmark-code&gt;

It may be due to corrupted memory as &lt;denchmark-link:https://github.com/romerojosh&gt;@romerojosh&lt;/denchmark-link&gt;
 suggested. Looking into it now.
		</comment>
		<comment id='4' author='eric-haibin-lin' date='2019-11-25T23:49:25Z'>
		I also noticed that if I build Horovod without HOROVOD_ALL_REDUCE=NCCL, there is no error.
In that case, the tensor will be copied to CPU and allreduce is performed between CPUs before they are copied back to GPU memory.
		</comment>
		<comment id='5' author='eric-haibin-lin' date='2019-11-25T23:58:04Z'>
		The original error was generated with HOROVOD_GPU_ALLREDUCE=NCCL enabled right? Given that the original error shows that the problem segfaults during an MPI_Allreduce call, this would suggest that hvd.allreduce(a * 1, average=False) is actually using the path that assumes the tensor is on the CPU. Is the result of a*1 supposed to be a CPU tensor?
		</comment>
		<comment id='6' author='eric-haibin-lin' date='2019-11-29T18:32:47Z'>
		No, a*1 should yield a tensor on the same context as a's (mx.gpu(hvd.rank()))
		</comment>
		<comment id='7' author='eric-haibin-lin' date='2019-12-02T04:58:38Z'>
		I have same issue.
		</comment>
		<comment id='8' author='eric-haibin-lin' date='2020-01-03T22:09:41Z'>
		&lt;denchmark-link:https://github.com/apeforest&gt;@apeforest&lt;/denchmark-link&gt;
 is there any fix ?
		</comment>
		<comment id='9' author='eric-haibin-lin' date='2020-01-03T22:15:56Z'>
		Got preempted by other work. PR should be out next week.
		</comment>
	</comments>
</bug>