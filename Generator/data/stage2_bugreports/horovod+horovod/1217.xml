<bug id='1217' author='alsrgv' open_date='2019-07-13T01:32:52Z' closed_time='2019-07-22T23:14:25Z'>
	<summary>MXNet cu100-pre broke docker build on CPU machine</summary>
	<description>
Environment:

Framework: MXNet
Framework version: mxnet-cu100 --pre
Horovod version: master
MPI version: 3.0.0
CUDA version: 10.0
NCCL version: 2.4.7
Python version: 2.7
OS and version: Ubuntu 16.04
GCC version: 5.4.0

Checklist:

Did you search issues to find if somebody asked this question before?
If your question is about hang, did you read this doc?
If your question is about docker, did you read this doc?
Did you check if you question is answered in the troubleshooting guide?

Bug report:
Please describe errorneous behavior you're observing and steps to reproduce it.
&lt;denchmark-link:https://buildkite.com/horovod/horovod/builds/710#7d3ba97d-0126-4117-b04a-cae10bdc9767&gt;https://buildkite.com/horovod/horovod/builds/710#7d3ba97d-0126-4117-b04a-cae10bdc9767&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;/usr/bin/g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/horovod/common/common.o build/temp.linux-x86_64-2.7/horovod/common/fusion_buffer_manager.o build/temp.linux-x86_64-2.7/horovod/common/half.o build/temp.linux-x86_64-2.7/horovod/common/message.o build/temp.linux-x86_64-2.7/horovod/common/mpi_context.o build/temp.linux-x86_64-2.7/horovod/common/operations.o build/temp.linux-x86_64-2.7/horovod/common/parameter_manager.o build/temp.linux-x86_64-2.7/horovod/common/response_cache.o build/temp.linux-x86_64-2.7/horovod/common/timeline.o build/temp.linux-x86_64-2.7/horovod/common/ops/collective_operations.o build/temp.linux-x86_64-2.7/horovod/common/ops/mpi_operations.o build/temp.linux-x86_64-2.7/horovod/common/ops/operation_manager.o build/temp.linux-x86_64-2.7/horovod/common/optim/bayesian_optimization.o build/temp.linux-x86_64-2.7/horovod/common/optim/gaussian_process.o build/temp.linux-x86_64-2.7/horovod/common/logging.o build/temp.linux-x86_64-2.7/horovod/common/ops/cuda_operations.o build/temp.linux-x86_64-2.7/horovod/common/ops/mpi_cuda_operations.o build/temp.linux-x86_64-2.7/horovod/common/ops/nccl_operations.o build/temp.linux-x86_64-2.7/horovod/torch/mpi_ops_v2.o build/temp.linux-x86_64-2.7/horovod/torch/handle_manager.o build/temp.linux-x86_64-2.7/horovod/torch/ready_event.o build/temp.linux-x86_64-2.7/horovod/torch/cuda_util.o build/temp.linux-x86_64-2.7/horovod/torch/adapter_v2.o -L/usr/local/cuda/lib -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib64 -lcudart -lnccl_static -lcudart -o build/lib.linux-x86_64-2.7/horovod/torch/mpi_lib_v2.so -Wl,--version-script=horovod.lds -I/usr/local/include -pthread -Wl,-rpath -Wl,/usr/local/lib -Wl,--enable-new-dtags -L/usr/local/lib -lmpi
--
  | terminate called after throwing an instance of 'dmlc::Error'
  | what():  [01:22:52] include/mxnet/base.h:427: Check failed: e == cudaSuccess (35 vs. 0) :  CUDA: CUDA driver version is insufficient for CUDA runtime version
  | Stack trace:
  | [bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x4b1deb) [0x7f4b76b93deb]
  | [bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x253cc04) [0x7f4b78c1ec04]
  | [bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2725e1) [0x7f4b769545e1]
  | [bt] (3) /lib64/ld-linux-x86-64.so.2(+0x106ca) [0x7f4ce813f6ca]
  | [bt] (4) /lib64/ld-linux-x86-64.so.2(+0x107db) [0x7f4ce813f7db]
  | [bt] (5) /lib64/ld-linux-x86-64.so.2(+0x158f2) [0x7f4ce81448f2]
  | [bt] (6) /lib64/ld-linux-x86-64.so.2(+0x10574) [0x7f4ce813f574]
  | [bt] (7) /lib64/ld-linux-x86-64.so.2(+0x14db9) [0x7f4ce8143db9]
  | [bt] (8) /lib/x86_64-linux-gnu/libdl.so.2(+0xf09) [0x7f4ce7944f09]
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/apeforest&gt;@apeforest&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/yuxihu&gt;@yuxihu&lt;/denchmark-link&gt;
, could you take a look?
	</description>
	<comments>
		<comment id='1' author='alsrgv' date='2019-07-13T01:34:39Z'>
		cc &lt;denchmark-link:https://github.com/karakusc&gt;@karakusc&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='alsrgv' date='2019-07-17T21:46:21Z'>
		ping &lt;denchmark-link:https://github.com/apeforest&gt;@apeforest&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/yuxihu&gt;@yuxihu&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='alsrgv' date='2019-07-17T22:29:03Z'>
		I just created a p2.8xlarge instance (with Deep Learning AMI (Ubuntu) Version 23.1) and tried the following things. It worked for me. &lt;denchmark-link:https://github.com/alsrgv&gt;@alsrgv&lt;/denchmark-link&gt;
 Anything I missed?
&lt;denchmark-code&gt;pip install mxnet-cu100 --pre
git clone --recursive https://github.com/horovod/horovod.git
HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_WITHOUT_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITH_MXNET=1 pip install --no-cache-dir ~/horovod
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;(mxnet_p36) ubuntu@ip-172-31-21-35:~$ pip list | grep mx
mxnet-cu100                        1.5.0b20190716
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;(mxnet_p36) ubuntu@ip-172-31-21-35:~$ ~/anaconda3/envs/mxnet_p36/bin/mpirun -np 2 -H localhost:2 pytest horovod/test/test_mxnet.py
============================= test session starts ==============================
platform linux -- Python 3.6.5, pytest-3.5.1, py-1.5.3, pluggy-0.6.0
============================= test session starts ==============================
platform linux -- Python 3.6.5, pytest-3.5.1, py-1.5.3, pluggy-0.6.0
rootdir: /home/ubuntu/horovod, inifile:
rootdir: /home/ubuntu/horovod, inifile:
plugins: remotedata-0.2.1, openfiles-0.3.0, doctestplus-0.1.3, arraydiff-0.2
plugins: remotedata-0.2.1, openfiles-0.3.0, doctestplus-0.1.3, arraydiff-0.2
collected 13 items
collected 13 items

horovod/test/test_mxnet.py
horovod/test/test_mxnet.py --------------------------------------------------------------------------
WARNING: Linux kernel CMA support was requested via the
btl_vader_single_copy_mechanism MCA variable, but CMA support is
not available due to restrictive ptrace settings.

The vader shared memory BTL will fall back on another single-copy
mechanism if one is available. This may result in lower performance.

  Local host: ip-172-31-21-35
--------------------------------------------------------------------------
[ip-172-31-21-35:53394] 1 more process has sent help message help-btl-vader.txt / cma-permission-denied
[ip-172-31-21-35:53394] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
..........................                                 [100%]                                 [100%]



========================== 13 passed in 19.57 seconds ==========================
========================== 13 passed in 19.57 seconds ==========================
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;(mxnet_p36) ubuntu@ip-172-31-21-35:~$ nvidia-smi
Wed Jul 17 22:24:41 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:00:17.0 Off |                    0 |
| N/A   41C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:00:18.0 Off |                    0 |
| N/A   42C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:00:19.0 Off |                    0 |
| N/A   40C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:00:1A.0 Off |                    0 |
| N/A   41C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla K80           On   | 00000000:00:1B.0 Off |                    0 |
| N/A   35C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla K80           On   | 00000000:00:1C.0 Off |                    0 |
| N/A   36C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla K80           On   | 00000000:00:1D.0 Off |                    0 |
| N/A   32C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |
| N/A   36C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='alsrgv' date='2019-07-17T22:37:09Z'>
		&lt;denchmark-link:https://github.com/yuxihu&gt;@yuxihu&lt;/denchmark-link&gt;
, we currently have  installed.  I'll try to upgrade to  and let you know.
		</comment>
		<comment id='5' author='alsrgv' date='2019-07-18T01:16:29Z'>
		Nevermind, it's happening on CPU docker build worker and &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/15551&gt;apache/incubator-mxnet#15551&lt;/denchmark-link&gt;
 should fix it. Running a build to confirm.
		</comment>
		<comment id='6' author='alsrgv' date='2019-07-18T06:15:59Z'>
		&lt;denchmark-link:https://github.com/apeforest&gt;@apeforest&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/yuxihu&gt;@yuxihu&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://buildkite.com/horovod/horovod/builds/728#7c666363-2727-491c-bff6-fda9727b1773&gt;now I'm getting&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;OSError: /usr/local/lib/python2.7/dist-packages/horovod/mxnet/mpi_lib.so: undefined symbol: _ZN5mxnet7Context13CudaLibChecksEv
&lt;/denchmark-code&gt;

Any idea?  I checked and libmxnet.so really doesn't export any CudaLibChecks().
		</comment>
		<comment id='7' author='alsrgv' date='2019-07-18T16:37:10Z'>
		&lt;denchmark-link:https://github.com/alsrgv&gt;@alsrgv&lt;/denchmark-link&gt;
 The function is added in the fixing PR. Let me verify.
		</comment>
		<comment id='8' author='alsrgv' date='2019-07-18T16:38:18Z'>
		
Nevermind, it's happening on CPU docker build worker and apache/incubator-mxnet#15551 should fix it. Running a build to confirm.

Question: are we using mxnet-cu100 on CPU machine? Shall we just use mxnet --pre instead?
Update: I just checked the &lt;denchmark-link:https://github.com/horovod/horovod/blob/master/docker-compose.test.yml&gt;test&lt;/denchmark-link&gt;
 yaml file and we are using mxnet for cpu build and mxnet-cu100 for gpu build.
		</comment>
		<comment id='9' author='alsrgv' date='2019-07-18T16:47:41Z'>
		I got the same error when running unit test on p2.8xlarge instance with the latest nightly build (mxnet_cu100-1.5.0b20190717). I will work on a PR to fix it.
		</comment>
		<comment id='10' author='alsrgv' date='2019-07-18T16:48:03Z'>
		&lt;denchmark-link:https://github.com/yuxihu&gt;@yuxihu&lt;/denchmark-link&gt;
, thanks! 
		</comment>
	</comments>
</bug>