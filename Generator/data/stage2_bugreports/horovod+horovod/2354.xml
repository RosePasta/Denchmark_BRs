<bug id='2354' author='PaulKarlshoeferBULL' open_date='2020-10-06T13:57:39Z' closed_time='2020-11-10T08:25:26Z'>
	<summary>Examples fail: munmap_chunk(): invalid pointer</summary>
	<description>
Environment:

Framework: TensorFlow2
Framework version: 2.2
Horovod version: latest 20.3
MPI version: 4.0.1
CUDA version: 10.1.105
NCCL version: 2
Python version: 3.6.8
Spark / PySpark version:
OS and version: RHEL 7.4
GCC version: 7.3
CMake version: 3.13

Hello,
I installed horovod on a fresh python3.6 with TF2.
I installed using the following flags:
HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITHOUT_GLOO=1 HOROVOD_CUDA_INCLUDE=/usr/local/cuda/10.1.105/include/ HOROVOD_NCCL_INCLUDE=/users/bull/bullacc/Miniprojects/Horovod/resources/nccl-master/build/include/ HOROVOD_NCCL_LIB=/users/bull/bullacc/Miniprojects/Horovod/resources/nccl-master/build/lib/ HOROVOD_GPU_OPERATIONS=NCCL pip3.6 install --no-index --find-links file:///... --prefix=... .
I run the TF2 examples like so:
$PYTHONPATH/horovodrun -np 4 -H localhost:4 $PYTHONPATH/python3.6 $HOROVOD_EXAMPLES/tensorflow2_synthetic_benchmark.py
With any example, I run into this error:
&lt;denchmark-code&gt;[1,2]&lt;stderr&gt;:*** Error in `/users/bull/bullacc/Miniprojects/Horovod_2/install/bin/python3.6': munmap_chunk(): invalid pointer: 0x0000000059ea0770 ***
[1,2]&lt;stderr&gt;:======= Backtrace: =========
[1,2]&lt;stderr&gt;:/usr/lib64/libc.so.6(+0x7ab54)[0x2aef7877cb54]
[1,2]&lt;stderr&gt;:/usr/local/openmpi/gnu/3.1.5/lib/libmpi.so.40(ompi_coll_base_allreduce_intra_recursivedoubling+0x40a)[0x2af06d9d08ea]
[1,2]&lt;stderr&gt;:/usr/local/openmpi/gnu/3.1.5/lib/libmpi.so.40(PMPI_Allreduce+0x14f)[0x2af06d990d7f]
[1,2]&lt;stderr&gt;:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common13MPIController19CrossRankBitwiseAndERSt6vectorIxSaIxEEi+0x2c)[0x2af0654b655c]
[1,2]&lt;stderr&gt;:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common16CacheCoordinator4syncESt10shared_ptrINS0_10ControllerEEb+0x19a)[0x2af06547f99a]
[1,2]&lt;stderr&gt;:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common10Controller23CoordinateCacheAndStateERNS0_16CacheCoordinatorE+0x5f)[0x2af06544ab2f]
[1,2]&lt;stderr&gt;:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(_ZN7horovod6common10Controller19ComputeResponseListERSt6atomicIbERNS0_18HorovodGlobalStateE+0x23c7)[0x2af0654523f7]
[1,2]&lt;stderr&gt;:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so(+0x74b29)[0x2af06546db29]
[1,2]&lt;stderr&gt;:/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/tensorflow/python/../libtensorflow_framework.so.2(+0x173375f)[0x2af05758275f]
[1,2]&lt;stderr&gt;:/usr/lib64/libpthread.so.0(+0x7e25)[0x2aef77de4e25]
[1,2]&lt;stderr&gt;:/usr/lib64/libc.so.6(clone+0x6d)[0x2aef787fa34d]
&lt;/denchmark-code&gt;

What is wrong? Thanks for your help!
	</description>
	<comments>
		<comment id='1' author='PaulKarlshoeferBULL' date='2020-10-06T14:02:12Z'>
		this is the complete output of a test run.
&lt;denchmark-link:https://github.com/horovod/horovod/files/5334363/slurm-472647.txt&gt;slurm-472647.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='PaulKarlshoeferBULL' date='2020-10-06T19:32:53Z'>
		Looks like it's segfaulting in the response cache.  &lt;denchmark-link:https://github.com/romerojosh&gt;@romerojosh&lt;/denchmark-link&gt;
, could you take a look?
		</comment>
		<comment id='3' author='PaulKarlshoeferBULL' date='2020-10-09T14:58:34Z'>
		Hi &lt;denchmark-link:https://github.com/PaulKarlshoeferBULL&gt;@PaulKarlshoeferBULL&lt;/denchmark-link&gt;
. Could you try running with the environment variable  set and see if the segfault goes away? While the segfault is occurring in the response cache, this might be the first MPI collective called in the run, so it could be a more general MPI configuration issue.
		</comment>
		<comment id='4' author='PaulKarlshoeferBULL' date='2020-10-09T17:23:56Z'>
		Hi! thank you for your help so far. I did run it with your suggested env var and the error changed to the following:
It is still munmap_chunk(): invalid pointer, but with a different stack trace.
&lt;denchmark-code&gt;[1,0]&lt;stdout&gt;:Model: ResNet50
[1,0]&lt;stdout&gt;:Batch size: 32
[1,0]&lt;stdout&gt;:Number of GPUs: 4
[1,0]&lt;stdout&gt;:Running warmup...
[1,3]&lt;stderr&gt;:2020-10-09 19:11:29.719377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
[1,0]&lt;stderr&gt;:2020-10-09 19:11:30.211332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
[1,3]&lt;stderr&gt;:2020-10-09 19:11:30.237862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
[1,1]&lt;stderr&gt;:2020-10-09 19:11:30.271868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
[1,2]&lt;stderr&gt;:2020-10-09 19:11:30.327180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
[1,0]&lt;stderr&gt;:2020-10-09 19:11:30.708046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
[1,1]&lt;stderr&gt;:2020-10-09 19:11:30.765672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
[1,2]&lt;stderr&gt;:2020-10-09 19:11:30.820998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
[1,0]&lt;stderr&gt;:*** Error in `/users/bull/bullacc/Miniprojects/Horovod_2/install/bin/python3.6': munmap_chunk(): invalid pointer: 0x0000000054dec800 ***
[1,0]&lt;stderr&gt;:======= Backtrace: =========
[1,0]&lt;stderr&gt;:/usr/lib64/libc.so.6(+0x7ab54)[0x2ada9777fb54]
[1,0]&lt;stderr&gt;:/usr/lib64/libcuda.so.1(+0x217141)[0x2adba3270141]
[1,0]&lt;stderr&gt;:/usr/lib64/libcuda.so.1(+0x28dd6d)[0x2adba32e6d6d]
[1,0]&lt;stderr&gt;:/usr/lib64/libcuda.so.1(+0x219648)[0x2adba3272648]
[1,0]&lt;stderr&gt;:/usr/lib64/libpthread.so.0(+0x7e25)[0x2ada96de7e25]
[1,0]&lt;stderr&gt;:/usr/lib64/libc.so.6(clone+0x6d)[0x2ada977fd34d]
[1,0]&lt;stderr&gt;:======= Memory map: ========
...
&lt;/denchmark-code&gt;

Complete output:
&lt;denchmark-link:https://github.com/horovod/horovod/files/5356527/slurm-475587.txt&gt;slurm-475587.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='PaulKarlshoeferBULL' date='2020-10-09T17:37:17Z'>
		In your logs, I see references to /usr/local/openmpi/gnu/3.1.5/ in the stack trace output, but it seems that you are launching with an mpirun using a different major MPI version: /users/bull/bullacc/Miniprojects/mini_ucx/software/openmpi-4.0.1/bin/mpirun. Can you try to launch using the mpirun from a consistent MPI version?
		</comment>
		<comment id='6' author='PaulKarlshoeferBULL' date='2020-10-09T17:53:05Z'>
		right, this output is more consistent. I lost track of what I had tried  out..
Unfortunately, the "error message" hasn't changed.
I am using the latest MPI version on the system (3.1.5). Do you think I should try to reinstall with MPI 4.0 ? If so, is there a specific way to specify the mpi install location in horovod?
&lt;denchmark-link:https://github.com/horovod/horovod/files/5356684/slurm-475646.txt&gt;slurm-475646.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='PaulKarlshoeferBULL' date='2020-10-21T15:03:29Z'>
		I reinstalled with openmpi 4.0.4.
The error changed to this:
&lt;denchmark-code&gt;[1,3]&lt;stderr&gt;:[olympevolta1:50772:0:50772] Caught signal 11 (Segmentation fault: address not mapped to object at address (nil))
[1,3]&lt;stderr&gt;:
[1,3]&lt;stderr&gt;:/usr/include/c++/4.8.2/bits/stl_vector.h: [ std::vector&lt;tensorflow::shape_inference::ShapeHandle, std::allocator&lt;tensorflow::shape_inference::ShapeHandle&gt; &gt;::_M_range_check() ]
[1,3]&lt;stderr&gt;:      ...
[1,3]&lt;stderr&gt;:      790       _M_range_check(size_type __n) const
[1,3]&lt;stderr&gt;:      791       {
[1,3]&lt;stderr&gt;:      792         if (__n &gt;= this-&gt;size())
[1,3]&lt;stderr&gt;:==&gt;   793           __throw_out_of_range(__N("vector::_M_range_check"));
[1,3]&lt;stderr&gt;:      794       }
[1,3]&lt;stderr&gt;:      795
[1,3]&lt;stderr&gt;:      796     public:
[1,3]&lt;stderr&gt;:
[1,0]&lt;stderr&gt;:[olympevolta1:50640:0:50640] Caught signal 11 (Segmentation fault: address not mapped to object at address (nil))
[1,3]&lt;stderr&gt;:==== backtrace (tid:  50772) ====
[1,3]&lt;stderr&gt;: 0 0x000000000004d8ce ucs_debug_print_backtrace()  /tmpdir/sysinst/openmpi/UCX/UCX_1.8.1/COMPILER/ucx-1.8.1/src/ucs/debug/debug.c:653
[1,3]&lt;stderr&gt;: 1 0x00000000000d3d61 std::vector&lt;tensorflow::shape_inference::ShapeHandle, std::allocator&lt;tensorflow::shape_inference::ShapeHandle&gt; &gt;::_M_range_check()  /usr/include/c++/4.8.2/bits/stl_vector.h:793
[1,3]&lt;stderr&gt;: 2 0x00000000000d3d61 operator()()  /tmp/pip-req-build-bftu_odg/horovod/tensorflow/mpi_ops.cc:436
[1,3]&lt;stderr&gt;: 3 0x00000000000d3d61 _FUN()  /tmp/pip-req-build-bftu_odg/horovod/tensorflow/mpi_ops.cc:438
[1,3]&lt;stderr&gt;: 4 0x00000000000d5cec std::_Function_handler&lt;tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::Status (*)(tensorflow::shape_inference::InferenceContext*)&gt;::_M_invoke()  /usr/include/c++/4.8.2/functional:2057
[1,3]&lt;stderr&gt;: 5 0x0000000000eb1102 tensorflow::shape_inference::InferenceContext::Run()  ???:0
[1,3]&lt;stderr&gt;: 6 0x000000000afd22c4 tensorflow::ShapeRefiner::RunShapeFn()  ???:0
[1,3]&lt;stderr&gt;: 7 0x000000000afd368e tensorflow::ShapeRefiner::AddNode()  ???:0
[1,3]&lt;stderr&gt;: 8 0x000000000333d4d2 TF_FinishOperation()  ???:0
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='PaulKarlshoeferBULL' date='2020-10-26T17:51:52Z'>
		&lt;denchmark-link:https://github.com/tgaddair&gt;@tgaddair&lt;/denchmark-link&gt;
 Have you seen errors like this before? This looks like it is happening within the TF op shape inference, which is very odd.
		</comment>
		<comment id='9' author='PaulKarlshoeferBULL' date='2020-10-30T00:08:31Z'>
		&lt;denchmark-link:https://github.com/PaulKarlshoeferBULL&gt;@PaulKarlshoeferBULL&lt;/denchmark-link&gt;
, another thing we can try is running with Gloo instead of MPI, to determine if this is an MPI-specific problem.  Can you try installing with Gloo and running with ?
		</comment>
		<comment id='10' author='PaulKarlshoeferBULL' date='2020-11-05T13:30:18Z'>
		I tried to run with GLOO, however i always run in some sort of this error:
&lt;denchmark-code&gt;/usr/local/openmpi/icc/openmpi404_intel1820_cuda101105_ucx18_gdrcopy2/bin/mpirun
Filtering local host names.
Remote host found:
All hosts are local, finding the interfaces with address 127.0.0.1
Local interface found lo
Traceback (most recent call last):
  File "/users/bull/bullacc/Miniprojects/Horovod_2/install/bin/horovodrun", line 10, in &lt;module&gt;
    sys.exit(run_commandline())
  File "/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/runner/launch.py", line 723, in run_commandline
    _run(args)
  File "/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/runner/launch.py", line 713, in _run
    return _run_static(args)
  File "/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/runner/launch.py", line 571, in _run_static
    _launch_job(args, settings, nics, command)
  File "/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/runner/launch.py", line 686, in _launch_job
    args.verbose)
  File "/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/runner/launch.py", line 634, in run_controller
    if not gloo_built(verbose=verbose):
  File "/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/common/util.py", line 119, in wrapper
    retval = f(*args, **kwargs)
  File "/users/bull/bullacc/Miniprojects/Horovod_2/install/lib/python3.6/site-packages/horovod/common/util.py", line 152, in gloo_built
    raise RuntimeError('Failed to determine if Gloo support has been built. '
RuntimeError: Failed to determine if Gloo support has been built. Run again with --verbose for more details.

&lt;/denchmark-code&gt;

For installation, I use the same command as in my first post, but with HOROVOD_WITH_GLOO=1, other than that, no changes.
I run with horovodrun --verbose --gloo -np 4 -H localhost:4 $MY_PYTHON_PATH/python3.6 $HOROVOD_EXAMPLES/tensorflow2_synthetic_benchmark.py  --verbose
		</comment>
		<comment id='11' author='PaulKarlshoeferBULL' date='2020-11-05T18:09:30Z'>
		Hey &lt;denchmark-link:https://github.com/PaulKarlshoeferBULL&gt;@PaulKarlshoeferBULL&lt;/denchmark-link&gt;
, can you share the full log output?  It may be that the error is hiding somewhere above.
		</comment>
		<comment id='12' author='PaulKarlshoeferBULL' date='2020-11-06T10:06:53Z'>
		&lt;denchmark-link:https://github.com/tgaddair&gt;@tgaddair&lt;/denchmark-link&gt;
 okay, I ran again with and the error appears to be this:

The complete output:
&lt;denchmark-link:https://github.com/horovod/horovod/files/5500602/output_horovod.txt&gt;output_horovod.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='PaulKarlshoeferBULL' date='2020-11-06T15:43:26Z'>
		Hey &lt;denchmark-link:https://github.com/PaulKarlshoeferBULL&gt;@PaulKarlshoeferBULL&lt;/denchmark-link&gt;
, that's interesting, it seems to suggest that the version of MPI that Horovod was installed with differs from what it's able to find at runtime.
One way to further isolate this would be to uninstall Horovod, then reinstall with the additional flags ... HOROVOD_WITH_GLOO=1 HOROVOD_WITHOUT_MPI=1 pip install --no-cache-dir ....  That way, MPI should not even be installed, and we can see if Gloo resolves the issue.
		</comment>
		<comment id='14' author='PaulKarlshoeferBULL' date='2020-11-10T08:25:26Z'>
		Hey &lt;denchmark-link:https://github.com/tgaddair&gt;@tgaddair&lt;/denchmark-link&gt;
, great! I can run the examples with Gloo, now. Thank you for your help. :)
		</comment>
	</comments>
</bug>