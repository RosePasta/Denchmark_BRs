<bug id='906' author='johnyquest7' open_date='2018-07-26T22:49:47Z' closed_time='2019-01-17T21:21:52Z'>
	<summary>issue running on Google Colab</summary>
	<description>
I was able to run turicreate on CoLab up until recently using some workarounds, lately it is not working.
Environment
google CoLab
Python 3.6
GPU Telsa K80
When I tried to create a model following error was displayed

ERROR: Incomplete installation for leveraging GPUs for computations.
Please make sure you have CUDA installed and run the following line in
your terminal and try again:

&lt;denchmark-code&gt;pip uninstall -y mxnet &amp;&amp; pip install mxnet-cu90==1.1.0
&lt;/denchmark-code&gt;

Adjust 'cu90' depending on your CUDA version ('cu75' and 'cu80' are also available).
You can also disable GPU usage altogether by invoking turicreate.config.set_num_gpus(0)
An exception has occurred, use %tb to see the full traceback.
on traceback



MXNetError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/turicreate/toolkits/_mxnet_utils.py in get_mxnet_context(max_devices)
64             for ctx_i in ctx:
---&gt; 65                 _mx.nd.array([1], ctx=ctx_i)
66
/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/utils.py in array(source_array, ctx, dtype)
/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/ndarray.py in array(source_array, ctx, dtype)
/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/ndarray.py in empty(shape, ctx, dtype)
/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/ndarray.py in _new_alloc_handle(shape, ctx, delay_alloc, dtype)
/usr/local/lib/python3.6/dist-packages/mxnet/base.py in check_call(ret)
MXNetError: [22:40:31] src/storage/storage.cc:118: Compile with USE_CUDA=1 to enable GPU usage
Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x192112) [0x7f25fc9c5112]
[bt] (1) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x192738) [0x7f25fc9c5738]
[bt] (2) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27c553a) [0x7f25feff853a]
[bt] (3) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27ca134) [0x7f25feffd134]
[bt] (4) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x27ca607) [0x7f25feffd607]
[bt] (5) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(+0x22ac511) [0x7f25feadf511]
[bt] (6) /usr/local/lib/python3.6/dist-packages/mxnet/libmxnet.so(MXNDArrayCreateEx+0x169) [0x7f25feadfd99]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f26880eee18]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x32a) [0x7f26880ee87a]
[bt] (9) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x4cd) [0x7f268830296d]
During handling of the above exception, another exception occurred:
SystemExit                                Traceback (most recent call last)
 in ()
1
----&gt; 2 model = tc.image_similarity.create(reference_data)
/usr/local/lib/python3.6/dist-packages/turicreate/toolkits/image_similarity/image_similarity.py in create(dataset, label, feature, model, verbose, batch_size)
121         feature = _tkutl._find_only_image_column(dataset)
122
--&gt; 123     feature_extractor = _image_feature_extractor._create_feature_extractor(model)
124
125     # Extract features
/usr/local/lib/python3.6/dist-packages/turicreate/toolkits/_image_feature_extractor.py in _create_feature_extractor(model_name)
22     if system() != 'Darwin' or _mac_ver() &lt; (10, 13):
23         ptModel = MODELS&lt;denchmark-link:&gt;model_name&lt;/denchmark-link&gt;

---&gt; 24         return MXFeatureExtractor(ptModel)
25
26     download_path = _get_model_cache_dir()
/usr/local/lib/python3.6/dist-packages/turicreate/toolkits/_image_feature_extractor.py in (self, ptModel)
84         self.feature_layer = ptModel.feature_layer
85         self.image_shape = ptModel.input_image_shape
---&gt; 86         self.context = _mxnet_utils.get_mxnet_context()
87
88     &lt;denchmark-link:https://github.com/staticmethod&gt;@staticmethod&lt;/denchmark-link&gt;

/usr/local/lib/python3.6/dist-packages/turicreate/toolkits/_mxnet_utils.py in get_mxnet_context(max_devices)
77             print("Adjust 'cu90' depending on your CUDA version ('cu75' and 'cu80' are also available).")
78             print('You can also disable GPU usage altogether by invoking turicreate.config.set_num_gpus(0)')
---&gt; 79             _sys.exit(1)
80         return ctx
81
SystemExit: 1
	</description>
	<comments>
		<comment id='1' author='johnyquest7' date='2018-07-26T23:58:30Z'>
		&lt;denchmark-link:https://github.com/johnyquest7&gt;@johnyquest7&lt;/denchmark-link&gt;
 - It looks like the CUDA version installed on the system is not CUDA9. Installing  will only work if a version of CUDA 9 is installed on the system.
You'll need to figure out which CUDA version is installed and install the corresponding mxnet-cuXX package, where XX is the version.
The next likely version of CUDA is 8. So you could just try pip install mxnet-cu80==1.1.0 and see if that works.
		</comment>
		<comment id='2' author='johnyquest7' date='2018-07-27T00:07:47Z'>
		Tried installing CUDA 8, it did not work
Could be due to the way  CUDA is installed in google colab
		</comment>
		<comment id='3' author='johnyquest7' date='2018-07-27T00:38:47Z'>
		Following code used to work -
&lt;denchmark-link:https://github.com/johnyquest7/TuriCreate_CoLab_Image_classification/blob/master/Image_Classification_Tutorial.ipynb&gt;https://github.com/johnyquest7/TuriCreate_CoLab_Image_classification/blob/master/Image_Classification_Tutorial.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='johnyquest7' date='2018-07-27T23:26:12Z'>
		&lt;denchmark-link:https://github.com/johnyquest7&gt;@johnyquest7&lt;/denchmark-link&gt;
 What version of CUDA is installed in Google Colab? Where is that CUDA installation located on disk? Note that you'll need to install the corresponding version of mxnet, so if you have CUDA 9.1, you'll need to use  specifically.
		</comment>
		<comment id='5' author='johnyquest7' date='2018-07-29T00:09:44Z'>
		Unable to find cuda version using standard commands :-(
		</comment>
		<comment id='6' author='johnyquest7' date='2018-07-30T15:10:35Z'>
		&lt;denchmark-link:https://github.com/johnyquest7&gt;@johnyquest7&lt;/denchmark-link&gt;
 Can you try either  or type  (the most common installation destination) and hit tab. Either it might be , in which case the version is clear. If there is no dash after , then look at .
		</comment>
		<comment id='7' author='johnyquest7' date='2018-07-31T03:09:36Z'>
		&lt;denchmark-link:https://github.com/gustavla&gt;@gustavla&lt;/denchmark-link&gt;


returned

/bin/sh: 1: nvcc: not found

under /usr/local there is no cuda directory
		</comment>
		<comment id='8' author='johnyquest7' date='2018-07-31T03:10:35Z'>
		Unfortunately I could not find a reference for the location of Cuda directory in Google Colab
		</comment>
		<comment id='9' author='johnyquest7' date='2018-07-31T04:17:22Z'>
		&lt;denchmark-link:https://github.com/johnyquest7&gt;@johnyquest7&lt;/denchmark-link&gt;
 Are you sure then that CUDA is installed? Since it can't find , it means at least your PATH is not pointing to the CUDA location.
If CoLab installs it in a different path, perhaps it also sets an environment variable describing where it is. Check:
&lt;denchmark-code&gt;env | grep CUDA
&lt;/denchmark-code&gt;

You can also try something like this to see if if the CUDA include directory is being picked up:
&lt;denchmark-code&gt;echo '#include &lt;cuda.h&gt;' | cpp -H -o /dev/null 2&gt;&amp;1 | head -n1
&lt;/denchmark-code&gt;

If neither of those work, it looks from our end that CUDA is not installed. As a sanity check you should also check if you can run the command nvidia-smi. However, this command comes with your NVIDIA drivers and not with CUDA, but it will be a pre-requisite for installing CUDA, so that command should be available at least.
		</comment>
		<comment id='10' author='johnyquest7' date='2018-08-01T01:51:26Z'>
		I was able to use turicreate in the past and use GPU. So I am assuming that CUDA is installed. Tensor flow is able to use the GPU in CoLab.
Tried this
echo '#include &lt;cuda.h&gt;' | cpp -H -o /dev/null 2&gt;&amp;1 | head -n1
Output was
stdin&gt;:1:10: fatal error: cuda.h: No such file or directory
Tried
nvidia-smi
output was
Wed Aug  1 01:47:38 2018
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.111                Driver Version: 384.111                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |
| N/A   31C    P8    27W / 149W |      0MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Since this is not resolved, I have tried to use my laptop. Surprisingly it was fast even without GPU - took only 3 minutes!
Thanks you all for looking into this.
		</comment>
		<comment id='11' author='johnyquest7' date='2018-08-17T20:44:13Z'>
		&lt;denchmark-link:https://github.com/johnyquest7&gt;@johnyquest7&lt;/denchmark-link&gt;
 Is this issue still able to repro for you? If so, can you try looking in  to see if there may be a hint as to the installed CUDA version there?
		</comment>
		<comment id='12' author='johnyquest7' date='2018-08-19T19:50:26Z'>
		&lt;denchmark-link:https://github.com/znation&gt;@znation&lt;/denchmark-link&gt;

Following is a Colab notebook where I tried to look under different folders.
&lt;denchmark-link:https://colab.research.google.com/drive/12uvYRM04mdrI12B0zAtsTfvtRqDes0jE&gt;https://colab.research.google.com/drive/12uvYRM04mdrI12B0zAtsTfvtRqDes0jE&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='johnyquest7' date='2018-08-21T00:10:23Z'>
		&lt;denchmark-link:https://github.com/johnyquest7&gt;@johnyquest7&lt;/denchmark-link&gt;
 From that notebook, I don't see any evidence that CUDA is installed at all. Are you sure it is?
		</comment>
		<comment id='14' author='johnyquest7' date='2018-08-22T03:05:04Z'>
		TuriCreate used to work in CoLab and was able to use GPU. TensorFlow is able to use GPU in CoLab. Not sure whether it is in a docker container.
		</comment>
		<comment id='15' author='johnyquest7' date='2018-08-22T21:14:24Z'>
		&lt;denchmark-link:https://github.com/johnyquest7&gt;@johnyquest7&lt;/denchmark-link&gt;
 I see - can you confirm that TensorFlow with GPU still works in the same environment that you're trying to run Turi Create in? Please follow the instructions &lt;denchmark-link:https://colab.research.google.com/notebooks/gpu.ipynb&gt;here&lt;/denchmark-link&gt;
 and paste the output from the first cell. From my reading, you may need to change some settings in the notebook UI (something like Runtime -&gt; Change or Accelerator -&gt; GPU). Those settings may also affect whether CUDA is present in the environment for other purposes, so make sure that's enabled for Turi Create, and when looking on the filesystem for the presence of CUDA.
		</comment>
		<comment id='16' author='johnyquest7' date='2018-08-23T03:00:18Z'>
		&lt;denchmark-link:https://github.com/znation&gt;@znation&lt;/denchmark-link&gt;
 GPU is enabled in my notebooks.
Output for the first cell was

Found GPU at: /device:GPU:0
According to CoLab documentation this means GPU is available.

I also ran the second cell to confirm and following was the result

Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.
CPU (s):
9.67492699623
GPU (s):
0.87723493576
GPU speedup over CPU: 11x

		</comment>
		<comment id='17' author='johnyquest7' date='2018-08-24T22:21:54Z'>
		There's a relevant thread on Stackoverflow: &lt;denchmark-link:https://stackoverflow.com/questions/50560395/how-to-install-cuda-in-google-colab-gpus/51029933#51029933&gt;https://stackoverflow.com/questions/50560395/how-to-install-cuda-in-google-colab-gpus/51029933#51029933&lt;/denchmark-link&gt;

Perhaps start with the second response: &lt;denchmark-link:https://stackoverflow.com/a/51029933&gt;https://stackoverflow.com/a/51029933&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/johnyquest7&gt;@johnyquest7&lt;/denchmark-link&gt;
 Can you give this a try? Let us know how it goes.
		</comment>
		<comment id='18' author='johnyquest7' date='2018-08-25T04:29:51Z'>
		Initially when I encountered the problem, I tried all the solutions mentioned in that stackoverflow thread. Nothing worked for me.
		</comment>
		<comment id='19' author='johnyquest7' date='2018-11-09T20:32:34Z'>
		Works for me: &lt;denchmark-link:https://medium.com/@nickzamosenchuk/training-the-model-for-ios-coreml-in-google-colab-60-times-faster-6b3d1669fc46&gt;https://medium.com/@nickzamosenchuk/training-the-model-for-ios-coreml-in-google-colab-60-times-faster-6b3d1669fc46&lt;/denchmark-link&gt;

You need to uninstall Cuda9 (with lots of packages), add Cuda8 repo, install cuda8, but a couple of packages will need manual installation. Then installing mx-net for Cuda8.
Feel free to ping me if you need any help.
(upd 11.Nov) The code is now properly formatted in the post and has a couple of minor improvements.
		</comment>
		<comment id='20' author='johnyquest7' date='2018-11-09T22:00:05Z'>
		Thanks &lt;denchmark-link:https://github.com/nzamosenchuk&gt;@nzamosenchuk&lt;/denchmark-link&gt;
 Will try it out
		</comment>
		<comment id='21' author='johnyquest7' date='2019-01-17T21:21:52Z'>
		Closing this right now. Please re-open if we have a repro.
		</comment>
	</comments>
</bug>