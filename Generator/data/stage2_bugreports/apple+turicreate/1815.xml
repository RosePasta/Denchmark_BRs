<bug id='1815' author='znation' open_date='2019-04-30T04:09:35Z' closed_time='2020-01-10T21:37:28Z'>
	<summary>Style transfer export to CoreML requires tons of RAM</summary>
	<description>
The style transfer test_export_coreml unit test crashes on systems with low RAM. This includes the shared runners on Gitlab.com CI. They seem to reliably have an amount of RAM that leads to this crash:
&lt;denchmark-code&gt;test_style_transfer.py::StyleTransferTest::test_export_coreml /build/scripts/test_wheel.sh: line 90:  2340 Aborted                 (core dumped) ${PYTHON} -m pytest -v --junit-xml=../../../../../../../pytest.xml
&lt;/denchmark-code&gt;

Build log: &lt;denchmark-link:https://gitlab.com/zach_nation/turicreate/-/jobs/204605929&gt;https://gitlab.com/zach_nation/turicreate/-/jobs/204605929&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='znation' date='2019-04-30T07:00:06Z'>
		I suppose it's possible that it's the test code that requires tons of RAM, and the actual export is fine -- it's not clear what causes it, but this test failure is only reproducible in a low-RAM environment.
		</comment>
		<comment id='2' author='znation' date='2019-05-01T04:19:29Z'>
		This seems to be consistently causing public Gitlab CI test failures. Here's another example: &lt;denchmark-link:https://gitlab.com/zach_nation/turicreate/pipelines/59209472&gt;https://gitlab.com/zach_nation/turicreate/pipelines/59209472&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='znation' date='2019-05-24T19:26:26Z'>
		Hopefully this will go away once we port the toolkit to C++
		</comment>
		<comment id='4' author='znation' date='2019-12-10T01:13:27Z'>
		Let's move this to the 6.1 milestone and begin by determining if this is even still an issue.
		</comment>
		<comment id='5' author='znation' date='2020-01-10T18:31:23Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/14238915/72176175-b3065580-3392-11ea-8ce3-bbc7d9f7b5aa.png&gt;&lt;/denchmark-link&gt;

For 6.0, the peak memory usage is about 2.3 GiB and most of them are from .
Whereas for 5.8, the peak ram usage is about 4.8 GiB
&lt;denchmark-link:https://user-images.githubusercontent.com/14238915/72176737-e0073800-3393-11ea-8c08-0c7b424b28e8.png&gt;&lt;/denchmark-link&gt;

Most memory allocation is from Mxnet.
		</comment>
		<comment id='6' author='znation' date='2020-01-10T18:52:19Z'>
		&lt;denchmark-link:https://github.com/guihao-liang&gt;@guihao-liang&lt;/denchmark-link&gt;
 Thanks for the thorough investigation! I think we can call this issue fixed.
		</comment>
		<comment id='7' author='znation' date='2020-01-10T21:37:18Z'>
		&lt;denchmark-link:https://github.com/znation&gt;@znation&lt;/denchmark-link&gt;
 I run the test with
pytest.main(["-s", "src/python/turicreate/test/test_style_transfer.py", "-k", "test_single_image"])
on another single test case, which will use RAM about 2GiB during peak time.
&lt;denchmark-link:https://user-images.githubusercontent.com/14238915/72187476-a0007f00-33ac-11ea-824b-c572e56bef20.png&gt;&lt;/denchmark-link&gt;

I think the RAM usage is from the SetUpClass stage, where the model is trained, which is consistent with the report above.
		</comment>
		<comment id='8' author='znation' date='2020-01-10T21:41:31Z'>
		The setup class will train the model and call tensorflow. It's unclear how RAM-hungry SF is.
&lt;denchmark-code&gt;def _get_data(feature, num_examples=100):
    from PIL import Image as _PIL_Image
    rs = np.random.RandomState(1234)
    def from_pil_image(pil_img, image_format='png'):
        # The above didn't work, so as a temporary fix write to temp files
        if image_format == 'raw':
            image = np.array(pil_img)
            FORMAT_RAW = 2
            return tc.Image(_image_data=image.tobytes(),
                            _width=image.shape[1],
                            _height=image.shape[0],
                            _channels=image.shape[2],
                            _format_enum=FORMAT_RAW,
                            _image_data_size=image.size)
        else:
            with tempfile.NamedTemporaryFile(mode='w+b', suffix='.' + image_format) as f:
                pil_img.save(f, format=image_format)
                return tc.Image(f.name)

    images = []
    FORMATS = ['png', 'jpeg', 'raw']
    for i in range(num_examples):
        # Randomly determine image size (should handle large and small)
        img_shape = tuple(rs.randint(100, 600, size=2)) + (3,)
        img = rs.randint(255, size=img_shape)

        pil_img = _PIL_Image.fromarray(img, mode='RGB')
        # Randomly select image format
        image_format = FORMATS[rs.randint(len(FORMATS))]
        images.append(from_pil_image(pil_img, image_format=image_format))

    data = tc.SFrame({
            feature: tc.SArray(images),
    })
    return data
&lt;/denchmark-code&gt;

The worst case is that the input size is 18MiB (100 * (100 * 600 * 3)), so the input is not the bottleneck. And the model is only trained once, so the graph should only be initialized once. My take is that the image training phase is a kind of memory hog.
		</comment>
	</comments>
</bug>