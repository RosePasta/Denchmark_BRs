<bug id='1080' author='dhgokul' open_date='2018-09-12T07:08:13Z' closed_time='2018-10-03T23:44:20Z'>
	<summary>Got segmentation error - when training 66 images @ GPU</summary>
	<description>
&lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 Got segmentation error, when training with 66 image dataset
Error :
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(std::istream::read(char*, long)+0x19) [0x7fbf325c8889]
[bt] (4) /usr/local/lib/python2.7/dist-packages/turicreate/cython/../libunity_shared.so(+0xe86532) [0x7fbf0d3ba532]
[bt] (5) /usr/local/lib/python2.7/dist-packages/turicreate/cython/../libunity_shared.so(turi::lambda::lambda_master::bulk_eval(unsigned long, turi::sframe_rows const&amp;, std::vector&lt;turi::flexible_type, std::allocatorturi::flexible_type &gt;&amp;, bool, int)+0x18d) [0x7fbf0d3badfd]
[bt] (6) /usr/local/lib/python2.7/dist-packages/turicreate/cython/../libunity_shared.so(+0x7d15a9) [0x7fbf0cd055a9]
[bt] (7) /usr/local/lib/python2.7/dist-packages/turicreate/cython/../libunity_shared.so(+0x7fdf80) [0x7fbf0cd31f80]
[bt] (8) /usr/local/lib/python2.7/dist-packages/turicreate/cython/../libunity_shared.so(+0x1a1331f) [0x7fbf0df4731f]
/home/ubuntu/turicreate/test_mongo.sh: line 23: 20660 Segmentation fault      (core dumped) python /home/ubuntu/turicreate/test.py

&lt;denchmark-link:https://user-images.githubusercontent.com/5689804/45407648-b054fc80-b687-11e8-9999-8976ee6f2d61.png&gt;&lt;/denchmark-link&gt;

Mxnet version :
mxnet==1.1.0
mxnet-cu90==1.1.0
No of GPU used :
tc.config.set_num_gpus(-1)
Any help appreciated !
	</description>
	<comments>
		<comment id='1' author='dhgokul' date='2018-09-12T07:17:12Z'>
		Can you share the code you wrote for this?
		</comment>
		<comment id='2' author='dhgokul' date='2018-09-12T07:20:21Z'>
		sample code snippet :
data['annotations'] = SArray(data=annotations,dtype=list)
print(data['annotations'])
data.save('/home/ubuntu/turicreate/training.sframe')
# Load the data
print("Load SFrame data")
data = tc.SFrame('/home/ubuntu/turicreate/training.sframe')
# Make a train-test split
train_data, test_data = data.random_split(0.8)
&lt;denchmark-code&gt;# Disables GPU usage
tc.config.set_num_gpus(-1)

# Automatically picks the right model based on your data.
model = tc.object_detector.create(train_data, feature='image', annotations='annotations', max_iterations=50)


#Returns the name of the model
modelname = model.name()

# Save the model for later use in Turi Create
# Important to save in case something after breaks the script
model.save('/home/ubuntu/turicreatei/Turicreate' + modelname + '.model')

# Mean average Precision
scores = model.evaluate(data)
print('Mean Average Precision(mAP): {:.1%}'.format(scores['mean_average_precision']))

#Print a summary of the model
model.summary()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='dhgokul' date='2018-09-12T07:22:53Z'>
		&lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 any idea of issue cause ?
Again run same script with tc.config.set_num_gpus(1) , it worked .Got result inconsistently sometime it worked and sometime getting issue
		</comment>
		<comment id='4' author='dhgokul' date='2018-09-12T07:29:27Z'>
		I'm a bit confused by your last statement. Does tc.config.set_num_gpus(1) work consistently?
Also, if you want to disable the GPU, you should use 
(see more details &lt;denchmark-link:https://github.com/apple/turicreate/blob/master/userguide/image_classifier/advanced-usage.md&gt;https://github.com/apple/turicreate/blob/master/userguide/image_classifier/advanced-usage.md&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='5' author='dhgokul' date='2018-09-12T07:32:08Z'>
		&lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 Utilized max set of GPU by assign tc.config.set_num_gpus(-1)
Now i modified to utilize single GPU (tc.config.set_num_gpus(1) ) and run the training , it working . But  it works inconsistently
		</comment>
		<comment id='6' author='dhgokul' date='2018-09-12T07:33:34Z'>
		What does work inconsistently mean? Does it crash intermittently?
Also, does tc.config.set_num_gpus(0) work?
		</comment>
		<comment id='7' author='dhgokul' date='2018-09-12T07:34:49Z'>
		Sometime got segmentation issue when run GPU tc.config.set_num_gpus(1) and sometimes its working
Also, does tc.config.set_num_gpus(0) work? - Yes checked in local CPU machine, it worked for minimum iteration
		</comment>
		<comment id='8' author='dhgokul' date='2018-09-12T08:01:41Z'>
		In addition to previous dataset (66 images) added (62 images)- totally 128 images, now got bad allocation memory issue
Issue :
File "/usr/local/lib/python2.7/dist-packages/turicreate/toolkits/object_detector/_sframe_loader.py", line 232, in _next
self.sframe = self.sframe.sort(_TMP_COL_RANDOM_ORDER)
File "/usr/local/lib/python2.7/dist-packages/turicreate/data_structures/sframe.py", line 5421, in sort
return SFrame(_proxy=self.proxy.sort(sort_column_names, sort_column_orders))
File "/usr/local/lib/python2.7/dist-packages/turicreate/cython/context.py", line 49, in exit
raise exc_type(exc_value)
MemoryError: std::bad_alloc

&lt;denchmark-link:https://user-images.githubusercontent.com/5689804/45410653-e7c7a700-b68f-11e8-9e15-b88f2479ae72.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='dhgokul' date='2018-09-12T08:05:49Z'>
		Is this second report a separate one? That issue seems to be different?
Can you share the dataset you have with us by separating out the dataset with 66 images with the one with 128 images. That would greatly help us isolate both bugs.
In addition to that, we'd appreciate some info around:

What version of TC is this?
How much memory does this machine have?

		</comment>
		<comment id='10' author='dhgokul' date='2018-09-12T08:08:33Z'>
		TC version - 4.3.2
AWS deep learning machine - g2.2xlarge
Will share dataset privately
		</comment>
		<comment id='11' author='dhgokul' date='2018-09-12T08:10:01Z'>
		We fixed a lot of issues in the object detector in 5.0. Can you upgrade to 5.0 (using pip install turicreate --upgrade) and confirm that you are having the same set of issues?
		</comment>
		<comment id='12' author='dhgokul' date='2018-09-12T08:13:17Z'>
		&lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 Thanks ! will check and update you
		</comment>
		<comment id='13' author='dhgokul' date='2018-09-12T11:31:10Z'>
		Upgrade version to 5.0 and create coreML for sample dataset. Tried to import coreML in xcode i got issue and not able to import model created from turicreate 5.0
I have latest xcode version 9.4.1, coreML model created from 4.3.8 can able to import without any issue, when import coreML created from turicreate 5.0 , I got below issue - PFA
&lt;denchmark-link:https://user-images.githubusercontent.com/5689804/45422286-6da61b00-b6ad-11e8-8985-a40270d9fe3e.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='dhgokul' date='2018-09-12T15:30:54Z'>
		Did upgrading to version 5.0 solve the original issue or are you still having that?
To fix this issue, you can export the model using the following for iOS 11 (the default export targets iOS 12 and above).
&lt;denchmark-code&gt;model.export_coreml('MyDetector.mlmodel', include_non_maximum_suppression=False)
&lt;/denchmark-code&gt;

See &lt;denchmark-link:https://github.com/apple/turicreate/blob/master/userguide/object_detection/export-coreml.md&gt;https://github.com/apple/turicreate/blob/master/userguide/object_detection/export-coreml.md&lt;/denchmark-link&gt;
 for more details.
		</comment>
		<comment id='15' author='dhgokul' date='2018-09-12T17:03:24Z'>
		&lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 Thanks for your prompt response ! Original issue got resolved, Still need to check multiple scenerios and let you know.
Will modify export coreml model and update you for xcode issue
		</comment>
		<comment id='16' author='dhgokul' date='2018-10-03T23:44:20Z'>
		Hey &lt;denchmark-link:https://github.com/dhgokul&gt;@dhgokul&lt;/denchmark-link&gt;
 , closing this since the original issue got resolved. Feel free to reopen this issue if you run into that problem again!
		</comment>
	</comments>
</bug>