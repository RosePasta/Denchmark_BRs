<bug id='1974' author='srikris' open_date='2019-05-29T05:22:10Z' closed_time='2019-11-12T15:34:29Z'>
	<summary>Drawing classifier evaluation object has additional keys that it should not have</summary>
	<description>
There seems to be more in this dictionary that is needed.
&lt;denchmark-code&gt;In [23]: evals.keys()
Out[23]:
['f1_score',
 'roc_curve',
 'labels',
 'precision',
 'label_metrics',
 'sorted_labels',
 'training_time',
 'conf_mat',
 'num_test_examples',
 'confidence_threshold',
 'num_classes',
 'max_iterations',
 'confidence_metric_for_threshold',
 'training_loss',
 'auc',
 'confusion_matrix',
 'feature',
 'test_data',
 'num_examples',
 'recall',
 'hesitant_threshold',
 'model_name',
 'accuracy']
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='srikris' date='2019-05-29T06:42:51Z'>
		&lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 Which ones should it have, and which ones should it not have?
		</comment>
		<comment id='2' author='srikris' date='2019-05-29T06:44:08Z'>
		I think it should only have these:
&lt;denchmark-code&gt;['f1_score',
 'roc_curve',
 'precision',
 'auc',
 'confusion_matrix',
 'recall',
 'accuracy']
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='srikris' date='2019-05-29T16:39:21Z'>
		This is related to &lt;denchmark-link:https://github.com/apple/turicreate/issues/1785&gt;#1785&lt;/denchmark-link&gt;
. Some of those additional keys/values are very costly to generate, particularly when there are a large number of classes.
		</comment>
		<comment id='4' author='srikris' date='2019-05-29T18:42:30Z'>
		I think the main issue here is that many of these keys are not actually metrics, whereas previously the caller could iterate over the keys of the evaluation dictionary and assume that each key was an evaluation metric
		</comment>
		<comment id='5' author='srikris' date='2019-11-07T23:14:22Z'>
		To verify after implementing in C++.
		</comment>
		<comment id='6' author='srikris' date='2019-11-12T15:34:29Z'>
		Verified fix for 6.0
&lt;denchmark-code&gt;In [16]: metrics.keys()
Out[16]:
['f1_score',
 'auc',
 'recall',
 'precision',
 'log_loss',
 'roc_curve',
 'confusion_matrix',
 'accuracy']
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>