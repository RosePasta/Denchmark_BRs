<bug id='1632' author='huynhtnhut97' open_date='2019-03-19T16:43:28Z' closed_time='2020-08-31T23:16:04Z'>
	<summary>"OSError: Fail to write. Disk may be full" when create model for trainning</summary>
	<description>
Hi,
I'm using visdrone dataset for training a person/pedestrian detection model. Visdrone2018 train dataset has around 25k images and I'm using 14k for trainning. This is my structure for json file:
&lt;denchmark-link:https://user-images.githubusercontent.com/48727822/54623435-1179e480-4a9e-11e9-908f-8c7867821889.png&gt;&lt;/denchmark-link&gt;

Each line is an annotation for an image which contains many bounding boxes for 1 label. It's exactly like the structure of data requirements from docs.
The problem is when i loaded data to sframe variable and init a model with . During state "Using GPU to create model", it keeps failing beucause OSError.
This is my code for init a model:
  print ('-----------------------------------PREPARATION DATA-----------------------------------')
  #path = "/storageStudents/Datasets/VisDrone/VisDrone2018-VID-train/VisDrone2018-VID-train/annotations/*.txt"
  path = os.path.join(anno,"*.txt")
  files = glob.glob(path)

  data=[]
  print ('---------------------------------------------------------------------------------------------')
  print ('---------------------------------------------------------------------------------------------')
  print ('---------------------------------------------------------------------------------------------')

  train_imgs_dir = os.path.join(os.getcwd(),"image_train")

  raw_sf_train = tc.image_analysis.load_images(train_imgs_dir, recursive=False, random_order=False)

  # Split file names so that we can determine what kind of image each row is
  info_train = raw_sf_train['path'].apply(lambda path: os.path.basename(path).split('.')[:2])

  # Rename columns to 'name' and 'type'
  info_train = info_train.unpack().rename({'X.0': 'name', 'X.1': 'type'})

  # Add to our main SFrame
  raw_sf_train = raw_sf_train.add_columns(info_train)

  # Extract label (e.g. 'bike') from name (e.g. 'bike_003')
  raw_sf_train['label'] = 'person'

  # Original path no longer needed
  del raw_sf_train['path']
  del raw_sf_train['type']

  print ('------------------------LOAD DATA ANNOTATION TRAIN--------------------------')
  # Load the data
  train_data = SFrame.read_json(os.path.join(os.getcwd(),'data_train_visdrone.json'), orient='lines')
  train_annotations = SFrame(train_data)

                                          
  sf_train = raw_sf_train.join(train_annotations, on='name', how='right')

  sf_train['annotations'] = sf_train['annotations'].fillna([])

  sf_train['label'] = sf_train['label.1']
  sf_train = sf_train.remove_column('label.1')

  print ('------------------------PREPARE DATA COMPLETED--------------------------')
  
  # Create a model
  model = tc.object_detector.create(sf_train, feature='image', annotations='annotations', batch_size=16)

  file_name = 'ObjectDetectionVisdrone.model'
  
  # Save the model for later use in Turi Create
  model.save(file_name)
And i got this error:
&lt;denchmark-link:https://user-images.githubusercontent.com/48727822/54624785-a1b92900-4aa0-11e9-945e-448257474326.png&gt;&lt;/denchmark-link&gt;

Is there some setting that needs to be enabled for these memory issues?
	</description>
	<comments>
		<comment id='1' author='huynhtnhut97' date='2019-03-19T17:17:57Z'>
		I still have a large memory on disk space, so there is no sense about hard disk memory
&lt;denchmark-link:https://user-images.githubusercontent.com/48727822/54627234-99afb800-4aa5-11e9-9d86-0929e3f53619.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='huynhtnhut97' date='2019-03-22T06:11:53Z'>
		Any solution ?
		</comment>
		<comment id='3' author='huynhtnhut97' date='2019-03-22T16:57:22Z'>
		What do mean by "Each line is an annotation for an image which contains many bounding boxes for 1 label?" Do you mean that each image has many bounding boxes? Typically each annotation has exactly one bounding box and exactly one label.
The error is occurring in a part of our code where we convert the SFrame from having one row per image to having one row per image-annotation pair. As a sanity check, could you see what happens if you change your annotation column to have just one annotation per row (stored as a single dictionary, instead of a list of dictionaries)?
		</comment>
		<comment id='4' author='huynhtnhut97' date='2020-08-31T23:16:04Z'>
		I'm going to close this issue due to inactivity. Free feel to reopen with the requested information.
		</comment>
	</comments>
</bug>