<bug id='552' author='andremontenegrof' open_date='2018-04-25T23:55:45Z' closed_time='2018-06-12T16:59:25Z'>
	<summary>Object Detector training loss = NaN</summary>
	<description>
Hello, can you please suggest reasons that would make the value of the loss to start becoming NaN?
&lt;denchmark-code&gt;&gt;&gt;&gt; object_detector = tc.object_detector.create(test_data_392, annotations='annotations',feature='image',max_iterations=500,verbose=True)
2018-04-26 00:50:15  Training   1/500  Loss  6.347
2018-04-26 00:50:30  Training   2/500  Loss  6.344
2018-04-26 00:50:44  Training   3/500  Loss  6.265
2018-04-26 00:50:56  Training   4/500  Loss    nan
2018-04-26 00:51:08  Training   5/500  Loss    nan
2018-04-26 00:51:19  Training   6/500  Loss    nan
2018-04-26 00:51:35  Training   7/500  Loss    nan
2018-04-26 00:51:46  Training   8/500  Loss    nan
2018-04-26 00:51:58  Training   9/500  Loss    nan
2018-04-26 00:52:09  Training  10/500  Loss    nan
2018-04-26 00:52:20  Training  11/500  Loss    nan
2018-04-26 00:52:31  Training  12/500  Loss    nan
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='andremontenegrof' date='2018-04-26T03:44:44Z'>
		&lt;denchmark-link:https://github.com/gustavla&gt;@gustavla&lt;/denchmark-link&gt;
 I'm guessing the loss should never be . Seems like a bug?
		</comment>
		<comment id='2' author='andremontenegrof' date='2018-04-26T09:50:59Z'>
		I have capped the same annotations to 43 and nan is not appearing:
&lt;denchmark-code&gt;&gt;&gt;&gt; object_detector = tc.object_detector.create(test_data_43)
Using 'image' as feature column
Using 'annotations' as annotations column
2018-04-26 10:45:50  Training    1/1000  Loss  6.893
2018-04-26 10:46:01  Training    2/1000  Loss  6.828
2018-04-26 10:46:13  Training    3/1000  Loss  6.749
2018-04-26 10:46:24  Training    4/1000  Loss  6.648
2018-04-26 10:46:36  Training    5/1000  Loss  6.589
2018-04-26 10:46:48  Training    6/1000  Loss  6.472
2018-04-26 10:47:00  Training    7/1000  Loss  6.441
2018-04-26 10:47:11  Training    8/1000  Loss  6.374
2018-04-26 10:47:23  Training    9/1000  Loss  6.326
2018-04-26 10:47:34  Training   10/1000  Loss  6.244
2018-04-26 10:47:46  Training   11/1000  Loss  6.221
2018-04-26 10:47:57  Training   12/1000  Loss  6.206
2018-04-26 10:48:09  Training   13/1000  Loss  6.229

&lt;/denchmark-code&gt;

I have tried with 206 images and some warnings appeared:
&lt;denchmark-code&gt;&gt;&gt;&gt; object_detector = tc.object_detector.create(test_data_206)
Using 'image' as feature column
Using 'annotations' as annotations column
2018-04-26 10:52:09  Training    1/3000  Loss  6.182
2018-04-26 10:52:21  Training    2/3000  Loss  6.223
/Library/Python/2.7/site-packages/mxnet/image/detection.py:264: RuntimeWarning: invalid value encountered in divide
  coverage = self._calculate_areas(out[:, 1:]) * w * h / self._calculate_areas(label[:, 1:])
/Library/Python/2.7/site-packages/mxnet/image/detection.py:266: RuntimeWarning: invalid value encountered in greater
  valid = np.logical_and(valid, coverage &gt; self.min_eject_coverage)
2018-04-26 10:52:31  Training    3/3000  Loss  6.162
2018-04-26 10:52:42  Training    4/3000  Loss    nan
2018-04-26 10:52:54  Training    5/3000  Loss    nan
2018-04-26 10:53:05  Training    6/3000  Loss    nan
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='andremontenegrof' date='2018-05-01T03:09:28Z'>
		&lt;denchmark-link:https://github.com/andremontenegrof&gt;@andremontenegrof&lt;/denchmark-link&gt;
 Can you share your dataset by any chance. It seems like the divergence is a property of your dataset and we'd like to be able to trace it down.
		</comment>
		<comment id='4' author='andremontenegrof' date='2018-05-02T08:41:01Z'>
		&lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 can you please download it from: &lt;denchmark-link:https://www.dropbox.com/sh/v8659d7e2unwa35/AADg_4hr5hMM8fxdvu6MTDoMa?dl=0&gt;https://www.dropbox.com/sh/v8659d7e2unwa35/AADg_4hr5hMM8fxdvu6MTDoMa?dl=0&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='andremontenegrof' date='2018-05-07T09:02:45Z'>
		Hey &lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 please let me know if you have trouble downloading the dataset. Thanks!
		</comment>
		<comment id='6' author='andremontenegrof' date='2018-05-16T00:48:17Z'>
		&lt;denchmark-link:https://github.com/gustavla&gt;@gustavla&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/srikris&gt;@srikris&lt;/denchmark-link&gt;
 Sorry, I just found out I had some negative heights and widths.
After fixing that, the gradient stopped exploding.
I assumed some behaviour in the tool I used for annotation and this was the result :S
I have some negative x and y values. I don't know if that will be a problem for yolo as well.
		</comment>
		<comment id='7' author='andremontenegrof' date='2018-05-16T20:58:43Z'>
		&lt;denchmark-link:https://github.com/gustavla&gt;@gustavla&lt;/denchmark-link&gt;
 We should consider skipping data with bad bounding boxes.
		</comment>
		<comment id='8' author='andremontenegrof' date='2018-05-16T22:07:36Z'>
		Yes, we should definitely handle this better (I thought we did, but I don't see it anywhere in the code). Thanks for reporting this &lt;denchmark-link:https://github.com/andremontenegrof&gt;@andremontenegrof&lt;/denchmark-link&gt;
! I'll work on a fix.
		</comment>
		<comment id='9' author='andremontenegrof' date='2018-05-16T23:47:29Z'>
		Hey! I believe raising exception is better than silently skipping. For example, it is always great if we have the program telling us that the data in row 142 is invalid.
		</comment>
		<comment id='10' author='andremontenegrof' date='2018-05-17T00:02:35Z'>
		&lt;denchmark-link:https://github.com/andremontenegrof&gt;@andremontenegrof&lt;/denchmark-link&gt;
 Perhaps an eye-catching warning would be the way to go? Since this is a recoverable issue and the user has potentially been training for hundreds of iterations (or even more), then an exception caused by a single bad sample could be really frustrating.
For this to be effective though, we should probably have a mechanism that tracks warnings and then re-reports them or at least notifies the user to scroll up to read them once training completes. It doesn't matter how eye-catching it is if the user leaves the computer to let it run and it produces enough valid output after the warning to completely miss it.
		</comment>
		<comment id='11' author='andremontenegrof' date='2018-05-17T00:23:13Z'>
		&lt;denchmark-link:https://github.com/gustavla&gt;@gustavla&lt;/denchmark-link&gt;
 maybe we could do a quick single-pass over the images to check correctness of bounding boxes before training starts (and error out if the data is bad)?
		</comment>
		<comment id='12' author='andremontenegrof' date='2018-05-17T00:53:24Z'>
		&lt;denchmark-link:https://github.com/znation&gt;@znation&lt;/denchmark-link&gt;
 I like that idea!
		</comment>
		<comment id='13' author='andremontenegrof' date='2018-05-19T17:10:48Z'>
		Indeed an exception would only make sense in the beginning. To present a set of warnings at the end is also an elegant solution. Thank you!
		</comment>
	</comments>
</bug>