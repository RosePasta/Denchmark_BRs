<bug id='2773' author='guihao-liang' open_date='2019-12-03T00:12:54Z' closed_time='2019-12-04T05:16:55Z'>
	<summary>od 6.0 behaves inconsistent among different platforms</summary>
	<description>
&lt;denchmark-h:h1&gt;repro&lt;/denchmark-h&gt;


get a wheel of 6.0rc1 for python3.6
export weights on darwin and save it
scp the saved model to linux box
load the model and predict.

evaluation on darwin:
&lt;denchmark-code&gt;Using 'image' as feature column
Using 'annotations' as annotations column
Using GPU to create model (AMD Radeon Pro 560X)
Setting 'batch_size' to 32
+--------------+--------------+--------------+
| Iteration    | Loss         | Elapsed Time |
+--------------+--------------+--------------+
| 1            | 5.25522      | 1.29s        |
| 2            | 5.40305      | 2.16s        |
| 3            | 5.45075      | 3.10s        |
| 4            | 5.49147      | 3.96s        |
| 5            | 5.57757      | 4.91s        |
| 6            | 5.6226       | 5.77s        |
| 11           | 5.41964      | 10.34s       |
| 16           | 5.17099      | 14.81s       |
| 20           | 5.12047      | 18.99s       |
+--------------+--------------+--------------+
dump evaluation dictionary:
 {'average_precision': {'bike': 0.012373289093375206, 'carsgraz': 0.013162309303879738}, 'average_precision_50': {'bike': 0.07835809886455536, 'carsgraz': 0.06423525512218475}, 'mean_average_precision': 0.012767799198627472, 'mean_average_precision_50': 0.07129667699337006}
&lt;/denchmark-code&gt;

on ubuntu 16.04
&lt;denchmark-code&gt;{'average_precision': {'bike': 0.007338845171034336, 'carsgraz': 0.013124960474669933}, 'average_precision_50': {'bike': 0.04268103092908859, 'carsgraz': 0.06689130514860153}, 'mean_average_precision': 0.010231902822852135, 'mean_average_precision_50': 0.05478616803884506}
&lt;/denchmark-code&gt;

scripts to load model and save model is mentioned in &lt;denchmark-link:https://github.com/apple/turicreate/issues/2769&gt;#2769&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='guihao-liang' date='2019-12-03T00:15:08Z'>
		as always, 20 iterations. Since models on Darwin and Linux are using the same weights, we should expect a very similar result even though the training hasn't converged due to a small or insufficient iteration number.
		</comment>
	</comments>
</bug>