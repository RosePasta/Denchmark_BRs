<bug id='969' author='igiloh' open_date='2018-08-14T15:17:03Z' closed_time='2018-08-21T22:06:10Z'>
	<summary>Activity classifier should support test dataset with fewer unique labels than the training set</summary>
	<description>
As described in &lt;denchmark-link:https://github.com/apple/turicreate/issues/964&gt;#964&lt;/denchmark-link&gt;
 - the user has introduced larger number of labels in the test set than the number of labels the model have been trained on.
Instead of giving him an explicit error right during the  portion of  - he got a less intuitive error:
&lt;denchmark-code&gt;ToolkitError: Size of prediction probability vector(3) != number of classes(1)
&lt;/denchmark-code&gt;

We should probably detect these cases explicitly, right in the beginning of predict(), and give an informative error.
	</description>
	<comments>
		<comment id='1' author='igiloh' date='2018-08-17T16:12:41Z'>
		Actually, it looks like the opposite: the model was trained with three possible labels (hence the model outputting a prediction vector of size 3), but the dataset being evaluated only has 1 class. This should not generate an error at all and should just work.
		</comment>
		<comment id='2' author='igiloh' date='2018-08-17T16:14:20Z'>
		Ultimately this is due to these Python-based toolkits not inheriting all of the better-tested code paths from the C++ supervised-learning base classes.... It's possible that just printing a better error message is the correct fix in the short term, with the long-term fix to replace all of the Python code and move to C++.
		</comment>
		<comment id='3' author='igiloh' date='2018-08-18T00:00:21Z'>
		It turns out that this problem is not specific to the activity classifier: it's arguably an API bug in the evaluation toolkit. I filed &lt;denchmark-link:https://github.com/apple/turicreate/issues/1007&gt;#1007&lt;/denchmark-link&gt;
. For the purposes of the evaluate() method here, we can work around this issue by providing the class index map explicitly, instead of allowing the evaluation toolkit to infer it from the test-set labels.
		</comment>
	</comments>
</bug>