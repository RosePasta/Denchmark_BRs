<bug id='384' author='PietroMessineo' open_date='2018-03-19T17:40:51Z' closed_time='2018-04-01T07:09:55Z'>
	<summary>MemoryError</summary>
	<description>
Hi guys,
I'm encountering an error. While I'm doing the task "performing feature extraction on resized images..." on a dataset of more than 55K images at almost 19K I'm facing out this:
Traceback (most recent call last): File "export_model.py", line 10, in &lt;module&gt; model = tc.image_classifier.create(train_data, target='label', max_iterations=5000) File "/root/anaconda3/envs/my_env/lib/python2.7/site-packages/turicreate/toolkits/image_classifier/image_classifier.py", line 122, in create '__image_features__': feature_extractor.extract_features(dataset, feature, verbose=verbose), File "/root/anaconda3/envs/my_env/lib/python2.7/site-packages/turicreate/toolkits/_image_feature_extractor.py", line 111, in extract_features model.forward(next(dataIter)) File "/root/anaconda3/envs/my_env/lib/python2.7/site-packages/mxnet/io.py", line 219, in next if self.iter_next(): File "/root/anaconda3/envs/my_env/lib/python2.7/site-packages/turicreate/mx/_mx_sframe_iter.py", line 351, in iter_next self.data_ndarray = (self.data_ndarray - self._rgb_mask.asnumpy()) * self._scale MemoryError 
There is a way to fix it? I'm encountering this on a new VPS that I booked today.
Thank you !
	</description>
	<comments>
		<comment id='1' author='PietroMessineo' date='2018-03-20T17:03:02Z'>
		I am guessing the instance does not have too much memory? I suspect the combined memory pressure of SFrame cache and MXNet is causing memory issues.
Can you take a look at the value of:
&lt;denchmark-code&gt;tc.config.get_runtime_config('TURI_FILEIO_MAXIMUM_CACHE_CAPACITY')
&lt;/denchmark-code&gt;

It defaults to half of total system memory (in bytes). You can try lowering it further with:
&lt;denchmark-code&gt;tc.config.set_runtime_config('TURI_FILEIO_MAXIMUM_CACHE_CAPACITY', [memory in bytes])
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='PietroMessineo' date='2018-03-23T09:39:40Z'>
		I'm really sorry I forgot to reply to your message. Actually it is, the server was running out of memory because the swap wasn't enabled. So now I enabled the swap but there is another problem. I have now 73GB of Swap and the python script run since almost one day and the model is not exported yet.
Typing "top" I'm able to see that CPU is still working, have you an idea if it's stacked or something went wrong?
&lt;denchmark-link:https://user-images.githubusercontent.com/9380832/37826175-b608332c-2e92-11e8-805b-69e14c2fcb4d.png&gt;&lt;/denchmark-link&gt;

As explained on the first post I'm trying to train 55K images, but I haven't ever thought that could be so slow...
Thank you very much, and sorry again for the late reply.
		</comment>
		<comment id='3' author='PietroMessineo' date='2018-03-23T21:16:52Z'>
		Hi,
I recommend lowering the maximum cache capacity to maybe about 2GB. i.e.
&lt;denchmark-code&gt;tc.config.set_runtime_config('TURI_FILEIO_MAXIMUM_CACHE_CAPACITY', 2*1024*1024*1024)
&lt;/denchmark-code&gt;

Also, you don't need 5000 iterations in
&lt;denchmark-code&gt;tc.image_classifier.create(train_data, target='label', max_iterations=5000)
&lt;/denchmark-code&gt;

The optimizer used here is LBFGS. The default (~20-50 iterations) is sufficient.
Yucheng
		</comment>
		<comment id='4' author='PietroMessineo' date='2018-03-23T21:21:54Z'>
		Hi Ylow,
I’ll do the modifications to the capacity that you are advising to me. For what about the iterations, if I’m setting just 20 or 50 iterations it will return to me that the model may not be optimal and to increase “max iterations” and it will automatically kill without save the model.
Something that I could do? Thanks!
		</comment>
		<comment id='5' author='PietroMessineo' date='2018-03-23T21:23:43Z'>
		It will print a warning that "model may not be optimal". But it will still return a useable model.
		</comment>
		<comment id='6' author='PietroMessineo' date='2018-03-23T21:25:58Z'>
		Really? I need to try again... it was returning to me after the warning “killed 9”... probably it was running out of space! Ill try to set as max iterations 50 and I’ll let you know ! Thank you!
		</comment>
		<comment id='7' author='PietroMessineo' date='2018-03-24T13:18:55Z'>
		Hi Ylow,
I'm still facing out some problems. This is my code, is it placed (tc.config.set_runtime_config('TURI_FILEIO_MAXIMUM_CACHE_CAPACITY', 210241024*1024))  in a wrong way? Could you help me? Thank you!
&lt;denchmark-code&gt;import turicreate as tc

# Load the data
data = tc.SFrame('alfa.sframe')

# Make a train-test split
train_data, test_data = data.random_split(0.8)

tc.config.set_runtime_config('TURI_FILEIO_MAXIMUM_CACHE_CAPACITY', 2*1024*1024*1024)

# Create a model
model = tc.image_classifier.create(train_data, target='label', max_iterations=50)

# Save predictions to an SFrame (class and corresponding class-probabilities)
predictions = model.classify(test_data)

# Evaluate the model and save the results into a dictionary
results = model.evaluate(test_data)
print "Accuracy         : %s" % results['accuracy']
print "Confusion Matrix : \n%s" % results['confusion_matrix']

# Save the model for later usage in Turi Create
model.save('Alfa2.model')
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='PietroMessineo' date='2018-03-25T00:28:58Z'>
		Where is it failing?
		</comment>
		<comment id='9' author='PietroMessineo' date='2018-03-25T07:02:11Z'>
		Is not failing but its appearing the warning that the model maybe not optimal and it’s not exporting the model... staying stacked for hours.
I tested it with 5K images and everything was fine, when I’m increasing dataset from 5 to 55K images I’m encountering the problem. CPU and RAM are in anyway working so the program is not stacked it seems.
If you can say to me that’s normal and that I need to wait days that’s it, I’ll do it.
Thank you very much!!
		</comment>
	</comments>
</bug>