<bug id='11' author='joschu' open_date='2017-10-23T19:01:38Z' closed_time='2017-10-24T16:24:37Z'>
	<summary>PPO reference</summary>
	<description>
This library looks great -- beautiful work.
The proper reference for PPO is the arxiv paper from my coauthors and me (&lt;denchmark-link:https://arxiv.org/abs/1707.06347&gt;https://arxiv.org/abs/1707.06347&lt;/denchmark-link&gt;
). As acknowledged by Heess et al. in their DPPO paper, their algorithm was based on my github code, which didn't have a corresponding publication at the time.
	</description>
	<comments>
		<comment id='1' author='joschu' date='2017-10-24T14:14:29Z'>
		Hi John,
Glad you liked the framework.
Thanks a lot, we are great fans of your work!
Sorry for the confusion.
It is fixed now in the GitHub repo &lt;denchmark-link:https://github.com/IntelLabs/coach/commit/eb0b57d7fad541e59c9a0fce09ec1a9a6e11ec4b&gt;eb0b57d&lt;/denchmark-link&gt;
, and should also be fixed at &lt;denchmark-link:http://coach.nervanasys.com&gt;http://coach.nervanasys.com&lt;/denchmark-link&gt;
 and in the &lt;denchmark-link:https://www.intelnervana.com/reinforcement-learning-coach-intel/&gt;blog post&lt;/denchmark-link&gt;
 in a day or two.
		</comment>
		<comment id='2' author='joschu' date='2017-10-24T16:24:37Z'>
		Great, thanks!
		</comment>
	</comments>
</bug>