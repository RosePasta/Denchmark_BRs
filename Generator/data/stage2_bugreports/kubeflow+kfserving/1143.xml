<bug id='1143' author='kd303' open_date='2020-10-19T14:48:56Z' closed_time='2020-10-27T11:02:03Z'>
	<summary>Kubeflow KfServing "Ingress Notconfigured"</summary>
	<description>
/kind bug

Installed &lt;denchmark-link:https://github.com/kubeflow/kfserving/tree/master/docs/samples/sklearn&gt;https://github.com/kubeflow/kfserving/tree/master/docs/samples/sklearn&lt;/denchmark-link&gt;
 in on-premise Kubernetes cluster
Created a sample services, all containers are up and running (istio-init, sklearnserving, storageInitizer etc).
I have installed default Kfserving with kubeflow cluster
What did you expect to happen:
I expect the inference service to be in "ready" state

[Miscellaneous information that will assist in solving the issue.]
Followed the debugging &lt;denchmark-link:https://github.com/kubeflow/kfserving/blob/master/docs/KFSERVING_DEBUG_GUIDE.md&gt;guide&lt;/denchmark-link&gt;

Running kvc:
&lt;denchmark-code&gt;kubectl get ksvc
sklearn-v4-predictor-default                 http://sklearn-v4-predictor-default.mmskubeflow.example.com                 sklearn-v4-predictor-default-psfnl                 sklearn-v4-predictor-default-psfnl                 Unknown   IngressNotConfigured
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;NAME                                          GATEWAYS                                                            HOSTS                                                                                                                                                                                                                                                             AGE
sklearn-v4-predictor-default                      [knative-serving/cluster-local-gateway kubeflow/kubeflow-gateway]   [sklearn-v4-predictor-default.mmskubeflow sklearn-v4-predictor-default.mmskubeflow.example.com sklearn-v4-predictor-default.mmskubeflow.svc sklearn-v4-predictor-default.mmskubeflow.svc.cluster.local]                                                           144m
sklearn-v4-predictor-default-mesh                 [mesh]                                                              [sklearn-v4-predictor-default.mmskubeflow sklearn-v4-predictor-default.mmskubeflow.svc sklearn-v4-predictor-default.mmskubeflow.svc.cluster.local]
&lt;/denchmark-code&gt;

Please note this particular step kubectl get vs sklearn-iris -oyaml,
I dont have such VS, my VS is created as below named..
&lt;denchmark-code&gt;kubectl get vs sklearn-v4-predictor-default -oyaml -nmmskubeflow
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  annotations:
    networking.knative.dev/ingress.class: istio.ingress.networking.knative.dev
    serving.knative.dev/creator: system:serviceaccount:kubeflow:default
    serving.knative.dev/lastModifier: system:serviceaccount:kubeflow:default
  creationTimestamp: "2020-10-19T11:42:26Z"
  generation: 1
  labels:
    serving.knative.dev/route: sklearn-v4-predictor-default
    serving.knative.dev/routeNamespace: mmskubeflow
  name: sklearn-v4-predictor-default
  namespace: mmskubeflow
  ownerReferences:
  - apiVersion: networking.internal.knative.dev/v1alpha1
    blockOwnerDeletion: true
    controller: true
    kind: Ingress
    name: sklearn-v4-predictor-default
    uid: 090c2335-738c-4032-b5e1-c7af26347082
  resourceVersion: "1698016"
  selfLink: /apis/networking.istio.io/v1alpha3/namespaces/mmskubeflow/virtualservices/sklearn-v4-predictor-default
  uid: d4ea70ab-a2d0-43ef-b2fa-10bbc9a10bd9
spec:
  gateways:
  - knative-serving/cluster-local-gateway
  - kubeflow/kubeflow-gateway
  hosts:
  - sklearn-v4-predictor-default.mmskubeflow
  - sklearn-v4-predictor-default.mmskubeflow.example.com
  - sklearn-v4-predictor-default.mmskubeflow.svc
  - sklearn-v4-predictor-default.mmskubeflow.svc.cluster.local
  http:
  - headers:
      request:
        add:
          K-Network-Hash: 9bb7416d50664fcb41a24403ced6c44d
    match:
    - authority:
        prefix: sklearn-v4-predictor-default.mmskubeflow.example.com
      gateways:
      - kubeflow/kubeflow-gateway
    - authority:
        prefix: sklearn-v4-predictor-default.mmskubeflow
      gateways:
      - knative-serving/cluster-local-gateway
    retries:
      attempts: 3
      perTryTimeout: 600s
    route:
    - destination:
        host: sklearn-v4-predictor-default-psfnl.mmskubeflow.svc.cluster.local
        port:
          number: 80
      headers:
        request:
          add:
            Knative-Serving-Namespace: mmskubeflow
            Knative-Serving-Revision: sklearn-v4-predictor-default-psfnl
      weight: 100
    timeout: 600s
    websocketUpgrade: true
&lt;/denchmark-code&gt;


Installed using - &lt;denchmark-link:https://github.com/kubeflow/kfctl/releases/tag/v1.1.0&gt;https://github.com/kubeflow/kfctl/releases/tag/v1.1.0&lt;/denchmark-link&gt;


Istio Version:
Knative Version:
KFServing Version:
Kubeflow version:
Kfdef:[k8s_istio/istio_dex/gcp_basic_auth/gcp_iap/aws/aws_cognito/ibm]
Minikube version: NA
Kubernetes version: (use kubectl version):
Client Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.3", GitCommit:"2e7996e3e2712684bc73f0dec0200d64eec7fe40", GitTreeState:"clean", BuildDate:"2020-05-20T12:52:00Z", GoVersion:"go1.13.9", Compiler:"gc", Platform:"windows/amd64"}
Server Version: version.Info{Major:"1", Minor:"15", GitVersion:"v1.15.6", GitCommit:"7015f71e75f670eb9e7ebd4b5749639d42e20079", GitTreeState:"clean", BuildDate:"2019-11-13T11:11:50Z", GoVersion:"go1.12.12", Compiler:"gc", Platform:"linux/amd64"}
OS (e.g. from /etc/os-release):

	</description>
	<comments>
		<comment id='1' author='kd303' date='2020-10-19T14:49:05Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




area/inference
1.00



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://label-bot-prod.mlbot.net/data/kubeflow/kfserving&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='kd303' date='2020-10-19T14:49:26Z'>
		closingm will submit with appropriate logs.
		</comment>
		<comment id='3' author='kd303' date='2020-10-19T20:46:14Z'>
		&lt;denchmark-link:https://github.com/kd303&gt;@kd303&lt;/denchmark-link&gt;
 virtual service  is only created after the underlying ksvc is healthy, looks like somehow the knative probes to your ingress gateway is failing, can you check the  pod log following the debugging guide?
		</comment>
		<comment id='4' author='kd303' date='2020-10-20T04:55:05Z'>
		&lt;denchmark-link:https://github.com/yuzisun&gt;@yuzisun&lt;/denchmark-link&gt;
 I have pasted the logs in original issue log, the ksvc is showing as "IngressNotConfigured", below are the logs from  pod
the status probe is giving the error, however I am not able to figure out why. the said service exists.. see the output
&lt;denchmark-code&gt;{"level":"error","ts":"2020-10-20T04:49:20.342Z","logger":"istiocontroller.ingress-controller.status-manager","caller":"ingress/status.go:365","msg":"Probing of http://sklearn-v4-predictor-default.mmskubeflow.svc:80/ failed, IP: 10.244.3.14:80, ready: false, error: error roundtripping http://sklearn-v4-predictor-default.mmskubeflow.svc:80/: dial tcp 10.244.3.14:80: connect: cannot assign requested address (depth: 0)","commit":"c9be0ab","knative.dev/controller":"ingress-controller","stacktrace":"knative.dev/serving/pkg/reconciler/ingress.(*StatusProber).processWorkItem\n\t/home/prow/go/src/knative.dev/serving/pkg/reconciler/ingress/status.go:365\nknative.dev/serving/pkg/reconciler/ingress.(*StatusProber).Start.func1\n\t/home/prow/go/src/knative.dev/serving/pkg/reconciler/ingress/status.go:268"} 
&lt;/denchmark-code&gt;

Please see the out of kubectl get svc -nmmskubeflow
&lt;denchmark-code&gt;sklearn-v4-predictor-default                               ExternalName   &lt;none&gt;           sklearn-v4-predictor-default.mmskubeflow.example.com   &lt;none&gt;                              17h
sklearn-v4-predictor-default-psfnl                         ClusterIP      10.106.87.168    &lt;none&gt;                                                 80/TCP                              17h
sklearn-v4-predictor-default-psfnl-private                 ClusterIP      10.96.52.164     &lt;none&gt;                                                 80/TCP,9090/TCP,9091/TCP,8022/TCP   17h
&lt;/denchmark-code&gt;

Not an expert here but the external name has example.com domain in it, not sure where that is coming from. Also in the probe url same does not exists.. does the probe calls via external name or internal name?
		</comment>
		<comment id='5' author='kd303' date='2020-10-20T06:17:35Z'>
		Apologies for flooding this tickets with logs, but I am trying this for last 4 days without any luck, multiple times I have gone through the debugging guide, any help would be appreciated, it is saying PredictorHostNameUnknown - is this something to worry about? :
&lt;denchmark-code&gt;apiVersion: serving.kubeflow.org/v1alpha2
kind: InferenceService
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"serving.kubeflow.org/v1alpha2","kind":"InferenceService","metadata":{"annotations":{},"name":"sklearn-v4","namespace":"mmskubeflow"},"spec":{"default":{"predictor":{"serviceAccountName":"miniosa","sklearn":{"storageUri":"s3://mms-objects/models/sklearn/iris"}}}}}
  creationTimestamp: "2020-10-19T11:41:56Z"
  generation: 1
  name: sklearn-v4
  namespace: mmskubeflow
  resourceVersion: "1698025"
  selfLink: /apis/serving.kubeflow.org/v1alpha2/namespaces/mmskubeflow/inferenceservices/sklearn-v4
  uid: 2a4d6bd5-e83e-4631-8888-6c6a80ad98f8
spec:
  default:
    predictor:
      serviceAccountName: miniosa
      sklearn:
        resources:
          limits:
            cpu: "1"
            memory: 2Gi
          requests:
            cpu: "1"
            memory: 2Gi
        runtimeVersion: v0.3.0
        storageUri: s3://mms-objects/models/sklearn/iris
status:
  canary: {}
  conditions:
  - lastTransitionTime: "2020-10-19T11:42:26Z"
    message: Ingress has not yet been reconciled.
    **reason: IngressNotConfigured**
    status: Unknown
    type: DefaultPredictorReady
  - lastTransitionTime: "2020-10-19T11:41:56Z"
    message: Failed to reconcile predictor
    **reason: PredictorHostnameUnknown**
    status: "False"
    type: Ready
  - lastTransitionTime: "2020-10-19T11:41:56Z"
    message: Failed to reconcile predictor
    **reason: PredictorHostnameUnknown**
    status: "False"
    type: RoutesReady
  default:
    predictor:
      name: sklearn-v4-predictor-default-psfnl
&lt;/denchmark-code&gt;

Revisions are running fine
&lt;denchmark-code&gt;kubectl get revision sklearn-v4-predictor-default-psfnl -nmmskubeflow
NAME                                 CONFIG NAME                    K8S SERVICE NAME                     GENERATION   READY   REASON
sklearn-v4-predictor-default-psfnl   sklearn-v4-predictor-default   sklearn-v4-predictor-default-psfnl   1            True
&lt;/denchmark-code&gt;

Configuration
&lt;denchmark-code&gt;kubectl get configuration sklearn-v4-predictor-default -nmmskubeflow
NAME                           LATESTCREATED                        LATESTREADY                          READY   REASON
sklearn-v4-predictor-default   sklearn-v4-predictor-default-psfnl   sklearn-v4-predictor-default-psfnl   True
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;kubectl describe configuration sklearn-v4-predictor-default -nmmskubeflow
Name:         sklearn-v4-predictor-default
Namespace:    mmskubeflow
Labels:       serving.knative.dev/route=sklearn-v4-predictor-default
              serving.knative.dev/service=sklearn-v4-predictor-default
Annotations:  serving.knative.dev/creator: system:serviceaccount:kubeflow:default
              serving.knative.dev/lastModifier: system:serviceaccount:kubeflow:default
API Version:  serving.knative.dev/v1
Kind:         Configuration
Metadata:
  Creation Timestamp:  2020-10-19T11:41:57Z
  Generation:          1
  Owner References:
    API Version:           serving.knative.dev/v1alpha1
    Block Owner Deletion:  true
    Controller:            true
    Kind:                  Service
    Name:                  sklearn-v4-predictor-default
    UID:                   f4f754ef-96a5-4b87-b2af-a1b0fc7ddb72
  Resource Version:        1698000
  Self Link:               /apis/serving.knative.dev/v1/namespaces/mmskubeflow/configurations/sklearn-v4-predictor-default
  UID:                     08adbb9f-09fe-4247-9d14-f11bd87ddce5
Spec:
  Template:
    Metadata:
      Annotations:
        autoscaling.knative.dev/class:                                kpa.autoscaling.knative.dev
        autoscaling.knative.dev/minScale:                             1
        autoscaling.knative.dev/target:                               1
        internal.serving.kubeflow.org/storage-initializer-sourceuri:  s3://mms-objects/models/sklearn/iris
        queue.sidecar.serving.knative.dev/resourcePercentage:         20
      Creation Timestamp:                                             &lt;nil&gt;
      Labels:
        Component:                              predictor
        Endpoint:                               default
        Model:                                  sklearn-v4
        serving.kubeflow.org/inferenceservice:  sklearn-v4
    Spec:
      Container Concurrency:  0
      Containers:
        Args:
          --model_name=sklearn-v4
          --model_dir=/mnt/models
          --http_port=8080
        Env:
          Name:  AWS_ACCESS_KEY_ID
          Value From:
            Secret Key Ref:
              Key:   awsAccessKeyID
              Name:  minio-secret
          Name:      AWS_SECRET_ACCESS_KEY
          Value From:
            Secret Key Ref:
              Key:   awsSecretAccessKey
              Name:  minio-secret
          Name:      S3_USE_HTTPS
          Value:     0
          Name:      S3_ENDPOINT
          Value:     minio-service.kubeflow:9000
          Name:      AWS_ENDPOINT_URL
          Value:     http://minio-service.kubeflow:9000
        Image:       gcr.io/kfserving/sklearnserver:v0.3.0
        Name:        kfserving-container
        Readiness Probe:
          Success Threshold:  1
          Tcp Socket:
            Port:  0
        Resources:
          Limits:
            Cpu:     1
            Memory:  2Gi
          Requests:
            Cpu:             1
            Memory:          2Gi
      Service Account Name:  miniosa
      Timeout Seconds:       60
Status:
  Conditions:
    Last Transition Time:        2020-10-19T11:42:30Z
    Status:                      True
    Type:                        Ready
  Latest Created Revision Name:  sklearn-v4-predictor-default-psfnl
  Latest Ready Revision Name:    sklearn-v4-predictor-default-psfnl
  Observed Generation:           1
Events:                          &lt;none&gt;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='kd303' date='2020-10-21T09:24:21Z'>
		Now my ingress has reconciled and service is looking up (after redeployment of IngressGateway/isito-networking) - mistry though is I was busy doing something else and then suddenly I see the services up...
Now my IngressGateway does not have an external IP, that is published as NodePort (port 80 i.e.)
when I run POST request I get 404 (ingress node port &amp; IP)
		</comment>
		<comment id='7' author='kd303' date='2020-10-21T14:35:01Z'>
		Linking issue &lt;denchmark-link:https://github.com/kubeflow/kfserving/issues/1153&gt;#1153&lt;/denchmark-link&gt;
 as both are same. The only way services are turning to ready state is by re-starting networking-istio and cluster-local-gateway pods.
		</comment>
		<comment id='8' author='kd303' date='2020-10-23T13:10:49Z'>
		&lt;denchmark-link:https://github.com/kd303&gt;@kd303&lt;/denchmark-link&gt;
 let's work out the issue on &lt;denchmark-link:https://github.com/kubeflow/kfserving/issues/1153&gt;#1153&lt;/denchmark-link&gt;
, can we close this one?
		</comment>
		<comment id='9' author='kd303' date='2020-10-26T11:48:32Z'>
		sure, pls close.
		</comment>
		<comment id='10' author='kd303' date='2020-10-27T11:02:21Z'>
		will be tracked as a part of &lt;denchmark-link:https://github.com/kubeflow/kfserving/issues/1153&gt;#1153&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>