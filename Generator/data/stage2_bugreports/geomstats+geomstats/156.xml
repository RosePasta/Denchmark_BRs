<bug id='156' author='farrell236' open_date='2018-10-17T10:44:18Z' closed_time='2020-04-21T21:30:20Z'>
	<summary>special_orthogonal_group.py unit tests</summary>
	<description>
I have tried running the unit test for special_orthogonal_group.py with the tensorflow backend by enabling:
&lt;denchmark-code&gt;import os
os.environ['GEOMSTATS_BACKEND'] = 'tensorflow'  # NOQA

import tensorflow as tf
tf.enable_eager_execution()
&lt;/denchmark-code&gt;

However it fails 100% of the tests. I have started to fix some, and have some passing, but it seems there are still a lot to do. Most failures are backend issues such as incorrect of use of syntax (i.e. addressing and assigning tensor elements: someArray[someIndex] = someValue), this is not available in tensorflow. This may be allowed in pyTorch but I think it does a mem-copy from gpu to cpu, does the operation and then copy it back to the gpu. If case, then the overhead would make it very inefficient.
I have also noticed that the code is made to be generalised to nD, but there are special implementations for SO(2), SO(3), SE(2) and SE(3) cases. For example in &lt;denchmark-link:https://github.com/geomstats/geomstats/blob/a4e753f110618f718099758f96f38aa02e3a41b4/geomstats/special_orthogonal_group.py#L316&gt;skew_matrix_from_vector()&lt;/denchmark-link&gt;
, we can have a  and  and .
&lt;denchmark-code&gt;        if self.n == 2: # SO(2)
            id_skew = gs.array([[[0., 1.], [-1., 0.]]] * n_vecs)
            skew_mat = gs.einsum('nij,ni-&gt;nij', gs.cast(id_skew, gs.float32), vec)
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/geomstats/geomstats/blob/a4e753f110618f718099758f96f38aa02e3a41b4/tests/test_special_orthogonal_group.py#L207&gt;test_regularize()&lt;/denchmark-link&gt;
 fails &lt;denchmark-link:https://github.com/geomstats/geomstats/blob/a4e753f110618f718099758f96f38aa02e3a41b4/tests/test_special_orthogonal_group.py#L260&gt;here&lt;/denchmark-link&gt;
 on the SO(3) case. It seems the CPU and GPU machine precision is different. Running on numpy, the 0 value is in the order of e-8 where as its e-7 on GPU.
Let me know your thoughts, and how about we should go to fix these :)
	</description>
	<comments>
		<comment id='1' author='farrell236' date='2018-10-17T14:58:10Z'>
		Hi, I did some progress on tf for SOn, I just pushed the corresponding branch: nina-son-tf. It might fix some of your issues? Do you want to take it from there?
Cheers!
		</comment>
		<comment id='2' author='farrell236' date='2018-10-17T15:13:25Z'>
		Thanks! I'll take a look. Shall I make future pull requests to this branch?
		</comment>
		<comment id='3' author='farrell236' date='2018-10-17T23:05:51Z'>
		You can directly submit a PR of this (updated) branch to master, even if only a subset of the unit tests are running. What do you think?
		</comment>
		<comment id='4' author='farrell236' date='2018-10-17T23:11:33Z'>
		Sounds like a good idea. I'll make sure it always pass the unit test for numpy, and then bit by bit commit the changes for tensorflow.
I'll aim to make changes for the dimensions n=2 and n=3. For nD, I don't think it'll be commonly used so we can leave it numpy only for now(?).
		</comment>
		<comment id='5' author='farrell236' date='2018-10-17T23:21:07Z'>
		Perfect, thank you.
Yes, let's focus on n=2 and n=3 only for now!
		</comment>
		<comment id='6' author='farrell236' date='2020-04-21T21:30:20Z'>
		This issue is outdated, as most tests are now passing with tf and the ones that still don't have a decorator skipping them.
The implementation of SO(n) for any n is on-going.
		</comment>
	</comments>
</bug>