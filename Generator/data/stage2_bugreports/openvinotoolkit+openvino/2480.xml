<bug id='2480' author='lablabla' open_date='2020-10-01T07:52:42Z' closed_time='2020-11-15T17:53:34Z'>
	<summary>[Bug] OpenVINO adds wrong output name after conversion from ONNX</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenVINO=&gt; 2020.3.194
Operating System / Platform =&gt; Windows 10 64 bit
Compiler =&gt; N/A (python)
Problem classification =&gt; Model conversion
Framework: ONNX (opsets 9,10,11)
Model name: Custom YOLOv3

I've converted a (modified) Darknet model to onnx, (with opset 10 &amp; 11) and then converting this onnx model into IR using &lt;denchmark-link:https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_ONNX.html&gt;this (at the bottom)&lt;/denchmark-link&gt;

Everything seems to be OK
&lt;denchmark-code&gt;C:\Program Files (x86)\IntelSWTools\openvino_2020.3.194\deployment_tools\model_optimizer&gt;python mo.py --input_model C:\dev\yolo\weights\export.onnx --progress --output_dir C:\dev\yolo\weights\
Model Optimizer arguments:
Common parameters:
        - Path to the Input Model:      C:\dev\yolo\weights\export.onnx
        - Path for generated IR:        C:\dev\yolo\weights\
        - IR output name:       export
        - Log level:    ERROR
        - Batch:        Not specified, inherited from the model
        - Input layers:         Not specified, inherited from the model
        - Output layers:        Not specified, inherited from the model
        - Input shapes:         Not specified, inherited from the model
        - Mean values:  Not specified
        - Scale values:         Not specified
        - Scale factor:         Not specified
        - Precision of IR:      FP32
        - Enable fusing:        True
        - Enable grouped convolutions fusing:   True
        - Move mean values to preprocess section:       False
        - Reverse input channels:       False
ONNX specific parameters:
Model Optimizer version:
Progress: [....................] 100.00% done
[ SUCCESS ] Generated IR version 10 model.
[ SUCCESS ] XML file: C:\dev\yolo\weights\export.xml
[ SUCCESS ] BIN file: C:\dev\yolo\weights\export.bin
[ SUCCESS ] Total execution time: 10.24 seconds.
&lt;/denchmark-code&gt;

When I try to load this model using the provided YOLO sample from &lt;denchmark-link:https://docs.openvinotoolkit.org/2019_R1/_inference_engine_ie_bridges_python_sample_object_detection_demo_yolov3_async_README.html&gt;here&lt;/denchmark-link&gt;
, loading is fine, but when I inspect the net object in debug mode I see that the outputs are
,  and .
When I inspect the layers, I see it contains ,  and  (note, missing  in the split)
This causes the sample to fail with KeyError: 'Slice_230/Split.1' in object_detection_demo_yolov3_async.py line 233:
&lt;denchmark-code&gt;    for layer_name, out_blob in output.items():
        out_blob = out_blob.buffer.reshape(net.layers[net.layers[layer_name].parents[0]].out_data[0].shape)
&lt;/denchmark-code&gt;

If I inspect the IR's .XML file I don't see any .1 in it
&lt;denchmark-code&gt;		&lt;layer id="214" name="Slice_230/Split" type="VariadicSplit" version="opset1"&gt;
			&lt;input&gt;
				&lt;port id="0"&gt;
					&lt;dim&gt;6&lt;/dim&gt;
					&lt;dim&gt;142191&lt;/dim&gt;
				&lt;/port&gt;
				&lt;port id="1"/&gt;
				&lt;port id="2"&gt;
					&lt;dim&gt;3&lt;/dim&gt;
				&lt;/port&gt;
			&lt;/input&gt;
			&lt;output&gt;
				&lt;port id="3" precision="FP32"&gt;
					&lt;dim&gt;4&lt;/dim&gt;
					&lt;dim&gt;142191&lt;/dim&gt;
				&lt;/port&gt;
				&lt;port id="4" precision="FP32"&gt;
					&lt;dim&gt;1&lt;/dim&gt;
					&lt;dim&gt;142191&lt;/dim&gt;
				&lt;/port&gt;
				&lt;port id="5" precision="FP32"&gt;
					&lt;dim&gt;1&lt;/dim&gt;
					&lt;dim&gt;142191&lt;/dim&gt;
				&lt;/port&gt;
			&lt;/output&gt;
		&lt;/layer&gt;
&lt;/denchmark-code&gt;

Any suggestions where this .1 comes from?
When exporting using opset 9, the same thing happens only this time with Slice_174/Split &amp; Slice_174/Split.1
	</description>
	<comments>
		<comment id='1' author='lablabla' date='2020-10-01T08:02:42Z'>
		I've checked the ONNX &amp; the XML files in Netron and it seems that the offending output doesn't exists in the ONNX part, also, it's called fake_data_Slice_230/sink_port_0 in the XML one
XML:
&lt;denchmark-link:https://user-images.githubusercontent.com/1851781/94783535-81786300-03d5-11eb-8267-0798acc20d62.png&gt;&lt;/denchmark-link&gt;

ONNX:
&lt;denchmark-link:https://user-images.githubusercontent.com/1851781/94783610-9a811400-03d5-11eb-9ed5-dc65d5291a32.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='lablabla' date='2020-10-04T14:09:15Z'>
		Just updated to the latest OpenVINO version 2020.4.287 and the issue still exists
		</comment>
		<comment id='3' author='lablabla' date='2020-10-21T00:33:16Z'>
		&lt;denchmark-link:https://github.com/lablabla&gt;@lablabla&lt;/denchmark-link&gt;

1-) Could you try to use 2021.1 and let me know if you are still facing the issue?
2-) Can you attach the original ONNX model file for me to reproduce the issue?
".1" suffix comes from that Split is the multioutput operation and we have to add it to specify output port. So this is expected behavior.
3-) Could you also attach the error from the object detection demo that you are receiving?
		</comment>
		<comment id='4' author='lablabla' date='2020-10-21T09:58:34Z'>
		&lt;denchmark-link:https://github.com/agungor2&gt;@agungor2&lt;/denchmark-link&gt;
 Thanks
I just tried 2021.1 (optimizing using it, and using the samples) and it still happen
The full outputs is:
&lt;denchmark-code&gt;(open_vino_yolo) C:\Program Files (x86)\IntelSWTools\openvino_2021.1.110\deployment_tools\open_model_zoo\demos\python_demos\object_detection_demo_yolov3_async&gt;python object_detection_demo_yolov3_async.py -i "C:/dev/benchmark-example/sample-benchmarks/test_input.jpg" -m "C:/dev/yolo/weights/export.xml"
[ INFO ] Creating Inference Engine...
[ INFO ] Loading network
[ INFO ] Preparing inputs
MFX: Unsupported extension: C:/dev/benchmark-example/sample-benchmarks/test_input.jpg
[ INFO ] Loading model to the plugin
[ INFO ] Starting inference...
To close the application, press 'CTRL+C' here or switch to the output window and press ESC key
To switch between min_latency/user_specified modes, press TAB key in the output window
object_detection_demo_yolov3_async.py:228: DeprecationWarning: 'layers' property of IENetwork class is deprecated. For iteration over network please use get_ops()/get_ordered_ops() methods from nGraph Python API
  out_blob = out_blob.buffer.reshape(net.layers[net.layers[layer_name].parents[0]].out_data[0].shape)
Traceback (most recent call last):
  File "object_detection_demo_yolov3_async.py", line 490, in &lt;module&gt;
    sys.exit(main() or 0)
  File "object_detection_demo_yolov3_async.py", line 380, in main
    args.keep_aspect_ratio)
  File "object_detection_demo_yolov3_async.py", line 228, in get_objects
    out_blob = out_blob.buffer.reshape(net.layers[net.layers[layer_name].parents[0]].out_data[0].shape)
KeyError: 'Slice_230/Split.2'
&lt;/denchmark-code&gt;

Now the key error has Split.2 instead of Split.1, but maybe I did something wrong
this is the model optimizer output:
&lt;denchmark-code&gt;(open_vino_yolo) C:\Program Files (x86)\IntelSWTools\openvino_2021\deployment_tools\model_optimizer&gt;python mo.py --input_model C:\dev\yolo\weights\export.onnx --progress --output_dir C:\dev\yolo\weights\
Model Optimizer arguments:
Common parameters:
        - Path to the Input Model:      C:\dev\yolo\weights\export.onnx
        - Path for generated IR:        C:\dev\yolo\weights\
        - IR output name:       export
        - Log level:    ERROR
        - Batch:        Not specified, inherited from the model
        - Input layers:         Not specified, inherited from the model
        - Output layers:        Not specified, inherited from the model
        - Input shapes:         Not specified, inherited from the model
        - Mean values:  Not specified
        - Scale values:         Not specified
        - Scale factor:         Not specified
        - Precision of IR:      FP32
        - Enable fusing:        True
        - Enable grouped convolutions fusing:   True
        - Move mean values to preprocess section:       None
        - Reverse input channels:       False
ONNX specific parameters:
Model Optimizer version:        2021.1.0-1237-bece22ac675-releases/2021/1
Progress: [....................] 100.00% done
[ SUCCESS ] Generated IR version 10 model.
[ SUCCESS ] XML file: C:\dev\yolo\weights\export.xml
[ SUCCESS ] BIN file: C:\dev\yolo\weights\export.bin
[ SUCCESS ] Total execution time: 24.69 seconds.
&lt;/denchmark-code&gt;

The ONNX file can be downloaded from &lt;denchmark-link:https://drive.google.com/file/d/1_Yu6tpwn6JhjAqDi1sQOwonocoU1eC6e/view?usp=sharing&gt;https://drive.google.com/file/d/1_Yu6tpwn6JhjAqDi1sQOwonocoU1eC6e/view?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='lablabla' date='2020-10-30T23:38:26Z'>
		&lt;denchmark-link:https://github.com/lablabla&gt;@lablabla&lt;/denchmark-link&gt;
, Can you please run it with the &lt;denchmark-link:https://docs.openvinotoolkit.org/latest/openvino_inference_engine_samples_benchmark_app_README.html&gt;benchmark app&lt;/denchmark-link&gt;
 and let us know if you are still having issues with the 2021.1 release?
I am able to run the demo and benchmark app both with your models on windows and ubuntu.
		</comment>
		<comment id='6' author='lablabla' date='2020-11-01T06:35:12Z'>
		&lt;denchmark-link:https://github.com/agungor2&gt;@agungor2&lt;/denchmark-link&gt;

Running the benchmark app in python works
&lt;denchmark-code&gt;C:\Program Files (x86)\IntelSWTools\openvino_2021.1.110\deployment_tools\tools\benchmark_tool&gt;python benchmark_app.py -m "C:\dev\yolo\weights\export.xml" -i C:\dev\benchmark-example\sample-benchmarks\sample0.jpg
[Step 1/11] Parsing and validating input arguments
C:\Program Files (x86)\IntelSWTools\openvino_2021.1.110\python\python3.7\openvino\tools\benchmark\main.py:29: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(" -nstreams default value is determined automatically for a device. "
[ WARNING ]  -nstreams default value is determined automatically for a device. Although the automatic selection usually provides a reasonable performance, but it still may be non-optimal for some cases, for more information look at README. 
[Step 2/11] Loading Inference Engine
[ INFO ] InferenceEngine:
         API version............. 2.1.2021.1.0-1237-bece22ac675-releases/2021/1
[ INFO ] Device info
         CPU
         MKLDNNPlugin............ version 2.1
         Build................... 2021.1.0-1237-bece22ac675-releases/2021/1

[Step 3/11] Setting device configuration
[ WARNING ] -nstreams default value is determined automatically for CPU device. Although the automatic selection usually provides a reasonable performance,but it still may be non-optimal for some cases, for more information look at README.
[Step 4/11] Reading network files
[ INFO ] Read network took 180.50 ms
[Step 5/11] Resizing network to match image sizes and given batch
[ INFO ] Network batch size: 1
[Step 6/11] Configuring input of the model
[Step 7/11] Loading the model to the device
[ INFO ] Load network took 279.25 ms
[Step 8/11] Setting optimal runtime parameters
[Step 9/11] Creating infer requests and filling input blobs with images
[ INFO ] Network input 'input.1' precision U8, dimensions (NCHW): 1 3 1952 1184
C:\Program Files (x86)\IntelSWTools\openvino_2021.1.110\python\python3.7\openvino\tools\benchmark\utils\inputs_filling.py:93: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  images_to_be_used, len(image_files)))
[ WARNING ] Some image input files will be duplicated: 4 files are required, but only 1 were provided
[ INFO ] Infer Request 0 filling
[ INFO ] Prepare image C:\dev\benchmark-example\sample-benchmarks\sample0.jpg
[ WARNING ] Image is resized from ((3072, 5120)) to ((1952, 1184))
[ INFO ] Infer Request 1 filling
[ INFO ] Prepare image C:\dev\benchmark-example\sample-benchmarks\sample0.jpg
[ WARNING ] Image is resized from ((3072, 5120)) to ((1952, 1184))
[ INFO ] Infer Request 2 filling
[ INFO ] Prepare image C:\dev\benchmark-example\sample-benchmarks\sample0.jpg
[ WARNING ] Image is resized from ((3072, 5120)) to ((1952, 1184))
[ INFO ] Infer Request 3 filling
[ INFO ] Prepare image C:\dev\benchmark-example\sample-benchmarks\sample0.jpg
[ WARNING ] Image is resized from ((3072, 5120)) to ((1952, 1184))
[Step 10/11] Measuring performance (Start inference asyncronously, 4 inference requests using 4 streams for CPU, limits: 60000 ms duration)
[ INFO ] First inference took 403.20 ms
[Step 11/11] Dumping statistics report
Count:      304 iterations
Duration:   61271.90 ms
Latency:    816.82 ms
Throughput: 4.96 FPS
&lt;/denchmark-code&gt;

So for some reason the models just doesn't play well with the yolo sample
is there any difference between the way the benchmark app loads the models and the way the samples does?
or maybe the benchmark app just doesn't try to actually access the output layers so it doesn't access the non-existent Slice_236/Split.2 layer?
		</comment>
		<comment id='7' author='lablabla' date='2020-11-09T19:53:19Z'>
		&lt;denchmark-link:https://github.com/lablabla&gt;@lablabla&lt;/denchmark-link&gt;
, there is no difference from IE perspective.
Why do we get an additional output in IR?
When optimizing the model in MO we apply transformation that replaces the sequence of Slices consuming the same data with VariadicSplit operation, and for some cases when Slices doesn't slice all the data we have to add additional Result operations because of plugins limitations. So this additional Result operation is expected for now and we just have to ignore this output in inference results.
		</comment>
		<comment id='8' author='lablabla' date='2020-11-09T19:57:11Z'>
		&lt;denchmark-link:https://github.com/lablabla&gt;@lablabla&lt;/denchmark-link&gt;

After further analysis, we concluded the following:
&lt;denchmark-link:https://github.com/openvinotoolkit/open_model_zoo/blob/master/demos/python_demos/object_detection_demo_yolov3_async/README.md&gt;OMZ Async demo&lt;/denchmark-link&gt;
 expects model with YoloRegion as the final layer, while in this ONNX I see that postprocessing inserted after it, it returns 2 output - [142191,1] and [142191,4]. The demo is not adopted for this case and we do not have intentions to support this case right now (it requires different logic for output parsing in comparison with models in &lt;denchmark-link:https://github.com/openvinotoolkit/open_model_zoo&gt;OMZ&lt;/denchmark-link&gt;
).
Here some links which can be useful:
Demo readme, where noted that models should be downloaded using model downloader &lt;denchmark-link:https://github.com/openvinotoolkit/open_model_zoo/blob/master/demos/python_demos/object_detection_demo_yolov3_async/README.md&gt;https://github.com/openvinotoolkit/open_model_zoo/blob/master/demos/python_demos/object_detection_demo_yolov3_async/README.md&lt;/denchmark-link&gt;

list of models which officially supported by demo &lt;denchmark-link:https://github.com/openvinotoolkit/open_model_zoo/blob/master/demos/python_demos/object_detection_demo_yolov3_async/models.lst&gt;https://github.com/openvinotoolkit/open_model_zoo/blob/master/demos/python_demos/object_detection_demo_yolov3_async/models.lst&lt;/denchmark-link&gt;

description of output format for yolo v3 which expects demo &lt;denchmark-link:https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/yolo-v3-tf/yolo-v3-tf.md#output&gt;https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/yolo-v3-tf/yolo-v3-tf.md#output&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='lablabla' date='2020-11-15T17:53:34Z'>
		&lt;denchmark-link:https://github.com/agungor2&gt;@agungor2&lt;/denchmark-link&gt;

Thanks for you assistance.
I'll close the issue and try to use our model using our own pre &amp; post processing
Thanks again
		</comment>
	</comments>
</bug>