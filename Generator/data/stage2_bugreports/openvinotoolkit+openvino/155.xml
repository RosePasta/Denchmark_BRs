<bug id='155' author='xiaoheizi123' open_date='2019-05-20T11:48:52Z' closed_time='2020-07-20T13:03:31Z'>
	<summary>need help!  openvino_2019.1.094  uman_pose_estimation_demo  [ ERROR ] std::bad_alloc</summary>
	<description>
I download openvino from &lt;denchmark-link:url&gt;https://software.intel.com/zh-cn/openvino-toolkit&lt;/denchmark-link&gt;

Then, I convert a model .onnx to xml文件，python3 mo_onnx.py --input_model /data_openvino/model_23.onnx --input_shape [1,3,224,224]
get:
ONNX specific parameters:
Model Optimizer version: 	2019.1.0-341-gc9b66a2
[ SUCCESS ] Generated IR model.
[ SUCCESS ] XML file: /opt/intel/openvino_2019.1.094/deployment_tools/model_optimizer/./model_23.xml
[ SUCCESS ] BIN file: /opt/intel/openvino_2019.1.094/deployment_tools/model_optimizer/./model_23.bin
[ SUCCESS ] Total execution time: 19.00 seconds.
Then,
root@f920ae206f6f:/opt/intel/openvino_2019.1.094/deployment_tools/inference_engi
ne# /root/inference_engine_samples_build/intel64/Release/human_pose_estimation_demo -i luboshangke.mp4 -m ../model_optimizer/model_23.xml -d CPU
InferenceEngine:
API version ............ 1.6
Build .................. custom_releases/2019/R1_c9b66a26e4d65bb986bb740e73f58c6e9e84c7c2
[ INFO ] Parsing input parameters
[ INFO ] Parsing input parameters: before judge FLAGS_i
[ INFO ] Parsing input parameters: after judge FLAGS_i
[ INFO ] Parsing input parameters before return true
after cap read image
[ ERROR ] std::bad_alloc
Look forward for your help!!
	</description>
	<comments>
		<comment id='1' author='xiaoheizi123' date='2019-05-20T15:06:22Z'>
		Dear &lt;denchmark-link:https://github.com/xiaoheizi123&gt;@xiaoheizi123&lt;/denchmark-link&gt;

What is your onnx model ? Is it something publicly available ? Perhaps it's a Pytorch model ? Please give me details here. You can perhaps attach it as a *.zip file.
Thanks kindly,
Shubha
		</comment>
		<comment id='2' author='xiaoheizi123' date='2019-05-21T08:51:19Z'>
		thank u.
1 、The onnx model is exported from a pytorch model by ‘torch.onnx.export(model,dummy_input,filepath,verbose=True)’.
The pytorch model is trained from Alphapose,&lt;denchmark-link:url&gt;https://github.com/MVIG-SJTU/AlphaPose/tree/pytorch&lt;/denchmark-link&gt;
, the trained pytorch model file is model_23.pkl, the onnx model is model_23.onnx, they are all in &lt;denchmark-link:https://pan.baidu.com/s/1vWhJqLvyU5a-QiTC-zXiVw&gt;there.&lt;/denchmark-link&gt;
 ,the password is 'stdt'
2、Additionally, the human_pose_estimation_demo also cannot work with the publicly tensorflow model there. The project is &lt;denchmark-link:https://github.com/ildoonet/tf-pose-estimation&gt;here&lt;/denchmark-link&gt;
, by '$ cd models/graph/cmu
$ bash download.sh' , I get the graph_opt.pb. and I also get a error std::bad_alloc, as following:
&lt;denchmark-link:https://user-images.githubusercontent.com/25768851/58092132-e6c31e00-7bfd-11e9-99ef-48a8da96054a.jpg&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='xiaoheizi123' date='2019-05-23T01:03:51Z'>
		I found the bottom of the converted both .xml is different from human-pose-estimation-0001.xml. The graph_opt.xml layer don not have datas.
The graph_opt.pb is like this:
&lt;denchmark-link:https://user-images.githubusercontent.com/25768851/58218475-92bd5400-7d39-11e9-8d72-dfde989e13d9.jpg&gt;&lt;/denchmark-link&gt;

and the human-pose-estimation-0001.xml. is like this:
&lt;denchmark-link:https://user-images.githubusercontent.com/25768851/58218513-a8cb1480-7d39-11e9-8eec-2ff2be894445.jpg&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='xiaoheizi123' date='2019-05-28T21:24:00Z'>
		Dear &lt;denchmark-link:https://github.com/xiaoheizi123&gt;@xiaoheizi123&lt;/denchmark-link&gt;
,
I was not able to retrieve your models and scripts from &lt;denchmark-link:https://pan.baidu.com/s/1vWhJqLvyU5a-QiTC-zXiVw&gt;https://pan.baidu.com/s/1vWhJqLvyU5a-QiTC-zXiVw&lt;/denchmark-link&gt;
 because I don't have a Baidu account. Also &lt;denchmark-link:https://github.com/opencv/dldt/issues/url&gt;https://github.com/opencv/dldt/issues/url&lt;/denchmark-link&gt;
 is a bad link. Finally I was able to download a frozen tensorflow for tf-pose-estimation from here:
&lt;denchmark-link:http://www.mediafire.com/file/1pyjsjl0p93x27c/graph_freeze.pb&gt;http://www.mediafire.com/file/1pyjsjl0p93x27c/graph_freeze.pb&lt;/denchmark-link&gt;
 which is the same one mentioned in the download.sh (I have Windows so I can't run *.sh). Anyway, so I run the following mo command as you describe on 2019R1.1 and I get an error which indicates that there are unsupported layers in this model.

python "c:\Program Files (x86)\IntelSWTools\openvino_2019.1.148\deployment_tools\model_optimizer\mo_tf.py" --input_model graph_freeze.pb --input_shape [1,3,224,224]  --log_level DEBUG

serialize_network(graph, net, unsupported)
File "c:\Program Files (x86)\IntelSWTools\openvino_2019.1.148\deployment_tools\model_optimizer\mo\back\ie_ir_ver_2\emitter.py", line 344, in serialize_network
raise Error(str(e).replace('', '{} (id = {})'.format(node.soft_get('name'), node.id))) from e
mo.utils.error.Error: Error while emitting attributes for layer pool2_stage1 (id = 11). It usually means that there is unsupported pattern around this node or unsupported combination of attributes.
But it seems like you got your ONNX model converted fine, so that's good. Rather than point me to your Baidu drive can you kindly attach your stuff via *.zip to this github issue ?
The fact that you got Pytorch (through ONNX) converted OK while Tensorflow fails model optimizer is definitely odd and could be a bug.
Thanks,
Shubha
		</comment>
		<comment id='5' author='xiaoheizi123' date='2020-05-29T09:02:09Z'>
		&lt;denchmark-link:https://github.com/xiaoheizi123&gt;@xiaoheizi123&lt;/denchmark-link&gt;
 Can you try to use the last version of OpenVINO?
&lt;denchmark-link:https://github.com/dmitry-gorokhov&gt;@dmitry-gorokhov&lt;/denchmark-link&gt;
 FYI
		</comment>
		<comment id='6' author='xiaoheizi123' date='2020-07-20T13:03:31Z'>
		It seems that the issues is not actual anymore as no response. Closing it. Feel free to reopen it or create a new one.
		</comment>
	</comments>
</bug>