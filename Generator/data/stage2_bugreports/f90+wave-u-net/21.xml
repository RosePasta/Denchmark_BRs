<bug id='21' author='Jaesuny' open_date='2018-12-28T02:27:39Z' closed_time='2019-01-03T11:37:13Z'>
	<summary>Random seed</summary>
	<description>
Hello, I'm trying to find the validation set you used.
To split data into train/validation, you said you fixed the random seed.



Wave-U-Net/Training.py


         Line 208
      in
      55109a0






 # Pick 25 random songs for validation from MUSDB train set (this is always the same selection each time since we fix the random seed!) 





I found you defined random seed in config,



Wave-U-Net/Config.py


         Line 37
      in
      48fb1a2






 seed=1337 





but I couldn't find where this value is used.
Where was the random seed fixed?
Or, can you tell me the indices of validation split you used?
	</description>
	<comments>
		<comment id='1' author='Jaesuny' date='2018-12-28T21:54:08Z'>
		This appears confusing since the sacred package is doing a lot behind the scenes. See this page
&lt;denchmark-link:https://sacred.readthedocs.io/en/latest/randomness.html&gt;https://sacred.readthedocs.io/en/latest/randomness.html&lt;/denchmark-link&gt;

that explains that if you set a seed variable in the Sacred config, it will be used to initialise the RNG in python and also numpy. So Sacred takes care of setting up the RNG, and thus the 25 random songs are actually the same every time you recreate the dataset.
Does that clear everything up?
		</comment>
		<comment id='2' author='Jaesuny' date='2018-12-29T13:20:05Z'>
		Thanks!
		</comment>
		<comment id='3' author='Jaesuny' date='2018-12-30T15:18:51Z'>
		The seed value of Ingredient does not work.
I found another seed value generated randomly just below Configuration (modified, added, typechanged, doc):  by running following command.
$ python Training.py print_config with cfg.full_44KHz
Configuration (modified, added, typechanged, doc):
  seed = 350916074
  cfg:
    experiment_id = 259884
    seed = 1337
    model_config:                    # Base configuration
      augmentation = True
      batch_size = 16
      cache_size = 16
      context = True
      duration = 2
      epoch_it = 2000
      estimates_path = 'Source_Estimates'
      expected_sr = 44100
      filter_size = 15
      init_sup_sep_lr = 0.0001
      log_dir = 'logs'
      merge_filter_size = 5
      min_replacement_rate = 16
      model_base_dir = 'checkpoints'
      mono_downmix = False
      musdb_path = '/data/musdb18'
      network = 'unet'
      num_channels = 2
      num_frames = 16384
      num_initial_filters = 24
      num_layers = 12
      num_sources = 2
      num_workers = 6
      output_type = 'difference'
      raw_audio_loss = True
      task = 'voice'
      upsampling = 'learned'
      worse_epochs = 20
The seed value in the above is changed every time I run.
And sacred package seems to use this seed.
I think you have to set seed using ex.config in Training.py.
		</comment>
		<comment id='4' author='Jaesuny' date='2019-01-02T11:25:11Z'>
		Thanks for spotting this!! You are right, it worked before, but then I exported the configuration to Config.py and by introducing that "sub-configuration" it messed up setting the right seed!
I committed a new version into the repository containing a fix, on my end the seed is now set correctly and produces the same random number in the training code each time.
Could you please pull the newest version and check if it's solved on your end? Thanks!
		</comment>
		<comment id='5' author='Jaesuny' date='2019-01-03T11:37:13Z'>
		Fixed with the help of the generous &lt;denchmark-link:https://github.com/Jaesuny&gt;@Jaesuny&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>