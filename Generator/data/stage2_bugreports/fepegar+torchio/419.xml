<bug id='419' author='nicoloesch' open_date='2021-01-15T13:50:49Z' closed_time='2021-01-15T16:08:20Z'>
	<summary>Grid Sampler and Aggregator do not take the Protected Attribute _transform of a SubjectsDataset</summary>
	<description>
üêõBug
Hello, I am using TorchIO for some time now and this is my first "bug report". I'm currently setting my dataset up for inference and stumbled across the Grid Sampler and Aggregator (as stated by the Tutorials on Colab). In the Colab document, a single subject is selected from the whole SubjectsDataset in order to push it to the GridSampler.
However, I applied a specific lambda transformation in order to make the labels one hot. I encountered the error due to size mismatch of the target labels and the logits (due to the missing transformation increasing the channels from 1 to 4).
To reproduce
transform = self.compose_transformations(stage=stage, n_categories=n_categories)
subjects_dataset = tio.SubjectsDataset(subjects_list, transform=transform)

#with the following in reduced form

compose_transformations():
    transforms.append(tt.ZNormalization())
    transforms.append(
                tt.Lambda(lambda x: misc.make_one_hot(x, num_classes=n_categories), types_to_apply=[tio.LABEL]))

# and the creation of one validation subject
for idx in range(self.hparams.num_val_samples):
    _subject = subjects_dataset.subjects[idx]

    dataset = tio.inference.GridSampler(
        subject=_subject,
        patch_size=self.hparams.patch_size,
        patch_overlap=self.hparams.patch_overlap)

    aggregator.append(tio.inference.GridAggregator(dataset))
        data_loader.append(tod.DataLoader(dataset=dataset,
        batch_size=self.hparams.batch_size,
        num_workers=self.hparams.num_workers,
        pin_memory=self.hparams.pin_memory))
assert logits.shape == target.shape #1,4,16,16,16 vs. 1,1,16,16,16
AssertionError

Exception ignored in: &lt;function tqdm.__del__ at 0x7f2fef73a550&gt;
Traceback (most recent call last):
  File "/home/nico/.local/lib/python3.8/site-packages/tqdm/std.py", line 1090, in __del__
  File "/home/nico/.local/lib/python3.8/site-packages/tqdm/std.py", line 1303, in close
  File "/home/nico/.local/lib/python3.8/site-packages/tqdm/std.py", line 1481, in display
  File "/home/nico/.local/lib/python3.8/site-packages/tqdm/std.py", line 1093, in __repr__
  File "/home/nico/.local/lib/python3.8/site-packages/tqdm/std.py", line 1443, in format_dict
TypeError: cannot unpack non-iterable NoneType object

Process finished with exit code 1

Expected behavior
Applying the transformations in the process of training/validation as soon as Data is loaded.
Actual behavior
Due to "slicing" of the SubjectsDataset, the _transform attribute won't be passed to the GridSampler.
Workaround
Applying transform before passing it to the GridSampler.
TorchIO version
0.18.1 (i know it's not the most recent version)
I hope my report is detailed enough since it's my first post on GitHub :). Maybe just add it to the Documentation or the Colab, that one need to manually apply transformations if using only one subject (as required by the GridSampler)
	</description>
	<comments>
		<comment id='1' author='nicoloesch' date='2021-01-15T14:48:03Z'>
		Hi, &lt;denchmark-link:https://github.com/nicoloesch&gt;@nicoloesch&lt;/denchmark-link&gt;
. I would say it's a pretty good report for a first-time issue 
A couple of issues here:

In the Colab document

Which tutorial are you referring to?

I encountered the error

That seems to be a tqdm error. It would be helpful if you could include the full

a single subject is selected from the whole SubjectsDataset

There are multiple hypothetical ways you could get subjects from the SubjectsDataset:

Slicing: dataset[3:5]. This is not implemented.
Indexing: dataset[3]. This is the standard way. It is equivalent to dataset.__getitem__(3). If you read the code in SubjectsDataset.__getitem__, you'll see that the transform is applied before returning the subject
Indexing the internal subjects list, which is what you're doing: datasets.subjects[3].

You're directly accessing the attribute, therefore no transform is applied. The _transform attribute is not expected to be passed to the sampler, as it's not its responsibility to transform the input.
I am going to rename the subjects attribute to imply that it's private.

I applied a specific lambda transformation in order to make the labels one hot

Do you think it would be useful to have a new ToOneHot transform? In that case, we can work together to add it to TorchIO.
		</comment>
		<comment id='2' author='nicoloesch' date='2021-01-15T15:39:02Z'>
		Hi &lt;denchmark-link:https://github.com/fepegar&gt;@fepegar&lt;/denchmark-link&gt;
,
thank you so much for replying that quickly!

Which tutorial are you referring to?

I refer to the following Tutorial: &lt;denchmark-link:https://colab.research.google.com/github/fepegar/torchio-notebooks/blob/main/notebooks/TorchIO_tutorial.ipynb#scrollTo=SKu8k5Z2wkSD&gt;https://colab.research.google.com/github/fepegar/torchio-notebooks/blob/main/notebooks/TorchIO_tutorial.ipynb#scrollTo=SKu8k5Z2wkSD&lt;/denchmark-link&gt;
 and precisely the block for the patch-based sampling
validation_set = tio.SubjectsDataset(validation_subjects, transform=validation_transform) # a bit further up
sample = random.choice(validation_set)
Based on the functionality of random.choice i could have already figured the behavior so I'm sorry for making up this bug report. But i really appreciate your help and as well giving multiple ways of accessing individual elements of SubjectsDataset with the transformation. I checked it and it functions perfectly again!

Do you think it would be useful to have a new ToOneHot transform? In that case, we can work together to add it to TorchIO

This is our current approach to the OneHot Transformation.
def make_one_hot(int_labels, num_classes: int = -1):
    """Adjusted version expects CxDxWxH"""

    labels_type = int_labels.dtype
    int_labels = int_labels.squeeze().type(torch.long)
    one_hot = torch.nn.functional.one_hot(int_labels, num_classes=num_classes)  # num_classes ensures all categories are created.
    one_hot = one_hot.permute((3,) + tuple(range(0, int_labels.dim()))).type(labels_type)
&lt;denchmark-code&gt;return one_hot
&lt;/denchmark-code&gt;

In essence, we use the standard one_hot implementation of torch but reshape it to match our desired format BxCxVolume_dim so i would say there is not need to add another one_hot transformation to torchio, since everyone will probably tailor the transformation to their individual needs.
Kind regards,
Nico
		</comment>
		<comment id='3' author='nicoloesch' date='2021-01-15T16:08:19Z'>
		I'm glad it works now. Thanks for sharing your code for one hot! I think your choice of dimensions is very common, so I will probably add the transform soon. That will improve a bit our support for label maps (related to &lt;denchmark-link:https://github.com/fepegar/torchio/issues/400&gt;#400&lt;/denchmark-link&gt;
).
		</comment>
	</comments>
</bug>