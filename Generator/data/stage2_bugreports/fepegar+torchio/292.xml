<bug id='292' author='romainVala' open_date='2020-08-26T07:48:19Z' closed_time='2020-09-17T09:23:03Z'>
	<summary>3 test failling</summary>
	<description>
üêõBug
After un update of my python package I now get error on the following test
FAIL: test_with_zero_intensity (tests.transforms.augmentation.test_random_spike.TestRandomSpike)
FAIL: test_with_zero_spike (tests.transforms.augmentation.test_random_spike.TestRandomSpike)
FAIL: test_no_movement (tests.transforms.augmentation.test_random_motion.TestRandomMotion)
To reproduce
numpy                     1.19.1                   pypi_0    pypi
numpy-base                1.17.2           py37hde5b4d6_0
numpydoc                  1.1.0                      py_0
# Your code here
array=np.random.uniform(0,40,100)
transformed = np.fft.fftn(array)
fshift = np.fft.fftshift(transformed)
f_ishift = np.fft.ifftshift(fshift)
img_back = np.fft.ifftn(f_ishift)
np.max(array-np.abs(img_back))

# Your errors here
 1.4210854715202004e-14
Expected behavior
it is related to fft and fft inverse that now to not get the exact same number
Solution will be to replace
assert_array_equal with  des np.all_close
but may be it is due to something wrong in my python package ...
TorchIO version
0.17.34
	</description>
	<comments>
		<comment id='1' author='romainVala' date='2020-08-30T19:19:48Z'>
		Hello,
If I may add a similar bug that sometimes happens when running the tests with pytest:
FAILED transforms/test_transforms.py::TestTransforms::test_transforms_array
Coming from the bias field generation transform when a division by 0 occurs
@staticmethod
    def generate_bias_field(
            data: TypeData,
            order: int,
            coefficients: TypeData,
            ) -&gt; np.ndarray:
        # Create the bias field map using a linear combination of polynomial
        # functions and the coefficients previously sampled
        shape = np.array(data.shape[1:])  # first axis is channels
        half_shape = shape / 2
    
        ranges = [np.arange(-n, n) for n in half_shape]
    
        bias_field = np.zeros(shape)
        x_mesh, y_mesh, z_mesh = np.asarray(np.meshgrid(*ranges))
    
&gt;       x_mesh /= x_mesh.max()
E       FloatingPointError: divide by zero encountered in true_divide

../torchio/transforms/augmentation/intensity/random_bias_field.py:94: FloatingPointError
		</comment>
		<comment id='2' author='romainVala' date='2020-09-16T19:21:37Z'>
		Thank you both for reporting.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/romainVala&gt;@romainVala&lt;/denchmark-link&gt;

I agree that  should be used for these type of tests. However, I think a more efficient solution for us would be to leave the input as it was for the cases tested in those tests. What do you and &lt;denchmark-link:https://github.com/GFabien&gt;@GFabien&lt;/denchmark-link&gt;
 think?
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/GReguig&gt;@GReguig&lt;/denchmark-link&gt;

I think this is unrelated. It looks like RandomDownsample is making some dimensions 1 and RandomBiasField is not happy. I'll open a new issue and investigate. What version of TorchIO are you using?
		</comment>
		<comment id='3' author='romainVala' date='2020-09-17T08:29:20Z'>
		
I agree that assert_array_almost_equal should be used for these type of tests. However, I think a more efficient solution for us would be to leave the input as it was for the cases tested in those tests. What do you and @GFabien think?

Actually I'm not sure about that. In one hand, it's more effective and output will truly equal input if we leave the input untouched  when transforms are supposed to have no effect. On the other hand, it shows that the transform somehow behaves properly by not altering the input (or almost) when it is supposed to have no effect. What do you think?
		</comment>
		<comment id='4' author='romainVala' date='2020-09-17T08:32:30Z'>
		I think you are right. What's the point of using 0 intensity or 0 spikes anyway? I will just switch to assert_array_almost_equal in the tests.
		</comment>
		<comment id='5' author='romainVala' date='2020-09-17T09:27:48Z'>
		Fixed in v0.17.35.
		</comment>
	</comments>
</bug>