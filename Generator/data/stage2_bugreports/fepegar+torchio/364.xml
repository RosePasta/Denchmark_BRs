<bug id='364' author='9B8DY6' open_date='2020-12-01T02:44:04Z' closed_time='2020-12-01T09:38:24Z'>
	<summary>PatchSampler object is not callable</summary>
	<description>
üêõBug
TypeError: 'PatchSampler' object is not callable
To reproduce
### dataloader with queue ###
patch_size = 12
samples_per_volume = 3
max_queue_length = 300
training_batch_size = 32
validation_batch_size = 32


patches_training_set = torchio.Queue(
    subjects_dataset=training_set,
    max_length=max_queue_length,
    samples_per_volume=samples_per_volume,
    sampler=torchio.data.PatchSampler(patch_size),
    num_workers=0,
    shuffle_subjects=True,
    shuffle_patches=True,
)

patches_validation_set = torchio.Queue(
    subjects_dataset=validation_set,
    max_length=max_queue_length,
    samples_per_volume=samples_per_volume,
    sampler=torchio.data.PatchSampler(patch_size),
    num_workers=0,
    shuffle_subjects=False,
    shuffle_patches=False,
)

training_loader = torch.utils.data.DataLoader(
    patches_training_set, batch_size=training_batch_size)

validation_loader = torch.utils.data.DataLoader(
    patches_validation_set, batch_size=validation_batch_size)

#training

count = 0
loss_valid = np.array([])
iteration_list = []
loss_train = np.array([])

for epoch in range(num_epochs):
    count += 1
    i=0
    l_epoch=0
    
    for batch in training_loader:
        model.to(device).train()
        inputs_train = batch['mri'][DATA].to(device)
        target_train = (batch['age']/100.).float().to(device)
        i=i+1
        optimizer.zero_grad()
        outputs = model(inputs_train)
        target_train= target_train.reshape(-1,1)
        loss = error(outputs, target_train).to(device)
        l_epoch+=loss
        loss.backward()
        optimizer.step()
        
    loss_train = np.append(loss_train,l_epoch.cpu().detach().numpy()/i)
    print('epoch_train : ',count)
    print('train loss: ',loss_train[-1])
    print('outputs : ',outputs[:5])
    print('label : ',target_train[:5])
    torch.save(model.state_dict(), f'v0_patch_T1_reg_PD_new_1.pth')
        
    i=0
    l_epoch=0
    for batch in validation_loader:
      model.to(device).eval()
      inputs_test = batch['mri'][DATA].to(device)
      target_test = (batch['age']/100.).float().to(device)
      i=i+1
      outputs = model(inputs_test)
      target_test= target_test.reshape(-1,1)
      loss = error(outputs, target_test).to(device)
      l_epoch+=loss
    loss_valid = np.append(loss_valid,l_epoch.cpu().detach().numpy()/i)
    scheduler.step(loss_valid[-1])
    
    print('valid_epoch: {}  valid_loss: {} '.format(count, loss_valid[-1]))
    plt.plot(loss_train,label='train loss')
    plt.plot(loss_valid,label='valid loss')

    plt.legend(loc='upper right')
    plt.title('epoch: %d '%(epoch))
    plt.pause(.0001)

    print('train loss: ',loss_train[-1])
    print('valid loss: ',loss_valid[-1])
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-37-1b712dc4dcbb&gt; in &lt;module&gt;()
     13     l_epoch=0
     14 
---&gt; 15     for batch in training_loader:
     16         model.to(device).train()
     17         inputs_train = batch['mri'][DATA].to(device)

~\Anaconda3\envs\dyb\lib\site-packages\torch\utils\data\dataloader.py in __next__(self)
    343 
    344     def __next__(self):
--&gt; 345         data = self._next_data()
    346         self._num_yielded += 1
    347         if self._dataset_kind == _DatasetKind.Iterable and \

~\Anaconda3\envs\dyb\lib\site-packages\torch\utils\data\dataloader.py in _next_data(self)
    383     def _next_data(self):
    384         index = self._next_index()  # may raise StopIteration
--&gt; 385         data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
    386         if self._pin_memory:
    387             data = _utils.pin_memory.pin_memory(data)

~\Anaconda3\envs\dyb\lib\site-packages\torch\utils\data\_utils\fetch.py in fetch(self, possibly_batched_index)
     42     def fetch(self, possibly_batched_index):
     43         if self.auto_collation:
---&gt; 44             data = [self.dataset[idx] for idx in possibly_batched_index]
     45         else:
     46             data = self.dataset[possibly_batched_index]

~\Anaconda3\envs\dyb\lib\site-packages\torch\utils\data\_utils\fetch.py in &lt;listcomp&gt;(.0)
     42     def fetch(self, possibly_batched_index):
     43         if self.auto_collation:
---&gt; 44             data = [self.dataset[idx] for idx in possibly_batched_index]
     45         else:
     46             data = self.dataset[possibly_batched_index]

~\Anaconda3\envs\dyb\lib\site-packages\torchio\data\queue.py in __getitem__(self, _)
    104         if not self.patches_list:
    105             self.print('Patches list is empty.')
--&gt; 106             self.fill()
    107         sample_patch = self.patches_list.pop()
    108         self.num_sampled_patches += 1

~\Anaconda3\envs\dyb\lib\site-packages\torchio\data\queue.py in fill(self)
    160         for _ in iterable:
    161             subject_sample = self.get_next_subject_sample()
--&gt; 162             iterable = self.sampler(subject_sample)
    163             patches = list(islice(iterable, self.samples_per_volume))
    164             self.patches_list.extend(patches)

TypeError: 'PatchSampler' object is not callable
Expected behavior
Actual behavior
TorchIO version


0.17.0

      
	</description>
	<comments>
		<comment id='1' author='9B8DY6' date='2020-12-01T09:28:22Z'>
		Hi, &lt;denchmark-link:https://github.com/9B8DY6&gt;@9B8DY6&lt;/denchmark-link&gt;
.

Please use a more recent version of TorchIO: pip install --upgrade torchio
PatchSampler is indeed not callable. You should use a child class as in the examples. I will reorganize the docs and add a note about this

		</comment>
	</comments>
</bug>