<bug id='366' author='PeterMcGor' open_date='2020-12-01T17:07:32Z' closed_time='2020-12-01T18:37:19Z'>
	<summary>Cannot employ a Lambda transform into SubjectsDatasets for Queue</summary>
	<description>
üêõBug
Hi guys, thanks for the library is quite cool!
I want to employ torchio in a 2D architecture so I am employing the Queue dataset in order to extract patches that represent one slice. Everything works fine when I do not apply transforms or I employ your built-in transforms. However, since I am using a pre-pre-trained model with a different slice orientation I am trying to apply an easy Lambda which just employs torch.transpose. In this case, I get the error showed at traces paragraph.
Just in case let me add that the Lambda transform alone works OK
To reproduce
transpose_transform = tio.Lambda(lambda x: torch.transpose(x, 1,2))
transformadas = tio.Compose([transpose_transform]) #Without or  with built-in transforms works properly
dataset_transform = tio.SubjectsDataset(subjects, transform=transformadas) # I tried with just the transpose (instead a composition) transform but I got the same result

slices_queue = tio.Queue(
    subjects_dataset=dataset_transform,
    max_length=24,
    samples_per_volume=4, # For this test I employ a datsset just with 6 3D-images 
    sampler=tio.sampler.UniformSampler((500,400,1)),
    num_workers=6,
    shuffle_subjects=False,
    shuffle_patches=True)
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/queues.py", line 234, in _feed
    obj = _ForkingPickler.dumps(obj)
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/queues.py", line 234, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.6/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
_pickle.PicklingError: Can't pickle &lt;function &lt;lambda&gt; at 0x7f3d89c6fb70&gt;: attribute lookup &lt;lambda&gt; on __main__ failed
  File "/usr/lib/python3.6/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
_pickle.PicklingError: Can't pickle &lt;function &lt;lambda&gt; at 0x7f3d89c6fb70&gt;: attribute lookup &lt;lambda&gt; on __main__ failed
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/queues.py", line 234, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.6/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
_pickle.PicklingError: Can't pickle &lt;function &lt;lambda&gt; at 0x7f3d89c6fb70&gt;: attribute lookup &lt;lambda&gt; on __main__ failed
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/queues.py", line 234, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.6/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
_pickle.PicklingError: Can't pickle &lt;function &lt;lambda&gt; at 0x7f3d89c6fb70&gt;: attribute lookup &lt;lambda&gt; on __main__ failed
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/queues.py", line 234, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.6/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
_pickle.PicklingError: Can't pickle &lt;function &lt;lambda&gt; at 0x7f3d89c6fb70&gt;: attribute lookup &lt;lambda&gt; on __main__ failed
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/queues.py", line 234, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.6/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
_pickle.PicklingError: Can't pickle &lt;function &lt;lambda&gt; at 0x7f3d89c6fb70&gt;: attribute lookup &lt;lambda&gt; on __main__ failed
Expected behavior
Work as with the built-in transforms
"Can't pickle"
TorchIO version
0.18.0
	</description>
	<comments>
		<comment id='1' author='PeterMcGor' date='2020-12-01T17:20:09Z'>
		Hi, &lt;denchmark-link:https://github.com/PeterMcGor&gt;@PeterMcGor&lt;/denchmark-link&gt;
. Thanks for reporting and for your kind words!
I have been able to reproduce the error on macOS using this code:
import torch
import torchio as tio
subject = tio.Subject(im=tio.ScalarImage(tensor=torch.rand(1, 2, 3, 1)))
transform = tio.Lambda(lambda x: x)
dataset = tio.SubjectsDataset([subject], transform=transform)
loader = torch.utils.data.DataLoader(dataset, num_workers=2)
next(iter(loader))
If I use def f(x): return x and I pass f to Lambda, I also get an error, but different.
Both approaches work fine on Linux, which makes me think it's a macOS issue, and more related to PyTorch than to TorchIO. What OS are you using?
		</comment>
		<comment id='2' author='PeterMcGor' date='2020-12-01T17:29:09Z'>
		It does work on macOS when num_workers=0.
I also tried passing f as the transform for the dataset (basically an identity transform), but I get yet another error. Again, that did work on Linux.
		</comment>
		<comment id='3' author='PeterMcGor' date='2020-12-01T17:48:29Z'>
		Sorry, I forgot to mention it before.
I am using a jupyter-lab hosted on a docker with Ubuntu 18.04 and python 3.6.9 with memory limited to 24GB, 8 cores and one Nvidia Titan V.
As you pointed out, with 0 workers it works. Thank you for the workaround, however, I need to apply more demanding transforms for my real code and employing just the main process is quite slow.
The multiprocessing with python is always a pain...
I have no problem with your example by the way.
		</comment>
		<comment id='4' author='PeterMcGor' date='2020-12-01T17:55:29Z'>
		Thanks. That's a very specific environment that I won't be able to test, unfortunately. Can you try using a non-anonymous function such as the f I shared above?
I don't know much about multiprocessing, but I seem to recall something about each process needing to be able to "see" the function in their namespace, or something like that.
I also tried this
class Transpose:
    def __call__(self, x):
        return torch.transpose(x, 1, 2)
But got the same error as with f. Maybe it's related to the fact that I'm using IPython. I'll try a script instead.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;


I have no problem with your example by the way.

That's interesting. You just copy-pasted the snippet I shared and it worked?
		</comment>
		<comment id='5' author='PeterMcGor' date='2020-12-01T18:03:37Z'>
		It seems to work when the function is defined somewhere else (different file).
if __name__ == "__main__":
    import torch
    import torchio as tio
    from t import Transpose
    subject = tio.Subject(im=tio.ScalarImage(tensor=torch.rand(1, 2, 3, 1)))
    transform = Transpose()
    dataset = tio.SubjectsDataset([subject], transform=transform)
    loader = torch.utils.data.DataLoader(dataset, num_workers=2)
    next(iter(loader))
And t.py:
class Transpose:
    def __call__(self, x):
        return torch.transpose(x, 1, 2)
ü§∑‚Äç‚ôÇÔ∏è
		</comment>
		<comment id='6' author='PeterMcGor' date='2020-12-01T18:15:48Z'>
		You were right! I was trying stuff and did not realize about your comment about declaring a function explicitly
I have been reading and apparently, python is not able to pickle anonymous functions multiprocessing so you need to declare an f (or whatever) function. Multiprocessing depends on the OS so... good luck with the MAC. Let me know if I can help you!
		</comment>
		<comment id='7' author='PeterMcGor' date='2020-12-01T18:33:26Z'>
		
Multiprocessing depends on the OS so... good luck with the MAC. Let me know if I can help you!

Thanks! But I just use mac for my day-to-day work. For training, I use a DGX üí™

You were right! I was trying stuff and did not realize about your comment about declaring a function explicitly
I have been reading and apparently, python is not able to pickle anonymous functions multiprocessing so you need to declare an f (or whatever) function.

Nice. Does this mean that solved your problem?
		</comment>
		<comment id='8' author='PeterMcGor' date='2020-12-01T18:37:18Z'>
		Yeah!
		</comment>
		<comment id='9' author='PeterMcGor' date='2021-01-13T22:22:03Z'>
		This does not work for me.
I am currently using this:
### Some code here
augmentations.append(ZNormalization(masking_method=NonZero()))

### In a dfifferent file
class NonZero:
    def __call__(self, x):
        return x &gt; 0
I am using Linux 20.04 right now and setting q_num_workers gives this error to me.
		</comment>
		<comment id='10' author='PeterMcGor' date='2021-01-13T22:55:17Z'>
		Hi, &lt;denchmark-link:https://github.com/Geeks-Sid&gt;@Geeks-Sid&lt;/denchmark-link&gt;
. Could you please &lt;denchmark-link:https://github.com/fepegar/torchio/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=&gt;open a new issue&lt;/denchmark-link&gt;
 and share a &lt;denchmark-link:https://stackoverflow.com/help/minimal-reproducible-example&gt;minimal, reproducible example&lt;/denchmark-link&gt;
 that I can run on my Linux computer? That will help me solve your issue.
		</comment>
	</comments>
</bug>