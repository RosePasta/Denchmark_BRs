<bug_data>
<bug id='532' author='Balandat' open_date='2019-02-22T21:57:14Z' closed_time='2019-03-19T14:58:12Z'>
 	<summary>batch evaluation of Hadamard Multi-Task GP fails</summary>
 	<description>
 Note: This happens both on master and on the batch_lt3 branch
 Repro:
 First run the &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/blob/master/examples/03_Multitask_GP_Regression/Hadamard_Multitask_GP_Regression.ipynb&gt;Hadamard MTGP example&lt;/denchmark-link&gt;
 .
 Then
 &lt;denchmark-code&gt;test_x = torch.linspace(0, 1, 51).unsqueeze(-1).repeat(2, 1, 1)
 tast_i_task1 = torch.full_like(test_x, dtype=torch.long, fill_value=0)
 
 with torch.no_grad(), gpytorch.settings.fast_pred_var():
     observed_pred_y1 = likelihood(model(test_x, tast_i_task1))
 &lt;/denchmark-code&gt;
 
 errors out with
 &lt;denchmark-code&gt;---------------------------------------------------------------------------
 RuntimeError                              Traceback (most recent call last)
 &lt;ipython-input-62-28172f8b7beb&gt; in &lt;module&gt;()
       1 with torch.no_grad(), gpytorch.settings.fast_pred_var():
 ----&gt; 2     observed_pred_y1 = likelihood(model(test_x, tast_i_task1))
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)
     199             )
     200 
 --&gt; 201             full_output = super(ExactGP, self).__call__(*full_inputs, **kwargs)
     202             if settings.debug().on():
     203                 if not isinstance(full_output, MultivariateNormal):
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/module.py in __call__(self, *inputs, **kwargs)
      18 
      19     def __call__(self, *inputs, **kwargs):
 ---&gt; 20         outputs = self.forward(*inputs, **kwargs)
      21         if isinstance(outputs, list):
      22             return [_validate_module_outputs(output) for output in outputs]
 
 &lt;ipython-input-52-b565681c3db1&gt; in forward(self, x, i)
      17         covar_i = self.task_covar_module(i)
      18         # Multiply the two together to get the covariance we want
 ---&gt; 19         covar = covar_x.mul(covar_i)
      20 
      21         return gpytorch.distributions.MultivariateNormal(mean_x, covar)
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in mul(self, other)
     950                 return self._mul_constant(other.view(*other.shape[:-2]))
     951 
 --&gt; 952         return self._mul_matrix(other)
     953 
     954     def ndimension(self):
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in _mul_matrix(self, other)
     443         """
     444         from .mul_lazy_tensor import MulLazyTensor
 --&gt; 445         return MulLazyTensor(self, other).evaluate_kernel()
     446 
     447     def _preconditioner(self):
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_tensor.py in evaluate_kernel(self)
     734         all lazily evaluated kernels actually evaluated.
     735         """
 --&gt; 736         return self.representation_tree()(*self.representation())
     737 
     738     def inv_matmul(self, right_tensor, left_tensor=None):
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/mul_lazy_tensor.py in representation_tree(self)
     235 
     236     def representation_tree(self):
 --&gt; 237         if self.non_lazy_self is not None:
     238             return self.non_lazy_self.representation_tree()
     239         else:
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/mul_lazy_tensor.py in non_lazy_self(self)
      37         if hasattr(self, "_non_lazy_self"):
      38             return self._non_lazy_self[0]
 ---&gt; 39         elif len(self._args) == 1:
      40             return self._args[0]
      41         else:
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/mul_lazy_tensor.py in _args(self)
      54         if not hasattr(self, "_mul_args_memo") and not hasattr(self, "_non_lazy_self"):
      55             lazy_tensors = sorted(
 ---&gt; 56                 (lv.evaluate_kernel() for lv in self.lazy_tensors), key=lambda lv: lv.root_decomposition_size()
      57             )
      58 
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/mul_lazy_tensor.py in &lt;genexpr&gt;(.0)
      54         if not hasattr(self, "_mul_args_memo") and not hasattr(self, "_non_lazy_self"):
      55             lazy_tensors = sorted(
 ---&gt; 56                 (lv.evaluate_kernel() for lv in self.lazy_tensors), key=lambda lv: lv.root_decomposition_size()
      57             )
      58 
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in evaluate_kernel(self)
     159             with settings.lazily_evaluate_kernels(False):
     160                 self._cached_kernel_eval = self.kernel(
 --&gt; 161                     x1, x2, diag=False, batch_dims=self.batch_dims, **self.params
     162                 )
     163 
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/kernels/kernel.py in __call__(self, x1, x2, diag, batch_dims, **params)
     396                 res = LazyEvaluatedKernelTensor(self, x1_, x2_, batch_dims=batch_dims, **params)
     397             else:
 --&gt; 398                 res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)
     399 
     400             # TODO: remove bach checking once kernels support arbitrary batch dimensions
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/module.py in __call__(self, *inputs, **kwargs)
      18 
      19     def __call__(self, *inputs, **kwargs):
 ---&gt; 20         outputs = self.forward(*inputs, **kwargs)
      21         if isinstance(outputs, list):
      22             return [_validate_module_outputs(output) for output in outputs]
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/kernels/index_kernel.py in forward(self, i1, i2, **params)
      78     def forward(self, i1, i2, **params):
      79         covar_matrix = self._eval_covar_matrix()
 ---&gt; 80         res = InterpolatedLazyTensor(base_lazy_tensor=covar_matrix, left_interp_indices=i1, right_interp_indices=i2)
      81         return res
 
 /data/users/balandat/fbsource/fbcode/buck-out/dev/gen/bento/kernels/bento_kernel_ae_lazarus#link-tree/gpytorch/lazy/interpolated_lazy_tensor.py in __init__(self, base_lazy_tensor, left_interp_indices, left_interp_values, right_interp_indices, right_interp_values)
      60             raise RuntimeError(
      61                 "left interp size ({}) is incompatible with base_lazy_tensor size ({}). Make sure the two "
 ---&gt; 62                 "have the same number of batch dimensions".format(left_interp_indices.size(), base_lazy_tensor.size())
      63             )
      64         if right_interp_indices.shape[:-2] != base_lazy_tensor.batch_shape:
 
 RuntimeError: left interp size (torch.Size([2, 251, 1])) is incompatible with base_lazy_tensor size (torch.Size([1, 2, 2])). Make sure the two have the same number of batch dimensions
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='5ae7e24308aa3da597e27bae3f4e6ea28630654f' author='Geoff Pleiss' date='2019-03-18 19:27:07-04:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='gpytorch\lazy\interpolated_lazy_tensor.py' new_name='gpytorch\lazy\interpolated_lazy_tensor.py'>
 		<file_info nloc='312' complexity='39' token_count='2738'></file_info>
 		<method name='_check_args' parameters='self,base_lazy_tensor,left_interp_indices,left_interp_values,right_interp_indices,right_interp_values'>
 				<method_info nloc='2' complexity='1' token_count='13' nesting_level='1' start_line='15' end_line='16'></method_info>
 			<added_lines>15,16</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,70,71,72,73,74,75,76,77</added_lines>
 			<deleted_lines>35,36,37,38,39,40,52,53,54,55,56,57,59,61,62,63,64,65,66,67,68,69</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\lazy\test_interpolated_lazy_tensor.py' new_name='test\lazy\test_interpolated_lazy_tensor.py'>
 		<file_info nloc='108' complexity='12' token_count='1265'></file_info>
 		<method name='create_lazy_tensor' parameters='self'>
 				<method_info nloc='13' complexity='1' token_count='259' nesting_level='1' start_line='101' end_line='115'></method_info>
 			<added_lines>109</added_lines>
 			<deleted_lines>109,111</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
