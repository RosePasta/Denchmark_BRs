<bug_data>
<bug id='147' author='geoHeil' open_date='2018-12-09T12:50:18Z' closed_time='2019-05-31T04:57:30Z'>
 	<summary>pyarrow pandas dataframe buffer source array is read-only exception</summary>
 	<description>
 When a pyArrow backed pandas parquet Dataframe is used with pandas-profiling:
 I get the stack trace below. However, when using a CSV backed data frame with the same data pandas-profiling works just fine.
 &lt;denchmark-code&gt;--------------------------------------------------------------------------
 ValueError                                Traceback (most recent call last)
 &lt;ipython-input-9-4f6d7d159b1b&gt; in &lt;module&gt;
 ----&gt; 1 pandas_profiling.ProfileReport(aa)
 
 /opt/conda/lib/python3.6/site-packages/pandas_profiling/__init__.py in __init__(self, df, **kwargs)
      64         sample = kwargs.get('sample', df.head())
      65 
 ---&gt; 66         description_set = describe(df, **kwargs)
      67 
      68         self.html = to_html(sample,
 
 /opt/conda/lib/python3.6/site-packages/pandas_profiling/describe.py in describe(df, bins, check_correlation, correlation_threshold, correlation_overrides, check_recoded, pool_size, **kwargs)
     413         'table': table_stats,
     414         'variables': variable_stats.T,
 --&gt; 415         'freq': {k: (base.get_groupby_statistic(df[k])[0] if variable_stats[k].type != base.S_TYPE_UNSUPPORTED else None) for k in df.columns},
     416         'correlations': {'pearson': dfcorrPear, 'spearman': dfcorrSpear}
     417     }
 
 /opt/conda/lib/python3.6/site-packages/pandas_profiling/describe.py in &lt;dictcomp&gt;(.0)
     413         'table': table_stats,
     414         'variables': variable_stats.T,
 --&gt; 415         'freq': {k: (base.get_groupby_statistic(df[k])[0] if variable_stats[k].type != base.S_TYPE_UNSUPPORTED else None) for k in df.columns},
     416         'correlations': {'pearson': dfcorrPear, 'spearman': dfcorrSpear}
     417     }
 
 /opt/conda/lib/python3.6/site-packages/pandas_profiling/base.py in get_groupby_statistic(data)
      45         return _VALUE_COUNTS_MEMO[data.name]
      46 
 ---&gt; 47     value_counts_with_nan = data.value_counts(dropna=False)
      48     value_counts_without_nan = value_counts_with_nan.loc[value_counts_with_nan.index.dropna()]
      49     distinct_count_with_nan = value_counts_with_nan.count()
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/base.py in value_counts(self, normalize, sort, ascending, bins, dropna)
    1036         from pandas.core.algorithms import value_counts
    1037         result = value_counts(self, sort=sort, ascending=ascending,
 -&gt; 1038                               normalize=normalize, bins=bins, dropna=dropna)
    1039         return result
    1040 
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/algorithms.py in value_counts(values, sort, ascending, normalize, bins, dropna)
     721 
     722     if sort:
 --&gt; 723         result = result.sort_values(ascending=ascending)
     724 
     725     if normalize:
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/series.py in sort_values(self, axis, ascending, inplace, kind, na_position)
    2494             raise ValueError('invalid na_position: {!r}'.format(na_position))
    2495 
 -&gt; 2496         result = self._constructor(arr[sortedIdx], index=self.index[sortedIdx])
    2497 
    2498         if inplace:
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py in __getitem__(self, key)
    2095         result = getitem(key)
    2096         if not is_scalar(result):
 -&gt; 2097             return promote(result)
    2098         else:
    2099             return result
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/indexes/category.py in _shallow_copy(self, values, categories, ordered, dtype, **kwargs)
     206             dtype = self.dtype if dtype is None else dtype
     207             return super(CategoricalIndex, self)._shallow_copy(
 --&gt; 208                 values=values, dtype=dtype, **kwargs)
     209         if categories is None:
     210             categories = self.categories
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py in _shallow_copy(self, values, **kwargs)
     516         if not len(values) and 'dtype' not in kwargs:
     517             attributes['dtype'] = self.dtype
 --&gt; 518         return self._simple_new(values, **attributes)
     519 
     520     def _shallow_copy_with_infer(self, values=None, **kwargs):
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/indexes/category.py in _simple_new(cls, values, name, categories, ordered, dtype, **kwargs)
     182 
     183         values = cls._create_categorical(cls, values, categories, ordered,
 --&gt; 184                                          dtype=dtype)
     185         result._data = values
     186         result.name = name
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/indexes/category.py in _create_categorical(self, data, categories, ordered, dtype)
     173             if isinstance(dtype, CategoricalDtype):
     174                 # we want to silently ignore dtype='category'
 --&gt; 175                 data = data._set_dtype(dtype)
     176         return data
     177 
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/arrays/categorical.py in _set_dtype(self, dtype)
     728         """
     729         codes = _recode_for_categories(self.codes, self.categories,
 --&gt; 730                                        dtype.categories)
     731         return type(self)(codes, dtype=dtype, fastpath=True)
     732 
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/arrays/categorical.py in _recode_for_categories(codes, old_categories, new_categories)
    2461         # All null anyway, so just retain the nulls
    2462         return codes.copy()
 -&gt; 2463     indexer = coerce_indexer_dtype(new_categories.get_indexer(old_categories),
    2464                                    new_categories)
    2465     new_codes = take_1d(indexer, codes.copy(), fill_value=-1)
 
 /opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance)
    3257                                  'backfill or nearest reindexing')
    3258 
 -&gt; 3259             indexer = self._engine.get_indexer(target._ndarray_values)
    3260 
    3261         return _ensure_platform_int(indexer)
 
 pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_indexer()
 
 pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.lookup()
 
 /opt/conda/lib/python3.6/site-packages/pandas/_libs/hashtable.cpython-36m-x86_64-linux-gnu.so in View.MemoryView.memoryview_cwrapper()
 
 /opt/conda/lib/python3.6/site-packages/pandas/_libs/hashtable.cpython-36m-x86_64-linux-gnu.so in View.MemoryView.memoryview.__cinit__()
 
 ValueError: buffer source array is read-only
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='geoHeil' date='2019-05-30T17:46:45Z'>
 		Hi &lt;denchmark-link:https://github.com/geoHeil&gt;@geoHeil&lt;/denchmark-link&gt;
  ,
 Thank you for reporting this issue. Testing it with a recent version of pandas-profiling works just fine for me, in the myriad of ways I have tested it. This code works for example and seems to be comparable to what you mention in your post:
 &lt;denchmark-code&gt;import pandas as pd
 from pandas_profiling import ProfileReport
 
 
 # https://github.com/pandas-profiling/pandas-profiling/issues/147
 def test_issue147():
     "Data from https://github.com/Teradata/kylo/raw/master/samples/sample-data/parquet/userdata2.parquet"
     df = pd.read_parquet(r"userdata2.parquet", engine='pyarrow')
     report = ProfileReport(df, title="PyArrow with Pandas Parquet Backend")
     html = report.to_html()
     assert type(html) == str and '&lt;p class="h2"&gt;Dataset info&lt;/p&gt;' in html
 &lt;/denchmark-code&gt;
 
 It could be that recent updates have solved the problem, or that your dataset contains more than I am now testing. In any case, the first step would be to take another shot at the dataset with the latest pandas-profiling.  If the error persists, please let us know.
 Kind regards,
 		</comment>
 		<comment id='2' author='geoHeil' date='2019-05-31T04:57:30Z'>
 		Indeed. I will close it now.
 		</comment>
 	</comments>
 </bug>
<commit id='d6c85be96b2d7279075678eccd832fc133e9999f' author='sbrugman' date='2019-05-30 20:30:37+02:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.29411764705882354'></dmm_unit>
 	<modification change_type='MODIFY' old_name='.gitignore' new_name='.gitignore'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>71,72</added_lines>
 			<deleted_lines>71</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='docs\view\formatters.html' new_name='docs\view\formatters.html'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>27,111,163</added_lines>
 			<deleted_lines>110,162</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pandas_profiling\view\formatters.py' new_name='pandas_profiling\view\formatters.py'>
 		<file_info nloc='80' complexity='10' token_count='256'></file_info>
 		<method name='fmt' parameters='value'>
 				<method_info nloc='13' complexity='2' token_count='35' nesting_level='0' start_line='74' end_line='86'></method_info>
 			<added_lines>86</added_lines>
 			<deleted_lines>85</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>2</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='requirements-test.txt' new_name='requirements-test.txt'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>5</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='tests\issues\test_issue147.py'>
 		<file_info nloc='14' complexity='2' token_count='90'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_describe.py' new_name='tests\test_describe.py'>
 		<file_info nloc='637' complexity='28' token_count='3451'></file_info>
 		<method name='test_recoding_reject' parameters='recoding_data'>
 				<method_info nloc='34' complexity='8' token_count='242' nesting_level='0' start_line='60' end_line='94'></method_info>
 			<added_lines>62,63,64,65,66,67,68,69,70,71,72,73,74,75</added_lines>
 			<deleted_lines>62,63,92,93</deleted_lines>
 		</method>
 		<method name='test_cramers_reject' parameters='recoding_data'>
 				<method_info nloc='38' complexity='8' token_count='293' nesting_level='0' start_line='97' end_line='137'></method_info>
 			<added_lines>104,105,106,107,108,109,110,111,112,113,114,115,116,117,118</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
