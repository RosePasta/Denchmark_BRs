<bug_data>
<bug id='781' author='ddetone' open_date='2020-11-13T20:03:59Z' closed_time='2020-11-23T01:51:48Z'>
 	<summary>[Bug] RandomSharpen returns three channels for one channel input?</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 The RandomSharpen function returns a 3 channel image when a 1 channel input is given. Is this a bug or expected behavior? I would expect it to return a 1 channel image as well.
 &lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Steps to reproduce the behavior:
 This example is taken directly from: &lt;denchmark-link:https://github.com/kornia/kornia/blob/master/kornia/augmentation/augmentation.py#L1053&gt;https://github.com/kornia/kornia/blob/master/kornia/augmentation/augmentation.py#L1053&lt;/denchmark-link&gt;
 
 &gt;&gt;&gt; rng = torch.manual_seed(0)
 &gt;&gt;&gt; input = torch.rand(1, 1, 5, 5)
 &gt;&gt;&gt; sharpness = RandomSharpness(1.)
 &gt;&gt;&gt; sharpness(input)
 tensor([[[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],
           [0.6341, 0.7720, 0.9537, 0.7566, 0.6323],
           [0.3489, 0.7325, 0.5629, 0.6284, 0.2939],
           [0.5185, 0.8648, 0.9106, 0.6249, 0.2823],
           [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]],
 &lt;BLANKLINE&gt;
          [[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],
           [0.6341, 0.7720, 0.9537, 0.7566, 0.6323],
           [0.3489, 0.7325, 0.5629, 0.6284, 0.2939],
           [0.5185, 0.8648, 0.9106, 0.6249, 0.2823],
           [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]],
 &lt;BLANKLINE&gt;
          [[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],
           [0.6341, 0.7720, 0.9537, 0.7566, 0.6323],
           [0.3489, 0.7325, 0.5629, 0.6284, 0.2939],
           [0.5185, 0.8648, 0.9106, 0.6249, 0.2823],
           [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]]]])
 &lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;
 
 Output should only have one channel, i.e. the shape should be (1, 1, 5, 5) not (1, 3, 5, 5).
 &gt;&gt;&gt; rng = torch.manual_seed(0)
 &gt;&gt;&gt; input = torch.rand(1, 1, 5, 5)
 &gt;&gt;&gt; sharpness = RandomSharpness(1.)
 &gt;&gt;&gt; sharpness(input)
 tensor([[[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],
           [0.6341, 0.5845, 0.9156, 0.5565, 0.6323],
           [0.3489, 0.5125, 0.2034, 0.3228, 0.2939],
           [0.5185, 0.7537, 0.8371, 0.3164, 0.2823],
           [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]]]])
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 Collecting environment information...
 PyTorch version: 1.6.0
 Is debug build: False
 CUDA used to build PyTorch: None
 ROCM used to build PyTorch: N/A
 OS: Mac OSX 10.15.7 (x86_64)
 GCC version: Could not collect
 Clang version: 12.0.0 (clang-1200.0.32.2)
 CMake version: Could not collect
 Python version: 3.7 (64-bit runtime)
 Is CUDA available: False
 CUDA runtime version: No CUDA
 GPU models and configuration: No CUDA
 Nvidia driver version: No CUDA
 cuDNN version: No CUDA
 HIP runtime version: N/A
 MIOpen runtime version: N/A
 Versions of relevant libraries:
 [pip3] numpy==1.16.1
 [pip3] torch==1.6.0
 [pip3] torchvision==0.8.1
 [conda] Could not collect
 	</description>
 	<comments>
 		<comment id='1' author='ddetone' date='2020-11-14T04:05:30Z'>
 		That makes sense. Will fix it in &lt;denchmark-link:https://github.com/kornia/kornia/pull/783&gt;#783&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='f7dba6ab79adaf77e7266bd614b75c2a47fda698' author='shijianjian' date='2020-11-23 09:51:47+08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='kornia\augmentation\augmentation.py' new_name='kornia\augmentation\augmentation.py'>
 		<file_info nloc='1054' complexity='93' token_count='6308'></file_info>
 		<modified_lines>
 			<added_lines>1104,1105,1106</added_lines>
 			<deleted_lines>1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='kornia\enhance\adjust.py' new_name='kornia\enhance\adjust.py'>
 		<file_info nloc='508' complexity='76' token_count='3505'></file_info>
 		<method name='sharpness' parameters='Tensor,float'>
 				<method_info nloc='45' complexity='5' token_count='339' nesting_level='0' start_line='398' end_line='450'></method_info>
 			<added_lines>399,400,401,402,412,413,414,415,416,417,418,419,420,423,424,425,426,427,428,429,430,435,442,448,449,450</added_lines>
 			<deleted_lines>399,411,412,413,414,415,416,417,422,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449</deleted_lines>
 		</method>
 		<method name='_blend_one' parameters='Tensor,Tensor,Tensor'>
 				<method_info nloc='24' complexity='6' token_count='129' nesting_level='0' start_line='453' end_line='477'></method_info>
 			<added_lines>453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='equalize' parameters='Tensor'>
 				<method_info nloc='18' complexity='3' token_count='73' nesting_level='0' start_line='534' end_line='554'></method_info>
 			<added_lines>536,542</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='sharpness._blend_one' parameters='Tensor,Tensor,float'>
 				<method_info nloc='13' complexity='6' token_count='115' nesting_level='1' start_line='434' end_line='446'></method_info>
 			<added_lines>435,442</added_lines>
 			<deleted_lines>434,435,436,437,438,439,440,441,442,443,444,445,446</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>451,452</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\enhance\test_adjust.py' new_name='test\enhance\test_adjust.py'>
 		<file_info nloc='578' complexity='48' token_count='6459'></file_info>
 		<method name='test_smoke' parameters='self,device,dtype'>
 				<method_info nloc='4' complexity='1' token_count='64' nesting_level='1' start_line='751' end_line='754'></method_info>
 			<added_lines>751,752,753,754</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_jit' parameters='self,device,dtype'>
 				<method_info nloc='6' complexity='1' token_count='76' nesting_level='1' start_line='831' end_line='836'></method_info>
 			<added_lines>831,832,833,834,835,836</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_gradcheck' parameters='self,device'>
 				<method_info nloc='7' complexity='1' token_count='71' nesting_level='1' start_line='254' end_line='260'></method_info>
 			<added_lines>258</added_lines>
 			<deleted_lines>258</deleted_lines>
 		</method>
 		<method name='test_value_batch' parameters='self,device,dtype'>
 				<method_info nloc='21' complexity='1' token_count='382' nesting_level='1' start_line='792' end_line='820'></method_info>
 			<added_lines>792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_exception' parameters='self,device,dtype'>
 				<method_info nloc='8' complexity='1' token_count='120' nesting_level='1' start_line='765' end_line='772'></method_info>
 			<added_lines>765,766,767,768,769,770,771,772</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_gradcheck' parameters='self'>
 				<method_info nloc='6' complexity='1' token_count='58' nesting_level='1' start_line='52' end_line='57'></method_info>
 			<added_lines>55</added_lines>
 			<deleted_lines>55</deleted_lines>
 		</method>
 		<method name='test_value' parameters='self,device,dtype'>
 				<method_info nloc='9' complexity='1' token_count='152' nesting_level='1' start_line='774' end_line='790'></method_info>
 			<added_lines>774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_module' parameters='self,device,dtype'>
 				<method_info nloc='2' complexity='1' token_count='31' nesting_level='1' start_line='840' end_line='841'></method_info>
 			<added_lines>840,841</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_cardinality' parameters='self,batch_size,channels,height,width,factor,device,dtype'>
 				<method_info nloc='3' complexity='1' token_count='67' nesting_level='1' start_line='761' end_line='763'></method_info>
 			<added_lines>761,762,763</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_gradcheck' parameters='self,device,dtype'>
 				<method_info nloc='5' complexity='1' token_count='71' nesting_level='1' start_line='823' end_line='827'></method_info>
 			<added_lines>823,824,825,826,827</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>4,126,459,599,661,730,745,746,747,748,749,750,755,756,757,758,759,760,764,773,791,821,822,828,829,830,837,838,839,842,843</added_lines>
 			<deleted_lines>4,126,459,599,661,730</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
