<bug_data>
<bug id='80' author='ET-Chan' open_date='2018-03-08T17:35:47Z' closed_time='2018-03-09T11:00:19Z'>
 	<summary>gpu_allow_growth is not working</summary>
 	<description>
 Calling the tutorial code with additional argument gpu_allow_growth
 &lt;denchmark-code&gt;python -m bin.main train_and_eval --gpu_allow_growth --model config/models/nmt_small.py --config config/opennmt-defaults.yml config/data/toy-ende.yml
 &lt;/denchmark-code&gt;
 
 does not prevent GPU memory being fully allocated. After some digging, it can be found that a call in &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-tf/blob/master/opennmt/utils/parallel.py#L27&gt;https://github.com/OpenNMT/OpenNMT-tf/blob/master/opennmt/utils/parallel.py#L27&lt;/denchmark-link&gt;
  is causing this.
 It seems that this issue is already brought up on a &lt;denchmark-link:https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow&gt;stackoverflow question&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='ET-Chan' date='2018-03-09T09:53:27Z'>
 		Interesting. Thanks for highlighting the culprit!
 An easy fix would be to not call device_lib.list_local_devices() when num_devices is 1, thus making --gpu_allow_growth only work for single GPU training. I would assume that when training on multiple GPUs, people do not execute other tasks on them.
 What do you think?
 		</comment>
 		<comment id='2' author='ET-Chan' date='2018-03-09T10:37:33Z'>
 		I am not entirely sure if this is a reasonable assumption. We, however, can enforce allow_growth by a trick mentioned in
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/8021&gt;tensorflow/tensorflow#8021&lt;/denchmark-link&gt;
 
 Specifically, create a session before the first list_local_devices call, as some gpu options, e.g. allow_growth, only have effect when it is used in the 1st session created in the process.
 I've tested in by just adding
 &lt;denchmark-code&gt;gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333, allow_growth=True)
 sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
 &lt;/denchmark-code&gt;
 
 in &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-tf/blob/master/bin/main.py#L79&gt;https://github.com/OpenNMT/OpenNMT-tf/blob/master/bin/main.py#L79&lt;/denchmark-link&gt;
  and it works.
 (For details why this works, read &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/8136&gt;tensorflow/tensorflow#8136&lt;/denchmark-link&gt;
 )
 		</comment>
 		<comment id='3' author='ET-Chan' date='2018-03-09T11:01:01Z'>
 		Thanks for the details. I applied your recommendation in the commit above.
 		</comment>
 	</comments>
 </bug>
<commit id='eadbb039cb7c28d9d091921fc226b0d0b2b5b079' author='Guillaume Klein' date='2018-03-09 11:58:54+01:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='opennmt\runner.py' new_name='opennmt\runner.py'>
 		<file_info nloc='150' complexity='23' token_count='1275'></file_info>
 		<modified_lines>
 			<added_lines>48,49,50,51</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
