<bug_data>
<bug id='76' author='dapurv5' open_date='2020-02-13T19:34:42Z' closed_time='2020-02-15T01:04:16Z'>
 	<summary>NoneType has no attribute to</summary>
 	<description>
 I get the following error when I run my training. When I comment out this line the training works but the loss doesn't decrease
 &lt;denchmark-code&gt;File "/storage/home/ec2-user/ner/trainer/trainer.py", line 131, in _train_epoch
   self.model.step()
 File "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/deepspeed/pt/deepspeed_light.py", line 628, in step
   fp32_param.grad = fp16_param.grad.to(fp32_param.dtype)
 AttributeError: 'NoneType' object has no attribute 'to'
   self.optimizer.step()
 File "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/deepspeed/pt/fp16_unfused_optimizer.py", line 165, in step
   fp32_param.grad = fp16_param.grad.to(fp32_param.dtype)
 AttributeError: 'NoneType' object has no attribute 'to'
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='dapurv5' date='2020-02-14T14:57:40Z'>
 		I would like to contribute
 		</comment>
 		<comment id='2' author='dapurv5' date='2020-02-15T00:55:47Z'>
 		Hi &lt;denchmark-link:https://github.com/Tejaswgupta&gt;@Tejaswgupta&lt;/denchmark-link&gt;
 , thanks for reaching out and wanting to contribute. Is there something specific you have in mind you'd like to contribute? If it was this issue I do have a PR being reviewed currently that fixes this issue. We're in the process of trying to create some new issues that would be good to take care of as a new user. Keep an eye out for those :)
 &lt;denchmark-link:https://github.com/dapurv5&gt;@dapurv5&lt;/denchmark-link&gt;
 , Thanks for bringing this bug to our attention. We previously fixed this type of bug in a different code path but now have added unit tests for it and fixed it in your code path and one other. The PR should be merged soon.
 		</comment>
 		<comment id='3' author='dapurv5' date='2020-02-17T04:59:49Z'>
 		Sure &lt;denchmark-link:https://github.com/jeffra&gt;@jeffra&lt;/denchmark-link&gt;
  :)
 		</comment>
 	</comments>
 </bug>
<commit id='807480a04bdc371525776e42c31f7c72d9132f0a' author='Jeff Rasley' date='2020-02-14 17:04:15-08:00'>
 	<dmm_unit complexity='0.8232044198895028' interfacing='0.5966850828729282' size='0.712707182320442'></dmm_unit>
 	<modification change_type='MODIFY' old_name='deepspeed\pt\fp16_unfused_optimizer.py' new_name='deepspeed\pt\fp16_unfused_optimizer.py'>
 		<file_info nloc='200' complexity='45' token_count='1396'></file_info>
 		<method name='step' parameters='self,closure'>
 				<method_info nloc='29' complexity='9' token_count='235' nesting_level='1' start_line='146' end_line='190'></method_info>
 			<added_lines>170,171,172,173,174,175</added_lines>
 			<deleted_lines>165</deleted_lines>
 		</method>
 		<method name='step_fused_lamb' parameters='self,closure'>
 				<method_info nloc='27' complexity='6' token_count='196' nesting_level='1' start_line='110' end_line='144'></method_info>
 			<added_lines>119,120,121,122,123,124,125</added_lines>
 			<deleted_lines>119,120</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='tests\unit\test_fp16.py'>
 		<file_info nloc='175' complexity='21' token_count='1139'></file_info>
 	</modification>
 </commit>
</bug_data>
