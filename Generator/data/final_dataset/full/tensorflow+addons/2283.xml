<bug_data>
<bug id='2283' author='vlawhern' open_date='2020-12-10T20:52:38Z' closed_time='2020-12-15T05:14:21Z'>
 	<summary>Can't save keras model weights when using LayerNormLSTMCell and Eager mode due to non-unique weight names</summary>
 	<description>
 System information
 
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
 TensorFlow version and how it was installed (source or binary): TF 2.2, installed with Anaconda through conda package manager
 TensorFlow-Addons version and how it was installed (source or binary): 0.11.2, pip install
 Python version: 3.7.6
 Is GPU used? (yes/no): Yes
 
 Describe the bug
 When using a model with LayerNormLSTMCell with Eager Execution enabled, you cannot save the model weights due to it having non-unique weight names. Apparently this is a known Keras issue (see &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27688#issuecomment-595950270&gt;tensorflow/tensorflow#27688 (comment)&lt;/denchmark-link&gt;
 ).
 For example, this code works just fine:
 import tensorflow as tf
 from tensorflow_addons.rnn import LayerNormLSTMCell
 from tensorflow.keras.layers import LSTMCell
 
 import numpy as np
 
 x_train = np.random.randn(1000, 10, 20)
 y_train = np.random.randint(0, 1, x_train.shape[0])
 
 model = tf.keras.Sequential([
     tf.keras.layers.RNN(LSTMCell(10), input_shape = (10,20)),
     tf.keras.layers.Dense(2),
     tf.keras.layers.Activation('softmax')
 ])
 
 
 model.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['sparse_categorical_accuracy'])
 
 model.fit(x_train, y_train, epochs=1)
 model.save_weights('/tmp/weights.h5')
 while this code fails
 import tensorflow as tf
 from tensorflow_addons.rnn import LayerNormLSTMCell
 from tensorflow.keras.layers import LSTMCell
 
 import numpy as np
 
 x_train = np.random.randn(1000, 10, 20)
 y_train = np.random.randint(0, 1, x_train.shape[0])
 
 model = tf.keras.Sequential([
     tf.keras.layers.RNN(LayerNormLSTMCell(10), input_shape = (10,20)),
     tf.keras.layers.Dense(2),
     tf.keras.layers.Activation('softmax')
 ])
 
 
 model.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['sparse_categorical_accuracy'])
 
 model.fit(x_train, y_train, epochs=1)
 model.save_weights('/tmp/weights.h5')
 with the following error:
 RuntimeError: Unable to create link (name already exists)
 I believe this is happening due to the LayerNormLSTMCell weight names not being unique. Here are the weight names; weights 3,5,7 and 4,6,8 each have the same name.
 model.layers[0].weights[0].name
 Out[7]: 'rnn_2/kernel:0'
 
 model.layers[0].weights[1].name
 Out[8]: 'rnn_2/recurrent_kernel:0'
 
 model.layers[0].weights[2].name
 Out[9]: 'rnn_2/bias:0'
 
 model.layers[0].weights[3].name
 Out[10]: 'rnn_2/gamma:0'
 
 model.layers[0].weights[4].name
 Out[11]: 'rnn_2/beta:0'
 
 model.layers[0].weights[5].name
 Out[12]: 'rnn_2/gamma:0'
 
 model.layers[0].weights[6].name
 Out[13]: 'rnn_2/beta:0'
 
 model.layers[0].weights[7].name
 Out[14]: 'rnn_2/gamma:0'
 
 model.layers[0].weights[8].name
 Out[15]: 'rnn_2/beta:0'
 The suggested solution is to disable eager execution (via tf.compat.v1.disable_eager_execution()) which does allow both code snippets to work; however, in my use case I run into severe performance degradation this way. If possible I'd like to be able to save model weights when use LayerNormLSTMCell with Eager mode.
 	</description>
 	<comments>
 		<comment id='1' author='vlawhern' date='2020-12-10T22:22:55Z'>
 		Seems that the name of  layer does not propagate successfully. Hi &lt;denchmark-link:https://github.com/qlzh727&gt;@qlzh727&lt;/denchmark-link&gt;
 , can you confirm if this is a keras upstream issue and is there any workaround on this?
 &lt;denchmark-link:https://colab.research.google.com/drive/1M9BUa8t0ynV8qPQzGh8T_OH2IpKMnog8?usp=sharing&gt;https://colab.research.google.com/drive/1M9BUa8t0ynV8qPQzGh8T_OH2IpKMnog8?usp=sharing&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='vlawhern' date='2020-12-10T23:22:31Z'>
 		I think its a layerNormCell issue, since the duplicated name is caused by kernel_norm/recurrent_norm/state_norm sub layers. More specifically, build() method of LayerNormLSTMCell should call kernel_norm.build() with a name scope, so that the weights created will the proper name to identify them.
 &lt;denchmark-link:https://github.com/tensorflow/addons/blob/master/tensorflow_addons/rnn/layer_norm_lstm_cell.py#L157&gt;https://github.com/tensorflow/addons/blob/master/tensorflow_addons/rnn/layer_norm_lstm_cell.py#L157&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='vlawhern' date='2020-12-10T23:26:10Z'>
 		Sounds good. So the name passed into layer does nothing for name scope?
 &lt;denchmark-link:https://github.com/tensorflow/addons/blob/master/tensorflow_addons/rnn/layer_norm_lstm_cell.py#L196-L202&gt;https://github.com/tensorflow/addons/blob/master/tensorflow_addons/rnn/layer_norm_lstm_cell.py#L196-L202&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='4' author='vlawhern' date='2020-12-10T23:28:24Z'>
 		It should, but since we manually invoke the build() method for those sublayers, and that is causing the problem for missing the name. If you take a look for the base_layer in keras, there are quite some logic around build() method before it is invoked.
 		</comment>
 		<comment id='5' author='vlawhern' date='2020-12-10T23:35:20Z'>
 		Thanks for clarification!
 		</comment>
 	</comments>
 </bug>
<commit id='3ca4decde94b4c07632c5b9750a442d155b1faea' author='Qianli Scott Zhu' date='2020-12-14 20:54:08-08:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.2727272727272727'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\rnn\layer_norm_lstm_cell.py' new_name='tensorflow_addons\rnn\layer_norm_lstm_cell.py'>
 		<file_info nloc='140' complexity='10' token_count='734'></file_info>
 		<method name='build.maybe_build_sublayer' parameters='sublayer,build_shape'>
 				<method_info nloc='5' complexity='2' token_count='38' nesting_level='2' start_line='158' end_line='162'></method_info>
 			<added_lines>158,159,160,161,162</added_lines>
 			<deleted_lines>158,159</deleted_lines>
 		</method>
 		<method name='build' parameters='self,input_shape'>
 				<method_info nloc='6' complexity='1' token_count='72' nesting_level='1' start_line='155' end_line='166'></method_info>
 			<added_lines>157,158,159,160,161,162,163,164,165,166</added_lines>
 			<deleted_lines>157,158,159</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\rnn\tests\layer_norm_lstm_cell_test.py' new_name='tensorflow_addons\rnn\tests\layer_norm_lstm_cell_test.py'>
 		<file_info nloc='110' complexity='5' token_count='1022'></file_info>
 		<method name='test_build' parameters=''>
 				<method_info nloc='16' complexity='1' token_count='155' nesting_level='0' start_line='126' end_line='141'></method_info>
 			<added_lines>126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>124,125</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
