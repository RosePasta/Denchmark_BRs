<bug_data>
<bug id='699' author='sarim-zafar' open_date='2019-11-14T22:14:26Z' closed_time='2019-11-18T15:30:22Z'>
 	<summary>Lifted Struct Loss Error</summary>
 	<description>
 System information
 
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Linux)
 TensorFlow version and how it was installed (source or binary): binary 2.0
 TensorFlow-Addons version and how it was installed (source or binary): binary 0.6.0
 Python version: 3
 Is GPU used? (yes/no): Yes
 
 Describe the bug
 I get an assert shape error when I try to initialize the LiftedStructLoss obj
 assert lshape.shape == 1 AssertionError is the error I get. However, it can easily be resolved by removing the assert line. I have one more question, why does it say that the vector should not be l2 normalized? while in the case of semihardtriplet loss it says that the vector should be l2 normalized
 Code to reproduce the issue
 import tensorflow_addons as tfa
 tfa.losses.LiftedStructLoss()
 	</description>
 	<comments>
 		<comment id='1' author='sarim-zafar' date='2019-11-15T07:11:53Z'>
 		
 That is similar to #295. I would submit a PR later.
 I think it is ok to take normalized embedding as input for lifted struct loss as there is no addition normalization done in the paper; triplet loss used in facenet model states the embedding should be normalized in Figure 2.
 
 However, in both implementation, we do not check whether the embedding is l2 normalized explicitly so the documentation is only a note for user rather than a constraint. Please correct me if I am wrong. Thanks for reporting the issue!
 		</comment>
 		<comment id='2' author='sarim-zafar' date='2019-11-15T15:19:39Z'>
 		
 Yes it is same as the one referenced above
 I tried experimenting with l2 normalization of relu , sigmoid activation, relu activation. After a couple thousand iterations, the normalized embedding's loss stagnates while the other two keep decreasing. So there is definitely something specific to the implementation. I tried going through the paper for lifted struct loss but they don't mention normalization anywhere.
 As for the triplet loss i am fine with it and yes i know they add normalization there.
 
 		</comment>
 	</comments>
 </bug>
<commit id='245986497878f28963c22a1e06ddc28d429ad5a3' author='Tzu-Wei Sung' date='2019-11-18 15:30:21+00:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\losses\lifted.py' new_name='tensorflow_addons\losses\lifted.py'>
 		<file_info nloc='72' complexity='4' token_count='561'></file_info>
 		<method name='lifted_struct_loss' parameters='labels,embeddings,margin'>
 				<method_info nloc='39' complexity='1' token_count='384' nesting_level='0' start_line='27' end_line='102'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>42</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\losses\lifted_test.py' new_name='tensorflow_addons\losses\lifted_test.py'>
 		<file_info nloc='68' complexity='12' token_count='570'></file_info>
 		<method name='testLiftedStruct' parameters='self'>
 				<method_info nloc='38' complexity='9' token_count='337' nesting_level='1' start_line='57' end_line='107'></method_info>
 			<added_lines>67,69,72,74</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_keras_model_compile' parameters='self'>
 				<method_info nloc='6' complexity='1' token_count='57' nesting_level='1' start_line='109' end_line='114'></method_info>
 			<added_lines>109,110,111,112,113,114</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>115</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
