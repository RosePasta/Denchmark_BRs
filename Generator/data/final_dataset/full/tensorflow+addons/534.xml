<bug_data>
<bug id='534' author='kazemnejad' open_date='2019-09-20T19:53:00Z' closed_time='2019-10-07T18:28:09Z'>
 	<summary>BasicDecoder fails with masked input tensor</summary>
 	<description>
 System information
 
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
 TensorFlow version and how it was installed (source or binary): binary(2.0.0-dev20190920)
 TensorFlow-Addons version and how it was installed (source or binary): binary(0.6.0-dev)
 Python version: 3.6
 Is GPU used? (yes/no): yes
 
 Describe the bug
 When the BasicDecoder receives a tensor equipped with masking meta-data as the input, it will fail due to the unhandled mask argument in TrainingSampler.initialize(..). This is a common scenario in which the input tensor is computed using the embedding layer.
 Code to reproduce the issue
 units = 32
 vocab_size = 1000
 embedding = tf.keras.layers.Embedding(
     input_dim=vocab_size, output_dim=units, mask_zero=True)
 attention_mechanism = attention_wrapper.LuongAttention(units)
 cell = tf.keras.layers.LSTMCell(units)
 cell = tfa.seq2seq.AttentionWrapper(cell, attention_mechanism)
 output_layer = tf.keras.layers.Dense(vocab_size)
 sampler = tfa.seq2seq.sampler.TrainingSampler()
 decoder = tfa.seq2seq.BasicDecoder(
     cell, sampler, output_layer=output_layer)
 
 # setup the attention mechanism's memory with a random tensor
 fake_mem = tf.random.normal((2, 3, units))
 fake_mem_mask = tf.ones((2,3), dtype=tf.bool)
 attention_mechanism(fake_mem, mask=fake_mem_mask, setup_memory=True)
 
 word_ids = tf.random.uniform((2, 5), 0, vocab_size, dtype=tf.int64) \
             * tf.constant([[1, 1, 1, 0, 0], [1, 1, 1, 1, 1]], dtype=tf.int64)
 word_embeds = embedding(word_ids)
 mask = embedding.compute_mask(word_ids)
 
 initial_state = cell.get_initial_state(batch_size=2, dtype=tf.float32)
 outputs = decoder(
     inputs=word_embeds,
     initial_state=initial_state,
     sequence_length=tf.math.reduce_sum(tf.cast(mask, tf.int32), axis=1),
 )
 It will raise the following error:
 &lt;denchmark-code&gt;  File "tensorflow_addons/seq2seq/basic_decoder.py", line 72, in initialize
     return self.sampler.initialize(inputs, **kwargs) + (initial_state,)
 TypeError: initialize() got an unexpected keyword argument 'mask'
 &lt;/denchmark-code&gt;
 
 Other info / logs
 This issue happens because we capture the mask argument on the BaseDecoder.call(..., **kwargs) and propagate it all the way through TrainingSample.initialize(...) except that the initialize method doesn't accept the mask argument.
 One can temporarily fix this error by adding delattr(word_embeds, '_keras_mask') just before calling the decoder instance.
 I encountered this issue when i was working on #335
 Ideas to fix this issue:
 
 Fix the BasicDecoder to only pass the appropriate argument when it calls the sampler. or even fix the TrainingSampler to capture all other arguments using the kwargs
 Add the appropriate support for the mask argument in the TrainingSampler in additon to sequence_length (similar to AttentionMechanism)
 
 I think there is no harm in the latter option as it provides a more Keras-friendly way to work with the framework.
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='83d28c90dcdf8d361ee5d3102258d924459e911c' author='Amirhossein Kazemnejad' date='2019-10-07 14:28:08-04:00'>
 	<dmm_unit complexity='0.6017699115044248' interfacing='0.9557522123893806' size='0.20353982300884957'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\seq2seq\basic_decoder_test.py' new_name='tensorflow_addons\seq2seq\basic_decoder_test.py'>
 		<file_info nloc='712' complexity='22' token_count='5029'></file_info>
 		<method name='testStepWithTrainingHelperMaskedInput' parameters='self,use_mask'>
 				<method_info nloc='85' complexity='5' token_count='618' nesting_level='1' start_line='127' end_line='219'></method_info>
 			<added_lines>127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testRightPaddedSequenceAssertion' parameters='self'>
 				<method_info nloc='12' complexity='1' token_count='95' nesting_level='1' start_line='803' end_line='816'></method_info>
 			<added_lines>803,804,805,806,807,808,809,810,811,812,813,814,815,816</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>125,126,220,817</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\seq2seq\sampler.py' new_name='tensorflow_addons\seq2seq\sampler.py'>
 		<file_info nloc='517' complexity='85' token_count='3468'></file_info>
 		<method name='_check_sequence_is_right_padded' parameters='mask,time_major'>
 				<method_info nloc='11' complexity='2' token_count='107' nesting_level='0' start_line='803' end_line='817'></method_info>
 			<added_lines>803,804,805,806,807,808,809,810,811,812,813,814,815,816,817</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='initialize' parameters='self,inputs,sequence_length,mask,auxiliary_inputs'>
 				<method_info nloc='5' complexity='1' token_count='19' nesting_level='1' start_line='433' end_line='437'></method_info>
 			<added_lines>433,434,435,436,437</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='initialize' parameters='self,inputs,sequence_length,mask,embedding'>
 				<method_info nloc='5' complexity='1' token_count='19' nesting_level='1' start_line='337' end_line='341'></method_info>
 			<added_lines>337,338,339,340,341</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='initialize' parameters='self,inputs,sequence_length'>
 				<method_info nloc='22' complexity='4' token_count='210' nesting_level='1' start_line='204' end_line='241'></method_info>
 			<added_lines>205,211,223,224,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241</added_lines>
 			<deleted_lines>204,222,223,224,225,226,227,228,229,234,235</deleted_lines>
 		</method>
 		<method name='initialize' parameters='self,inputs,sequence_length,auxiliary_inputs'>
 				<method_info nloc='18' complexity='4' token_count='133' nesting_level='1' start_line='400' end_line='418'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>400,418</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,time_major'>
 				<method_info nloc='3' complexity='1' token_count='20' nesting_level='1' start_line='176' end_line='188'></method_info>
 			<added_lines>184,185</added_lines>
 			<deleted_lines>184</deleted_lines>
 		</method>
 		<method name='initialize' parameters='self,inputs,sequence_length,embedding'>
 				<method_info nloc='10' complexity='3' token_count='68' nesting_level='1' start_line='308' end_line='317'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>308,317</deleted_lines>
 		</method>
 		<method name='initialize' parameters='self,inputs,sequence_length,mask'>
 				<method_info nloc='45' complexity='10' token_count='391' nesting_level='1' start_line='205' end_line='270'></method_info>
 			<added_lines>205,211,223,224,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260</added_lines>
 			<deleted_lines>222,223,224,225,226,227,228,229,234,235</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>350,455,456,457,801,802</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
