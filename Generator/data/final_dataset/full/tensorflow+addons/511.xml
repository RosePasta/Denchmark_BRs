<bug_data>
<bug id='511' author='kazemnejad' open_date='2019-09-15T11:44:17Z' closed_time='2019-09-18T06:03:02Z'>
 	<summary>Creating an instance of BasicDecoder fails with AttentionMechanism without memory</summary>
 	<description>
 System information
 
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
 TensorFlow version and how it was installed (source or binary): 2.0.0-dev20190914
 TensorFlow-Addons version and how it was installed (source or binary): 0.6.0-dev
 Python version: 3.6
 Is GPU used? (yes/no): Yes
 
 Describe the bug
 When creating a BasicDecoder using an AttentionWrapper cell which itself is created by using an AttentionMechinsm without a memory, an error is raised.
 Code to reproduce the issue
 units = 32
 vocab_size = 1000
 attention_mechanism = tfa.seq2seq.LuongAttention(units)
 cell = tf.keras.layers.LSTMCell(units)
 attention_wrapper = tfa.seq2seq.AttentionWrapper(
     cell, attention_mechanism)
 
 vocab_proj_layer = tf.keras.layers.Dense(vocab_size)
 decoder_sampler = tfa.seq2seq.sampler.TrainingSampler()
 decoder = tfa.seq2seq.BasicDecoder(
     cell=attention_wrapper, 
     sampler=decoder_sampler, 
     output_layer=vocab_proj_layer)
 Other info / logs
 &lt;denchmark-code&gt;ValueError: The AttentionMechanism instances passed to this AttentionWrapper should be initialized with a memory first, either by passing it to the AttentionMechanism constructor or calling attention_mechanism.setup_memory()
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-link:https://github.com/tensorflow/addons/files/3613698/error.txt&gt;Full trace&lt;/denchmark-link&gt;
 
 The cause of this error is probably the rnn_cell_impl.assert_like_rnncell("cell", cell) check which is present in the BasicDecoder's constructor. The above assertion will end up in AttentionWrapper.output_size or AttentionWrapper.state_size.
 This issue is probably related to &lt;denchmark-link:https://github.com/tensorflow/addons/issues/461&gt;#461&lt;/denchmark-link&gt;
 
 I encountered this issue when i was working on #335.
 	</description>
 	<comments>
 		<comment id='1' author='kazemnejad' date='2019-09-15T13:05:04Z'>
 		Thanks for the report!
 It appears  reimplements its own  in terms of : &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/d70e8ee2d8c75d5af830f6f6ebc233fc93a89081&gt;tensorflow/tensorflow@d70e8ee&lt;/denchmark-link&gt;
 . This is certainly to support cells overriding  but it's unclear how common this use case is.
 As it is a private TensorFlow API, I would suggest to implement an alternative that works for us. What do you think?
 		</comment>
 		<comment id='2' author='kazemnejad' date='2019-09-15T17:21:42Z'>
 		Yes, I think it would work completely fine. However, it would restrict the type of RNNCells that we could potentially accept. So probably we need to document it somewhere in our code to inform the future users.
 In addition, Maybe we should warn the user to not use our .output_size/.state_size before the memory initialization. And even double-check our code to make sure that we wait until the initialization of the memory.
 		</comment>
 	</comments>
 </bug>
<commit id='b086968285088816c02a38f28852178bfbe4bb98' author='Guillaume Klein' date='2019-09-18 14:03:01+08:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.68'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\seq2seq\attention_wrapper.py' new_name='tensorflow_addons\seq2seq\attention_wrapper.py'>
 		<file_info nloc='1084' complexity='137' token_count='6340'></file_info>
 		<modified_lines>
 			<added_lines>29,30,1639</added_lines>
 			<deleted_lines>1637</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\seq2seq\basic_decoder.py' new_name='tensorflow_addons\seq2seq\basic_decoder.py'>
 		<file_info nloc='68' complexity='12' token_count='504'></file_info>
 		<method name='__init__' parameters='self,cell,sampler,output_layer,kwargs'>
 				<method_info nloc='13' complexity='4' token_count='105' nesting_level='1' start_line='39' end_line='65'></method_info>
 			<added_lines>54</added_lines>
 			<deleted_lines>56</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>27</added_lines>
 			<deleted_lines>27,28,29</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\seq2seq\basic_decoder_test.py' new_name='tensorflow_addons\seq2seq\basic_decoder_test.py'>
 		<file_info nloc='613' complexity='16' token_count='4291'></file_info>
 		<method name='testBasicDecoderWithAttentionWrapper' parameters='self'>
 				<method_info nloc='10' complexity='1' token_count='74' nesting_level='1' start_line='695' end_line='705'></method_info>
 			<added_lines>695,696,697,698,699,700,701,702,703,704,705</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>25,706</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\seq2seq\beam_search_decoder.py' new_name='tensorflow_addons\seq2seq\beam_search_decoder.py'>
 		<file_info nloc='671' complexity='82' token_count='4357'></file_info>
 		<modified_lines>
 			<added_lines>28,275</added_lines>
 			<deleted_lines>30,31,32,277</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\utils\keras_utils.py' new_name='tensorflow_addons\utils\keras_utils.py'>
 		<file_info nloc='57' complexity='14' token_count='321'></file_info>
 		<method name='_hasattr' parameters='obj,attr_name'>
 				<method_info nloc='9' complexity='3' token_count='34' nesting_level='0' start_line='72' end_line='82'></method_info>
 			<added_lines>72,73,74,75,76,77,78,79,80,81,82</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='assert_like_rnncell' parameters='cell_name,cell'>
 				<method_info nloc='16' complexity='4' token_count='94' nesting_level='0' start_line='85' end_line='114'></method_info>
 			<added_lines>85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>70,71,83,84</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_addons\utils\keras_utils_test.py' new_name='tensorflow_addons\utils\keras_utils_test.py'>
 		<file_info nloc='32' complexity='5' token_count='264'></file_info>
 		<method name='test_non_cell' parameters='self'>
 				<method_info nloc='3' complexity='1' token_count='30' nesting_level='1' start_line='45' end_line='47'></method_info>
 			<added_lines>45,46,47</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_custom_cell.output_size' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='3' start_line='52' end_line='53'></method_info>
 			<added_lines>52,53</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_normalize_tuple' parameters='self'>
 				<method_info nloc='11' complexity='1' token_count='113' nesting_level='1' start_line='26' end_line='38'></method_info>
 			<added_lines>27,28,30,31,32,35,38</added_lines>
 			<deleted_lines>26,28,31,34</deleted_lines>
 		</method>
 		<method name='test_custom_cell' parameters='self'>
 				<method_info nloc='5' complexity='1' token_count='31' nesting_level='1' start_line='49' end_line='55'></method_info>
 			<added_lines>49,50,51,52,53,54,55</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_standard_cell' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='42' end_line='43'></method_info>
 			<added_lines>42,43</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>21,22,39,40,41,44,48</added_lines>
 			<deleted_lines>21</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
