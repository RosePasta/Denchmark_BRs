<bug_data>
<bug id='1290' author='AmitMY' open_date='2020-03-30T11:08:50Z' closed_time='2020-04-24T14:29:25Z'>
 	<summary>bug(logger): wandb fails on sweep</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 When using wandb sweeps for hyperparameters search, I get this error:
 
 wandb: ERROR Attempted to change value of key "dropout_std" from 0.030424838979365657 to 0.030424838979365654
 
 The reason is I ran:
 wandb_logger.log_hyperparams(params)
 Which I guess has some problem with floating-point numbers in high accuracy?
 	</description>
 	<comments>
 		<comment id='1' author='AmitMY' date='2020-03-30T18:04:40Z'>
 		+1, I faced the same issue when using pytorch lightning with wandb sweeps. To summarize, wandb automatically logs hyperparams when we run the wandb sweep agent on a machine. Later, pytorch lightning again tries to log same hyperparams but due to precision error between lightning and wandb already logged hyperparams, wandb throws this error. Just a guess: wandb sweep agent might be using double format to generate new hyperparams and when lightning receives those args from command line, it converts them to float and tries to log it. I haven't digged in detail where these hyperparams get altered, it could be on wandb side or lightning side.
 I reported this issue to wandb and got the following response:
 
 It is preferred to either pass your config parameters all at once to: wandb.init(config=config_dict_that_could_have_params_set_by_sweep)
 or:
 experiment = wandb.init()
 experiment.config.setdefaults(config_dict_that_could_have_params_set_by_sweep)
 The advantage of doing this is that it will ignore setting any key that has already been set by the sweep.
 We will look into the torch lightning integration and see if we can make this safer for those using sweeps.
 
 		</comment>
 		<comment id='2' author='AmitMY' date='2020-03-30T18:05:52Z'>
 		cc: &lt;denchmark-link:https://github.com/neggert&gt;@neggert&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='AmitMY' date='2020-03-30T18:24:10Z'>
 		&lt;denchmark-link:https://github.com/borisdayma&gt;@borisdayma&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/calclavia&gt;@calclavia&lt;/denchmark-link&gt;
  pls ^^
 		</comment>
 		<comment id='4' author='AmitMY' date='2020-03-30T18:37:27Z'>
 		The problem is that it tries to log this value twice and is probably called before automatically by pytorch-lightning.
 The callback will automatically log every parameter which is in pl.LightningModule.params (where you probably already have the dropout).
 See an example of using pytorch-lightning with wandb (including sweeps) here: &lt;denchmark-link:https://github.com/borisdayma/lightning-kitti&gt;https://github.com/borisdayma/lightning-kitti&lt;/denchmark-link&gt;
 
 I'll be adding it to the pytorch-lightning repo later but still need to push a PR related to the watch method for it to work properly.
 		</comment>
 		<comment id='5' author='AmitMY' date='2020-04-16T22:26:11Z'>
 		&lt;denchmark-link:https://github.com/borisdayma&gt;@borisdayma&lt;/denchmark-link&gt;
  is it fixed now?
 		</comment>
 		<comment id='6' author='AmitMY' date='2020-04-16T23:45:41Z'>
 		I added a fix.
 &lt;denchmark-link:https://github.com/AmitMY&gt;@AmitMY&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/amoudgl&gt;@amoudgl&lt;/denchmark-link&gt;
  Feel free to test it with your sweeps and let me know if there's still an error.
 		</comment>
 	</comments>
 </bug>
<commit id='f3d139e90f9212813c4f5e6de777bdef9dfe7635' author='Boris Dayma' date='2020-04-24 10:29:24-04:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>69,70</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\loggers\wandb.py' new_name='pytorch_lightning\loggers\wandb.py'>
 		<file_info nloc='115' complexity='15' token_count='546'></file_info>
 		<method name='log_hyperparams' parameters='self,str'>
 				<method_info nloc='3' complexity='1' token_count='43' nesting_level='1' start_line='115' end_line='117'></method_info>
 			<added_lines>117</added_lines>
 			<deleted_lines>117</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\loggers\test_wandb.py' new_name='tests\loggers\test_wandb.py'>
 		<file_info nloc='40' complexity='2' token_count='375'></file_info>
 		<method name='test_wandb_logger' parameters='wandb'>
 				<method_info nloc='14' complexity='1' token_count='190' nesting_level='0' start_line='11' end_line='32'></method_info>
 			<added_lines>26</added_lines>
 			<deleted_lines>26</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
