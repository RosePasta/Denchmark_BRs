<bug_data>
<bug id='2058' author='ssakhavi' open_date='2020-06-03T08:16:37Z' closed_time='2020-06-23T15:20:45Z'>
 	<summary>Hydra MLFlow Clash</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 When using the MLFlow logger with Hydra, because the parameters passed to the LightningModule is a DictConfig, the condition in the logger/base.py is not met.
 
 
 
 pytorch-lightning/pytorch_lightning/loggers/base.py
 
 
          Line 177
       in
       8211256
 
 
 
 
 
 
  if isinstance(input_dict, dict): 
 
 
 
 
 
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Use Hydra and MLFlow together.
 Traceback (most recent call last):
   File "/home/siavash/KroniKare/kwae2/kwae_ma/models/pl_train_segmentation_model.py", line 115, in &lt;module&gt;
     main()
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/hydra/main.py", line 24, in decorated_main
     strict=strict,
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/hydra/_internal/utils.py", line 174, in run_hydra
     overrides=args.overrides,
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/hydra/_internal/hydra.py", line 86, in run
     job_subdir_key=None,
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/hydra/plugins/common/utils.py", line 109, in run_job
     ret.return_value = task_function(task_cfg)
   File "/home/siavash/KroniKare/kwae2/kwae_ma/models/pl_train_segmentation_model.py", line 111, in main
     trainer.fit(wound_seg_pl)
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 765, in fit
     self.single_gpu_train(model)
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py", line 492, in single_gpu_train
     self.run_pretrain_routine(model)
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 843, in run_pretrain_routine
     self.logger.log_hyperparams(ref_model.hparams)
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py", line 275, in log_hyperparams
     [logger.log_hyperparams(params) for logger in self._logger_iterable]
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py", line 275, in &lt;listcomp&gt;
     [logger.log_hyperparams(params) for logger in self._logger_iterable]
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py", line 10, in wrapped_fn
     return fn(*args, **kwargs)
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/pytorch_lightning/loggers/mlflow.py", line 105, in log_hyperparams
     self.experiment.log_param(self.run_id, k, v)
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/mlflow/tracking/client.py", line 206, in log_param
     self._tracking_client.log_param(run_id, key, value)
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py", line 177, in log_param
     _validate_param_name(key)
   File "/home/siavash/anaconda3/envs/kwae-ma/lib/python3.7/site-packages/mlflow/utils/validation.py", line 120, in _validate_param_name
     INVALID_PARAMETER_VALUE)
 mlflow.exceptions.MlflowException: Invalid parameter name: ''. Names may be treated as files in certain cases, and must not resolve to other names when treated as such. This name would resolve to '.'
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 Check whether the instance if dict or DictConfig in the given line.
 	</description>
 	<comments>
 		<comment id='1' author='ssakhavi' date='2020-06-03T08:17:21Z'>
 		Hi! thanks for your contribution!, great first issue!
 		</comment>
 		<comment id='2' author='ssakhavi' date='2020-06-03T09:35:01Z'>
 		
 Check whether the instance if dict or DictConfig in the given line.
 
 &lt;denchmark-link:https://github.com/ssakhavi&gt;@ssakhavi&lt;/denchmark-link&gt;
  that sounds reasonable solution, mind sending a PR - fix and its test?
 		</comment>
 	</comments>
 </bug>
<commit id='44385bb582467acaa35cd4da553b2343a7860598' author='Siavash Sakhavi' date='2020-06-23 17:20:44+02:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\loggers\base.py' new_name='pytorch_lightning\loggers\base.py'>
 		<file_info nloc='281' complexity='63' token_count='1438'></file_info>
 		<method name='_flatten_dict' parameters='str,str'>
 				<method_info nloc='19' complexity='2' token_count='49' nesting_level='1' start_line='155' end_line='186'></method_info>
 			<added_lines>175,177</added_lines>
 			<deleted_lines>177,179</deleted_lines>
 		</method>
 		<method name='_flatten_dict._dict_generator' parameters='input_dict,prefixes'>
 				<method_info nloc='12' complexity='9' token_count='119' nesting_level='2' start_line='173' end_line='184'></method_info>
 			<added_lines>175,177</added_lines>
 			<deleted_lines>177,179</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>6</added_lines>
 			<deleted_lines>6,11,12</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
