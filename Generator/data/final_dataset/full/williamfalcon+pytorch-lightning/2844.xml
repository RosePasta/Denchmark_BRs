<bug_data>
<bug id='2844' author='ananthsub' open_date='2020-08-06T01:26:00Z' closed_time='2020-08-07T13:13:22Z'>
 	<summary>Tensorboard logger fails to save model OmegaConf hparams</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 The Tensorboard logger fails to log module hyperparameters configured with OmegaConf. This happens when updating the logger hparams here:
 
 The trainer calls the logger's log_hyperparams here:
 Inside log_hyperparams the logger's hparams are updated here. This causes the hparams type to now be dict instead of DictConfig
 As a result, this branch in [save_hparams_to_yaml](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/core/saving.py#L330-L333) is never triggered
 
 This is the stacktrace when logging hyperparams: &lt;denchmark-link:https://gist.github.com/ananthsub/7acfdb0e0f551ed030f05f7674c37b46&gt;https://gist.github.com/ananthsub/7acfdb0e0f551ed030f05f7674c37b46&lt;/denchmark-link&gt;
 
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;
 
 A hacky fix would be something like changing the hparams update to use this inside the tensorboard logger:
 &lt;denchmark-code&gt;if isinstance(params, Container):
    self.hparams = OmegaConf.merge(self.hparams, params)
 else:
     self.hparams.update(params)
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 Please copy and paste the output from our
 &lt;denchmark-link:https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py&gt;environment collection script&lt;/denchmark-link&gt;
 
 (or fill out the checklist below manually).
 You can get the script and run it with:
 &lt;denchmark-code&gt;wget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py
 # For security purposes, please check the contents of collect_env_details.py before running it.
 python collect_env_details.py
 &lt;/denchmark-code&gt;
 
 
 PyTorch Version (e.g., 1.0):
 OS (e.g., Linux):
 How you installed PyTorch (conda, pip, source):
 Build command you used (if compiling from source):
 Python version:
 CUDA/cuDNN version:
 GPU models and configuration:
 Any other relevant information:
 
 &lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;
 
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='b39f4798a6859d2237b48b29b39a2390164612c1' author='ananthsub' date='2020-08-07 09:13:21-04:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>42,43</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\saving.py' new_name='pytorch_lightning\core\saving.py'>
 		<file_info nloc='283' complexity='41' token_count='1177'></file_info>
 		<method name='save_hparams_to_yaml' parameters='config_yaml,dict'>
 				<method_info nloc='19' complexity='6' token_count='125' nesting_level='0' start_line='323' end_line='345'></method_info>
 			<added_lines>332</added_lines>
 			<deleted_lines>330</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>20,21,22</added_lines>
 			<deleted_lines>20</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\loggers\tensorboard.py' new_name='pytorch_lightning\loggers\tensorboard.py'>
 		<file_info nloc='169' complexity='26' token_count='871'></file_info>
 		<modified_lines>
 			<added_lines>20,21,22,23,24,25,26,122,123,124,125</added_lines>
 			<deleted_lines>115</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_io.py' new_name='pytorch_lightning\trainer\training_io.py'>
 		<file_info nloc='371' complexity='96' token_count='1870'></file_info>
 		<method name='dump_checkpoint' parameters='self,bool'>
 				<method_info nloc='45' complexity='20' token_count='310' nesting_level='1' start_line='335' end_line='402'></method_info>
 			<added_lines>395</added_lines>
 			<deleted_lines>393</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>135,136,137</added_lines>
 			<deleted_lines>135</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\loggers\test_tensorboard.py' new_name='tests\loggers\test_tensorboard.py'>
 		<file_info nloc='104' complexity='9' token_count='777'></file_info>
 		<method name='test_tensorboard_no_name' parameters='tmpdir,name'>
 				<method_info nloc='5' complexity='1' token_count='49' nesting_level='0' start_line='92' end_line='97'></method_info>
 			<added_lines>97</added_lines>
 			<deleted_lines>97</deleted_lines>
 		</method>
 		<method name='test_tensorboard_hparams_reload' parameters='tmpdir'>
 				<method_info nloc='10' complexity='1' token_count='101' nesting_level='0' start_line='19' end_line='36'></method_info>
 			<added_lines>22,28,32,36</added_lines>
 			<deleted_lines>19,20,21,22,28,32,36</deleted_lines>
 		</method>
 		<method name='test_tensorboard_log_metrics' parameters='tmpdir,step_idx'>
 				<method_info nloc='9' complexity='1' token_count='55' nesting_level='0' start_line='101' end_line='109'></method_info>
 			<added_lines>107</added_lines>
 			<deleted_lines>107</deleted_lines>
 		</method>
 		<method name='test_tensorboard_log_omegaconf_hparams_and_metrics' parameters='tmpdir'>
 				<method_info nloc='13' complexity='1' token_count='87' nesting_level='0' start_line='143' end_line='158'></method_info>
 			<added_lines>143,144,145,146,147,148,149,150,151,152,153,154,155,156,157</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_tensorboard_log_hparams_and_metrics' parameters='tmpdir'>
 				<method_info nloc='14' complexity='1' token_count='101' nesting_level='0' start_line='127' end_line='140'></method_info>
 			<added_lines>134,136,137,139,140</added_lines>
 			<deleted_lines>134,136,137,139</deleted_lines>
 		</method>
 		<method name='test_tensorboard_log_hyperparams' parameters='tmpdir'>
 				<method_info nloc='13' complexity='1' token_count='83' nesting_level='0' start_line='112' end_line='124'></method_info>
 			<added_lines>119,121,122</added_lines>
 			<deleted_lines>119,121,122</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>7,15,16,17,18,91,141,142</added_lines>
 			<deleted_lines>14,15,91</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
