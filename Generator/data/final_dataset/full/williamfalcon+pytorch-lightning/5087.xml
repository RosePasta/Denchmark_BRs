<bug_data>
<bug id='5087' author='philipbecker' open_date='2020-12-11T12:07:11Z' closed_time='2021-01-17T18:34:59Z'>
 	<summary>Edge case bug when validating on multiple data sets if .log is not called at least once for each data set.</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 When validating on multiple data sets, if you call self.log(..) for any data set, self.log(..) also has to have been called for all previous data sets at least once. If not, you get a KeyError when the results are auto reduced. I encountered this because for one of my validation sets I only created and logged images.
 &lt;denchmark-h:h2&gt;Reproduce&lt;/denchmark-h&gt;
 
 import pytorch_lightning as pl
 import torch
 from torch.utils.data import DataLoader, TensorDataset
 
 
 class Module(pl.LightningModule):
     def __init__(self):
         super().__init__()
         self.model = torch.nn.Linear(1, 1)
 
     def validation_step(self, batch, batch_idx, dataset_idx):
         if dataset_idx == 0:
             # When you uncomment the following line, everything works.
             # self.log("test1", 0.)
             # Just calling self.log for dataset 0 and not for dataset 1 also works
             pass
         else:
             self.log("test2", 0.)
 
     def val_dataloader(self):
         return (
             DataLoader(TensorDataset(torch.ones(2, 1))),
             DataLoader(TensorDataset(torch.ones(2, 1)))
         )
 
     def training_step(self, batch, batch_idx):
         return torch.mean(self.model(batch[0]))
 
     def train_dataloader(self):
         return DataLoader(TensorDataset(torch.ones(2, 1)))
 
     def configure_optimizers(self):
         return torch.optim.SGD(self.parameters(), lr=0.01)
 
 
 if __name__ == "__main__":
     trainer = pl.Trainer()
     trainer.fit(Module())
 Error you get:
 &lt;denchmark-code&gt;  File "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py", line 690, in run_sanity_check
     _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches)
   File "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py", line 622, in run_evaluation
     deprecated_eval_results = self.evaluation_loop.evaluation_epoch_end()
   File "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/evaluation_loop.py", line 203, in evaluation_epoch_end
     self.trainer.logger_connector.evaluation_epoch_end(self.testing)
   File "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py", line 225, in evaluation_epoch_end
     self.cached_results.has_batch_loop_finished = True
   File "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py", line 441, in has_batch_loop_finished
     self.auto_reduce_results_on_epoch_end()
   File "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py", line 431, in auto_reduce_results_on_epoch_end
     hook_result.auto_reduce_results_on_epoch_end()
   File "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py", line 195, in auto_reduce_results_on_epoch_end
     epoch_metrics = self._internals[dl_idx]
 KeyError: 0
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;* CUDA:
         - GPU:
         - available:         False
         - version:           10.2
 * Packages:
         - numpy:             1.19.4
         - pyTorch_debug:     False
         - pyTorch_version:   1.7.1
         - pytorch-lightning: 1.1.0
         - tqdm:              4.54.1
 * System:
         - OS:                Linux
         - architecture:
                 - 64bit
                 - ELF
         - processor:         x86_64
         - python:            3.6.9
         - version:           #62-Ubuntu SMP Mon Nov 23 19:20:19 UTC 2020
 
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='philipbecker' date='2020-12-11T12:08:00Z'>
 		Hi! thanks for your contribution!, great first issue!
 		</comment>
 		<comment id='2' author='philipbecker' date='2021-01-10T18:06:11Z'>
 		This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!
 		</comment>
 	</comments>
 </bug>
<commit id='9cfbf8d6092de6d6b26b67dbdb93dfeb406a2c70' author='Rohit Gupta' date='2021-01-06 12:57:24+01:00'>
 	<dmm_unit complexity='1.0' interfacing='0.8809523809523809' size='0.5714285714285714'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>71,72</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='docs\source\debugging.rst' new_name='docs\source\debugging.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>31,38,39,40,41,42</added_lines>
 			<deleted_lines>31</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='docs\source\trainer.rst' new_name='docs\source\trainer.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>669,670,671</added_lines>
 			<deleted_lines>669,670,671</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\callbacks\early_stopping.py' new_name='pytorch_lightning\callbacks\early_stopping.py'>
 		<file_info nloc='162' complexity='34' token_count='736'></file_info>
 		<method name='_run_early_stopping_check' parameters='self,trainer,pl_module'>
 				<method_info nloc='27' complexity='10' token_count='191' nesting_level='1' start_line='181' end_line='221'></method_info>
 			<added_lines>186,188,189,190,191</added_lines>
 			<deleted_lines>181,182,183,184,185,186,187,194,196</deleted_lines>
 		</method>
 		<method name='on_train_epoch_end' parameters='self,trainer,pl_module,outputs'>
 				<method_info nloc='4' complexity='2' token_count='25' nesting_level='1' start_line='174' end_line='179'></method_info>
 			<added_lines>179</added_lines>
 			<deleted_lines>179</deleted_lines>
 		</method>
 		<method name='on_validation_epoch_end' parameters='self,trainer,pl_module'>
 				<method_info nloc='5' complexity='4' token_count='34' nesting_level='1' start_line='166' end_line='172'></method_info>
 			<added_lines>167,170</added_lines>
 			<deleted_lines>167,170</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>180</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\callbacks\gpu_stats_monitor.py' new_name='pytorch_lightning\callbacks\gpu_stats_monitor.py'>
 		<file_info nloc='166' complexity='33' token_count='876'></file_info>
 		<method name='_should_log' parameters='trainer'>
 				<method_info nloc='7' complexity='3' token_count='38' nesting_level='1' start_line='210' end_line='217'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>216</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>27</added_lines>
 			<deleted_lines>27</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\callbacks\lr_monitor.py' new_name='pytorch_lightning\callbacks\lr_monitor.py'>
 		<file_info nloc='139' complexity='34' token_count='741'></file_info>
 		<method name='on_train_batch_start' parameters='self,trainer,args,kwargs'>
 				<method_info nloc='8' complexity='5' token_count='68' nesting_level='1' start_line='100' end_line='109'></method_info>
 			<added_lines>108</added_lines>
 			<deleted_lines>108</deleted_lines>
 		</method>
 		<method name='_should_log' parameters='trainer'>
 				<method_info nloc='7' complexity='3' token_count='38' nesting_level='1' start_line='187' end_line='194'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>193</deleted_lines>
 		</method>
 		<method name='on_train_epoch_start' parameters='self,trainer,args,kwargs'>
 				<method_info nloc='6' complexity='4' token_count='58' nesting_level='1' start_line='111' end_line='117'></method_info>
 			<added_lines>116</added_lines>
 			<deleted_lines>116</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\callbacks\model_checkpoint.py' new_name='pytorch_lightning\callbacks\model_checkpoint.py'>
 		<file_info nloc='481' complexity='93' token_count='2427'></file_info>
 		<method name='__resolve_ckpt_dir' parameters='self,trainer,pl_module'>
 				<method_info nloc='22' complexity='8' token_count='161' nesting_level='1' start_line='420' end_line='462'></method_info>
 			<added_lines>454,461</added_lines>
 			<deleted_lines>453,460</deleted_lines>
 		</method>
 		<method name='save_checkpoint' parameters='self,trainer,pl_module'>
 				<method_info nloc='19' complexity='8' token_count='110' nesting_level='1' start_line='208' end_line='243'></method_info>
 			<added_lines>218,219</added_lines>
 			<deleted_lines>218</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>26,27</added_lines>
 			<deleted_lines>23,26</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\callbacks\progress.py' new_name='pytorch_lightning\callbacks\progress.py'>
 		<file_info nloc='311' complexity='59' token_count='1456'></file_info>
 		<method name='on_epoch_start' parameters='self,trainer,pl_module'>
 				<method_info nloc='11' complexity='3' token_count='79' nesting_level='1' start_line='321' end_line='332'></method_info>
 			<added_lines>325</added_lines>
 			<deleted_lines>326</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>25</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\connectors\debugging_connector.py' new_name='pytorch_lightning\trainer\connectors\debugging_connector.py'>
 		<file_info nloc='65' complexity='8' token_count='358'></file_info>
 		<modified_lines>
 			<added_lines>16,17,19,59,62,63,64,65,68</added_lines>
 			<deleted_lines>15,61</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\properties.py' new_name='pytorch_lightning\trainer\properties.py'>
 		<file_info nloc='237' complexity='68' token_count='1402'></file_info>
 		<method name='early_stopping_callbacks' parameters='self'>
 				<method_info nloc='6' complexity='3' token_count='28' nesting_level='1' start_line='234' end_line='239'></method_info>
 			<added_lines>234,235,236,237,238,239</added_lines>
 			<deleted_lines>235</deleted_lines>
 		</method>
 		<method name='early_stopping_callback' parameters='self'>
 				<method_info nloc='7' complexity='2' token_count='30' nesting_level='1' start_line='225' end_line='231'></method_info>
 			<added_lines>225,226,227,228,229,230,231</added_lines>
 			<deleted_lines>227,228</deleted_lines>
 		</method>
 		<method name='checkpoint_callbacks' parameters='self'>
 				<method_info nloc='6' complexity='3' token_count='28' nesting_level='1' start_line='251' end_line='256'></method_info>
 			<added_lines>252,253,254,255</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='checkpoint_callback' parameters='self'>
 				<method_info nloc='7' complexity='2' token_count='30' nesting_level='1' start_line='242' end_line='248'></method_info>
 			<added_lines>244,245</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='enable_validation' parameters='self'>
 				<method_info nloc='5' complexity='2' token_count='33' nesting_level='1' start_line='198' end_line='202'></method_info>
 			<added_lines>202</added_lines>
 			<deleted_lines>202</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>18,21,224,232,233,240</added_lines>
 			<deleted_lines>18,21</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_loop.py' new_name='pytorch_lightning\trainer\training_loop.py'>
 		<file_info nloc='553' complexity='164' token_count='4091'></file_info>
 		<method name='save_loggers_on_train_batch_end' parameters='self'>
 				<method_info nloc='4' complexity='4' token_count='41' nesting_level='1' start_line='911' end_line='915'></method_info>
 			<added_lines>914,915</added_lines>
 			<deleted_lines>914,915</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>916</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\callbacks\test_early_stopping.py' new_name='tests\callbacks\test_early_stopping.py'>
 		<file_info nloc='193' complexity='23' token_count='1434'></file_info>
 		<method name='test_early_stopping_no_extraneous_invocations' parameters='tmpdir'>
 				<method_info nloc='14' complexity='1' token_count='75' nesting_level='0' start_line='86' end_line='101'></method_info>
 			<added_lines>89,93,99,100</added_lines>
 			<deleted_lines>93</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>16,23,26</added_lines>
 			<deleted_lines>21,23,24,26</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\checkpointing\test_checkpoint_callback_frequency.py' new_name='tests\checkpointing\test_checkpoint_callback_frequency.py'>
 		<file_info nloc='56' complexity='5' token_count='470'></file_info>
 		<method name='test_mc_called_on_fastdevrun' parameters='tmpdir'>
 				<method_info nloc='17' complexity='1' token_count='98' nesting_level='0' start_line='25' end_line='66'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66</deleted_lines>
 		</method>
 		<method name='test_mc_called_on_fastdevrun.training_step' parameters='self,batch,batch_idx'>
 				<method_info nloc='3' complexity='1' token_count='25' nesting_level='2' start_line='48' end_line='50'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>48,49,50</deleted_lines>
 		</method>
 		<method name='test_mc_called_on_fastdevrun.__init__' parameters='self'>
 				<method_info nloc='5' complexity='1' token_count='27' nesting_level='2' start_line='42' end_line='46'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>42,43,44,45,46</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>20</added_lines>
 			<deleted_lines>20,24,67,68</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\checkpointing\test_model_checkpoint.py' new_name='tests\checkpointing\test_model_checkpoint.py'>
 		<file_info nloc='711' complexity='93' token_count='5327'></file_info>
 		<method name='test_hparams_type' parameters='tmpdir,hparams_type'>
 				<method_info nloc='26' complexity='3' token_count='148' nesting_level='0' start_line='880' end_line='909'></method_info>
 			<added_lines>893,894</added_lines>
 			<deleted_lines>892</deleted_lines>
 		</method>
 		<method name='test_current_score_when_nan' parameters='tmpdir,mode'>
 				<method_info nloc='22' complexity='2' token_count='104' nesting_level='0' start_line='851' end_line='876'></method_info>
 			<added_lines>866,867</added_lines>
 			<deleted_lines>866</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>31</added_lines>
 			<deleted_lines>31</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\loggers\test_all.py' new_name='tests\loggers\test_all.py'>
 		<file_info nloc='265' complexity='29' token_count='1896'></file_info>
 		<method name='_test_loggers_fit_test' parameters='tmpdir,logger_class'>
 				<method_info nloc='45' complexity='7' token_count='280' nesting_level='0' start_line='83' end_line='141'></method_info>
 			<added_lines>117,118,119</added_lines>
 			<deleted_lines>117,118,119</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\trainer\flags\test_fast_dev_run.py' new_name='tests\trainer\flags\test_fast_dev_run.py'>
 		<file_info nloc='69' complexity='8' token_count='464'></file_info>
 		<method name='test_callbacks_and_logger_not_called_with_fastdevrun.validation_step' parameters='self,batch,batch_idx'>
 				<method_info nloc='3' complexity='1' token_count='25' nesting_level='2' start_line='49' end_line='51'></method_info>
 			<added_lines>49,50,51</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_callbacks_and_logger_not_called_with_fastdevrun.training_step' parameters='self,batch,batch_idx'>
 				<method_info nloc='5' complexity='1' token_count='58' nesting_level='2' start_line='43' end_line='47'></method_info>
 			<added_lines>43,44,45,46,47</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_skip_on_fast_dev_run_tuner' parameters='tmpdir,tuner_alg'>
 				<method_info nloc='12' complexity='3' token_count='71' nesting_level='0' start_line='14' end_line='27'></method_info>
 			<added_lines>17</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_callbacks_and_logger_not_called_with_fastdevrun._make_fast_dev_run_assertions' parameters='trainer'>
 				<method_info nloc='8' complexity='1' token_count='71' nesting_level='1' start_line='62' end_line='74'></method_info>
 			<added_lines>62,63,64,65,66,67,68,69,70,71,72,73,74</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_callbacks_and_logger_not_called_with_fastdevrun.__init__' parameters='self'>
 				<method_info nloc='5' complexity='1' token_count='27' nesting_level='2' start_line='37' end_line='41'></method_info>
 			<added_lines>37,38,39,40,41</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_callbacks_and_logger_not_called_with_fastdevrun' parameters='tmpdir,fast_dev_run'>
 				<method_info nloc='29' complexity='1' token_count='131' nesting_level='0' start_line='32' end_line='101'></method_info>
 			<added_lines>32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1,2,3,5,6,8,9,10,28,29,30,31</added_lines>
 			<deleted_lines>3,10,11</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
