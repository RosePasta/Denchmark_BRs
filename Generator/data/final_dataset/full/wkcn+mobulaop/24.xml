<bug_data>
<bug id='24' author='YutingZhang' open_date='2018-12-28T06:16:57Z' closed_time='2018-12-29T14:18:55Z'>
 	<summary>Not working with MXNet nightly build (1.5.0b20181222)</summary>
 	<description>
 With MXNet 1.5 nightly build (1.5.0b20181222), import mobula gives segmentation fault.
 	</description>
 	<comments>
 		<comment id='1' author='YutingZhang' date='2018-12-28T07:35:22Z'>
 		Thanks for your report.
 In my test,
 &lt;denchmark-code&gt;OS: Arch Linux
 Python: 2.7.15 &amp; 3.7.1
 mxnet==1.5.0b20181222 (only cpu)
 MobulaOP (master, a58c062)
 
 OS: Ubuntu 16.04
 Python: 3.5.2
 mxnet-cu90==1.5.0b20181222
 MobulaOP (master, a58c062)
 &lt;/denchmark-code&gt;
 
 Script:
 import mobula
 It works fine.
 Could you please provide the following information?
 
 Operating System
 Python Version
 Error message, including stack trace
 
 Thank you!
 		</comment>
 		<comment id='2' author='YutingZhang' date='2018-12-28T23:48:41Z'>
 		Thank you for your reply.
 EC2 machine: p3.xlarge
 OS: Ubuntu 16.04
 CUDA: 9.0
 Python: 3.6.6 (anaconda mxnet_p36 from AWS deep learning AMI)
 MXNet: installed by pip install -U mxnet-cu90mkl --pre (so now it is mxnet-cu90mkl-1.5.0b20181228)
 Error message:
 &lt;denchmark-code&gt;[15:47:50] $ python3 -c 'import mobula'
 
 Segmentation fault: 11
 
 Stack trace returned 10 entries:
 [bt] (0) /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3ebbea) [0x7f20fb0ecbea]
 [bt] (1) /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x34740b6) [0x7f20fe1750b6]
 [bt] (2) /lib/x86_64-linux-gnu/libc.so.6(+0x354b0) [0x7f213dd524b0]
 [bt] (3) /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so(+0x420308) [0x7f206b1c1308]
 [bt] (4) /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so(+0x422520) [0x7f206b1c3520]
 [bt] (5) /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so(+0xbbfcb2) [0x7f206b960cb2]
 [bt] (6) /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so(torch::onnx::initONNXBindings(_object*)+0x4f) [0x7f206b95aeff]
 [bt] (7) /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/torch/_C.cpython-36m-x86_64-linux-gnu.so(PyInit__C+0x15a) [0x7f206b11f60a]
 [bt] (8) python3(_PyImport_LoadDynamicModuleWithSpec+0x185) [0x55c473b50b85]
 [bt] (9) python3(+0x215d85) [0x55c473b50d85]
 &lt;/denchmark-code&gt;
 
 By the way, it is working with mxnet-cu90mkl-1.3.1
 		</comment>
 		<comment id='3' author='YutingZhang' date='2018-12-29T01:26:01Z'>
 		&lt;denchmark-link:https://github.com/YutingZhang&gt;@YutingZhang&lt;/denchmark-link&gt;
  Thanks.
 MobulaOP will import MXNet and PyTorch simultaneously if MXNet and PyTorch exist.
 It seems that there is a conflict when importing MXNet and PyTorch.
 The following script may trigger segmentation fault too.
 import mxnet
 import torch
 or
 import torch
 import mxnet
 I will fix the bug of MobulaOP to avoid importing MXNet and PyTorch simultaneously.
 		</comment>
 		<comment id='4' author='YutingZhang' date='2018-12-29T02:34:11Z'>
 		I create a new branch &lt;denchmark-link:https://github.com/wkcn/MobulaOP/tree/patch_for_24&gt;patch_for_24&lt;/denchmark-link&gt;
  to fix the bug.
 It may work. Thanks.
 		</comment>
 		<comment id='5' author='YutingZhang' date='2018-12-29T04:15:06Z'>
 		&lt;denchmark-link:https://github.com/wkcn&gt;@wkcn&lt;/denchmark-link&gt;
  Thank you so much! The patch is working.
 		</comment>
 		<comment id='6' author='YutingZhang' date='2018-12-29T14:18:55Z'>
 		Fixed the bug in PR &lt;denchmark-link:https://github.com/wkcn/MobulaOP/pull/26&gt;#26&lt;/denchmark-link&gt;
  :)
 		</comment>
 	</comments>
 </bug>
<commit id='c93b6ad4720ef031f053e21e68f501832191aa1b' author='JackieWu' date='2018-12-29 22:17:48+08:00'>
 	<dmm_unit complexity='0.9130434782608695' interfacing='1.0' size='0.9130434782608695'></dmm_unit>
 	<modification change_type='MODIFY' old_name='mobula\glue\backend.py' new_name='mobula\glue\backend.py'>
 		<file_info nloc='80' complexity='25' token_count='497'></file_info>
 		<method name='_register_backend_real' parameters='glue_name,types_name'>
 				<method_info nloc='22' complexity='7' token_count='124' nesting_level='0' start_line='17' end_line='39'></method_info>
 			<added_lines>17,18,33,34,35,39</added_lines>
 			<deleted_lines>31,35</deleted_lines>
 		</method>
 		<method name='get_var_type_backend' parameters='v_type'>
 				<method_info nloc='10' complexity='3' token_count='65' nesting_level='0' start_line='61' end_line='71'></method_info>
 			<added_lines>61,62,63,64,65,66,67,68,69,70,71</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_var_backend' parameters='v'>
 				<method_info nloc='2' complexity='1' token_count='13' nesting_level='0' start_line='74' end_line='75'></method_info>
 			<added_lines>75</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='register_backend' parameters='glue_name,types_name'>
 				<method_info nloc='11' complexity='3' token_count='57' nesting_level='0' start_line='42' end_line='52'></method_info>
 			<added_lines>42,43,44,45,46,47,48,49,50,51,52</added_lines>
 			<deleted_lines>42,44,45,46,50</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>3,4,5,40,41,60</added_lines>
 			<deleted_lines>3,4,16</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='mobula\glue\common.py' new_name='mobula\glue\common.py'>
 		<file_info nloc='132' complexity='26' token_count='961'></file_info>
 		<method name='__getitem__' parameters='self,input_type'>
 				<method_info nloc='6' complexity='1' token_count='34' nesting_level='1' start_line='98' end_line='108'></method_info>
 			<added_lines>99</added_lines>
 			<deleted_lines>99</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
