<bug_data>
<bug id='2035' author='yeliang2258' open_date='2020-02-11T13:00:30Z' closed_time='2020-04-15T06:10:14Z'>
 	<summary>The AGP_Pruner example provided can not run successfully, An error occurred: TypeError: unsupported operand type (s) for *: 'Tensor' and 'dict'</summary>
 	<description>
 The error is:
 &lt;denchmark-link:https://user-images.githubusercontent.com/30516196/74238560-01e83780-4d11-11ea-8864-98d74396143d.png&gt;&lt;/denchmark-link&gt;
 
 The first epoch can run, but the second epoch reports an error.
 The code is from  the sample main_torch_pruner.py（&lt;denchmark-link:https://github.com/microsoft/nni/blob/master/examples/model_compress/main_torch_pruner.py%EF%BC%89&gt;https://github.com/microsoft/nni/blob/master/examples/model_compress/main_torch_pruner.py）&lt;/denchmark-link&gt;
 
 code：
 from nni.compression.torch import AGP_Pruner
 import torch
 import torch.nn.functional as F
 from torchvision import datasets, transforms
 class Mnist(torch.nn.Module):
 def init(self):
 super().init()
 self.conv1 = torch.nn.Conv2d(1, 20, 5, 1)
 self.conv2 = torch.nn.Conv2d(20, 50, 5, 1)
 self.fc1 = torch.nn.Linear(4 * 4 * 50, 500)
 self.fc2 = torch.nn.Linear(500, 10)
 &lt;denchmark-code&gt;def forward(self, x):
     x = F.relu(self.conv1(x))
     x = F.max_pool2d(x, 2, 2)
     x = F.relu(self.conv2(x))
     x = F.max_pool2d(x, 2, 2)
     x = x.view(-1, 4 * 4 * 50)
     x = F.relu(self.fc1(x))
     x = self.fc2(x)
     return F.log_softmax(x, dim=1)
 &lt;/denchmark-code&gt;
 
 def train(model, device, train_loader, optimizer):
 model.train()
 for batch_idx, (data, target) in enumerate(train_loader):
 data, target = data.to(device), target.to(device)
 optimizer.zero_grad()
 output = model(data)
 loss = F.nll_loss(output, target)
 loss.backward()
 optimizer.step()
 if batch_idx % 100 == 0:
 print('{:2.0f}%  Loss {}'.format(100 * batch_idx / len(train_loader), loss.item()))
 def test(model, device, test_loader):
 model.eval()
 test_loss = 0
 correct = 0
 with torch.no_grad():
 for data, target in test_loader:
 data, target = data.to(device), target.to(device)
 output = model(data)
 test_loss += F.nll_loss(output, target, reduction='sum').item()
 pred = output.argmax(dim=1, keepdim=True)
 correct += pred.eq(target.view_as(pred)).sum().item()
 test_loss /= len(test_loader.dataset)
 &lt;denchmark-code&gt;print('Loss: {}  Accuracy: {}%)\n'.format(
     test_loss, 100 * correct / len(test_loader.dataset)))
 &lt;/denchmark-code&gt;
 
 def main():
 torch.manual_seed(0)
 device = torch.device('cpu')
 &lt;denchmark-code&gt;trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
 train_loader = torch.utils.data.DataLoader(
     datasets.MNIST('data', train=True, download=True, transform=trans),
     batch_size=64, shuffle=True)
 test_loader = torch.utils.data.DataLoader(
     datasets.MNIST('data', train=False, transform=trans),
     batch_size=1000, shuffle=True)
 
 model = Mnist()
 model.to(device)
 
 '''you can change this to LevelPruner to implement it
 pruner = LevelPruner(configure_list)
 '''
 configure_list = [{
     'initial_sparsity': 0,
     'final_sparsity': 0.8,
     'start_epoch': 0,
     'end_epoch': 10,
     'frequency': 1,
     'op_types': ['default']
 }]
 
 pruner = AGP_Pruner(model, configure_list)
 model = pruner.compress()
 
 optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)
 for epoch in range(10):
     pruner.update_epoch(epoch)
     print('# Epoch {} #'.format(epoch))
     train(model, device, train_loader, optimizer)
     test(model, device, test_loader)
 pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28])
 &lt;/denchmark-code&gt;
 
 if name == 'main':
 main()
 Thanks！
 	</description>
 	<comments>
 		<comment id='1' author='yeliang2258' date='2020-02-11T15:09:43Z'>
 		Hi &lt;denchmark-link:https://github.com/yeliang2258&gt;@yeliang2258&lt;/denchmark-link&gt;
  , thanks for bringing up this issue！Could you try using nni v1.4? This is fixed in latest version.
 		</comment>
 		<comment id='2' author='yeliang2258' date='2020-02-12T06:52:37Z'>
 		
 Hi @yeliang2258 , thanks for bringing up this issue！Could you try using nni v1.4? This is fixed in latest version.
 
 Hello, using cpu, AGP can work normally, but using cuda will report an error, the error message is as follows. The code is the provided example, I changed cpu to cuda, Thanks！
 &lt;denchmark-link:https://user-images.githubusercontent.com/30516196/74310011-1d9e1d00-4da7-11ea-82ca-a79dae0f90f0.png&gt;&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='yeliang2258' date='2020-02-12T07:35:00Z'>
 		Hi, &lt;denchmark-link:https://github.com/yeliang2258&gt;@yeliang2258&lt;/denchmark-link&gt;
  , could you try add  after line  and see if it works? It seems some buffers registered by pruner are not transfered into cuda, which caused the error. Thanks!
 		</comment>
 		<comment id='4' author='yeliang2258' date='2020-02-12T07:46:20Z'>
 		
 Hi, @yeliang2258 , could you try add model = model.to(device) after line model = pruner.compress() and see if it works? It seems some buffers registered by pruner are not transfered into cuda, which caused the error. Thanks!
 
 Still not working, the error message is as follows：
 &lt;denchmark-link:https://user-images.githubusercontent.com/30516196/74313508-c734dc80-4dae-11ea-9678-b9c7cd82dfec.png&gt;&lt;/denchmark-link&gt;
 
 The function pruner.export_model ()) in the example has no effect. Thanks!
 		</comment>
 		<comment id='5' author='yeliang2258' date='2020-02-12T07:53:31Z'>
 		Hi &lt;denchmark-link:https://github.com/yeliang2258&gt;@yeliang2258&lt;/denchmark-link&gt;
 , could you change  into ?
 default device for export_model is cpu, which cause the error.
 If it works, you are welcome to submit a PR for this  outdated example. Thanks!
 		</comment>
 		<comment id='6' author='yeliang2258' date='2020-02-12T08:01:40Z'>
 		
 Hi @yeliang2258, could you change pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28]) into pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28], device)?
 default device for export_model is cpu, which cause the error.
 If it works, you are welcome to submit a PR for this outdated example. Thanks!
 
 I modified it and found two problems. First, the pruner.export_model () function did not generate the corresponding file. Second, cuda still couldn't be used, and the same error was reported. my torch is 1.2.0，and nni is V1.4
 		</comment>
 		<comment id='7' author='yeliang2258' date='2020-02-12T08:50:31Z'>
 		Hi &lt;denchmark-link:https://github.com/yeliang2258&gt;@yeliang2258&lt;/denchmark-link&gt;
 , after some debugging, it turns out there is a bug in code for transfering buffers between device. Since most examples set origin  buffers on cuda, the bug is not spotted. Anyway, I will fix this issue later and inform you after this issue is fixed and tested.
 		</comment>
 		<comment id='8' author='yeliang2258' date='2020-02-12T09:10:08Z'>
 		
 Hi @yeliang2258, after some debugging, it turns out there is a bug in code for transfering buffers between device. Since most examples set origin buffers on cuda, the bug is not spotted. Anyway, I will fix this issue later and inform you after this issue is fixed and tested.
 
 Ok! thank you very much! Also, the pruner.export_model () function in AGP does not seem to work, it does not generate the corresponding file.
 		</comment>
 		<comment id='9' author='yeliang2258' date='2020-02-12T09:13:09Z'>
 		Hi, &lt;denchmark-link:https://github.com/yeliang2258&gt;@yeliang2258&lt;/denchmark-link&gt;
  , the file is generated in the same directory as the directory you run the python command. example:  then file is in directory a. Files are generated as expected in my machine. could you check if files are in other directory? Thanks!
 		</comment>
 		<comment id='10' author='yeliang2258' date='2020-04-15T06:10:13Z'>
 		Closing as the original problem is fixed. thanks &lt;denchmark-link:https://github.com/yeliang2258&gt;@yeliang2258&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/Cjkkkk&gt;@Cjkkkk&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='b7045b1938cb58506a6f8dc8274c971f630d9105' author='Cjkkkk' date='2020-02-16 21:14:11+08:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.9090909090909091'></dmm_unit>
 	<modification change_type='MODIFY' old_name='examples\model_compress\main_torch_pruner.py' new_name='examples\model_compress\main_torch_pruner.py'>
 		<file_info nloc='80' complexity='9' token_count='757'></file_info>
 		<method name='main' parameters=''>
 				<method_info nloc='33' complexity='2' token_count='280' nesting_level='0' start_line='56' end_line='92'></method_info>
 			<added_lines>58,69,85,92</added_lines>
 			<deleted_lines>58,69,85,92</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\sdk\pynni\nni\compression\torch\compressor.py' new_name='src\sdk\pynni\nni\compression\torch\compressor.py'>
 		<file_info nloc='277' complexity='81' token_count='2138'></file_info>
 		<method name='get_registered_buffers' parameters='self'>
 				<method_info nloc='5' complexity='2' token_count='29' nesting_level='1' start_line='244' end_line='248'></method_info>
 			<added_lines>244,245,246,247,248</added_lines>
 			<deleted_lines>246</deleted_lines>
 		</method>
 		<method name='forward' parameters='self,inputs'>
 				<method_info nloc='10' complexity='6' token_count='147' nesting_level='1' start_line='250' end_line='261'></method_info>
 			<added_lines>251</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,module,module_name,module_type,config,pruner'>
 				<method_info nloc='18' complexity='4' token_count='173' nesting_level='1' start_line='204' end_line='242'></method_info>
 			<added_lines>229,237,238,242</added_lines>
 			<deleted_lines>229,237,238,239</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,module,module_name,module_type,config,quantizer'>
 				<method_info nloc='18' complexity='4' token_count='162' nesting_level='1' start_line='382' end_line='424'></method_info>
 			<added_lines>407,424</added_lines>
 			<deleted_lines>416,419</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>243,425,426,427,428,429,430,440,449,462</added_lines>
 			<deleted_lines>243,429,438,451</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\sdk\pynni\nni\compression\torch\pruners.py' new_name='src\sdk\pynni\nni\compression\torch\pruners.py'>
 		<file_info nloc='195' complexity='45' token_count='1509'></file_info>
 		<method name='update_epoch' parameters='self,epoch'>
 				<method_info nloc='5' complexity='3' token_count='40' nesting_level='1' start_line='161' end_line='173'></method_info>
 			<added_lines>173</added_lines>
 			<deleted_lines>173</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
