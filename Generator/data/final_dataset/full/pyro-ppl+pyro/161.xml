<bug_data>
<bug id='161' author='fritzo' open_date='2017-09-27T21:20:25Z' closed_time='2017-10-04T05:45:13Z'>
 	<summary>Dirichlet distribution treats shape inconsistently</summary>
 	<description>
 While the tests for pyro.distributions.dirichlet test with a 1-dimensional tensor alpha, the Dirichlet constructor uses ad hoc logic to ensure there are at least 2 dimensions in the alpha. Moreover the ad hoc 2-dimensional tensor does not work, and is preventing me from using Dirichlet as a prior on component weights in a mixture model.
 See &lt;denchmark-link:https://github.com/pyro-ppl/pyro/issues/153&gt;#153&lt;/denchmark-link&gt;
  for more comprehensive solution.
 Example excerpt:
 # This is inside a model:
 ps = pyro.sample('ps', Dirichlet(alpha=Variable(torch.ones(10) / 0.5)))
 Error message:
 
 ---------------------------------------------------------------------------
 ValueError                                Traceback (most recent call last)
  in ()
       1 get_ipython().magic(u'pdb off')
 ----&gt; 2 inference(data)
 /Users/fritzobermeyer/github/uber/pyro/pyro/infer/kl_qp.pyc in call(self, *args, **kwargs)
 51
 52     def call(self, *args, **kwargs):
 ---&gt; 53         return self.step(*args, **kwargs)
 54
 55     def populate_traces(self, *args, **kwargs):
 /Users/fritzobermeyer/github/uber/pyro/pyro/infer/kl_qp.pyc in step(self, *args, **kwargs)
 160
 161         if 'loss_and_params' not in kwargs.keys():
 --&gt; 162             [loss, all_trainable_params] = self.eval_grad(*args, **kwargs)
 163         else:
 164             [loss, all_trainable_params] = kwargs['loss_and_params']
 /Users/fritzobermeyer/github/uber/pyro/pyro/infer/kl_qp.pyc in eval_grad(self, *args, **kwargs)
 109         """
 110
 --&gt; 111         [model_traces, guide_traces, log_r_per_sample] = self.populate_traces(*args, **kwargs)
 112
 113         elbo = 0.0
 /Users/fritzobermeyer/github/uber/pyro/pyro/infer/kl_qp.pyc in populate_traces(self, *args, **kwargs)
 64             guide_trace = poutine.trace(self.guide)(*args, **kwargs)
 65             model_trace = poutine.trace(
 ---&gt; 66                 poutine.replay(self.model, guide_trace))(*args, **kwargs)
 67
 68             log_r = model_trace.log_pdf() - guide_trace.log_pdf()
 /Users/fritzobermeyer/github/uber/pyro/pyro/poutine/init.pyc in _fn(*args, **kwargs)
 25     def _fn(*args, **kwargs):
 26         p = TracePoutine(fn)
 ---&gt; 27         return p(*args, **kwargs)
 28
 29     return _fn
 /Users/fritzobermeyer/github/uber/pyro/pyro/poutine/poutine.pyc in call(self, *args, **kwargs)
 28
 29             # run the original function overloading the fcts
 ---&gt; 30             base_r_val = self.orig_fct(*args, **kwargs)
 31
 32             # then return the pyro global fcts to their previous state
 /Users/fritzobermeyer/github/uber/pyro/pyro/poutine/init.pyc in _fn(*args, **kwargs)
 49     def _fn(*args, **kwargs):
 50         p = ReplayPoutine(fn, trace, sites=sites)
 ---&gt; 51         return p(*args, **kwargs)
 52
 53     return _fn
 /Users/fritzobermeyer/github/uber/pyro/pyro/poutine/poutine.pyc in call(self, *args, **kwargs)
 28
 29             # run the original function overloading the fcts
 ---&gt; 30             base_r_val = self.orig_fct(*args, **kwargs)
 31
 32             # then return the pyro global fcts to their previous state
  in model(data)
 6     # Global parameters.
 7     if use_dirichlet_prior:
 ----&gt; 8         ps = pyro.sample('ps', Dirichlet(alpha=Variable(torch.ones(K) * 0.5)))
 9     else:
 10         # FIXME I would put a Dirichlet prior here, but Dirichlet is buggy.
 /Users/fritzobermeyer/github/uber/pyro/pyro/init.pyc in sample(name, fn, *args, **kwargs)
 105         }
 106         # apply the stack and return its return value
 --&gt; 107         out_msg = apply_stack(msg)
 108         return out_msg["ret"]
 109
 /Users/fritzobermeyer/github/uber/pyro/pyro/init.pyc in apply_stack(initial_msg, stack)
 71     # go until time to stop?
 72     for j in range(0, len(stack)):
 ---&gt; 73         msg = stack[j].up(msg)
 74         if msg["stop"]:
 75             break
 /Users/fritzobermeyer/github/uber/pyro/pyro/poutine/poutine.pyc in up(self, msg)
 67             ret = self._pyro_sample(msg, msg["name"],
 68                                     msg["fn"],
 ---&gt; 69                                     *msg["args"], **msg["kwargs"])
 70         elif msg["type"] == "observe":
 71             ret = self._pyro_observe(msg, msg["name"],
 /Users/fritzobermeyer/github/uber/pyro/pyro/poutine/replay_poutine.pyc in _pyro_sample(self, msg, name, fn, *args, **kwargs)
 67         # case 2: dict, negative: sample from model
 68         elif name not in self.sites:
 ---&gt; 69             return super(ReplayPoutine, self)._pyro_sample(msg, name, fn, *args, **kwargs)
 70         else:
 71             raise ValueError(
 /Users/fritzobermeyer/github/uber/pyro/pyro/poutine/poutine.pyc in _pyro_sample(self, msg, name, fn, *args, **kwargs)
 128         if msg["done"]:
 129             return msg["ret"]
 --&gt; 130         val = fn(*args, **kwargs)
 131         msg["done"] = True
 132         return val
 /Users/fritzobermeyer/github/uber/pyro/pyro/distributions/distribution.pyc in call(self, *args, **kwargs)
 16         Samples on call
 17         """
 ---&gt; 18         return self.sample(*args, **kwargs)
 19
 20     def sample(self, *args, **kwargs):
 /Users/fritzobermeyer/github/uber/pyro/pyro/distributions/dirichlet.pyc in sample(self, alpha, *args, **kwargs)
 45         # _alpha = Variable(torch.Tensor([[1,2],[3,4]]))
 46         x = Variable(torch.Tensor(spr.dirichlet.rvs(
 ---&gt; 47                      _alpha.data.numpy()))
 48                      .type_as(_alpha.data)).squeeze(0)
 49         return x
 /Users/fritzobermeyer/miniconda2/envs/pyro2/lib/python2.7/site-packages/scipy/stats/_multivariate.pyc in rvs(self, alpha, size, random_state)
 1355
 1356         """
 -&gt; 1357         alpha = _dirichlet_check_parameters(alpha)
 1358         random_state = self._get_random_state(random_state)
 1359         return random_state.dirichlet(alpha, size=size)
 /Users/fritzobermeyer/miniconda2/envs/pyro2/lib/python2.7/site-packages/scipy/stats/_multivariate.pyc in _dirichlet_check_parameters(alpha)
 1075     elif alpha.ndim != 1:
 1076         raise ValueError("Parameter vector 'a' must be one dimensional, "
 -&gt; 1077                        "but a.shape = %s." % (alpha.shape, ))
 1078     return alpha
 1079
 ValueError: Parameter vector 'a' must be one dimensional, but a.shape = (1, 2).
 
 
 	</description>
 	<comments>
 		<comment id='1' author='fritzo' date='2017-09-27T21:21:19Z'>
 		It's also concerning that we're not testing the codepath
 x = Dirichlet(alpha=anything_other_than_None)
 Has this codepath ever worked? What is its intended behavior?
 		</comment>
 		<comment id='2' author='fritzo' date='2017-09-27T22:21:21Z'>
 		good call, the scipy Dirichlet only takes 1-d alphas, which mean that the expand in the constructor should be removed. This also means that you can never call batch_log_pdf on it because these samples are one dimensional. thats kind of annoying, we might need to implement batched alphas ourselves. numpy allows you to sample a specific shape, but those are using the same alpha and drawing m x n samples
 		</comment>
 	</comments>
 </bug>
<commit id='00b5688ecb1535f844ee4575ec590f2166dd8a62' author='Fritz Obermeyer' date='2017-10-03 22:45:12-07:00'>
 	<dmm_unit complexity='0.19230769230769232' interfacing='0.07692307692307693' size='0.19230769230769232'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pyro\distributions\dirichlet.py' new_name='pyro\distributions\dirichlet.py'>
 		<file_info nloc='81' complexity='24' token_count='778'></file_info>
 		<method name='__init__' parameters='self,alpha,batch_size,args,kwargs'>
 				<method_info nloc='8' complexity='2' token_count='69' nesting_level='1' start_line='57' end_line='69'></method_info>
 			<added_lines>59,60,61,63,64,65,66,67</added_lines>
 			<deleted_lines>59,60,61,62</deleted_lines>
 		</method>
 		<method name='_sanitize_input' parameters='self,alpha'>
 				<method_info nloc='8' complexity='4' token_count='45' nesting_level='1' start_line='19' end_line='28'></method_info>
 			<added_lines>22,23,25,28</added_lines>
 			<deleted_lines>21,24,25</deleted_lines>
 		</method>
 		<method name='sample' parameters='self,alpha,args,kwargs'>
 				<method_info nloc='13' complexity='4' token_count='142' nesting_level='1' start_line='71' end_line='90'></method_info>
 			<added_lines>73,75,77,78,80,81,82,83,84,85,86,87,88,89,90</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='log_pdf' parameters='self,x,alpha,args,kwargs'>
 				<method_info nloc='5' complexity='1' token_count='57' nesting_level='1' start_line='51' end_line='55'></method_info>
 			<added_lines>51,52,53,54,55</added_lines>
 			<deleted_lines>51,53,54,55</deleted_lines>
 		</method>
 		<method name='_expand_dims' parameters='self,x,alpha'>
 				<method_info nloc='21' complexity='11' token_count='296' nesting_level='1' start_line='30' end_line='55'></method_info>
 			<added_lines>30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55</added_lines>
 			<deleted_lines>30,32,33,34,35,41,42,44,45,46,47,48,49,51,53,54,55</deleted_lines>
 		</method>
 		<method name='batch_log_pdf' parameters='self,x,alpha,batch_size,args,kwargs'>
 				<method_info nloc='9' complexity='1' token_count='104' nesting_level='1' start_line='93' end_line='115'></method_info>
 			<added_lines>94,95,96,97,98,99,100,101,102,103,104,105,106,107,109,110,111,112</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1,12,13,14,16,29,92</added_lines>
 			<deleted_lines>11,13,14,29</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pyro\util.py' new_name='pyro\util.py'>
 		<file_info nloc='164' complexity='51' token_count='1397'></file_info>
 		<method name='log_beta' parameters='t'>
 				<method_info nloc='9' complexity='2' token_count='81' nesting_level='0' start_line='120' end_line='135'></method_info>
 			<added_lines>121,122,123,124,125,126,127,128</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
