<bug_data>
<bug id='2607' author='jmugan' open_date='2020-08-20T02:28:37Z' closed_time='2020-08-31T18:49:19Z'>
 	<summary>Sampling Categorical Quits After Two Samples [bug, but probably user error]</summary>
 	<description>
 &lt;denchmark-h:h3&gt;Issue Description&lt;/denchmark-h&gt;
 
 The sampler works with a Gaussian but not with categorical. Similar as &lt;denchmark-link:https://github.com/pyro-ppl/pyro/issues/2159&gt;#2159&lt;/denchmark-link&gt;
  but it was suggested that I open a new issue.
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 Python 3.7 with Pyro 1.4.0
 &lt;denchmark-h:h3&gt;Code Snippet&lt;/denchmark-h&gt;
 
 If I set use_gaussian to True it works as expected.
 &lt;denchmark-code&gt;import torch
 import pyro
 import pyro.distributions as dist
 import pyro.poutine as poutine
 from pyro.infer import MCMC, NUTS
 #pyro.set_rng_seed(101)
 
 # This works if I set it to True
 use_gaussian = False
 
 def model(prior_elves):
     print('prior:', prior_elves)
     if use_gaussian:
         num_elves = pyro.sample("num_elves",
                                    dist.Normal(prior_elves, torch.tensor(2.0)))
     else:
         num_elves = pyro.sample("num_elves",
                                pyro.distributions.Categorical(probs=prior_elves))
     print("Num elves: ", num_elves)
 
     num_rocks = num_elves * 4
     num_logs = num_elves * 6
 
     print(f"Rocks: {num_rocks}, Logs: {num_logs}")
 
     # begin https://pyro.ai/examples/intro_part_ii.html
 
     rocks_observed = pyro.sample("rocks_observed",
                                    dist.Normal(num_rocks, torch.tensor(3.0)))
 
     logs_observed = pyro.sample("logs_observed",
                                    dist.Normal(num_logs, torch.tensor(3.0)))
 
     print(f"Rocks obs: {rocks_observed}, Logs obs: {logs_observed}")
 
     return num_elves
 
 def conditioned_model(model, data, prior_elves):
     return poutine.condition(model, data=data)(prior_elves)
 
 data = {"rocks_observed": torch.tensor(4),
     "logs_observed": torch.tensor(6),
     }
 
 if use_gaussian:
     prior_elves = torch.tensor(2.0)
 else:
     prior_elves = torch.tensor([.2,.2,.2,.2,.2])
 
 nuts_kernel = NUTS(conditioned_model, jit_compile=False)
 mcmc = MCMC(nuts_kernel,
                 num_samples=10,
                 warmup_steps=5,
                 num_chains=1)
 mcmc.run(model, data, prior_elves)
 
 mcmc.summary(prob=.5)
 &lt;/denchmark-code&gt;
 
 Gives the output
 &lt;denchmark-code&gt;Sample: 100%|██████████| 15/15 [00:00, 1853.70it/s, step size=1.00e+00, acc. prob=1.000]
 prior: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])
 Num elves:  tensor(4)
 Rocks: 16, Logs: 24
 Rocks obs: 4, Logs obs: 6
 prior: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])
 Num elves:  tensor([0, 1, 2, 3, 4])
 Rocks: tensor([ 0,  4,  8, 12, 16]), Logs: tensor([ 0,  6, 12, 18, 24])
 Rocks obs: 4, Logs obs: 6
 prior: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])
 Num elves:  tensor([0, 1, 2, 3, 4])
 Rocks: tensor([ 0,  4,  8, 12, 16]), Logs: tensor([ 0,  6, 12, 18, 24])
 Rocks obs: 4, Logs obs: 6
 
 Traceback (most recent call last):
   File "/Users/jmugan/Dropbox/code/python_examples/jwm_pyro/elves.py", line 75, in &lt;module&gt;
     mcmc.summary(prob=.5)
   File "/Users/jmugan/anaconda3/lib/python3.7/site-packages/pyro/infer/mcmc/api.py", line 485, in summary
     print_summary(self._samples, prob=prob)
   File "/Users/jmugan/anaconda3/lib/python3.7/site-packages/pyro/infer/mcmc/util.py", line 522, in print_summary
     max_len = max(max(map(lambda x: len(x), row_names.values())), 10)
 ValueError: max() arg is an empty sequence
 
 Process finished with exit code 1
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='jmugan' date='2020-08-20T04:35:54Z'>
 		Because your conditioned_model does not have any continuous latent variable, MCMC will collect nothing for you. The ValueError is indeed a bug: we should print an empty summary, rather than triggering an error.
 		</comment>
 		<comment id='2' author='jmugan' date='2020-08-20T04:49:43Z'>
 		Thanks. I'll have to think about how all this works. I'll leave it open due to the ValueError. Thanks again.
 		</comment>
 		<comment id='3' author='jmugan' date='2020-08-20T05:17:24Z'>
 		In Pyro MCMC, we marginalize the discrete latent variable num_elves. After that, there is no latent variable (two variables rocks_observed and logs_observed are observed after you conditioned on the data). If you only condition on rocks_observed
 (i.e. data = {"rocks_observed": torch.tensor(4)}), then MCMC will collect logs_observed samples. I think your model is a nice example to illustrate the difference between using discrete vs continuous latent variables in Pyro. :)
 		</comment>
 	</comments>
 </bug>
<commit id='927001fdf85d085c669d6a18a6f76e0e6d27845a' author='Du Phan' date='2020-08-20 12:52:18-07:00'>
 	<dmm_unit complexity='0.0' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pyro\infer\mcmc\util.py' new_name='pyro\infer\mcmc\util.py'>
 		<file_info nloc='454' complexity='102' token_count='3406'></file_info>
 		<method name='print_summary' parameters='samples,prob,group_by_chain'>
 				<method_info nloc='22' complexity='7' token_count='276' nesting_level='0' start_line='504' end_line='541'></method_info>
 			<added_lines>518,519</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
