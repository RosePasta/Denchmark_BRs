<bug_data>
<bug id='1841' author='curtis999' open_date='2019-04-30T03:16:49Z' closed_time='2019-05-08T05:55:21Z'>
 	<summary>LDA tutorial: incorrect tensor shape when document size is larger than the vocabulary size</summary>
 	<description>
 
 
 
 pyro/examples/lda.py
 
 
          Line 101
       in
       56c0617
 
 
 
 
 
 
  counts.scatter_add_(0, data[:, ind], torch.tensor(1.).expand(counts.shape)) 
 
 
 
 
 
 The filler array of ones should have expanded into the size of the sliced data. This is problematic when the number of words per document is larger than the vocabulary size
 Try
 counts.scatter_add_(0, data[:, ind], torch.tensor(1.).expand(data[:,ind].shape))
 instead
 	</description>
 	<comments>
 		<comment id='1' author='curtis999' date='2019-04-30T17:02:23Z'>
 		Thanks &lt;denchmark-link:https://github.com/curtis999&gt;@curtis999&lt;/denchmark-link&gt;
  for the report and fix! Do you have a simple example we can add as a regression test? It can be totally random data.
 		</comment>
 		<comment id='2' author='curtis999' date='2019-04-30T21:36:15Z'>
 		&lt;denchmark-link:https://github.com/fritzo&gt;@fritzo&lt;/denchmark-link&gt;
  the error can be replicated simply by passing  or whatever that sets the vocabulary size to be smaller than the total number of words in a document.
 In the example, the data is from the generative model, or we can explicatly generate it with
 &lt;denchmark-code&gt;theta = dist.Dirichlet(torch.zeros([args.num_docs, args.num_topics]) + 0.2).sample()
 phi = dist.Dirichlet(torch.zeros([args.num_topics, args.num_words]) + 0.1).sample()
 z = dist.Categorical(theta).expand([args.num_words_per_doc, args.num_docs]).sample()
 data = dist.Categorical(phi[z]).sample()
 &lt;/denchmark-code&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='3671ec74b8cbdf08af8b1031b91c0596fe53dc14' author='Fritz Obermeyer' date='2019-05-07 22:55:21-07:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='examples\lda.py' new_name='examples\lda.py'>
 		<file_info nloc='107' complexity='10' token_count='999'></file_info>
 		<method name='parametrized_guide' parameters='predictor,data,args,batch_size'>
 				<method_info nloc='19' complexity='1' token_count='210' nesting_level='0' start_line='78' end_line='101'></method_info>
 			<added_lines>95,98,99</added_lines>
 			<deleted_lines>97,98,99,100,101</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_examples.py' new_name='tests\test_examples.py'>
 		<file_info nloc='157' complexity='20' token_count='797'></file_info>
 		<modified_lines>
 			<added_lines>118</added_lines>
 			<deleted_lines>118</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
