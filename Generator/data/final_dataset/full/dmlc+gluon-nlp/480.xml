<bug_data>
<bug id='480' author='szhengac' open_date='2018-12-24T12:04:56Z' closed_time='2019-04-01T18:24:45Z'>
 	<summary>Bug in text classification script?</summary>
 	<description>
 &lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 . In script , I see that the average of the word embeddings without masking out the padding tokens are used to form the hidden units. This looks like a bug as the padding tokens should not be included during averaging the representations.
 	</description>
 	<comments>
 		<comment id='1' author='szhengac' date='2018-12-24T13:11:02Z'>
 		I'm not sure about the text classification scripts. &lt;denchmark-link:https://github.com/sravanbabuiitm&gt;@sravanbabuiitm&lt;/denchmark-link&gt;
  authored them. &lt;denchmark-link:https://github.com/sravanbabuiitm&gt;@sravanbabuiitm&lt;/denchmark-link&gt;
  can you help clarify / fix this?
 		</comment>
 		<comment id='2' author='szhengac' date='2019-04-01T18:24:45Z'>
 		This should have already been fixed in the previous PRs. Let me know if you need the issue reopened.
 		</comment>
 	</comments>
 </bug>
<commit id='f48e12cb42de447768daa6f8feec1c9a06995e62' author='Sravan Babu Bodapati' date='2019-02-19 18:20:34+08:00'>
 	<dmm_unit complexity='1.0' interfacing='0.53125' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='scripts\text_classification\fasttext_word_ngram.py' new_name='scripts\text_classification\fasttext_word_ngram.py'>
 		<file_info nloc='297' complexity='40' token_count='2157'></file_info>
 		<method name='__init__' parameters='self,prefix,params'>
 				<method_info nloc='2' complexity='1' token_count='30' nesting_level='1' start_line='49' end_line='50'></method_info>
 			<added_lines>49,50</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='evaluate_accuracy' parameters='data_iterator,net,ctx,loss_fun,num_classes'>
 				<method_info nloc='18' complexity='3' token_count='187' nesting_level='0' start_line='134' end_line='156'></method_info>
 			<added_lines>142,143,144,145,146,147,149,154</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_length' parameters='inp'>
 				<method_info nloc='2' complexity='1' token_count='17' nesting_level='0' start_line='244' end_line='246'></method_info>
 			<added_lines>244,245,246</added_lines>
 			<deleted_lines>244,245</deleted_lines>
 		</method>
 		<method name='preprocess_dataset' parameters='dataset,labels'>
 				<method_info nloc='9' complexity='1' token_count='88' nesting_level='0' start_line='271' end_line='281'></method_info>
 			<added_lines>271,272,273,274,275,276,277,278,279,280,281</added_lines>
 			<deleted_lines>274</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,vocab_size,embedding_dim,num_classes,kwargs'>
 				<method_info nloc='17' complexity='2' token_count='109' nesting_level='1' start_line='70' end_line='86'></method_info>
 			<added_lines>73,74,76,77,85</added_lines>
 			<deleted_lines>70,71</deleted_lines>
 		</method>
 		<method name='hybrid_forward' parameters='self,F,x'>
 				<method_info nloc='4' complexity='1' token_count='43' nesting_level='1' start_line='69' end_line='72'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>69,70,71</deleted_lines>
 		</method>
 		<method name='hybrid_forward' parameters='self,F,doc,valid_length'>
 				<method_info nloc='6' complexity='1' token_count='62' nesting_level='1' start_line='88' end_line='93'></method_info>
 			<added_lines>88,89,90,91,92</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_dataloader' parameters='train_dataset,train_data_lengths,test_dataset,batch_size'>
 				<method_info nloc='2' complexity='1' token_count='11' nesting_level='0' start_line='284' end_line='285'></method_info>
 			<added_lines>284,285</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_sequence' parameters='inpt'>
 				<method_info nloc='4' complexity='1' token_count='27' nesting_level='0' start_line='249' end_line='253'></method_info>
 			<added_lines>249,250,251,252,253</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='hybrid_forward' parameters='self,F,data,valid_length'>
 				<method_info nloc='7' complexity='1' token_count='58' nesting_level='1' start_line='52' end_line='60'></method_info>
 			<added_lines>52,53,54,55,56,57,58,59,60</added_lines>
 			<deleted_lines>55,56,58,59</deleted_lines>
 		</method>
 		<method name='convert_to_sequences' parameters='dataset,vocab'>
 				<method_info nloc='9' complexity='1' token_count='76' nesting_level='0' start_line='256' end_line='268'></method_info>
 			<added_lines>256,257,258,259,260,261,262,263,264,265,266,267,268</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='parse_args' parameters=''>
 				<method_info nloc='32' complexity='1' token_count='229' nesting_level='0' start_line='175' end_line='214'></method_info>
 			<added_lines>190,191</added_lines>
 			<deleted_lines>188</deleted_lines>
 		</method>
 		<method name='train' parameters='args'>
 				<method_info nloc='96' complexity='10' token_count='712' nesting_level='0' start_line='311' end_line='416'></method_info>
 			<added_lines>311,312,319,320,322,323,329,330,331,332,344,355,356,357,358,359,360,361,368,370,389,390,397,398,401,403,406,407,408,409,411,413,415</added_lines>
 			<deleted_lines>311,318,319,320,324,327,328,329,330,331,332,334,336,338,339,346,347</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>33,36,46,47,48,51,61,62,247,248,254,255,269,270,282,283,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,422,423</added_lines>
 			<deleted_lines>40,121,122,123,124,125,127,132,224,225,226,227,235,236,242,243,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='scripts\text_classification\index.rst' new_name='scripts\text_classification\index.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>26,29,42,44,55,57</added_lines>
 			<deleted_lines>26,29,42,44,55,57</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
