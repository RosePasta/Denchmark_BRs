<bug_data>
<bug id='1217' author='avinashsai' open_date='2020-05-02T11:30:29Z' closed_time='2020-05-07T19:00:43Z'>
 	<summary>TextCNN rand model downloads pretrained vectors even if not needed</summary>
 	<description>
 
 
 TextCNN rand model downloads pretrained word vectors even if not needed. rand model initializes word vectors randomly and updates in the training process. So, I think there is not need to download word vectors for this model.
 
 
 There should be a flag passed to _build_vocab  function representing the type of model. If the model is other than rand, then pretrained vectors should be downloaded.
 
 
 	</description>
 	<comments>
 		<comment id='1' author='avinashsai' date='2020-05-02T17:10:06Z'>
 		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
  your thoughts on this?
 		</comment>
 		<comment id='2' author='avinashsai' date='2020-05-05T21:46:39Z'>
 		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
  I have code ready for this and iam able to reproduce the results as well. What do you think?
 		</comment>
 		<comment id='3' author='avinashsai' date='2020-05-05T21:47:21Z'>
 		Yes, your proposal is sensible. Would you like to open a PR? Thank you.
 		</comment>
 		<comment id='4' author='avinashsai' date='2020-05-05T21:48:26Z'>
 		Sure, will submit PR to this
 		</comment>
 		<comment id='5' author='avinashsai' date='2020-05-07T19:00:43Z'>
 		Fixed via &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/pull/1222&gt;#1222&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='f429d526a0ad9dca21754b53694cba055d3f0986' author='Avinash Madasu' date='2020-05-07 11:59:15-07:00'>
 	<dmm_unit complexity='0.14285714285714285' interfacing='0.14285714285714285' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='scripts\sentiment_analysis\process_data.py' new_name='scripts\sentiment_analysis\process_data.py'>
 		<file_info nloc='116' complexity='27' token_count='1126'></file_info>
 		<method name='load_dataset' parameters='data_name,model_name'>
 				<method_info nloc='22' complexity='3' token_count='225' nesting_level='0' start_line='127' end_line='149'></method_info>
 			<added_lines>127,131,136,143,144</added_lines>
 			<deleted_lines>130,137</deleted_lines>
 		</method>
 		<method name='load_dataset' parameters='data_name'>
 				<method_info nloc='21' complexity='3' token_count='217' nesting_level='0' start_line='121' end_line='142'></method_info>
 			<added_lines>127,131,136</added_lines>
 			<deleted_lines>121,125,130,137</deleted_lines>
 		</method>
 		<method name='_build_vocab' parameters='data_name,train_dataset,test_dataset,dev_dataset,model_name'>
 				<method_info nloc='25' complexity='7' token_count='264' nesting_level='0' start_line='83' end_line='107'></method_info>
 			<added_lines>83,92,93,94,95,96,97,98</added_lines>
 			<deleted_lines>83,92</deleted_lines>
 		</method>
 		<method name='_build_vocab' parameters='data_name,train_dataset,test_dataset,dev_dataset'>
 				<method_info nloc='19' complexity='6' token_count='225' nesting_level='0' start_line='83' end_line='101'></method_info>
 			<added_lines>83,92,93,94,95,96,97,98</added_lines>
 			<deleted_lines>83,92</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='scripts\sentiment_analysis\sentiment_analysis_cnn.py' new_name='scripts\sentiment_analysis\sentiment_analysis_cnn.py'>
 		<file_info nloc='167' complexity='11' token_count='1227'></file_info>
 		<modified_lines>
 			<added_lines>41,42,73,76,79,80</added_lines>
 			<deleted_lines>31,42,43,44,75,78,81</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
