<bug_data>
<bug id='1102' author='liuzh91' open_date='2020-01-08T07:03:27Z' closed_time='2020-01-10T02:46:03Z'>
 	<summary>Log average loss metric of training GNMT</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 Current log_avg_loss in the train_gnmt.py script is incorrect.
 with mx.autograd.record():
         out, _ = model(src_seq, tgt_seq[:, :-1], src_valid_length, tgt_valid_length - 1)
         loss = loss_function(out, tgt_seq[:, 1:], tgt_valid_length - 1).mean()
         loss = loss * (tgt_seq.shape[1] - 1) / (tgt_valid_length - 1).mean()
         loss.backward()
 step_loss = loss.asscalar()
 log_avg_loss += step_loss
 log_avg_gnorm += gnorm
 log_avg_loss sums up averaged losses from different batches. It is divided by args.log_interval to compute the loss during the interval. It is inconsistent with the loss metric used in train_transformer script. In the latter script, losses and valid lengths during the interval are summed up separately. The average loss is computed from interval_loss/interval_valid_length.
 Although these two computations are similar, I think it will be better to unify them in training scripts.
 &lt;denchmark-h:h2&gt;Log Message&lt;/denchmark-h&gt;
 
 I print out the log message here:
 &lt;denchmark-code&gt;2020-01-08 07:00:24,259 - root - [Epoch 0 Batch 100/1043] loss=6.2948, ppl=541.7368, gnorm=0.7030, throughput=36.26K wps, wc=606.57K
 2020-01-08 07:00:37,441 - root - [Epoch 0 Batch 200/1043] loss=5.7232, ppl=305.8789, gnorm=0.3394, throughput=44.32K wps, wc=584.18K
 2020-01-08 07:00:50,411 - root - [Epoch 0 Batch 300/1043] loss=5.2613, ppl=192.7247, gnorm=0.3442, throughput=45.71K wps, wc=592.78K
 2020-01-08 07:01:03,364 - root - [Epoch 0 Batch 400/1043] loss=4.9213, ppl=137.1854, gnorm=0.3193, throughput=44.10K wps, wc=571.26K
 2020-01-08 07:01:16,174 - root - [Epoch 0 Batch 500/1043] loss=4.6531, ppl=104.9109, gnorm=0.3304, throughput=43.29K wps, wc=554.48K
 2020-01-08 07:01:28,367 - root - [Epoch 0 Batch 600/1043] loss=4.4185, ppl=82.9729, gnorm=0.3167, throughput=44.80K wps, wc=546.26K
 2020-01-08 07:01:41,019 - root - [Epoch 0 Batch 700/1043] loss=4.3236, ppl=75.4571, gnorm=0.3128, throughput=44.82K wps, wc=566.96K
 2020-01-08 07:01:53,287 - root - [Epoch 0 Batch 800/1043] loss=4.2010, ppl=66.7544, gnorm=0.3120, throughput=44.95K wps, wc=551.40K
 2020-01-08 07:02:06,260 - root - [Epoch 0 Batch 900/1043] loss=4.0903, ppl=59.7581, gnorm=0.3177, throughput=44.53K wps, wc=577.61K
 2020-01-08 07:02:19,849 - root - [Epoch 0 Batch 1000/1043] loss=4.0345, ppl=56.5169, gnorm=0.3055, throughput=43.28K wps, wc=588.16K
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='liuzh91' date='2020-01-08T21:27:01Z'>
 		They are different because train_transformer uses multi-gpu training. Where is interval_valid_length? I think there is no such variable.
 		</comment>
 	</comments>
 </bug>
<commit id='a528e747f5f6bbbfa9f5cb5f8142da462a738746' author='liuzh91' date='2020-01-08 21:27:12-08:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='scripts\machine_translation\train_gnmt.py' new_name='scripts\machine_translation\train_gnmt.py'>
 		<file_info nloc='229' complexity='14' token_count='2138'></file_info>
 		<method name='train' parameters=''>
 				<method_info nloc='85' complexity='8' token_count='821' nesting_level='0' start_line='193' end_line='281'></method_info>
 			<added_lines>202,203,217,218,219,220,227,228,236,237,241,242</added_lines>
 			<deleted_lines>202,216,223,224,232,233,237</deleted_lines>
 		</method>
 		<method name='evaluate' parameters='data_loader'>
 				<method_info nloc='29' complexity='6' token_count='305' nesting_level='0' start_line='147' end_line='190'></method_info>
 			<added_lines>173,176</added_lines>
 			<deleted_lines>173,176</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
