<bug_data>
<bug id='293' author='miikargh' open_date='2020-05-13T11:10:30Z' closed_time='2020-05-13T13:25:16Z'>
 	<summary>NNCF export to ONNX fails</summary>
 	<description>
 Describe the bug
 Trying to export a  compressed model to onnx and I get the following error:
 Traceback (most recent call last):
   File "onnx_example.py", line 13, in &lt;module&gt;
     compressed_model.export_model("/models/compressed_model.onnx")
   File "/openvino_training_extensions/pytorch_toolkit/nncf/nncf/nncf_network.py", line 443, in __getattr__
     return super().__getattr__(name)
   File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 585, in __getattr__
     type(self).__name__, name))
 AttributeError: 'NNCFNetwork' object has no attribute 'export_model'
 Steps to Reproduce
 
 Install the latest version of  NNCF
 Run the following code
 
 import nncf
 from nncf import create_compressed_model, Config as NNCFConfig
 
 # Instantiate your uncompressed model
 from torchvision.models.resnet import resnet50
 
 model = resnet50()
 
 # Apply compression according to a loaded NNCF config
 nncf_config = NNCFConfig.from_json("./resnet_rb_sparsity_int8.json")
 comp_ctrl, compressed_model = create_compressed_model(model, nncf_config)
 
 compressed_model.export_model("/models/compressed_model.onnx")
 
 Dockerfile along with all necessary steps to reproduce found here: &lt;denchmark-link:https://github.com/miikargh/nncf_issue&gt;https://github.com/miikargh/nncf_issue&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='miikargh' date='2020-05-13T11:54:22Z'>
 		&lt;denchmark-link:https://github.com/AlexKoff88&gt;@AlexKoff88&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/vshampor&gt;@vshampor&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/ljaljushkin&gt;@ljaljushkin&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='miikargh' date='2020-05-13T11:57:57Z'>
 		Greetings, &lt;denchmark-link:https://github.com/miikargh&gt;@miikargh&lt;/denchmark-link&gt;
 !
 This is a mistake in the documentation. Use comp_ctrl.export_model("/models/compressed_model.onnx") instead.
 		</comment>
 	</comments>
 </bug>
<commit id='c553a56088f0055baba838b68c9299e19683227e' author='Vasily Shamporov' date='2020-05-13 16:25:15+03:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_toolkit\nncf\README.md' new_name='pytorch_toolkit\nncf\README.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>42</added_lines>
 			<deleted_lines>42</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
