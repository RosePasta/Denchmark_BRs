<bug_data>
<bug id='208' author='jocaml' open_date='2019-05-29T11:36:14Z' closed_time='2019-06-01T18:26:06Z'>
 	<summary>Segmentation fault when accessing output consumers</summary>
 	<description>
 Using version 0.13.0, when I try to call any method on members of the op.output_consumers(i)vector, I get a segmentation fault:
 fn f(graph: &amp;Graph) {
     let placeholders = graph
         .operation_iter()
         .filter(|op| op.op_type() == Ok("Placeholder".into()));
 
     for op in placeholders {
         for i in 0..op.num_outputs() {
             for (consumer_op, input_index) in op.output_consumers(i) {
                 consumer_op.input(input_index); // Segmentation fault (core dumped)
             }
         }
     }
 }
 Here is a &lt;denchmark-link:https://github.com/tensorflow/rust/files/3235555/valgrind.log&gt;valgrind log&lt;/denchmark-link&gt;
 . Not sure if this should be submitted to the tensorflow repo.
 Here is the cargo project: &lt;denchmark-link:https://github.com/tensorflow/rust/files/3235562/tf.zip&gt;tf.zip&lt;/denchmark-link&gt;
 
 Edit: I've uploaded a new valgrind log, the last one had some garbage from other dependencies (though not sure how they ended up in there hm).
 	</description>
 	<comments>
 		<comment id='1' author='jocaml' date='2019-05-30T05:19:12Z'>
 		I tried it with all versions from 0.9.0 (tensorflow 1.7.0) and it's the same. On one run I managed to get
 [src/tf.rs:104] consumer_op.input(input_index) = (
     Operation {
         inner: 0x0000000000000000,
         gimpl: GraphImpl {
             inner: 0x000056278c30bb50,
             owned: true,
         },
     },
     18446744073709551615,
 )
 Is prebuilt downloaded TensorFlow compiled with jemalloc?
 		</comment>
 		<comment id='2' author='jocaml' date='2019-05-31T03:34:03Z'>
 		I've tracked it down to a bug in the Rust bindings.  I'll submit a fix.
 		</comment>
 		<comment id='3' author='jocaml' date='2019-06-01T18:31:44Z'>
 		By the way, the prebuilt TensorFlow is compiled with jemalloc.  I have to disable it and compile TensorFlow from scratch (which takes quite a while) to check for memory leaks with valgrind.
 		</comment>
 	</comments>
 </bug>
<commit id='778fe376b0032b5aef860c7d9576bd59e5a155e2' author='Adam Crume' date='2019-05-30 20:43:42-07:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\graph.rs' new_name='src\graph.rs'>
 		<file_info nloc='2395' complexity='254' token_count='14844'></file_info>
 		<method name='output_consumers' parameters=''>
 				<method_info nloc='19' complexity='1' token_count='197' nesting_level='0' start_line='2826' end_line='2844'></method_info>
 			<added_lines>2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='output_consumers' parameters='self,usize'>
 				<method_info nloc='29' complexity='1' token_count='162' nesting_level='0' start_line='1107' end_line='1135'></method_info>
 			<added_lines>1120</added_lines>
 			<deleted_lines>1120</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>2824,2825</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
