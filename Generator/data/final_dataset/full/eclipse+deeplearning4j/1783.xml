<bug_data>
<bug id='1783' author='ghost(ghost)' open_date='2016-07-05T11:23:31Z' closed_time='2017-02-28T09:33:01Z'>
 	<summary>Persistence issue (Spark) when Serialization is disabled (aka .cache()) and allegedly unnecessary re-caching</summary>
 	<description>
 
 It appears that a Memory-Serialized RDD[DataSet] of ~300MB will become ~60GB if cached Memory-DE-Serialized.
 By using the SparkDl4jMultiLayer binding to spark, the original dataset (points) gets re-cached into memory on each epoch, despite being already cached, deserialized (I get the reason behind it, but I guess nd4j objects are poorly cached when deserialized). As far as I understand, there is basically no reason to re-cache the original dataset, as it actually stays as is across all epochs, and what actually changes is the network's weights.
 
 	</description>
 	<comments>
 		<comment id='1' author='ghost(ghost)' date='2019-01-19T12:20:19Z'>
 		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
 		</comment>
 	</comments>
 </bug>
<commit id='92c52944be776e9ca9ebf438f70e04e6fd766070' author='FranÃ§ois Garillot' date='2017-02-23 00:49:53-05:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='deeplearning4j-nlp-parent\deeplearning4j-nlp\src\test\java\org\deeplearning4j\models\embeddings\inmemory\InMemoryLookupTableTest.java' new_name='deeplearning4j-nlp-parent\deeplearning4j-nlp\src\test\java\org\deeplearning4j\models\embeddings\inmemory\InMemoryLookupTableTest.java'>
 		<file_info nloc='110' complexity='3' token_count='979'></file_info>
 		<method name='InMemoryLookupTableTest::testConsumeOnEqualVocabs' parameters=''>
 				<method_info nloc='35' complexity='1' token_count='300' nesting_level='1' start_line='30' end_line='82'></method_info>
 			<added_lines>81</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='deeplearning4j-scaleout\spark\dl4j-spark-nlp\src\main\java\org\deeplearning4j\spark\models\embeddings\word2vec\Word2Vec.java' new_name='deeplearning4j-scaleout\spark\dl4j-spark-nlp\src\main\java\org\deeplearning4j\spark\models\embeddings\word2vec\Word2Vec.java'>
 		<file_info nloc='318' complexity='40' token_count='2533'></file_info>
 		<method name='Word2Vec::train' parameters='corpusRDD'>
 				<method_info nloc='72' complexity='8' token_count='754' nesting_level='1' start_line='130' end_line='253'></method_info>
 			<added_lines>190</added_lines>
 			<deleted_lines>190</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='deeplearning4j-scaleout\spark\dl4j-spark-nlp\src\test\java\org\deeplearning4j\spark\models\embeddings\glove\GloveTest.java' new_name='deeplearning4j-scaleout\spark\dl4j-spark-nlp\src\test\java\org\deeplearning4j\spark\models\embeddings\glove\GloveTest.java'>
 		<file_info nloc='33' complexity='1' token_count='345'></file_info>
 		<method name='GloveTest::testGlove' parameters=''>
 				<method_info nloc='13' complexity='1' token_count='155' nesting_level='1' start_line='46' end_line='60'></method_info>
 			<added_lines>53</added_lines>
 			<deleted_lines>53</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='deeplearning4j-scaleout\spark\dl4j-spark\src\test\java\org\deeplearning4j\spark\datavec\MiniBatchTests.java' new_name='deeplearning4j-scaleout\spark\dl4j-spark\src\test\java\org\deeplearning4j\spark\datavec\MiniBatchTests.java'>
 		<file_info nloc='39' complexity='2' token_count='368'></file_info>
 		<method name='MiniBatchTests::testMiniBatches' parameters=''>
 				<method_info nloc='15' complexity='1' token_count='161' nesting_level='1' start_line='41' end_line='58'></method_info>
 			<added_lines>55,56</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='deeplearning4j-scaleout\spark\dl4j-spark\src\test\java\org\deeplearning4j\spark\impl\paramavg\TestSparkMultiLayerParameterAveraging.java' new_name='deeplearning4j-scaleout\spark\dl4j-spark\src\test\java\org\deeplearning4j\spark\impl\paramavg\TestSparkMultiLayerParameterAveraging.java'>
 		<file_info nloc='807' complexity='48' token_count='8164'></file_info>
 		<method name='TestSparkMultiLayerParameterAveraging::testFromSvmLight' parameters=''>
 				<method_info nloc='35' complexity='1' token_count='384' nesting_level='1' start_line='130' end_line='169'></method_info>
 			<added_lines>136</added_lines>
 			<deleted_lines>136</deleted_lines>
 		</method>
 		<method name='TestSparkMultiLayerParameterAveraging::testFromSvmLightBackprop' parameters=''>
 				<method_info nloc='35' complexity='1' token_count='358' nesting_level='1' start_line='84' end_line='126'></method_info>
 			<added_lines>90</added_lines>
 			<deleted_lines>90</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
