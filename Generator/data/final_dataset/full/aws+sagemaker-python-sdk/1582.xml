<bug_data>
<bug id='1582' author='ChaiBapchya' open_date='2020-06-12T07:42:04Z' closed_time='2020-06-17T17:59:38Z'>
 	<summary>local_gpu with distributed training for single instance multi-gpu distributed training</summary>
 	<description>
 Describe the bug
 Upon testing for local-session [sagemaker], single instance, multi-gpu distributed training
 It fails at
 &lt;denchmark-code&gt;Input
 training_instance_type = 'local_gpu', distributions = {'mpi': {'enabled': True, 'processes_per_host': 4}}
 &lt;/denchmark-code&gt;
 
 Stack Trace
 &lt;denchmark-code&gt;    def warn_if_parameter_server_with_multi_gpu(training_instance_type, distributions):
         """Warn the user that training will not fully leverage all the GPU
         cores if parameter server is enabled and a multi-GPU instance is selected.
         Distributed training with the default parameter server setup doesn't
         support multi-GPU instances.
 
         Args:
             training_instance_type (str): A string representing the type of training instance selected.
             distributions (dict): A dictionary with information to enable distributed training.
                 (Defaults to None if distributed training is not enabled.) For example:
 
                 .. code:: python
 
                     {
                         'parameter_server':
                         {
                             'enabled': True
                         }
                     }
 
 
         """
         if training_instance_type == "local" or distributions is None:
             return
 
         is_multi_gpu_instance = (
 &gt;           training_instance_type.split(".")[1].startswith("p")
             and training_instance_type not in SINGLE_GPU_INSTANCE_TYPES
         )
 E       IndexError: list index out of range
 
 .tox/py37/lib/python3.7/site-packages/sagemaker/fw_utils.py:620: IndexError
 &lt;/denchmark-code&gt;
 
 To reproduce
 &lt;denchmark-code&gt;tox -e py37 -- tests/integ/test_horovod_mx.py
 &lt;/denchmark-code&gt;
 
 
 Build custom docker image :
 https://github.com/ChaiBapchya/sagemaker-mxnet-training-toolkit/tree/mx_hvd_mpi
 custom Sagemaker python SDK build from source : https://github.com/ChaiBapchya/sagemaker-python-sdk/tree/mx_estimator_horovod_mpi
 
 Expected behavior
 For running Distributed training on single instance multi-gpu for mpi-based horovod, I encounter this error.
 Since I'm using horovod [mpi] this warning isn't relevant.
 I suggest we should also add local_gpu here
 &lt;denchmark-code&gt;if training_instance_type in ["local","local_gpu"] or distributions is None:
             return
 &lt;/denchmark-code&gt;
 
 System information
 A description of your system. Please provide:
 
 SageMaker Python SDK version: Build from source [1.62.1.dev0]
 Framework name (eg. PyTorch) or algorithm (eg. KMeans):MXNet
 Framework version:1.6.0
 Python version:3
 CPU or GPU:GPU
 Custom Docker image (Y/N):Y
 
 	</description>
 	<comments>
 		<comment id='1' author='ChaiBapchya' date='2020-06-17T17:59:37Z'>
 		warning message update has been released in &lt;denchmark-link:https://github.com/aws/sagemaker-python-sdk/releases/tag/v1.65.0&gt;https://github.com/aws/sagemaker-python-sdk/releases/tag/v1.65.0&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='af7f75ae336f0481e52bb968e4cc6df91b1bac2c' author='Chuyang' date='2020-06-16 19:41:06-07:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\sagemaker\fw_utils.py' new_name='src\sagemaker\fw_utils.py'>
 		<file_info nloc='355' complexity='48' token_count='2002'></file_info>
 		<method name='warn_if_parameter_server_with_multi_gpu' parameters='training_instance_type,distributions'>
 				<method_info nloc='12' complexity='8' token_count='73' nesting_level='0' start_line='602' end_line='637'></method_info>
 			<added_lines>628,629,630</added_lines>
 			<deleted_lines>628,629,630</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>52,53</added_lines>
 			<deleted_lines>52,53</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\unit\test_fw_utils.py' new_name='tests\unit\test_fw_utils.py'>
 		<file_info nloc='1006' complexity='114' token_count='4937'></file_info>
 		<method name='test_warn_if_parameter_server_with_local_multi_gpu' parameters='caplog'>
 				<method_info nloc='7' complexity='1' token_count='39' nesting_level='0' start_line='1277' end_line='1284'></method_info>
 			<added_lines>1277,1278,1279,1280,1281,1282,1283,1284</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1275,1276</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
