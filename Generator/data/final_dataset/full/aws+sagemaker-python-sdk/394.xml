<bug_data>
<bug id='394' author='vbvg2008' open_date='2018-09-19T03:18:34Z' closed_time='2018-12-20T21:09:52Z'>
 	<summary>Using customized tensor name for prediction after deploying the model</summary>
 	<description>
 Please fill out the form below.
 &lt;denchmark-h:h3&gt;System Information&lt;/denchmark-h&gt;
 
 
 Framework (e.g. TensorFlow) / Algorithm (e.g. KMeans): TensorFlow
 Framework Version: 1.10
 Python Version: 2.7
 CPU or GPU: GPU
 Are you using a custom image: No
 
 &lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;
 
 All of the Sagemaker tensorflow tutorial uses "inputs" as the input name for prediction.  for example, in "tensorflow_resnet_cifar10_with_tensorboard" example, the prediction is simply done by
 random_image = np.random.rand(32, 32, 3)
 predictor.predict(random_image_data)
 but what if I trained a tensorflow model with a customized input name?  say my model inputs only accepts a dictionary like this:
 inputs = {"input_image": tf.placeholder(tf.float32, [None, 32, 32, 3])}
 Although I successfully trained and deployed the model, but when I try to do the prediction such as:
 random_image = np.random.rand(32, 32, 3)
 predictor.predict({'input_image':random_image})
 it gives me error saying my data is not JSON serializable. How do I use a customized name as input name for prediction?
 	</description>
 	<comments>
 		<comment id='1' author='vbvg2008' date='2018-09-20T00:31:39Z'>
 		Hello &lt;denchmark-link:https://github.com/vbvg2008&gt;@vbvg2008&lt;/denchmark-link&gt;
  ,
 I believe that this issue is related to &lt;denchmark-link:https://github.com/aws/sagemaker-tensorflow-training-toolkit/issues/71&gt;aws/sagemaker-tensorflow-training-toolkit#71&lt;/denchmark-link&gt;
 .
 We are in the process to release a newer container with these codefixes. I will update you in this ticket when it happens.
 Thanks for using SageMaker!
 		</comment>
 		<comment id='2' author='vbvg2008' date='2018-09-25T22:20:40Z'>
 		&lt;denchmark-link:https://github.com/mvsusp&gt;@mvsusp&lt;/denchmark-link&gt;
  The problem is fixed on the container side, but now we need to make a fix to the Python SDK to serialize numpy arrays in dicts correctly.
 &lt;denchmark-link:https://github.com/vbvg2008&gt;@vbvg2008&lt;/denchmark-link&gt;
  in the meantime, if you want to unblock yourself, try the workaround described here:
 &lt;denchmark-link:https://github.com/aws/sagemaker-tensorflow-training-toolkit/issues/71#issuecomment-422101489&gt;aws/sagemaker-tensorflow-training-toolkit#71 (comment)&lt;/denchmark-link&gt;
 
 Basically, convert your numpy arrays into lists before putting them in the dict.
 		</comment>
 		<comment id='3' author='vbvg2008' date='2018-10-05T04:03:02Z'>
 		hi &lt;denchmark-link:https://github.com/winstonaws&gt;@winstonaws&lt;/denchmark-link&gt;
 ,
 I am running into an issue that seems like it may be related.  I have logged it under issue &lt;denchmark-link:https://github.com/aws/sagemaker-python-sdk/issues/413&gt;#413&lt;/denchmark-link&gt;
 .
 If you have any idea on how to coerce my input data into an acceptable format I would very much appreciate it.
 		</comment>
 		<comment id='4' author='vbvg2008' date='2018-10-10T17:08:26Z'>
 		hi @eL0ck,
 We have merged in a change to accept dicts with numpy arrays on the python sdk side - &lt;denchmark-link:https://github.com/aws/sagemaker-python-sdk/pull/404&gt;#404&lt;/denchmark-link&gt;
  .
 Your original way to do the prediction should work now:
 random_image = np.random.rand(32, 32, 3)
 predictor.predict({'input_image':random_image})
 Please let us know if the problems persists.
 		</comment>
 	</comments>
 </bug>
<commit id='d3ef9813d7b2d2a0072407491d8e318ff5ab1153' author='winstonaws' date='2018-10-04 13:23:07-07:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.rst' new_name='CHANGELOG.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>9</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\sagemaker\predictor.py' new_name='src\sagemaker\predictor.py'>
 		<file_info nloc='177' complexity='62' token_count='1169'></file_info>
 		<method name='_json_serialize_python_object' parameters='data'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='0' start_line='270' end_line='271'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>270,271</deleted_lines>
 		</method>
 		<method name='_json_serialize_object' parameters='data'>
 				<method_info nloc='2' complexity='1' token_count='12' nesting_level='0' start_line='278' end_line='279'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>278,279</deleted_lines>
 		</method>
 		<method name='_json_serialize_numpy_array' parameters='data'>
 				<method_info nloc='2' complexity='1' token_count='14' nesting_level='0' start_line='265' end_line='267'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>265,266,267</deleted_lines>
 		</method>
 		<method name='__call__' parameters='self,data'>
 				<method_info nloc='6' complexity='4' token_count='64' nesting_level='1' start_line='231' end_line='249'></method_info>
 			<added_lines>242,243,249</added_lines>
 			<deleted_lines>240,241,242,243,244,245,246,247,248,249</deleted_lines>
 		</method>
 		<method name='_ndarray_to_list' parameters='data'>
 				<method_info nloc='2' complexity='2' token_count='22' nesting_level='0' start_line='255' end_line='256'></method_info>
 			<added_lines>255,256</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>19</added_lines>
 			<deleted_lines>251,252,253,259,268,269,280,281</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\unit\test_predictor.py' new_name='tests\unit\test_predictor.py'>
 		<file_info nloc='277' complexity='49' token_count='2228'></file_info>
 		<method name='test_json_serializer_python_dictionary_invalid_empty' parameters=''>
 				<method_info nloc='2' complexity='1' token_count='12' nesting_level='0' start_line='65' end_line='66'></method_info>
 			<added_lines>66</added_lines>
 			<deleted_lines>65,66</deleted_lines>
 		</method>
 		<method name='test_json_serializer_numpy_invalid_empty' parameters=''>
 				<method_info nloc='4' complexity='1' token_count='31' nesting_level='0' start_line='43' end_line='47'></method_info>
 			<added_lines>43,44</added_lines>
 			<deleted_lines>43,44,45,46,47</deleted_lines>
 		</method>
 		<method name='test_json_serializer_python_invalid_empty' parameters=''>
 				<method_info nloc='2' complexity='1' token_count='12' nesting_level='0' start_line='61' end_line='62'></method_info>
 			<added_lines>62</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_json_serializer_empty' parameters=''>
 				<method_info nloc='2' complexity='1' token_count='17' nesting_level='0' start_line='43' end_line='44'></method_info>
 			<added_lines>43,44</added_lines>
 			<deleted_lines>43,44</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>67,71,72,73</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\unit\test_tf_predictor.py' new_name='tests\unit\test_tf_predictor.py'>
 		<file_info nloc='281' complexity='18' token_count='1304'></file_info>
 		<method name='test_json_serialize_dict' parameters=''>
 				<method_info nloc='5' complexity='1' token_count='45' nesting_level='0' start_line='341' end_line='346'></method_info>
 			<added_lines>341,342,343,344,345,346</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_json_serialize_dict_with_numpy' parameters=''>
 				<method_info nloc='5' complexity='1' token_count='75' nesting_level='0' start_line='349' end_line='354'></method_info>
 			<added_lines>349,350,351,352,353,354</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_json_serialize_numpy' parameters=''>
 				<method_info nloc='3' complexity='1' token_count='35' nesting_level='0' start_line='357' end_line='359'></method_info>
 			<added_lines>357,358,359</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>339,340,347,348,355,356</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
