<bug_data>
<bug id='540' author='OleStauning' open_date='2017-02-01T22:04:05Z' closed_time='2017-03-10T20:42:45Z'>
 	<summary>SIGSEGV when adding dropout layer</summary>
 	<description>
 Code:
 &lt;denchmark-code&gt;    network&lt;sequential&gt; net;
     adam opt;
 
     net &lt;&lt; fc&lt;relu&gt;(9*2,40)
         &lt;&lt; fc&lt;relu&gt;(40,10)
         &lt;&lt; dropout(10,0.5)
         &lt;&lt; fc&lt;sigmoid&gt;(10,2);
 
     int epoch=0;
     int epochs = 50;
     int batch = 50;
     net.fit&lt;mse&gt;(opt, xtrain, ytrain, batch, epochs,
     [](){},
     [&amp;](){
         auto loss = net.get_loss&lt;mse&gt;(xtest, ytest);
         std::cout &lt;&lt; "Loss=" &lt;&lt; loss &lt;&lt; std::endl;
     });
 &lt;/denchmark-code&gt;
 
 Error when using valgrind:
 &lt;denchmark-code&gt;==7176== Invalid read of size 1
 ==7176==    at 0x115C35: tiny_dnn::dropout_layer::back_propagation(std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;*, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;*&gt; &gt; const&amp;, std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;*, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;*&gt; &gt; const&amp;, std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;*, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;*&gt; &gt;&amp;, std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;*, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;*&gt; &gt;&amp;) (dropout_layer.h:86)
 ==7176==    by 0x112683: tiny_dnn::layer::backward() (layer.h:515)
 ==7176==    by 0x11486E: tiny_dnn::sequential::backward(std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; &gt; &gt; const&amp;) (nodes.h:285)
 ==7176==    by 0x13032C: void tiny_dnn::network&lt;tiny_dnn::sequential&gt;::bprop&lt;tiny_dnn::mse&gt;(std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; &gt; &gt; const&amp;, std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; &gt; &gt; const&amp;, std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; &gt; &gt; const&amp;) (network.h:946)
 ==7176==    by 0x12D112: void tiny_dnn::network&lt;tiny_dnn::sequential&gt;::train_onebatch&lt;tiny_dnn::mse, tiny_dnn::adam&gt;(tiny_dnn::adam&amp;, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*, int, int, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*) (network.h:845)
 ==7176==    by 0x128B7C: void tiny_dnn::network&lt;tiny_dnn::sequential&gt;::train_once&lt;tiny_dnn::mse, tiny_dnn::adam&gt;(tiny_dnn::adam&amp;, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*, int, int, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*) (network.h:818)
 ==7176==    by 0x10E407: bool tiny_dnn::network&lt;tiny_dnn::sequential&gt;::fit&lt;tiny_dnn::mse, tiny_dnn::adam, main::{lambda()#1}, main::{lambda()#2}&gt;(tiny_dnn::adam&amp;, std::vector&lt;tiny_dnn::adam&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::aligned_allocator&gt; &gt;, std::allocator&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const&amp;, std::vector&lt;tiny_dnn::adam&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::aligned_allocator&gt; &gt;, std::allocator&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, unsigned long, int, main::{lambda()#1}, main::{lambda()#2}, bool, int, std::vector&lt;tiny_dnn::adam&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::aligned_allocator&gt; &gt;, std::allocator&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;) (network.h:784)
 ==7176==    by 0x10E11B: bool tiny_dnn::network&lt;tiny_dnn::sequential&gt;::fit&lt;tiny_dnn::mse, tiny_dnn::adam, main::{lambda()#1}, main::{lambda()#2}, std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, tiny_dnn::aligned_allocator&gt;(tiny_dnn::adam&amp;, {lambda()#2}&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::adam&gt; &gt; const&amp;, {lambda()#2}&lt;tiny_dnn::aligned_allocator, std::allocator&lt;{lambda()#2}&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::adam&gt; &gt; const&gt; &gt; const&amp;, unsigned long, int, main::{lambda()#1}, main::{lambda()#2}, bool, int, {lambda()#2}&lt;tiny_dnn::aligned_allocator, std::allocator&lt;{lambda()#2}&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::adam&gt; &gt; const&gt; &gt;) (network.h:335)
 .....................
 ==4475== Process terminating with default action of signal 11 (SIGSEGV)
 ==4475==  Access not within mapped region at address 0x10
 ==4475==    at 0x12113A: std::_Sp_counted_base&lt;(__gnu_cxx::_Lock_policy)2&gt;::_M_release() (shared_ptr_base.h:150)
 ==4475==    by 0x11AFCE: std::__shared_count&lt;(__gnu_cxx::_Lock_policy)2&gt;::~__shared_count() (shared_ptr_base.h:662)
 ==4475==    by 0x114D4F: std::__shared_ptr&lt;tiny_dnn::edge, (__gnu_cxx::_Lock_policy)2&gt;::~__shared_ptr() (shared_ptr_base.h:928)
 ==4475==    by 0x114D6B: std::shared_ptr&lt;tiny_dnn::edge&gt;::~shared_ptr() (shared_ptr.h:93)
 ==4475==    by 0x115E54: tiny_dnn::layer::backward() (layer.h:511)
 ==4475==    by 0x118078: tiny_dnn::sequential::backward(std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; &gt; &gt; const&amp;) (nodes.h:285)
 ==4475==    by 0x136CC6: void tiny_dnn::network&lt;tiny_dnn::sequential&gt;::bprop&lt;tiny_dnn::mse&gt;(std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; &gt; &gt; const&amp;, std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; &gt; &gt; const&amp;, std::vector&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, std::allocator&lt;std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; &gt; &gt; const&amp;) (network.h:946)
 ==4475==    by 0x13309E: void tiny_dnn::network&lt;tiny_dnn::sequential&gt;::train_onebatch&lt;tiny_dnn::mse, tiny_dnn::adam&gt;(tiny_dnn::adam&amp;, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*, int, int, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*) (network.h:845)
 ==4475==    by 0x12E01C: void tiny_dnn::network&lt;tiny_dnn::sequential&gt;::train_once&lt;tiny_dnn::mse, tiny_dnn::adam&gt;(tiny_dnn::adam&amp;, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*, int, int, std::vector&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const*) (network.h:818)
 ==4475==    by 0x110E71: bool tiny_dnn::network&lt;tiny_dnn::sequential&gt;::fit&lt;tiny_dnn::mse, tiny_dnn::adam, main::{lambda()#1}, main::{lambda()#2}&gt;(tiny_dnn::adam&amp;, std::vector&lt;tiny_dnn::adam&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::aligned_allocator&gt; &gt;, std::allocator&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt; const&amp;, std::vector&lt;tiny_dnn::adam&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::aligned_allocator&gt; &gt;, std::allocator&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;, unsigned long, int, main::{lambda()#1}, main::{lambda()#2}, bool, int, std::vector&lt;tiny_dnn::adam&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::aligned_allocator&gt; &gt;, std::allocator&lt;tiny_dnn::adam&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt; &gt; &gt;) (network.h:784)
 ==4475==    by 0x110B85: bool tiny_dnn::network&lt;tiny_dnn::sequential&gt;::fit&lt;tiny_dnn::mse, tiny_dnn::adam, main::{lambda()#1}, main::{lambda()#2}, std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, tiny_dnn::aligned_allocator&gt;(tiny_dnn::adam&amp;, {lambda()#2}&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::adam&gt; &gt; const&amp;, {lambda()#2}&lt;tiny_dnn::aligned_allocator, std::allocator&lt;{lambda()#2}&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::adam&gt; &gt; const&gt; &gt; const&amp;, unsigned long, int, main::{lambda()#1}, main::{lambda()#2}, bool, int, {lambda()#2}&lt;tiny_dnn::aligned_allocator, std::allocator&lt;{lambda()#2}&lt;std::vector&lt;float, tiny_dnn::aligned_allocator&lt;float, 64ul&gt; &gt;, std::allocator&lt;tiny_dnn::adam&gt; &gt; const&gt; &gt;) (network.h:335)
 &lt;/denchmark-code&gt;
 
 The code works fine without the dropout layer. Am I doing something wrong?
 Best regards
 	</description>
 	<comments>
 		<comment id='1' author='OleStauning' date='2017-02-01T23:13:36Z'>
 		I saw a crash with dropout, but with a different model of course. Also works fine if I comment out dropout. This is on windows
 		</comment>
 		<comment id='2' author='OleStauning' date='2017-02-24T18:26:07Z'>
 		My guess is out_type of dropout_layer is {vector_type::data} and in_type of fully_connected_layer is {vector_type::data, vector_type::weight, vector_type::bias} or {vector_type::data, vector_type::weight}, so they can't be connected.
 But if it's really so, network class should report an error about inappropriate layer configuration.
 		</comment>
 		<comment id='3' author='OleStauning' date='2017-02-24T18:59:03Z'>
 		It was my misunderstanding.
 		</comment>
 		<comment id='4' author='OleStauning' date='2017-02-24T19:31:03Z'>
 		In dropout_layer::back_propagation method, in_grad is updated.
 for (serial_size_t sample = 0;
       sample &lt; static_cast&lt;serial_size_t&gt;(prev_delta.size()); ++sample) {
   for (serial_size_t i = 0;
         i &lt; static_cast&lt;serial_size_t&gt;(curr_delta.size()); i++) {
     prev_delta[sample][i] = mask_[sample][i] * curr_delta[sample][i];
   }
 }
 During the process, mask_ member is accesed. A problem is found by adding below assert statement.
   assert(mask_[sample].size() == curr_delta.size());
 		</comment>
 		<comment id='5' author='OleStauning' date='2017-02-25T01:57:43Z'>
 		Posted a fix to the problem.
 &lt;denchmark-link:https://github.com/tiny-dnn/tiny-dnn/pull/543#issuecomment-282450220&gt;#543 (comment)&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='6' author='OleStauning' date='2017-03-02T15:03:18Z'>
 		&lt;denchmark-link:https://github.com/OleStauning&gt;@OleStauning&lt;/denchmark-link&gt;
  can you please check with current master?
 		</comment>
 		<comment id='7' author='OleStauning' date='2017-03-10T20:42:45Z'>
 		Yes - this have fixed the problem. Thanks.
 		</comment>
 	</comments>
 </bug>
<commit id='9c4ae800b4f034693aee20d45fac817c81a9e3d6' author='Evgeniy Zheltonozhskiy' date='2017-03-02 16:55:20+02:00'>
 	<dmm_unit complexity='0.6865671641791045' interfacing='1.0' size='0.30597014925373134'></dmm_unit>
 	<modification change_type='MODIFY' old_name='test\test.cpp' new_name='test\test.cpp'>
 		<file_info nloc='32' complexity='1' token_count='88'></file_info>
 		<modified_lines>
 			<added_lines>17</added_lines>
 			<deleted_lines>16,17</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\test_dropout_layer.h' new_name='test\test_dropout_layer.h'>
 		<file_info nloc='68' complexity='6' token_count='800'></file_info>
 		<method name='tiny_dnn::TEST' parameters='dropout,full_net_batch'>
 				<method_info nloc='18' complexity='2' token_count='269' nesting_level='1' start_line='82' end_line='108'></method_info>
 			<added_lines>82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tiny_dnn::TEST' parameters='dropout,full_net'>
 				<method_info nloc='18' complexity='2' token_count='269' nesting_level='1' start_line='53' end_line='80'></method_info>
 			<added_lines>53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>10,81</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\test_fully_connected_layer.h' new_name='test\test_fully_connected_layer.h'>
 		<file_info nloc='137' complexity='15' token_count='1599'></file_info>
 		<method name='tiny_dnn::TEST' parameters='fully_connected,train_different_batches'>
 				<method_info nloc='30' complexity='3' token_count='363' nesting_level='1' start_line='53' end_line='94'></method_info>
 			<added_lines>53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>95</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\test_network.h' new_name='test\test_network.h'>
 		<file_info nloc='452' complexity='60' token_count='4862'></file_info>
 		<method name='tiny_dnn::TEST' parameters='network,read_write'>
 				<method_info nloc='44' complexity='2' token_count='390' nesting_level='1' start_line='591' end_line='644'></method_info>
 			<added_lines>631</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tiny_dnn::TEST' parameters='network,train_predict_different_batches'>
 				<method_info nloc='42' complexity='7' token_count='484' nesting_level='1' start_line='257' end_line='310'></method_info>
 			<added_lines>257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>311</added_lines>
 			<deleted_lines>576</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\testhelper.h' new_name='test\testhelper.h'>
 		<file_info nloc='173' complexity='29' token_count='1326'></file_info>
 		<method name='tiny_dnn::serialization_test' parameters='src,dst'>
 				<method_info nloc='19' complexity='1' token_count='176' nesting_level='1' start_line='99' end_line='128'></method_info>
 			<added_lines>118,120,121,122,127</added_lines>
 			<deleted_lines>100</deleted_lines>
 		</method>
 		<method name='tiny_dnn::network_serialization_test' parameters='src,dst'>
 				<method_info nloc='13' complexity='1' token_count='148' nesting_level='1' start_line='73' end_line='96'></method_info>
 			<added_lines>73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96</added_lines>
 			<deleted_lines>83,93,95</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>72,97</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tiny_dnn\layers\batch_normalization_layer.h' new_name='tiny_dnn\layers\batch_normalization_layer.h'>
 		<file_info nloc='166' complexity='42' token_count='1326'></file_info>
 		<method name='tiny_dnn::batch_normalization_layer::save' parameters='os,precision'>
 				<method_info nloc='8' complexity='3' token_count='66' nesting_level='2' start_line='177' end_line='184'></method_info>
 			<added_lines>177,178,179,180,181</added_lines>
 			<deleted_lines>177,178,183,184</deleted_lines>
 		</method>
 		<method name='tiny_dnn::batch_normalization_layer::load' parameters='is'>
 				<method_info nloc='5' complexity='3' token_count='44' nesting_level='2' start_line='183' end_line='187'></method_info>
 			<added_lines>186,187</added_lines>
 			<deleted_lines>183,184</deleted_lines>
 		</method>
 		<method name='tiny_dnn::batch_normalization_layer::load' parameters='is,precision'>
 				<method_info nloc='7' complexity='3' token_count='61' nesting_level='2' start_line='186' end_line='192'></method_info>
 			<added_lines>186,187,188,189</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tiny_dnn::batch_normalization_layer::save' parameters='os'>
 				<method_info nloc='5' complexity='3' token_count='49' nesting_level='2' start_line='177' end_line='181'></method_info>
 			<added_lines>177,178,179,180,181</added_lines>
 			<deleted_lines>177,178</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tiny_dnn\layers\dropout_layer.h' new_name='tiny_dnn\layers\dropout_layer.h'>
 		<file_info nloc='94' complexity='23' token_count='791'></file_info>
 		<method name='tiny_dnn::dropout_layer::back_propagation' parameters='in_data,out_data,out_grad,in_grad'>
 				<method_info nloc='15' complexity='3' token_count='150' nesting_level='2' start_line='72' end_line='90'></method_info>
 			<added_lines>82,83,84,85,86</added_lines>
 			<deleted_lines>82,83,84,85</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tiny_dnn\layers\layer.h' new_name='tiny_dnn\layers\layer.h'>
 		<file_info nloc='512' complexity='133' token_count='4178'></file_info>
 		<method name='tiny_dnn::layer::save' parameters='os'>
 				<method_info nloc='6' complexity='3' token_count='44' nesting_level='2' start_line='334' end_line='342'></method_info>
 			<added_lines>334,335,336,337,338,339,340,341,342</added_lines>
 			<deleted_lines>334,335,336,337</deleted_lines>
 		</method>
 		<method name='tiny_dnn::layer::load' parameters='is'>
 				<method_info nloc='7' complexity='3' token_count='45' nesting_level='2' start_line='344' end_line='350'></method_info>
 			<added_lines>350</added_lines>
 			<deleted_lines>344</deleted_lines>
 		</method>
 		<method name='tiny_dnn::layer::load' parameters='is,precision'>
 				<method_info nloc='11' complexity='3' token_count='70' nesting_level='2' start_line='350' end_line='360'></method_info>
 			<added_lines>350,351,352,353,354</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tiny_dnn::layer::save' parameters='os,precision'>
 				<method_info nloc='10' complexity='3' token_count='69' nesting_level='2' start_line='334' end_line='348'></method_info>
 			<added_lines>334,335,336,337,338,339,340,341,342,343</added_lines>
 			<deleted_lines>334,335,336,337,344</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
