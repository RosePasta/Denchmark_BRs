<bug_data>
<bug id='223' author='capavrulus' open_date='2020-11-01T09:45:08Z' closed_time='2020-11-02T02:37:21Z'>
 	<summary>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!</summary>
 	<description>
 I made my own recipe but I got this error when I started training. I have no idea how this error occurred because theoretically it shouldn't depend on which recipe I use. I don't even know which variable is not on GPU.
 sc_loss, mag_loss = self.criterion["stft"](y_.squeeze(1), y.squeeze(1)) both y_ and y are on GPU.
 sc_l, mag_l = f(x, y) both x and y are on GPU.
 x_stft = torch.stft(x, fft_size, hop_size, win_length, window) x is on GPU.
 
 [train]:   0%|          | 0/400000 [00:00&lt;?, ?it/s]/home/train/.local/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)
 normalized, onesided, return_complex)
 Traceback (most recent call last):
 File "/home/train/.local/bin/parallel-wavegan-train", line 11, in 
 load_entry_point('parallel-wavegan', 'console_scripts', 'parallel-wavegan-train')()
 File "/home/train/ParallelWaveGAN/parallel_wavegan/bin/train.py", line 921, in main
 trainer.run()
 File "/home/train/ParallelWaveGAN/parallel_wavegan/bin/train.py", line 91, in run
 self._train_epoch()
 File "/home/train/ParallelWaveGAN/parallel_wavegan/bin/train.py", line 291, in _train_epoch
 self._train_step(batch)
 File "/home/train/ParallelWaveGAN/parallel_wavegan/bin/train.py", line 175, in train_step
 sc_loss, mag_loss = self.criterion["stft"](y.squeeze(1), y.squeeze(1))
 File "/home/train/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
 result = self.forward(*input, **kwargs)
 File "/home/train/ParallelWaveGAN/parallel_wavegan/losses/stft_loss.py", line 147, in forward
 sc_l, mag_l = f(x, y)
 File "/home/train/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
 result = self.forward(*input, **kwargs)
 File "/home/train/ParallelWaveGAN/parallel_wavegan/losses/stft_loss.py", line 101, in forward
 x_mag = stft(x, self.fft_size, self.shift_size, self.win_length, self.window)
 File "/home/train/ParallelWaveGAN/parallel_wavegan/losses/stft_loss.py", line 26, in stft
 x_stft = torch.stft(x, fft_size, hop_size, win_length, window)
 File "/home/train/.local/lib/python3.7/site-packages/torch/functional.py", line 516, in stft
 normalized, onesided, return_complex)
 RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
 
 	</description>
 	<comments>
 		<comment id='1' author='capavrulus' date='2020-11-01T09:26:55Z'>
 		Maybe you use torch==1.7.
 Not yet tested.
 For quick fixing, please use torch&lt;=1.6.
 		</comment>
 		<comment id='2' author='capavrulus' date='2020-11-01T09:33:05Z'>
 		
 Maybe you use torch==1.7.
 Not yet tested.
 For quick fixing, please use torch&lt;=1.6.
 
 Resolved by using torch==1.6.0. Thank you!
 		</comment>
 		<comment id='3' author='capavrulus' date='2020-11-02T02:37:43Z'>
 		Fixed in &lt;denchmark-link:https://github.com/kan-bayashi/ParallelWaveGAN/pull/225&gt;#225&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='a4f8c0960d016ecba6b29522b518ee759373a9ca' author='kan-bayashi' date='2020-11-02 11:22:36+09:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='parallel_wavegan\losses\stft_loss.py' new_name='parallel_wavegan\losses\stft_loss.py'>
 		<file_info nloc='69' complexity='11' token_count='609'></file_info>
 		<method name='stft' parameters='x,fft_size,hop_size,win_length,window'>
 				<method_info nloc='10' complexity='2' token_count='102' nesting_level='0' start_line='16' end_line='40'></method_info>
 			<added_lines>30,31,32,33,34,35</added_lines>
 			<deleted_lines>26</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,fft_size,shift_size,win_length,window'>
 				<method_info nloc='2' complexity='1' token_count='19' nesting_level='1' start_line='88' end_line='89'></method_info>
 			<added_lines>88,89</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,fft_sizes,2048,hop_sizes,240,win_lengths,1200,window'>
 				<method_info nloc='6' complexity='1' token_count='38' nesting_level='1' start_line='124' end_line='129'></method_info>
 			<added_lines>124,125,126,127,128,129</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,fft_size,shift_size,win_length,window'>
 				<method_info nloc='8' complexity='1' token_count='74' nesting_level='1' start_line='79' end_line='87'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>79,85</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,fft_sizes,2048,hop_sizes,240,win_lengths,1200,window'>
 				<method_info nloc='5' complexity='1' token_count='39' nesting_level='1' start_line='112' end_line='116'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>112,113,114,115,116</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>11,12,13,14,90,98,99,130</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
