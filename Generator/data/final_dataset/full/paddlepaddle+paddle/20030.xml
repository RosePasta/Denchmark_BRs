<bug_data>
<bug id='20030' author='LDOUBLEV' open_date='2019-09-26T08:16:11Z' closed_time='2019-09-27T05:53:48Z'>
 	<summary>layers.mul 计算double grad时报memory_size()的错</summary>
 	<description>
 报错环境：
 CPU/GPU
 paddle 1.5.2
 问题复现代码：
 &lt;denchmark-code&gt;def test_mul_grad_paddle_vs_torch():
     train_program = fluid.Program()
     start_program = fluid.Program()
     #place = fluid.CUDAPlace(0)
     place = fluid.CPUPlace()
     with fluid.program_guard(train_program, start_program):
         rng = np.random.RandomState(0)
         inp_ = rng.uniform(-1, 1, [3, 2]).astype('float32')
         w1_ = rng.uniform(-1, 1, [2, 5]).astype('float32')
         w2_ = rng.uniform(-1, 1, [5, 4]).astype('float32')
         yg_ = rng.uniform(-1, 1, [2, ]).astype('float32')
 
         inp = fluid.layers.data('inp', [3, 2], append_batch_size=False)
         w1 = fluid.layers.data('w1', [2, 5], append_batch_size=False)
         w2 = fluid.layers.data('w2', [5, 4], append_batch_size=False)
         yg = fluid.layers.data('yg', [2, ], append_batch_size=False)
 
         inp.stop_gradient = False
         w1.stop_gradient = False
         w2.stop_gradient = False
         yg.stop_gradient = False
 
         y = fluid.layers.mul(fluid.layers.mul(inp, w1), w2)
 
         f = y
 
         x = [w1, w2]
         dfdx_f1 = fluid.gradients(f, x, f)
 
         # double gradient
         dfdx_x_ = fluid.gradients([dfdx_f1[0]*x[0], dfdx_f1[1]*x[1]], f)
         print(dfdx_x_)
 
     exe = fluid.Executor(place)
     exe.run(program=fluid.default_startup_program())
     compiled_prog = fluid.compiler.CompiledProgram(train_program)
 
     res = exe.run(compiled_prog, feed={'inp':inp_, 'w1':w1_, 'w2':w2_, 'yg':yg_},
                   fetch_list=[dfdx_f1[0].name, dfdx_f1[1].name, dfdx_x[0].name)
     print(res[0], res[1], '\n', res[2])
 
     """ for torch matmul """
     import torch
     def n2t(x): return torch.from_numpy(np.array(x))
 
     inp_t, w1_t, w2_t, yg_t = n2t(inp_), n2t(w1_), n2t(w2_), n2t(yg_)
     w1_t.requires_grad = True
     w2_t.requires_grad = True
 
     yt = torch.matmul(torch.matmul(inp_t, w1_t), w2_t)
 
     x = [w1_t, w2_t]
     g = yt.detach()
     g.requires_grad = True
 
     dfdxt_g = torch.autograd.grad(yt, x, g, create_graph=True)
     print(dfdxt_g[0].detach().numpy(), '\n', dfdxt_g[1].detach().numpy())
 
     dfdx_x = torch.autograd.grad(dfdxt_g, g, x, retain_graph=True)
 
     np.testing.assert_allclose(dfdxt_g[0].detach().numpy(), res[0], atol=1e-5, rtol=1e-5)
     np.testing.assert_allclose(dfdxt_g[1].detach().numpy(), res[1], atol=1e-5, rtol=1e-5)
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='LDOUBLEV' date='2019-09-26T08:16:56Z'>
 		报错截图
 &lt;denchmark-link:https://user-images.githubusercontent.com/26592129/65670971-facdcf00-e078-11e9-8f7b-19a5757e1376.png&gt;&lt;/denchmark-link&gt;
 
 打印的第二次计算的梯度信息
 &lt;denchmark-link:https://user-images.githubusercontent.com/26592129/65671005-0a4d1800-e079-11e9-994e-2398353c3b59.png&gt;&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='LDOUBLEV' date='2019-09-27T03:01:43Z'>
 		已经提了pr修复
 		</comment>
 	</comments>
 </bug>
<commit id='647ff784e2fee81dab4fd7c0c7f94a820c1e7e6f' author='lvmengsi' date='2019-09-27 13:53:47+08:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='paddle\fluid\operators\mul_op.cc' new_name='paddle\fluid\operators\mul_op.cc'>
 		<file_info nloc='254' complexity='28' token_count='1651'></file_info>
 		<method name='paddle::operators::MulDoubleGradMaker::Apply' parameters=''>
 				<method_info nloc='19' complexity='5' token_count='233' nesting_level='3' start_line='265' end_line='287'></method_info>
 			<added_lines>279,280,281</added_lines>
 			<deleted_lines>278,279,280</deleted_lines>
 		</method>
 		<method name='paddle::operators::MulDoubleGradOp::InferShape' parameters='ctx'>
 				<method_info nloc='15' complexity='8' token_count='140' nesting_level='3' start_line='242' end_line='257'></method_info>
 			<added_lines>247,248</added_lines>
 			<deleted_lines>247</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
