<bug_data>
<bug id='140' author='sanersbug' open_date='2018-10-25T05:42:19Z' closed_time='2018-12-17T22:19:21Z'>
 	<summary>ninja: build stopped: subcommand failed.</summary>
 	<description>
 After i installed ninja , When i run
 python main.py --dataset cifar10 --model encnetdrop --widen 8 --ncodes 32 --resume model/encnet_cifar.pth.tar --eval
 it shows the error:
 /home/anaconda3/lib/python3.6/site-packages/torch/utils/cpp_extension.py:118: UserWarning:
 &lt;denchmark-code&gt;                           !! WARNING !!
 &lt;/denchmark-code&gt;
 
 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 Your compiler (c++) may be ABI-incompatible with PyTorch!
 Please use a compiler that is ABI-compatible with GCC 4.9 and above.
 See &lt;denchmark-link:https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html&gt;https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html&lt;/denchmark-link&gt;
 .
 See &lt;denchmark-link:https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6&gt;https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6&lt;/denchmark-link&gt;
 
 for instructions on how to install GCC 4.9 or higher.
 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 &lt;denchmark-code&gt;                          !! WARNING !!
 &lt;/denchmark-code&gt;
 
 warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))
 Traceback (most recent call last):
 File "/home/anaconda3/lib/python3.6/site-packages/torch/utils/cpp_extension.py", line 759, in _build_extension_module
 ['ninja', '-v'], stderr=subprocess.STDOUT, cwd=build_directory)
 File "/home/anaconda3/lib/python3.6/subprocess.py", line 336, in check_output
 **kwargs).stdout
 File "/home/anaconda3/lib/python3.6/subprocess.py", line 418, in run
 output=stdout, stderr=stderr)
 subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.
 During handling of the above exception, another exception occurred:
 Traceback (most recent call last):
 File "main.py", line 24, in 
 from encoding.utils import *
 File "/home/anaconda3/lib/python3.6/site-packages/encoding/init.py", line 13, in 
 from . import nn, functions, dilated, parallel, utils, models, datasets
 File "/home/anaconda3/lib/python3.6/site-packages/encoding/nn/init.py", line 12, in 
 from .encoding import *
 File "/home/anaconda3/lib/python3.6/site-packages/encoding/nn/encoding.py", line 18, in 
 from ..functions import scaled_l2, aggregate, pairwise_cosine
 File "/home/anaconda3/lib/python3.6/site-packages/encoding/functions/init.py", line 2, in 
 from .encoding import *
 File "/home/anaconda3/lib/python3.6/site-packages/encoding/functions/encoding.py", line 14, in 
 from .. import lib
 File "/home/anaconda3/lib/python3.6/site-packages/encoding/lib/init.py", line 15, in 
 ], build_directory=cpu_path, verbose=False)
 File "/home/anaconda3/lib/python3.6/site-packages/torch/utils/cpp_extension.py", line 514, in load
 with_cuda=with_cuda)
 File "/home/anaconda3/lib/python3.6/site-packages/torch/utils/cpp_extension.py", line 682, in _jit_compile
 _build_extension_module(name, build_directory)
 File "/home/anaconda3/lib/python3.6/site-packages/torch/utils/cpp_extension.py", line 765, in _build_extension_module
 name, error.output.decode()))
 RuntimeError: Error building extension 'enclib_cpu': [1/4] c++ -MMD -MF syncbn_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/TH -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/THC -I/home/anaconda3/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/syncbn_cpu.cpp -o syncbn_cpu.o
 FAILED: syncbn_cpu.o
 c++ -MMD -MF syncbn_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/TH -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/THC -I/home/anaconda3/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/syncbn_cpu.cpp -o syncbn_cpu.o
 /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/syncbn_cpu.cpp:1:26: fatal error: torch/tensor.h: No such file or directory
 compilation terminated.
 [2/4] c++ -MMD -MF roi_align_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/TH -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/THC -I/home/anaconda3/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/roi_align_cpu.cpp -o roi_align_cpu.o
 FAILED: roi_align_cpu.o
 c++ -MMD -MF roi_align_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/TH -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/THC -I/home/anaconda3/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/roi_align_cpu.cpp -o roi_align_cpu.o
 /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/roi_align_cpu.cpp:1:26: fatal error: torch/tensor.h: No such file or directory
 compilation terminated.
 [3/4] c++ -MMD -MF nms_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/TH -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/THC -I/home/anaconda3/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/nms_cpu.cpp -o nms_cpu.o
 FAILED: nms_cpu.o
 c++ -MMD -MF nms_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/TH -I/home/anaconda3/lib/python3.6/site-packages/torch/lib/include/THC -I/home/anaconda3/include/python3.6m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/nms_cpu.cpp -o nms_cpu.o
 /home/anaconda3/lib/python3.6/site-packages/encoding/lib/cpu/nms_cpu.cpp:1:26: fatal error: torch/tensor.h: No such file or directory
 compilation terminated.
 ninja: build stopped: subcommand failed.
 	</description>
 	<comments>
 		<comment id='1' author='sanersbug' date='2018-10-25T14:43:54Z'>
 		That looks like PyTorch problem.
 		</comment>
 		<comment id='2' author='sanersbug' date='2018-11-13T04:23:08Z'>
 		hi, have you solved this problem ?
 		</comment>
 		<comment id='3' author='sanersbug' date='2018-11-13T14:14:17Z'>
 		Wow, I have faced with the same problem. But I have an gcc version of 5.4.0, I don't know why.
 		</comment>
 		<comment id='4' author='sanersbug' date='2018-11-13T16:05:24Z'>
 		Hello! im getting the same error when i try running model/download_models.py
 Did anyone manage to solve this issue?
 		</comment>
 		<comment id='5' author='sanersbug' date='2018-11-13T17:58:43Z'>
 		Please change torch/torch.h to torch/extension.h. This is because rapid updates in PyTorch.
 		</comment>
 		<comment id='6' author='sanersbug' date='2018-11-14T10:50:09Z'>
 		Thanks for the quick reply.
 Unfortunately the error message persists even after changing the name.
 (I changed pipPath/torch/lib/include/torch/torch.h to extension.h, where pipPath = folder that includes all pip installs).
 Heres the error message i get when running model/download_models.py. I will highlight the errors in bold with gcc version5.4.0:
 `
 /home/ev/.local/lib/python3.5/site-packages/torch/utils/cpp_extension.py:118: UserWarning:
 &lt;denchmark-code&gt;                           !! WARNING !!
 &lt;/denchmark-code&gt;
 
 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 Your compiler (c++) may be ABI-incompatible with PyTorch!
 Please use a compiler that is ABI-compatible with GCC 4.9 and above.
 See &lt;denchmark-link:https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html&gt;https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html&lt;/denchmark-link&gt;
 .
 See &lt;denchmark-link:https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6&gt;https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6&lt;/denchmark-link&gt;
 
 for instructions on how to install GCC 4.9 or higher.
 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 &lt;denchmark-code&gt;                          !! WARNING !!
 &lt;/denchmark-code&gt;
 
 warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))
 Traceback (most recent call last):
 File "/home/ev/.local/lib/python3.5/site-packages/torch/utils/cpp_extension.py", line 759, in _build_extension_module
 ['ninja', '-v'], stderr=subprocess.STDOUT, cwd=build_directory)
 File "/usr/lib/python3.5/subprocess.py", line 626, in check_output
 **kwargs).stdout
 File "/usr/lib/python3.5/subprocess.py", line 708, in run
 output=stdout, stderr=stderr)
 subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1
 During handling of the above exception, another exception occurred:
 Traceback (most recent call last):
 File "model/download_models.py", line 1, in 
 import encoding
 File "/home/ev/.local/lib/python3.5/site-packages/encoding/init.py", line 13, in 
 from . import nn, functions, dilated, parallel, utils, models, datasets
 File "/home/ev/.local/lib/python3.5/site-packages/encoding/nn/init.py", line 12, in 
 from .encoding import *
 File "/home/ev/.local/lib/python3.5/site-packages/encoding/nn/encoding.py", line 18, in 
 from ..functions import scaled_l2, aggregate, pairwise_cosine
 File "/home/ev/.local/lib/python3.5/site-packages/encoding/functions/init.py", line 2, in 
 from .encoding import *
 File "/home/ev/.local/lib/python3.5/site-packages/encoding/functions/encoding.py", line 14, in 
 from .. import lib
 File "/home/ev/.local/lib/python3.5/site-packages/encoding/lib/init.py", line 15, in 
 ], build_directory=cpu_path, verbose=False)
 File "/home/evangello/.local/lib/python3.5/site-packages/torch/utils/cpp_extension.py", line 514, in load
 with_cuda=with_cuda)
 File "/home/evangello/.local/lib/python3.5/site-packages/torch/utils/cpp_extension.py", line 682, in _jit_compile
 _build_extension_module(name, build_directory)
 File "/home/ev/.local/lib/python3.5/site-packages/torch/utils/cpp_extension.py", line 765, in _build_extension_module
 name, error.output.decode()))
 RuntimeError: Error building extension 'enclib_cpu': [1/4] c++ -MMD -MF syncbn_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/TH -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/THC -I/usr/include/python3.5m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/syncbn_cpu.cpp -o syncbn_cpu.o
 FAILED: syncbn_cpu.o
 c++ -MMD -MF syncbn_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/TH -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/THC -I/usr/include/python3.5m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/syncbn_cpu.cpp -o syncbn_cpu.o
 /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/syncbn_cpu.cpp:1:26: fatal error: torch/tensor.h: No such file or directory
 compilation terminated.
 [2/4] c++ -MMD -MF roi_align_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/TH -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/THC -I/usr/include/python3.5m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/roi_align_cpu.cpp -o roi_align_cpu.o
 FAILED: roi_align_cpu.o
 c++ -MMD -MF roi_align_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/TH -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/THC -I/usr/include/python3.5m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/roi_align_cpu.cpp -o roi_align_cpu.o
 /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/roi_align_cpu.cpp:1:26: fatal error: torch/tensor.h: No such file or directory
 compilation terminated.
 [3/4] c++ -MMD -MF nms_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/TH -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/THC -I/usr/include/python3.5m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/nms_cpu.cpp -o nms_cpu.o
 FAILED: nms_cpu.o
 c++ -MMD -MF nms_cpu.o.d -DTORCH_EXTENSION_NAME=enclib_cpu -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/TH -I/home/ev/.local/lib/python3.5/site-packages/torch/lib/include/THC -I/usr/include/python3.5m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/nms_cpu.cpp -o nms_cpu.o
 /home/ev/.local/lib/python3.5/site-packages/encoding/lib/cpu/nms_cpu.cpp:1:26: fatal error: torch/tensor.h: No such file or directory
 compilation terminated.
 ninja: build stopped: subcommand failed.
 `
 		</comment>
 		<comment id='7' author='sanersbug' date='2018-11-14T17:11:11Z'>
 		see my previous comment &lt;denchmark-link:https://github.com/zhanghang1989/PyTorch-Encoding/issues/140#issuecomment-438373706&gt;#140 (comment)&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='8' author='sanersbug' date='2018-11-18T01:59:44Z'>
 		I found that the problem is that the position of &lt;torch/tensor.h&gt; has been changed , it's in &lt;torch/serialize/tensor.h&gt; now. I changed the code and solved my prolem.
 		</comment>
 		<comment id='9' author='sanersbug' date='2018-11-19T05:45:31Z'>
 		
 I found that the problem is that the position of &lt;torch/tensor.h&gt; has been changed , it's in &lt;torch/serialize/tensor.h&gt; now. I changed the code and solved my prolem.
 
 Hi, which version of pytorch do you use??
 		</comment>
 		<comment id='10' author='sanersbug' date='2018-11-19T06:08:14Z'>
 		&lt;denchmark-link:https://user-images.githubusercontent.com/18614177/48689044-bb865480-ec03-11e8-9fc7-18a17380cf7c.png&gt;&lt;/denchmark-link&gt;
 
 This is the version of pytorch. I use the master branch of Nov, 17. But I think may be v1.0 will help after change the code.
 ps:CUDA=9.0, CUDNN=7.0. I wish that these will help.
 		</comment>
 		<comment id='11' author='sanersbug' date='2018-11-19T18:11:58Z'>
 		Please change torch/torch.h to torch/extension.h. This is because rapid updates in PyTorch.
 		</comment>
 		<comment id='12' author='sanersbug' date='2018-11-29T03:22:21Z'>
 		
 I found that the problem is that the position of &lt;torch/tensor.h&gt; has been changed , it's in &lt;torch/serialize/tensor.h&gt; now. I changed the code and solved my prolem.
 
 Hello, i meet the same problems, i want to know how to change the code? than you
 		</comment>
 		<comment id='13' author='sanersbug' date='2018-11-29T03:36:39Z'>
 		
 
 I found that the problem is that the position of &lt;torch/tensor.h&gt; has been changed , it's in &lt;torch/serialize/tensor.h&gt; now. I changed the code and solved my prolem.
 
 Hello, i meet the same problems, i want to know how to change the code? than you
 
 At first I tried what &lt;denchmark-link:https://github.com/zhanghang1989&gt;@zhanghang1989&lt;/denchmark-link&gt;
  said " Please change torch/torch.h to torch/extension.h. " .But it didn't solve my problem. I found that the error was that &lt;torch/tensor.h&gt; couldnot be found, so I changed all the "#include &lt;torch/tensor.h&gt;" in cpp files to "#include &lt;torch/serialize/tensor.h&gt;". Maybe the position of "tensor.h" can be different, you can change the path in your own system. Hope this will help.
 		</comment>
 		<comment id='14' author='sanersbug' date='2018-11-30T09:20:10Z'>
 		
 
 
 I found that the problem is that the position of &lt;torch/tensor.h&gt; has been changed , it's in &lt;torch/serialize/tensor.h&gt; now. I changed the code and solved my prolem.
 
 Hello, i meet the same problems, i want to know how to change the code? than you
 
 At first I tried what @zhanghang1989 said " Please change torch/torch.h to torch/extension.h. " .But it didn't solve my problem. I found that the error was that &lt;torch/tensor.h&gt; couldnot be found, so I changed all the "#include &lt;torch/tensor.h&gt;" in cpp files to "#include &lt;torch/serialize/tensor.h&gt;". Maybe the position of "tensor.h" can be different, you can change the path in your own system. Hope this will help.
 
 I have the same problem as yours.
 		</comment>
 		<comment id='15' author='sanersbug' date='2019-04-10T02:59:35Z'>
 		
 Please change torch/torch.h to torch/extension.h. This is because rapid updates in PyTorch.
 
 
 hi, Rename torch.h to extension.h  ?
 		</comment>
 	</comments>
 </bug>
<commit id='ce461dae8d088253dcd9818d2999d4049bce3493' author='Hang Zhang' date='2018-12-17 14:19:19-08:00'>
 	<dmm_unit complexity='1.0' interfacing='0.41098169717138106' size='0.17470881863560733'></dmm_unit>
 	<modification change_type='MODIFY' old_name='docs\source\experiments\cifar.rst' new_name='docs\source\experiments\cifar.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>60,61,62,63,64,65,66,67,68,69,70,71,72</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='docs\source\experiments\segmentation.rst' new_name='docs\source\experiments\segmentation.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>41,42,43,44,45,46,47,48,49,50,51,52,53</added_lines>
 			<deleted_lines>41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='docs\source\experiments\texture.rst' new_name='docs\source\experiments\texture.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>25,27,29,37</added_lines>
 			<deleted_lines>25,27,28,29,30,31,32,34,42,65,66,67,68,69,70,71,72,73,74,75,76,77,78</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='DELETE' old_name='docs\source\functions.rst' new_name='None'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='docs\source\index.rst' new_name='docs\source\index.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>33</added_lines>
 			<deleted_lines>33,34</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='RENAME' old_name='docs\source\dilated.rst' new_name='docs\source\models.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='docs\source\nn.rst' new_name='docs\source\nn.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>17,20,29,30,31,32,33,34</added_lines>
 			<deleted_lines>17,20</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='docs\source\notes\compile.rst' new_name='docs\source\notes\compile.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>5,6,8</added_lines>
 			<deleted_lines>5,6,8,9,10,11</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\__init__.py' new_name='encoding\__init__.py'>
 		<file_info nloc='3' complexity='0' token_count='22'></file_info>
 		<modified_lines>
 			<added_lines>13</added_lines>
 			<deleted_lines>13</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\datasets\__init__.py' new_name='encoding\datasets\__init__.py'>
 		<file_info nloc='50' complexity='3' token_count='236'></file_info>
 		<method name='_make_deprecate' parameters='meth,old_name'>
 				<method_info nloc='11' complexity='1' token_count='38' nesting_level='0' start_line='41' end_line='56'></method_info>
 			<added_lines>41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_segmentation_dataset' parameters='name,kwargs'>
 				<method_info nloc='2' complexity='1' token_count='21' nesting_level='0' start_line='18' end_line='19'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>18</deleted_lines>
 		</method>
 		<method name='get_dataset' parameters='name,kwargs'>
 				<method_info nloc='2' complexity='1' token_count='21' nesting_level='0' start_line='38' end_line='39'></method_info>
 			<added_lines>38</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_make_deprecate.deprecated_init' parameters='args,kwargs'>
 				<method_info nloc='4' complexity='1' token_count='33' nesting_level='1' start_line='44' end_line='47'></method_info>
 			<added_lines>44,45,46,47</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1,2,10,11,12,13,22,23,24,25,26,27,28,29,30,31,32,33,34,35,40,57,58</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\datasets\ade20k.py' new_name='encoding\datasets\ade20k.py'>
 		<file_info nloc='120' complexity='24' token_count='1054'></file_info>
 		<method name='_sync_transform' parameters='self,img,mask'>
 				<method_info nloc='28' complexity='6' token_count='322' nesting_level='1' start_line='60' end_line='91'></method_info>
 			<added_lines>60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>92</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\datasets\base.py' new_name='encoding\datasets\base.py'>
 		<file_info nloc='85' complexity='18' token_count='791'></file_info>
 		<method name='_sync_transform' parameters='self,img,mask'>
 				<method_info nloc='28' complexity='6' token_count='322' nesting_level='1' start_line='64' end_line='95'></method_info>
 			<added_lines>71,73,74,75,77,78,79</added_lines>
 			<deleted_lines>70,71,74,75,77,78,93,94,95</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>96</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\datasets\cityscapes.py' new_name='encoding\datasets\cityscapes.py'>
 		<file_info nloc='117' complexity='27' token_count='1138'></file_info>
 		<method name='_sync_transform' parameters='self,img,mask'>
 				<method_info nloc='32' complexity='7' token_count='377' nesting_level='1' start_line='90' end_line='128'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>129</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\datasets\coco.py' new_name='encoding\datasets\coco.py'>
 		<file_info nloc='117' complexity='14' token_count='829'></file_info>
 		<modified_lines>
 			<added_lines>26,103</added_lines>
 			<deleted_lines>126</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\datasets\imagenet.py'>
 		<file_info nloc='11' complexity='1' token_count='97'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\datasets\minc.py'>
 		<file_info nloc='42' complexity='10' token_count='372'></file_info>
 	</modification>
 	<modification change_type='DELETE' old_name='encoding\dilated\__init__.py' new_name='None'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\functions\syncbn.py' new_name='encoding\functions\syncbn.py'>
 		<file_info nloc='231' complexity='32' token_count='1966'></file_info>
 		<method name='backward' parameters='ctx,gradOutput'>
 				<method_info nloc='9' complexity='2' token_count='70' nesting_level='1' start_line='53' end_line='61'></method_info>
 			<added_lines>53,54,55,56,57,58,59,60,61</added_lines>
 			<deleted_lines>53,54,55,56,57,58,61</deleted_lines>
 		</method>
 		<method name='forward' parameters='ctx,x'>
 				<method_info nloc='6' complexity='2' token_count='32' nesting_level='1' start_line='21' end_line='26'></method_info>
 			<added_lines>21,22,23,24,25,26</added_lines>
 			<deleted_lines>22,24,25,26</deleted_lines>
 		</method>
 		<method name='sum_square' parameters='input'>
 				<method_info nloc='3' complexity='1' token_count='14' nesting_level='0' start_line='17' end_line='19'></method_info>
 			<added_lines>17,19</added_lines>
 			<deleted_lines>17,18,19</deleted_lines>
 		</method>
 		<method name='backward' parameters='ctx,gradSum,gradSquare'>
 				<method_info nloc='7' complexity='2' token_count='40' nesting_level='1' start_line='33' end_line='39'></method_info>
 			<added_lines>33,34,35,36,37,38,39</added_lines>
 			<deleted_lines>33,34,35,36,39</deleted_lines>
 		</method>
 		<method name='_act_forward' parameters='ctx,x'>
 				<method_info nloc='8' complexity='3' token_count='45' nesting_level='0' start_line='156' end_line='163'></method_info>
 			<added_lines>156,157,158,159,160,161,162,163</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='forward' parameters='cls,ctx,x,gamma,beta,running_mean,running_var,extra,sync,training,momentum,eps,activation,slope'>
 				<method_info nloc='3' complexity='1' token_count='49' nesting_level='1' start_line='38' end_line='40'></method_info>
 			<added_lines>38,39,40</added_lines>
 			<deleted_lines>39</deleted_lines>
 		</method>
 		<method name='_act_backward' parameters='ctx,x,dx'>
 				<method_info nloc='8' complexity='3' token_count='49' nesting_level='0' start_line='165' end_line='172'></method_info>
 			<added_lines>165,166,167,168,170,171,172</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='forward' parameters='ctx,input'>
 				<method_info nloc='7' complexity='2' token_count='48' nesting_level='1' start_line='24' end_line='30'></method_info>
 			<added_lines>24,25,26,29,30</added_lines>
 			<deleted_lines>24,25,26,27,29,30</deleted_lines>
 		</method>
 		<method name='batchnormtrain' parameters='input,mean,std,gamma,beta'>
 				<method_info nloc='16' complexity='1' token_count='30' nesting_level='0' start_line='64' end_line='79'></method_info>
 			<added_lines>64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79</added_lines>
 			<deleted_lines>64,65,66,68,70,72,74,75,76,78,79</deleted_lines>
 		</method>
 		<method name='backward' parameters='ctx,dz'>
 				<method_info nloc='32' complexity='8' token_count='315' nesting_level='1' start_line='105' end_line='143'></method_info>
 			<added_lines>105,106,107,108,109,110,111,112,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='forward' parameters='ctx,input,mean,std,gamma,beta'>
 				<method_info nloc='7' complexity='2' token_count='74' nesting_level='1' start_line='44' end_line='50'></method_info>
 			<added_lines>44,45,46,47,48,49,50</added_lines>
 			<deleted_lines>44,45,46,47,49,50</deleted_lines>
 		</method>
 		<method name='_parse_extra' parameters='ctx,extra'>
 				<method_info nloc='9' complexity='2' token_count='62' nesting_level='1' start_line='146' end_line='154'></method_info>
 			<added_lines>146,147,148,149,150,151,152,153,154</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='backward' parameters='ctx,dex,dex2'>
 				<method_info nloc='6' complexity='2' token_count='34' nesting_level='1' start_line='29' end_line='34'></method_info>
 			<added_lines>29,30,31,33,34</added_lines>
 			<deleted_lines>29,30,33,34</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>12,14,20,41,42,43,51,52,62,63,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,104,155,164,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,244,245,246,247,248,249,250,251,252,253,254,255,259,260,261,262,263,264,265,266,267,269,270,272,273,274,275,276,277,278,280,281,282,283,285,287,288,289,290,291,292,293,294,295,296,298,299</added_lines>
 			<deleted_lines>15,16,42</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\__init__.py' new_name='encoding\lib\__init__.py'>
 		<file_info nloc='24' complexity='0' token_count='234'></file_info>
 		<modified_lines>
 			<added_lines>20,26,27</added_lines>
 			<deleted_lines>25</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='DELETE' old_name='encoding\lib\cpu\__init__.py' new_name='encoding\lib\cpu\__init__.py'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\cpu\nms_cpu.cpp' new_name='encoding\lib\cpu\nms_cpu.cpp'>
 		<file_info nloc='83' complexity='15' token_count='857'></file_info>
 		<modified_lines>
 			<added_lines>1</added_lines>
 			<deleted_lines>1</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='DELETE' old_name='encoding\lib\cpu\roi_align.cpp' new_name='None'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\cpu\roi_align_cpu.cpp' new_name='encoding\lib\cpu\roi_align_cpu.cpp'>
 		<file_info nloc='386' complexity='48' token_count='2617'></file_info>
 		<modified_lines>
 			<added_lines>1</added_lines>
 			<deleted_lines>1</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\cpu\syncbn_cpu.cpp' new_name='encoding\lib\cpu\syncbn_cpu.cpp'>
 		<file_info nloc='51' complexity='7' token_count='407'></file_info>
 		<modified_lines>
 			<added_lines>1</added_lines>
 			<deleted_lines>1</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='DELETE' old_name='encoding\lib\gpu\__init__.py' new_name='encoding\lib\gpu\__init__.py'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\lib\gpu\activation_kernel.cu'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\gpu\encoding_kernel.cu' new_name='encoding\lib\gpu\encoding_kernel.cu'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>2</added_lines>
 			<deleted_lines>2</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\gpu\encodingv2_kernel.cu' new_name='encoding\lib\gpu\encodingv2_kernel.cu'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>2</added_lines>
 			<deleted_lines>2</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\gpu\nms_kernel.cu' new_name='encoding\lib\gpu\nms_kernel.cu'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>1</added_lines>
 			<deleted_lines>1</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\gpu\operator.cpp' new_name='encoding\lib\gpu\operator.cpp'>
 		<file_info nloc='28' complexity='1' token_count='274'></file_info>
 		<method name='PYBIND11_MODULE' parameters='TORCH_EXTENSION_NAME,m'>
 				<method_info nloc='27' complexity='1' token_count='272' nesting_level='0' start_line='3' end_line='29'></method_info>
 			<added_lines>12,14,15,16,17,18,27,28</added_lines>
 			<deleted_lines>13,14</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\gpu\operator.h' new_name='encoding\lib\gpu\operator.h'>
 		<file_info nloc='124' complexity='0' token_count='748'></file_info>
 		<modified_lines>
 			<added_lines>1,57,58,59,60,61,62,63,64,65,66,71,72,73,74,75,76,77,78,79,80,81,83,84,86,89,91,92,93,94,95,96,97,98,99,100,101,102,103,106,107,108,111,112,113,114,115,123,124,125,126,127,128,143,144,145,146</added_lines>
 			<deleted_lines>1,57,62,63,65,66,68,71,73,74,77,78,79,82,83,84,85,86,94,95,96,97,98,99</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\gpu\roi_align_kernel.cu' new_name='encoding\lib\gpu\roi_align_kernel.cu'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>1</added_lines>
 			<deleted_lines>1</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\gpu\setup.py' new_name='encoding\lib\gpu\setup.py'>
 		<file_info nloc='18' complexity='0' token_count='55'></file_info>
 		<modified_lines>
 			<added_lines>9</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\lib\gpu\syncbn_kernel.cu' new_name='encoding\lib\gpu\syncbn_kernel.cu'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>2,14,17,20,21,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,168,169,182,183,184,207,209,210,211,220,221,226,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,256,257,258,260,263,267,268,270,271,273,281,287,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,366,367,369,370,372,373,374,375,376,377,382,389,393,394,398,399,402,405,408,409,415,418,419,421,422,425,428,430,431,439,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,482,483,484</added_lines>
 			<deleted_lines>2,14,17,20,21,102,103,104,117,118,119,142,144,145,154,155,160,163,164,168,169,170,171,173,176,180,181,183,192,198,207,208,210,211,213,214,215,216,217,222,229,233,234,238,239,242,245,248,249,257,258,260,261,264,267,269,270,281,282,284,285</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\models\__init__.py' new_name='encoding\models\__init__.py'>
 		<file_info nloc='20' complexity='1' token_count='100'></file_info>
 		<method name='get_segmentation_model' parameters='name,kwargs'>
 				<method_info nloc='11' complexity='1' token_count='54' nesting_level='0' start_line='11' end_line='21'></method_info>
 			<added_lines>16,18,19</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>3,4,9</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\models\base.py' new_name='encoding\models\base.py'>
 		<file_info nloc='187' complexity='32' token_count='1817'></file_info>
 		<method name='forward' parameters='self,image'>
 				<method_info nloc='67' complexity='8' token_count='596' nesting_level='1' start_line='120' end_line='196'></method_info>
 			<added_lines>141,142,143,144,145,146,147,148,149,150,151</added_lines>
 			<deleted_lines>183</deleted_lines>
 		</method>
 		<method name='base_forward' parameters='self,x'>
 				<method_info nloc='24' complexity='2' token_count='222' nesting_level='1' start_line='52' end_line='75'></method_info>
 			<added_lines>53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74</added_lines>
 			<deleted_lines>53,54,55,56,57,58,59,60</deleted_lines>
 		</method>
 		<method name='resize_image' parameters='img,h,w,up_kwargs'>
 				<method_info nloc='2' complexity='1' token_count='28' nesting_level='0' start_line='207' end_line='208'></method_info>
 			<added_lines>208</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>17,37</added_lines>
 			<deleted_lines>13,18</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\models\cifarresnet.py'>
 		<file_info nloc='107' complexity='17' token_count='920'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\models\deeplab.py'>
 		<file_info nloc='118' complexity='13' token_count='974'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\models\deepten.py'>
 		<file_info nloc='80' complexity='7' token_count='461'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\models\encnet.py' new_name='encoding\models\encnet.py'>
 		<file_info nloc='220' complexity='16' token_count='1235'></file_info>
 		<method name='__init__' parameters='self,in_channels,nclass,ncodes,se_loss,norm_layer'>
 				<method_info nloc='16' complexity='2' token_count='145' nesting_level='1' start_line='45' end_line='60'></method_info>
 			<added_lines>52,53,55</added_lines>
 			<deleted_lines>52,53,55</deleted_lines>
 		</method>
 		<method name='forward' parameters='self,x'>
 				<method_info nloc='10' complexity='2' token_count='101' nesting_level='1' start_line='31' end_line='41'></method_info>
 			<added_lines>36,39</added_lines>
 			<deleted_lines>36,39</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,nclass,backbone,aux,se_loss,lateral,norm_layer,kwargs'>
 				<method_info nloc='2' complexity='1' token_count='28' nesting_level='1' start_line='21' end_line='22'></method_info>
 			<added_lines>22</added_lines>
 			<deleted_lines>22</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,nclass,backbone,aux,se_loss,lateral,norm_layer,kwargs'>
 				<method_info nloc='2' complexity='1' token_count='30' nesting_level='1' start_line='21' end_line='22'></method_info>
 			<added_lines>22</added_lines>
 			<deleted_lines>22</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>14,139</added_lines>
 			<deleted_lines>12,137,138,139,140,141,144</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\models\fcn.py' new_name='encoding\models\fcn.py'>
 		<file_info nloc='151' complexity='13' token_count='777'></file_info>
 		<method name='__init__' parameters='self,in_channels,out_channels,norm_layer'>
 				<method_info nloc='8' complexity='1' token_count='85' nesting_level='1' start_line='62' end_line='69'></method_info>
 			<added_lines>62,63,64,65,66,67,68,69</added_lines>
 			<deleted_lines>62,65,66,67,68,69</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,nclass,backbone,aux,se_loss,with_global,norm_layer,kwargs'>
 				<method_info nloc='2' complexity='1' token_count='28' nesting_level='1' start_line='42' end_line='43'></method_info>
 			<added_lines>42,43</added_lines>
 			<deleted_lines>43</deleted_lines>
 		</method>
 		<method name='forward' parameters='self,x'>
 				<method_info nloc='11' complexity='2' token_count='95' nesting_level='1' start_line='49' end_line='60'></method_info>
 			<added_lines>54,58</added_lines>
 			<deleted_lines>52,56</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,in_channels,out_channels,norm_layer,up_kwargs'>
 				<method_info nloc='7' complexity='1' token_count='70' nesting_level='1' start_line='71' end_line='77'></method_info>
 			<added_lines>71,72,73,74,75,76,77</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='64' end_line='65'></method_info>
 			<added_lines>64,65</added_lines>
 			<deleted_lines>65</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,nclass,backbone,aux,se_loss,norm_layer,kwargs'>
 				<method_info nloc='5' complexity='2' token_count='77' nesting_level='1' start_line='41' end_line='45'></method_info>
 			<added_lines>42,43,45</added_lines>
 			<deleted_lines>41,43</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,in_channels,out_channels,norm_layer,up_kwargs,with_global'>
 				<method_info nloc='21' complexity='2' token_count='189' nesting_level='1' start_line='86' end_line='106'></method_info>
 			<added_lines>86,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106</added_lines>
 			<deleted_lines>92,93,94,95,96,97,99</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>11,12,70,78,79,80,81,82,83,130</added_lines>
 			<deleted_lines>11</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\models\model_store.py' new_name='encoding\models\model_store.py'>
 		<file_info nloc='90' complexity='12' token_count='481'></file_info>
 		<modified_lines>
 			<added_lines>10,13,14,15</added_lines>
 			<deleted_lines>10,13</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\models\model_zoo.py' new_name='encoding\models\model_zoo.py'>
 		<file_info nloc='29' complexity='2' token_count='156'></file_info>
 		<method name='get_model' parameters='name,kwargs'>
 				<method_info nloc='22' complexity='2' token_count='120' nesting_level='0' start_line='13' end_line='50'></method_info>
 			<added_lines>31,32,33,34,35,36,37,48</added_lines>
 			<deleted_lines>38</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>3,4,8</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\models\psp.py' new_name='encoding\models\psp.py'>
 		<file_info nloc='66' complexity='8' token_count='491'></file_info>
 		<method name='forward' parameters='self,x'>
 				<method_info nloc='12' complexity='2' token_count='110' nesting_level='1' start_line='24' end_line='36'></method_info>
 			<added_lines>30,34</added_lines>
 			<deleted_lines>30,34</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>11,56</added_lines>
 			<deleted_lines>11,55,56,57,58,59,61</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='RENAME' old_name='encoding\dilated\resnet.py' new_name='encoding\models\resnet.py'>
 		<file_info nloc='227' complexity='30' token_count='1928'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\nn\__init__.py' new_name='encoding\nn\__init__.py'>
 		<file_info nloc='5' complexity='0' token_count='21'></file_info>
 		<modified_lines>
 			<added_lines>15</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='DELETE' old_name='encoding\nn\comm.py' new_name='None'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\nn\customize.py' new_name='encoding\nn\customize.py'>
 		<file_info nloc='123' complexity='18' token_count='907'></file_info>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='16' nesting_level='1' start_line='24' end_line='26'></method_info>
 			<added_lines>24,25,26</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='forward' parameters='self,inputs'>
 				<method_info nloc='2' complexity='1' token_count='29' nesting_level='1' start_line='28' end_line='29'></method_info>
 			<added_lines>28,29</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,in_channels,norm_layer,up_kwargs'>
 				<method_info nloc='20' complexity='1' token_count='214' nesting_level='1' start_line='129' end_line='150'></method_info>
 			<added_lines>131,132,133,134,137,139,140,142,143,145,146,148,149</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='forward' parameters='self,inputs'>
 				<method_info nloc='21' complexity='5' token_count='251' nesting_level='1' start_line='53' end_line='73'></method_info>
 			<added_lines>61,71</added_lines>
 			<deleted_lines>53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73</deleted_lines>
 		</method>
 		<method name='forward' parameters='self,x'>
 				<method_info nloc='5' complexity='2' token_count='34' nesting_level='1' start_line='118' end_line='122'></method_info>
 			<added_lines>118,119,120,121,122</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,modules'>
 				<method_info nloc='2' complexity='1' token_count='20' nesting_level='1' start_line='115' end_line='116'></method_info>
 			<added_lines>115,116</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,se_loss,se_weight,nclass,aux,aux_weight,weight,size_average,ignore_index'>
 				<method_info nloc='3' complexity='1' token_count='43' nesting_level='1' start_line='42' end_line='44'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>42,43,44</deleted_lines>
 		</method>
 		<method name='_get_batch_label_vector' parameters='target,nclass'>
 				<method_info nloc='10' complexity='2' token_count='84' nesting_level='1' start_line='76' end_line='86'></method_info>
 			<added_lines>81</added_lines>
 			<deleted_lines>76,77,78,79,80,81,82,83,84,85,86</deleted_lines>
 		</method>
 		<method name='softmax_crossentropy' parameters='input,target,weight,size_average,ignore_index,reduce'>
 				<method_info nloc='3' complexity='1' token_count='41' nesting_level='0' start_line='36' end_line='38'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>36,37,38</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>13,19,20,21,23,27,30,31,32,33,46,108,109,110,111,112,113,114,117,124,154,155,156,157</added_lines>
 			<deleted_lines>13,14,20,21,23,39,40,41,45,46,47,48,49,50,51,52,74,75,87,88,89,104,114,124,152,159,160,161,162,165,167,168,170,171,173,174,176,177,182,183,184,185</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\nn\loss.py'>
 		<file_info nloc='144' complexity='23' token_count='1562'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\nn\syncbn.py' new_name='encoding\nn\syncbn.py'>
 		<file_info nloc='131' complexity='9' token_count='635'></file_info>
 		<method name='extra_repr' parameters='self'>
 				<method_info nloc='7' complexity='2' token_count='44' nesting_level='1' start_line='124' end_line='130'></method_info>
 			<added_lines>124,125,126,127,128,129,130</added_lines>
 			<deleted_lines>130</deleted_lines>
 		</method>
 		<method name='forward' parameters='self,input'>
 				<method_info nloc='14' complexity='3' token_count='167' nesting_level='1' start_line='39' end_line='59'></method_info>
 			<added_lines>59</added_lines>
 			<deleted_lines>39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59</deleted_lines>
 		</method>
 		<method name='_clear' parameters='self'>
 				<method_info nloc='5' complexity='1' token_count='30' nesting_level='1' start_line='199' end_line='203'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>199,200,201,202,203</deleted_lines>
 		</method>
 		<method name='__len__' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='9' nesting_level='1' start_line='240' end_line='241'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>240,241</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,nGPUs'>
 				<method_info nloc='5' complexity='1' token_count='38' nesting_level='1' start_line='193' end_line='197'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>193,194,195,196,197</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,args,kwargs'>
 				<method_info nloc='4' complexity='1' token_count='43' nesting_level='1' start_line='137' end_line='140'></method_info>
 			<added_lines>137,138,139,140</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='forward' parameters='self,x'>
 				<method_info nloc='24' complexity='3' token_count='217' nesting_level='1' start_line='96' end_line='122'></method_info>
 			<added_lines>96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122</added_lines>
 			<deleted_lines>96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122</deleted_lines>
 		</method>
 		<method name='push' parameters='self,inputs'>
 				<method_info nloc='13' complexity='4' token_count='87' nesting_level='1' start_line='205' end_line='219'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>205,206,207,208,209,210,211,212,213,214,215,216,217,218,219</deleted_lines>
 		</method>
 		<method name='__repr__' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='9' nesting_level='1' start_line='243' end_line='244'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>243,244</deleted_lines>
 		</method>
 		<method name='_compute_mean_std' parameters='self,sum_,ssum,size'>
 				<method_info nloc='9' complexity='1' token_count='105' nesting_level='1' start_line='93' end_line='105'></method_info>
 			<added_lines>93,94,95,96,97,98,99,100,101,102,103,104,105</added_lines>
 			<deleted_lines>93,94,95,96,97,98,99,100,101,102,103,104,105</deleted_lines>
 		</method>
 		<method name='_check_input_dim' parameters='self,input'>
 				<method_info nloc='5' complexity='3' token_count='49' nesting_level='1' start_line='115' end_line='119'></method_info>
 			<added_lines>115,116,117,118,119</added_lines>
 			<deleted_lines>115,116,117,118,119</deleted_lines>
 		</method>
 		<method name='pull' parameters='self,igpu'>
 				<method_info nloc='15' complexity='6' token_count='138' nesting_level='1' start_line='221' end_line='238'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238</deleted_lines>
 		</method>
 		<method name='_data_parallel_master' parameters='self,intermediates'>
 				<method_info nloc='13' complexity='7' token_count='182' nesting_level='1' start_line='70' end_line='91'></method_info>
 			<added_lines>75,80,81,82,83,84,85,86,87,88,89,90,91</added_lines>
 			<deleted_lines>70,71,72,73,74,75,76,77,78,79,80,81,82,83,85,87,88,89,91</deleted_lines>
 		</method>
 		<method name='__data_parallel_replicate__' parameters='self,ctx,copy_id'>
 				<method_info nloc='6' complexity='2' token_count='42' nesting_level='1' start_line='61' end_line='68'></method_info>
 			<added_lines>61,62,63,64</added_lines>
 			<deleted_lines>61,62,63,64,65,66,67,68</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,num_features,eps,momentum,sync,activation,slope,inplace'>
 				<method_info nloc='2' complexity='1' token_count='37' nesting_level='1' start_line='80' end_line='81'></method_info>
 			<added_lines>80,81</added_lines>
 			<deleted_lines>80,81</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,num_features,eps,momentum,affine'>
 				<method_info nloc='5' complexity='1' token_count='66' nesting_level='1' start_line='32' end_line='37'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>32,33,34,35,36,37</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>12,13,14,15,16,17,21,25,28,60,92,123,131,132,133,134,135,136,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160</added_lines>
 			<deleted_lines>12,13,15,16,17,19,20,23,24,25,26,27,28,29,30,31,38,60,69,131,132,133,134,158,159,170,172,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,198,204,220,239,242</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\parallel.py' new_name='encoding\parallel.py'>
 		<file_info nloc='152' complexity='33' token_count='957'></file_info>
 		<method name='replicate' parameters='self,module,device_ids'>
 				<method_info nloc='4' complexity='1' token_count='30' nesting_level='1' start_line='99' end_line='102'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>101</deleted_lines>
 		</method>
 		<method name='execute_replication_callbacks' parameters='modules'>
 				<method_info nloc='8' complexity='5' token_count='82' nesting_level='0' start_line='201' end_line='222'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222</deleted_lines>
 		</method>
 		<method name='patch_replication_callback' parameters='data_parallel'>
 				<method_info nloc='6' complexity='1' token_count='32' nesting_level='0' start_line='225' end_line='249'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249</deleted_lines>
 		</method>
 		<method name='patch_replication_callback.new_replicate' parameters='module,device_ids'>
 				<method_info nloc='4' complexity='1' token_count='21' nesting_level='1' start_line='244' end_line='247'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>244,245,246,247</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>54,136,191,192,193,194,195,196,197,198,199,200,223,224</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\transforms\__init__.py'>
 		<file_info nloc='82' complexity='8' token_count='619'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\utils\__init__.py' new_name='encoding\utils\__init__.py'>
 		<file_info nloc='11' complexity='0' token_count='65'></file_info>
 		<modified_lines>
 			<added_lines>15,18</added_lines>
 			<deleted_lines>15</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='encoding\utils\misc.py'>
 		<file_info nloc='5' complexity='0' token_count='22'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\utils\pallete.py' new_name='encoding\utils\pallete.py'>
 		<file_info nloc='32' complexity='8' token_count='2707'></file_info>
 		<method name='get_mask_pallete' parameters='npimg,dataset'>
 				<method_info nloc='11' complexity='5' token_count='81' nesting_level='0' start_line='13' end_line='26'></method_info>
 			<added_lines>22</added_lines>
 			<deleted_lines>22</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\utils\presets.py' new_name='encoding\utils\presets.py'>
 		<file_info nloc='22' complexity='5' token_count='219'></file_info>
 		<method name='load_image' parameters='filename,size,scale,keep_asp,transform'>
 				<method_info nloc='13' complexity='5' token_count='155' nesting_level='0' start_line='13' end_line='27'></method_info>
 			<added_lines>13,25,26</added_lines>
 			<deleted_lines>13,25</deleted_lines>
 		</method>
 		<method name='load_image' parameters='filename,size,scale,keep_asp'>
 				<method_info nloc='12' complexity='4' token_count='148' nesting_level='0' start_line='13' end_line='26'></method_info>
 			<added_lines>13,25,26</added_lines>
 			<deleted_lines>13,25</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>7</added_lines>
 			<deleted_lines>7</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='encoding\utils\train_helper.py' new_name='encoding\utils\train_helper.py'>
 		<file_info nloc='59' complexity='6' token_count='226'></file_info>
 		<modified_lines>
 			<added_lines>12,13,14,15,16,17</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='experiments\recognition\dataset\minc.py' new_name='experiments\recognition\dataset\minc.py'>
 		<file_info nloc='103' complexity='17' token_count='957'></file_info>
 		<method name='__init__' parameters='self,args'>
 				<method_info nloc='29' complexity='2' token_count='271' nesting_level='1' start_line='78' end_line='108'></method_info>
 			<added_lines>97,99</added_lines>
 			<deleted_lines>97,99</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>52,136,137</added_lines>
 			<deleted_lines>52,136,137</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='experiments\recognition\main.py' new_name='experiments\recognition\main.py'>
 		<file_info nloc='142' complexity='21' token_count='1167'></file_info>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='1' start_line='165' end_line='166'></method_info>
 			<added_lines>165,166</added_lines>
 			<deleted_lines>165,166</deleted_lines>
 		</method>
 		<method name='accuracy' parameters='output,target,topk'>
 				<method_info nloc='13' complexity='2' token_count='132' nesting_level='0' start_line='146' end_line='160'></method_info>
 			<added_lines>146,147,148,149,150,151,152,153,154,155,156,157,158,159,160</added_lines>
 			<deleted_lines>146,147,148,149,150,151,152,153,156</deleted_lines>
 		</method>
 		<method name='main' parameters=''>
 				<method_info nloc='54' complexity='8' token_count='483' nesting_level='0' start_line='26' end_line='144'></method_info>
 			<added_lines>28,31,36,37,38,39,40,41,42,43,44,45,46,47,48,50,59,61,69,70,71,78,79,82,83,84,96,97,98,99,101,103,105,106,107,109,115,116,117,119,122,125,126,127,129,131,134,135,139,144</added_lines>
 			<deleted_lines>26,29,30,31,35,39,40,41,42,43,47,48,49,51,52,62,70,71,72,79,80,83,84,90,97,98,99,100,101,102,103,105,107,109,110,112,116,119,120,121,122,123,125,126,127,130,133,134,135,137,139,142,143</deleted_lines>
 		</method>
 		<method name='main.train' parameters='epoch'>
 				<method_info nloc='20' complexity='3' token_count='178' nesting_level='1' start_line='80' end_line='101'></method_info>
 			<added_lines>82,83,84,96,97,98,99,101</added_lines>
 			<deleted_lines>80,83,84,90,97,98,99,100,101</deleted_lines>
 		</method>
 		<method name='update' parameters='self,val,n'>
 				<method_info nloc='5' complexity='1' token_count='39' nesting_level='1' start_line='174' end_line='178'></method_info>
 			<added_lines>174,175,176,177,178</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='main.test' parameters='epoch'>
 				<method_info nloc='43' complexity='6' token_count='331' nesting_level='1' start_line='107' end_line='153'></method_info>
 			<added_lines>107,109,115,116,117,119,122,125,126,127,129,131,134,135,139,144,145,146,147,148,149,150,151,152,153</added_lines>
 			<deleted_lines>107,109,110,112,116,119,120,121,122,123,125,126,127,130,133,134,135,137,139,142,143,145,146,147,148,149,150,151,152,153</deleted_lines>
 		</method>
 		<method name='main.validate' parameters='epoch'>
 				<method_info nloc='31' complexity='5' token_count='245' nesting_level='1' start_line='103' end_line='136'></method_info>
 			<added_lines>103,105,106,107,109,115,116,117,119,122,125,126,127,129,131,134,135</added_lines>
 			<deleted_lines>103,105,107,109,110,112,116,119,120,121,122,123,125,126,127,130,133,134,135</deleted_lines>
 		</method>
 		<method name='reset' parameters='self'>
 				<method_info nloc='5' complexity='1' token_count='25' nesting_level='1' start_line='168' end_line='172'></method_info>
 			<added_lines>168,169,170,171,172</added_lines>
 			<deleted_lines>168,169,170,171</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>13,18,22,23,24,161,162,163,164,167,173</added_lines>
 			<deleted_lines>12,14,15,19,20,21,24,25,161,162,163,164,167</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='experiments\recognition\model\deepten.py' new_name='experiments\recognition\model\deepten.py'>
 		<file_info nloc='48' complexity='9' token_count='412'></file_info>
 		<modified_lines>
 			<added_lines>17</added_lines>
 			<deleted_lines>17</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='DELETE' old_name='experiments\recognition\model\download_models.py' new_name='None'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='experiments\recognition\option.py' new_name='experiments\recognition\option.py'>
 		<file_info nloc='57' complexity='3' token_count='531'></file_info>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='49' complexity='1' token_count='492' nesting_level='1' start_line='15' end_line='71'></method_info>
 			<added_lines>23,24,41,42,43,54,55</added_lines>
 			<deleted_lines>39,50,51</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='experiments\segmentation\option.py' new_name='experiments\segmentation\option.py'>
 		<file_info nloc='97' complexity='5' token_count='783'></file_info>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='68' complexity='1' token_count='618' nesting_level='1' start_line='12' end_line='88'></method_info>
 			<added_lines>33,47,50,80,81</added_lines>
 			<deleted_lines>33,47,50</deleted_lines>
 		</method>
 		<method name='parse' parameters='self'>
 				<method_info nloc='25' complexity='4' token_count='152' nesting_level='1' start_line='90' end_line='115'></method_info>
 			<added_lines>97,100,101,106,108,110,111</added_lines>
 			<deleted_lines>95,97,99,102,103,104,105,108,109,110,113</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='experiments\segmentation\test.py' new_name='experiments\segmentation\test.py'>
 		<file_info nloc='74' complexity='13' token_count='717'></file_info>
 		<method name='test' parameters='args'>
 				<method_info nloc='56' complexity='13' token_count='601' nesting_level='0' start_line='24' end_line='90'></method_info>
 			<added_lines>37,38,39,52,53,57,68,69</added_lines>
 			<deleted_lines>52,63,64</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>17</added_lines>
 			<deleted_lines>17</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='experiments\segmentation\test_models.py' new_name='experiments\segmentation\test_models.py'>
 		<file_info nloc='19' complexity='0' token_count='139'></file_info>
 		<modified_lines>
 			<added_lines>10</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='experiments\segmentation\train.py' new_name='experiments\segmentation\train.py'>
 		<file_info nloc='152' complexity='19' token_count='1342'></file_info>
 		<method name='__init__' parameters='self,args'>
 				<method_info nloc='58' complexity='10' token_count='607' nesting_level='1' start_line='30' end_line='97'></method_info>
 			<added_lines>39,41,54,66,67</added_lines>
 			<deleted_lines>39,41,54,66</deleted_lines>
 		</method>
 		<method name='validation' parameters='self,epoch'>
 				<method_info nloc='32' complexity='4' token_count='258' nesting_level='1' start_line='127' end_line='169'></method_info>
 			<added_lines>164,165,166,167,168,169</added_lines>
 			<deleted_lines>163,164,165,166,167,168</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>18,20,178,179,180,181,182,183,184</added_lines>
 			<deleted_lines>18,20,177,178,179,180</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='DELETE' old_name='scripts\prepare_cityscapes.py' new_name='None'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='scripts\prepare_coco.py' new_name='scripts\prepare_coco.py'>
 		<file_info nloc='55' complexity='6' token_count='324'></file_info>
 		<method name='download_coco' parameters='path,overwrite'>
 				<method_info nloc='21' complexity='3' token_count='133' nesting_level='0' start_line='19' end_line='44'></method_info>
 			<added_lines>25,26,31,32,33,34,40,41,42,43,44</added_lines>
 			<deleted_lines>23,24,36,37</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='scripts\prepare_imagenet.py'>
 		<file_info nloc='112' complexity='17' token_count='839'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='scripts\prepare_pcontext.py' new_name='scripts\prepare_pcontext.py'>
 		<file_info nloc='55' complexity='6' token_count='329'></file_info>
 		<method name='download_ade' parameters='path,overwrite'>
 				<method_info nloc='20' complexity='3' token_count='139' nesting_level='0' start_line='20' end_line='41'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>26</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='setup.py' new_name='setup.py'>
 		<file_info nloc='74' complexity='3' token_count='357'></file_info>
 		<modified_lines>
 			<added_lines>21</added_lines>
 			<deleted_lines>21</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\unit_test\test_function.py' new_name='tests\unit_test\test_function.py'>
 		<file_info nloc='188' complexity='14' token_count='2596'></file_info>
 		<method name='test_moments' parameters=''>
 				<method_info nloc='7' complexity='1' token_count='83' nesting_level='0' start_line='176' end_line='182'></method_info>
 			<added_lines>176,181,182</added_lines>
 			<deleted_lines>176,181,182</deleted_lines>
 		</method>
 		<method name='test_sum_square' parameters=''>
 				<method_info nloc='7' complexity='1' token_count='83' nesting_level='0' start_line='176' end_line='182'></method_info>
 			<added_lines>176,181,182</added_lines>
 			<deleted_lines>176,181,182</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\unit_test\test_module.py' new_name='tests\unit_test\test_module.py'>
 		<file_info nloc='156' complexity='37' token_count='1652'></file_info>
 		<method name='testSyncBN.testSyncBN._check_batchnorm_result._find_bn' parameters='module'>
 				<method_info nloc='5' complexity='3' token_count='42' nesting_level='2' start_line='49' end_line='53'></method_info>
 			<added_lines>52</added_lines>
 			<deleted_lines>52</deleted_lines>
 		</method>
 		<method name='test_Atten_Module' parameters=''>
 				<method_info nloc='6' complexity='1' token_count='84' nesting_level='0' start_line='189' end_line='194'></method_info>
 			<added_lines>189,190,191,192,193,194</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testABN.testABN._check_batchnorm_result._syncParameters' parameters='bn1,bn2'>
 				<method_info nloc='8' complexity='3' token_count='74' nesting_level='2' start_line='136' end_line='143'></method_info>
 			<added_lines>136,137,138,139,140,141,142,143</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testABN.__init__' parameters='self,num_features,eps,momentum,sync,activation,slope'>
 				<method_info nloc='2' complexity='1' token_count='33' nesting_level='2' start_line='110' end_line='111'></method_info>
 			<added_lines>110,111</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testABN.forward' parameters='self,x'>
 				<method_info nloc='13' complexity='5' token_count='111' nesting_level='2' start_line='115' end_line='128'></method_info>
 			<added_lines>115,116,117,118,119,120,121,122,123,124,125,126,127,128</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testABN.testABN._check_batchnorm_result._find_bn' parameters='module'>
 				<method_info nloc='5' complexity='3' token_count='42' nesting_level='2' start_line='131' end_line='135'></method_info>
 			<added_lines>131,132,133,134,135</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testSyncBN._check_batchnorm_result' parameters='bn1,bn2,input,is_train,cuda'>
 				<method_info nloc='30' complexity='4' token_count='268' nesting_level='1' start_line='48' end_line='94'></method_info>
 			<added_lines>52,73,74,75,76,77,78,79,80,81,82,83,85,91,92</added_lines>
 			<deleted_lines>52,73,74,76,84,85,88,90</deleted_lines>
 		</method>
 		<method name='testSyncBN' parameters=''>
 				<method_info nloc='8' complexity='2' token_count='105' nesting_level='0' start_line='47' end_line='104'></method_info>
 			<added_lines>52,73,74,75,76,77,78,79,80,81,82,83,85,91,92,95,98,101</added_lines>
 			<deleted_lines>52,73,74,76,84,85,88,90,95</deleted_lines>
 		</method>
 		<method name='testABN' parameters=''>
 				<method_info nloc='13' complexity='2' token_count='147' nesting_level='0' start_line='108' end_line='185'></method_info>
 			<added_lines>108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testABN._check_batchnorm_result' parameters='bn1,bn2,input,is_train,cuda'>
 				<method_info nloc='32' complexity='4' token_count='274' nesting_level='1' start_line='130' end_line='177'></method_info>
 			<added_lines>130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>105,106,107,186,187,188</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
