<bug_data>
<bug id='412' author='mufeili' open_date='2019-02-25T19:54:49Z' closed_time='2019-02-26T06:24:48Z'>
 	<summary>Fixing random seeds does not yield deterministic results</summary>
 	<description>
 
 Related discussion thread
 
 It has been observed by Erutan-pku, &lt;denchmark-link:https://github.com/hbsun2113&gt;@hbsun2113&lt;/denchmark-link&gt;
  , me and &lt;denchmark-link:https://github.com/yzh119&gt;@yzh119&lt;/denchmark-link&gt;
  that after fixing NumPy random seed, PyTorch random seed and  we still get different results across runs. There can be two possibilities:
 
 This is a bug.
 Some system optimization involves randomness, in which case we should provide APIs for users to fix results.
 
 	</description>
 	<comments>
 		<comment id='1' author='mufeili' date='2019-02-25T22:46:37Z'>
 		In the case of SGC, the function python/dgl/data/citation_graph.py:_encode_onehot does not necessarily return the same output from the same input, since it is enumerating a set.
 Changing from classes = set(labels) to classes = list(sorted(set(labels))) solves the problem.
 		</comment>
 		<comment id='2' author='mufeili' date='2019-02-26T01:41:35Z'>
 		&lt;denchmark-link:https://github.com/BarclayII&gt;@BarclayII&lt;/denchmark-link&gt;
  In that case we may want to add an option for our API to decide if a deterministic split is to be employed. Could you also please check GraphSAGE as mentioned by &lt;denchmark-link:https://github.com/hbsun2113&gt;@hbsun2113&lt;/denchmark-link&gt;
  ?
 		</comment>
 		<comment id='3' author='mufeili' date='2019-02-26T03:09:13Z'>
 		Works for me.
 		</comment>
 		<comment id='4' author='mufeili' date='2019-02-26T03:09:56Z'>
 		
 @BarclayII In that case we may want to add an option for our API to decide if a deterministic split is to be employed. Could you also please check GraphSAGE as mentioned by @hbsun2113 ?
 
 Also it's not related to splitting the dataset, but encoding the labels into one-hot vectors.
 		</comment>
 		<comment id='5' author='mufeili' date='2019-02-26T06:11:29Z'>
 		
 Changing from classes = set(labels) to classes = list(sorted(set(labels))) solves the problem.
 
 &lt;denchmark-link:/BarclayII&gt;BarclayII&lt;/denchmark-link&gt;
  hiÔºÅ I wonder why we need sort the ?
 		</comment>
 		<comment id='6' author='mufeili' date='2019-02-26T06:21:53Z'>
 		&lt;denchmark-link:https://github.com/hbsun2113&gt;@hbsun2113&lt;/denchmark-link&gt;
  Sets are unordered and you can get different results across tries. To sort it can solve the issue.
 		</comment>
 		<comment id='7' author='mufeili' date='2019-02-26T06:39:02Z'>
 		
 Sets are unordered and you can get different results across tries. To sort it can solve the issue.
 
 &lt;denchmark-link:https://github.com/mufeili&gt;@mufeili&lt;/denchmark-link&gt;
   Encoding label to different onehot leads to different results?
 I think we only need call  once during training.
 		</comment>
 		<comment id='8' author='mufeili' date='2019-02-26T08:00:53Z'>
 		
 @mufeili Encoding label to different onehot leads to different results?
 I think we only need call _encode_onehot once during training.
 
 Yes to both.
 Think of a linear logistic regression.  If we swap the positive and negative labels, the optimal parameters would switch their signs as well.  This implies that, given everything the same (including initial parameters) except that we permute the labels, the trajectory of parameter updates would still be different.
 Now that we have a complicated non-convex model, we know that a lot of local minima exist.  Since the trajectory of parameter updates differ if we permute the labels, it is natural that the model performance would be (slightly) different between runs.  This also naturally extends to multi-class classification.
 		</comment>
 		<comment id='9' author='mufeili' date='2019-05-15T03:10:48Z'>
 		I just find an issue worth noting. When I fix all random seeds (torch, cuda, numpy, random,python), I can get same results (examples/gcn/train.py) using CPU but different results with GPU.
 Is there any function in DGL using GPU atomic function? This would introduce troubles in reproducity. Thanks.
 		</comment>
 		<comment id='10' author='mufeili' date='2019-05-15T06:36:13Z'>
 		&lt;denchmark-link:https://github.com/michaeljyt&gt;@michaeljyt&lt;/denchmark-link&gt;
  Currently all operation in dgl are using framework operator, which you can find &lt;denchmark-link:https://github.com/dmlc/dgl/blob/master/python/dgl/backend/pytorch/tensor.py&gt;here&lt;/denchmark-link&gt;
 . Using reduce function  will call  function and it might be non-deterministic. We will introduce new kernel in 0.3, using cuSparse kernel which is deterministic. (Correct me if I'm wrong &lt;denchmark-link:https://github.com/jermainewang&gt;@jermainewang&lt;/denchmark-link&gt;
  @ylfdq1118  )
 		</comment>
 		<comment id='11' author='mufeili' date='2019-05-15T10:23:29Z'>
 		&lt;denchmark-link:https://github.com/VoVAllen&gt;@VoVAllen&lt;/denchmark-link&gt;
  Thank very much for your reply. In my experiment, non-deterministic operation affects the performance seriously. CuSparse is a good choice. From the cuda document, the CUSPARSE_COOMM_ALG2 for cusparseSpMM is deterministic. Hope the new version would come out soon.
 		</comment>
 		<comment id='12' author='mufeili' date='2019-05-17T08:17:16Z'>
 		
 @michaeljyt Currently all operation in dgl are using framework operator, which you can find here. Using reduce function fn.sum will call spmm function and it might be non-deterministic. We will introduce new kernel in 0.3, using cuSparse kernel which is deterministic. (Correct me if I'm wrong @jermainewang @ylfdq1118 )
 
 Hi VoVAllen, I just tested torch.sparse function and find it quite slow (even worse than cpu). I am not familiar with CuSparse, so you may please test its speed first.
 		</comment>
 		<comment id='13' author='mufeili' date='2019-05-17T08:33:49Z'>
 		&lt;denchmark-link:https://github.com/michaeljyt&gt;@michaeljyt&lt;/denchmark-link&gt;
  Another option is to use  to do the neighborhood sum at current stage, which is deterministic and had better performance.
 		</comment>
 		<comment id='14' author='mufeili' date='2019-05-17T08:39:28Z'>
 		
 @michaeljyt Another option is to use scatter_add to do the neighborhood sum at current stage, which is deterministic and had better performance.
 
 Unfortunately, scatter_add is not deterministic using gpu... The document of Pytorch has clarified it... Anyway, if dgl is used in supervised learning, this issue is not important. :D
 		</comment>
 	</comments>
 </bug>
<commit id='c07ae34a990b05e9aeb9756977dcf7052c424a69' author='Quan (Andy) Gan' date='2019-02-26 01:24:48-05:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\dgl\data\citation_graph.py' new_name='python\dgl\data\citation_graph.py'>
 		<file_info nloc='312' complexity='51' token_count='2808'></file_info>
 		<method name='_encode_onehot' parameters='labels'>
 				<method_info nloc='7' complexity='2' token_count='72' nesting_level='0' start_line='391' end_line='397'></method_info>
 			<added_lines>392</added_lines>
 			<deleted_lines>392</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
