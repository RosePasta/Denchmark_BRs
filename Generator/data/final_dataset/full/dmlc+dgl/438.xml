<bug_data>
<bug id='438' author='jackroos' open_date='2019-03-08T13:36:22Z' closed_time='2019-03-19T04:02:15Z'>
 	<summary>Picking/unpickling DGLGraph breaks feature set/get</summary>
 	<description>
 Hi, I am trying to emit BatchedDGLGraph in torch.utils.data.DataLoader, but it failed when num_workers &gt; 0. Could you help me solve this problem?
 The error message is as following:
 
 Traceback (most recent call last):
 File "/xxx/anaconda3/envs/xxx/lib/python3.6/multiprocessing/queues.py", line 234, in _feed
 obj = _ForkingPickler.dumps(obj)
 File "/xxx/anaconda3/envs/xxx/lib/python3.6/multiprocessing/reduction.py", line 51, in dumps
 cls(buf, protocol).dump(obj)
 TypeError: can't pickle module objects
 
 	</description>
 	<comments>
 		<comment id='1' author='jackroos' date='2019-03-08T23:23:12Z'>
 		Hi, could you paste the code here? My guess is you use "register_reduce_func" somewhere and the function/module object is not pickleable. A walkaround is directly pass the reduce func to the message passing APIs you call (e.g. update_all, send_and_recv, etc.).
 		</comment>
 		<comment id='2' author='jackroos' date='2019-03-09T03:27:05Z'>
 		
 Hi, could you paste the code here? My guess is you use "register_reduce_func" somewhere and the function/module object is not pickleable. A walkaround is directly pass the reduce func to the message passing APIs you call (e.g. update_all, send_and_recv, etc.).
 
 I do not use register_reduce_func . I just construct a DGLGraph with nodes, edges, ndata, edata in __getitem__() of my dataset, and use dgl.batch() in collate_fn of dataloader. My original code is a little complicated. I am trying to reproduce this error using toy example. But I find I can't reproduce the error now. By the way, if I remove the BatchedDGLGraph in the output of collate_fn. This error will disappear. So it must be related to the graph.
 		</comment>
 		<comment id='3' author='jackroos' date='2019-03-09T03:48:47Z'>
 		Actually, I can't even pickle graph.ndata.
 		</comment>
 		<comment id='4' author='jackroos' date='2019-03-09T16:58:12Z'>
 		I'll look into this.
 		</comment>
 		<comment id='5' author='jackroos' date='2019-03-11T11:26:56Z'>
 		It is very weird. When I debug line by line in my code, I find the graph can't be pickled just after it be created and call add_nodes. But when I try to reproduce this in following simple code:
 import dgl
 import torch
 import _pickle
 
 graph = dgl.DGLGraph()
 graph.add_nodes(5, {'type': torch.zeros(5, dtype=torch.int64)})
 _pickle.dumps(graph)
 the graph is pickled successfully. Do you have any ideas?
 		</comment>
 		<comment id='6' author='jackroos' date='2019-03-11T11:32:06Z'>
 		In addition, in my original code, after graph created by:
 &lt;denchmark-code&gt;graph = dgl.DGLGraph()
 &lt;/denchmark-code&gt;
 
 then _pickle.dumps(graph) will be None. But in the simple code of my previous comment, it's not None.
 		</comment>
 		<comment id='7' author='jackroos' date='2019-03-11T11:44:31Z'>
 		
 In addition, in my original code, after graph created by:
 graph = dgl.DGLGraph()
 
 then _pickle.dumps(graph) will be None. But in the simple code of my previous comment, it's not None.
 
 Sorry, I debug again using IPython, it's not None. Previously I used 'evaluate' in PyCharm Debugger. But in IPython, it still can't be pickled just after add_nodes.
 		</comment>
 		<comment id='8' author='jackroos' date='2019-03-12T20:49:21Z'>
 		Hi, I found the following script can reproduce the error on my side consistently. Could you help confirm?
 import networkx as nx
 import dgl
 import torch
 import pickle
 import io
 def _reconstruct_pickle(obj):
     f = io.BytesIO()
     pickle.dump(obj, f)
     f.seek(0)
     obj = pickle.load(f)
     f.close()
     return obj
 
 def test_pickling_batched_graph():
     glist = [nx.path_graph(i + 5) for i in range(5)]
     glist = [dgl.DGLGraph(g) for g in glist]
     bg = dgl.batch(glist)
     bg.ndata['x'] = torch.randn((35, 5))
     bg.edata['y'] = torch.randn((60, 3))
     new_bg = _reconstruct_pickle(bg)
 
 test_pickling_batched_graph()
 		</comment>
 		<comment id='9' author='jackroos' date='2019-03-12T20:57:27Z'>
 		In fact, the problem is torch dtype. Here is a more precise reproduction. Note that if import networkx is deleted, the code works ...
 import networkx as nx  # if this line is removed, it works !!
 import torch
 import pickle
 import io
 
 def _reconstruct_pickle(obj):
     f = io.BytesIO()
     pickle.dump(obj, f)
     f.seek(0)
     obj = pickle.load(f)
     f.close()
     return obj
 
 def test():
     x = torch.float32
     new_bg = _reconstruct_pickle(x)
 
 test()
 		</comment>
 		<comment id='10' author='jackroos' date='2019-03-13T00:55:29Z'>
 		Similar dtype pickling issues are tracked in &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/14057&gt;pytorch/pytorch#14057&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='11' author='jackroos' date='2019-03-13T10:53:22Z'>
 		Hi, &lt;denchmark-link:https://github.com/jermainewang&gt;@jermainewang&lt;/denchmark-link&gt;
 . I can reproduce your result. But after I remove all 'import networkx' in my code. It still has 'pickle' problem. I guess some other library I import have the same problem with 'networkx'. Do you know any other library of this kind?
 		</comment>
 		<comment id='12' author='jackroos' date='2019-03-13T14:49:40Z'>
 		Try this workaround. First, figure out the path of your DGL installation by:
 &gt;&gt;&gt; import dgl
 &gt;&gt;&gt; dgl.__path__
 Then, in the DGL folder, remove the if in L31 in dgl/frame.py and unindent L32-L40. The change will use our own serializer for torch.dtype. Let me know whether this fixes your issue and we will include it in the next patch release.
 		</comment>
 		<comment id='13' author='jackroos' date='2019-03-14T02:41:32Z'>
 		It does fix pickling error. But when I want to transfer data of graph to cuda by following code:
 def graph_to_cuda(graph):
     for key in graph.ndata:
         graph.ndata[key] = graph.ndata[key].cuda(non_blocking=True)
 
     for key in graph.edata:
         graph.edata[key] = graph.edata[key].cuda(non_blocking=True)
 
     return graph
 Another error happened:
 Traceback (most recent call last):
   File "xxx.py", line 63, in xxx
     graph = graph_to_cuda(graph)
   File "xxx/graph.py", line 158, in graph_to_cuda
     graph.ndata[key] = graph.ndata[key].cuda(non_blocking=True)
   File "xxx/python3.6/site-packages/dgl/view.py", line 60, in __setitem__
     self._graph.set_n_repr({key : val}, self._nodes)
   File "xxx/lib/python3.6/site-packages/dgl/graph.py", line 1591, in set_n_repr
     self._node_frame[key] = val
   File "xxx/lib/python3.6/site-packages/dgl/frame.py", line 616, in __setitem__
     self.update_data(key, val, inplace=False)
   File "xxx/lib/python3.6/site-packages/dgl/frame.py", line 643, in update_data
     self.update_column(key, val, inplace=inplace)
   File "xxx/lib/python3.6/site-packages/dgl/frame.py", line 681, in update_column
     fcol.update(self._index, data, inplace)
   File "xxx/lib/python3.6/site-packages/dgl/frame.py", line 149, in update
     self.data = F.scatter_row(self.data, idx, feats)
   File "xxx/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py", line 115, in scatter_row
     return data.index_copy(0, row_index, value)
   File "xxx/lib/python3.6/site-packages/torch/tensor.py", line 312, in index_copy
     return self.clone().index_copy_(dim, index, tensor)
 RuntimeError: Expected object of backend CPU but got backend CUDA for argument #4 'source'
 		</comment>
 		<comment id='14' author='jackroos' date='2019-03-14T02:56:41Z'>
 		Could you show how the graph is created?
 		</comment>
 		<comment id='15' author='jackroos' date='2019-03-14T06:25:24Z'>
 		It's something like this.
 def construct_graph():
     graph = dgl.DGLGraph()
     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})
     for i in range(4):
         for j in range(4):
             if i == j:
                 continue
             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),
                          'type': torch.tensor([0])}
             graph.add_edge(i, j, edge_data)
 
     super_id = graph.number_of_nodes()
     graph.add_nodes(1, {'type': torch.tensor([2], dtype=torch.int64)})
 
     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})
     for i1 in range(4):
         i = i1 + 4 + 1
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i, super_id, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(super_id, i, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i, i1, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i1, i, edge_data)
         for j1 in range(4):
             j = j1 + 4 + 1
             if i == j:
                 continue
             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),
                          'type': torch.tensor([1])}
             graph.add_edge(i, j, edge_data)
 
     # assign in-degree for each node
     assign_norm(graph)
 
     return graph
 
 def assign_norm(graph):
 
     def msg_func(edges):
         return {'msg': torch.ones_like(edges.data['type'])}
 
     def reduce_func(nodes):
         in_deg = torch.sum(nodes.mailbox['msg'], 1)
         norm = 1.0 / torch.sqrt(in_deg.float())
         return {'norm': norm}
 
     graph.update_all(msg_func, reduce_func, None)
 		</comment>
 		<comment id='16' author='jackroos' date='2019-03-15T14:11:28Z'>
 		Any ideas to solve this? &lt;denchmark-link:https://github.com/jermainewang&gt;@jermainewang&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='17' author='jackroos' date='2019-03-18T03:24:50Z'>
 		Hi &lt;denchmark-link:https://github.com/jackroos&gt;@jackroos&lt;/denchmark-link&gt;
  , sorry for the late reply! I tried your codes but cannot reproduce the error. Would you provide some environment information? Thank you.
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 
 DGL Version (e.g., 1.0):
 Backend Library &amp; Version (e.g., PyTorch 0.4.1, MXNet/Gluon 1.3):
 OS (e.g., Linux):
 How you installed DGL (conda, pip, source):
 Build command you used (if compiling from source):
 Python version:
 CUDA/cuDNN version (if applicable):
 GPU models and configuration (e.g. V100):
 Any other relevant information:
 
 		</comment>
 		<comment id='18' author='jackroos' date='2019-03-18T03:54:05Z'>
 		
 DGL: build from my forked version: https://github.com/jackroos/dgl, just modify the pickle part in frame.py.
 Backend: PyTorch 1.0.0
 OS: Linux, Ubuntu 16.04
 Build command:
 
 python setup.py install
 
 Python version: 3.6.6
 CUDA version: release 9.0, V9.0.176
 cuDNN version: 7.0
 GPU models: Tesla M40 24GB
 
 		</comment>
 		<comment id='19' author='jackroos' date='2019-03-18T03:59:49Z'>
 		Tried your repo and still cannot reproduce the error. Could you verify this is the error example?
 import torch
 import dgl
 
 def construct_graph():
     graph = dgl.DGLGraph()
     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})
     for i in range(4):
         for j in range(4):
             if i == j:
                 continue
             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),
                          'type': torch.tensor([0])}
             graph.add_edge(i, j, edge_data)
 
     super_id = graph.number_of_nodes()
     graph.add_nodes(1, {'type': torch.tensor([2], dtype=torch.int64)})
 
     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})
     for i1 in range(4):
         i = i1 + 4 + 1
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i, super_id, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(super_id, i, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i, i1, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i1, i, edge_data)
         for j1 in range(4):
             j = j1 + 4 + 1
             if i == j:
                 continue
             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),
                          'type': torch.tensor([1])}
             graph.add_edge(i, j, edge_data)
 
     # assign in-degree for each node
     assign_norm(graph)
 
     return graph
 
 def assign_norm(graph):
 
     def msg_func(edges):
         return {'msg': torch.ones_like(edges.data['type'])}
 
     def reduce_func(nodes):
         in_deg = torch.sum(nodes.mailbox['msg'], 1)
         norm = 1.0 / torch.sqrt(in_deg.float())
         return {'norm': norm}
 
     graph.update_all(msg_func, reduce_func, None)
 
 def graph_to_cuda(graph):
     for key in graph.ndata:
         graph.ndata[key] = graph.ndata[key].cuda(non_blocking=True)
 
     for key in graph.edata:
         graph.edata[key] = graph.edata[key].cuda(non_blocking=True)
 
     return graph
 
 g = construct_graph()
 g = graph_to_cuda(g)
 print(g.ndata)
 		</comment>
 		<comment id='20' author='jackroos' date='2019-03-18T04:01:28Z'>
 		Oh, could you also verify the DGL version by python -c 'import dgl; print(dgl.__version__)'?
 		</comment>
 		<comment id='21' author='jackroos' date='2019-03-18T04:38:38Z'>
 		
 python -c 'import dgl; print(dgl.version)'
 
 0.2
 		</comment>
 		<comment id='22' author='jackroos' date='2019-03-18T04:39:54Z'>
 		I can't reproduce the error based on this simple code also. I don't know if it's something related to dependency again. BTW, in the situation of num_workers=0, graph_to_cuda() can successfully transfer the graph to cuda. But now dataloader is the bottleneck of my code, so I must increase num_workers to improve my training speed.
 		</comment>
 		<comment id='23' author='jackroos' date='2019-03-18T22:36:16Z'>
 		Finally bug confirmed! The cuda call failed after pickle and unpickle:
 import torch
 import dgl
 
 def construct_graph():
     graph = dgl.DGLGraph()
     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})
     for i in range(4):
         for j in range(4):
             if i == j:
                 continue
             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),
                          'type': torch.tensor([0])}
             graph.add_edge(i, j, edge_data)
 
     super_id = graph.number_of_nodes()
     graph.add_nodes(1, {'type': torch.tensor([2], dtype=torch.int64)})
 
     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})
     for i1 in range(4):
         i = i1 + 4 + 1
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i, super_id, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(super_id, i, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i, i1, edge_data)
         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),
                      'type': torch.tensor([1])}
         graph.add_edge(i1, i, edge_data)
         for j1 in range(4):
             j = j1 + 4 + 1
             if i == j:
                 continue
             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),
                          'type': torch.tensor([1])}
             graph.add_edge(i, j, edge_data)
 
     # assign in-degree for each node
     assign_norm(graph)
 
     return graph
 
 def assign_norm(graph):
 
     def msg_func(edges):
         return {'msg': torch.ones_like(edges.data['type'])}
 
     def reduce_func(nodes):
         in_deg = torch.sum(nodes.mailbox['msg'], 1)
         norm = 1.0 / torch.sqrt(in_deg.float())
         return {'norm': norm}
 
     graph.update_all(msg_func, reduce_func, None)
 
 def graph_to_cuda(graph):
     for key in graph.ndata:
         graph.ndata[key] = graph.ndata[key].cuda(non_blocking=True)
 
     for key in graph.edata:
         graph.edata[key] = graph.edata[key].cuda(non_blocking=True)
 
     return graph
 
 import pickle
 import io
 
 def _reconstruct_pickle(obj):
     f = io.BytesIO()
     pickle.dump(obj, f)
     f.seek(0)
     obj = pickle.load(f)
     f.close()
     return obj
 
 g = construct_graph()
 gg = _reconstruct_pickle(g)
 gg = graph_to_cuda(gg)
 print(gg.ndata)
 		</comment>
 		<comment id='24' author='jackroos' date='2019-03-19T03:28:32Z'>
 		Cool! Thank you so much for your effort! Look forward to the bug fix.
 		</comment>
 		<comment id='25' author='jackroos' date='2019-03-19T03:49:07Z'>
 		Just merged the fix. The above example works on my machine. Could you pull the latest master and test it again?
 		</comment>
 		<comment id='26' author='jackroos' date='2019-03-19T03:59:16Z'>
 		It works for me now! Many thanks to you again! 🐮🍺!!!
 		</comment>
 	</comments>
 </bug>
<commit id='33b9c38389a37086b69397872e75d9fdbc58ee09' author='Minjie Wang' date='2019-03-18 23:48:20-04:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\dgl\frame.py' new_name='python\dgl\frame.py'>
 		<file_info nloc='357' complexity='111' token_count='2685'></file_info>
 		<method name='_reconstruct_scheme' parameters='cls,shape,dtype_str'>
 				<method_info nloc='3' complexity='1' token_count='24' nesting_level='1' start_line='34' end_line='36'></method_info>
 			<added_lines>34,35,36</added_lines>
 			<deleted_lines>34,35,36</deleted_lines>
 		</method>
 		<method name='__reduce__' parameters='self'>
 				<method_info nloc='3' complexity='1' token_count='27' nesting_level='1' start_line='29' end_line='31'></method_info>
 			<added_lines>29,30,31</added_lines>
 			<deleted_lines>31</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>24,32,33</added_lines>
 			<deleted_lines>7,25,26,32,33,37,38,39,40</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\dgl\utils.py' new_name='python\dgl\utils.py'>
 		<file_info nloc='276' complexity='97' token_count='2072'></file_info>
 		<method name='__getstate__' parameters='self'>
 				<method_info nloc='5' complexity='2' token_count='25' nesting_level='1' start_line='130' end_line='135'></method_info>
 			<added_lines>131,132,133,134,135</added_lines>
 			<deleted_lines>131</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\compute\test_pickle.py' new_name='tests\compute\test_pickle.py'>
 		<file_info nloc='172' complexity='20' token_count='1639'></file_info>
 		<method name='_assert_is_identical_batchedgraph' parameters='bg1,bg2'>
 				<method_info nloc='5' complexity='1' token_count='37' nesting_level='0' start_line='52' end_line='56'></method_info>
 			<added_lines>52,53,54,55,56</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_assert_is_identical_index' parameters='i1,i2'>
 				<method_info nloc='3' complexity='1' token_count='36' nesting_level='0' start_line='58' end_line='60'></method_info>
 			<added_lines>58,59,60</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_assert_is_identical' parameters='g,g2'>
 				<method_info nloc='14' complexity='3' token_count='151' nesting_level='0' start_line='14' end_line='28'></method_info>
 			<added_lines>14,15,16,17,18,19,20,21,22,23,24,25,26,27,28</added_lines>
 			<deleted_lines>24,27,28</deleted_lines>
 		</method>
 		<method name='test_pickling_batched_graph' parameters=''>
 				<method_info nloc='8' complexity='3' token_count='91' nesting_level='0' start_line='208' end_line='215'></method_info>
 			<added_lines>208,209,210,211,212,213,214,215</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_assert_is_identical_nodeflow' parameters='nf1,nf2'>
 				<method_info nloc='20' complexity='5' token_count='269' nesting_level='0' start_line='30' end_line='50'></method_info>
 			<added_lines>30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_pickling_index' parameters=''>
 				<method_info nloc='9' complexity='1' token_count='61' nesting_level='0' start_line='71' end_line='82'></method_info>
 			<added_lines>72,77,79,80,81,82</added_lines>
 			<deleted_lines>71,72,73,74,75,76,77,78,79,80,81,82</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1,12,13,29,51,57,61,216,223</added_lines>
 			<deleted_lines>63,64,65,66,67,68,69,70,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='tests\pytorch\test_pickle.py'>
 		<file_info nloc='21' complexity='4' token_count='148'></file_info>
 	</modification>
 </commit>
</bug_data>
