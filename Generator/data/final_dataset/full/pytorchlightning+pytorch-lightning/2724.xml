<bug_data>
<bug id='2724' author='jpblackburn' open_date='2020-07-27T14:32:27Z' closed_time='2020-09-14T08:05:52Z'>
 	<summary>Issues with Confusion Matrix normalization and DDP computation</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 I started using the ConfusionMatrix metric to compute normalized confusion matrices within a mult-GPU DDP environment.  However, I found the following issues:
 
 The normalization divisor is computed correctly in a row-wise manner; however, the division is applied column-wise.
 The normalization does not protect against divide by zero if there is no data in a particular row.  While this is not a usual case for a well-designed validation set, it is possible when you have a large number of unbalanced classes and limit_val_batches is small (such as when debugging).
 There is no way to specify the number of classes for the confusion matrix.  This is critical when performing DDP reduction as it is possible that the automatic computation of the number of classes could produce different answers for each process.  I encountered this possibility when using a large number of unbalanced classes such that one of the DDP processes did not see any true data or declarations of the last class, causing its number of classes to be one less than for the other processes.  This bug sometimes causes the entire training process to hang such that I needed to manually kill each DDP process.
 When computing a normalized confusion matrix with DDP reduction, the sum reduction needs to happen prior to the normalization.
 
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 As a means to reproduce these issues, I have attached two python scripts.  I had to change the extension to .txt such that they would upload the Github.  The script confusion_matrix.py exposes the first two issues with normalization within a single process.  The script confusion_matrix_ddp.py exposes the final two issues by computing the metric within a model trained using DDP over two GPUs.  For both scripts, they create a 4 class problem with 20 samples unevenly divided among the classes.  The true confusion matrix is computed within the script and printed to standard out, along with the confusion matrix computed by Pytorch Lightning.
 &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/files/4982230/confusion_matrix.py.txt&gt;confusion_matrix.py.txt&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/files/4982231/confusion_matrix_ddp.py.txt&gt;confusion_matrix_ddp.py.txt&lt;/denchmark-link&gt;
 
 Steps to reproduce the behavior:
 
 Download both scripts
 Rename them to remove the .txt extension
 ./confusion_matrix.py on a machine with at least 1 GPU.  Compare the true and test confusion matrices.
 ./confusion_matrix_ddp.py on a machine with at least 2 GPUs.  This computes the unnormalized confusion matrix.  Compare the true and test confusion matrices.
 
 WARNING: This may hang the process and require you to manually kill each process.
 
 
 ./confusion_matrix_ddp.py --normalize on a machine with at least 2 GPUs.   This computes the normalized confusion matrix.  Compare the true and test confusion matrices.
 
 WARNING: This may hang the process and require you to manually kill each process.
 
 
 
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 The computed confusion matrix will be identical to the true confusion matrix printed within the scripts provided above.
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 
 PyTorch Version (e.g., 1.0):  1.5.1=py3.8_cuda10.2.89_cudnn7.6.5_0
 OS (e.g., Linux):  CentOS
 How you installed PyTorch (conda, pip, source):  conda
 Build command you used (if compiling from source):  NA
 Python version:  3.8.3
 CUDA/cuDNN version:  Conda cudatoolkit=10.2.89=hfd86e86_1
 GPU models and configuration:  GeForce GTX 1070 and GeForce GTX 970
 
 &lt;denchmark-h:h3&gt;Solution&lt;/denchmark-h&gt;
 
 I have forked Pytorch Lightning and created fixes for all of these issues:  &lt;denchmark-link:https://github.com/jpblackburn/pytorch-lightning/tree/bugfix/confusion_matrix&gt;https://github.com/jpblackburn/pytorch-lightning/tree/bugfix/confusion_matrix&lt;/denchmark-link&gt;
 .  I am willing to turn this into a pull request.
 The solution to the first two issues did not require any major changes.  The third issue required the addition of a new argument to ConfusionMatrix for the number of classes.  It is optional and the final argument, so that the API is backwards compatible.  The fourth issue was most involved as it required modifying ConfusionMatrix to derive from Metric rather than TensorMetric.  It then uses an internal class that drives from TensorMetric.  In this manner, forward delegates the computation of the unnormalized confusion matrix and the DDP reduction to the internal class, performing the normalization itself after the DDP reduction is complete.
 I incrementally fixed the issues for easier understanding:
 
 Issues 1 and 2: 8b8b635
 Issue 3: 83927a9 and 913c1e3
 Issue 4: e3e0743
 
 &lt;denchmark-h:h4&gt;To validate the solution:&lt;/denchmark-h&gt;
 
 
 ./confusion_matrix.py on a machine with at least 1 GPU.  Compare the true and test confusion matrices.
 ./confusion_matrix_ddp.py --set-num-classes on a machine with at least 2 GPUs.  Compare the true and test confusion matrices.
 ./confusion_matrix_ddp.py --set-num-classes --normalize on a machine with at least 2 GPUs.   Compare the true and test confusion matrices.
 
 Note the addition of --set-num-classes to the DDP script.
 	</description>
 	<comments>
 		<comment id='1' author='jpblackburn' date='2020-07-27T14:33:21Z'>
 		Hi! thanks for your contribution!, great first issue!
 		</comment>
 		<comment id='2' author='jpblackburn' date='2020-09-12T09:26:27Z'>
 		Hi!
 Issue 3 already fixed at &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3450&gt;#3450&lt;/denchmark-link&gt;
  and Issue 2 under process at &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3465&gt;#3465&lt;/denchmark-link&gt;
 . I'm interested in ConfusionMatrix fix for DDP mode too, so maybe we can collaborate to apply your changes for modern version of source code?
 UPD: As I understand,  for DDP already fixed at &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2528&gt;#2528&lt;/denchmark-link&gt;
 , so there is no need to change it for 
 		</comment>
 		<comment id='3' author='jpblackburn' date='2020-09-12T10:46:12Z'>
 		&lt;denchmark-link:https://github.com/c00k1ez&gt;@c00k1ez&lt;/denchmark-link&gt;
  could you also take care of issue 1 in your &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3465&gt;#3465&lt;/denchmark-link&gt;
  PR?
 Should be a simple change from  to  in the normalization.
 		</comment>
 		<comment id='4' author='jpblackburn' date='2020-09-12T10:56:14Z'>
 		Yeah, just a moment üëç
 		</comment>
 		<comment id='5' author='jpblackburn' date='2020-09-12T11:26:04Z'>
 		Fix Issue 1  at &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3465&gt;#3465&lt;/denchmark-link&gt;
  (commit &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/commit/fd19c78879e17198282cdc29317405dde5fdf96a&gt;fd19c78&lt;/denchmark-link&gt;
 ).
 		</comment>
 		<comment id='6' author='jpblackburn' date='2020-09-14T09:31:50Z'>
 		&lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
  As I remember, &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3465&gt;#3465&lt;/denchmark-link&gt;
  do not solve issue 4
 		</comment>
 		<comment id='7' author='jpblackburn' date='2020-09-14T10:45:40Z'>
 		&lt;denchmark-link:https://github.com/c00k1ez&gt;@c00k1ez&lt;/denchmark-link&gt;
  you are correct, it was auto closed when &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3465&gt;#3465&lt;/denchmark-link&gt;
  was merged. However, I do have a fix for this, hope to do it soon (write to me on slack if you want to take over)
 		</comment>
 	</comments>
 </bug>
<commit id='a552d4a2d5056705c68f2eed570a83ee3160b3bc' author='Cookie_thief' date='2020-09-14 10:05:51+02:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\metrics\functional\classification.py' new_name='pytorch_lightning\metrics\functional\classification.py'>
 		<file_info nloc='880' complexity='30' token_count='3437'></file_info>
 		<modified_lines>
 			<added_lines>315,316,317,318,319</added_lines>
 			<deleted_lines>315</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\metrics\functional\test_classification.py' new_name='tests\metrics\functional\test_classification.py'>
 		<file_info nloc='270' complexity='24' token_count='4721'></file_info>
 		<method name='test_confusion_matrix' parameters=''>
 				<method_info nloc='19' complexity='1' token_count='406' nesting_level='0' start_line='174' end_line='198'></method_info>
 			<added_lines>190,191,192,193,194,195,196,197,198</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>199,200</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\metrics\test_classification.py' new_name='tests\metrics\test_classification.py'>
 		<file_info nloc='172' complexity='24' token_count='1850'></file_info>
 		<method name='test_confusion_matrix_norm' parameters='normalize,num_classes'>
 				<method_info nloc='8' complexity='1' token_count='74' nesting_level='0' start_line='59' end_line='68'></method_info>
 			<added_lines>59,60,61,62,63,64,65,66,67,68</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>56,57,58,69,70</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
