<bug_data>
<bug id='3974' author='nrupatunga' open_date='2020-10-08T04:31:02Z' closed_time='2020-10-08T14:20:56Z'>
 	<summary>[Bug]: Late update of Trainer `current_epoch` property for `LightningDataModule`</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 Late update of Trainer current_epoch property for LightningDataModule object.
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 The below code reproduces the issue:
 Please check for the print logs for the current_epoch number in train_dataloader.
 &lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from torchvision import transforms
 from torchvision.datasets import MNIST
 from torch.utils.data import random_split, DataLoader
 
 import pytorch_lightning as pl
 
 
 class LitModel(pl.LightningModule):
 
     def __init__(self, channels, width, height, num_classes, hidden_size=64, learning_rate=2e-4):
 
         super().__init__()
 
         # We take in input dimensions as parameters and use those to dynamically build model.
         self.channels = channels
         self.width = width
         self.height = height
         self.num_classes = num_classes
         self.hidden_size = hidden_size
         self.learning_rate = learning_rate
 
         self.model = nn.Sequential(
             nn.Flatten(),
             nn.Linear(channels * width * height, hidden_size),
             nn.ReLU(),
             nn.Dropout(0.1),
             nn.Linear(hidden_size, hidden_size),
             nn.ReLU(),
             nn.Dropout(0.1),
             nn.Linear(hidden_size, num_classes))
 
     def forward(self, x):
         x = self.model(x)
         return F.log_softmax(x, dim=1)
 
     def training_step(self, batch, batch_idx):
         x, y = batch
         logits = self(x)
         loss = F.nll_loss(logits, y)
         return loss
 
     def configure_optimizers(self):
         optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
         return optimizer
 
 
 class MNISTDataModule(pl.LightningDataModule):
 
     def __init__(self, data_dir: str = './'):
         super().__init__()
         self.data_dir = data_dir
         self.transform = transforms.Compose([
             transforms.ToTensor(),
             transforms.Normalize((0.1307,), (0.3081,))
         ])
 
         # self.dims is returned when you call dm.size()
         # Setting default dims here because we know them.
         # Could optionally be assigned dynamically in dm.setup()
         self.dims = (1, 28, 28)
         self.num_classes = 10
 
     def prepare_data(self):
         # download
         MNIST(self.data_dir, train=True, download=True)
         MNIST(self.data_dir, train=False, download=True)
 
     def setup(self, stage=None):
 
         # Assign train/val datasets for use in dataloaders
         if stage == 'fit' or stage is None:
             mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)
             self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])
 
         # Assign test dataset for use in dataloader(s)
         if stage == 'test' or stage is None:
             self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)
 
     def train_dataloader(self):
         print('\n----------------------------')
         print(f'Current epoch: {self.trainer.current_epoch}')
         print('----------------------------')
         if self.trainer.current_epoch &gt; 2:
             return DataLoader(self.mnist_train, batch_size=32)
         else:
             return DataLoader(self.mnist_train, batch_size=32)
 
 
 # Init DataModule
 dm = MNISTDataModule()
 # Init model from datamodule's attributes
 model = LitModel(*dm.size(), dm.num_classes)
 # Init trainer
 trainer = pl.Trainer(max_epochs=5, progress_bar_refresh_rate=20, gpus=1, reload_dataloaders_every_epoch=True)
 # Pass the datamodule as arg to trainer.fit to override model hooks :)
 trainer.fit(model, dm)
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h4&gt;logs&lt;/denchmark-h&gt;
 
 Note: current_epoch is 0 two time, which is indeed due to the late update of this property
 &lt;denchmark-code&gt;----------------------------
 Current epoch: 0
 ----------------------------
 /home/nthere/2020/pytorch-lightning/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
   warnings.warn(*args, **kwargs)
 Epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1700/1719 [00:10&lt;00:00, 157.72it/s, loss=0.284, v_num=16]
 ----------------------------
 Current epoch: 0
 ----------------------------
 Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1700/1719 [00:10&lt;00:00, 164.23it/s, loss=0.200, v_num=16]
 ----------------------------
 Current epoch: 1
 ----------------------------
 Epoch 2:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1700/1719 [00:10&lt;00:00, 164.02it/s, loss=0.168, v_num=16]
 ----------------------------
 Current epoch: 2
 ----------------------------
 Epoch 3:  10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                                                                                                | 180/1719 [00:01&lt;00:09, 163.17it/s, loss=0.185, v_num=16]
 ^C/home/nthere/2020/pytorch-lightning/pytorch_lightning/utilities/distributed.py:45: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
   warnings.warn(*args, **kwargs)
 Epoch 3:  10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                                                                                                | 180/1719 [00:01&lt;00:10, 150.43it/s, loss=0.185, v_num=16]
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 current_epoch should be updated and reflect the right epoch number for the LightningDataModule
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 Please copy and paste the output from our
 &lt;denchmark-link:https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py&gt;environment collection script&lt;/denchmark-link&gt;
 
 (or fill out the checklist below manually).
 You can get the script and run it with:
 &lt;denchmark-code&gt;* CUDA:
         - GPU:
                 - GeForce GTX 960
         - available:         True
         - version:           10.1
 * Packages:
         - numpy:             1.18.5
         - pyTorch_debug:     False
         - pyTorch_version:   1.5.0+cu101
         - pytorch-lightning: 0.10.0
         - tqdm:              4.47.0
 * System:
         - OS:                Linux
         - architecture:
                 - 64bit
                 - ELF
         - processor:         x86_64
         - python:            3.8.3
         - version:           #113~16.04.1-Ubuntu SMP Fri Jul 10 04:37:08 UTC 2020
 
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='nrupatunga' date='2020-10-08T04:31:48Z'>
 		Hi! thanks for your contribution!, great first issue!
 		</comment>
 		<comment id='2' author='nrupatunga' date='2020-10-08T05:08:41Z'>
 		great catch &lt;denchmark-link:https://github.com/nrupatunga&gt;@nrupatunga&lt;/denchmark-link&gt;
  !
 
 this bug happens specifically when using the flag reload_dataloaders_every_epoch
 this is because reload_dataloaders_every_epoch  happens before train_epoch_start
 trainer.current_epoch is updated in train_epoch_start, so the epoch state when used inside of train_dataloader is stale
 
 We could:
 
 set trainer.current_epoch directly in the trainer at the beginning of the loop
 Move reload_dataloaders_every_epoch into train_epoch_start
 Or both?
 
 What do you think &lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/awaelchli&gt;@awaelchli&lt;/denchmark-link&gt;
  ?
 		</comment>
 		<comment id='3' author='nrupatunga' date='2020-10-08T05:11:31Z'>
 		Suggested changes in this PR
 &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3975&gt;#3975&lt;/denchmark-link&gt;
 
 Please review let me know if there is a better way, Thank you
 		</comment>
 	</comments>
 </bug>
<commit id='fcfa5874923000a4b391c88b6488e065aee4d671' author='Nrupatunga' date='2020-10-08 10:20:55-04:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.03125'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>23</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\trainer.py' new_name='pytorch_lightning\trainer\trainer.py'>
 		<file_info nloc='584' complexity='59' token_count='2872'></file_info>
 		<method name='train' parameters='self'>
 				<method_info nloc='37' complexity='11' token_count='218' nesting_level='1' start_line='438' end_line='503'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>456,457,458,459</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_loop.py' new_name='pytorch_lightning\trainer\training_loop.py'>
 		<file_info nloc='479' complexity='147' token_count='3754'></file_info>
 		<method name='on_train_epoch_start' parameters='self,epoch'>
 				<method_info nloc='17' complexity='3' token_count='120' nesting_level='1' start_line='208' end_line='239'></method_info>
 			<added_lines>209,210,211,212,215,216,217,218</added_lines>
 			<deleted_lines>217,218,219</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\core\test_datamodules.py' new_name='tests\core\test_datamodules.py'>
 		<file_info nloc='300' complexity='31' token_count='1900'></file_info>
 		<method name='test_dm_reload_dataloaders_every_epoch' parameters='tmpdir'>
 				<method_info nloc='16' complexity='1' token_count='78' nesting_level='0' start_line='424' end_line='444'></method_info>
 			<added_lines>424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='prepare_data' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='19' nesting_level='1' start_line='406' end_line='407'></method_info>
 			<added_lines>406,407</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='setup' parameters='self,None'>
 				<method_info nloc='6' complexity='1' token_count='69' nesting_level='1' start_line='409' end_line='415'></method_info>
 			<added_lines>409,410,411,412,413,414,415</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,str'>
 				<method_info nloc='4' complexity='1' token_count='29' nesting_level='1' start_line='401' end_line='404'></method_info>
 			<added_lines>401,402,403,404</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='train_dataloader' parameters='self'>
 				<method_info nloc='4' complexity='1' token_count='39' nesting_level='1' start_line='417' end_line='421'></method_info>
 			<added_lines>417,418,419,420,421</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>4,8,12,397,398,399,400,405,408,416,422,423</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
