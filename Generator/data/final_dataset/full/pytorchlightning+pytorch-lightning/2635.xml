<bug_data>
<bug id='2635' author='ibeltagy' open_date='2020-07-17T19:38:29Z' closed_time='2020-07-28T20:29:47Z'>
 	<summary>Loss value in the progress bar is wrong when `accumulate_grad_batches &amp;gt; 1`</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 The loss value reported in the progress bar is the_correct_loss_value / accumulate_grad_batches, so this value is wrong when accumulate_grad_batches &gt; 1.
 This is happening because &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/0.8.5/pytorch_lightning/trainer/training_loop.py#L799&gt;here&lt;/denchmark-link&gt;
  the loss is divided by , then &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/0.8.5/pytorch_lightning/trainer/training_loop.py#L663&gt;here&lt;/denchmark-link&gt;
  the running loss is the  of these losses.
 To fix this, either remove the first line (no division by accumulate_grad_batches) or replace mean with sum in the second line.
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 
 Train any model with accumulate_grad_batches=1 and note the loss value reported in the progress bar
 Train the same model with accumulate_grad_batches=2 and half the batch size,  now the loss value in the progress bar will be half the value from step 1.
 
 &lt;denchmark-h:h3&gt;Expected Behaviour&lt;/denchmark-h&gt;
 
 The loss in steps (1) and (2) should be the same
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 pytorch-lightning==v0.8.5
 	</description>
 	<comments>
 		<comment id='1' author='ibeltagy' date='2020-07-19T20:02:40Z'>
 		duplicate of &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2569&gt;#2569&lt;/denchmark-link&gt;
 ?
 		</comment>
 	</comments>
 </bug>
<commit id='c047676fae8cdbfe77189c218cfde73d863acc91' author='Iz Beltagy' date='2020-07-28 16:29:46-04:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_loop.py' new_name='pytorch_lightning\trainer\training_loop.py'>
 		<file_info nloc='727' complexity='189' token_count='3856'></file_info>
 		<method name='run_training_batch' parameters='self,batch,batch_idx'>
 				<method_info nloc='70' complexity='22' token_count='501' nesting_level='1' start_line='677' end_line='801'></method_info>
 			<added_lines>775</added_lines>
 			<deleted_lines>775</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
