<bug_data>
<bug id='4857' author='YannDubs' open_date='2020-11-25T16:44:23Z' closed_time='2020-12-06T13:01:44Z'>
 	<summary>Logging not working in `on_train_batch_end` of a callback.</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 logging in on_train_batch_end of a callback doesn't work but for on_train_validation_batch_end it does.
 I.e. below only eval will be logged not train
 class TestCallback(Callback):
   
     def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):
         pl_module.log("train", 0)
 
     def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):
         pl_module.log("eval", 0)
 reproduce:  &lt;denchmark-link:https://colab.research.google.com/drive/1Utnf7uqQTPid68_baS9yMdApZaoMP6Lq?usp=sharing&gt;https://colab.research.google.com/drive/1Utnf7uqQTPid68_baS9yMdApZaoMP6Lq?usp=sharing&lt;/denchmark-link&gt;
 
 context: I found that error because logging of training in pl_bolts.callbacks.ssl_online.SSLOnlineEvaluator does not work.
 	</description>
 	<comments>
 		<comment id='1' author='YannDubs' date='2020-11-25T16:45:05Z'>
 		Hi! thanks for your contribution!, great first issue!
 		</comment>
 		<comment id='2' author='YannDubs' date='2020-11-25T18:25:17Z'>
 		can you try with master??
 		</comment>
 		<comment id='3' author='YannDubs' date='2020-11-25T19:45:56Z'>
 		works! thanks
 		</comment>
 		<comment id='4' author='YannDubs' date='2020-12-03T00:44:22Z'>
 		&lt;denchmark-link:https://github.com/rohitgr7&gt;@rohitgr7&lt;/denchmark-link&gt;
  now it doesn't work even on master (see  &lt;denchmark-link:https://colab.research.google.com/drive/1Utnf7uqQTPid68_baS9yMdApZaoMP6Lq?usp=sharing&gt;https://colab.research.google.com/drive/1Utnf7uqQTPid68_baS9yMdApZaoMP6Lq?usp=sharing&lt;/denchmark-link&gt;
  )
 		</comment>
 		<comment id='5' author='YannDubs' date='2020-12-03T14:54:16Z'>
 		&lt;denchmark-link:https://github.com/tchaton&gt;@tchaton&lt;/denchmark-link&gt;
 , mind check this?
 		</comment>
 		<comment id='6' author='YannDubs' date='2020-12-04T08:30:07Z'>
 		Hey &lt;denchmark-link:https://github.com/YannDubs&gt;@YannDubs&lt;/denchmark-link&gt;
 ,
 Yes, I deactivated to optimize logging.
 &lt;denchmark-code&gt;******************************
 Logging from a LightningModule
 ******************************
 
 Lightning offers automatic log functionalities for logging scalars, or manual logging for anything else.
 
 Automatic logging
 =================
 Use the :func:`~~pytorch_lightning.core.lightning.LightningModule.log` method to log from :ref:`lightning_module` and :ref:`callbacks`
 Currently, it is supported in the following functions:
     - training_step
     - evaluation_step
     - test_step
     - training_epoch_end
     - validation_epoch_end
     - test_epoch_end
     - on_train_epoch_end
     - on_validation_epoch_end
     - on_validation_end
     - on_test_epoch_end
     - on_test_end
     - on_epoch_end
 &lt;/denchmark-code&gt;
 
 However, I have an idea for an Hybrid version which might work out.
 I will update you when finished.
 		</comment>
 	</comments>
 </bug>
<commit id='2e838e6dd8803f40da3a1d4111669bd69ae7dd0f' author='chaton' date='2020-12-06 13:01:43+00:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='docs\source\logging.rst' new_name='docs\source\logging.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>9,60,62,63,64,100,101,102,152,153,246</added_lines>
 			<deleted_lines>9,60,62,147,148,241</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\connectors\logger_connector\epoch_result_store.py' new_name='pytorch_lightning\trainer\connectors\logger_connector\epoch_result_store.py'>
 		<file_info nloc='348' complexity='87' token_count='2301'></file_info>
 		<method name='update_logger_connector' parameters='self'>
 				<method_info nloc='37' complexity='4' token_count='198' nesting_level='1' start_line='348' end_line='400'></method_info>
 			<added_lines>360,361,362,368,399,400</added_lines>
 			<deleted_lines>358,367,369</deleted_lines>
 		</method>
 		<method name='cache_result' parameters='self'>
 				<method_info nloc='25' complexity='6' token_count='172' nesting_level='1' start_line='307' end_line='346'></method_info>
 			<added_lines>342,343,344</added_lines>
 			<deleted_lines>342</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>401</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py' new_name='pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py'>
 		<file_info nloc='367' complexity='107' token_count='2732'></file_info>
 		<method name='log_train_step_metrics' parameters='self,batch_output'>
 				<method_info nloc='9' complexity='6' token_count='78' nesting_level='1' start_line='589' end_line='599'></method_info>
 			<added_lines>590,595,596,597,598,599</added_lines>
 			<deleted_lines>593,595,596,597</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\evaluation_loop.py' new_name='pytorch_lightning\trainer\evaluation_loop.py'>
 		<file_info nloc='244' complexity='86' token_count='1875'></file_info>
 		<method name='__log_result_step_metrics' parameters='self,step_log_metrics,step_pbar_metrics,batch_idx'>
 				<method_info nloc='12' complexity='4' token_count='106' nesting_level='1' start_line='348' end_line='364'></method_info>
 			<added_lines>349,350</added_lines>
 			<deleted_lines>349,350,351,352</deleted_lines>
 		</method>
 		<method name='on_evaluation_end' parameters='self,args,kwargs'>
 				<method_info nloc='5' complexity='2' token_count='46' nesting_level='1' start_line='107' end_line='111'></method_info>
 			<added_lines>109,111</added_lines>
 			<deleted_lines>109,111</deleted_lines>
 		</method>
 		<method name='on_evaluation_epoch_end' parameters='self,args,kwargs'>
 				<method_info nloc='5' complexity='2' token_count='46' nesting_level='1' start_line='329' end_line='334'></method_info>
 			<added_lines>332,334</added_lines>
 			<deleted_lines>332,334</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\trainer.py' new_name='pytorch_lightning\trainer\trainer.py'>
 		<file_info nloc='658' complexity='75' token_count='3140'></file_info>
 		<method name='_reset_result_and_set_hook_fx_name' parameters='self,hook_name'>
 				<method_info nloc='8' complexity='3' token_count='41' nesting_level='1' start_line='857' end_line='865'></method_info>
 			<added_lines>858,859</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='call_hook' parameters='self,hook_name,args,capture,kwargs'>
 				<method_info nloc='18' complexity='6' token_count='136' nesting_level='1' start_line='871' end_line='899'></method_info>
 			<added_lines>873,875,898</added_lines>
 			<deleted_lines>871,873,874,897</deleted_lines>
 		</method>
 		<method name='call_hook' parameters='self,hook_name,args,kwargs'>
 				<method_info nloc='17' complexity='5' token_count='132' nesting_level='1' start_line='873' end_line='900'></method_info>
 			<added_lines>873,875,898</added_lines>
 			<deleted_lines>873,874,897</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_loop.py' new_name='pytorch_lightning\trainer\training_loop.py'>
 		<file_info nloc='553' complexity='167' token_count='4175'></file_info>
 		<method name='run_on_epoch_end_hook' parameters='self,epoch_output'>
 				<method_info nloc='4' complexity='1' token_count='34' nesting_level='1' start_line='824' end_line='829'></method_info>
 			<added_lines>828,829</added_lines>
 			<deleted_lines>828,829</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_deprecated.py' new_name='tests\test_deprecated.py'>
 		<file_info nloc='88' complexity='18' token_count='728'></file_info>
 		<modified_lines>
 			<added_lines>1,2,3,4,5,6,7,8,9,10,11,12,13</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\trainer\logging_tests\test_eval_loop_logging_1_0.py' new_name='tests\trainer\logging_tests\test_eval_loop_logging_1_0.py'>
 		<file_info nloc='643' complexity='100' token_count='4862'></file_info>
 		<method name='test_log_works_in_test_callback.on_test_batch_end' parameters='self,trainer,pl_module,outputs,batch,batch_idx,dataloader_idx'>
 				<method_info nloc='4' complexity='1' token_count='50' nesting_level='2' start_line='673' end_line='680'></method_info>
 			<added_lines>673,674</added_lines>
 			<deleted_lines>678,679,680</deleted_lines>
 		</method>
 		<method name='test_log_works_in_test_callback' parameters='tmpdir'>
 				<method_info nloc='104' complexity='18' token_count='675' nesting_level='0' start_line='602' end_line='782'></method_info>
 			<added_lines>673,674,722,726</added_lines>
 			<deleted_lines>665,678,679,680,681,682,693,731,735,736,737</deleted_lines>
 		</method>
 		<method name='test_log_works_in_val_callback' parameters='tmpdir'>
 				<method_info nloc='100' complexity='16' token_count='591' nesting_level='0' start_line='427' end_line='598'></method_info>
 			<added_lines>487,495,543,547</added_lines>
 			<deleted_lines>475,476,513,514,544,546,550,553</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\trainer\logging_tests\test_train_loop_logging_1_0.py' new_name='tests\trainer\logging_tests\test_train_loop_logging_1_0.py'>
 		<file_info nloc='549' complexity='77' token_count='4246'></file_info>
 		<method name='test_log_works_in_train_callback' parameters='tmpdir'>
 				<method_info nloc='94' complexity='17' token_count='632' nesting_level='0' start_line='504' end_line='674'></method_info>
 			<added_lines>561</added_lines>
 			<deleted_lines>561,574,575,576,577,578,579,580,581,582,595,632,636,637,641,642</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
