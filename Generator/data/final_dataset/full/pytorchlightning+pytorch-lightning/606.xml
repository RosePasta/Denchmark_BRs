<bug_data>
<bug id='606' author='awaelchli' open_date='2019-12-08T00:30:41Z' closed_time='2019-12-09T18:32:50Z'>
 	<summary>Early Stopping kicks in at min_epochs + 2 instead of min_epochs</summary>
 	<description>
 &lt;denchmark-h:h3&gt;Describe the bug&lt;/denchmark-h&gt;
 
 I was working on a fix for &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/524&gt;#524&lt;/denchmark-link&gt;
  and found that early stopping starts to kick in at epoch 3 despite min_epochs = 1.
 &lt;denchmark-h:h4&gt;To Reproduce&lt;/denchmark-h&gt;
 
 run basic_examples/gpu_template.py and log the callback calls every epoch.
 &lt;denchmark-h:h4&gt;Expected behavior&lt;/denchmark-h&gt;
 
 When setting min_epochs=n (counting from 1), we should evaluate early stopping at the end of epoch n.
 &lt;denchmark-h:h4&gt;Proposed fix:&lt;/denchmark-h&gt;
 
 I propose to change &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/58cc6e13b9999161a526b83063c983750e6553b1/pytorch_lightning/trainer/training_loop.py#L322&gt;this&lt;/denchmark-link&gt;
  line in the training loop:
 
 to
 
 
 
 Why the "-1"? The epoch variable in the training loop starts at 0, but the Trainer argument min_epochs starts counting at 1.
 
 
 Why the "&gt;="? The early stop check is done at the end of each epoch, hence the epoch counter will be = to min_epochs after min_epochs have passed.
 
 
 Desktop (please complete the following information):
 
 OS: Linux
 Version: master
 
 	</description>
 	<comments>
 		<comment id='1' author='awaelchli' date='2019-12-09T12:49:31Z'>
 		submit the PR for this?
 		</comment>
 		<comment id='2' author='awaelchli' date='2019-12-09T13:20:42Z'>
 		yep. was waiting for an approval.
 		</comment>
 	</comments>
 </bug>
<commit id='e2ee4ddbdb75a91132394208fabc8c62ca39f3e9' author='Adrian WÃ¤lchli' date='2019-12-09 10:32:49-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_loop.py' new_name='pytorch_lightning\trainer\training_loop.py'>
 		<file_info nloc='414' complexity='79' token_count='1694'></file_info>
 		<method name='train' parameters='self'>
 				<method_info nloc='49' complexity='19' token_count='369' nesting_level='1' start_line='282' end_line='360'></method_info>
 			<added_lines>345</added_lines>
 			<deleted_lines>342</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>53,54,55</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
