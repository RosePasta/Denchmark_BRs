<bug_data>
<bug id='3032' author='AAnoosheh' open_date='2020-08-18T07:32:29Z' closed_time='2020-08-20T10:27:49Z'>
 	<summary>Epoch counting is one-off in multiple instances</summary>
 	<description>
 üêõ Bug
 Two issues occur:
 
 The final epoch does not save a checkpoint during training.
 Resuming from a checkpoint N will start the epochs at N+2.
 
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 
 Final checkpoint should save a .ckpt file, as usual.
 Should resume from epoch N+1.
 
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;* CUDA:
 	- GPU:
 		- Tesla V100-DGXS-16GB
 		- Tesla V100-DGXS-16GB
 		- Tesla V100-DGXS-16GB
 		- Tesla V100-DGXS-16GB
 	- available:         True
 	- version:           10.1
 * Packages:
 	- numpy:             1.18.1
 	- pyTorch_debug:     False
 	- pyTorch_version:   1.6.0
 	- pytorch-lightning: 0.9.0rc12
 	- tensorboard:       2.2.1
 	- tqdm:              4.46.1
 * System:
 	- OS:                Linux
 	- architecture:
 		- 64bit
 		-
 	- processor:         x86_64
 	- python:            3.7.7
 	- version:           #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='AAnoosheh' date='2020-08-18T18:04:58Z'>
 		&lt;denchmark-link:https://github.com/AAnoosheh&gt;@AAnoosheh&lt;/denchmark-link&gt;
  Honestly I do not understand how the PR you linked relates to the bug your report. Did you mean to link another issue?
 
 The final epoch does not save a checkpoint during training.
 
 I don't experience this. The epoch number is 0-indexed, and by default it only saves best checkpoints. Could one of these reasons be why you may think this is a bug?
 How can I reproduce the second issue?
 		</comment>
 		<comment id='2' author='AAnoosheh' date='2020-08-18T18:22:15Z'>
 		Sorry I should have clarified I use the following to save every epoch:
 pl.callbacks.ModelCheckpoint(save_top_k=-1, verbose=True)
 The second is done via Trainer(resume_from_checkpoint=some_ckpt_file)
 I assume some change was made to move epochs to 0-index, when previously they were 1-indexed, and there's a mismatch now.
 EDIT:
 I also have no idea how a PR was linked in my comment. Those numbers came out of nowhere from the auto-generated issue template.
 		</comment>
 		<comment id='3' author='AAnoosheh' date='2020-08-19T14:35:57Z'>
 		&lt;denchmark-link:https://github.com/AAnoosheh&gt;@AAnoosheh&lt;/denchmark-link&gt;
  so when you run  all the checkpoints are saved, however we do not save the last one as 'last.ckpt'. Also, the checkpoints are numbered from 0, so if you run for 4 epochs, the last checkpoint saved will be 'epoch=3.ckpt' and when you resume, it resumes from the expected 5th epoch.
 Updating tests and code for this
 		</comment>
 	</comments>
 </bug>
<commit id='10150fccb001867472e3cbde298591999e321278' author='Ananya Harsh Jha' date='2020-08-20 06:27:48-04:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\callbacks\progress.py' new_name='pytorch_lightning\callbacks\progress.py'>
 		<file_info nloc='300' complexity='56' token_count='1361'></file_info>
 		<method name='on_epoch_start' parameters='self,trainer,pl_module'>
 				<method_info nloc='11' complexity='4' token_count='84' nesting_level='1' start_line='322' end_line='333'></method_info>
 			<added_lines>333</added_lines>
 			<deleted_lines>333</deleted_lines>
 		</method>
 		<method name='total_val_batches' parameters='self'>
 				<method_info nloc='11' complexity='3' token_count='52' nesting_level='1' start_line='108' end_line='118'></method_info>
 			<added_lines>116</added_lines>
 			<deleted_lines>116</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
