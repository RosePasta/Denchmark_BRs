<bug_data>
<bug id='2742' author='remisphere' open_date='2020-07-28T15:54:40Z' closed_time='2020-08-02T00:17:58Z'>
 	<summary>[DataModule] `prepare_data()` and `setup()` not called</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 It seems that when using DataModule to separate training logic and data loading,
 of the &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/datamodules.html#methods&gt;five methods&lt;/denchmark-link&gt;
  that should be called that are
 , , ,  and ,
 only the last three are actually used, witch is problematic since the datasets used by the data-loaders should be assigned in the .
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Steps to reproduce the behavior:
 Run this:
 &lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;
 
 import torch
 from pytorch_lightning import LightningDataModule
 from pytorch_lightning.core.lightning import LightningModule
 from pytorch_lightning.trainer import Trainer
 from torch.nn import L1Loss, Linear
 from torch.optim import SGD
 from torch.utils.data import DataLoader
 
 
 class MyDataModule(LightningDataModule):
 
     def __init__(self):
         super().__init__()
 
     def prepare_data(self):
         print('in prepare_data, '
               'this should be called before train_dataloader() but is not.')
 
     def setup(self, stage):
         print('in setup, '
               'this should be called before train_dataloader() but is not.')
         self.train_dataset = 'whatever'
 
     def train_dataloader(self):
         print('in train_dataloader')
         return DataLoader(self.train_dataset)
 
 
 class MyLightningModule(LightningModule):
 
     def __init__(self):
         super().__init__()
         self.layer = Linear(1, 1)
         self.loss_function = L1Loss()
 
     def forward(self, x):
         return self.layer(x)
 
     def configure_optimizers(self):
         return SGD(self.parameters(), lr=0.01)
 
     def training_step(self, batch, batch_idx):
         print("you won't even get here")
         raise NotImplementedError
 
 
 data_module = MyDataModule()
 model = MyLightningModule()
 trainer = Trainer(gpus=1)
 trainer.fit(model, data_module)
 this gives AttributeError: 'MyDataModule' object has no attribute 'train_dataset'.
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 When entering train_dataloader(), prepare_data() and setup() should already have been executed, and thus the train_dataset attribute should exist.
 &lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;
 
 IMHO, it comes from &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/590e7fb1fd1729b732128b3b96c919ebdf524077/pytorch_lightning/trainer/trainer.py#L1161-L1167&gt;here&lt;/denchmark-link&gt;
 
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 
 CUDA:
 
 GPU:
 
 GeForce RTX 2080 Ti
 GeForce RTX 2080 Ti
 
 
 available:         True
 version:           10.1
 
 
 Packages:
 
 numpy:             1.19.1
 pyTorch_debug:     False
 pyTorch_version:   1.5.1+cu101
 pytorch-lightning: 0.9.0rc2
 tensorboard:       2.3.0
 tqdm:              4.48.0
 
 
 System:
 
 OS:                Linux
 architecture:
 
 64bit
 
 
 processor:         x86_64
 python:            3.7.6
 version:           #41-Ubuntu SMP Tue Dec 3 00:27:35 UTC 2019
 
 
 
 	</description>
 	<comments>
 		<comment id='1' author='remisphere' date='2020-07-28T16:18:17Z'>
 		
 
 you're not specifying the datamodule kwarg in trainer.fit() - your last line should look like this: trainer.fit(model, datamodule=data_module)
 
 
 In this first iteration of LightningDataModule, you have to call setup and prepare_data manually for the datamodule instance. We have it set up this way so if you don't want to use Lightning, you can use your datamodule's loaders with pure Pytorch. I thought of having them called implicitly in the PR, but ended up landing on this for now. I'm not sure if users would always want these to run implicitly.
 
 
 TL;DR: you can update your code to look like this:
 # Init a datamodule
 dm = MyDataModule()
 
 # Manually call prepare_data and setup. You could put this at end of __init__ if you want
 dm.prepare_data()
 dm.setup()
 
 model = MyLightningModule()
 trainer = Trainer(gpus=1)
 trainer.fit(model, datamodule=dm)
 &lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;
 
 That being said, we're open to any ideas on making this more intuitive, so feel free to throw out some alternatives. üòÑ
 		</comment>
 		<comment id='2' author='remisphere' date='2020-07-28T16:39:39Z'>
 		
 
 is not true in 0.9.0rc2: a data module as second positional argument is taken care of here.
 
 
 I don't have a global enough view to know what other users might want, so if it is a feature i'm fine with it.
 I just saw that the manual call was in the docs, my bad for not looking far enough.
 
 
 Anyway thank you for the clear answer ^^
 		</comment>
 		<comment id='3' author='remisphere' date='2020-07-29T19:54:45Z'>
 		&lt;denchmark-link:https://github.com/remisphere&gt;@remisphere&lt;/denchmark-link&gt;
  I totally didn't notice! You were completely right on the dm arg. things move fast haha.
 Reopening actually, as I think your intended use is more user friendly.
 		</comment>
 	</comments>
 </bug>
<commit id='036bcea4992865e8a82a5939f0d374530e17b778' author='Nathan Raw' date='2020-08-01 20:17:57-04:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='docs\source\datamodules.rst' new_name='docs\source\datamodules.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,93,94,95,96,97,98,99,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,135,140,141,142,143,144,145,146,147,148,149,150,151,167,168,169,170,171,172,173,174,175,176,177,178,184,185,186,187,188,189,190,191,192,193,194,195,201,219,224,225,243,248,249</added_lines>
 			<deleted_lines>15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,63,64,65,66,67,80,81,82,83,84,85,86,87,88,89,90,91,99,100,101,102,103,104,105,106,122,123,124,125,126,127,128,129,135,136,137,138,139,140,141,142,165,170,187</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\accelerator_backends\cpu_backend.py' new_name='pytorch_lightning\accelerator_backends\cpu_backend.py'>
 		<file_info nloc='15' complexity='4' token_count='110'></file_info>
 		<method name='setup' parameters='self,model'>
 				<method_info nloc='8' complexity='2' token_count='62' nesting_level='1' start_line='23' end_line='36'></method_info>
 			<added_lines>29</added_lines>
 			<deleted_lines>29,30,31</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\accelerator_backends\ddp_spawn_backend.py' new_name='pytorch_lightning\accelerator_backends\ddp_spawn_backend.py'>
 		<file_info nloc='85' complexity='21' token_count='733'></file_info>
 		<method name='ddp_train' parameters='self,process_idx,mp_queue,model,is_master,proc_offset'>
 				<method_info nloc='54' complexity='15' token_count='515' nesting_level='1' start_line='63' end_line='171'></method_info>
 			<added_lines>109</added_lines>
 			<deleted_lines>109,110,111</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\accelerator_backends\dp_backend.py' new_name='pytorch_lightning\accelerator_backends\dp_backend.py'>
 		<file_info nloc='74' complexity='21' token_count='515'></file_info>
 		<method name='setup' parameters='self,model'>
 				<method_info nloc='12' complexity='2' token_count='97' nesting_level='1' start_line='34' end_line='58'></method_info>
 			<added_lines>36</added_lines>
 			<deleted_lines>36,37,38</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\accelerator_backends\gpu_backend.py' new_name='pytorch_lightning\accelerator_backends\gpu_backend.py'>
 		<file_info nloc='30' complexity='8' token_count='229'></file_info>
 		<method name='setup' parameters='self,model'>
 				<method_info nloc='11' complexity='5' token_count='103' nesting_level='1' start_line='31' end_line='49'></method_info>
 			<added_lines>34</added_lines>
 			<deleted_lines>34,35,36</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\accelerator_backends\tpu_backend.py' new_name='pytorch_lightning\accelerator_backends\tpu_backend.py'>
 		<file_info nloc='88' complexity='20' token_count='622'></file_info>
 		<method name='tpu_train_in_process' parameters='self,int,LightningModule,trainer,mp_queue'>
 				<method_info nloc='8' complexity='2' token_count='71' nesting_level='1' start_line='99' end_line='118'></method_info>
 			<added_lines>105,106</added_lines>
 			<deleted_lines>105,106,107</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\datamodule.py' new_name='pytorch_lightning\core\datamodule.py'>
 		<file_info nloc='237' complexity='48' token_count='965'></file_info>
 		<method name='setup' parameters='self,None'>
 				<method_info nloc='1' complexity='1' token_count='15' nesting_level='1' start_line='237' end_line='247'></method_info>
 			<added_lines>237,244</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='has_prepared_data' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='1' start_line='189' end_line='195'></method_info>
 			<added_lines>189,190,191,192,193,194,195</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='setup' parameters='self,args,kwargs'>
 				<method_info nloc='1' complexity='1' token_count='12' nesting_level='1' start_line='158' end_line='168'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>158,165</deleted_lines>
 		</method>
 		<method name='has_setup_fit' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='1' start_line='198' end_line='204'></method_info>
 			<added_lines>198,199,200,201,202,203,204</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='track_data_hook_calls.wrapped_fn' parameters='args,kwargs'>
 				<method_info nloc='11' complexity='8' token_count='93' nesting_level='1' start_line='62' end_line='84'></method_info>
 			<added_lines>62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='has_setup_test' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='1' start_line='207' end_line='213'></method_info>
 			<added_lines>207,208,209,210,211,212,213</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__call__' parameters='cls,args,kwargs'>
 				<method_info nloc='5' complexity='1' token_count='51' nesting_level='1' start_line='27' end_line='43'></method_info>
 			<added_lines>32,35,36,37,38</added_lines>
 			<deleted_lines>33,34</deleted_lines>
 		</method>
 		<method name='track_data_hook_calls' parameters='fn'>
 				<method_info nloc='4' complexity='1' token_count='17' nesting_level='0' start_line='46' end_line='86'></method_info>
 			<added_lines>46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>15,19,87,88,140,141,142,143,144,188,196,197,205,206,214</added_lines>
 			<deleted_lines>18</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\distrib_data_parallel.py' new_name='pytorch_lightning\trainer\distrib_data_parallel.py'>
 		<file_info nloc='484' complexity='116' token_count='2405'></file_info>
 		<method name='ddp_train' parameters='self,process_idx,mp_queue,model,is_master,proc_offset'>
 				<method_info nloc='48' complexity='16' token_count='405' nesting_level='1' start_line='497' end_line='600'></method_info>
 			<added_lines>539</added_lines>
 			<deleted_lines>533,534,535</deleted_lines>
 		</method>
 		<method name='call_setup_hook' parameters='self,args'>
 				<method_info nloc='1' complexity='1' token_count='9' nesting_level='1' start_line='216' end_line='217'></method_info>
 			<added_lines>216,217</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>148,208,215,218</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\distrib_parts.py' new_name='pytorch_lightning\trainer\distrib_parts.py'>
 		<file_info nloc='318' complexity='85' token_count='1730'></file_info>
 		<method name='horovod_train' parameters='self,model'>
 				<method_info nloc='36' complexity='14' token_count='317' nesting_level='1' start_line='185' end_line='249'></method_info>
 			<added_lines>187</added_lines>
 			<deleted_lines>185</deleted_lines>
 		</method>
 		<method name='call_setup_hook' parameters='self,args'>
 				<method_info nloc='1' complexity='1' token_count='9' nesting_level='1' start_line='92' end_line='93'></method_info>
 			<added_lines>92,93</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>91,94</added_lines>
 			<deleted_lines>183,184</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\trainer.py' new_name='pytorch_lightning\trainer\trainer.py'>
 		<file_info nloc='1080' complexity='136' token_count='4779'></file_info>
 		<method name='__attach_datamodule' parameters='self,model,datamodule'>
 				<method_info nloc='9' complexity='6' token_count='77' nesting_level='1' start_line='1072' end_line='1084'></method_info>
 			<added_lines>1079</added_lines>
 			<deleted_lines>1072</deleted_lines>
 		</method>
 		<method name='__test_given_model' parameters='self,model,test_dataloaders'>
 				<method_info nloc='12' complexity='3' token_count='78' nesting_level='1' start_line='1342' end_line='1362'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>1343,1344</deleted_lines>
 		</method>
 		<method name='__attach_datamodule' parameters='self,model,datamodule,stage'>
 				<method_info nloc='10' complexity='6' token_count='82' nesting_level='1' start_line='1079' end_line='1100'></method_info>
 			<added_lines>1079,1086,1087,1088,1089,1090,1091,1092,1100</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__test_using_best_weights' parameters='self,ckpt_path,test_dataloaders'>
 				<method_info nloc='32' complexity='8' token_count='192' nesting_level='1' start_line='1295' end_line='1340'></method_info>
 			<added_lines>1298</added_lines>
 			<deleted_lines>1297</deleted_lines>
 		</method>
 		<method name='can_prepare_data' parameters='self'>
 				<method_info nloc='8' complexity='7' token_count='64' nesting_level='1' start_line='1057' end_line='1065'></method_info>
 			<added_lines>1058,1059,1060,1061,1063,1065</added_lines>
 			<deleted_lines>1058</deleted_lines>
 		</method>
 		<method name='call_setup_hook' parameters='self,model'>
 				<method_info nloc='8' complexity='5' token_count='65' nesting_level='1' start_line='1384' end_line='1392'></method_info>
 			<added_lines>1384,1385,1386,1387,1388,1389,1390,1391,1392</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>381,945,958,959,1101,1393</added_lines>
 			<deleted_lines>944,1056,1282,1283,1284</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\base\datamodules.py' new_name='tests\base\datamodules.py'>
 		<file_info nloc='26' complexity='10' token_count='287'></file_info>
 		<method name='__init__' parameters='self,str'>
 				<method_info nloc='4' complexity='1' token_count='28' nesting_level='1' start_line='9' end_line='12'></method_info>
 			<added_lines>12</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='setup' parameters='self,str'>
 				<method_info nloc='9' complexity='5' token_count='140' nesting_level='1' start_line='18' end_line='29'></method_info>
 			<added_lines>18,19,20,21,22,23,24,25,26,27,28,29</added_lines>
 			<deleted_lines>18,19,20</deleted_lines>
 		</method>
 		<method name='setup' parameters='self'>
 				<method_info nloc='5' complexity='1' token_count='87' nesting_level='1' start_line='16' end_line='20'></method_info>
 			<added_lines>18,19,20</added_lines>
 			<deleted_lines>16,17,18,19,20</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>8</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\core\test_datamodules.py' new_name='tests\core\test_datamodules.py'>
 		<file_info nloc='207' complexity='16' token_count='1184'></file_info>
 		<method name='test_full_loop' parameters='tmpdir'>
 				<method_info nloc='14' complexity='1' token_count='75' nesting_level='0' start_line='215' end_line='235'></method_info>
 			<added_lines>216,217,229</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_dm_pickle_after_setup' parameters='tmpdir'>
 				<method_info nloc='5' complexity='1' token_count='26' nesting_level='0' start_line='37' end_line='41'></method_info>
 			<added_lines>37,38,39,40,41</added_lines>
 			<deleted_lines>37,38,39,40,41</deleted_lines>
 		</method>
 		<method name='test_full_loop_ddp_spawn' parameters='tmpdir'>
 				<method_info nloc='18' complexity='1' token_count='96' nesting_level='0' start_line='290' end_line='315'></method_info>
 			<added_lines>294,295,309</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_data_hooks_called_with_stage_kwarg' parameters='tmpdir'>
 				<method_info nloc='10' complexity='1' token_count='61' nesting_level='0' start_line='120' end_line='131'></method_info>
 			<added_lines>120,121,122,123,124,125,126,127,128,129,130,131</added_lines>
 			<deleted_lines>120,121,131</deleted_lines>
 		</method>
 		<method name='test_data_hooks_called_verbose' parameters='tmpdir'>
 				<method_info nloc='17' complexity='1' token_count='99' nesting_level='0' start_line='98' end_line='117'></method_info>
 			<added_lines>98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117</added_lines>
 			<deleted_lines>105,108</deleted_lines>
 		</method>
 		<method name='test_full_loop_dp' parameters='tmpdir'>
 				<method_info nloc='16' complexity='1' token_count='82' nesting_level='0' start_line='264' end_line='286'></method_info>
 			<added_lines>265,266,280</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_can_prepare_data' parameters='tmpdir'>
 				<method_info nloc='27' complexity='1' token_count='147' nesting_level='0' start_line='13' end_line='65'></method_info>
 			<added_lines>13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65</added_lines>
 			<deleted_lines>37,38,39,40,41,42,43,46,47,62,65</deleted_lines>
 		</method>
 		<method name='test_data_hooks_called' parameters='tmpdir'>
 				<method_info nloc='13' complexity='1' token_count='74' nesting_level='0' start_line='81' end_line='95'></method_info>
 			<added_lines>81,82,83,84,85,86,87,88,89,90,91,92,93,94,95</added_lines>
 			<deleted_lines>85,88,90,95</deleted_lines>
 		</method>
 		<method name='test_train_loop_only' parameters='tmpdir'>
 				<method_info nloc='17' complexity='1' token_count='88' nesting_level='0' start_line='155' end_line='175'></method_info>
 			<added_lines>173,175</added_lines>
 			<deleted_lines>158,161</deleted_lines>
 		</method>
 		<method name='test_full_loop_single_gpu' parameters='tmpdir'>
 				<method_info nloc='15' complexity='1' token_count='78' nesting_level='0' start_line='239' end_line='260'></method_info>
 			<added_lines>240,241,254</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_train_val_loop_only' parameters='tmpdir'>
 				<method_info nloc='15' complexity='1' token_count='76' nesting_level='0' start_line='178' end_line='197'></method_info>
 			<added_lines>179,180,195,197</added_lines>
 			<deleted_lines>188,191</deleted_lines>
 		</method>
 		<method name='test_base_datamodule_with_verbose_setup' parameters='tmpdir'>
 				<method_info nloc='5' complexity='1' token_count='27' nesting_level='0' start_line='74' end_line='78'></method_info>
 			<added_lines>74,75,76,77,78</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_test_loop_only' parameters='tmpdir'>
 				<method_info nloc='10' complexity='1' token_count='46' nesting_level='0' start_line='200' end_line='212'></method_info>
 			<added_lines>200,201,202,203,204,205,206,207,208,209,210,211,212</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>2,3,6,9,10,11,12,79,80,96,97,118,119,132,133,198,199</added_lines>
 			<deleted_lines>5,7,67,72,73,96,134,146,147,176,177</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
