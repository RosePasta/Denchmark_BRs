<bug_data>
<bug id='827' author='srush' open_date='2020-02-12T17:33:30Z' closed_time='2020-03-30T16:05:24Z'>
 	<summary>Support/Features for step-based models</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug+Feature&lt;/denchmark-h&gt;
 
 For models like transformer, we utilize step-based learning rates and evaluation.
 It would be nice to have several features along this line.
 
 
 Support for step-based schedulers. Right now we use cannot give the scheduler to lightning, because it calls scheduler.step(epochs=epoch) internally which resets the scheduler.
 
 
 Fix docs for step based evaluation and checkpointing. It seems like it exists but it is hard to tell which is epochs / steps.
 
 
 Add a max_steps option for stopping training.
 
 
 Helper functions for converting between steps and epochs. For instance, from the number of epochs and parallelism, get the steps for configure_optimizers
 
 
 	</description>
 	<comments>
 		<comment id='1' author='srush' date='2020-02-13T09:44:08Z'>
 		Hi &lt;denchmark-link:https://github.com/srush&gt;@srush&lt;/denchmark-link&gt;
 
 For 1. I have opened issue &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/806&gt;#806&lt;/denchmark-link&gt;
  to discuss about it and I will contribute this soon.
 For 3. I added PR &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/728&gt;#728&lt;/denchmark-link&gt;
  that adds max/min steps for training such models.
 		</comment>
 		<comment id='2' author='srush' date='2020-02-20T13:11:15Z'>
 		&lt;denchmark-link:https://github.com/srush&gt;@srush&lt;/denchmark-link&gt;
  good suggestions, would you mind to send a PR for 2 and 4?
 		</comment>
 		<comment id='3' author='srush' date='2020-02-20T13:14:24Z'>
 		we just merged a pr &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/728&gt;#728&lt;/denchmark-link&gt;
  about this
 		</comment>
 		<comment id='4' author='srush' date='2020-03-30T16:05:24Z'>
 		feel free to reopen if needed ü§ñ
 		</comment>
 	</comments>
 </bug>
<commit id='969e929a482b3384c0c23777389db866bcc5c5ed' author='William Falcon' date='2020-03-05 06:48:54-05:00'>
 	<dmm_unit complexity='0.5759493670886076' interfacing='1.0' size='0.13924050632911392'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>27</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\lightning.py' new_name='pytorch_lightning\core\lightning.py'>
 		<file_info nloc='911' complexity='54' token_count='1367'></file_info>
 		<method name='configure_optimizers' parameters='self'>
 				<method_info nloc='64' complexity='1' token_count='22' nesting_level='1' start_line='726' end_line='789'></method_info>
 			<added_lines>761,762,763,764,765,766,767,768,769,785,786</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\trainer.py' new_name='pytorch_lightning\trainer\trainer.py'>
 		<file_info nloc='1095' complexity='81' token_count='3184'></file_info>
 		<method name='configure_schedulers' parameters='self,list'>
 				<method_info nloc='23' complexity='6' token_count='152' nesting_level='1' start_line='1104' end_line='1130'></method_info>
 			<added_lines>1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>9,1081,1085,1086,1088,1091,1092,1095,1096,1097,1098,1099,1100,1101,1102,1103</added_lines>
 			<deleted_lines>746,747,1082,1086,1087,1089,1092,1093,1097,1098,1099,1100,1101</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_io.py' new_name='pytorch_lightning\trainer\training_io.py'>
 		<file_info nloc='305' complexity='67' token_count='1466'></file_info>
 		<method name='dump_checkpoint' parameters='self'>
 				<method_info nloc='31' complexity='10' token_count='226' nesting_level='1' start_line='300' end_line='345'></method_info>
 			<added_lines>322,323</added_lines>
 			<deleted_lines>323</deleted_lines>
 		</method>
 		<method name='restore_training_state' parameters='self,checkpoint'>
 				<method_info nloc='27' complexity='14' token_count='235' nesting_level='1' start_line='370' end_line='414'></method_info>
 			<added_lines>414</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91</added_lines>
 			<deleted_lines>231,232</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_loop.py' new_name='pytorch_lightning\trainer\training_loop.py'>
 		<file_info nloc='493' complexity='116' token_count='2418'></file_info>
 		<method name='update_learning_rates' parameters='self,interval'>
 				<method_info nloc='19' complexity='8' token_count='132' nesting_level='1' start_line='712' end_line='738'></method_info>
 			<added_lines>712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='run_training_epoch' parameters='self'>
 				<method_info nloc='54' complexity='29' token_count='431' nesting_level='1' start_line='390' end_line='496'></method_info>
 			<added_lines>437,438,439</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='train' parameters='self'>
 				<method_info nloc='55' complexity='23' token_count='387' nesting_level='1' start_line='296' end_line='388'></method_info>
 			<added_lines>364</added_lines>
 			<deleted_lines>364,365,366,367,368,369,370,371,372,373,374</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>739</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\__init__.py' new_name='tests\models\__init__.py'>
 		<file_info nloc='40' complexity='3' token_count='141'></file_info>
 		<modified_lines>
 			<added_lines>22,23,24</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\base.py' new_name='tests\models\base.py'>
 		<file_info nloc='133' complexity='19' token_count='1175'></file_info>
 		<method name='training_step' parameters='self,batch,batch_idx,optimizer_idx'>
 				<method_info nloc='16' complexity='4' token_count='125' nesting_level='1' start_line='133' end_line='162'></method_info>
 			<added_lines>133</added_lines>
 			<deleted_lines>133</deleted_lines>
 		</method>
 		<method name='training_step' parameters='self,batch,batch_idx'>
 				<method_info nloc='16' complexity='4' token_count='121' nesting_level='1' start_line='133' end_line='162'></method_info>
 			<added_lines>133</added_lines>
 			<deleted_lines>133</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\mixins.py' new_name='tests\models\mixins.py'>
 		<file_info nloc='414' complexity='87' token_count='2852'></file_info>
 		<method name='configure_optimizers' parameters='self'>
 				<method_info nloc='7' complexity='2' token_count='82' nesting_level='1' start_line='602' end_line='608'></method_info>
 			<added_lines>602,603,604,605,606,607,608</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>4,601,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639</added_lines>
 			<deleted_lines>4</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\utils.py' new_name='tests\models\utils.py'>
 		<file_info nloc='153' complexity='36' token_count='1163'></file_info>
 		<method name='run_model_test' parameters='trainer_options,model,on_gpu'>
 				<method_info nloc='19' complexity='5' token_count='159' nesting_level='0' start_line='52' end_line='89'></method_info>
 			<added_lines>85</added_lines>
 			<deleted_lines>85</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_gpu_models.py' new_name='tests\test_gpu_models.py'>
 		<file_info nloc='289' complexity='40' token_count='2297'></file_info>
 		<method name='test_optimizer_return_options' parameters=''>
 				<method_info nloc='24' complexity='8' token_count='280' nesting_level='0' start_line='94' end_line='126'></method_info>
 			<added_lines>119,120,123,124,125,126</added_lines>
 			<deleted_lines>119,122</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='tests\trainer\test_optimizers.py'>
 		<file_info nloc='101' complexity='14' token_count='611'></file_info>
 	</modification>
 </commit>
</bug_data>
