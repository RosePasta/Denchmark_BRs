<bug_data>
<bug id='1751' author='marcopodda' open_date='2020-05-07T06:12:51Z' closed_time='2020-05-26T23:06:06Z'>
 	<summary>Early Stopping behavior</summary>
 	<description>
 Hi there,
 thanks for the great library (I am using 0.7.5.). I am not following the bug report template as I'm not sure this is indeed a bug, or simply I cannot understand how early stopping is implemented. My code looks as follows:
 &lt;denchmark-code&gt;    early_stop_callback = EarlyStopping(
         monitor='val_acc',
         min_delta=0.0,
         patience=80,
         verbose=True,
         mode=self.mode
     )
 
     trainer = Trainer(
         early_stop_callback=early_stop_callback,
         auto_select_gpus=True,
         max_epochs=200,
         terminate_on_nan=True,
         show_progress_bar=True,
         fast_dev_run=False,
         gpus=1
     )
 &lt;/denchmark-code&gt;
 
 As I understand it, the model should perform early stopping after AT LEAST 80 epochs have passed without improvement on the validation accuracy. However, in my case, early stopping happened at epoch 75. Is this how it should be?
 As I said, I am not sure this is actually a bug or a choice (perhaps early stopping is implemented at the batch level?). If it is indeed a bug, I will work a reproducible example. Thank you!
 	</description>
 	<comments>
 		<comment id='1' author='marcopodda' date='2020-05-07T06:13:44Z'>
 		Hi! thanks for your contribution!, great first issue!
 		</comment>
 		<comment id='2' author='marcopodda' date='2020-05-07T08:07:26Z'>
 		I would expect that it should iterate for at least 80 epochs, too. So to me, it looks like a bug or some kind of unexpected behavior. Would be great to figure it out!
 		</comment>
 		<comment id='3' author='marcopodda' date='2020-05-07T09:54:37Z'>
 		Ok then, I'll work out some notebook to see if I can reproduce.
 		</comment>
 		<comment id='4' author='marcopodda' date='2020-05-07T14:16:58Z'>
 		Thanks &lt;denchmark-link:https://github.com/mateuszpieniak&gt;@mateuszpieniak&lt;/denchmark-link&gt;
 
 Here is a working example. As you can see, it stops at epoch 41 even though patience is set to 80.
 &lt;denchmark-link:https://github.com/marcopodda/pl-es-example/blob/master/ES%20example.ipynb&gt;https://github.com/marcopodda/pl-es-example/blob/master/ES%20example.ipynb&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='5' author='marcopodda' date='2020-05-07T16:00:54Z'>
 		It is definitely a bug. I discovered that EarlyStopping.on_epoch_end is executed twice within one epoch, meaning that patience=160 should solve your issue temporarily.
 In the file training_loop.py:
 First call:
 &lt;denchmark-code&gt;            if self.fast_dev_run or should_check_val:
                 self.run_evaluation(test_mode=self.testing)
                 self.call_checkpoint_callback()
                 self.call_early_stop_callback()
 &lt;/denchmark-code&gt;
 
 Second call:
 &lt;denchmark-code&gt;                # TODO wrap this logic into the callback
                 if self.enable_early_stop:
                     if (met_min_epochs and met_min_steps) or self.fast_dev_run:
                         should_stop = self.early_stop_callback.on_epoch_end(self, self.get_model())
                         # stop training
                         stop = should_stop and met_min_epochs
                         if stop:
                             self.run_training_teardown()
                             return
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='6' author='marcopodda' date='2020-05-08T09:45:12Z'>
 		I upgraded to the bleeding edge version yesterday and can confirm that this started happening to me too. I didn't have an issue before I upgraded (I think I was on 0.7.3 before?)
 		</comment>
 		<comment id='7' author='marcopodda' date='2020-05-10T23:57:11Z'>
 		Yep we ran into this as well. It is called once in trainer and once in the on epoch end callback.
 		</comment>
 		<comment id='8' author='marcopodda' date='2020-05-11T20:45:55Z'>
 		&lt;denchmark-link:https://github.com/Anjum48&gt;@Anjum48&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/ricpruss&gt;@ricpruss&lt;/denchmark-link&gt;
  mind send a fix, PR?
 		</comment>
 		<comment id='9' author='marcopodda' date='2020-05-11T21:44:26Z'>
 		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
  Well, I would love to make my first PL's PR if that's okay? 
 		</comment>
 		<comment id='10' author='marcopodda' date='2020-05-11T21:48:58Z'>
 		&lt;denchmark-link:https://github.com/mateuszpieniak&gt;@mateuszpieniak&lt;/denchmark-link&gt;
  sure go ahead! 
 		</comment>
 	</comments>
 </bug>
<commit id='3af4994d5a84bc80738b50983b4b42c3eb946433' author='Mateusz Pieniak' date='2020-05-26 19:06:06-04:00'>
 	<dmm_unit complexity='0.4' interfacing='0.0' size='0.4'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>41,42</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_loop.py' new_name='pytorch_lightning\trainer\training_loop.py'>
 		<file_info nloc='536' complexity='127' token_count='2636'></file_info>
 		<method name='call_early_stop_callback' parameters='self'>
 				<method_info nloc='3' complexity='2' token_count='24' nesting_level='1' start_line='794' end_line='796'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>794,795,796</deleted_lines>
 		</method>
 		<method name='run_training_epoch' parameters='self'>
 				<method_info nloc='68' complexity='35' token_count='562' nesting_level='1' start_line='380' end_line='509'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>455,501</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>797</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
