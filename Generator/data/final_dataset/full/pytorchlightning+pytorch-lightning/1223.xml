<bug_data>
<bug id='1223' author='lobantseff' open_date='2020-03-24T14:24:01Z' closed_time='2020-05-31T12:31:22Z'>
 	<summary>gan.py multi-gpu running problems</summary>
 	<description>
 Running &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/domain_templates/gan.py&gt;gan.py&lt;/denchmark-link&gt;
  example with Trainer(ngpus=2) causes two types of error:
 
 if Trainer(ngpus=2, distributed_backend='dp')
 
 &lt;denchmark-code&gt;Exception has occurred: AttributeError
 'NoneType' object has no attribute 'detach'
   File "/home/user/gan.py", line 146, in training_step
     self.discriminator(self.generated_imgs.detach()), fake)
 &lt;/denchmark-code&gt;
 
 
 if Trainer(ngpus=2, distributed_backend='ddp')
 
 
 in ./lightling_logs one run creates two folders: version_0 and version_1
 Exception caused:
 File "/opt/miniconda3/envs/ctln-gan/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 122, in _del_model
 os.remove(filepath)
 FileNotFoundError: [Errno 2] No such file or directory: '/home/user/pyproj/DCGAN/lightning_logs/version_1/checkpoints/epoch=0.ckpt'
 
 it seems that each subprocess tries to create its own checkpoints and delete not ctrated one.
 &lt;denchmark-h:h4&gt;Environment version:&lt;/denchmark-h&gt;
 
 python 3.7.5
 pytorch 1.4.0
 pytorch-lightning 0.7.1
 	</description>
 	<comments>
 		<comment id='1' author='lobantseff' date='2020-03-24T14:24:41Z'>
 		Hi! thanks for your contribution!, great first issue!
 		</comment>
 		<comment id='2' author='lobantseff' date='2020-03-24T16:49:10Z'>
 		The problem is that gan.py example suppose to use buffered values self.generated_images and self.last_img, however during replicating and gathering in 
 
 
 pytorch-lightning/pytorch_lightning/overrides/data_parallel.py
 
 
          Line 64
       in
       22a7264
 
 
 
 
 
 
  replicas = self.replicate(self.module, self.device_ids[:len(inputs)]) 
 
 
 
 
 
 buffered values are not replicated and not gathered to main LightningModule model
 		</comment>
 		<comment id='3' author='lobantseff' date='2020-03-27T12:01:55Z'>
 		@armavox good catch, mind draft a PR? ðŸ¤–
 		</comment>
 		<comment id='4' author='lobantseff' date='2020-03-29T22:14:14Z'>
 		yep, I'll try
 		</comment>
 		<comment id='5' author='lobantseff' date='2020-04-14T17:29:01Z'>
 		@armavox how is it going?
 		</comment>
 		<comment id='6' author='lobantseff' date='2020-04-22T09:43:20Z'>
 		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
   I assume to fix it by May
 		</comment>
 		<comment id='7' author='lobantseff' date='2020-05-28T14:00:50Z'>
 		@armavox Any updates on this? Having the same issue...
 		</comment>
 		<comment id='8' author='lobantseff' date='2020-05-30T15:50:34Z'>
 		Made some updates. Sorry for waiting.
 There is an official l warning about the use of local (buffered here) variables during the distributed training: &lt;denchmark-link:https://pytorch.org/docs/stable/nn.html#torch.nn.DataParallel&gt;https://pytorch.org/docs/stable/nn.html#torch.nn.DataParallel&lt;/denchmark-link&gt;
 
 So I didn't try to create detours in the Lightning code and fixed only the example to work with dp and ddp.
 		</comment>
 		<comment id='9' author='lobantseff' date='2020-05-30T15:55:50Z'>
 		The problem from point 2 in the heading post seems to be fixed by someone. But the unused folder for parallel experiment still created during ddp training. The problem is in 
 
 
 pytorch-lightning/pytorch_lightning/trainer/callback_config.py
 
 
          Line 66
       in
       fdbbe96
 
 
 
 
 
 
  os.makedirs(ckpt_path, exist_ok=True) 
 
 
 
 
 , which doesn't use rank_zero_only decorator or something else.
 I would propose some good fixes, but don't know how to do this elegant.
 Thanks for your work!
 Best regards, Artem.
 		</comment>
 	</comments>
 </bug>
<commit id='55fdfe384537e4d43e7397306ba001ffc3474322' author='Artem Lobantsev' date='2020-05-31 08:31:21-04:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pl_examples\domain_templates\generative_adversarial_net.py' new_name='pl_examples\domain_templates\generative_adversarial_net.py'>
 		<file_info nloc='147' complexity='16' token_count='1195'></file_info>
 		<method name='main' parameters='args'>
 				<method_info nloc='4' complexity='1' token_count='26' nesting_level='0' start_line='186' end_line='202'></method_info>
 			<added_lines>186,190,195,196</added_lines>
 			<deleted_lines>188,192</deleted_lines>
 		</method>
 		<method name='on_epoch_end' parameters='self'>
 				<method_info nloc='5' complexity='1' token_count='56' nesting_level='1' start_line='177' end_line='183'></method_info>
 			<added_lines>178</added_lines>
 			<deleted_lines>179,180</deleted_lines>
 		</method>
 		<method name='main' parameters='hparams'>
 				<method_info nloc='4' complexity='1' token_count='22' nesting_level='0' start_line='188' end_line='202'></method_info>
 			<added_lines>190,195,196</added_lines>
 			<deleted_lines>188,192</deleted_lines>
 		</method>
 		<method name='training_step' parameters='self,batch,batch_idx,optimizer_idx'>
 				<method_info nloc='35' complexity='3' token_count='279' nesting_level='1' start_line='102' end_line='160'></method_info>
 			<added_lines>104,105,106,107,116,117,118,126,147,150</added_lines>
 			<deleted_lines>105,109,110,111,117,118,119,127,148,151</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>82,94</added_lines>
 			<deleted_lines>93,94,95</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
