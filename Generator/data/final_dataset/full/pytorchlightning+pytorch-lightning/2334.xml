<bug_data>
<bug id='2334' author='dscarmo' open_date='2020-06-23T21:05:29Z' closed_time='2020-06-28T21:20:34Z'>
 	<summary>LightningModule.load_from_checkpoint not working with .ckpt from 0.7.6</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 Trying to use an old experiment .ckpt (generated with ModelCheckpoint(monitor="val_loss", mode="min') in 0.7.6) results in an error when trying to load.
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Steps to reproduce the behavior:
 
 Train something with 0.7.6 and save checkpoint with the checkpoint callback
 Try to load checkpoint with 0.8.1
 
 &lt;denchmark-code&gt;Trying to load: ckpts/MNIST_0.7.6epoch=4.ckpt with PL version: 0.8.1
 ---------------------------------------------------------------------------
 TypeError                                 Traceback (most recent call last)
 &lt;ipython-input-3-36a7290b43c6&gt; in &lt;module&gt;()
      35 selected_ckpt = glob(os.path.join("ckpts", "*.ckpt"))[0]
      36 print(f"Trying to load: {selected_ckpt} with PL version: {pl.__version__}")
 ---&gt; 37 LitClassifier.load_from_checkpoint(selected_ckpt)
 
 1 frames
 /usr/local/lib/python3.6/dist-packages/pytorch_lightning/core/saving.py in load_from_checkpoint(cls, checkpoint_path, map_location, hparams_file, tags_csv, *args, **kwargs)
     169         checkpoint[cls.CHECKPOINT_HYPER_PARAMS_KEY].update(kwargs)
     170 
 --&gt; 171         model = cls._load_model_state(checkpoint, *args, **kwargs)
     172         return model
     173 
 
 /usr/local/lib/python3.6/dist-packages/pytorch_lightning/core/saving.py in _load_model_state(cls, checkpoint, *args, **kwargs)
     184 
     185             if cls.CHECKPOINT_HYPER_PARAMS_TYPE in checkpoint:
 --&gt; 186                 model_args = checkpoint[cls.CHECKPOINT_HYPER_PARAMS_TYPE](model_args)
     187 
     188             args_name = checkpoint.get(cls.CHECKPOINT_HYPER_PARAMS_NAME)
 
 TypeError: 'str' object is not callable
 &lt;/denchmark-code&gt;
 
 Here is a Colab notebook reproducing the issue: &lt;denchmark-link:https://colab.research.google.com/drive/1s7SzG3EkLJZOmUOkb0mJ85zDcOxBcDLG?usp=sharing&gt;https://colab.research.google.com/drive/1s7SzG3EkLJZOmUOkb0mJ85zDcOxBcDLG?usp=sharing&lt;/denchmark-link&gt;
 
 Maybe this is related to the changes in hparams recently?
 It happened in my local enviroment and in Google Colab's enviroment.
 I was able to load the checkpoint after downgrading to 0.7.6 without problems.
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 Being able to use old .ckpts.
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 
 PyTorch Version (e.g., 1.0): 1.5
 OS (e.g., Linux): Ubuntu 18.04
 How you installed PyTorch (conda, pip, source): pip
 Build command you used (if compiling from source):
 Python version: 3.6.9
 CUDA/cuDNN version: 10.2
 GPU models and configuration: 1060
 Any other relevant information:
 
 Also happened in the Colab enviroment.
 	</description>
 	<comments>
 		<comment id='1' author='dscarmo' date='2020-06-25T12:51:43Z'>
 		Added a Google Colab notebook reproducing the issue.
 		</comment>
 		<comment id='2' author='dscarmo' date='2020-06-29T01:55:26Z'>
 		&lt;denchmark-link:https://user-images.githubusercontent.com/3640001/85965231-09d80980-b98a-11ea-9291-0510ebebf40e.png&gt;&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://github.com/dscarmo&gt;@dscarmo&lt;/denchmark-link&gt;
  no more bug :) &lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
  fixed it!
 		</comment>
 	</comments>
 </bug>
<commit id='861a73be12ef17214bb0ed49aabc9f48a80fde16' author='Jirka Borovec' date='2020-06-28 17:20:33-04:00'>
 	<dmm_unit complexity='1.0' interfacing='0.14285714285714285' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>45,46</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\saving.py' new_name='pytorch_lightning\core\saving.py'>
 		<file_info nloc='311' complexity='40' token_count='1224'></file_info>
 		<method name='_convert_loaded_hparams' parameters='dict,Callable,None'>
 				<method_info nloc='7' complexity='3' token_count='43' nesting_level='0' start_line='250' end_line='259'></method_info>
 			<added_lines>250,251,252,253,254,255,256,257,258,259</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_load_model_state' parameters='cls,str,cls_args,cls_kwargs'>
 				<method_info nloc='24' complexity='10' token_count='203' nesting_level='1' start_line='173' end_line='208'></method_info>
 			<added_lines>183</added_lines>
 			<deleted_lines>183,184</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>260,261</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\test_hparams.py' new_name='tests\models\test_hparams.py'>
 		<file_info nloc='242' complexity='41' token_count='1945'></file_info>
 		<method name='test_collect_init_arguments' parameters='tmpdir,cls'>
 				<method_info nloc='29' complexity='7' token_count='272' nesting_level='0' start_line='249' end_line='291'></method_info>
 			<added_lines>271</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_load_past_checkpoint' parameters='tmpdir,past_key'>
 				<method_info nloc='13' complexity='1' token_count='103' nesting_level='0' start_line='384' end_line='403'></method_info>
 			<added_lines>395</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
