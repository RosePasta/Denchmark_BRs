<bug_data>
<bug id='3053' author='yukw777' open_date='2020-08-19T20:11:59Z' closed_time='2020-08-20T11:19:12Z'>
 	<summary>load_from_checkpoint() doesn't work when a LightningModule inherits from typing.Generic</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 When a LightningModule with saved hyperparameters inherits from , hyperparameters saved in the checkpoint file are not loaded automatically, causing an error. When  calls  to gather the list of arguments of the LightningModule that inherits from ,  returns  instead of the actual arguments, because  implements an empty  (the execution path ends up here: &lt;denchmark-link:https://github.com/python/cpython/blob/3.8/Lib/inspect.py#L2324&gt;https://github.com/python/cpython/blob/3.8/Lib/inspect.py#L2324&lt;/denchmark-link&gt;
 ). As a result, PL filters out all the saved hyperparameters from the checkpoint, which results in an error when trying to instantiate the LightningModule. I'd assume this would happen when a LightningModule inherits from any class that implements  such as .
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Create a LightningModule that inherits from typing.Generic with some hyperparameters, fit it, then try to load it from a checkpoint.
 &lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;
 
 import torch
 import torch.nn.functional as F
 import pytorch_lightning as pl
 
 from typing import Generic, TypeVar
 from torch.utils.data import DataLoader
 
 T = TypeVar("T")
 
 
 class GenericLitClassifier(Generic[T], pl.LightningModule):
     def __init__(self, dim):
         super().__init__()
         self.l1 = torch.nn.Linear(28 * 28, dim)
         self.save_hyperparameters()
 
     def forward(self, x):
         return torch.relu(self.l1(x.view(x.size(0), -1)))
 
     def training_step(self, batch, batch_nb):
         x, y = batch
         loss = F.cross_entropy(self(x), y)
         tensorboard_logs = {"train_loss": loss}
         return {"loss": loss, "log": tensorboard_logs}
 
     def configure_optimizers(self):
         return torch.optim.Adam(self.parameters(), lr=0.02)
 
 
 class LitClassifier(GenericLitClassifier[str]):
     pass
 
 
 class Dataset:
     def __getitem__(self, idx):
         return torch.ones(1, 784), 1
 
     def __len__(self):
         return 5
 
 
 train_loader = DataLoader(Dataset(), batch_size=2)
 model = LitClassifier(10)
 trainer = pl.Trainer(max_epochs=5)
 trainer.fit(model, train_loader)
 
 for path, _ in trainer.checkpoint_callback.best_k_models.items():
     lm = LitClassifier.load_from_checkpoint(path)
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 Even when a LightningModule inherits from any class that implements __new__() (e.g. typing.Generic), its hyperparameters should be loaded automatically from a checkpoint.
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;* CUDA:
         - GPU:
         - available:         False
         - version:           None
 * Packages:
         - numpy:             1.19.1
         - pyTorch_debug:     False
         - pyTorch_version:   1.5.1
         - pytorch-lightning: 0.8.5
         - tensorboard:       2.3.0
         - tqdm:              4.48.2
 * System:
         - OS:                Darwin
         - architecture:
                 - 64bit
                 - 
         - processor:         i386
         - python:            3.7.7
         - version:           Darwin Kernel Version 18.7.0: Mon Apr 27 20:09:39 PDT 2020; root:xnu-4903.278.35~1/RELEASE_X86_64
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;
 
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='88886ace7232c8e25ece431969c5d8d101f3368d' author='Peter Yu' date='2020-08-20 07:19:11-04:00'>
 	<dmm_unit complexity='0.0' interfacing='0.1' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\saving.py' new_name='pytorch_lightning\core\saving.py'>
 		<file_info nloc='289' complexity='44' token_count='1245'></file_info>
 		<method name='_load_model_state' parameters='cls,str,bool,cls_args,cls_kwargs'>
 				<method_info nloc='25' complexity='13' token_count='241' nesting_level='1' start_line='157' end_line='197'></method_info>
 			<added_lines>159</added_lines>
 			<deleted_lines>159</deleted_lines>
 		</method>
 		<method name='load_from_checkpoint' parameters='cls,str,args,str,str,device,int,None,None,bool,kwargs'>
 				<method_info nloc='8' complexity='1' token_count='55' nesting_level='1' start_line='50' end_line='57'></method_info>
 			<added_lines>51,52,53,54,55,56,57</added_lines>
 			<deleted_lines>51,52,53,54,55,56,57</deleted_lines>
 		</method>
 		<method name='load_from_checkpoint' parameters='cls,str,args,str,str,device,int,None,None,bool,kwargs'>
 				<method_info nloc='8' complexity='1' token_count='56' nesting_level='1' start_line='50' end_line='57'></method_info>
 			<added_lines>51,52,53,54,55,56,57</added_lines>
 			<deleted_lines>51,52,53,54,55,56,57</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\base\__init__.py' new_name='tests\base\__init__.py'>
 		<file_info nloc='3' complexity='0' token_count='19'></file_info>
 		<modified_lines>
 			<added_lines>4</added_lines>
 			<deleted_lines>4</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\base\model_template.py' new_name='tests\base\model_template.py'>
 		<file_info nloc='137' complexity='8' token_count='750'></file_info>
 		<method name='__init__' parameters='self,float,int,int,float,str,str,int,int,float,float'>
 				<method_info nloc='12' complexity='1' token_count='76' nesting_level='1' start_line='41' end_line='52'></method_info>
 			<added_lines>42,43,44,45,46,47,48,49,50,51,52</added_lines>
 			<deleted_lines>41,42,43,44,45,46,47,48,49,50</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,float,int,int,float,str,str,int,int,float,float'>
 				<method_info nloc='12' complexity='1' token_count='75' nesting_level='1' start_line='39' end_line='50'></method_info>
 			<added_lines>42,43,44,45,46,47,48,49,50</added_lines>
 			<deleted_lines>40,41,42,43,44,45,46,47,48,49,50</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,float,int,int,float,str,str,int,int,float,float'>
 				<method_info nloc='12' complexity='1' token_count='44' nesting_level='1' start_line='139' end_line='150'></method_info>
 			<added_lines>139,140,141,142,143,144,145,146,147,148,149,150</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_default_hparams' parameters='bool,int'>
 				<method_info nloc='18' complexity='2' token_count='92' nesting_level='1' start_line='113' end_line='132'></method_info>
 			<added_lines>129</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__build_model' parameters='self'>
 				<method_info nloc='5' complexity='1' token_count='70' nesting_level='1' start_line='83' end_line='92'></method_info>
 			<added_lines>88,92</added_lines>
 			<deleted_lines>86,87,88,89</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>5,6,33,133,134,135,136,137,138,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167</added_lines>
 			<deleted_lines>31,93,94,95,96,133,134</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\test_restore.py' new_name='tests\models\test_restore.py'>
 		<file_info nloc='233' complexity='23' token_count='1742'></file_info>
 		<method name='test_strict_model_load_less_params' parameters='monkeypatch,tmpdir,tmpdir_server,url_ckpt'>
 				<method_info nloc='23' complexity='2' token_count='174' nesting_level='0' start_line='355' end_line='395'></method_info>
 			<added_lines>367,389,394</added_lines>
 			<deleted_lines>358,359,360,365,366,367,384,385,386,387</deleted_lines>
 		</method>
 		<method name='test_load_model_from_checkpoint' parameters='tmpdir'>
 				<method_info nloc='24' complexity='3' token_count='209' nesting_level='0' start_line='154' end_line='192'></method_info>
 			<added_lines>154,155,157,158,179</added_lines>
 			<deleted_lines>154,156,157,178</deleted_lines>
 		</method>
 		<method name='test_model_saving_loading' parameters='tmpdir'>
 				<method_info nloc='26' complexity='4' token_count='209' nesting_level='0' start_line='265' end_line='310'></method_info>
 			<added_lines>274,304</added_lines>
 			<deleted_lines>278,279,280,281</deleted_lines>
 		</method>
 		<method name='test_load_model_from_checkpoint' parameters='tmpdir,model_template'>
 				<method_info nloc='24' complexity='3' token_count='211' nesting_level='0' start_line='155' end_line='193'></method_info>
 			<added_lines>155,157,158,179</added_lines>
 			<deleted_lines>156,157,178</deleted_lines>
 		</method>
 		<method name='test_strict_model_load_more_params' parameters='monkeypatch,tmpdir,tmpdir_server,url_ckpt'>
 				<method_info nloc='22' complexity='2' token_count='184' nesting_level='0' start_line='314' end_line='351'></method_info>
 			<added_lines>328,345,350</added_lines>
 			<deleted_lines>314,338,339,340,341</deleted_lines>
 		</method>
 		<method name='test_dp_resume' parameters='tmpdir'>
 				<method_info nloc='27' complexity='1' token_count='198' nesting_level='0' start_line='197' end_line='262'></method_info>
 			<added_lines>202</added_lines>
 			<deleted_lines>201,202,203,204,205,206</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>15</added_lines>
 			<deleted_lines>15,311,312,313,409,410,411,416,417,418</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
