<bug_data>
<bug id='3185' author='VirajBagal' open_date='2020-08-26T05:19:53Z' closed_time='2020-09-01T13:17:53Z'>
 	<summary>Value out of range (expected to be in range of [-1, 0], but got 1)</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Value out of range (expected to be in range of [-1, 0], but got 1)&lt;/denchmark-h&gt;
 
 Exception in device=TPU:5: torch_xla/csrc/helpers.cpp:97 : Check failed: min_shape_dim &lt;= dim &amp;&amp; dim &lt;= max_shape_dim
 Following is the stack trace when I am using all 8 TPU cores on Kaggle. The exact same code with
 
 sync_dist=False
 
 works completely fine on Kaggle GPU.
 
 Value out of range (expected to be in range of [-1, 0], but got 1)Exception in device=TPU:5: torch_xla/csrc/helpers.cpp:97 : Check failed: min_shape_dim &lt;= dim &amp;&amp; dim &lt;= max_shape_dim
 *** Begin stack trace ***
 tensorflow::CurrentStackTrace()
 torch_xla::XlaHelpers::GetCanonicalDimensionIndex(long long, long long)
 torch_xla::XlaHelpers::MakeTransposePermutation(long long, long long, long long)
 torch_xla::XLATensor::transpose(torch_xla::XLATensor const&amp;, long long, long long)
 torch_xla::AtenXlaType::t(at::Tensor const&amp;)
 c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;at::Tensor ()(at::Tensor const&amp;), at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor (at::Tensor const&amp;)&gt;::call(c10::OperatorKernel, at::Tensor const&amp;)
 at::t(at::Tensor const&amp;)
 at::Tensor::t() const
 _PyMethodDef_RawFastCallKeywords
 _PyMethodDescr_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallDict
 _PyObject_Call_Prepend
 PyObject_Call
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallDict
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallDict
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallDict
 _PyObject_Call_Prepend
 _PyObject_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallDict
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 PyEval_EvalCodeEx
 PyEval_EvalCode
 _PyMethodDef_RawFastCallKeywords
 _PyCFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyGen_Send
 _PyEval_EvalFrameDefault
 _PyGen_Send
 _PyEval_EvalFrameDefault
 _PyGen_Send
 _PyMethodDef_RawFastCallKeywords
 _PyMethodDescr_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallDict
 _PyObject_Call_Prepend
 PyObject_Call
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyMethodDef_RawFastCallKeywords
 _PyCFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyMethodDef_RawFastCallKeywords
 _PyCFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyMethodDef_RawFastCallKeywords
 _PyCFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyEval_EvalCodeWithName
 _PyFunction_FastCallDict
 _PyObject_Call_Prepend
 PyObject_Call
 _PyEval_EvalFrameDefault
 _PyGen_Send
 _PyMethodDef_RawFastCallKeywords
 _PyMethodDescr_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallKeywords
 _PyEval_EvalFrameDefault
 _PyFunction_FastCallDict
 *** End stack trace ***
 
 Here is the code for my LightningModule
 class GraphAEStage1(pl.LightningModule):
   def __init__(self, config):
     super(GraphAEStage1, self).__init__()
     max_deg = config['poc_max_degree']
     input_dim = config['input_dim']
     hidden_feat = config['hidden_feat_dim']
     layerid = config['layerid']
     self.lr = config['lr']
   
     self.encoder = GraphEncoderStage1(max_deg, input_dim, hidden_feat[layerid])
     self.decoder = GraphDecoderStage1(max_deg, input_dim, hidden_feat[layerid])
     
     self.encoder.apply(self.init_weights)
     
     self.crit = torch.nn.L1Loss()
     self.node_mae = MAE()
     self.adj_mae = MAE()
     
     self.decoder.self_linear.weight = nn.Parameter(self.encoder.self_linear.weight.permute(1,0))
     for d in range(config['poc_max_degree']):
         self.decoder.neigh_linear[d].weight = nn.Parameter(self.encoder.neigh_linear[d].weight.permute(1,0))
 
   def training_step(self, batch, batch_idx):
     loss, tf_node, _, _, _ = self.shared_step(batch)
     result = pl.TrainResult(minimize=loss)
     result.log('train_loss', loss, prog_bar = True, logger = True, on_step = False, on_epoch = True, sync_dist = True)
     return result
 
   def validation_step(self, batch, batch_idx):
     loss, tf_node, recon_node, val_node_mae, val_adj_mae = self.shared_step(batch)
     
     logs = {'val_loss': loss, 'node_mae': val_node_mae, 'adj_mae': val_adj_mae}
     result = pl.EvalResult(checkpoint_on = loss)
     result.log_dict(logs, prog_bar = True, logger = True, on_step = False, on_epoch = True, sync_dist = True)
     
     return result               
 
   def shared_step(self, batch):
     node, adj, deg, mask = batch
     tf_node, avg_adj = self.encoder(node, adj, deg, mask)
     recon_node, recon_adj = self.decoder(tf_node, deg)
 
     
     node_loss = self.criterion(recon_node, node)
     adj_loss = self.criterion(recon_adj, avg_adj)
     loss = node_loss + adj_loss
     
     node_mae = self.node_mae(node, recon_node)
     adj_mae = self.adj_mae(recon_adj, avg_adj)
     
     return loss, tf_node, recon_node, node_mae, adj_mae
 
   def configure_optimizers(self):
     optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
     return optimizer
 
   def criterion(self, output, target):
     return self.crit(output, target)
 
   def init_weights(self, m):
     if type(m) == nn.Linear:
         torch.nn.init.xavier_uniform(m.weight)
         m.bias.data.fill_(0.00)  
 There are similar issues reported on PyTorch XLA repo, but many of them were using CrossEntropyLoss. I am not using CrossEntropyLoss here.
 	</description>
 	<comments>
 		<comment id='1' author='VirajBagal' date='2020-08-26T15:24:23Z'>
 		&lt;denchmark-link:https://github.com/lezwon&gt;@lezwon&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
  mind taking a look at this?
 		</comment>
 		<comment id='2' author='VirajBagal' date='2020-08-26T15:41:59Z'>
 		&lt;denchmark-link:https://github.com/VirajBagal&gt;@VirajBagal&lt;/denchmark-link&gt;
  could you share the notebook?
 		</comment>
 		<comment id='3' author='VirajBagal' date='2020-08-26T16:32:46Z'>
 		&lt;denchmark-link:https://github.com/lezwon&gt;@lezwon&lt;/denchmark-link&gt;
  Due to some privacy issues, I can't share it publicly here. I have shared it with you on Kaggle. Please check the "Shared With You" tab on Kaggle.
 		</comment>
 		<comment id='4' author='VirajBagal' date='2020-08-26T16:46:24Z'>
 		Sure.. Will do üòäüëç
 		</comment>
 		<comment id='5' author='VirajBagal' date='2020-08-28T17:42:29Z'>
 		It seems xla does not support the  operation on 1-dimensional tensors. &lt;denchmark-link:https://github.com/zcain117&gt;@zcain117&lt;/denchmark-link&gt;
  could you help us out?  seems to be throwing the error mentioned when called. PyTorch usually returns 1d tensors as is.
 		</comment>
 	</comments>
 </bug>
<commit id='3910ad033074367f6abfe0001562db725a75cb73' author='Lezwon Castelino' date='2020-09-01 09:17:52-04:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.07407407407407407'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\callbacks\early_stopping.py' new_name='pytorch_lightning\callbacks\early_stopping.py'>
 		<file_info nloc='180' complexity='36' token_count='966'></file_info>
 		<method name='_stop_distributed_training' parameters='self,trainer,pl_module'>
 				<method_info nloc='11' complexity='4' token_count='133' nesting_level='1' start_line='221' end_line='234'></method_info>
 			<added_lines>232</added_lines>
 			<deleted_lines>232</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\step_result.py' new_name='pytorch_lightning\core\step_result.py'>
 		<file_info nloc='511' complexity='129' token_count='3308'></file_info>
 		<method name='weighted_mean' parameters='result,weights'>
 				<method_info nloc='5' complexity='1' token_count='58' nesting_level='0' start_line='846' end_line='850'></method_info>
 			<added_lines>848</added_lines>
 			<deleted_lines>846</deleted_lines>
 		</method>
 		<method name='__copy__' parameters='self'>
 				<method_info nloc='7' complexity='3' token_count='52' nesting_level='1' start_line='299' end_line='305'></method_info>
 			<added_lines>302,303</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\test_tpu.py' new_name='tests\models\test_tpu.py'>
 		<file_info nloc='203' complexity='15' token_count='1297'></file_info>
 		<method name='test_result_obj_on_tpu' parameters='tmpdir'>
 				<method_info nloc='25' complexity='1' token_count='127' nesting_level='0' start_line='248' end_line='276'></method_info>
 			<added_lines>248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>7,244,245,246,247</added_lines>
 			<deleted_lines>7</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
