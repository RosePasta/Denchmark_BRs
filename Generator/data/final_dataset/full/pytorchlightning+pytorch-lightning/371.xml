<bug_data>
<bug id='371' author='hvy' open_date='2019-10-15T07:50:40Z' closed_time='2019-10-18T08:18:06Z'>
 	<summary>Number of batches is off-by-one during training</summary>
 	<description>
 Describe the bug
 The number of mini batches iterated over during an epoch seems to be off-by-one during training when passing a train_percent_check &lt; 1.0. More specifically, it trains for one additional iteration.
 The operator in this line should probably be changed from  to .
 &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L1130&gt;https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L1130&lt;/denchmark-link&gt;
 
 Evaluation by the way seems correct as seen in the following code.
 &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L614&gt;https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L614&lt;/denchmark-link&gt;
 
 This leads to unexpected behaviors in e.g. EarlyStopping since the log that it's given is the callback log from the training and not the evaluation (the additional iteration overwrites the evaluation log with the training log).
 To Reproduce
 
 Specify some train_percent_check &lt; 1.0 e.g 0.5.
 Fit.
 Notice that it trains for an additional iteration.
 
 Expected behavior
 It should not train for that additional iteration.
 	</description>
 	<comments>
 		<comment id='1' author='hvy' date='2019-10-16T13:58:13Z'>
 		are you sure itâ€™s not a rounding error?
 If it is indeed an error, want to take a stab at a PR?
 		</comment>
 	</comments>
 </bug>
<commit id='0fac2d64cf4c6c31d3b21605a272ace01d0c51a2' author='Hiroyuki Vincent Yamazaki' date='2019-10-18 10:18:05+02:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\trainer.py' new_name='pytorch_lightning\trainer\trainer.py'>
 		<file_info nloc='924' complexity='284' token_count='5795'></file_info>
 		<method name='run_training_epoch' parameters='self'>
 				<method_info nloc='33' complexity='19' token_count='255' nesting_level='1' start_line='1114' end_line='1173'></method_info>
 			<added_lines>1131</added_lines>
 			<deleted_lines>1131</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
