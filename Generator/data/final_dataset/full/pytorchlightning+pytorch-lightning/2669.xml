<bug_data>
<bug id='2669' author='ananyahjha93' open_date='2020-07-22T09:29:05Z' closed_time='2020-07-24T08:26:06Z'>
 	<summary>--gpus flag with add_argparse_args bug</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 When using
 &lt;denchmark-code&gt;parser = Trainer.add_argparse_args(parser)
 args = parser.parse_args()
 
 trainer = Trainer.from_argparse_args(args)
 &lt;/denchmark-code&gt;
 
 if the user does not provide the --gpus flag, the code allocates some memory on the GPU and reports
 GPU available: True, used: True
 but does not use this GPU. This issue has been discovered in bolts:
 
 PyTorchLightning/pytorch-lightning-bolts#35
 PyTorchLightning/pytorch-lightning-bolts#124
 
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Steps to reproduce the behavior:
 Use the following method to create the trainer object
 &lt;denchmark-code&gt;parser = Trainer.add_argparse_args(parser)
 args = parser.parse_args()
 
 trainer = Trainer.from_argparse_args(args)
 &lt;/denchmark-code&gt;
 
 and don't pass the --gpus flag.
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 If --gpus flag is not provided in the script call, then Lightning should report
 GPU available: True, used: False
 with a warning, and not allocate any memory on the GPU. This way, the user can set the --gpus flag if they have missed out on it.
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='6780214b27e6ebace9cf38b6f5701224204e28ad' author='Ananya Harsh Jha' date='2020-07-24 08:26:05+00:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\distrib_data_parallel.py' new_name='pytorch_lightning\trainer\distrib_data_parallel.py'>
 		<file_info nloc='473' complexity='113' token_count='2328'></file_info>
 		<method name='set_distributed_mode' parameters='self,distributed_backend'>
 				<method_info nloc='58' complexity='28' token_count='336' nesting_level='1' start_line='247' end_line='314'></method_info>
 			<added_lines>313,314</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>315</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\trainer.py' new_name='pytorch_lightning\trainer\trainer.py'>
 		<file_info nloc='1143' complexity='137' token_count='4848'></file_info>
 		<modified_lines>
 			<added_lines>533,534</added_lines>
 			<deleted_lines>466,467</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
