<bug_data>
<bug id='537' author='VSJMilewski' open_date='2019-11-21T15:44:20Z' closed_time='2019-12-09T12:42:07Z'>
 	<summary>Summary not working for model on GPU with multiple inputs</summary>
 	<description>
 Describe the bug
 When you want a summary for a model that requires multiple input parameters for forward, then this doesn't work. You can set self.example_input_array to be a tuple and there is some code for passing this to the forward method. However, if the model is on cuda, it tries to pass to move this input directly to cuda without a check whether it is a tuple or list.
 the line with the error is here:
 &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/7324dd902b8d071f4889ab1274a4d4dc09de9a78/pytorch_lightning/root_module/memory.py#L53&gt;pytorch-lightning/blob/master/pytorch_lightning/root_module/memory.py#L53&lt;/denchmark-link&gt;
 
 example of how it should be checked:
 &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/7324dd902b8d071f4889ab1274a4d4dc09de9a78/pytorch_lightning/root_module/memory.py#L61&gt;pytorch-lightning/blob/master/pytorch_lightning/root_module/memory.py#L61&lt;/denchmark-link&gt;
 
 To Reproduce
 Steps to reproduce the behavior:
 
 create a model that requires multiple inputs in the forward method.
 set self.example_input_array to be a tuple
 run the model on GPU
 
 Expected behavior
 a list with all layers and the input and output shapes of these layers.
 
 &lt;denchmark-link:https://user-images.githubusercontent.com/6348139/69352469-4bc70180-0c7d-11ea-88c6-8056ab531c80.png&gt;&lt;/denchmark-link&gt;
 
 Desktop (please complete the following information):
 
 OS: Linux Mint 19.2
 Browser chrome
 Version 8.0.3904.97 (Official Build) (64-bit)
 
 	</description>
 	<comments>
 		<comment id='1' author='VSJMilewski' date='2019-11-25T11:26:29Z'>
 		@victormilewski1994 good point. I guess we didn't specifically design the summarizer to take in multiple inputs. Would you be interested in submitting a PR?
 		</comment>
 	</comments>
 </bug>
<commit id='d562172b4cd363b86f9d670120932cd333b03cf5' author='VSJMilewski' date='2019-12-09 04:42:07-08:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\memory.py' new_name='pytorch_lightning\core\memory.py'>
 		<file_info nloc='178' complexity='56' token_count='1256'></file_info>
 		<method name='get_variable_sizes' parameters='self'>
 				<method_info nloc='44' complexity='16' token_count='333' nesting_level='1' start_line='45' end_line='100'></method_info>
 			<added_lines>53,54,55,56,57,58,59,62,63,64,65,66,67,72,77,89</added_lines>
 			<deleted_lines>53,56,61,66,78</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
