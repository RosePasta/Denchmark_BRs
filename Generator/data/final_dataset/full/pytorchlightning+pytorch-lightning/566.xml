<bug_data>
<bug id='566' author='iamsimha' open_date='2019-12-02T11:24:36Z' closed_time='2019-12-04T12:04:59Z'>
 	<summary>Using print_nan_grads in the Trainer results in an error</summary>
 	<description>
 Describe the bug
 When using
 &lt;denchmark-code&gt;print_nan_grads=True
 &lt;/denchmark-code&gt;
 
 in the Trainer, I am getting the error below.
 trainer.fit(lstm_model)
 File "/Users/anaconda3/envs/snorkel/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py", line 364, in fit
 self.run_pretrain_routine(model)
 File "/Users/anaconda3/envs/snorkel/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py", line 471, in run_pretrain_routine
 self.train()
 File "/Users/anaconda3/envs/snorkel/lib/python3.6/site-packages/pytorch_lightning/trainer/train_loop_mixin.py", line 60, in train
 self.run_training_epoch()
 File "/Users/anaconda3/envs/snorkel/lib/python3.6/site-packages/pytorch_lightning/trainer/train_loop_mixin.py", line 99, in run_training_epoch
 output = self.run_training_batch(batch, batch_nb)
 File "/Users/anaconda3/envs/snorkel/lib/python3.6/site-packages/pytorch_lightning/trainer/train_loop_mixin.py", line 219, in run_training_batch
 self.print_nan_gradients()
 File "/Users/anaconda3/envs/snorkel/lib/python3.6/site-packages/pytorch_lightning/trainer/training_tricks_mixin.py", line 16, in print_nan_gradients
 if torch.isnan(param.grad.float()).any():
 AttributeError: 'NoneType' object has no attribute 'float'
 To Reproduce
 Steps to reproduce the behavior:
 If some param object, does not have .grad, then that object should not be checked for nans
 	</description>
 	<comments>
 		<comment id='1' author='iamsimha' date='2019-12-03T06:40:52Z'>
 		sounds like an easy fix: iterate only over params where grad is not None. Would that solve the issue?
 		</comment>
 		<comment id='2' author='iamsimha' date='2019-12-03T12:57:28Z'>
 		exactly. Anyone want to submit the PR?
 		</comment>
 	</comments>
 </bug>
<commit id='d4571d1d6f524b0b9284e84ea8f95bb8eb656c86' author='Ir1dXD' date='2019-12-04 07:04:58-05:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_tricks_mixin.py' new_name='pytorch_lightning\trainer\training_tricks_mixin.py'>
 		<file_info nloc='22' complexity='9' token_count='172'></file_info>
 		<method name='print_nan_gradients' parameters='self'>
 				<method_info nloc='5' complexity='4' token_count='58' nesting_level='1' start_line='13' end_line='17'></method_info>
 			<added_lines>16</added_lines>
 			<deleted_lines>16</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
