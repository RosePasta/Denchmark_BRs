<bug_data>
<bug id='2444' author='NumesSanguis' open_date='2020-07-01T08:42:24Z' closed_time='2020-08-28T07:07:44Z'>
 	<summary>self.hparam silently removes params that are not serializable</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 Following the approach found under &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/hyperparameters.html#lightningmodule-hyperparameters&gt;hyperparameters in the docs&lt;/denchmark-link&gt;
 , step 3, I passed a dict with parameters to my .
 In the  printing  shows all contents I passed.
 However, in the function , some hparams are gone.
 This might be related to that not all param values are YAML serializable, and therefore automatically removed? Because the 2 removed params are "criterion": torch.nn.BCELoss() and "optimizer": partial(optim.Adam, lr=0.001).
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Steps to reproduce the behavior:
 
 Run the following script:
 
 from functools import partial
 import torch
 import torch.optim as optim
 from torch.utils.data import Dataset
 import pytorch_lightning as pl
 from pytorch_lightning import Trainer
 
 # partial to give all params, except the data
 hparams = {
     "criterion": torch.nn.BCELoss(),  # F.cross_entropy(),  # loss function
     "optimizer": partial(optim.Adam, lr=0.001),  # (lr=0.001),
     # "learning_rate": 0.001,
     "filters": 64,
     "layers": 2
 }
 
 class EmptyDataset(Dataset):
     def __init__(self, transform=None):
         pass
     
     def __len__(self):
         return 32
     
     def __getitem__(self, idx):
         return {"input": np.array([1]), "output": "nothing"}
 
 class LitLake(pl.LightningModule):
     def __init__(self, hparams: dict, transforms: dict = None):
         super().__init__()
         
         self.hparams = hparams
         print("self.hparams\n", self.hparams)
         
     def forward(self, x):
         pass
     
     def training_step(self, batch, batch_idx):
         """
         Lightning calls this inside the training loop with the data from the training dataloader
         passed in as `batch`.
         """
         # forward pass
         x, y = batch
         y_hat = self(x)
         loss = self.hparams["criterion"](y_hat, y)
         tensorboard_logs = {'train_loss': loss}
         return {'loss': loss, 'log': tensorboard_logs}
         
     def configure_optimizers(self):
         print("self.hparams\n", self.hparams)
         optimizer = self.hparams["optimizer"](self.parameters())
         scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)
         return [optimizer], [scheduler]
     
     def train_dataloader(self):
          return DataLoader(EmptyDataset(), batch_size=4, num_workers=1)
 
 model = LitLake(hparams=hparams)
 # most basic trainer, uses good defaults
 trainer = Trainer()  # gpus=1, num_nodes=1
 trainer.fit(model)  # KeyError: 'optimizer'
 
 See error
 
 Script output (CLICK ME)
 
 self.hparams
  "criterion": BCELoss()
 "filters":   64
 "layers":    2
 "optimizer": functools.partial(&lt;class 'torch.optim.adam.Adam'&gt;, lr=0.001)
 GPU available: True, used: False
 TPU available: False, using: 0 TPU cores
 self.hparams
  "filters": 64
 "layers":  2
 Traceback (most recent call last):
   File "lightning_hparams_bug.py", line 61, in &lt;module&gt;
     trainer.fit(model)  # KeyError: 'optimizer'
   File "/home/*user*/anaconda3/envs/onseilake/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 965, in fit
     self.optimizers, self.lr_schedulers, self.optimizer_frequencies = self.init_optimizers(model)
   File "/home/*user*/anaconda3/envs/onseilake/lib/python3.7/site-packages/pytorch_lightning/trainer/optimizers.py", line 18, in init_optimizers
     optim_conf = model.configure_optimizers()
   File "lightning_hparams_bug.py", line 51, in configure_optimizers
     optimizer = self.hparams["optimizer"](self.parameters())
 KeyError: 'optimizer'
 
 
 &lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 Either:
 
 self.hparams keeping the non-serializable parameters (will give problems with loading?)
 Throw an error explaining why those param values are not acceptable and how to approach it, instead of silently removing them.
 
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 
 PyTorch Version (e.g., 1.0): 1.5.0
 OS (e.g., Linux): Ubuntu 18.04
 How you installed PyTorch (conda, pip, source): conda
 Build command you used (if compiling from source): -
 Python version: 3.7.6
 CUDA/cuDNN version: 10.2
 GPU models and configuration: 1x GeForce GTX 1080 Ti
 Any other relevant information: -
 
 &lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;
 
 Bug reproduced by &lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='NumesSanguis' date='2020-07-01T19:13:22Z'>
 		Happens to me too. I'm also waiting for this fix, since i really want to use the new feature to put anything in hparams.
 		</comment>
 		<comment id='2' author='NumesSanguis' date='2020-07-02T16:33:19Z'>
 		&lt;denchmark-link:https://github.com/dscarmo&gt;@dscarmo&lt;/denchmark-link&gt;
  you can take it over and send a PR :] or I ll check it tomorrow...
 		</comment>
 		<comment id='3' author='NumesSanguis' date='2020-08-04T19:29:05Z'>
 		Need to add warning about this.
 		</comment>
 		<comment id='4' author='NumesSanguis' date='2020-08-18T23:14:11Z'>
 		&lt;denchmark-link:https://github.com/awaelchli&gt;@awaelchli&lt;/denchmark-link&gt;
  this should be fixed with PR, right?
 		</comment>
 		<comment id='5' author='NumesSanguis' date='2020-08-18T23:19:45Z'>
 		&lt;denchmark-link:https://github.com/edenlightning&gt;@edenlightning&lt;/denchmark-link&gt;
  yes the linked PR solves this.
 		</comment>
 	</comments>
 </bug>
<commit id='d5254ff9dfb67fba388de224a320f3a562561a80' author='monney' date='2020-08-28 09:07:43+02:00'>
 	<dmm_unit complexity='1.0' interfacing='0.6' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\utilities\__init__.py' new_name='pytorch_lightning\utilities\__init__.py'>
 		<file_info nloc='20' complexity='0' token_count='127'></file_info>
 		<modified_lines>
 			<added_lines>9</added_lines>
 			<deleted_lines>9</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\utilities\parsing.py' new_name='pytorch_lightning\utilities\parsing.py'>
 		<file_info nloc='141' complexity='41' token_count='792'></file_info>
 		<method name='clean_namespace' parameters='hparams'>
 				<method_info nloc='8' complexity='5' token_count='60' nesting_level='0' start_line='55' end_line='66'></method_info>
 			<added_lines>56,58,60,61,62,63,64,65,66</added_lines>
 			<deleted_lines>55,56,57,58,59,60,61</deleted_lines>
 		</method>
 		<method name='is_picklable' parameters='object'>
 				<method_info nloc='7' complexity='2' token_count='27' nesting_level='0' start_line='45' end_line='52'></method_info>
 			<added_lines>45,46,47,48,49,50,51,52</added_lines>
 			<deleted_lines>46,47,48,49,50,51,52</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>16,20,21,53,54</added_lines>
 			<deleted_lines>43,53,54</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\test_hparams.py' new_name='tests\models\test_hparams.py'>
 		<file_info nloc='318' complexity='55' token_count='2584'></file_info>
 		<method name='test_hparams_pickle_warning' parameters='tmpdir'>
 				<method_info nloc='6' complexity='1' token_count='47' nesting_level='0' start_line='425' end_line='430'></method_info>
 			<added_lines>425,426,427,428,429,430</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_collect_init_arguments' parameters='tmpdir,cls'>
 				<method_info nloc='29' complexity='7' token_count='272' nesting_level='0' start_line='251' end_line='293'></method_info>
 			<added_lines>285</added_lines>
 			<deleted_lines>285</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,foo,pickle_me'>
 				<method_info nloc='4' complexity='1' token_count='43' nesting_level='1' start_line='419' end_line='422'></method_info>
 			<added_lines>419,420,421,422</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>14,416,417,418,423,424,431,432</added_lines>
 			<deleted_lines>14</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
