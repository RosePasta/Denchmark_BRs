<bug_data>
<bug id='189' author='ExpectationMax' open_date='2019-09-03T15:48:23Z' closed_time='2019-09-05T02:31:13Z'>
 	<summary>Logging of GPU memory utilization can significantly slow down training</summary>
 	<description>
 When training using GPUs pytorch_lightning automatically logs the GPU memory utilization during training. This is a useful feature, but can severely impact performance dependent on the speed of the nvidia-smi call.
 On our particular cluster (University-scale hpc cluster based on IBM LSF), this leads to a performance decrease of almost 10 fold when training on GPU vs. CPU.
 Describe the bug
 Logging of GPU memory can have a severe impact on training performance.
 
 Remove gpu memory logging by commenting out the lines 937 to 939 in pytorch_lightning/models/trainer.py
 &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/models/trainer.py#L937-L939&gt;see here&lt;/denchmark-link&gt;
 
 Expected behavior
 Logging of GPU memory utilization should not impede performance (by running the nvidia-smi call in the background) or it should at least be possible to deactivate it in case performance issues arise.
 Desktop (please complete the following information):
 
 OS: Ubuntu Linux 16.04, NVIDIA Geforce GTX 1080
 
 	</description>
 	<comments>
 		<comment id='1' author='ExpectationMax' date='2019-09-05T02:31:12Z'>
 		merged
 		</comment>
 	</comments>
 </bug>
<commit id='dac41030d48acbfecdf7c083b8e7b00f3fd9be06' author='Max Horn' date='2019-09-04 10:43:46-04:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='docs\Trainer\Logging.md' new_name='docs\Trainer\Logging.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>17,18,19,20,21,22,23,24</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\models\trainer.py' new_name='pytorch_lightning\models\trainer.py'>
 		<file_info nloc='730' complexity='196' token_count='4660'></file_info>
 		<method name='__init__' parameters='self,experiment,early_stop_callback,checkpoint_callback,gradient_clip,cluster,process_position,current_gpu_name,nb_gpu_nodes,gpus,log_gpu_memory,show_progress_bar,overfit_pct,track_grad_norm,check_val_every_n_epoch,fast_dev_run,accumulate_grad_batches,max_nb_epochs,min_nb_epochs,train_percent_check,val_percent_check,test_percent_check,val_check_interval,log_save_interval,add_log_row_interval,distributed_backend,use_amp,print_nan_grads,print_weights_summary,amp_level,nb_sanity_val_steps'>
 				<method_info nloc='31' complexity='1' token_count='136' nesting_level='1' start_line='56' end_line='86'></method_info>
 			<added_lines>66</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='run_tng_epoch' parameters='self'>
 				<method_info nloc='45' complexity='22' token_count='341' nesting_level='1' start_line='892' end_line='969'></method_info>
 			<added_lines>942</added_lines>
 			<deleted_lines>937</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>98,99,100,125</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
