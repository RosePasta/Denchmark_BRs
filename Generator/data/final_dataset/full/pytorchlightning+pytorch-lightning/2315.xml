<bug_data>
<bug id='2315' author='elias-ramzi' open_date='2020-06-22T13:25:26Z' closed_time='2020-06-26T13:33:36Z'>
 	<summary>Bug in average_precision Metric</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 Hi everyone, I encountered a bug when using the average_precision metric (pytorch_lightning.metrics.functional.classification). It yields incorrect results (negative ones).
 There seems to be a missing parenthesis in the code here :
 &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/metrics/functional/classification.py#L847&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/metrics/functional/classification.py#L847&lt;/denchmark-link&gt;
 
 It works when corrected as :
 return -torch.sum((recall[1:] - recall[:-1]) * precision[:-1])
 In order to reproduce negative results :
 &lt;denchmark-code&gt;import torch
 import pytorch_lightning.metrics.functional.classification as M
 
 torch.manual_seed(23)
 truth = (torch.rand(100) &gt; .6)
 pred = torch.rand(100)
 
 M.average_precision(pred, truth)
 &lt;/denchmark-code&gt;
 
 I did not find an issue on this topic yet. If needed I can submit a PR.
 Thanks ‚ò∫Ô∏è
 	</description>
 	<comments>
 		<comment id='1' author='elias-ramzi' date='2020-06-22T13:26:06Z'>
 		Hi! thanks for your contribution!, great first issue!
 		</comment>
 		<comment id='2' author='elias-ramzi' date='2020-06-22T14:58:38Z'>
 		I'd like to fix it
 		</comment>
 		<comment id='3' author='elias-ramzi' date='2020-06-22T18:22:07Z'>
 		Hi, I have already created a branch for the PR !
 		</comment>
 		<comment id='4' author='elias-ramzi' date='2020-06-22T20:10:01Z'>
 		Thanks for the issue and the fix! &lt;denchmark-link:https://github.com/InCogNiTo124&gt;@InCogNiTo124&lt;/denchmark-link&gt;
  Just saying- there are many other open issues if you want to take a stab at :)
 		</comment>
 	</comments>
 </bug>
<commit id='92f122e0df7e233f3a8b7873c7294155afbbf852' author='elias-ramzi' date='2020-06-23 13:21:00+02:00'>
 	<dmm_unit complexity='0.0' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>23,24</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\metrics\functional\classification.py' new_name='pytorch_lightning\metrics\functional\classification.py'>
 		<file_info nloc='786' complexity='33' token_count='3087'></file_info>
 		<modified_lines>
 			<added_lines>847</added_lines>
 			<deleted_lines>847</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\metrics\functional\test_classification.py' new_name='tests\metrics\functional\test_classification.py'>
 		<file_info nloc='301' complexity='22' token_count='4583'></file_info>
 		<method name='test_average_precision_constant_values' parameters=''>
 				<method_info nloc='5' complexity='1' token_count='47' nesting_level='0' start_line='345' end_line='356'></method_info>
 			<added_lines>345,352,353,354,355,356</added_lines>
 			<deleted_lines>345,348,350,351,353,356</deleted_lines>
 		</method>
 		<method name='test_average_precision' parameters='scores,target,expected_score'>
 				<method_info nloc='2' complexity='1' token_count='18' nesting_level='0' start_line='356' end_line='357'></method_info>
 			<added_lines>356,357</added_lines>
 			<deleted_lines>356</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
