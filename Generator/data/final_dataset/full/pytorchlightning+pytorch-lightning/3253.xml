<bug_data>
<bug id='3253' author='ShomyLiu' open_date='2020-08-29T09:06:08Z' closed_time='2020-09-03T10:27:33Z'>
 	<summary>**gather_all_tensors_if_available**  share the same underlying storage for all GPUs</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 Hi, one of new features in   &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2528&gt;#2528&lt;/denchmark-link&gt;
   has a   copy bug,  and this would lead that tensors in all GPUs  are the wrongly same as one GPU,  since they share the same storage:
 &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/metrics/converters.py#L304&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/metrics/converters.py#L304&lt;/denchmark-link&gt;
 
 &lt;denchmark-code&gt;gathered_result = world_size * [torch.zeros_like(result)]
 &lt;/denchmark-code&gt;
 
 change into:
 &lt;denchmark-code&gt;gathered_result = [torch.zeros_like(result) for _ in range(world_size)]
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='ShomyLiu' date='2020-09-01T14:53:57Z'>
 		&lt;denchmark-link:https://github.com/justusschock&gt;@justusschock&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='ShomyLiu' date='2020-09-01T15:21:15Z'>
 		&lt;denchmark-link:https://github.com/ShomyLiu&gt;@ShomyLiu&lt;/denchmark-link&gt;
  good catch, would you be up for sending a PR? Please, note that the function is not used anywhere yet, but are there for future changes to the metric package.
 		</comment>
 		<comment id='3' author='ShomyLiu' date='2020-09-01T15:31:27Z'>
 		&lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
   it's my pleasure for a PR. I will finish this as soon as possible.
 Yeah, it's a new function to wrap the torch.distributed.all_gather.  But I think it is a very common use case;  especially, when using DDP mode, we always need to gather all the outputs cross all the GPUs.
 		</comment>
 		<comment id='4' author='ShomyLiu' date='2020-09-01T15:35:57Z'>
 		&lt;denchmark-link:https://github.com/ShomyLiu&gt;@ShomyLiu&lt;/denchmark-link&gt;
  Yes, I agree that it is a common use case.
 Please ping me when PR is ready.
 		</comment>
 		<comment id='5' author='ShomyLiu' date='2020-09-02T04:47:06Z'>
 		&lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
   Hi, I have sent a PR jus now for your review   &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3319&gt;#3319&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='d521c1b1787930dd4f6375a3c61a25579ca59ee5' author='HT Liu' date='2020-09-03 12:27:32+02:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\metrics\converters.py' new_name='pytorch_lightning\metrics\converters.py'>
 		<file_info nloc='295' complexity='32' token_count='1068'></file_info>
 		<modified_lines>
 			<added_lines>304</added_lines>
 			<deleted_lines>304</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\metrics\test_converters.py' new_name='tests\metrics\test_converters.py'>
 		<file_info nloc='183' complexity='56' token_count='1441'></file_info>
 		<method name='test_gather_all_tensors_ddp' parameters=''>
 				<method_info nloc='5' complexity='1' token_count='35' nesting_level='0' start_line='180' end_line='186'></method_info>
 			<added_lines>180,181,182,183,184,185,186</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_ddp_test_gather_all_tensors' parameters='rank,worldsize'>
 				<method_info nloc='7' complexity='3' token_count='69' nesting_level='0' start_line='138' end_line='146'></method_info>
 			<added_lines>138,139,140,141,142,143,144,145,146</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>18,147,148,179,187,188</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
