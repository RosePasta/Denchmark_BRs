<bug_data>
<bug id='3778' author='carmocca' open_date='2020-10-01T22:03:07Z' closed_time='2020-10-04T21:10:26Z'>
 	<summary>training_step log requires that tbptt_reduce_fx is also set</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 training_step log requires that tbptt_reduce_fx is also set.
 &lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;
 
 def training_step(self, batch, batch_idx):
     ...
     self.log("train_loss", loss, on_step=False, on_epoch=True, sync_dist=True)
     self.log(
         "foo",
         torch.tensor(self.current_epoch),
         on_step=False,
         on_epoch=True,
         reduce_fx=max,
         #tbptt_reduce_fx=max, ERROR when commented
     )
     return loss
 
 def validation_step(self, batch, batch_idx):
     # No issues here
     self.log(
         "bar",
         torch.tensor(self.global_step),
         on_step=False,
         on_epoch=True,
         reduce_fx=max,
     )
 Error:
 &lt;denchmark-code&gt;time_outputs = [{'tr_loss': tensor(6.2107), 'foo': tensor(0), 'minimize': tensor(6.2107)}]
 
     @classmethod
     def reduce_across_time(cls, time_outputs):
         # auto-reduce across time for tbptt
         meta = time_outputs[0]['meta']
     
         # in 1.0 the results have 'extra'. Once we deprecate 0.10.0 we may not need this
         if 'extra' in time_outputs[0]:
             [x.pop('extra', None) for x in time_outputs]
     
         result = cls()
         result = recursive_gather(time_outputs, result)
         recursive_stack(result)
     
         for k, value in result.items():
             if k in ['meta', 'extra']:
                 continue
     
             # pick the reduce fx
             if k in ['checkpoint_on', 'early_stop_on', 'minimize']:
                 tbptt_reduce_fx = torch.mean
             else:
                 tbptt_reduce_fx = meta[k]['tbptt_reduce_fx']
 &gt;           result[k] = tbptt_reduce_fx(value)
 E           RuntimeError: Can only calculate the mean of floating types. Got Long instead.
 
 ../../venv/lib/python3.8/site-packages/pytorch_lightning/core/step_result.py:423: RuntimeError
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 That tbptt_reduce_fx is not required
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 Master @ commit &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/commit/8be002ccc7c2e8371ab426ea07c953f72747269e&gt;8be002c&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='carmocca' date='2020-10-02T13:01:25Z'>
 		good catch. yeah, that's a bug.
 want to submit a PR?
 		</comment>
 		<comment id='2' author='carmocca' date='2020-10-02T14:31:12Z'>
 		I am not familiar with the tbptt logic, so maybe its better someone else does it.
 I'll create a PR with the failing test so somebody can work on it.
 		</comment>
 		<comment id='3' author='carmocca' date='2020-12-22T23:48:14Z'>
 		What the hell is this tbptt, this looks crazy specific, why is this necessary? Why not keep things simple?
 		</comment>
 	</comments>
 </bug>
<commit id='89cc12311f5eaa7860d66bce9bfe3d93255f35b6' author='Carlos Mochol√≠' date='2020-10-04 17:10:25-04:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\step_result.py' new_name='pytorch_lightning\core\step_result.py'>
 		<file_info nloc='534' complexity='137' token_count='3429'></file_info>
 		<method name='reduce_across_time' parameters='cls,time_outputs'>
 				<method_info nloc='17' complexity='6' token_count='124' nesting_level='1' start_line='402' end_line='426'></method_info>
 			<added_lines>423</added_lines>
 			<deleted_lines>423</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\trainer\logging\test_train_loop_logging_1_0.py' new_name='tests\trainer\logging\test_train_loop_logging_1_0.py'>
 		<file_info nloc='195' complexity='14' token_count='1352'></file_info>
 		<method name='test__training_step__log_max_reduce_fx' parameters='tmpdir,batches,fx,result'>
 				<method_info nloc='15' complexity='1' token_count='76' nesting_level='0' start_line='249' end_line='277'></method_info>
 			<added_lines>249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test__training_step__log_max_reduce_fx.validation_step' parameters='self,batch,batch_idx'>
 				<method_info nloc='5' complexity='1' token_count='62' nesting_level='2' start_line='259' end_line='263'></method_info>
 			<added_lines>259,260,261,262,263</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test__training_step__log_max_reduce_fx.training_step' parameters='self,batch,batch_idx'>
 				<method_info nloc='4' complexity='1' token_count='51' nesting_level='2' start_line='254' end_line='257'></method_info>
 			<added_lines>254,255,256,257</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>9,10,11,246,247,248</added_lines>
 			<deleted_lines>4,5</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
