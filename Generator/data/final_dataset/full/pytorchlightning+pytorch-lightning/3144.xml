<bug_data>
<bug id='3144' author='lezwon' open_date='2020-08-25T03:35:04Z' closed_time='2020-08-26T16:22:20Z'>
 	<summary>ONNX model does not save on GPU</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 Attempting to export on ONNX after training model on GPU, throws an error is the input_sample or example_input_array is not a CUDA tensor.
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Steps to reproduce the behavior:
 
 Train a model on GPU
 Try to export to ONNX when  self.example_input_array = torch.zeros(1, 1, 500, 500) or input_sample = torch.zeros(1, 1, 500, 500)
 
 &lt;denchmark-code&gt;---------------------------------------------------------------------------
 RuntimeError                              Traceback (most recent call last)
 &lt;ipython-input-32-cd8009a0b6a3&gt; in &lt;module&gt;
       1 filepath = 'model.onnx'
 ----&gt; 2 model.to_onnx(filepath, export_params=True)
 
 /opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py in to_onnx(self, file_path, input_sample, **kwargs)
    1721         if 'example_outputs' not in kwargs:
    1722             self.eval()
 -&gt; 1723             kwargs['example_outputs'] = self(input_data)
    1724 
    1725         torch.onnx.export(self, input_data, file_path, **kwargs)
 
 /opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
     548             result = self._slow_forward(*input, **kwargs)
     549         else:
 --&gt; 550             result = self.forward(*input, **kwargs)
     551         for hook in self._forward_hooks.values():
     552             hook_result = hook(self, input, result)
 
 &lt;ipython-input-24-51cae3b5e57f&gt; in forward(self, inputs)
      20 
      21     def forward(self, inputs):
 ---&gt; 22         return self.model(inputs)
      23 
      24     def training_step(self, batch, batch_idx):
 
 /opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
     548             result = self._slow_forward(*input, **kwargs)
     549         else:
 --&gt; 550             result = self.forward(*input, **kwargs)
     551         for hook in self._forward_hooks.values():
     552             hook_result = hook(self, input, result)
 
 /opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py in forward(self, input)
      98     def forward(self, input):
      99         for module in self:
 --&gt; 100             input = module(input)
     101         return input
     102 
 
 /opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
     548             result = self._slow_forward(*input, **kwargs)
     549         else:
 --&gt; 550             result = self.forward(*input, **kwargs)
     551         for hook in self._forward_hooks.values():
     552             hook_result = hook(self, input, result)
 
 /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py in forward(self, input)
     351 
     352     def forward(self, input):
 --&gt; 353         return self._conv_forward(input, self.weight)
     354 
     355 class Conv3d(_ConvNd):
 
 /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py in _conv_forward(self, input, weight)
     348                             _pair(0), self.dilation, self.groups)
     349         return F.conv2d(input, weight, self.bias, self.stride,
 --&gt; 350                         self.padding, self.dilation, self.groups)
     351 
     352     def forward(self, input):
 
 RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;
 
 filepath = 'model.onnx'
 model.to_onnx(filepath, export_params=True)
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 Should automatically convert example_input_array or input_sample to the device type and save the model to ONNX.
 	</description>
 	<comments>
 		<comment id='1' author='lezwon' date='2020-08-25T07:09:53Z'>
 		I would say that the problem could be the distributed way, mind check running only on a single GPU?
 		</comment>
 		<comment id='2' author='lezwon' date='2020-08-25T09:31:24Z'>
 		I ran this on Kaggle notebook. When I tried to save after training, it threw the error.
 		</comment>
 	</comments>
 </bug>
<commit id='d9ea25590e95ca9e70401123a0f1f59de711e2ff' author='Lezwon Castelino' date='2020-08-26 16:22:19+00:00'>
 	<dmm_unit complexity='1.0' interfacing='0.75' size='0.2916666666666667'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>29,30</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='pytorch_lightning\core\lightning.py' new_name='pytorch_lightning\core\lightning.py'>
 		<file_info nloc='1480' complexity='100' token_count='2334'></file_info>
 		<method name='to_onnx' parameters='self,str,None,kwargs'>
 				<method_info nloc='17' complexity='5' token_count='120' nesting_level='1' start_line='1689' end_line='1730'></method_info>
 			<added_lines>1719,1720,1721,1722,1723,1724,1727,1728</added_lines>
 			<deleted_lines>1719,1720,1723</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\models\test_onnx.py' new_name='tests\models\test_onnx.py'>
 		<file_info nloc='97' complexity='11' token_count='816'></file_info>
 		<method name='test_if_inference_output_is_valid' parameters='tmpdir'>
 				<method_info nloc='14' complexity='1' token_count='139' nesting_level='0' start_line='118' end_line='141'></method_info>
 			<added_lines>128</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_error_if_no_input' parameters='tmpdir'>
 				<method_info nloc='7' complexity='1' token_count='49' nesting_level='0' start_line='97' end_line='104'></method_info>
 			<added_lines>101,102,103</added_lines>
 			<deleted_lines>102</deleted_lines>
 		</method>
 		<method name='test_model_saves_with_input_sample' parameters='tmpdir'>
 				<method_info nloc='9' complexity='1' token_count='81' nesting_level='0' start_line='14' end_line='24'></method_info>
 			<added_lines>20,21,22,23,24</added_lines>
 			<deleted_lines>20</deleted_lines>
 		</method>
 		<method name='test_error_if_input_sample_is_not_tensor' parameters='tmpdir'>
 				<method_info nloc='8' complexity='1' token_count='65' nesting_level='0' start_line='107' end_line='115'></method_info>
 			<added_lines>107,108,109,110,111,112,113,114,115</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_verbose_param' parameters='tmpdir,capsys'>
 				<method_info nloc='6' complexity='1' token_count='48' nesting_level='0' start_line='88' end_line='94'></method_info>
 			<added_lines>91</added_lines>
 			<deleted_lines>88</deleted_lines>
 		</method>
 		<method name='test_model_saves_on_multi_gpu' parameters='tmpdir'>
 				<method_info nloc='16' complexity='1' token_count='89' nesting_level='0' start_line='65' end_line='85'></method_info>
 			<added_lines>83</added_lines>
 			<deleted_lines>69,77</deleted_lines>
 		</method>
 		<method name='test_model_saves_with_example_output' parameters='tmpdir'>
 				<method_info nloc='10' complexity='1' token_count='87' nesting_level='0' start_line='41' end_line='52'></method_info>
 			<added_lines>47</added_lines>
 			<deleted_lines>44</deleted_lines>
 		</method>
 		<method name='test_model_saves_on_gpu' parameters='tmpdir'>
 				<method_info nloc='9' complexity='1' token_count='85' nesting_level='0' start_line='28' end_line='38'></method_info>
 			<added_lines>28,29,30,31,32,33,34</added_lines>
 			<deleted_lines>33</deleted_lines>
 		</method>
 		<method name='test_model_saves_with_example_input_array' parameters='tmpdir'>
 				<method_info nloc='6' complexity='1' token_count='53' nesting_level='0' start_line='55' end_line='61'></method_info>
 			<added_lines>58</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>25,26,27,116,117</added_lines>
 			<deleted_lines>87</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
