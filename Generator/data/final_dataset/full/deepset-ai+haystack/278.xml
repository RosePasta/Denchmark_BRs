<bug_data>
<bug id='278' author='nsankar' open_date='2020-07-31T16:18:23Z' closed_time='2020-08-03T14:22:51Z'>
 	<summary>ValueError: badly formed hexadecimal UUID string    exception</summary>
 	<description>
 Question
 ValueError: badly formed hexadecimal UUID string      exception
 Additional context
 I created a document store in elasticsearch by tokenizing text from a pdf document
 when I used the DensePassageRetriever,
 from haystack.retriever.dense import DensePassageRetriever
 retriever = DensePassageRetriever(document_store=document_store, embedding_model="dpr-bert-base-nq",do_lower_case=True, use_gpu=True)
 document_store.update_embeddings(retriever)
 I get the following ValueError  . What could be the reason ? and would like to know how to fix this issue?
 07/31/2020 16:12:59 - INFO - haystack.retriever.dpr_utils -   Loading saved model from models/dpr/checkpoint/retriever/single/nq/bert-base-encoder.cp
 07/31/2020 16:12:59 - INFO - haystack.retriever.dense -   Loaded encoder params:  {'do_lower_case': True, 'pretrained_model_cfg': 'bert-base-uncased', 'encoder_model_type': 'hf_bert', 'pretrained_file': None, 'projection_dim': 0, 'sequence_length': 256}
 07/31/2020 16:13:09 - INFO - haystack.retriever.dense -   Loading saved model state ...
 07/31/2020 16:13:09 - INFO - haystack.retriever.dense -   Loading saved model state ...
 07/31/2020 16:13:09 - INFO - elasticsearch -   POST https://df4bc7e5f2a54314ac10223dd343fe94.us-central1.gcp.cloud.es.io:9243/document/_search?scroll=5m&amp;size=1000 [status:200 request:0.139s]
 ---------------------------------------------------------------------------
 ValueError                                Traceback (most recent call last)
 &lt;ipython-input-22-9372aaabee19&gt; in &lt;module&gt;()
      11 # At query time, we only need to embed the query and compare it the existing doc embeddings which is very fast.
      12 
 ---&gt; 13 document_store.update_embeddings(retriever)
      14 
      15 # ES retreivar
 
 5 frames
 /usr/lib/python3.6/uuid.py in __init__(self, hex, bytes, bytes_le, fields, int, version)
     138             hex = hex.strip('{}').replace('-', '')
     139             if len(hex) != 32:
 --&gt; 140                 raise ValueError('badly formed hexadecimal UUID string')
     141             int = int_(hex, 16)
     142         if bytes_le is not None:
 
 **ValueError: badly formed hexadecimal UUID string**
 	</description>
 	<comments>
 		<comment id='1' author='nsankar' date='2020-08-02T02:59:54Z'>
 		Hi &lt;denchmark-link:https://github.com/nsankar&gt;@nsankar&lt;/denchmark-link&gt;
  I obtained the same error by posting to the API endpoint /models/{model_id}/doc-qa with an Elasticsearch Document Store.  Hopefully my findings can help you out. Digging further into the issue I noticed that this line 
  was causing the issue.  It looks like the returned results by Elasticsearch are passed to 
  which by definition as seen here the field id 
  can be a string or a UUID, however because my elasticsearch ids are not hex based strings then it fails like previously mentioned on line 
 
 I got around the issue on my local codebase by doing the following changes:
 
 
 modified line 35 from base.py to self.id = id
 
 
 adding to 
 
 
 haystack/rest_api/controller/search.py
 
 
          Line 4
       in
       d90435e
 
 
 
 
 
 
  from typing import List, Dict, Optional 
 
 
 
 
  the type Union
 
 
 Correcting 
 
 
 haystack/rest_api/controller/search.py
 
 
          Line 119
       in
       d90435e
 
 
 
 
 
 
  document_id: Optional[UUID] = None 
 
 
 
 
  to match the type flexibility defined in 
 
 
 haystack/haystack/database/base.py
 
 
          Line 8
       in
       d90435e
 
 
 
 
 
 
  id: Optional[Union[str, UUID]] = None, 
 
 
 
 
  by modifying line 119 of search.py to document_id: Optional[Union[str, UUID]] = None
 
 
 		</comment>
 		<comment id='2' author='nsankar' date='2020-08-02T09:46:53Z'>
 		
 however because my elasticsearch ids are not hex based strings [...]
 
 &lt;denchmark-link:https://github.com/karimjp&gt;@karimjp&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/nsankar&gt;@nsankar&lt;/denchmark-link&gt;
  Do I get this right that you both use your own "custom" elasticsearch indices that have been created without using DocumentStore.write_documents()?
 &lt;denchmark-link:https://github.com/tanaysoni&gt;@tanaysoni&lt;/denchmark-link&gt;
  Can you please investigate this further and work on a fix? I think we didn't cover this use case in the last PR that introduced UUIDs (&lt;denchmark-link:https://github.com/deepset-ai/haystack/pull/243&gt;#243&lt;/denchmark-link&gt;
  )
 		</comment>
 		<comment id='3' author='nsankar' date='2020-08-02T15:32:05Z'>
 		&lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
  I used DocumentStore.write_documents() to ingest my documents in elasticsearch 7.8.1. The latest commit on master at that time was &lt;denchmark-link:https://github.com/deepset-ai/haystack/commit/52a805be86414ea987cf6bf5be6bb5f6e2bf8f53&gt;52a805b&lt;/denchmark-link&gt;
 . Later, I pulled the latest changes and tried to run the API when I started seeing the errors related the uuid.  However, the case of custom indices is possible and if so an Elasticsearch document would need to be compatible with an _id field of at most &lt;denchmark-link:https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-id-field.html&gt;512 bytes&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='4' author='nsankar' date='2020-08-02T16:36:43Z'>
 		Ok got it. In that older commit we were still indexing with arbitrary IDs. The switch to UUID is now causing the issue.
 &lt;denchmark-link:https://github.com/tanaysoni&gt;@tanaysoni&lt;/denchmark-link&gt;
  what do you think? Shall we allow also arbitrary string IDs in the Document class, even though we loose assurance of uniqueness? Otherwise support of already existing, custom ES Indices might be difficult.
 		</comment>
 		<comment id='5' author='nsankar' date='2020-08-03T03:10:21Z'>
 		&lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
  I didn't use any custom ES indexing when I reported the error. I was using the standard Haystack APIs. My Elastic search instance  is an externally hosted one .that's it.
 		</comment>
 		<comment id='6' author='nsankar' date='2020-08-03T03:23:34Z'>
 		&lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
   How about Numeric hashes instead of UUIDs ?
 &lt;denchmark-link:https://www.elastic.co/blog/efficient-duplicate-prevention-for-event-based-data-in-elasticsearch&gt;https://www.elastic.co/blog/efficient-duplicate-prevention-for-event-based-data-in-elasticsearch&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='7' author='nsankar' date='2020-08-03T09:28:22Z'>
 		Hi &lt;denchmark-link:https://github.com/nsankar&gt;@nsankar&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/karimjp&gt;@karimjp&lt;/denchmark-link&gt;
 , thank you for raising the issue.
 
 
 Shall we allow also arbitrary string IDs in the Document class
 
 &lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
  from how I see, there are some constraints for the document IDs:
 
 the Document object is generic across different document store implementations, so the IDs should be compatible across document stores.
 for the creation of new documents via write_documents(), the IDs must be unique.
 
 For supporting existing document stores not created with Haystack, we cannot rely on the availability of UUIDs.
 As a workaround, we can change the Document.id to be always of str type. When we create a new document, we assign a UUID string under the hood, otherwise, we read string(or numeric) values from an existing index as str.
 		</comment>
 		<comment id='8' author='nsankar' date='2020-08-03T11:07:49Z'>
 		&lt;denchmark-link:https://github.com/tanaysoni&gt;@tanaysoni&lt;/denchmark-link&gt;
  Yeah, I think changing the id to str type would be good. It will come at some costs of risking duplicates if user provide their own id and don't check uniqueness by themselves, but I think the flexibility we gain (e.g support for custom indices and existing IDs from QA datasets) outweighs this.
 		</comment>
 		<comment id='9' author='nsankar' date='2020-08-03T12:39:01Z'>
 		&lt;denchmark-link:https://github.com/tanaysoni&gt;@tanaysoni&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
   Sounds good!
 		</comment>
 		<comment id='10' author='nsankar' date='2020-08-03T14:22:50Z'>
 		Hi &lt;denchmark-link:https://github.com/nsankar&gt;@nsankar&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/karimjp&gt;@karimjp&lt;/denchmark-link&gt;
 , this should now be resolved with &lt;denchmark-link:https://github.com/deepset-ai/haystack/pull/284&gt;#284&lt;/denchmark-link&gt;
 . I am closing this issue but please feel free to re-open if you still face any errors.
 		</comment>
 		<comment id='11' author='nsankar' date='2020-08-03T14:29:41Z'>
 		&lt;denchmark-link:https://github.com/tanaysoni&gt;@tanaysoni&lt;/denchmark-link&gt;
  thank you for taking a look at this issue. Not sure if this should go into another issue, but here is another use case for generating a unique ID with  beyond the use of UUIDs.
 
 Document Hash as ID case: A user has a directory with multiple documents to write documents from and keeps adding documents to it.  In order to prevent duplicate documents from being inserted with a different id the document id needs to have a hash of the document itself.
 
 I haven't tested what happens if I have an index with a custom mapping and my document to be inserted using write_documents() already has an _id field with any string I define but if that works, it could be the right answer for the use case above.
 		</comment>
 		<comment id='12' author='nsankar' date='2020-08-04T06:57:50Z'>
 		Hi &lt;denchmark-link:https://github.com/karimjp&gt;@karimjp&lt;/denchmark-link&gt;
 , for the document hash case, you can use the newly added(&lt;denchmark-link:https://github.com/deepset-ai/haystack/pull/285&gt;#285&lt;/denchmark-link&gt;
 )  parameter for the . When the parameter is set to , the documents with the same id gets updated. Otherwise, when set to , the document store throws an error if a document with the given id already exists.
 		</comment>
 	</comments>
 </bug>
<commit id='723921475f905077065183111c5d445aaa8ce5fa' author='Tanay Soni' date='2020-08-03 16:20:17+02:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='haystack\database\base.py' new_name='haystack\database\base.py'>
 		<file_info nloc='96' complexity='21' token_count='656'></file_info>
 		<method name='__init__' parameters='self,str,str,None,None,None,str,None,str,None,None'>
 				<method_info nloc='7' complexity='1' token_count='78' nesting_level='1' start_line='7' end_line='13'></method_info>
 			<added_lines>8</added_lines>
 			<deleted_lines>8</deleted_lines>
 		</method>
 		<method name='get_document_by_id' parameters='self,UUID,None'>
 				<method_info nloc='2' complexity='1' token_count='24' nesting_level='1' start_line='149' end_line='150'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>149</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,str,str,bool,bool,str,None,None,None,None'>
 				<method_info nloc='9' complexity='1' token_count='61' nesting_level='1' start_line='64' end_line='72'></method_info>
 			<added_lines>69</added_lines>
 			<deleted_lines>72</deleted_lines>
 		</method>
 		<method name='get_document_by_id' parameters='self,str,None'>
 				<method_info nloc='2' complexity='1' token_count='24' nesting_level='1' start_line='140' end_line='141'></method_info>
 			<added_lines>140</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,str,str,bool,bool,str,None,None,None,None'>
 				<method_info nloc='9' complexity='1' token_count='61' nesting_level='1' start_line='67' end_line='75'></method_info>
 			<added_lines>69</added_lines>
 			<deleted_lines>72</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,str,str,None,None,str,None,str,None,None'>
 				<method_info nloc='7' complexity='1' token_count='70' nesting_level='1' start_line='7' end_line='13'></method_info>
 			<added_lines>8</added_lines>
 			<deleted_lines>8</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>2,3,34,36,95</added_lines>
 			<deleted_lines>2,3,34,35,36,37,39,98,99,100,101,102,103,104</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='haystack\database\elasticsearch.py' new_name='haystack\database\elasticsearch.py'>
 		<file_info nloc='331' complexity='58' token_count='2560'></file_info>
 		<method name='get_document_by_id' parameters='self,str,index'>
 				<method_info nloc='7' complexity='3' token_count='84' nesting_level='1' start_line='124' end_line='131'></method_info>
 			<added_lines>124</added_lines>
 			<deleted_lines>125</deleted_lines>
 		</method>
 		<method name='get_document_by_id' parameters='self,UUID,index'>
 				<method_info nloc='7' complexity='3' token_count='89' nesting_level='1' start_line='125' end_line='132'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>125</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>9</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='haystack\database\memory.py' new_name='haystack\database\memory.py'>
 		<file_info nloc='130' complexity='49' token_count='1164'></file_info>
 		<method name='get_document_by_id' parameters='self,str,None'>
 				<method_info nloc='3' complexity='2' token_count='37' nesting_level='1' start_line='67' end_line='69'></method_info>
 			<added_lines>67</added_lines>
 			<deleted_lines>67</deleted_lines>
 		</method>
 		<method name='write_labels' parameters='self,None'>
 				<method_info nloc='6' complexity='5' token_count='83' nesting_level='1' start_line='44' end_line='50'></method_info>
 			<added_lines>49</added_lines>
 			<deleted_lines>49</deleted_lines>
 		</method>
 		<method name='get_document_by_id' parameters='self,str,None'>
 				<method_info nloc='3' complexity='2' token_count='42' nesting_level='1' start_line='67' end_line='69'></method_info>
 			<added_lines>67</added_lines>
 			<deleted_lines>67</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>2,4</added_lines>
 			<deleted_lines>2,4</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='haystack\database\sql.py' new_name='haystack\database\sql.py'>
 		<file_info nloc='158' complexity='35' token_count='1292'></file_info>
 		<method name='get_document_by_id' parameters='self,str,index'>
 				<method_info nloc='5' complexity='3' token_count='62' nesting_level='1' start_line='72' end_line='76'></method_info>
 			<added_lines>72</added_lines>
 			<deleted_lines>73</deleted_lines>
 		</method>
 		<method name='write_labels' parameters='self,labels,index'>
 				<method_info nloc='19' complexity='5' token_count='133' nesting_level='1' start_line='145' end_line='164'></method_info>
 			<added_lines>151</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_document_by_id' parameters='self,UUID,index'>
 				<method_info nloc='5' complexity='3' token_count='62' nesting_level='1' start_line='73' end_line='77'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>73</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>2,7,9,17,44,51</added_lines>
 			<deleted_lines>1,7,8,9,18,45,52</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rest_api\controller\search.py' new_name='rest_api\controller\search.py'>
 		<file_info nloc='156' complexity='12' token_count='952'></file_info>
 		<modified_lines>
 			<added_lines>118</added_lines>
 			<deleted_lines>5,119</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\test_tfidf_retriever.py' new_name='test\test_tfidf_retriever.py'>
 		<file_info nloc='16' complexity='1' token_count='117'></file_info>
 		<method name='test_tfidf_retriever' parameters=''>
 				<method_info nloc='16' complexity='1' token_count='116' nesting_level='0' start_line='1' end_line='19'></method_info>
 			<added_lines>17</added_lines>
 			<deleted_lines>1,2,3</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>20</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
