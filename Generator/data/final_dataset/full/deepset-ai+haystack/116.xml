<bug_data>
<bug id='116' author='Ierezell' open_date='2020-05-19T14:27:06Z' closed_time='2020-06-03T14:22:56Z'>
 	<summary>Cannot use EmbeddingRetriever (Indexing of embeddings)</summary>
 	<description>
 I want to use an EmbeddingRetriever instead of a BM25.
 I have a huge handcrafted corpus of text files, each corresponding to a paragraph.
 The goal is to ask a question, get the k best paragraph regarding the embeddings similarity (text files and question). I've done my own method but I would like to compare with Haystack.
 I'm creating the DocumentStore as in the doc :
 &lt;denchmark-code&gt;document_store = ElasticsearchDocumentStore(host="localhost", username="",  password="", index="document", text_field="answer", embedding_field="question_emb", embedding_dim=768, excluded_meta_data=["question_emb"])
     write_documents_to_db(document_store=document_store, only_empty_db=True, document_dir="./datas/txt")
 &lt;/denchmark-code&gt;
 
 Then the retriever (multilang sentence transformer):
 &lt;denchmark-code&gt;retriever = EmbeddingRetriever(document_store=document_store, embedding_model="distiluse-base-multilingual-cased", model_format="sentence_transformers")
 &lt;/denchmark-code&gt;
 
 And finnaly when I try to retrieve the top k documents :
 &lt;denchmark-code&gt;top_docs = retriever.retrieve(query=q, top_k=10)
 &lt;/denchmark-code&gt;
 
 I got this info :
 &lt;denchmark-code&gt;05/19/2020 10:22:49 - INFO - elasticsearch -   PUT http://localhost:9200/document [status:400 request:0.008s]
 05/19/2020 10:22:49 - INFO - elasticsearch -   POST http://localhost:9200/_count [status:200 request:0.003s]
 05/19/2020 10:22:49 - INFO - haystack.indexing.io -   Skip writing documents since DB already contains 2141 docs ...  (Disable `only_empty_db`, if you want to add docs anyway.)
 05/19/2020 10:22:49 - INFO - haystack.retriever.elasticsearch -   Init retriever using embeddings of model distiluse-base-multilingual-cased
 05/19/2020 10:22:49 - INFO - root -   Load pretrained SentenceTransformer: distiluse-base-multilingual-cased
 05/19/2020 10:22:49 - INFO - root -   Did not find a '/' or '\' in the name. Assume to download model from server.
 05/19/2020 10:22:49 - INFO - root -   Load SentenceTransformer from folder: /home/pedro/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distiluse-base-multilingual-cased.zip
 05/19/2020 10:22:51 - INFO - root -   Use pytorch device: cuda
 Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00&lt;00:00, 148.86it/s]
 &lt;/denchmark-code&gt;
 
 Then a traceback
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File "/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/serializer.py", line 50, in dumps
     return json.dumps(
   File "/home/pedro/.local/lib/python3.8/site-packages/simplejson/__init__.py", line 398, in dumps
     return cls(
   File "/home/pedro/.local/lib/python3.8/site-packages/simplejson/encoder.py", line 296, in encode
     chunks = self.iterencode(o, _one_shot=True)
   File "/home/pedro/.local/lib/python3.8/site-packages/simplejson/encoder.py", line 378, in iterencode
     return _iterencode(o, 0)
   File "/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/serializer.py", line 36, in default
     raise TypeError("Unable to serialize %r (type: %s)" % (data, type(data)))
 TypeError: Unable to serialize -0.065520875 (type: &lt;class 'numpy.float32'&gt;)
 
 During handling of the above exception, another exception occurred:
 
 Traceback (most recent call last):
   File "sdk/accuracy_retriever.py", line 75, in &lt;module&gt;
     top_docs = haystack_retriever(q, doc_store)
   File "/mnt/Documents/Projets/BotPress/R_D/R_D_q_a/sdk/retrievers.py", line 113, in haystack_retriever
     top_docs = retriever.retrieve(query=q, top_k=10)
   File "/mnt/Documents/Projets/git_clones/haystack/haystack/retriever/elasticsearch.py", line 92, in retrieve
     documents = self.document_store.query_by_embedding(query_emb[0], top_k, candidate_doc_ids)
   File "/mnt/Documents/Projets/git_clones/haystack/haystack/database/elasticsearch.py", line 184, in query_by_embedding
     result = self.client.search(index=self.index, body=body)["hits"]["hits"]
   File "/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/client/utils.py", line 92, in _wrapped
     return func(*args, params=params, headers=headers, **kwargs)
   File "/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/client/__init__.py", line 1622, in search
     return self.transport.perform_request(
   File "/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/transport.py", line 321, in perform_request
     body = self.serializer.dumps(body)
   File "/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/serializer.py", line 54, in dumps
     raise SerializationError(data, e)
 elasticsearch.exceptions.SerializationError: ({'size': 10, 'query': {'script_score': {'query': {'match_all': {}}, 'script': {'source': "cosineSimilarity(params.query_vector,doc['question_emb']) + 1.0", 'params': {'query_vector': [-0.065520875, 0.023728848, ... lot of numbers ..., 0.047961414]}}}}, '_source': {'excludes': ['question_emb']}}, TypeError("Unable to serialize -0.065520875 (type: &lt;class 'numpy.float32'&gt;)"))
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='Ierezell' date='2020-05-21T10:53:49Z'>
 		Hey &lt;denchmark-link:https://github.com/Ierezell&gt;@Ierezell&lt;/denchmark-link&gt;
  ,
 For using the EmbeddingRetriever you'll need to add the embeddings for your documents to the Elasticsearch index first. At query time we can then embed the question on-the-fly and calculate similarity to the indexed embeddings.
 Please have a look at &lt;denchmark-link:https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial4_FAQ_style_QA.py#L70&gt;Tutorial 4&lt;/denchmark-link&gt;
 , where we do this for "FAQ style QA". If you wanted to apply this to regular extractive QA, you would need to adjust the "write_documents_to_db()" utility function to also create the embeddings.
 We'll probably simplify this and add an example once we have implemented the DPR encoders (&lt;denchmark-link:https://github.com/deepset-ai/haystack/issues/63&gt;#63&lt;/denchmark-link&gt;
 ).
 Be aware that using sentence-transformers / USE embeddings for both (question and long passages) might not yield great performance. Dual encoder approaches usually work better here.
 		</comment>
 		<comment id='2' author='Ierezell' date='2020-05-25T20:40:10Z'>
 		Oh sorry I thought the write_to_db would get each sentence and embed it when initialising the db. I will embed them myself first, thanks.
 Yes indeed, to overcome that I splitted my dataset in chunks.
 Because I'm looking for similarity on the content, chunking is okay and just lead to more documents.
 Furthermore, I'm doing unsupervised lookup so I don't have pairs to train an Dual encoder, but thanks a lot for the suggestion, it's a really good one ðŸ˜ƒ
 		</comment>
 		<comment id='3' author='Ierezell' date='2020-05-26T09:33:23Z'>
 		Besides your issue of indexing the embeddings first, there was still a small issue with the serialization of float64 returned by sentence-transformers. Fixed this in &lt;denchmark-link:https://github.com/deepset-ai/haystack/pull/121&gt;#121&lt;/denchmark-link&gt;
 .
 		</comment>
 		<comment id='4' author='Ierezell' date='2020-06-03T14:22:56Z'>
 		Closing this as the original issue seems to be fixed. &lt;denchmark-link:https://github.com/Ierezell&gt;@Ierezell&lt;/denchmark-link&gt;
  feel free to re-open in case there's still a problem on your side.
 		</comment>
 	</comments>
 </bug>
<commit id='df554fcb458515c0fd5b08dab46cc11b73acd3bb' author='Malte Pietsch' date='2020-05-26 16:43:05+02:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='haystack\retriever\elasticsearch.py' new_name='haystack\retriever\elasticsearch.py'>
 		<file_info nloc='59' complexity='11' token_count='470'></file_info>
 		<method name='create_embedding' parameters='self'>
 				<method_info nloc='11' complexity='7' token_count='114' nesting_level='1' start_line='100' end_line='119'></method_info>
 			<added_lines>118</added_lines>
 			<deleted_lines>114</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>86,87,88,89,90</added_lines>
 			<deleted_lines>86</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
