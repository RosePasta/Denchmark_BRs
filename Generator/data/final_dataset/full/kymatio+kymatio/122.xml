<bug_data>
<bug id='122' author='janden' open_date='2018-11-05T20:53:14Z' closed_time='2018-11-30T19:51:36Z'>
 	<summary>3D crashes on CPU</summary>
 	<description>
 Getting the following error when calling forward:
 &lt;denchmark-code&gt;  File "/home/janden/projects/kymatio/scattering/scattering3d/scattering3d.py", line 326, in forward
     conv_modulus, method, method_args, j_1))
   File "/home/janden/projects/kymatio/scattering/scattering3d/scattering3d.py", line 175, in _compute_scattering_coefs
     return self._compute_standard_scattering_coefs(input_array)
   File "/home/janden/projects/kymatio/scattering/scattering3d/scattering3d.py", line 105, in _compute_standard_scattering_coefs
     convolved_input = self._low_pass_filter(input_array, self.J)
   File "/home/janden/projects/kymatio/scattering/scattering3d/scattering3d.py", line 85, in _low_pass_filter
     cuda = isinstance(input_array, torch.cuda.FloatTensor)
 RuntimeError: cuda runtime error (30) : unknown error at /opt/conda/conda-bld/pytorch_1532584813488/work/aten/src/THC/THCGeneral.cpp:74
 &lt;/denchmark-code&gt;
 
 From what I understand, the code is set up to detect whether the input is GPU and apply the appropriate operators (there's not cuda() or cpu() functions to convert the transformer like in 1D and 2D). Looks like when I run this without CUDA enabled, it crashes when trying to determine the type of the input tensor. It might be my personal config, but I should mention that torch.cuda.is_available() works without crashing.
 More bigger picture, do we want to modify this implementation to more closely align with the 1D/2D calling sequence? May make things easier for users (and also prevent the above type of errors).
 	</description>
 	<comments>
 		<comment id='1' author='janden' date='2018-11-06T06:25:32Z'>
 		Hmm so I think that this isinstance(input_array, torch.cuda.FloatTensor) call is not a good idea for how to find out whether a tensor is on GPU and should be fixed. Is that the call that is causing the error? (can't tell for sure)
 I think the calling sequence should be as similar as possible. That said, the code does something smart, quite implicitly, which is to copy filters back and forth from GPU. This is very useful in the 3D setting (as opposed to having all the filters in GPU memory all the time), because 3D images of any reasonable size together with the extra multiples of memory required to process them end up taking up a lot of space on the device.
 So yes, we should make the things as similar as possible, but there might be some limits. (That was also one reason for having separate code bases and merging what is mergeable later on rather than trying to unify everything from the beginning)
 		</comment>
 		<comment id='2' author='janden' date='2018-11-06T06:32:08Z'>
 		Yes that's the call that causes the crash.
 Right. That makes sense. Maybe that's an argument for having the same behavior for 1D/2D? The reason I'm bringing this up now is that it would be better to commit to a similar API from the beginning, as opposed to having things break down the road. Of course, we should only do this if we're relatively certain this is the way we want to go.
 		</comment>
 		<comment id='3' author='janden' date='2018-11-06T06:39:36Z'>
 		There is also this is_cuda method that Tensors and Variables have. I think this is a standard pytorch thing, but haven't pushed to adding it because I wasn't sure which version it was added, etc.
 There is a big chance that this would solve the issue (on top of making the code more readable). One could also just somehow log somewhere that "hey we are currently doing CPU".
 
 Maybe that's an argument for having the same behavior for 1D/2D?
 
 Actually I'd like to make sure I understand precisely what behavior you are referring to here
 		</comment>
 		<comment id='4' author='janden' date='2018-11-06T06:44:28Z'>
 		Ok. What I meant is that it may make sense to have the 1D/2D implementations detect whether the input is CPU/GPU and move their filters to/from the GPU depending, just like the 3D implementation. That is, we wouldn't have any cuda() or cpu() functions for Scattering1D and Scattering2D. The calling sequence would then be the same for 1D/2D/3D.
 		</comment>
 		<comment id='5' author='janden' date='2018-11-06T06:50:47Z'>
 		I'd say let's not do that:
 
 The pytorch convention of saying .cuda and .cpu to networks and them transferring reliably to that device seems like a useful thing to hold on to (and aspire to), because that is the behavior people will be used to.
 After release we can think about this magic check_array function which could do the converse of what you suggest (if set to do so): Move the data to where the model is (as opposed to moving the filters to where the data is). (This does not preclude 3D from storing most of its filters on CPU for space reasons - if it is declare to be on GPU it will perform its computations on GPU and that is what matters)
 
 		</comment>
 		<comment id='6' author='janden' date='2018-11-06T07:00:04Z'>
 		Ok. You're right, we don't want to do anything unexpected. But that's all the more reason to have the 3D behave more like 1D and 2D (with cuda() and cpu() methods, that is), no? Like you say, these methods do not have to explicitly move all the filters on/off the GPU, but may just set a flag telling the object whether it's allowed to use the GPU or not.
 		</comment>
 		<comment id='7' author='janden' date='2018-11-06T07:10:31Z'>
 		Yeah, I 100% agree with that.
 (Question is whether this should be before release or pushed to later. Though if we can find somebody to do it before release that would be great of course)
 		</comment>
 		<comment id='8' author='janden' date='2018-11-06T07:13:43Z'>
 		Ok good. Again, for the sake of stabilizing the API, before release is better. I would take a look but 1) I'm still behind on the 1D doc and 2) I'm not very familiar with any of the 3D stuff. I may take a stab at it, though.
 		</comment>
 		<comment id='9' author='janden' date='2018-11-18T14:51:31Z'>
 		&lt;denchmark-link:https://github.com/louity&gt;@louity&lt;/denchmark-link&gt;
  can you add this feature?
 		</comment>
 		<comment id='10' author='janden' date='2018-11-20T20:45:30Z'>
 		This needs to be fixed before release.
 		</comment>
 		<comment id='11' author='janden' date='2018-11-22T23:35:35Z'>
 		Yeah this is more important than having a skcuda backend for 3D
 		</comment>
 		<comment id='12' author='janden' date='2018-11-30T04:04:21Z'>
 		Interestingly, this doesn't crash if method='integral' is specified. All tests in the 3D suite have this set, which is why Travis doesn't complain.
 		</comment>
 		<comment id='13' author='janden' date='2018-11-30T04:09:00Z'>
 		Looks like the culprit is Scattering3D._low_pass_filter which checks CUDAness of the input using isinstance(x, torch.cuda.FloatTensor). If method='integral', this is never called, so no crash. The only other function checking CUDAness in this instance is Scattering3D._rotation_covariant_convolution_and_modulus, which uses x.is_cuda.
 		</comment>
 	</comments>
 </bug>
<commit id='0797b27d9a7f2d700b48591f732783e55e2d3051' author='Joakim AndÃ©n' date='2018-11-30 14:51:35-05:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='kymatio\scattering3d\scattering3d.py' new_name='kymatio\scattering3d\scattering3d.py'>
 		<file_info nloc='179' complexity='28' token_count='1107'></file_info>
 		<method name='_low_pass_filter' parameters='self,input_array,j'>
 				<method_info nloc='6' complexity='2' token_count='42' nesting_level='1' start_line='73' end_line='93'></method_info>
 			<added_lines>89</added_lines>
 			<deleted_lines>89</deleted_lines>
 		</method>
 		<method name='_convolution_and_modulus' parameters='self,input_array,l,j,m'>
 				<method_info nloc='6' complexity='2' token_count='57' nesting_level='1' start_line='218' end_line='247'></method_info>
 			<added_lines>243</added_lines>
 			<deleted_lines>243</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='kymatio\scattering3d\tests\test_scattering3d.py' new_name='kymatio\scattering3d\tests\test_scattering3d.py'>
 		<file_info nloc='136' complexity='21' token_count='1228'></file_info>
 		<method name='test_scattering_methods' parameters=''>
 				<method_info nloc='18' complexity='2' token_count='163' nesting_level='0' start_line='156' end_line='177'></method_info>
 			<added_lines>156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>155</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
