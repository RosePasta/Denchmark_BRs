<bug_data>
<bug id='483' author='fhieber' open_date='2018-07-19T16:34:38Z' closed_time='2018-07-31T10:19:44Z'>
 	<summary>hypotheses lengths off by one</summary>
 	<description>
 It seems that the current beam search implementation (_beam_search) does not compute hypotheses length correctly. This can be seen when printing sequences and lengths just before returning from _beam_search(): the length is always one short of the actual non-zero values in sequences:
 &lt;denchmark-code&gt;&gt; sequences[0]
 [    2    92  7741   907  2710   295    28     7  7741   907  2710     4
      7   383 10174  7324  9735   286   671   564  4085    71    22    98
  10671     4    13   782   485     8  6323  8665     4     8    23     8
   2976  1037  2448  3577    10   294   575  4664    13    34  3898   608
     43     5     3     0]
 &lt;NDArray 52 @cpu(0)&gt;
 
 &gt; lengths[0]
 [50.]
 &lt;NDArray 1 @cpu(0)&gt;
 &lt;/denchmark-code&gt;
 
 3 is the EOS id and the length of this hypothesis is clearly 51.
 Let me try to explain the problem below. In practice, it doesn't matter since _assemble_translation() uses the length value to cut off the EOS symbol; the following EOS stripping logic in _make_result() is then redundant. But of course it shouldn't be and I think _beam_search() should return consistent data structures.
 Here's the issue; I think this was introduced with length normalization only done for finished hypotheses:
 
 lengths is initialized with 1s to account for the initial data in sequences, namely the BOS symbol
 In each beam search iteration: as soon as we run topk on hypotheses scores, we effectively have expanded an hypothesis and its length increases by 1.
 However, we are not using the updated length to potentially normalize the hypothesis if its finished. We check the newly acquired best_word_indices for EOS/PAD to compute a current finished status, and if so, we normalize with the OLD length.
 This doesn't yet explain why we end beam_search with a length off by 1. This must somehow happen because the length array is only updated for hypotheses that are not finished and active. Since finished was just recomputed in step 3, the problem must lie in the inactive logic or the fact that right after we update lengths, we recompute finished once again and determine breaking out of the beam search loop based on that.
 
 I am not 100% sure whats wrong here, probably the order of operations isn't entirely correct, but I also don't fully understand the whole  logic introduced. &lt;denchmark-link:https://github.com/mjpost&gt;@mjpost&lt;/denchmark-link&gt;
  could you comment on this?
 At a minimum, we should make sure to normalize with correct length values. At best, we should make sure to return a lengths array from _beam_search that is consistent with sequences. With that, _assemble_translation would not silently cut off the last token (EOS), which by design should be handled later by _make_result().
 	</description>
 	<comments>
 		<comment id='1' author='fhieber' date='2018-07-24T08:33:22Z'>
 		From looking at the code, I think the problem is:
 
 We normalize finished hypotheses, and then update the set of finished hypotheses.
 This prevents lengths from being updated.
 
 I think it might be sufficient to:
 
 Return all_finished from the NormalizeFinishedHypotheses hybrid block (as is currently done, though without the extra variable assignment)
 In the calling block, save that to a new variable instead of overwriting finished. This value will then be used for pruning.
 
 With that, the updating of lengths should work correctly because finished itself will not have been updated yet.
 I should be able to look at this soon but thought I'd document this here in the meantime in case someone else wants to fix it.
 		</comment>
 		<comment id='2' author='fhieber' date='2018-07-24T08:58:20Z'>
 		Looking further, it seems we could eliminate the UpdateLengthsAndFinished hybrid block, and simply combine the two new blocks into a single block, done just before beam pruning.
 		</comment>
 		<comment id='3' author='fhieber' date='2018-07-24T09:17:23Z'>
 		Okay, I fixed this. You can run a simple test and you see at the end that  and  are now corrected. The tests pass but style check will fail because of pylint issue &lt;denchmark-link:https://github.com/awslabs/sockeye/issues/478&gt;#478&lt;/denchmark-link&gt;
 .
 		</comment>
 		<comment id='4' author='fhieber' date='2018-07-25T15:23:56Z'>
 		Are we sure the length calculations haven't always been like this?
 To me the lengths should be the length of symbols, which have been generated. In the sequences NDArray we include the &lt;s&gt; symbol, however it is not a symbol that gets generated by the model and it should therefore not count towards the length. That said, it would maybe be more consistent to return the sequences NDArray without &lt;s&gt;. With this in mind the length in the example given below is correct though if we discount for 0 and 2.
 For beam search I think it is actually the correct thing to use the old lengths array for normalizing for the fact that the lengths array is initialized to 1 instead of 0. After generating the first real symbol we should normalize the score by length_penalty(1) as we have only produced a single score thus far.
 So I think if we use the old lengths array we are doing the correct thing. That said, it is currently inconsistent and confusing what we do, so that there is potential for some refactoring/cleanup (that however should not change the way we score).
 		</comment>
 		<comment id='5' author='fhieber' date='2018-07-25T16:03:15Z'>
 		Okay, I think I agree that we should not include &lt;s&gt; in the length counts. The principle can be that we only count steps actually generated by the decoder. But I don't feel strongly about it.
 I think the other simplification I did can remain independent of this decision.
 		</comment>
 		<comment id='6' author='fhieber' date='2018-07-26T11:22:50Z'>
 		sounds good. Let's have the simplification, but not count the &lt;s&gt; for lengths and make sure that the returned values from _beam_search are consistent, e.g. by removing &lt;s&gt; before returning.
 		</comment>
 		<comment id='7' author='fhieber' date='2018-07-27T09:35:26Z'>
 		&lt;denchmark-link:https://github.com/tdomhan&gt;@tdomhan&lt;/denchmark-link&gt;
  your argument makes sense to me. The main reason I came across this is that it is a bit strange that we return  from  with  not matching the actual sequences in there, then removing  in  by using that length information, and finally remove the  token in  using the  logic.
 		</comment>
 		<comment id='8' author='fhieber' date='2018-07-27T09:42:29Z'>
 		Yes, so I think we did the correct thing the way we normalized with the lengths, however what we passed around was inconsistent and confusing.
 		</comment>
 		<comment id='9' author='fhieber' date='2018-07-27T11:54:42Z'>
 		Okay, I just pushed up a version rebased on master that does all of this. This simplifies a lot of logic where we have to add a null column or strip it off when concatenating. It should be ready to go.
 		</comment>
 		<comment id='10' author='fhieber' date='2018-07-27T12:44:01Z'>
 		great, thanks!
 		</comment>
 	</comments>
 </bug>
<commit id='8530156880edf632908e053eb799128e0c7bb05a' author='Matt Post' date='2018-07-31 12:19:42+02:00'>
 	<dmm_unit complexity='0.0' interfacing='0.8888888888888888' size='0.1111111111111111'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>13,14,15,16</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='sockeye\__init__.py' new_name='sockeye\__init__.py'>
 		<file_info nloc='1' complexity='0' token_count='3'></file_info>
 		<modified_lines>
 			<added_lines>14</added_lines>
 			<deleted_lines>14</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='sockeye\inference.py' new_name='sockeye\inference.py'>
 		<file_info nloc='1412' complexity='131' token_count='9908'></file_info>
 		<method name='_concat_translations' parameters='LengthPenalty'>
 				<method_info nloc='2' complexity='1' token_count='23' nesting_level='0' start_line='899' end_line='900'></method_info>
 			<added_lines>899</added_lines>
 			<deleted_lines>899</deleted_lines>
 		</method>
 		<method name='_concat_translations' parameters='int,LengthPenalty'>
 				<method_info nloc='2' complexity='1' token_count='27' nesting_level='0' start_line='899' end_line='900'></method_info>
 			<added_lines>899</added_lines>
 			<deleted_lines>899</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,int,int'>
 				<method_info nloc='4' complexity='1' token_count='32' nesting_level='1' start_line='1787' end_line='1790'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>1787,1788,1789,1790</deleted_lines>
 		</method>
 		<method name='hybrid_forward' parameters='self,F,best_word_indices,finished,scores_accumulated,lengths'>
 				<method_info nloc='8' complexity='1' token_count='65' nesting_level='1' start_line='1772' end_line='1779'></method_info>
 			<added_lines>1778</added_lines>
 			<deleted_lines>1772,1778,1779</deleted_lines>
 		</method>
 		<method name='hybrid_forward' parameters='self,F,best_word_indices,max_output_lengths,finished,scores_accumulated,lengths'>
 				<method_info nloc='13' complexity='1' token_count='147' nesting_level='1' start_line='1757' end_line='1778'></method_info>
 			<added_lines>1757,1764,1765,1766,1768,1778</added_lines>
 			<deleted_lines>1757,1772,1778</deleted_lines>
 		</method>
 		<method name='hybrid_forward' parameters='self,F,finished,inactive,lengths,max_output_lengths,best_word_indices'>
 				<method_info nloc='9' complexity='1' token_count='124' nesting_level='1' start_line='1792' end_line='1806'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>1792,1793,1794,1795,1796,1806</deleted_lines>
 		</method>
 		<method name='_concat_translations' parameters='self'>
 				<method_info nloc='8' complexity='1' token_count='28' nesting_level='1' start_line='1258' end_line='1265'></method_info>
 			<added_lines>1265</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>905,909,914,915,918,919,921,922,927,928,1030,1031,1032,1033,1034,1035,1242,1243,1391,1392,1393,1400,1524,1525,1526,1527,1528,1538,1542,1543,1554,1556,1560,1606,1607,1742</added_lines>
 			<deleted_lines>905,906,910,914,916,917,920,921,923,924,929,930,931,932,933,934,1036,1037,1038,1039,1040,1041,1046,1047,1048,1049,1050,1253,1254,1255,1277,1403,1404,1405,1412,1536,1537,1538,1539,1549,1550,1551,1552,1553,1554,1555,1556,1557,1572,1576,1622,1780,1782,1783,1784,1785,1786</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\unit\test_inference.py' new_name='test\unit\test_inference.py'>
 		<file_info nloc='298' complexity='28' token_count='3285'></file_info>
 		<method name='test_concat_translations' parameters=''>
 				<method_info nloc='20' complexity='1' token_count='294' nesting_level='0' start_line='71' end_line='95'></method_info>
 			<added_lines>76,90</added_lines>
 			<deleted_lines>76,90,91</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tutorials\constraints\README.md' new_name='tutorials\constraints\README.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>7,8,9,10,11,12,13,14,15,16,17,18,33,35,37,38,39</added_lines>
 			<deleted_lines>7,8,9,10,25,27,28,29,31,32,33</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
