<bug_data>
<bug id='460' author='jindrahelcl' open_date='2017-06-04T19:18:59Z' closed_time='2017-06-22T12:39:08Z'>
 	<summary>Tensorboard all validations</summary>
 	<description>
 When using multiple validation dataset, plot scores of all of them to tensorboard.
 	</description>
 	<comments>
 		<comment id='1' author='jindrahelcl' date='2017-06-04T19:54:05Z'>
 		Aha, původně jsem si myslel, že se jen netensorboardujou ty jiný než ta hlavní validace, podle který se ukládá. Ale je v tom bug. Takže to prosím @tomkocmi zkus opravit. Do tensorboardu se háže skóre ze všech validačních datasetů do jednoho grafu. Zejtra se kouknem na to, jak by to mělo bejt správně.
 		</comment>
 		<comment id='2' author='jindrahelcl' date='2017-06-05T09:35:04Z'>
 		me to na masteru opice kdyz jsem tuhle featuru pridaval funguje (nebo mozna nevim presne co myslis).
 		</comment>
 		<comment id='3' author='jindrahelcl' date='2017-06-05T09:35:54Z'>
 		pockat ty myslis jakoze kdyz mas ruzne validace na stejne uloze? typu prekladani novinovych clanku, titulku a treti validacni set jsou treba zakony, tak ze se to kresli do stejneho grafu?
 		</comment>
 		<comment id='4' author='jindrahelcl' date='2017-06-05T11:35:45Z'>
 		přesně tak
 		</comment>
 		<comment id='5' author='jindrahelcl' date='2017-06-16T09:22:53Z'>
 		Tenhle mam nekde na seznamu todo listu, ale neprijde mi podstatny, soucasne vypisovani do jednoho grafu se da vyresit jinyma metrikama. Podle me by to chtelo prekopat celou learning utils nez tam pridavat dalsi podminky (ale nekoukal jsem jak by sel tenhle issue osetrit) ... Mimochodem da se nejak nastavit, aby se mi ukazoval tenhle issue v notifikaci abych na nej nezapomenul?
 		</comment>
 		<comment id='6' author='jindrahelcl' date='2017-06-16T09:37:43Z'>
 		Nevim. Ale účinný je navyknout si jednou za čas zkontrolovat seznam issues na který jsi assignutej.
 Proč bych měl dělat různý metriky když chci měřit pořád jednu? Mam troje validační data a jeden evaluátor, kterej funguje na všechny. Takže to má fungovat tak, že místo grafu pro každou data series a každou na ní spoštěnou metriku se mi to ještě rozduplikuje přes validační datasety. Neřikám, že tam nebude potřeba promyslet a předělat pár věcí, ale takhle to zkrátka nedělá, co má.
 		</comment>
 	</comments>
 </bug>
<commit id='689288ea3955634a3ec5c31de945543560bad222' author='Tom Kocmi' date='2017-06-20 16:11:54+02:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='neuralmonkey\learning_utils.py' new_name='neuralmonkey\learning_utils.py'>
 		<file_info nloc='519' complexity='32' token_count='2986'></file_info>
 		<method name='_log_continuous_evaluation' parameters='FileWriter,TensorFlowManager,str,Evaluation,int,int,int,bool,str'>
 				<method_info nloc='10' complexity='1' token_count='56' nesting_level='0' start_line='455' end_line='464'></method_info>
 			<added_lines>463,464</added_lines>
 			<deleted_lines>462</deleted_lines>
 		</method>
 		<method name='_log_continuous_evaluation' parameters='FileWriter,TensorFlowManager,str,Evaluation,int,int,int,bool'>
 				<method_info nloc='9' complexity='1' token_count='50' nesting_level='0' start_line='454' end_line='462'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>462</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>70,251,469,470,471</added_lines>
 			<deleted_lines>250</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
