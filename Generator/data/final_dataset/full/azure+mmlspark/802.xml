<bug_data>
<bug id='802' author='13pranav5' open_date='2020-02-15T01:24:15Z' closed_time='2020-02-28T15:34:59Z'>
 	<summary>Error - LightGBMClassifier during train with initScoreCol for multi-label classification:  java.lang.ClassCastException: org.apache.spark.ml.linalg.SparseVector cannot be cast to java.lang.Double</summary>
 	<description>
 I get the below error during training of the model. I am using AWS Databricks and the latest snapshot release of MMLSpark package.
 This happens only when i provide initScoreCol parameter. What should be the data type for the inirScoreCol values?
 20/02/15 01:20:22 INFO LightGBMClassifier: driver closing all sockets and server socket
 20/02/15 01:20:44 WARN TaskSetManager: Lost task 15.0 in stage 26.0 (TID 4100, 10.96.150.62, executor 6): java.lang.ClassCastException: org.apache.spark.ml.linalg.SparseVector cannot be cast to java.lang.Double
 at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
 at org.apache.spark.sql.Row$class.getDouble(Row.scala:259)
 at org.apache.spark.sql.catalyst.expressions.GenericRow.getDouble(rows.scala:166)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$$anonfun$generateDataset$2$$anonfun$7.apply(TrainUtils.scala:63)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$$anonfun$generateDataset$2$$anonfun$7.apply(TrainUtils.scala:63)
 at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
 at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
 at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
 at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
 at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
 at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$$anonfun$generateDataset$2.apply(TrainUtils.scala:63)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$$anonfun$generateDataset$2.apply(TrainUtils.scala:62)
 at scala.Option.foreach(Option.scala:257)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$.generateDataset(TrainUtils.scala:62)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$.translate(TrainUtils.scala:233)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:385)
 at com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)
 at com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)
 at org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:200)
 at org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:197)
 at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:865)
 at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:865)
 at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)
 at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:317)
 at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)
 at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:317)
 at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
 at org.apache.spark.scheduler.Task.doRunTask(Task.scala:140)
 at org.apache.spark.scheduler.Task.run(Task.scala:113)
 at org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:533)
 at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1541)
 at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:539)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
 20/02/15 01:20:44 INFO TaskSetManager: Starting task 15.1 in stage 26.0 (TID 4325, 10.96.145.58, executor 8, partition 227, PROCESS_LOCAL, 5633 bytes)
 20/02/15 01:20:44 WARN TaskSetManager: Lost task 15.1 in stage 26.0 (TID 4325, 10.96.145.58, executor 8): java.net.ConnectException: Connection refused (Connection refused)
 at java.net.PlainSocketImpl.socketConnect(Native Method)
 at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
 at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
 at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
 at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
 at java.net.Socket.connect(Socket.java:589)
 at java.net.Socket.connect(Socket.java:538)
 at java.net.Socket.(Socket.java:434)
 at java.net.Socket.(Socket.java:211)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$.getNetworkInitNodes(TrainUtils.scala:299)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$$anonfun$12.apply(TrainUtils.scala:372)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$$anonfun$12.apply(TrainUtils.scala:367)
 at com.microsoft.ml.spark.core.env.StreamUtilities$.using(StreamUtilities.scala:28)
 at com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:366)
 at com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)
 at com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)
 at org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:200)
 at org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:197)
 at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:865)
 at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:865)
 at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)
 at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:317)
 at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)
 at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:317)
 at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
 at org.apache.spark.scheduler.Task.doRunTask(Task.scala:140)
 at org.apache.spark.scheduler.Task.run(Task.scala:113)
 at org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:533)
 at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1541)
 at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:539)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
 	</description>
 	<comments>
 		<comment id='1' author='13pranav5' date='2020-02-26T05:36:16Z'>
 		Thank you for finding this issue, I've sent the fix here:
 &lt;denchmark-link:https://github.com/Azure/mmlspark/pull/805&gt;#805&lt;/denchmark-link&gt;
 
 Iâ€™ve based the fix on the lightgbm python code here:
 &lt;denchmark-link:https://github.com/Microsoft/LightGBM/blob/master/python-package/lightgbm/basic.py#L840&gt;https://github.com/Microsoft/LightGBM/blob/master/python-package/lightgbm/basic.py#L840&lt;/denchmark-link&gt;
 
 And here:
 &lt;denchmark-link:https://github.com/microsoft/LightGBM/blob/master/src/io/metadata.cpp#L405&gt;https://github.com/microsoft/LightGBM/blob/master/src/io/metadata.cpp#L405&lt;/denchmark-link&gt;
 
 Also see related issue:
 &lt;denchmark-link:https://github.com/microsoft/LightGBM/issues/2595&gt;microsoft/LightGBM#2595&lt;/denchmark-link&gt;
 
 LightGBM actually only takes a single column, which caused some confusion for me, but for multiclass case the column of vectors need to be reshaped to a single column where all values for class 0 are followed by all values for class 1, etc.
 		</comment>
 		<comment id='2' author='13pranav5' date='2020-02-28T15:34:59Z'>
 		closing as this issue has been fixed and merged into master with PR &lt;denchmark-link:https://github.com/Azure/mmlspark/pull/805&gt;#805&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='df0244c7b4f48e6c86bd8a5478d4b674a9a554ce' author='Ilya Matiach' date='2020-02-27 22:08:50-05:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.17391304347826086'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\main\scala\com\microsoft\ml\spark\lightgbm\LightGBMBase.scala' new_name='src\main\scala\com\microsoft\ml\spark\lightgbm\LightGBMBase.scala'>
 		<file_info nloc='115' complexity='19' token_count='1102'></file_info>
 		<method name='getTrainingCols' parameters=''>
 				<method_info nloc='14' complexity='3' token_count='155' nesting_level='0' start_line='105' end_line='120'></method_info>
 			<added_lines>112</added_lines>
 			<deleted_lines>112</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\main\scala\com\microsoft\ml\spark\lightgbm\LightGBMDataset.scala' new_name='src\main\scala\com\microsoft\ml\spark\lightgbm\LightGBMDataset.scala'>
 		<file_info nloc='78' complexity='9' token_count='599'></file_info>
 		<method name='addDoubleField' parameters='String,Int'>
 				<method_info nloc='16' complexity='1' token_count='123' nesting_level='0' start_line='54' end_line='72'></method_info>
 			<added_lines>58</added_lines>
 			<deleted_lines>58</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\main\scala\com\microsoft\ml\spark\lightgbm\TrainUtils.scala' new_name='src\main\scala\com\microsoft\ml\spark\lightgbm\TrainUtils.scala'>
 		<file_info nloc='390' complexity='64' token_count='3269'></file_info>
 		<method name='addInitScoreColumn' parameters='Int,StructType'>
 				<method_info nloc='22' complexity='4' token_count='211' nesting_level='0' start_line='81' end_line='104'></method_info>
 			<added_lines>81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='generateDataset' parameters='String,String,StructType,Logger,TrainParams'>
 				<method_info nloc='40' complexity='6' token_count='388' nesting_level='0' start_line='24' end_line='67'></method_info>
 			<added_lines>61,63</added_lines>
 			<deleted_lines>61,62,63,64</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>15</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\test\scala\com\microsoft\ml\spark\lightgbm\split1\VerifyLightGBMClassifier.scala' new_name='src\test\scala\com\microsoft\ml\spark\lightgbm\split1\VerifyLightGBMClassifier.scala'>
 		<file_info nloc='439' complexity='26' token_count='3697'></file_info>
 		<method name='assertBinaryImprovement' parameters='DataFrame,DataFrame'>
 				<method_info nloc='4' complexity='1' token_count='33' nesting_level='0' start_line='240' end_line='244'></method_info>
 			<added_lines>244</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='assertMulticlassImprovement' parameters='DataFrame,DataFrame'>
 				<method_info nloc='4' complexity='1' token_count='33' nesting_level='0' start_line='244' end_line='248'></method_info>
 			<added_lines>244,245,246,247</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>264,265,266,267,268,269,270,271,272</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
