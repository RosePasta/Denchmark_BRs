<bug_data>
<bug id='2228' author='parthshah86' open_date='2018-04-16T06:54:08Z' closed_time='2018-05-20T21:57:10Z'>
 	<summary>excludes parameter behaves differently between to_bytes and from_bytes for Doc</summary>
 	<description>
 I am trying to exclude the tensor at serialization as that leads to a huge payload, but at deserialization it creates an issue.
 &lt;denchmark-code&gt;import spacy
 from spacy.tokens import Doc
 nlp = spacy.load('en')
 doc1 = nlp(u'Spacy is a great library for nlp')
 b = doc1.to_bytes(tensor=True)
 doc2 = Doc(nlp.vocab).from_bytes(b, tensor=True)
 
 
 KeyError                                  Traceback (most recent call last)
 &lt;ipython-input-9-c1c3e2da1529&gt; in &lt;module&gt;()
 ----&gt; 1 doc2 = Doc(nlp.vocab).from_bytes(b, tensor=False)
 doc.pyx in spacy.tokens.doc.Doc.from_bytes()
 KeyError: u'tensor'
 
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;
 
 
 Operating System: MacOS Sierra 2.6 GHz Intel Core i7, 4 Cores
 Python Version Used: 2.7.13
 spaCy Version Used: 2.0.11
 Environment Information:
 
 	</description>
 	<comments>
 		<comment id='1' author='parthshah86' date='2018-04-17T08:57:51Z'>
 		Experiencing the same issue. This was also brought up before in &lt;denchmark-link:https://github.com/explosion/spaCy/issues/1920&gt;#1920&lt;/denchmark-link&gt;
  (see &lt;denchmark-link:https://github.com/explosion/spaCy/issues/1920#issuecomment-365468782&gt;comment&lt;/denchmark-link&gt;
 )
 This happens because the key  is assumed to exist (unlike ) in the  function.
 Starting in line 832 in file spacy/tokens/doc.pyx.
 &lt;denchmark-code&gt;        if 'user_data' not in exclude and 'user_data_keys' in msg:
             user_data_keys = msgpack.loads(msg['user_data_keys'],
                                            use_list=False)
             user_data_values = msgpack.loads(msg['user_data_values'])
             for key, value in zip(user_data_keys, user_data_values):
                 self.user_data[key] = value
 
         cdef attr_t[:, :] attrs
         cdef int i, start, end, has_space
         self.sentiment = msg['sentiment']
         self.tensor = msg['tensor']
 &lt;/denchmark-code&gt;
 
 A similar issue occurs when sentiment is disable.
 &lt;denchmark-code&gt;a = nlp('This is a test')
 abytes = a.to_bytes(sentiment=False)
 b = Doc(nlp.vocab).from_bytes(abytes, sentiment=False)
 &lt;/denchmark-code&gt;
 
 This produces:
 &lt;denchmark-code&gt;KeyError                                  Traceback (most recent call last)
 &lt;ipython-input-32-cd4b0af97217&gt; in &lt;module&gt;()
       1 a = nlp('This is a test')
       2 abytes = a.to_bytes(sentiment=False)
 ----&gt; 3 b = Doc(nlp.vocab).from_bytes(abytes, sentiment=False)
 
 doc.pyx in spacy.tokens.doc.Doc.from_bytes()
 
 KeyError: 'sentiment'
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='2' author='parthshah86' date='2018-05-07T00:16:10Z'>
 		Thanks &lt;denchmark-link:https://github.com/therealronnie&gt;@therealronnie&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='parthshah86' date='2018-06-19T22:45:57Z'>
 		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
 		</comment>
 	</comments>
 </bug>
<commit id='6f5ccda19c66be1dc72af79b72dac0b3483741f2' author='Mr Roboto' date='2018-05-01 13:40:22+02:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='ADD' old_name='None' new_name='.github\contributors\therealronnie.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='spacy\tests\doc\test_doc_api.py' new_name='spacy\tests\doc\test_doc_api.py'>
 		<file_info nloc='210' complexity='48' token_count='2159'></file_info>
 		<method name='test_doc_api_serialize' parameters='en_tokenizer,text'>
 				<method_info nloc='16' complexity='13' token_count='222' nesting_level='0' start_line='104' end_line='121'></method_info>
 			<added_lines>111,112,113,114,115,116,117,118,119,120,121</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>122</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='spacy\tokens\doc.pyx' new_name='spacy\tokens\doc.pyx'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>838,839,840,841,842</added_lines>
 			<deleted_lines>838,839</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
