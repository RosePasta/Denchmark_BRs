<bug_data>
<bug id='4386' author='ryszardtuora' open_date='2019-10-06T16:38:12Z' closed_time='2019-10-07T11:38:36Z'>
 	<summary>An error while pruning vectors</summary>
 	<description>
 I'm trying to retrain my models because of the 2.2 version update (btw the old ones seem to work alright, but I'm retraining them to be sure), and while trying to initialize a model using CLI i get an error inside the vector pruning function.
 The error is as follows
 ✔ Successfully created model
 2123132it [01:09, 30354.25it/s]i-forms-all-100-skipg-hs.txt
 ✔ Loaded vectors from nkjp+wiki-forms-all-100-skipg-hs.txt
 Traceback (most recent call last):
   File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
     "__main__", mod_spec)
   File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
     exec(code, run_globals)
   File "/home/rtuora/.local/lib/python3.6/site-packages/spacy/__main__.py", line 35, in &lt;module&gt;
     plac.call(commands[command], sys.argv[1:])
   File "/home/rtuora/.local/lib/python3.6/site-packages/plac_core.py", line 328, in call
     cmd, result = parser.consume(arglist)
   File "/home/rtuora/.local/lib/python3.6/site-packages/plac_core.py", line 207, in consume
     return cmd, self.func(*(args + varargs + extraopts), **kwargs)
   File "/home/rtuora/.local/lib/python3.6/site-packages/spacy/cli/init_model.py", line 90, in init_model
     add_vectors(nlp, vectors_loc, prune_vectors, vectors_name)
   File "/home/rtuora/.local/lib/python3.6/site-packages/spacy/cli/init_model.py", line 201, in add_vectors
     nlp.vocab.prune_vectors(prune_vectors)
   File "vocab.pyx", line 324, in spacy.vocab.Vocab.prune_vectors
   File "vectors.pyx", line 341, in spacy.vectors.Vectors.most_similar
 ValueError: could not broadcast input array from shape (1323132,1) into shape (1024,1)
 
 &lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;
 
 the exact commend I use is
 python3 -m spacy init-model pl output --vectors-loc nkjp+wiki-forms-all-100-skipg-hs.txt --prune-vectors 800000
 I've tried this with 2 different embeddings, and all seems to work well unless I enable the pruning option.
 &lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;
 
 
 spaCy version: 2.2.1
 Platform: Linux-4.15.0-58-generic-x86_64-with-Ubuntu-18.04-bionic
 Python version: 3.6.8
 
 BTW: I'm not sure if my reasoning on pruning vectors is correct. The loading times of my models are very long, and I suspect this might be because of it. If my initial embeddings have 3.5 m entries, and I prune them down to the first 800.000, is this a good practice for a general purpose model? Perhaps I should delete these entries altogether, as their effect on regular parsing task must be marginal (or maybe even need not be positive).
 	</description>
 	<comments>
 		<comment id='1' author='ryszardtuora' date='2019-10-07T08:06:02Z'>
 		The most_similar() method was just updated and it looks like it's not taking the batch_size into account correctly. We'll look into it.
 		</comment>
 		<comment id='2' author='ryszardtuora' date='2019-11-06T11:54:33Z'>
 		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
 		</comment>
 	</comments>
 </bug>
<commit id='d53a8d9313099b0c9724e28ca276603274749313' author='adrianeboyd' date='2019-10-07 13:38:35+02:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='spacy\vectors.pyx' new_name='spacy\vectors.pyx'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>340</added_lines>
 			<deleted_lines>340</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
