<bug_data>
<bug id='4051' author='prashantbudania' open_date='2019-07-30T22:46:02Z' closed_time='2019-09-08T11:04:50Z'>
 	<summary>Retokenizer not setting POS tags correctly</summary>
 	<description>
 &lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;
 
 I am trying to merge entities and noun chunks for a custom application without having to use merge_entities or merge_noun_chunks pipeline. But the pos tag information is inaccurate. Here's one example:
 &lt;denchmark-code&gt;import spacy 
 from spacy import displacy
 from spacy.util import filter_spans
 
 nlp = spacy.load('en_2.1.0_md')
 doc = nlp("While our net charge-off rate improved from a year ago, our provision expense increased due to a $150 million reserve build in the first quarter of 2019 compared with a $550 million reserve release a year ago.")
 
 spans = list(doc.ents) + list(doc.noun_chunks)
 spans = filter_spans(spans)
 
 with doc.retokenize() as retokenizer:
     for span in spans:
         retokenizer.merge(span)
 
 for i, tkn in enumerate(doc):
     print("{:&lt;2}{:&lt;2}{:&lt;32}{:&lt;2}{:&lt;8}{:&lt;2}{:&lt;8}{:&lt;2}{:&lt;2}".format(i, '|', tkn.text, '|', tkn.pos_, '|', tkn.dep_, '|', tkn.ent_type_))
 &lt;/denchmark-code&gt;
 
 But if I specifically set the pos attribute to be the same as the root's attribute, it works fine:
 &lt;denchmark-code&gt;with doc.retokenize() as retokenizer:
     for span in spans:
         retokenizer.merge(span, attrs={"POS": span.root.pos_})
 &lt;/denchmark-code&gt;
 
 I remember this being the default behaviour in 2.0. And also, even after the fix, displacy would show the incorrect pos tag information:
 &lt;denchmark-code&gt;displacy.render(doc, style='dep')
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;
 
 
 Operating System: MacOS
 Python Version Used: 3.6
 spaCy Version Used: 2.1.4
 
 	</description>
 	<comments>
 		<comment id='1' author='prashantbudania' date='2019-07-31T08:46:21Z'>
 		Thanks for the report. I think what you're obversing here in displaCy might be related to a recent change that made the pos attribute writable (but possibly doesn't always account for the pos → tag) relationship. What happens if you set both the POS and the TAG?
 And yes, I do think it makes sense for those attribute to default to the root – not sure why this isn't happening here.
 		</comment>
 		<comment id='2' author='prashantbudania' date='2019-07-31T14:44:38Z'>
 		Yeah, it works fine if both the POS and the TAG attributes are set.
 		</comment>
 		<comment id='3' author='prashantbudania' date='2019-10-08T11:42:58Z'>
 		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
 		</comment>
 	</comments>
 </bug>
<commit id='aec755d3a3439c406801543c004975d718af4a56' author='adrianeboyd' date='2019-09-08 13:04:49+02:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='spacy\tests\doc\test_retokenize_merge.py' new_name='spacy\tests\doc\test_retokenize_merge.py'>
 		<file_info nloc='340' complexity='39' token_count='3817'></file_info>
 		<method name='test_doc_retokenize_spans_merge_tokens_default_attrs' parameters='en_tokenizer'>
 				<method_info nloc='33' complexity='3' token_count='363' nesting_level='0' start_line='102' end_line='134'></method_info>
 			<added_lines>102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_doc_retokenize_spans_entity_merge_iob' parameters=''>
 				<method_info nloc='32' complexity='1' token_count='319' nesting_level='0' start_line='185' end_line='218'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>185,198,218</deleted_lines>
 		</method>
 		<method name='test_doc_retokenize_spans_entity_merge_iob' parameters='en_vocab'>
 				<method_info nloc='83' complexity='1' token_count='873' nesting_level='0' start_line='220' end_line='312'></method_info>
 			<added_lines>220,233,234,238,239,240,241,242,243,244,245,246,247,248,249,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>135,136</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='spacy\tokens\_retokenize.pyx' new_name='spacy\tokens\_retokenize.pyx'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>112,113,138,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,281,400,401,402,403,404,405,406,407,408</added_lines>
 			<deleted_lines>112,113,114,115,116,117,118,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,354,355,356,357,358,359,360,361,362,363,364</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
