<bug_data>
<bug id='6318' author='AndriyMulyar' open_date='2020-10-28T21:34:19Z' closed_time='2021-01-07T07:48:34Z'>
 	<summary>Cannot use BiLSTM encoder with transition based NER parser. [spacy-nightly]</summary>
 	<description>
 I get the following error when attempting to use the BiLSTM encoder with the NER transition based parser:
 ℹ Using CPU
 
 =========================== Initializing pipeline ===========================
 ✘ Can't construct config: calling registry function
 (build_Tok2Vec_model) failed
 spacy.Tok2Vec.v1   "Cannot get dimension 'nO' for model 'with_padded(with_padded(pytorch))'"
 
 {'model': {'@architectures': 'spacy.Tok2Vec.v1', 'embed': {'@architectures': 'spacy.MultiHashEmbed.v1', 'width': 100, 'attrs': ['ORTH', 'SHAPE'], 'rows': [5000, 2500], 'include_static_vectors': 'True'}, 'encode': {'@architectures': 'spacy.TorchBiLSTMEncoder.v1', 'width': 100, 'depth': 2, 'dropout': 0.30000000000000004}}}
 Could the pytorch BiLSTM wrapper encoder perhaps be missing a line like this (which appears in the CNN encoders):
 
 
 
 spaCy/spacy/ml/models/tok2vec.py
 
 
          Line 274
       in
       dc816bb
 
 
 
 
 
 
  model.set_dim("nO", width) 
 
 
 
 
 
 
 
 
 spaCy/spacy/ml/models/tok2vec.py
 
 
          Line 302
       in
       dc816bb
 
 
 
 
 
 
  @registry.architectures.register("spacy.TorchBiLSTMEncoder.v1") 
 
 
 
 
 
 Also the docstring is not accurate (seems to be copied from the CNNs)
 My model components look like this:
 [components]
 
 [components.tok2vec]
 factory = "tok2vec"
 
 [components.tok2vec.model]
 @architectures = "spacy.Tok2Vec.v1"
 
 [components.tok2vec.model.embed]
 @architectures = "spacy.MultiHashEmbed.v1"
 width = ${components.tok2vec.model.encode.width}
 attrs = ["ORTH", "SHAPE"]
 rows = [5000, 2500]
 include_static_vectors = True
 
 [components.tok2vec.model.encode]
 @architectures = "spacy.TorchBiLSTMEncoder.v1"
 width = 100
 depth = 2
 dropout = ${training.dropout}
 
 [components.ner]
 factory = "ner"
 
 [components.ner.model]
 @architectures = "spacy.TransitionBasedParser.v1"
 state_type = "ner"
 extra_state_tokens = false
 hidden_width = 64
 maxout_pieces = 2
 use_upper = true
 nO = null
 
 [components.ner.model.tok2vec]
 @architectures = "spacy.Tok2VecListener.v1"
 width = ${components.tok2vec.model.encode.width}
 	</description>
 	<comments>
 		<comment id='1' author='AndriyMulyar' date='2020-10-29T09:06:39Z'>
 		Thanks for the report! That does look suspicious. Usually the nO dimension should be set by initializing the model with example input &amp; output, so that it can infer the dimensions, but this may not work with the Torch encoder. You could be right that we need to set it specifically. I'll have a look!
 		</comment>
 		<comment id='2' author='AndriyMulyar' date='2020-11-24T16:45:59Z'>
 		This issue was a bit more involved than I had initially hoped, but I think &lt;denchmark-link:https://github.com/explosion/spaCy/pull/6442&gt;#6442&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/explosion/thinc/pull/432&gt;explosion/thinc#432&lt;/denchmark-link&gt;
  together should fix this. At least the training now runs for me when I replicate your config.
 Thanks again for the detailed report!
 [EDIT: it works when I set include_static_vectors to False and fails with a different error otherwise, but that's another issue that I'm looking into]
 [EDIT 2: Never mind the above, it works with static vectors as well when setting e.g. vectors = "en_core_web_lg"]
 		</comment>
 	</comments>
 </bug>
<commit id='75d90193434ce13ff22b4210bfa063f9c3096936' author='Sofie Van Landeghem' date='2021-01-07 16:39:27+11:00'>
 	<dmm_unit complexity='1.0' interfacing='0.42857142857142855' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='spacy\cli\templates\quickstart_training.jinja' new_name='spacy\cli\templates\quickstart_training.jinja'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>208,223</added_lines>
 			<deleted_lines>208,223</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='spacy\ml\models\tok2vec.py' new_name='spacy\ml\models\tok2vec.py'>
 		<file_info nloc='376' complexity='16' token_count='1657'></file_info>
 		<method name='build_Tok2Vec_model' parameters=''>
 				<method_info nloc='3' complexity='1' token_count='32' nesting_level='0' start_line='114' end_line='116'></method_info>
 			<added_lines>114,115,116</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='MaxoutWindowEncoder' parameters='int,int,int,int'>
 				<method_info nloc='2' complexity='1' token_count='17' nesting_level='0' start_line='314' end_line='315'></method_info>
 			<added_lines>314,315</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='MishWindowEncoder' parameters='int,int,int'>
 				<method_info nloc='2' complexity='1' token_count='13' nesting_level='0' start_line='370' end_line='371'></method_info>
 			<added_lines>370,371</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>90,112,113,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,281,313,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,345,369,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,401,402,403</added_lines>
 			<deleted_lines>322,323,324</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='spacy\pipeline\morphologizer.pyx' new_name='spacy\pipeline\morphologizer.pyx'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>27,38</added_lines>
 			<deleted_lines>27,38</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='spacy\pipeline\textcat.py' new_name='spacy\pipeline\textcat.py'>
 		<file_info nloc='349' complexity='25' token_count='1699'></file_info>
 		<modified_lines>
 			<added_lines>22,32</added_lines>
 			<deleted_lines>22,32</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='spacy\tests\pipeline\test_tok2vec.py' new_name='spacy\tests\pipeline\test_tok2vec.py'>
 		<file_info nloc='161' complexity='13' token_count='1139'></file_info>
 		<modified_lines>
 			<added_lines>116,126</added_lines>
 			<deleted_lines>116,126</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='website\docs\api\architectures.md' new_name='website\docs\api\architectures.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>29,35,42,200,206,224,230,255,256,262,263,264,265,266,267,603,613</added_lines>
 			<deleted_lines>29,35,42,200,206,224,230,255,256,262,263,264,265,266,267,603,613</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='website\docs\usage\embeddings-transformers.md' new_name='website\docs\usage\embeddings-transformers.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>132,138,164,170</added_lines>
 			<deleted_lines>132,138,164,170</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='website\docs\usage\layers-architectures.md' new_name='website\docs\usage\layers-architectures.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>137,147,204,211,227</added_lines>
 			<deleted_lines>137,147,204,211,227</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
