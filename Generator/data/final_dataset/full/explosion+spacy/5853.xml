<bug_data>
<bug id='5853' author='thefirebanks' open_date='2020-08-01T02:25:58Z' closed_time='2020-08-03T11:53:16Z'>
 	<summary>Noun chunks not being updated appropriately according to multiple sentences in paragraph</summary>
 	<description>
 &lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;
 
 Hello! First of all, this awesome package! I am trying to do 2 things:
 
 Divide a string into sentences
 Get the noun_chunks of each sentence
 
 I am aiming to do this in a variety of languages, but primarily experimenting with English, Spanish and Portuguese.
 Issue 1: With the Spanish model, I get the following behavior:
 
 
 Sentence 1:  En resúmen AR es un servicio que auxilia los tecnicos de campo a obtener ayuda en la atención de casos     complejos o que necesite de un soporte de un especialista.
 Noun chunks:  [AR, un servicio, los tecnicos, campo, ayuda, la atención, casos, complejos, un soporte, un especialista]
 
 
 Sentence 2:  Se puede con eso utilizar del smartphone para compartir de manera segura la imagen del device permitindo que se haga notaciones en la pantalla facilitando el reparo.
 Noun chunks:  [AR, un servicio, los tecnicos, campo, ayuda, la atención, casos, complejos, un soporte]
 
 
 As you can see, the noun chunks for sentence 2 seem to be referring to the first sentence, as if when I call sentence.noun_chunks I would still be referring to the past sentence.
 &lt;denchmark-link:https://user-images.githubusercontent.com/31460539/89092012-f7733600-d362-11ea-82c8-89a8cc80297e.png&gt;&lt;/denchmark-link&gt;
 
 Issue 2: With the Portuguese model, I get the following sentence (same code as above only with the portuguese model pt_core_news_sm loaded:
 
 
 Sentence 1: Qual é o link para o estudo de Forrester sobre MVS em Portugues?
 noun chunks: [[]]
 
 
 Sentence 2: Aproveite a leitura e compartilhe com seus clientes.
 noun chunks: [[]]
 
 
 Am I doing something wrong or is this expected behavior? Maybe because it's a different language? In English things seem to be working relatively well. Thank you very much!
 &lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;
 
 
 Operating System: MacOS Catalina 10.15.5
 Python Version Used: 3.7
 spaCy Version Used:  2.3.2
 Environment Information:
 
 	</description>
 	<comments>
 		<comment id='1' author='thefirebanks' date='2020-08-03T07:02:43Z'>
 		Thanks for the report, this does look like a bug for Spanish. We'll look into it!
 Not all languages have an implemented noun_chunks method and there isn't one yet for Portuguese. Since it relies on UD POS tags and dependencies, it's possible that once the Spanish noun_chunks is fixed, you can adapt it easily to also work for Portuguese, since I would guess that Portuguese noun chunks are quite similar to Spanish noun chunks.
 		</comment>
 	</comments>
 </bug>
<commit id='cd59979ab446d7613ec7df5d5737539464918edf' author='Adriane Boyd' date='2020-08-03 13:53:15+02:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='spacy\lang\es\syntax_iterators.py' new_name='spacy\lang\es\syntax_iterators.py'>
 		<file_info nloc='53' complexity='18' token_count='358'></file_info>
 		<method name='noun_chunks' parameters='doclike'>
 				<method_info nloc='21' complexity='8' token_count='177' nesting_level='0' start_line='8' end_line='30'></method_info>
 			<added_lines>23</added_lines>
 			<deleted_lines>23,24</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
