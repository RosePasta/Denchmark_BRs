<bug_data>
<bug id='4871' author='danielvasic' open_date='2020-01-03T15:04:56Z' closed_time='2020-02-16T16:16:42Z'>
 	<summary>AttributeError: 'FunctionLayer' object has no attribute 'W'</summary>
 	<description>
 Hello, I have a problem using pretrained vectors with command line API. Steps to reproduce:
 &lt;denchmark-code&gt;python -m spacy pretrain fulltext.jsonl vectors/hr_vectors_web_md models/hr/language --use-vectors --use-char --dropout 0.3 --n-iter 60
 &lt;/denchmark-code&gt;
 
 After that trying to train NER tagger with this command:
 &lt;denchmark-code&gt;python -m spacy train hr models/ner train-ner.json dev-ner.json -v vectors/hr_vectors_web_md --init-tok2vec models/hr/language/model59.bin -p ner
 &lt;/denchmark-code&gt;
 
 Produces:
 
 Traceback (most recent call last):
 File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
 "main", mod_spec)
 File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
 exec(code, run_globals)
 File "/usr/local/lib/python3.6/dist-packages/spacy/main.py", line 33, in 
 plac.call(commands[command], sys.argv[1:])
 File "/usr/local/lib/python3.6/dist-packages/plac_core.py", line 328, in call
 cmd, result = parser.consume(arglist)
 File "/usr/local/lib/python3.6/dist-packages/plac_core.py", line 207, in consume
 return cmd, self.func(*(args + varargs + extraopts), **kwargs)
 File "/usr/local/lib/python3.6/dist-packages/spacy/cli/train.py", line 244, in train
 components = _load_pretrained_tok2vec(nlp, init_tok2vec)
 File "/usr/local/lib/python3.6/dist-packages/spacy/cli/train.py", line 551, in _load_pretrained_tok2vec
 component.tok2vec.from_bytes(weights_data)
 File "/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py", line 375, in from_bytes
 dest = getattr(layer, name)
 AttributeError: 'FunctionLayer' object has no attribute 'W'
 
 I'm using Google Colaboratory enviroment.
 &lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;
 
 
 spaCy version: 2.2.3
 Platform: Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic
 Python version: 3.6.9
 
 	</description>
 	<comments>
 		<comment id='1' author='danielvasic' date='2020-02-14T13:17:26Z'>
 		Hi &lt;denchmark-link:https://github.com/danielvasic&gt;@danielvasic&lt;/denchmark-link&gt;
 , thanks for the report!
 It looks like this is due to the  argument you used for , which should be replicated when you run the  command, but that option was not supported yet. PR &lt;denchmark-link:https://github.com/explosion/spaCy/pull/5021&gt;#5021&lt;/denchmark-link&gt;
  should hopefully fix that. See also my more extensive comment &lt;denchmark-link:https://github.com/explosion/spaCy/issues/4819#issuecomment-586282668&gt;here&lt;/denchmark-link&gt;
 .
 		</comment>
 		<comment id='2' author='danielvasic' date='2020-02-14T13:40:50Z'>
 		Dear &lt;denchmark-link:https://github.com/svlandeg&gt;@svlandeg&lt;/denchmark-link&gt;
  , thanks for the response.
 Looking forward for the support of --use-char option in train command as it's very important for morphologically rich languages such as Croatian. I will try to train the model without this option for now.
 All the best,
 Daniel
 		</comment>
 		<comment id='3' author='danielvasic' date='2020-02-14T13:46:20Z'>
 		As a quick hack, you could also set the environment variable  to  (it needs to be the negation of ), then the parser will hopefully find it &lt;denchmark-link:https://github.com/explosion/spaCy/blob/master/spacy/syntax/nn_parser.pyx#L57&gt;here&lt;/denchmark-link&gt;
 .
 All of this will be thoroughly refactored and much easier to work with, from spaCy v.3 onwards ;-)
 		</comment>
 		<comment id='4' author='danielvasic' date='2020-02-14T13:51:44Z'>
 		Actually, one more thought. If you want character embeddings, you should try running without vectors. Have a look at the code &lt;denchmark-link:https://github.com/explosion/spaCy/blob/master/spacy/ml/_legacy_tok2vec.py#L63&gt;here&lt;/denchmark-link&gt;
 :  is only used when  and  is  !
 		</comment>
 		<comment id='5' author='danielvasic' date='2020-02-14T13:57:14Z'>
 		I'm afraid I do not have enough annotated data not to use pre trained word vectors, I have already trained model using FastText word vectors, but  I will try this and compare the results maybe I'm wrong, many thanks for the support :-)
 		</comment>
 		<comment id='6' author='danielvasic' date='2020-02-14T13:57:34Z'>
 		And yet another note: you can add a block for CharacterEmbed combined with a vector, but there's a bug in concatenate_lists on GPU so you can only use it on CPU. (Which is probably part of why CharacterEmbed isn't used in any spacy v2.2 models by default.)
 		</comment>
 		<comment id='7' author='danielvasic' date='2020-02-14T17:19:52Z'>
 		&lt;denchmark-link:https://github.com/adrianeboyd&gt;@adrianeboyd&lt;/denchmark-link&gt;
  thank you very much for the suggestion, will give it a try.
 All the best,
 Daniel
 		</comment>
 		<comment id='8' author='danielvasic' date='2020-03-17T16:37:19Z'>
 		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
 		</comment>
 	</comments>
 </bug>
<commit id='257246017572433af7825d561de573dae73828f0' author='Sofie Van Landeghem' date='2020-02-16 17:16:41+01:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='spacy\cli\pretrain.py' new_name='spacy\cli\pretrain.py'>
 		<file_info nloc='319' complexity='25' token_count='2052'></file_info>
 		<method name='pretrain' parameters='texts_loc,vectors_model,output_dir,width,depth,bilstm_depth,cnn_pieces,sa_depth,use_chars,cnn_window,embed_rows,loss_func,use_vectors,dropout,n_iter,batch_size,max_length,min_length,seed,n_save_every,init_tok2vec,epoch_start'>
 				<method_info nloc='23' complexity='1' token_count='86' nesting_level='0' start_line='82' end_line='104'></method_info>
 			<added_lines>87</added_lines>
 			<deleted_lines>87</deleted_lines>
 		</method>
 		<method name='pretrain' parameters='texts_loc,vectors_model,output_dir,width,conv_depth,bilstm_depth,cnn_pieces,sa_depth,use_chars,cnn_window,embed_rows,loss_func,use_vectors,dropout,n_iter,batch_size,max_length,min_length,seed,n_save_every,init_tok2vec,epoch_start'>
 				<method_info nloc='23' complexity='1' token_count='86' nesting_level='0' start_line='82' end_line='104'></method_info>
 			<added_lines>87</added_lines>
 			<deleted_lines>87</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>37,135,136,137,138,139,140,143,171</added_lines>
 			<deleted_lines>37,137,165</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='spacy\cli\train.py' new_name='spacy\cli\train.py'>
 		<file_info nloc='631' complexity='40' token_count='4184'></file_info>
 		<method name='train' parameters='lang,output_path,train_path,dev_path,raw_text,base_model,pipeline,replace_components,vectors,width,conv_depth,cnn_window,cnn_pieces,use_chars,bilstm_depth,embed_rows,n_iter,n_early_stopping,n_examples,use_gpu,version,meta_path,init_tok2vec,parser_multitasks,entity_multitasks,noise_level,orth_variant_level,eval_beam_widths,gold_preproc,learn_tokens,textcat_multilabel,textcat_arch,textcat_positive_label,verbose,debug'>
 				<method_info nloc='36' complexity='1' token_count='139' nesting_level='0' start_line='64' end_line='99'></method_info>
 			<added_lines>74,75,76,77,78,79,80</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>36,37,38,39,40,41,42,133,268,269,270,271,272,273,274,275,276,401,402,403,404,405,406,407,408,409,410,411,412,413</added_lines>
 			<deleted_lines>253,378,379,380,381,382,383,384</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
