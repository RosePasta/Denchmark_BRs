<bug_data>
<bug id='2942' author='opatrascoiu' open_date='2018-11-18T12:38:40Z' closed_time='2018-12-03T00:33:22Z'>
 	<summary>Initialization in text</summary>
 	<description>
 In method from
 &lt;denchmark-link:https://github.com/explosion/spacy/blob/master/examples/training/train_textcat.py&gt;https://github.com/explosion/spacy/blob/master/examples/training/train_textcat.py&lt;/denchmark-link&gt;
 
 tp, fp, fn, and tn (true positives etc) are initialized to 1e-8 (see below)
 &lt;denchmark-code&gt;tp = 1e-8  # True positives
 fp = 1e-8  # False positives
 fn = 1e-8  # False negative
 tn = 1e-8  # True negatives
 &lt;/denchmark-code&gt;
 
 Why are the values not initlaized to 0? When there are no true positives the precision is 0.5, That doesn't seem right.
 	</description>
 	<comments>
 		<comment id='1' author='opatrascoiu' date='2018-11-26T12:57:37Z'>
 		Fair point --- I was avoiding the divide-by-zero error, but if there are no true or false positives, I guess the precision should be 0.0. It should be more correct to initialize tp and tn to 0.0, while fp and fn are initialized to a small value to avoid the denominator being zero.
 Do you want to make a pull request?
 		</comment>
 		<comment id='2' author='opatrascoiu' date='2019-01-02T01:01:33Z'>
 		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
 		</comment>
 	</comments>
 </bug>
<commit id='ae5601beae505d46861aae230522d956d9979b17' author='Gavriel Loria' date='2018-12-03 01:33:22+01:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='ADD' old_name='None' new_name='.github\contributors\gavrieltal.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\training\train_textcat.py' new_name='examples\training\train_textcat.py'>
 		<file_info nloc='103' complexity='25' token_count='823'></file_info>
 		<method name='evaluate' parameters='tokenizer,textcat,texts,cats'>
 				<method_info nloc='23' complexity='13' token_count='209' nesting_level='0' start_line='107' end_line='129'></method_info>
 			<added_lines>109,112</added_lines>
 			<deleted_lines>109,112</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
