<bug_data>
<bug id='6737' author='vitaly-d' open_date='2021-01-16T09:10:21Z' closed_time='2021-01-18T19:43:53Z'>
 	<summary>rc3 from develop: training NER with transformer encoder on GPU: Implicit conversion to a NumPy array in _resize_lower</summary>
 	<description>
 &lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;
 
  was started with config generated for Components:NER and Hardware:GPU as it is described at &lt;denchmark-link:https://nightly.spacy.io/usage/training#quickstart&gt;https://nightly.spacy.io/usage/training#quickstart&lt;/denchmark-link&gt;
 . It failed trying to get an evaluation score:
 &lt;denchmark-code&gt;⚠ Aborting and saving the final best model. Encountered exception:
 TypeError('Implicit conversion to a NumPy array is not allowed. Please use
 `.get()` to construct a NumPy array explicitly.')
 Traceback (most recent call last):
   File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
     return _run_code(code, main_globals, None,
   File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
     exec(code, run_globals)
   File "/spaCy/spacy/__main__.py", line 4, in &lt;module&gt;
     setup_cli()
   File "/spaCy/spacy/cli/_util.py", line 65, in setup_cli
     command(prog_name=COMMAND)
   File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 829, in __call__
     return self.main(*args, **kwargs)
   File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 782, in main
     rv = self.invoke(ctx)
   File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1259, in invoke
     return _process_result(sub_ctx.command.invoke(sub_ctx))
   File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
     return ctx.invoke(self.callback, **ctx.params)
   File "/opt/conda/lib/python3.8/site-packages/click/core.py", line 610, in invoke
     return callback(*args, **kwargs)
   File "/opt/conda/lib/python3.8/site-packages/typer/main.py", line 497, in wrapper
     return callback(**use_params)  # type: ignore
   File "/spaCy/spacy/cli/train.py", line 59, in train_cli
     train(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)
   File "/spaCy/spacy/training/loop.py", line 113, in train
     raise e
   File "/spaCy/spacy/training/loop.py", line 98, in train
     for batch, info, is_best_checkpoint in training_step_iterator:
   File "/spaCy/spacy/training/loop.py", line 210, in train_while_improving
     score, other_scores = evaluate()
   File "/spaCy/spacy/training/loop.py", line 261, in evaluate
     scores = nlp.evaluate(dev_corpus(nlp))
   File "/spaCy/spacy/language.py", line 1321, in evaluate
     for doc, eg in zip(
   File "/spaCy/spacy/util.py", line 1378, in _pipe
     yield from proc.pipe(docs, **kwargs)
   File "spacy/pipeline/transition_parser.pyx", line 184, in pipe
   File "spacy/pipeline/transition_parser.pyx", line 196, in spacy.pipeline.transition_parser.Parser.predict
   File "spacy/pipeline/transition_parser.pyx", line 213, in spacy.pipeline.transition_parser.Parser.greedy_parse
   File "spacy/pipeline/transition_parser.pyx", line 136, in spacy.pipeline.transition_parser.Parser._resize
   File "/spaCy/spacy/ml/models/parser.py", line 141, in resize_output
     return _resize_lower(model, new_nO)
   File "/spaCy/spacy/ml/models/parser.py", line 201, in _resize_lower
     larger_W[:, 0:old_nO, :, :] = smaller_W
   File "cupy/core/core.pyx", line 1188, in cupy.core.core.ndarray.__array__
 TypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.
 &lt;/denchmark-code&gt;
 
 I have commented out the 'with use_ops("numpy"):' line and it solves the problem. So it might be a fix if the lower layer is supposed to use CuPy.
 &lt;denchmark-code&gt;diff --git a/spacy/ml/models/parser.py b/spacy/ml/models/parser.py
 index 7ce0165a2..da53f562e 100644
 --- a/spacy/ml/models/parser.py
 +++ b/spacy/ml/models/parser.py
 @@ -185,8 +185,7 @@ def _resize_lower(model, new_nO):
      nI = smaller.maybe_get_dim("nI")
      nF = smaller.maybe_get_dim("nF")
      nP = smaller.maybe_get_dim("nP")
 -    with use_ops("numpy"):
 -        larger = _define_lower(nO=new_nO, nI=nI, nF=nF, nP=nP)
 +    larger = _define_lower(nO=new_nO, nI=nI, nF=nF, nP=nP)
      # it could be that the model is not initialized yet, then skip this bit
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;
 
 
 spaCy version: 3.0.0rc3
 branch: develop
 Commit: git rev-parse HEAD -&gt;  f0c696b
 Platform: Linux-5.4.0-60-generic-x86_64-with-glibc2.10
 Python version: 3.8.5
 Pipelines: en_core_web_lg (3.0.0a0), en_core_web_sm (3.0.0a0), en_core_web_trf (3.0.0a0)
 
 	</description>
 	<comments>
 		<comment id='1' author='vitaly-d' date='2021-01-16T22:43:44Z'>
 		Thanks for the report! Can you give the exact commands you ran to create the config, and run the training?
 		</comment>
 		<comment id='2' author='vitaly-d' date='2021-01-17T12:08:37Z'>
 		Hi!
 
 The initial config was generated using the quickstart widget at https://nightly.spacy.io/usage/training#quickstart (I did not use the init config command for that).
 Then 'init fill-config' and  'debug config' were called. '{vars.config}.cfg' points to authors_affiliations_ner_trf.cfg in the attached spaCy_6737.zip. The resulting config.cfg used for training is also included. The only modification I made is progressbar=true for training.logger.
 
 &lt;denchmark-code&gt;    help: "Train Affiliations NER: ${vars.model_name}"
     script:
       - "python -m spacy init fill-config configs/${vars.config}.cfg training/config.cfg"
       - "python -m spacy debug config training/config.cfg --paths.train corpus/${vars.train_name} --paths.dev corpus/${vars.dev_name} --nlp.lang=${vars.lang}"
       - "python -m spacy train training/config.cfg --output training/${vars.model_name} --gpu-id ${vars.gpu} --paths.train corpus/${vars.train_name} --paths.dev corpus/${vars.dev_name} --nlp.lang=${vars.lang}"
 &lt;/denchmark-code&gt;
 
 Also I've experimented with the 'spacy init config' command and realized that the config I used for training contains 'architectures = "spacy.TransitionBasedParser.v1"instead of @architectures = "spacy.TransitionBasedParser.v2". But the issue can also be reproduced with the output of spacy init config:
 &lt;denchmark-code&gt;# spacy init config configs/c.cfg -p ner -G -F
 ℹ Generated config template specific for your use case
 - Language: en
 - Pipeline: ner
 - Optimize for: efficiency
 - Hardware: GPU
 - Transformer: roberta-base
 /opt/conda/lib/python3.8/site-packages/thinc/config.py:1040: RuntimeWarning: fields may not start with an underscore, ignoring "_doc_data"
   return create_model("ArgModel", **sig_args)
 ✔ Auto-filled config with all values
 ✔ Saved config
 configs/c.cfg
 You can now add your data and train your pipeline:
 python -m spacy train c.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;# diff configs/c.cfg training/config.cfg
 29c29
 &lt; @architectures = "spacy.TransitionBasedParser.v2"
 ---
 &gt; @architectures = "spacy.TransitionBasedParser.v1"
 94c94
 &lt; size = 2000
 ---
 &gt; size = 4000
 100c100
 &lt; progress_bar = false
 ---
 &gt; progress_bar = true
 &lt;/denchmark-code&gt;
 
 Thanks!
 		</comment>
 		<comment id='3' author='vitaly-d' date='2021-01-18T17:44:33Z'>
 		Thanks for the detailed report!
 We've located and fixed the issue, and it'll be in the next release candidate rc3 (the one you're using is the one under development from the develop branch but not the actual released version yet ;-))
 		</comment>
 	</comments>
 </bug>
<commit id='26c34ab8b00466ec9b3daa8e9194bad068ee9e1c' author='Adriane Boyd' date='2021-01-18 20:43:15+01:00'>
 	<dmm_unit complexity='0.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='spacy\ml\models\parser.py' new_name='spacy\ml\models\parser.py'>
 		<file_info nloc='184' complexity='18' token_count='1001'></file_info>
 		<method name='_resize_lower' parameters='model,new_nO'>
 				<method_info nloc='30' complexity='5' token_count='275' nesting_level='0' start_line='178' end_line='211'></method_info>
 			<added_lines>188</added_lines>
 			<deleted_lines>188,189</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
