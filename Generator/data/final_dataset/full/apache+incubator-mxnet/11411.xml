<bug_data>
<bug id='11411' author='safrooze' open_date='2018-06-27T01:31:27Z' closed_time='2018-08-21T15:43:02Z'>
 	<summary>nd.softmax() doesn't support grad_req='add'</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
  does not support adding gradients specified by setting  to . This is obvious in &lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/a0a52b38a9046a3ede20c900ff64154642e8e2da/src/operator/nn/softmax-inl.h#L267&gt;this line of code&lt;/denchmark-link&gt;
 .
 However,  which is deprecated does support  equal to . This issue came up in &lt;denchmark-link:https://discuss.mxnet.io/t/aggregate-gradients-manually-over-n-batches/504/14?u=safrooze&gt;this discuss questions&lt;/denchmark-link&gt;
 .
 Package used: Python
 &lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;mxnet.base.MXNetError: [18:24:22] src/operator/nn/./softmax-inl.h:267: Check failed: req[0] != kAddTo (3 vs. 3)
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;
 
 import mxnet as mx
 from mxnet import gluon, nd, autograd
 
 print(mx.__version__)
 
 grad_req = 'add'
 
 x = (nd.random.uniform(shape=(2, 10)) - 0.5) * 10
 x_g = nd.zeros_like(x)
 
 autograd.mark_variables(x, x_g, grad_req)
 
 with autograd.record():
     # Change nd.softmax to nd.SoftmaxActivation and the code doesn't throw an error
     y = nd.softmax(x)
 y.backward()
 print(x_g.asnumpy())
 	</description>
 	<comments>
 		<comment id='1' author='safrooze' date='2018-06-27T15:54:14Z'>
 		&lt;denchmark-link:https://github.com/safrooze&gt;@safrooze&lt;/denchmark-link&gt;
  Thank you for submitting the issue! We are labeling it so MXNet community members can help resolve it.
 		</comment>
 		<comment id='2' author='safrooze' date='2018-07-12T21:31:50Z'>
 		&lt;denchmark-link:https://github.com/safrooze&gt;@safrooze&lt;/denchmark-link&gt;
  Taking a look at this now.
 		</comment>
 		<comment id='3' author='safrooze' date='2018-07-20T16:41:36Z'>
 		&lt;denchmark-link:https://github.com/safrooze&gt;@safrooze&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/11836&gt;#11836&lt;/denchmark-link&gt;
  should fix this issue, I've tried your reproduction script and here's the output from it:
 &lt;denchmark-code&gt;1.3.0
 [[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
     0.00000000e+00   0.00000000e+00]
  [ -3.20495186e-09  -2.34470221e-10  -3.99168448e-10  -9.83819623e-11
    -3.74679523e-08  -8.85198338e-12  -7.68905792e-08  -7.67132469e-11
    -2.32276004e-10  -5.95953564e-10]]
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='4' author='safrooze' date='2018-08-20T22:46:19Z'>
 		That's great, thanks &lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
 !
 		</comment>
 		<comment id='5' author='safrooze' date='2018-08-21T15:43:24Z'>
 		Resolving as  &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/11836&gt;#11836&lt;/denchmark-link&gt;
  is merged.
 		</comment>
 	</comments>
 </bug>
<commit id='d7b39f4c055a46c1b819b0dff4ae468c1983e016' author='Hao Jin' date='2018-08-20 22:38:08-07:00'>
 	<dmm_unit complexity='0.625' interfacing='0.5' size='0.5'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\operator\contrib\ctc_loss-inl.h' new_name='src\operator\contrib\ctc_loss-inl.h'>
 		<file_info nloc='398' complexity='47' token_count='3136'></file_info>
 		<method name='mxnet::op::CTCLossOp::cudnn_forward' parameters='ctx,s,data,costs,grad,data_lengths,label_lengths,packed_labels,max_seq_len,batch_size,alphabet_size,req_grad'>
 				<method_info nloc='71' complexity='5' token_count='507' nesting_level='3' start_line='354' end_line='433'></method_info>
 			<added_lines>429</added_lines>
 			<deleted_lines>429</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\softmax-inl.h' new_name='src\operator\nn\softmax-inl.h'>
 		<file_info nloc='248' complexity='37' token_count='2515'></file_info>
 		<method name='mxnet::op::mxnet_op::SoftmaxGrad' parameters='s,out,ograd,igrad,shape,axis,temperature'>
 				<method_info nloc='29' complexity='6' token_count='308' nesting_level='3' start_line='115' end_line='150'></method_info>
 			<added_lines>137,140,141,145,146</added_lines>
 			<deleted_lines>139,143</deleted_lines>
 		</method>
 		<method name='mxnet::op::mxnet_op::SoftmaxGrad' parameters='s,out,ograd,igrad,shape,axis,temperature'>
 				<method_info nloc='15' complexity='1' token_count='156' nesting_level='3' start_line='238' end_line='253'></method_info>
 			<added_lines>249</added_lines>
 			<deleted_lines>244</deleted_lines>
 		</method>
 		<method name='mxnet::op::SoftmaxGradCompute' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='26' complexity='4' token_count='330' nesting_level='2' start_line='299' end_line='324'></method_info>
 			<added_lines>312,313,314,315,316,317,318,319,320,321,322</added_lines>
 			<deleted_lines>301,308,309,310,311,312,313,314,315,316,317,318</deleted_lines>
 		</method>
 		<method name='mxnet::op::mxnet_op::softmax_gradient_kernel' parameters='out,ograd,igrad,M,axis,sshape,stride,temperature'>
 				<method_info nloc='24' complexity='3' token_count='252' nesting_level='3' start_line='209' end_line='234'></method_info>
 			<added_lines>228,230,231,232</added_lines>
 			<deleted_lines>226,227,232</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>114,208,237</added_lines>
 			<deleted_lines>114,205</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\unittest\test_operator.py' new_name='tests\python\unittest\test_operator.py'>
 		<file_info nloc='5734' complexity='937' token_count='71886'></file_info>
 		<method name='test_new_softmax' parameters=''>
 				<method_info nloc='13' complexity='3' token_count='172' nesting_level='0' start_line='4523' end_line='4535'></method_info>
 			<added_lines>4525,4526,4527,4528,4529,4530,4531,4532,4533,4534,4535</added_lines>
 			<deleted_lines>4525,4526,4527,4528,4529,4530,4531</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>4536</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
