<bug_data>
<bug id='11849' author='wgchang' open_date='2018-07-21T16:50:16Z' closed_time='2018-09-18T22:47:15Z'>
 	<summary>gluon.SymbolBlock cannot imports resnet trained with dtype="float16"</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 Cannot load fine-tuned resnet101 (incubator-mxnet/example/image-classification/symbols/resnet.py) with dtype="float16"  with "gluon.SymbolBlock.imports" method.
 &lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;
 
 AssertionError: Failed loading Parameter 'stage3_unit2_conv2_weight' from saved params: dtype incompatible expected &lt;type 'numpy.float32'&gt; vs saved &lt;type 'numpy.float16'&gt;
 &lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;
 
 net = gluon.SymbolBlock.imports('resnet-101-symbol.json',['data','softmax_label'],'resnet-101-0007.params')  # This line gives the error message.
 net = gluon.SymbolBlock.imports('resnet-101-symbol.json',['data','softmax_label']) 
 print(net.collect_params())
 &lt;denchmark-h:h2&gt;My Questions&lt;/denchmark-h&gt;
 
 In incubator-mxnet/example/image-classification/symbols/resnet.py,
 there is mx.sym.Cast for type conversion.
 I fine-tuned resnet101 with dtype="float16", and I need to load this model as HybridBlock, However, the method gluon.SymbolBlock.imports makes every params' type in the network as float32. Therefore, the trained model cannot be updated.
 Here, resnet-101-0007.params are trained with argument dtype='float16'
 In resnet-101-symbol.json file, there is the Cast op.
 {
 "op": "Cast",
 "name": "cast0",
 "attrs": {"dtype": "float16"},
 "inputs": [[7, 0, 0]]
 },
 It seems that gluon.SymbolBlock.imports does not consider the type conversion operator.
 For now, I think I need to load all parameter manualy, and change types then save.
 Is there any other solution to solve this problem?
 	</description>
 	<comments>
 		<comment id='1' author='wgchang' date='2018-07-23T22:24:28Z'>
 		&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
  Please help to label this issue 
 		</comment>
 		<comment id='2' author='wgchang' date='2018-08-14T08:36:57Z'>
 		Got the same problem here. Any updates here?
 		</comment>
 		<comment id='3' author='wgchang' date='2018-08-22T16:59:52Z'>
 		&lt;denchmark-link:https://github.com/rahul003&gt;@rahul003&lt;/denchmark-link&gt;
  same problem here, can't load back saved float16 models
 		</comment>
 		<comment id='4' author='wgchang' date='2018-08-29T22:16:44Z'>
 		Using below snippet:
 &lt;denchmark-code&gt;import mxnet as mx
 
 ctx = mx.cpu(0)
 data = mx.nd.zeros((1,3,224,224), ctx=ctx, dtype='float64')
 net_fp32 = mx.gluon.model_zoo.vision.resnet34_v2(pretrained=True, ctx=ctx)
 net_fp32.cast('float64')
 net_fp32.hybridize()
 pred = net_fp32.forward(data)
 net_fp32.export('resnet34_fp16', 0)
 print('export fp16 model')
 
 sm = mx.sym.load('resnet34_fp16-symbol.json')
 inputs = mx.sym.var('data', dtype='float64')
 net_fp16 = mx.gluon.SymbolBlock(sm, inputs)
 net_fp16.collect_params().load('resnet34_fp16-0000.params', ctx)
 pred = net_fp16.forward(data)
 &lt;/denchmark-code&gt;
 
 Below are my findings:
 
 Casting worked fine.
 Saved parameters are in the correct format (fp64 in my sample code)
 sym.load worked fine. If I infer symbol's type (sym.infer_type(data='float64') I get correct inferred type (float64) for all params.
 
 Below is the issue:
 
 When you create mx.gluon.SymbolBlock(sm, input). It creates the parameters in the Block. Type is not passed for creating the parameter.
 See here - https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/block.py#L1058 and the behavior is "If there is not parameter to get, it creates one and uses default type (fp32) https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/parameter.py#L688
 
 I am working on the fix.
 &lt;denchmark-link:https://github.com/apeforest&gt;@apeforest&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/ThomasDelteil&gt;@ThomasDelteil&lt;/denchmark-link&gt;
   - FYI
 		</comment>
 		<comment id='5' author='wgchang' date='2018-09-18T22:47:15Z'>
 		Resolving as changes are merged.
 		</comment>
 	</comments>
 </bug>
<commit id='acf309e87d48e47c7da7684a74a557aef5a76124' author='Sandeep Krishnamurthy' date='2018-09-18 15:46:53-07:00'>
 	<dmm_unit complexity='0.5833333333333334' interfacing='0.5833333333333334' size='0.041666666666666664'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\mxnet\gluon\block.py' new_name='python\mxnet\gluon\block.py'>
 		<file_info nloc='790' complexity='207' token_count='5115'></file_info>
 		<method name='cast' parameters='self,dtype'>
 				<method_info nloc='3' complexity='1' token_count='23' nesting_level='1' start_line='1095' end_line='1097'></method_info>
 			<added_lines>1095,1096,1097</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_infer_param_types' parameters='in_params,out_params,arg_params,aux_params,default_dtype'>
 				<method_info nloc='25' complexity='13' token_count='188' nesting_level='0' start_line='1102' end_line='1162'></method_info>
 			<added_lines>1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,outputs,inputs,params'>
 				<method_info nloc='34' complexity='13' token_count='368' nesting_level='1' start_line='1030' end_line='1074'></method_info>
 			<added_lines>1057,1058,1059,1060,1062,1063,1064,1065,1066,1067,1068,1069,1070</added_lines>
 			<deleted_lines>1056,1057,1058,1060,1061,1062</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>29,1098,1101</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\mxnet\gluon\parameter.py' new_name='python\mxnet\gluon\parameter.py'>
 		<file_info nloc='643' complexity='156' token_count='3806'></file_info>
 		<method name='get' parameters='self,name,kwargs'>
 				<method_info nloc='36' complexity='16' token_count='246' nesting_level='1' start_line='685' end_line='740'></method_info>
 			<added_lines>730,731</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\gpu\test_gluon_gpu.py' new_name='tests\python\gpu\test_gluon_gpu.py'>
 		<file_info nloc='170' complexity='32' token_count='1981'></file_info>
 		<method name='test_symbol_block_fp16' parameters=''>
 				<method_info nloc='18' complexity='4' token_count='204' nesting_level='0' start_line='207' end_line='234'></method_info>
 			<added_lines>207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>21,206,235</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\unittest\test_gluon.py' new_name='tests\python\unittest\test_gluon.py'>
 		<file_info nloc='1159' complexity='154' token_count='11876'></file_info>
 		<method name='test_symbol_block' parameters=''>
 				<method_info nloc='47' complexity='4' token_count='543' nesting_level='0' start_line='302' end_line='375'></method_info>
 			<added_lines>342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>18,19,20,376</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
