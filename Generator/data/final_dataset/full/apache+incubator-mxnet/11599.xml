<bug_data>
<bug id='11599' author='junrushao1994' open_date='2018-07-07T06:52:45Z' closed_time='2018-08-16T00:07:19Z'>
 	<summary>Autograd fails when using `take` operator repeatedly</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 Here provides a strange example that a backward pass on the accumulated sum of a 2-d NDArray sc, may potentially cause autograd to fail, depending on the shape of sc.
 &lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;
 
 TL;DR. This code calculates x = sum(sc[i, j] for each i, j), and then invokes a backward pass x.backward(). The error message says that it could not calculate the gradient w.r.t. some variables, but I didn't require gradient for non-differentiable variables like i or j.
 import mxnet as mx
 
 def _array(shape):
     """Create an NDArray with random entries and the given shape
     """
     return mx.nd.random.uniform(-1.0, 1.0, shape=shape, dtype="float32")
 
 def index(sc, i, j):
     """Equivalent to sc[i, j] in numpy
     """
     return sc.take(i).squeeze(axis=0)  \
              .take(j).squeeze(axis=0)
 
 # tweaking `sc` in different shapes, the code sometimes fails, sometimes not
 row_len, col_len = 2, 8
 
 # the scanned variable
 sc = _array((row_len, col_len))
 sc.attach_grad()  # we only require the gradient w.r.t. `sc`
 
 # `i`, `j` are loop variables which don't require grad
 i = mx.nd.array([0], dtype="int64")
 j = mx.nd.array([0], dtype="int64")
 
 with mx.autograd.record(train_mode=True):
     xs = []
     for _ in range(row_len):
         x_i = []
         for _ in range(col_len):
             x_ij = index(sc, i, j)
             x_i.append(x_ij)
             j = j + 1
         i = i + 1
         j = j - col_len  # reset j
         xs.append(mx.nd.stack(*x_i))
     x = mx.nd.stack(*xs)
     x = x.sum()
 
 x.backward()
 print(sc.grad.asnumpy())   # the expected result should be all `1`s
 &lt;denchmark-h:h2&gt;Error Message&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;&gt;&gt; python2 test.py
 /home/ubuntu/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
   from ._conv import register_converters as _register_converters
 Traceback (most recent call last):
   File "test.py", line 33, in &lt;module&gt;
     print(sc.grad.asnumpy())
   File "/home/ubuntu/Projects/mxnet/python/mxnet/ndarray/ndarray.py", line 1910, in asnumpy
     ctypes.c_size_t(data.size)))
   File "/home/ubuntu/Projects/mxnet/python/mxnet/base.py", line 210, in check_call
     raise MXNetError(py_str(_LIB.MXGetLastError()))
 mxnet.base.MXNetError: [06:43:28] src/operator/tensor/./indexing_op.h:829: Check failed: req[take_::kIdx] == kNullOp (1 vs. 0) take layer doesn't support gradient into index
 
 Stack trace returned 10 entries:
 [bt] (0) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x5b) [0x7f740cb6231b]
 [bt] (1) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x28) [0x7f740cb62b58]
 [bt] (2) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::op::TakeOpBackward&lt;mshadow::cpu&gt;(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)+0x220) [0x7f740e46c710]
 [bt] (3) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::imperative::PushFCompute(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt; const&amp;, nnvm::Op const*, nnvm::NodeAttrs const&amp;, mxnet::Context const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::Resource, std::allocator&lt;mxnet::Resource&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;unsigned int, std::allocator&lt;unsigned int&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x291) [0x7f740f26a7b1]
 [bt] (4) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext), mxnet::engine::ThreadedEngine::BulkAppend(std::function&lt;void (mxnet::RunContext)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;)+0x68) [0x7f740f7a7538]
 [bt] (5) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext), mxnet::engine::ThreadedEngine::BulkAppend(std::function&lt;void (mxnet::RunContext)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;)+0x47) [0x7f740f7a7517]
 [bt] (6) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext), mxnet::engine::ThreadedEngine::BulkAppend(std::function&lt;void (mxnet::RunContext)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;)+0x47) [0x7f740f7a7517]
 [bt] (7) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext), mxnet::engine::ThreadedEngine::BulkAppend(std::function&lt;void (mxnet::RunContext)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;)+0x47) [0x7f740f7a7517]
 [bt] (8) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext), mxnet::engine::ThreadedEngine::BulkAppend(std::function&lt;void (mxnet::RunContext)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;)+0x47) [0x7f740f7a7517]
 [bt] (9) /home/ubuntu/Projects/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext), mxnet::engine::ThreadedEngine::BulkAppend(std::function&lt;void (mxnet::RunContext)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;)+0x47) [0x7f740f7a7517]
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;
 
 
 Save the code as test.py, and run python2 test.py
 
 &lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;
 
 I have no idea where it comes from. That by tweaking row_len and col_len, it behaves differently seems weird to me. I only observed that
 
 When row_len = 1, it never fails
 When row_len = 2, and col_len &lt; 8, it doesn't fails; when col_len &gt;= 8, it fails
 When row_len = 3, and col_len &lt; 7, it doesn't fails; when col_len &gt;= 7, it fails
 When row_len = 4, and col_len &lt; 7, it doesn't fails; when col_len &gt;= 7, it fails
 
 &lt;denchmark-h:h2&gt;Environment info&lt;/denchmark-h&gt;
 
 Not relevant though.
 &lt;denchmark-code&gt;----------Python Info----------
 ('Version      :', '2.7.15')
 ('Compiler     :', 'GCC 7.2.0')
 ('Build        :', ('default', 'May  1 2018 23:32:55'))
 ('Arch         :', ('64bit', ''))
 ------------Pip Info-----------
 ('Version      :', '10.0.1')
 ('Directory    :', '/home/ubuntu/anaconda2/lib/python2.7/site-packages/pip')
 ----------MXNet Info-----------
 /home/ubuntu/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
   from ._conv import register_converters as _register_converters
 ('Version      :', '1.3.0')
 ('Directory    :', '/home/ubuntu/Projects/junru-mxnet/python/mxnet')
 Hashtag not found. Not installed from pre-built package.
 ----------System Info----------
 ('Platform     :', 'Linux-4.4.0-1062-aws-x86_64-with-debian-stretch-sid')
 ('system       :', 'Linux')
 ('node         :', 'ip-172-31-42-30')
 ('release      :', '4.4.0-1062-aws')
 ('version      :', '#71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018')
 ----------Hardware Info----------
 ('machine      :', 'x86_64')
 ('processor    :', 'x86_64')
 Architecture:          x86_64
 CPU op-mode(s):        32-bit, 64-bit
 Byte Order:            Little Endian
 CPU(s):                72
 On-line CPU(s) list:   0-71
 Thread(s) per core:    2
 Core(s) per socket:    18
 Socket(s):             2
 NUMA node(s):          2
 Vendor ID:             GenuineIntel
 CPU family:            6
 Model:                 85
 Model name:            Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz
 Stepping:              3
 CPU MHz:               3000.000
 BogoMIPS:              6000.00
 Hypervisor vendor:     KVM
 Virtualization type:   full
 L1d cache:             32K
 L1i cache:             32K
 L2 cache:              1024K
 L3 cache:              25344K
 NUMA node0 CPU(s):     0-17,36-53
 NUMA node1 CPU(s):     18-35,54-71
 Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single kaiser fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f rdseed adx smap clflushopt clwb avx512cd xsaveopt xsavec xgetbv1 ida arat
 ----------Network Test----------
 Setting timeout: 10
 Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0019 sec, LOAD: 0.5934 sec.
 Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0070 sec, LOAD: 0.1024 sec.
 Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0099 sec, LOAD: 0.5567 sec.
 Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0035 sec, LOAD: 0.0305 sec.
 Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0994 sec, LOAD: 0.5750 sec.
 Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1169 sec, LOAD: 0.5358 sec.
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Build info&lt;/denchmark-h&gt;
 
 Compiler: gcc
 MXNet commit hash: &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/dd954b45a35d5eb9e8cdb6c6e19dd872a0a3d84d&gt;dd954b4&lt;/denchmark-link&gt;
  (current HEAD)
 Build config: default
 	</description>
 	<comments>
 		<comment id='1' author='junrushao1994' date='2018-07-07T06:54:01Z'>
 		&lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/zheng-da&gt;@zheng-da&lt;/denchmark-link&gt;
  Could you help take a look at this? Did I misunderstand anything about the  operator? Thanks!
 		</comment>
 		<comment id='2' author='junrushao1994' date='2018-07-09T23:09:05Z'>
 		&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
  Could you please label this issue: ,
 		</comment>
 		<comment id='3' author='junrushao1994' date='2018-07-09T23:11:12Z'>
 		&lt;denchmark-link:https://github.com/junrushao1994&gt;@junrushao1994&lt;/denchmark-link&gt;
  will take a look later today
 		</comment>
 		<comment id='4' author='junrushao1994' date='2018-07-11T00:43:44Z'>
 		So the problem is that the req type of the indices is not null, maybe this is due to the usage, I'll take a deeper dive into your issue later.
 		</comment>
 		<comment id='5' author='junrushao1994' date='2018-07-31T18:55:52Z'>
 		Hey any updates?
 		</comment>
 		<comment id='6' author='junrushao1994' date='2018-08-02T00:26:05Z'>
 		Fix in &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/11983&gt;#11983&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='7' author='junrushao1994' date='2018-08-02T00:37:43Z'>
 		Thank you &lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
 ! You rock!
 		</comment>
 		<comment id='8' author='junrushao1994' date='2018-08-02T00:40:17Z'>
 		Will close the issue once &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/11983&gt;#11983&lt;/denchmark-link&gt;
  is merged
 		</comment>
 		<comment id='9' author='junrushao1994' date='2018-08-16T00:07:19Z'>
 		Closed since &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/11983&gt;#11983&lt;/denchmark-link&gt;
  is merged. Thank you &lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
 !
 		</comment>
 	</comments>
 </bug>
<commit id='0455a112c9aaa681b3e3e194975eb46d8ac4fcc3' author='Hao Jin' date='2018-08-15 15:31:14-07:00'>
 	<dmm_unit complexity='0.7931034482758621' interfacing='0.8620689655172413' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\operator\tensor\indexing_op.h' new_name='src\operator\tensor\indexing_op.h'>
 		<file_info nloc='1271' complexity='197' token_count='12097'></file_info>
 		<method name='mxnet::op::TakeOpBackward' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='52' complexity='8' token_count='574' nesting_level='2' start_line='1028' end_line='1094'></method_info>
 			<added_lines>1037,1038,1055,1056,1057,1058,1059</added_lines>
 			<deleted_lines>1037,1038</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\unittest\test_operator.py' new_name='tests\python\unittest\test_operator.py'>
 		<file_info nloc='5644' complexity='914' token_count='70731'></file_info>
 		<method name='test_take' parameters=''>
 				<method_info nloc='16' complexity='7' token_count='125' nesting_level='0' start_line='3762' end_line='3852'></method_info>
 			<added_lines>3815,3816,3817,3818,3819,3820,3821,3822,3823,3824,3825,3826,3827,3828,3829,3830,3831,3832,3833,3834,3835,3836,3837,3838,3839,3852</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_take.check_autograd_req' parameters=''>
 				<method_info nloc='23' complexity='3' token_count='223' nesting_level='1' start_line='3815' end_line='3838'></method_info>
 			<added_lines>3815,3816,3817,3818,3819,3820,3821,3822,3823,3824,3825,3826,3827,3828,3829,3830,3831,3832,3833,3834,3835,3836,3837,3838</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>3853</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
