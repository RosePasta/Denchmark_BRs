<bug_data>
<bug id='9405' author='opringle' open_date='2018-01-12T20:22:57Z' closed_time='2018-03-20T20:02:35Z'>
 	<summary>BucketingModule causes uncaught exception if symbol name not specified</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 When using the BucketingModule together with mx.rnn.BuckSentenceIter, I hit an uncaught exception if I do not specify the symbol name in either mx.sym.Embedding or mx.sym.FullyConnected symbols, despite each symbol in the network having a unique name.
 &lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;----------Python Info----------
 Version      : 3.6.3
 Compiler     : GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)
 Build        : ('default', 'Oct  4 2017 06:09:15')
 Arch         : ('64bit', '')
 ------------Pip Info-----------
 Version      : 9.0.1
 Directory    : /Users/opringle/Envs/finn-dl/lib/python3.6/site-packages/pip
 ----------MXNet Info-----------
 Version      : 1.0.0
 Directory    : /Users/opringle/Envs/finn-dl/lib/python3.6/site-packages/mxnet
 Commit Hash   : 2b67436802b750e15b9fbfdf275958c1000be6a8
 ----------System Info----------
 Platform     : Darwin-17.3.0-x86_64-i386-64bit
 system       : Darwin
 node         : MacBook-Pro-2.local
 release      : 17.3.0
 version      : Darwin Kernel Version 17.3.0: Thu Nov  9 18:09:22 PST 2017; root:xnu-4570.31.3~1/RELEASE_X86_64
 ----------Hardware Info----------
 machine      : x86_64
 processor    : i386
 b'machdep.cpu.brand_string: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz'
 b'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'
 b'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 HLE AVX2 BMI2 INVPCID RTM SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT'
 b'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'
 ----------Network Test----------
 Setting timeout: 10
 Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0077 sec, LOAD: 0.4726 sec.
 Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0263 sec, LOAD: 0.0633 sec.
 Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0897 sec, LOAD: 0.0599 sec.
 Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0259 sec, LOAD: 0.1184 sec.
 Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0139 sec, LOAD: 0.2371 sec.
 Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0305 sec, LOAD: 0.2018 sec.
 &lt;/denchmark-code&gt;
 
 I'm using python
 &lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;libc++abi.dylib: terminating with uncaught exception of type std::out_of_range: unordered_map::at: key not found
 Abort trap: 6
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;
 
 import mxnet as mx
 import random
 
 #synthetically create 1000 encoded sentences
 encoded_sentences = []
 for i in list(range(1000)):
     sentence_length = random.randint(1,20)
     sentence = random.sample(range(20), sentence_length)
     encoded_sentences.append(sentence)
 
 #define hyperparameters/info
 vocab = list(set(index for list in encoded_sentences for index in list))
 batch_size = 18
 num_embed = 10
 num_hidden = 3
 buckets = [5,10,15,20]
 epochs = 15
 
 #use mxnet bucketing iterator, label is next value in sentence
 train_iter = mx.rnn.BucketSentenceIter(sentences = encoded_sentences,
                                        batch_size = batch_size,
                                        buckets = buckets,
                                        data_name = 'data',
                                        label_name = 'softmax_label')
 
 #define recurrent cell outside of network TODO: why outside?
 r_cell = mx.rnn.LSTMCell(num_hidden=num_hidden)
 
 #define a network symbol based on sentence length
 def sym_gen1(seq_len):
 
     print("-" * 50)
 
     #define input shape so we can infer layer shapes as we go
     data_shape = (batch_size, seq_len)
     label_shape = (batch_size, seq_len)
 
     data = mx.sym.Variable('data')
     print("\ndata shape: ", data.infer_shape(data=data_shape)[1][0], "\n")
 
     label = mx.sym.Variable('softmax_label')
     print("\nlabel shape: ", label.infer_shape(softmax_label=label_shape)[1][0], "\n")
 
     embed = mx.sym.Embedding(data=data, input_dim=len(vocab), output_dim=num_embed,name='embed')
     print("\nembed layer shape: ", embed.infer_shape(data=data_shape)[1][0], "\n")
 
     output, shapes = r_cell.unroll(seq_len, inputs=embed, merge_outputs=True)
     print("\nconcatenated recurrent layer shape: ", output.infer_shape(data=data_shape)[1][0], "after ", seq_len, " unrolls\n")
 
     reshape = mx.sym.Reshape(output, shape=(-1, num_hidden))
     print("\nafter reshaping: ", reshape.infer_shape(data=data_shape)[1][0], "\n")
 
     fc = mx.sym.FullyConnected(data=reshape, num_hidden=len(vocab), name='pred')
     print("\nfully connected layer shape: ", fc.infer_shape(data=data_shape)[1][0], "\n")
 
     label = mx.sym.Reshape(label, shape=(-1,))
     print("\nlabel shape after reshaping: ", label.infer_shape(softmax_label=label_shape)[1][0], "\n")
 
     pred = mx.sym.SoftmaxOutput(data=fc, label=label, name='softmax')
     print("\nsoftmax shape: ", pred.infer_shape(data=data_shape, softmax_label = label_shape)[1][0], "\n")
 
     return pred, ('data',), ('softmax_label',)
 
 #define identical symbol but remove name arguement from fully connected layer
 def sym_gen2(seq_len):
 
     print("-" * 50)
 
     #define input shape so we can infer layer shapes as we go
     data_shape = (batch_size, seq_len)
     label_shape = (batch_size, seq_len)
 
     data = mx.sym.Variable('data')
     print("\ndata shape: ", data.infer_shape(data=data_shape)[1][0], "\n")
 
     label = mx.sym.Variable('softmax_label')
     print("\nlabel shape: ", label.infer_shape(softmax_label=label_shape)[1][0], "\n")
 
     embed = mx.sym.Embedding(data=data, input_dim=len(vocab), output_dim=num_embed,name='embed')
     print("\nembed layer shape: ", embed.infer_shape(data=data_shape)[1][0], "\n")
 
     output, shapes = r_cell.unroll(seq_len, inputs=embed, merge_outputs=True)
     print("\nconcatenated recurrent layer shape: ", output.infer_shape(data=data_shape)[1][0], "after ", seq_len, " unrolls\n")
 
     reshape = mx.sym.Reshape(output, shape=(-1, num_hidden))
     print("\nafter reshaping: ", reshape.infer_shape(data=data_shape)[1][0], "\n")
 
     fc = mx.sym.FullyConnected(data=reshape, num_hidden=len(vocab))
     print("\nfully connected layer shape: ", fc.infer_shape(data=data_shape)[1][0], "\n")
 
     label = mx.sym.Reshape(label, shape=(-1,))
     print("\nlabel shape after reshaping: ", label.infer_shape(softmax_label=label_shape)[1][0], "\n")
 
     pred = mx.sym.SoftmaxOutput(data=fc, label=label, name='softmax')
     print("\nsoftmax shape: ", pred.infer_shape(data=data_shape, softmax_label = label_shape)[1][0], "\n")
 
     return pred, ('data',), ('softmax_label',)
 
 
 #create a trainable bucketing module on cpu
 model = mx.mod.BucketingModule(sym_gen=sym_gen1, default_bucket_key=train_iter.default_bucket_key, context=mx.cpu())
 model_not_working = mx.mod.BucketingModule(sym_gen=sym_gen2, default_bucket_key=train_iter.default_bucket_key, context=mx.cpu())
 
 #fit the first module
 print("\n\n\nFITTING FIRST MODULE...\n\n\n")
 metric = mx.metric.create('loss')
 model.bind(data_shapes=train_iter.provide_data,
            label_shapes=train_iter.provide_label)
 model.init_params()
 model.init_optimizer(optimizer='Adam')
 for epoch in range(epochs):
     train_iter.reset()
     metric.reset()
     for batch in train_iter:
         model.forward(batch, is_train=True)             # compute predictions
         model.backward()                                # compute gradients
         model.update()                                  # update parameters
         model.update_metric(metric, batch.label)        # update metric
     print('\n', 'Epoch %d, Training %s' % (epoch, metric.get()))
 
 #fit the second module
 print("\n\n\nFITTING SECOND MODULE...\n\n\n")
 metric = mx.metric.create('loss')
 model_not_working.bind(data_shapes=train_iter.provide_data,
            label_shapes=train_iter.provide_label)
 model_not_working.init_params()
 model_not_working.init_optimizer(optimizer='Adam')
 for epoch in range(epochs):
     train_iter.reset()
     metric.reset()
     for batch in train_iter:
         model_not_working.forward(batch, is_train=True)             # compute predictions
         model_not_working.backward()                                # compute gradients
         model_not_working.update()                                  # update parameters
         model_not_working.update_metric(metric, batch.label)        # update metric
     print('\n', 'Epoch %d, Training %s' % (epoch, metric.get()))
 &lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;
 
 
 Run the script
 You will see the module fit correctly with gen_sym1() but fail with gen_sym2().  The only difference between the two is the name arguement has been removed from fc = mx.sym.FullyConnected(data=reshape, num_hidden=len(vocab), name='pred').
 
 &lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;
 
 
 I have solved the problem by including an input to the name parameter when creating the symbol.
 
 	</description>
 	<comments>
 		<comment id='1' author='opringle' date='2018-02-14T10:40:19Z'>
 		+1 for this. This is actually a very annoying bug.
 		</comment>
 		<comment id='2' author='opringle' date='2018-02-27T20:28:38Z'>
 		&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
   : Please tag: Bug
 		</comment>
 		<comment id='3' author='opringle' date='2018-03-03T21:33:53Z'>
 		Facing the same problem. However, in Gluon, it cannot define a name
 		</comment>
 	</comments>
 </bug>
<commit id='dd85860be914a1e7aa10a9ebebc18546fd262425' author='Anirudh Subramanian' date='2018-03-20 13:02:34-07:00'>
 	<dmm_unit complexity='1.0' interfacing='0.4' size='0.6'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\mxnet\module\bucketing_module.py' new_name='python\mxnet\module\bucketing_module.py'>
 		<file_info nloc='272' complexity='42' token_count='1570'></file_info>
 		<method name='_call_sym_gen' parameters='self,args,kwargs'>
 				<method_info nloc='3' complexity='1' token_count='27' nesting_level='1' start_line='106' end_line='108'></method_info>
 			<added_lines>106,107,108</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='output_names' parameters='self'>
 				<method_info nloc='6' complexity='2' token_count='39' nesting_level='1' start_line='120' end_line='126'></method_info>
 			<added_lines>125</added_lines>
 			<deleted_lines>120</deleted_lines>
 		</method>
 		<method name='switch_bucket' parameters='self,bucket_key,data_shapes,label_shapes'>
 				<method_info nloc='19' complexity='3' token_count='166' nesting_level='1' start_line='352' end_line='382'></method_info>
 			<added_lines>366</added_lines>
 			<deleted_lines>361</deleted_lines>
 		</method>
 		<method name='data_names' parameters='self'>
 				<method_info nloc='6' complexity='2' token_count='35' nesting_level='1' start_line='111' end_line='117'></method_info>
 			<added_lines>116</added_lines>
 			<deleted_lines>111</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>34,75,109,335</added_lines>
 			<deleted_lines>74,330</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\unittest\test_module.py' new_name='tests\python\unittest\test_module.py'>
 		<file_info nloc='649' complexity='74' token_count='7822'></file_info>
 		<method name='test_module_switch_bucket.sym_gen' parameters='seq_len'>
 				<method_info nloc='14' complexity='2' token_count='190' nesting_level='1' start_line='273' end_line='289'></method_info>
 			<added_lines>277</added_lines>
 			<deleted_lines>277</deleted_lines>
 		</method>
 		<method name='test_module_switch_bucket' parameters=''>
 				<method_info nloc='23' complexity='1' token_count='170' nesting_level='0' start_line='261' end_line='317'></method_info>
 			<added_lines>277,302,303,304,305</added_lines>
 			<deleted_lines>277</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
