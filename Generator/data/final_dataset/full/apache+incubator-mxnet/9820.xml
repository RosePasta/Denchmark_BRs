<bug_data>
<bug id='9820' author='marcoabreu' open_date='2018-02-18T11:13:26Z' closed_time='2018-03-01T10:55:31Z'>
 	<summary>Flaky test_gluon_model_zoo_gpu.test_training @ Python3: MKLDNN-GPU</summary>
 	<description>
 &lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9809/4/pipeline&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9809/4/pipeline&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/389/pipeline&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/389/pipeline&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/391/pipeline&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/391/pipeline&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/387/pipeline&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/387/pipeline&lt;/denchmark-link&gt;
 
 &lt;denchmark-code&gt;======================================================================
 
 FAIL: test_gluon_model_zoo_gpu.test_training
 
 ----------------------------------------------------------------------
 
 Traceback (most recent call last):
 
   File "/usr/local/lib/python3.5/dist-packages/nose/case.py", line 198, in runTest
 
     self.test(*self.arg)
 
   File "/workspace/tests/python/gpu/../unittest/common.py", line 155, in test_new
 
     orig_test(*args, **kwargs)
 
   File "/workspace/tests/python/gpu/test_gluon_model_zoo_gpu.py", line 159, in test_training
 
     assert_almost_equal(cpu_out.asnumpy(), gpu_out.asnumpy(), rtol=1e-2, atol=1e-2)
 
   File "/workspace/python/mxnet/test_utils.py", line 493, in assert_almost_equal
 
     raise AssertionError(msg)
 
 AssertionError: 
 
 Items are not equal:
 
 Error 84.491165 exceeds tolerance rtol=0.010000, atol=0.010000.  Location of maximum error:(9, 877), a=0.816808, b=-0.181214
 
  a: array([[ 0.46908194,  0.25131682,  0.27432024, ..., -0.3243659 ,
 
         -0.8637756 ,  0.57461524],
 
        [ 0.18945426,  0.32339886,  0.18884647, ...,  0.00044107,...
 
  b: array([[ 0.34904164,  0.3221189 ,  0.05189171, ..., -0.14858764,
 
         -0.9381798 ,  0.39666444],
 
        [ 0.3438487 ,  0.4455883 ,  0.32494336, ...,  0.15454161,...
 
 -------------------- &gt;&gt; begin captured logging &lt;&lt; --------------------
 
 urllib3.connectionpool: DEBUG: Starting new HTTP connection (1): data.mxnet.io
 
 urllib3.connectionpool: DEBUG: http://data.mxnet.io:80 "GET /data/val-5k-256.rec HTTP/1.1" 200 150874780
 
 root: INFO: downloaded http://data.mxnet.io/data/val-5k-256.rec into data/val-5k-256.rec successfully
 
 common: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1760574333 to reproduce.
 
 --------------------- &gt;&gt; end captured logging &lt;&lt; ---------------------
 
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='marcoabreu' date='2018-02-18T17:03:00Z'>
 		I think we should disable it for now.
 I run the tests many times. It seems both CPU and GPU occasionally generate
 incorrect results. I need more time to test the tests.
 &lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;
 
 
 On Sun, Feb 18, 2018 at 3:13 AM Marco de Abreu ***@***.***&gt; wrote:
  ´´´ FAIL: test_gluon_model_zoo_gpu.test_training
 
  Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/nose/case.py", line 197, in
  runTest
  self.test(*self.arg)
  File "/workspace/tests/python/gpu/test_gluon_model_zoo_gpu.py", line 150,
  in test_training
  assert_almost_equal(cpu_out.asnumpy(), gpu_out.asnumpy(), rtol=1e-2,
  atol=1e-2)
  File "/workspace/python/mxnet/test_utils.py", line 495, in
  assert_almost_equal
  raise AssertionError(msg)
  AssertionError:
  Items are not equal:
  Error 76.641708 exceeds tolerance rtol=0.010000, atol=0.010000. Location
  of maximum error:(9, 304), a=0.754152, b=-0.052508
  a: array([[ 0.45648926, -0.19809955, 0.35798055, ..., 1.0708873 ,
  -0.3380539 , -0.22070615],
  [ 0.42138988, 0.02357741, 0.38420224, ..., 1.0584493 ,...
  b: array([[ 0.28696495, -0.17991166, 0.37088192, ..., 1.0100358 ,
  -0.3728746 , -0.14392784],
  [ 0.27283525, 0.03558442, 0.45698166, ..., 0.9900025 ,...
  -------------------- &gt;&gt; begin captured logging &lt;&lt; --------------------
  urllib3.connectionpool: DEBUG: Starting new HTTP connection (1):
  data.mxnet.io
  urllib3.connectionpool: DEBUG: http://data.mxnet.io:80 "GET
  /data/val-5k-256.rec HTTP/1.1" 200 150874780
  root: INFO: downloaded http://data.mxnet.io/data/val-5k-256.rec into
  data/val-5k-256.rec successfully
  --------------------- &gt;&gt; end captured logging &lt;&lt; ---------------------
  ´´´
 
  —
  You are receiving this because you are subscribed to this thread.
  Reply to this email directly, view it on GitHub
  &lt;#9820&gt;, or mute the
  thread
  &lt;https://github.com/notifications/unsubscribe-auth/AAETUbgbE8AKGK5QtCNCn119Qr8M2JNlks5tWAXYgaJpZM4SJpzP&gt;
  .
 
 
 
 		</comment>
 		<comment id='2' author='marcoabreu' date='2018-02-18T17:05:37Z'>
 		Sounds good. Since we've now got the CI randomness PR merged into the master, it should be no problem to generate faulty tests.
 		</comment>
 		<comment id='3' author='marcoabreu' date='2018-02-21T08:21:32Z'>
 		&lt;denchmark-link:https://github.com/piiswrong&gt;@piiswrong&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;
  are you fine with disabling this test?
 		</comment>
 		<comment id='4' author='marcoabreu' date='2018-02-21T08:24:49Z'>
 		Ah wait. I just checked a few runs of test failures and it ONLY happens with MKLDNN. It looks to me like this is not a flaky test but could rather have a problem in the underlying implementation.
 &lt;denchmark-link:https://github.com/zheng-da&gt;@zheng-da&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/mli&gt;@mli&lt;/denchmark-link&gt;
  can you please make sure this gets resolved? This test is one of the biggest failure reasons and there might be a valid test failure.
 		</comment>
 		<comment id='5' author='marcoabreu' date='2018-02-21T15:49:50Z'>
 		&lt;denchmark-link:https://github.com/marcoabreu&gt;@marcoabreu&lt;/denchmark-link&gt;
  Thanks for the testing.
 Seems it's a non-deterministic failure both in GPU and CPU backend.
 We will take look this case to figure out the root cause w/ .
 BTW, the root cause of  &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/9843&gt;#9843&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/9844&gt;#9844&lt;/denchmark-link&gt;
  &amp; &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/9845&gt;#9845&lt;/denchmark-link&gt;
  may be the same as this one so I think we can duplicate these issues and track the progress in one thread.
 		</comment>
 		<comment id='6' author='marcoabreu' date='2018-02-21T17:07:17Z'>
 		At least &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/9845&gt;#9845&lt;/denchmark-link&gt;
  is not MKLDNN specific - I've seen (deterministic) failures in that test before, see &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/8780&gt;#8780&lt;/denchmark-link&gt;
 .
 		</comment>
 		<comment id='7' author='marcoabreu' date='2018-02-21T17:58:12Z'>
 		&lt;denchmark-link:https://github.com/marcoabreu&gt;@marcoabreu&lt;/denchmark-link&gt;
  I was testing it yesterday. It seems the problem exists when MKLDNN is compiled into MXNet, so it should be a bug caused by the code inside USE_MKLDNN. I'll look into the problem this week and try to fix it as soon as possible.
 I agree with &lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
  . This problem might be related to the other flaky failures.
 		</comment>
 		<comment id='8' author='marcoabreu' date='2018-02-21T21:51:10Z'>
 		I run more tests. The bug occurs when MKLDNN is compiled into MXNet and we use the threaded engine, which is the default executing engine. If we use the naive executing engine, the problem doesn't show up. It means that the bug isn't in the operator implementation. It should be in the executor engine or in the NDArray.
 		</comment>
 		<comment id='9' author='marcoabreu' date='2018-02-21T21:55:05Z'>
 		Thank you for the elaboration!
 &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/piiswrong&gt;@piiswrong&lt;/denchmark-link&gt;
  what do you think?
 		</comment>
 		<comment id='10' author='marcoabreu' date='2018-02-21T21:57:06Z'>
 		Most likely, what happens is that an operation needs to wait for some variables before proceeding to the next operator, but somehow the implementation doesn't wait for the right variables or misses some variables.
 		</comment>
 		<comment id='11' author='marcoabreu' date='2018-02-22T19:22:43Z'>
 		After one day of testing, I think I know where the problem is now. Basically, the current implementation sometimes needs to convert data format (from the MKLDNN format to the default format) inside an NDArray. In the threaded execution engine, while an NDArray is being converted in a thread, the array can also be read by another thread. In this case, the other thread can read wrong data.
 I changed the code to avoid data layout conversion inside an NDArray. It seems to work fine now. I'll have more tests.
 		</comment>
 		<comment id='12' author='marcoabreu' date='2018-02-22T19:26:44Z'>
 		Great news, thanks for diving deep on this problem!
 		</comment>
 		<comment id='13' author='marcoabreu' date='2018-03-01T10:55:31Z'>
 		Fixed as of &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/9862&gt;#9862&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='f9c2689ec2ffd61ce123dce5857f8a797f21e4df' author='Da Zheng' date='2018-03-01 11:54:35+01:00'>
 	<dmm_unit complexity='0.014925373134328358' interfacing='0.746268656716418' size='0.3880597014925373'></dmm_unit>
 	<modification change_type='MODIFY' old_name='include\mxnet\ndarray.h' new_name='include\mxnet\ndarray.h'>
 		<file_info nloc='594' complexity='92' token_count='4655'></file_info>
 		<method name='mxnet::NDArray::MKLDNNDataReorder' parameters='desc'>
 				<method_info nloc='4' complexity='1' token_count='29' nesting_level='2' start_line='625' end_line='628'></method_info>
 			<added_lines>625,626,627,628</added_lines>
 			<deleted_lines>625</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>634,635,636,637,638,639,640,641,642,643,644,645,646,647,900,903,904</added_lines>
 			<deleted_lines>883</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ndarray\ndarray.cc' new_name='src\ndarray\ndarray.cc'>
 		<file_info nloc='1681' complexity='369' token_count='16444'></file_info>
 		<method name='mxnet::NDArray::GetMKLDNNData' parameters=''>
 				<method_info nloc='31' complexity='7' token_count='338' nesting_level='1' start_line='580' end_line='617'></method_info>
 			<added_lines>582,583,584,585</added_lines>
 			<deleted_lines>584,585,586,587</deleted_lines>
 		</method>
 		<method name='mxnet::NDArray::CopyFrom' parameters='mem'>
 				<method_info nloc='63' complexity='12' token_count='820' nesting_level='1' start_line='619' end_line='699'></method_info>
 			<added_lines>627,628,629,630</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::NDArray::MKLDNNDataReorder' parameters='pd'>
 				<method_info nloc='29' complexity='7' token_count='317' nesting_level='1' start_line='537' end_line='574'></method_info>
 			<added_lines>537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574</added_lines>
 			<deleted_lines>537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574</deleted_lines>
 		</method>
 		<method name='mxnet::NDArray::Reorder2DefaultAsync' parameters=''>
 				<method_info nloc='11' complexity='1' token_count='97' nesting_level='1' start_line='556' end_line='566'></method_info>
 			<added_lines>556,557,558,559,560,561,562,563,564,565,566</added_lines>
 			<deleted_lines>556,557,558,559,560,561,562,563,564,565,566</deleted_lines>
 		</method>
 		<method name='mxnet::NDArray::SyncCopyToCPU' parameters='data,size'>
 				<method_info nloc='26' complexity='5' token_count='265' nesting_level='1' start_line='1887' end_line='1919'></method_info>
 			<added_lines>1896,1897,1898,1899,1900,1901</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::NDArray::Reorder2Default' parameters=''>
 				<method_info nloc='16' complexity='3' token_count='190' nesting_level='1' start_line='536' end_line='554'></method_info>
 			<added_lines>536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554</added_lines>
 			<deleted_lines>537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554</deleted_lines>
 		</method>
 		<method name='mxnet::NDArray::Chunk::MKLDNNDataReorder' parameters='pd'>
 				<method_info nloc='29' complexity='7' token_count='291' nesting_level='1' start_line='381' end_line='417'></method_info>
 			<added_lines>381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::CopyFromToDnsImpl' parameters='from,to,ctx'>
 				<method_info nloc='37' complexity='11' token_count='422' nesting_level='1' start_line='1029' end_line='1076'></method_info>
 			<added_lines>1063,1072</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::NDArray::Chunk::Reorder2Default' parameters=''>
 				<method_info nloc='15' complexity='2' token_count='171' nesting_level='1' start_line='360' end_line='379'></method_info>
 			<added_lines>378,379</added_lines>
 			<deleted_lines>378</deleted_lines>
 		</method>
 		<method name='mxnet::NDArray::MKLDNNDataReorderAsync' parameters='desc'>
 				<method_info nloc='11' complexity='1' token_count='108' nesting_level='1' start_line='568' end_line='578'></method_info>
 			<added_lines>568,569,570,571,572,573,574,575,576,577,578</added_lines>
 			<deleted_lines>568,569,570,571,572,573,574,575</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>380,579</added_lines>
 			<deleted_lines>500,501,502,503,1028,1852</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\mkldnn\mkldnn_base.cc' new_name='src\operator\nn\mkldnn\mkldnn_base.cc'>
 		<file_info nloc='336' complexity='98' token_count='3119'></file_info>
 		<method name='mxnet::FallBackCompute' parameters='fn,attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='30' complexity='6' token_count='327' nesting_level='1' start_line='267' end_line='301'></method_info>
 			<added_lines>273,275,276,277,278,279,281,282,283,284,285,286,287,288,289,291,292</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\mkldnn\mkldnn_convolution.cc' new_name='src\operator\nn\mkldnn\mkldnn_convolution.cc'>
 		<file_info nloc='304' complexity='48' token_count='3079'></file_info>
 		<method name='mxnet::op::MKLDNNConvolutionForward' parameters='attrs,ctx,in_data,req,out_data'>
 				<method_info nloc='34' complexity='6' token_count='395' nesting_level='2' start_line='259' end_line='302'></method_info>
 			<added_lines>265,266,274,275,276,277,278,282,283,284,285,286,287,288,289,290</added_lines>
 			<deleted_lines>265,266,274,275,276,277,281,282,283</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\mkldnn\mkldnn_deconvolution.cc' new_name='src\operator\nn\mkldnn\mkldnn_deconvolution.cc'>
 		<file_info nloc='325' complexity='40' token_count='3219'></file_info>
 		<method name='mxnet::op::MKLDNNDeconvForward::SetDataHandle' parameters='param,ctx,in_data,req,out_data'>
 				<method_info nloc='30' complexity='4' token_count='268' nesting_level='2' start_line='230' end_line='266'></method_info>
 			<added_lines>237,242,243,244,245,249,250,251,252,253,254,255,256,257</added_lines>
 			<deleted_lines>241,242,243,244,245,249,250,251</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\mkldnn\mkldnn_fully_connected.cc' new_name='src\operator\nn\mkldnn\mkldnn_fully_connected.cc'>
 		<file_info nloc='164' complexity='25' token_count='1785'></file_info>
 		<method name='mxnet::op::MKLDNNFCForward' parameters='attrs,ctx,in_data,req,out_data'>
 				<method_info nloc='44' complexity='8' token_count='618' nesting_level='2' start_line='83' end_line='130'></method_info>
 			<added_lines>93,94,95,96,97</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\tensor\cast_storage-inl.h' new_name='src\operator\tensor\cast_storage-inl.h'>
 		<file_info nloc='324' complexity='61' token_count='2689'></file_info>
 		<method name='mxnet::op::CastStorageComputeImpl' parameters='ctx,input,output'>
 				<method_info nloc='33' complexity='16' token_count='342' nesting_level='2' start_line='332' end_line='369'></method_info>
 			<added_lines>354,355,356,357,358,359</added_lines>
 			<deleted_lines>354</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\tensor\elemwise_sum.cc' new_name='src\operator\tensor\elemwise_sum.cc'>
 		<file_info nloc='140' complexity='19' token_count='1083'></file_info>
 		<method name='mxnet::op::ElementWiseSumComputeExCPU' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='23' complexity='6' token_count='253' nesting_level='2' start_line='108' end_line='132'></method_info>
 			<added_lines>127,128</added_lines>
 			<deleted_lines>125,127,128,129,130,131,132</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>28</added_lines>
 			<deleted_lines>133,134,135,136,137</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\gpu\test_gluon_model_zoo_gpu.py' new_name='tests\python\gpu\test_gluon_model_zoo_gpu.py'>
 		<file_info nloc='133' complexity='14' token_count='1194'></file_info>
 		<method name='test_training' parameters=''>
 				<method_info nloc='61' complexity='6' token_count='598' nesting_level='0' start_line='104' end_line='180'></method_info>
 			<added_lines>160,161,162,163</added_lines>
 			<deleted_lines>159</deleted_lines>
 		</method>
 		<method name='test_inference' parameters=''>
 				<method_info nloc='43' complexity='4' token_count='415' nesting_level='0' start_line='41' end_line='92'></method_info>
 			<added_lines>89,90,91</added_lines>
 			<deleted_lines>90</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>40</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
