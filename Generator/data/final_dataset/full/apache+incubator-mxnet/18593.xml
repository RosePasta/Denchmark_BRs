<bug_data>
<bug id='18593' author='xidulu' open_date='2020-06-19T04:32:38Z' closed_time='2020-11-04T19:53:21Z'>
 	<summary>Deferred computation does not work in HybridSequential</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 import mxnet as mx
 from mxnet import np, npx
 from mxnet.gluon.nn import HybridBlock
 
 class normalBlock(HybridBlock):
     def forward(self, x):
         return (x + 1)
 
 shape = (4, 4)
 for hybridize in [True, False]:
     initial_value = np.ones(shape)
     net = mx.gluon.nn.HybridSequential()
     net.add(normalBlock())
     net.add(normalBlock())
     if hybridize:
         net.hybridize()
     mx_out = net(initial_value).asnumpy()
 &lt;denchmark-code&gt;NotImplementedForSymbol                   Traceback (most recent call last)
 &lt;ipython-input-321-a136cd061b1d&gt; in &lt;module&gt;
      15     if hybridize:
      16         net.hybridize()
 ---&gt; 17     mx_out = net(initial_value).asnumpy()
      18 
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in __call__(self, x, *args)
    1322         if self.hybrid_forward.__func__ is not HybridBlock.hybrid_forward:
    1323             # Gluon 1 based on F:  hybrid_forward is defined by user
 -&gt; 1324             return super().__call__(x, *args)
    1325         else:  # Gluon 2 based on deferred compute mode
    1326             assert self.forward is not HybridBlock.forward, (
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in __call__(self, *args)
     703             hook(self, args)
     704 
 --&gt; 705         out = self.forward(*args)
     706 
     707         for hook in self._forward_hooks.values():
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in forward(self, x, *args)
    1367                                      'Find all contexts = {}'.format(ctx_set))
    1368                 with ctx:
 -&gt; 1369                     return self._call_cached_op(x, *args)
    1370             with ctx:
    1371                 try:
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in _call_cached_op(self, *args)
    1055     def _call_cached_op(self, *args):
    1056         if self._cached_op is None:
 -&gt; 1057             self._build_cache(*args)
    1058         assert self._cached_op, "Gluon failed to build the cache. " \
    1059                                 "This should never happen. " \
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in _build_cache(self, *args)
     984 
     985     def _build_cache(self, *args):
 --&gt; 986         data, out = self._get_graph(*args)
     987         data_names = {data.name: i for i, data in enumerate(data)}
     988         params = self.collect_params()
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in _get_graph(self, *args)
     978         if not self._cached_graph:
     979             if self.hybrid_forward.__func__ is not HybridBlock.hybrid_forward:  # Gluon 1
 --&gt; 980                 return self._get_graph_v1(*args)
     981             else:  # Gluon 2 based on deferred compute mode
     982                 return self._get_graph_v2(*args)
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in _get_graph_v1(self, *args)
     942             params = {i: j.var() for i, j in self._reg_params.items()}
     943             with self.name_scope():
 --&gt; 944                 out = self.hybrid_forward(symbol, *grouped_inputs, **params)  # pylint: disable=no-value-for-parameter
     945             out, self._out_format = _flatten(out, "output")
     946 
 
 ~/mxnet_master_develop/python/mxnet/gluon/nn/basic_layers.py in hybrid_forward(self, F, x, *args)
     126     def hybrid_forward(self, F, x, *args):
     127         for block in self._children.values():
 --&gt; 128             x = block()(x, *args)
     129             args = []
     130             if isinstance(x, (tuple, list)):
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in __call__(self, x, *args)
    1343                 return super().__call__(x, *args)
    1344 
 -&gt; 1345             return self._call_cached_op(x, *args)
    1346 
    1347     def forward(self, x, *args):
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in _call_cached_op(self, *args)
    1055     def _call_cached_op(self, *args):
    1056         if self._cached_op is None:
 -&gt; 1057             self._build_cache(*args)
    1058         assert self._cached_op, "Gluon failed to build the cache. " \
    1059                                 "This should never happen. " \
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in _build_cache(self, *args)
     984 
     985     def _build_cache(self, *args):
 --&gt; 986         data, out = self._get_graph(*args)
     987         data_names = {data.name: i for i, data in enumerate(data)}
     988         params = self.collect_params()
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in _get_graph(self, *args)
     980                 return self._get_graph_v1(*args)
     981             else:  # Gluon 2 based on deferred compute mode
 --&gt; 982                 return self._get_graph_v2(*args)
     983         return self._cached_graph
     984 
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in _get_graph_v2(self, *args)
     952         if not self._cached_graph:
     953             flatten_args, self._in_format = _flatten(args, "input")
 --&gt; 954             flatten_args = [ele.detach() if ele is not None else None for ele in flatten_args]
     955             real_args = [ele for ele in flatten_args if ele is not None]
     956             if len(real_args) == 0:
 
 ~/mxnet_master_develop/python/mxnet/gluon/block.py in &lt;listcomp&gt;(.0)
     952         if not self._cached_graph:
     953             flatten_args, self._in_format = _flatten(args, "input")
 --&gt; 954             flatten_args = [ele.detach() if ele is not None else None for ele in flatten_args]
     955             real_args = [ele for ele in flatten_args if ele is not None]
     956             if len(real_args) == 0:
 
 ~/mxnet_master_develop/python/mxnet/symbol/symbol.py in detach(self)
    2791 
    2792     def detach(self):
 -&gt; 2793         raise NotImplementedForSymbol(self.detach, None)
    2794 
    2795     def backward(self):
 
 NotImplementedForSymbol: Function detach is not implemented for Symbol and only available in NDArray.
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='xidulu' date='2020-06-19T04:54:01Z'>
 		It's "by design" as you can't call the new API from the old API: Calling a HybridBock.forward block from HybridBlock.hybrid_forward is not supported. Note that all the MXNet provided HybridBlocks currently implement hybrid_forward for compatibility.
 We can add temporary hack to HybridSequential to support this usecase if needed, as HybridSequential only passes through the arguments. In general HybridSequential will be switched to the new API together with all the other HybridBlocks in the near future.
 		</comment>
 		<comment id='2' author='xidulu' date='2020-06-19T05:28:30Z'>
 		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 
 Thanks for your response, I am not in urgent need of this usecase.
 But I believe it's crucial to let HybridSequential support the new API.
 		</comment>
 	</comments>
 </bug>
<commit id='3d1df4e035077b5d4de859e7bf464181388d47a0' author='Leonard Lausen' date='2020-11-04 11:53:20-08:00'>
 	<dmm_unit complexity='0.8888888888888888' interfacing='0.7083333333333334' size='0.6111111111111112'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\mxnet\gluon\block.py' new_name='python\mxnet\gluon\block.py'>
 		<file_info nloc='1128' complexity='349' token_count='8056'></file_info>
 		<method name='__call__' parameters='self,x,args'>
 				<method_info nloc='18' complexity='6' token_count='144' nesting_level='1' start_line='1409' end_line='1434'></method_info>
 			<added_lines>1410</added_lines>
 			<deleted_lines>1409</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='14' complexity='1' token_count='91' nesting_level='1' start_line='902' end_line='915'></method_info>
 			<added_lines>904</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='infer_shape' parameters='self,args'>
 				<method_info nloc='12' complexity='6' token_count='100' nesting_level='1' start_line='1284' end_line='1299'></method_info>
 			<added_lines>1286</added_lines>
 			<deleted_lines>1285</deleted_lines>
 		</method>
 		<method name='_get_graph' parameters='self,args'>
 				<method_info nloc='7' complexity='3' token_count='42' nesting_level='1' start_line='987' end_line='993'></method_info>
 			<added_lines>989</added_lines>
 			<deleted_lines>988</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\mxnet\gluon\nn\basic_layers.py' new_name='python\mxnet\gluon\nn\basic_layers.py'>
 		<file_info nloc='1040' complexity='115' token_count='4062'></file_info>
 		<method name='_forward' parameters='self,x,args'>
 				<method_info nloc='10' complexity='4' token_count='79' nesting_level='1' start_line='138' end_line='147'></method_info>
 			<added_lines>138,139,140,141,142,143,144,145,146,147</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__call__' parameters='self,args,kwargs'>
 				<method_info nloc='8' complexity='6' token_count='89' nesting_level='1' start_line='125' end_line='135'></method_info>
 			<added_lines>125,126,127,128,129,130,131,132,133,134,135</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='4' complexity='1' token_count='23' nesting_level='1' start_line='114' end_line='117'></method_info>
 			<added_lines>115,117</added_lines>
 			<deleted_lines>114</deleted_lines>
 		</method>
 		<method name='_forward' parameters='self,x'>
 				<method_info nloc='9' complexity='3' token_count='71' nesting_level='1' start_line='1030' end_line='1038'></method_info>
 			<added_lines>1030,1031,1032,1033,1034,1035,1036,1037,1038</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,axis'>
 				<method_info nloc='3' complexity='1' token_count='22' nesting_level='1' start_line='1026' end_line='1028'></method_info>
 			<added_lines>1027</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>26,32,136,137,148,149,1039</added_lines>
 			<deleted_lines>31,1000</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\unittest\test_gluon.py' new_name='tests\python\unittest\test_gluon.py'>
 		<file_info nloc='2602' complexity='458' token_count='27541'></file_info>
 		<method name='test_concatenate' parameters=''>
 				<method_info nloc='20' complexity='1' token_count='255' nesting_level='0' start_line='3078' end_line='3101'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>3078,3080,3081,3082,3084,3085,3086,3089,3090,3091</deleted_lines>
 		</method>
 		<method name='check_sequential_dc.__init__' parameters='self'>
 				<method_info nloc='4' complexity='1' token_count='51' nesting_level='2' start_line='1026' end_line='1029'></method_info>
 			<added_lines>1026,1027,1028,1029</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_sequential' parameters=''>
 				<method_info nloc='4' complexity='1' token_count='34' nesting_level='0' start_line='1051' end_line='1054'></method_info>
 			<added_lines>1054</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='check_sequential_dc' parameters='net'>
 				<method_info nloc='18' complexity='3' token_count='131' nesting_level='0' start_line='1024' end_line='1048'></method_info>
 			<added_lines>1024,1025,1026,1027,1028,1029,1030,1031,1032,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_concatenate' parameters='dc,hybridize'>
 				<method_info nloc='30' complexity='4' token_count='287' nesting_level='0' start_line='3113' end_line='3151'></method_info>
 			<added_lines>3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3126,3127,3128,3130,3131,3132,3135,3136,3137,3138,3143,3144,3145</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='check_sequential_dc.forward' parameters='self,x'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='2' start_line='1031' end_line='1032'></method_info>
 			<added_lines>1031,1032</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_concatenate.forward' parameters='self,x'>
 				<method_info nloc='2' complexity='1' token_count='14' nesting_level='3' start_line='3120' end_line='3121'></method_info>
 			<added_lines>3120,3121</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_concatenate.__init__' parameters='self,units,activation,in_units'>
 				<method_info nloc='3' complexity='1' token_count='44' nesting_level='3' start_line='3116' end_line='3118'></method_info>
 			<added_lines>3116,3117,3118</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='check_sequential' parameters='net'>
 				<method_info nloc='15' complexity='3' token_count='132' nesting_level='0' start_line='1007' end_line='1022'></method_info>
 			<added_lines>1014,1015,1016,1017,1018,1019,1020,1021,1022</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1023,1050,3109,3110,3111,3112</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
