<bug_data>
<bug id='18710' author='bgawrych' open_date='2020-07-14T11:41:28Z' closed_time='2020-08-07T09:27:37Z'>
 	<summary>[Numpy] Backward of softmax, logsoftmax failed on empty ndarray</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 During backporting change &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/18602&gt;#18602&lt;/denchmark-link&gt;
  to branch v1.x, CI detected problem similar to original issue (&lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/18569&gt;#18569&lt;/denchmark-link&gt;
 ).
 Backward propagation of softmax and log_softmax causes MXNetError: Check failed: delay_alloc:
 &lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File "r.py", line 10, in &lt;module&gt;
     a.grad.wait_to_read()
   File "/home/wihajster/Desktop/incubator-mxnet/python/mxnet/ndarray/ndarray.py", line 2371, in wait_to_read
     check_call(_LIB.MXNDArrayWaitToRead(self.handle))
   File "/home/wihajster/Desktop/incubator-mxnet/python/mxnet/base.py", line 246, in check_call
     raise get_last_ffi_error()
 mxnet.base.MXNetError: Traceback (most recent call last):
   [bt] (9) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)&gt;::operator()(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;) const+0xa6) [0x7f6d58049c9a]
   [bt] (8) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;), void (*)(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)&gt;::_M_invoke(std::_Any_data const&amp;, nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)+0x91) [0x7f6d56fc8a7d]
   [bt] (7) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(+0xbe611e0) [0x7f6d609281e0]
   [bt] (6) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::MKLDNNRun(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)&gt;, nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)+0xad) [0x7f6d580426f3]
   [bt] (5) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)&gt;::operator()(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;) const+0xa6) [0x7f6d58049c9a]
   [bt] (4) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;), void (*)(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)&gt;::_M_invoke(std::_Any_data const&amp;, nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)+0x91) [0x7f6d56fc8a7d]
   [bt] (3) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::op::MKLDNNLogSoftmaxBackward(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray, std::allocator&lt;mxnet::NDArray&gt; &gt; const&amp;)+0x1b6) [0x7f6d580b7d37]
   [bt] (2) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::NDArray::GetMKLDNNData() const+0x43b) [0x7f6d61188a0f]
   [bt] (1) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::NDArray::Chunk::SetMKLMem(mxnet::TShape const&amp;, int)+0x3c4) [0x7f6d61186dbe]
   [bt] (0) /home/wihajster/Desktop/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4d) [0x7f6d569b2acf]
   File "src/ndarray/ndarray.cc", line 580
 MXNetError: Check failed: delay_alloc:
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;import mxnet as mx
 from mxnet import npx
 npx.set_np()
 a = mx.np.array([]).reshape(2, 1, 0)
 a.attach_grad()
 
 with mx.autograd.record():
     b = mx.npx.log_softmax(a)
     b.backward()
     a.grad.wait_to_read()
 &lt;/denchmark-code&gt;
 
 PR is on its way
 	</description>
 	<comments>
 		<comment id='1' author='bgawrych' date='2020-07-16T02:20:16Z'>
 		Thanks for reporting. cc &lt;denchmark-link:https://github.com/yzhliu&gt;@yzhliu&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='bgawrych' date='2020-08-07T09:27:37Z'>
 		Done :)
 		</comment>
 	</comments>
 </bug>
<commit id='73d3a7bc9cef596b5cc8ba6d0e3cf21e1bc08fee' author='bgawrych' date='2020-08-03 22:20:49+08:00'>
 	<dmm_unit complexity='0.0' interfacing='0.7678571428571429' size='0.3392857142857143'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\operator\nn\log_softmax.cc' new_name='src\operator\nn\log_softmax.cc'>
 		<file_info nloc='121' complexity='9' token_count='943'></file_info>
 		<method name='mxnet::op::LogSoftmaxComputeExCPU' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='17' complexity='3' token_count='191' nesting_level='2' start_line='38' end_line='54'></method_info>
 			<added_lines>43</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::LogSoftmaxGradComputeExCPU' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='17' complexity='3' token_count='194' nesting_level='2' start_line='56' end_line='72'></method_info>
 			<added_lines>61</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\softmax-inl.h' new_name='src\operator\nn\softmax-inl.h'>
 		<file_info nloc='782' complexity='191' token_count='7971'></file_info>
 		<method name='mxnet::op::mxnet_op::Softmax' parameters='s,in,out,length,shape,axis,temperature'>
 				<method_info nloc='34' complexity='6' token_count='359' nesting_level='3' start_line='402' end_line='437'></method_info>
 			<added_lines>407</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::mxnet_op::SoftmaxGrad' parameters='s,out,ograd,igrad,length,shape,axis,temperature'>
 				<method_info nloc='35' complexity='6' token_count='377' nesting_level='3' start_line='555' end_line='593'></method_info>
 			<added_lines>561</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::mxnet_op::Softmax' parameters='s,in,out,length,shape,axis,temperature'>
 				<method_info nloc='77' complexity='32' token_count='846' nesting_level='3' start_line='71' end_line='162'></method_info>
 			<added_lines>74</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::SoftmaxCompute' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='61' complexity='11' token_count='610' nesting_level='2' start_line='776' end_line='837'></method_info>
 			<added_lines>782,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,821,822,823,824,825,826,828,829,830,831,833</added_lines>
 			<deleted_lines>778,801,802,803,805,806,807,808,809,810,811,812,813,814,815,816,818,819,820,821,822,823,824,825,826,827,828</deleted_lines>
 		</method>
 		<method name='mxnet::op::mxnet_op::SoftmaxGrad' parameters='s,out,ograd,igrad,length,shape,axis,temperature'>
 				<method_info nloc='63' complexity='19' token_count='702' nesting_level='3' start_line='186' end_line='259'></method_info>
 			<added_lines>190</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\softmax.cc' new_name='src\operator\nn\softmax.cc'>
 		<file_info nloc='146' complexity='13' token_count='1169'></file_info>
 		<method name='mxnet::op::SoftmaxComputeExCPU' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='17' complexity='3' token_count='191' nesting_level='2' start_line='39' end_line='55'></method_info>
 			<added_lines>44</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::SoftmaxGradComputeExCPU' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='17' complexity='3' token_count='194' nesting_level='2' start_line='57' end_line='73'></method_info>
 			<added_lines>62</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\numpy\np_boolean_mask_assign.cc' new_name='src\operator\numpy\np_boolean_mask_assign.cc'>
 		<file_info nloc='271' complexity='47' token_count='2443'></file_info>
 		<method name='mxnet::op::NumpyBooleanAssignForwardCPU' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='76' complexity='13' token_count='788' nesting_level='2' start_line='194' end_line='281'></method_info>
 			<added_lines>226,256,257,273</added_lines>
 			<deleted_lines>224,225</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\unittest\test_numpy_op.py' new_name='tests\python\unittest\test_numpy_op.py'>
 		<file_info nloc='7174' complexity='1733' token_count='79195'></file_info>
 		<method name='test_npx_softmax.np_softmax' parameters='x,axis'>
 				<method_info nloc='7' complexity='2' token_count='82' nesting_level='1' start_line='1580' end_line='1586'></method_info>
 			<added_lines>1580,1581,1582,1583,1584,1585,1586</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_npx_softmax.__init__' parameters='self,axis'>
 				<method_info nloc='3' complexity='1' token_count='22' nesting_level='2' start_line='1565' end_line='1567'></method_info>
 			<added_lines>1565,1566,1567</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_npx_softmax.np_log_softmax' parameters='x,axis'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='1588' end_line='1589'></method_info>
 			<added_lines>1588,1589</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_npx_softmax.hybrid_forward' parameters='self,F,a'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='2' start_line='1569' end_line='1570'></method_info>
 			<added_lines>1569,1570</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_npx_softmax' parameters=''>
 				<method_info nloc='28' complexity='6' token_count='225' nesting_level='0' start_line='1563' end_line='1616'></method_info>
 			<added_lines>1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1561,1562,1617</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
