<bug_data>
<bug id='13825' author='thomelane' open_date='2019-01-10T01:22:48Z' closed_time='2019-05-02T22:04:53Z'>
 	<summary>Dropout is Slow</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 Adding dropout to network seems to reduce speed of forward pass substantially.
 I've seen this a few times now, and the latest was occasion was on the discussion forum:
 &lt;denchmark-link:https://discuss.mxnet.io/t/training-speed-in-mxnet-is-nearly-2-5x-times-slower-than-pytorch&gt;https://discuss.mxnet.io/t/training-speed-in-mxnet-is-nearly-2-5x-times-slower-than-pytorch&lt;/denchmark-link&gt;
 . User's training was x2.5 slower than PyTorch originally, but reported a , ultimately making training faster than PyTorch. User also reported a significant reduction in memory usage.
 Could be related to &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/12976&gt;#12976&lt;/denchmark-link&gt;
 .
 &lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;
 
 User above is using MXNet version 1.3.1 on Ubuntu 16.04.5 with GTX1080.
 And I have been able to replicate on AWS EC2 p3.2xlarge.
 &lt;denchmark-code&gt;(mxnet_p36) ubuntu@ip-172-31-14-75:~$ python diagnose.py
 ----------Python Info----------
 Version      : 3.6.5
 Compiler     : GCC 7.2.0
 Build        : ('default', 'Apr 29 2018 16:14:56')
 Arch         : ('64bit', '')
 ------------Pip Info-----------
 Version      : 10.0.1
 Directory    : /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip
 ----------MXNet Info-----------
 Version      : 1.3.1
 Directory    : /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet
 Commit Hash   : 19c501680183237d52a862e6ae1dc4ddc296305b
 ----------System Info----------
 Platform     : Linux-4.4.0-1074-aws-x86_64-with-debian-stretch-sid
 system       : Linux
 node         : ip-172-31-14-75
 release      : 4.4.0-1074-aws
 version      : #84-Ubuntu SMP Thu Dec 6 08:57:58 UTC 2018
 ----------Hardware Info----------
 machine      : x86_64
 processor    : x86_64
 Architecture:          x86_64
 CPU op-mode(s):        32-bit, 64-bit
 Byte Order:            Little Endian
 CPU(s):                8
 On-line CPU(s) list:   0-7
 Thread(s) per core:    2
 Core(s) per socket:    4
 Socket(s):             1
 NUMA node(s):          1
 Vendor ID:             GenuineIntel
 CPU family:            6
 Model:                 79
 Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
 Stepping:              1
 CPU MHz:               2699.984
 CPU max MHz:           3000.0000
 CPU min MHz:           1200.0000
 BogoMIPS:              4600.16
 Hypervisor vendor:     Xen
 Virtualization type:   full
 L1d cache:             32K
 L1i cache:             32K
 L2 cache:              256K
 L3 cache:              46080K
 NUMA node0 CPU(s):     0-7
 Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single kaiser fsgsbase bmi1 hle avx2smep bmi2 erms invpcid rtm rdseed adx xsaveopt
 ----------Network Test----------
 Setting timeout: 10
 Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0019 sec, LOAD: 0.3825 sec.
 Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0998 sec, LOAD: 0.0959 sec.
 Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.5308 sec, LOAD: 0.2854 sec.
 Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0082 sec, LOAD: 0.1051 sec.
 Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0099 sec, LOAD: 0.3274 sec.
 Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0109 sec, LOAD: 0.0471 sec.
 &lt;/denchmark-code&gt;
 
 Package used (Python/R/Scala/Julia): Python
 &lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h3&gt;Using mx.nd.Dropout&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;%%timeit
 data = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu())
 for i in range(100):
     # using mode='always' to force dropout behaviour
     data = mx.nd.Dropout(data, 0.5, mode='always')
 mx.nd.waitall()
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;# 1.44 s ± 512 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
 &lt;/denchmark-code&gt;
 
 Approx ~4.5 times slower than custom dropout.
 &lt;denchmark-h:h3&gt;Using Custom Dropout&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;%%timeit
 data = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu())
 for i in range(100):
     dropout_mask = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu()) &gt; 0.5
     data = data * dropout_mask
 mx.nd.waitall()
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;# 325 ms ± 338 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
 &lt;/denchmark-code&gt;
 
 Approx ~4.5 times faster than mx.nd.Dropout.
 &lt;denchmark-h:h2&gt;Other examples, including backward pass.&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h3&gt;Network using mx.gluon.nn.Dropout&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;net = mx.gluon.nn.HybridSequential()
 net.add(mx.gluon.nn.Conv2D(channels=32, kernel_size=3, strides=2))
 net.add(mx.gluon.nn.BatchNorm())
 net.add(mx.gluon.nn.Activation('relu'))
 net.add(mx.gluon.nn.Dropout(0.5))
 net.add(mx.gluon.nn.GlobalMaxPool2D())
 net.add(mx.gluon.nn.Dense(units=1000))
 net.initialize(ctx=mx.gpu())
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;%%timeit
 for i in range(10):
     data = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu())
     with mx.autograd.record():
         output = net(data)
     output.backward()
     mx.nd.waitall()
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;# 524 ms ± 882 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
 &lt;/denchmark-code&gt;
 
 Approx 4 times slower than without.
 &lt;denchmark-h:h3&gt;Network without mx.gluon.nn.Dropout&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;net = mx.gluon.nn.HybridSequential()
 net.add(mx.gluon.nn.Conv2D(channels=32, kernel_size=3, strides=2))
 net.add(mx.gluon.nn.BatchNorm())
 net.add(mx.gluon.nn.Activation('relu'))
 net.add(mx.gluon.nn.GlobalMaxPool2D())
 net.add(mx.gluon.nn.Dense(units=1000))
 net.initialize(ctx=mx.gpu())
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;%%timeit
 for i in range(10):
     data = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu())
     with mx.autograd.record():
         output = net(data)
     output.backward()
     mx.nd.waitall()
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;# 123 ms ± 187 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
 &lt;/denchmark-code&gt;
 
 Approx 4 times faster than with.
 	</description>
 	<comments>
 		<comment id='1' author='thomelane' date='2019-01-10T01:24:20Z'>
 		&lt;denchmark-link:https://github.com/mxnet-label-bot&gt;@mxnet-label-bot&lt;/denchmark-link&gt;
  add [Bug, Operator, Python, Performance, CUDA]
 		</comment>
 		<comment id='2' author='thomelane' date='2019-02-26T21:02:30Z'>
 		Probably resolved by &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/13896&gt;#13896&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='thomelane' date='2019-02-28T05:10:23Z'>
 		after &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/13896&gt;#13896&lt;/denchmark-link&gt;
 , seems only  has performance improvements, but not  mx.nd.Dropout(data, 0.5, mode='always')
 following the above code sample:
 &lt;denchmark-h:h3&gt;Using mx.nd.Dropout&lt;/denchmark-h&gt;
 
 1.43 s ± 293 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
 &lt;denchmark-h:h3&gt;Using Custom Dropout&lt;/denchmark-h&gt;
 
 331 ms ± 411 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
 &lt;denchmark-h:h3&gt;Network using mx.gluon.nn.Dropout&lt;/denchmark-h&gt;
 
 128 ms ± 39.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
 &lt;denchmark-h:h3&gt;Network without mx.gluon.nn.Dropout&lt;/denchmark-h&gt;
 
 128 ms ± 30.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
 tested with both pip install mxnet-cu92 --pre and build from source on p3.2x
 		</comment>
 		<comment id='4' author='thomelane' date='2019-02-28T05:36:52Z'>
 		&lt;denchmark-link:https://github.com/roywei&gt;@roywei&lt;/denchmark-link&gt;
  by default cudnn_off is turned on. You need to turn it off to benefit from cudnn dropout.
 		</comment>
 		<comment id='5' author='thomelane' date='2019-04-01T21:51:59Z'>
 		&lt;denchmark-link:https://github.com/thomelane&gt;@thomelane&lt;/denchmark-link&gt;
  - Can you please confirm if the issue is resolved with CUDNN support?
 Or, this may be related to this - &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/14198&gt;#14198&lt;/denchmark-link&gt;
  ?
 		</comment>
 		<comment id='6' author='thomelane' date='2019-05-02T19:14:04Z'>
 		Tested with mxnet-cu90mkl==1.5.0b20190501 on g3.8xlarge instance.
 Code example (same as above):
 &lt;denchmark-code&gt;import mxnet as mx
 import time
 
 tic = time.time()
 
 data = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu())
 for i in range(100):
     # using mode='always' to force dropout behaviour
     data = mx.nd.Dropout(data, 0.5, mode='always')
 mx.nd.waitall()
 
 print("mx.nd.Dropout: ", time.time() - tic)
 
 tic = time.time()
 data = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu())
 for i in range(100):
     dropout_mask = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu()) &gt; 0.5
     data = data * dropout_mask
 mx.nd.waitall()
 
 print("Custom Dropout: ", time.time() - tic)
 
 net = mx.gluon.nn.HybridSequential()
 net.add(mx.gluon.nn.Conv2D(channels=32, kernel_size=3, strides=2))
 net.add(mx.gluon.nn.BatchNorm())
 net.add(mx.gluon.nn.Activation('relu'))
 net.add(mx.gluon.nn.Dropout(0.5))
 net.add(mx.gluon.nn.GlobalMaxPool2D())
 net.add(mx.gluon.nn.Dense(units=1000))
 net.initialize(ctx=mx.gpu())
 
 tic = time.time()
 for i in range(10):
     data = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu())
     with mx.autograd.record():
         output = net(data)
     output.backward()
     mx.nd.waitall()
 
 print("mx.gluon.nn.Dropout: ", time.time() - tic)
 
 net = mx.gluon.nn.HybridSequential()
 net.add(mx.gluon.nn.Conv2D(channels=32, kernel_size=3, strides=2))
 net.add(mx.gluon.nn.BatchNorm())
 net.add(mx.gluon.nn.Activation('relu'))
 net.add(mx.gluon.nn.GlobalMaxPool2D())
 net.add(mx.gluon.nn.Dense(units=1000))
 net.initialize(ctx=mx.gpu())
 
 tic = time.time()
 for i in range(10):
     data = mx.nd.random.uniform(shape=(100, 3, 224, 224), ctx=mx.gpu())
     with mx.autograd.record():
         output = net(data)
     output.backward()
     mx.nd.waitall()
 
 print("Without mx.gluon.nn.Dropout: ", time.time() - tic)
 &lt;/denchmark-code&gt;
 
 Performance results (in seconds):
 &lt;denchmark-code&gt;mx.nd.Dropout:  2.713014841079712
 Custom Dropout:  3.227015733718872
 mx.gluon.nn.Dropout:  0.9665834903717041
 Without mx.gluon.nn.Dropout:  0.7113254070281982
 &lt;/denchmark-code&gt;
 
 Looks like the dropout performance has been significantly improved with CUDNN support.
 &lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
  Please help close this issue.
 &lt;denchmark-link:https://github.com/thomelane&gt;@thomelane&lt;/denchmark-link&gt;
  Please reopen the issue if you have any further questions. Thanks.
 		</comment>
 	</comments>
 </bug>
<commit id='18b8704491640b126e344e6c81d1b6da90eae64e' author='Sheng Zha' date='2019-02-05 10:20:04-08:00'>
 	<dmm_unit complexity='0.6235294117647059' interfacing='0.23137254901960785' size='0.050980392156862744'></dmm_unit>
 	<modification change_type='MODIFY' old_name='docs\faq\env_var.md' new_name='docs\faq\env_var.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='include\mxnet\resource.h' new_name='include\mxnet\resource.h'>
 		<file_info nloc='80' complexity='10' token_count='592'></file_info>
 		<modified_lines>
 			<added_lines>47,48,49,50,51,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\mxnet\gluon\nn\basic_layers.py' new_name='python\mxnet\gluon\nn\basic_layers.py'>
 		<file_info nloc='621' complexity='67' token_count='2622'></file_info>
 		<method name='hybrid_forward' parameters='self,F,x'>
 				<method_info nloc='5' complexity='2' token_count='52' nesting_level='1' start_line='264' end_line='268'></method_info>
 			<added_lines>265,266,267,268</added_lines>
 			<deleted_lines>265</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\executor\attach_op_resource_pass.cc' new_name='src\executor\attach_op_resource_pass.cc'>
 		<file_info nloc='74' complexity='15' token_count='565'></file_info>
 		<method name='mxnet::exec::AttachOpResources' parameters='g,op_execs,start_nid,end_nid'>
 				<method_info nloc='63' complexity='14' token_count='506' nesting_level='2' start_line='33' end_line='102'></method_info>
 			<added_lines>65,66,67,68,69,70,71,72,73,74,75,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92</added_lines>
 			<deleted_lines>65,66,67,68,69,70,71,73,74,75,76,77,78</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\imperative\imperative_utils.h' new_name='src\imperative\imperative_utils.h'>
 		<file_info nloc='847' complexity='185' token_count='8070'></file_info>
 		<method name='mxnet::imperative::SetDependency' parameters='attrs,ctx,inputs,outputs,p_read_vars,p_write_vars,p_requested,p_mutate_idx,dispatch_mode'>
 				<method_info nloc='65' complexity='15' token_count='611' nesting_level='2' start_line='204' end_line='275'></method_info>
 			<added_lines>244,245,246,247,248,249</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\cudnn_rnn-inl.h' new_name='src\operator\cudnn_rnn-inl.h'>
 		<file_info nloc='676' complexity='79' token_count='4223'></file_info>
 		<method name='mxnet::op::CuDNNRNNOp::Init' parameters='s,in_data,out_data'>
 				<method_info nloc='219' complexity='27' token_count='1324' nesting_level='3' start_line='530' end_line='828'></method_info>
 			<added_lines>702,767</added_lines>
 			<deleted_lines>702,767</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\dropout-inl.h' new_name='src\operator\nn\dropout-inl.h'>
 		<file_info nloc='426' complexity='49' token_count='3645'></file_info>
 		<method name='mxnet::op::DropoutOp::Init' parameters='param'>
 				<method_info nloc='5' complexity='1' token_count='45' nesting_level='3' start_line='230' end_line='234'></method_info>
 			<added_lines>230,231,232,233,234</added_lines>
 			<deleted_lines>230</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLBackward' parameters='s,pkeep,in_grad,out_data,out_grad'>
 				<method_info nloc='6' complexity='1' token_count='50' nesting_level='3' start_line='176' end_line='181'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>176,177,178,179,180,181</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::DropoutOp' parameters='param,ctx'>
 				<method_info nloc='16' complexity='6' token_count='153' nesting_level='3' start_line='206' end_line='223'></method_info>
 			<added_lines>206,210,211,212,213,214,215,216,217,218,219,220,221,222,223</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLAvailable' parameters=''>
 				<method_info nloc='3' complexity='1' token_count='16' nesting_level='3' start_line='110' end_line='114'></method_info>
 			<added_lines>110,113,114</added_lines>
 			<deleted_lines>111,112,113,114</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLForward' parameters='s,pgen,pkeep,in_data,out_data'>
 				<method_info nloc='6' complexity='1' token_count='49' nesting_level='3' start_line='170' end_line='175'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>170,171,172,173,174,175</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLForward' parameters='s,pgen,pkeep,in_data,out_data'>
 				<method_info nloc='6' complexity='1' token_count='49' nesting_level='3' start_line='155' end_line='160'></method_info>
 			<added_lines>158</added_lines>
 			<deleted_lines>155,156,157,158,159,160</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutCompute' parameters='state,ctx,inputs,req,outputs'>
 				<method_info nloc='10' complexity='1' token_count='95' nesting_level='2' start_line='511' end_line='520'></method_info>
 			<added_lines>511,517</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutGradCompute' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='19' complexity='1' token_count='187' nesting_level='2' start_line='387' end_line='406'></method_info>
 			<added_lines>392,398,399,400,401</added_lines>
 			<deleted_lines>387,392,402,403</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::CuDNNForward' parameters='ctx,in,mask,out'>
 				<method_info nloc='37' complexity='1' token_count='255' nesting_level='3' start_line='242' end_line='286'></method_info>
 			<added_lines>242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286</added_lines>
 			<deleted_lines>247,248,249,250,251,253,254,255,258,260,261,262,269,275</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::CuDNNBackward' parameters='ctx,out_grad,mask,in_grad'>
 				<method_info nloc='33' complexity='1' token_count='200' nesting_level='3' start_line='288' end_line='324'></method_info>
 			<added_lines>288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324</added_lines>
 			<deleted_lines>293,294,295,296,297,298,299,300,301,314,315,316,317,318,319,320,321,322,323,324</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutCompute' parameters='attrs,ctx,inputs,req,outputs'>
 				<method_info nloc='12' complexity='1' token_count='106' nesting_level='2' start_line='373' end_line='384'></method_info>
 			<added_lines>374,380</added_lines>
 			<deleted_lines>373,378,380,381</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutParam::DMLC_DECLARE_PARAMETER' parameters='DropoutParam'>
 				<method_info nloc='15' complexity='1' token_count='106' nesting_level='3' start_line='69' end_line='83'></method_info>
 			<added_lines>80,81,82</added_lines>
 			<deleted_lines>81</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::~DropoutOp' parameters=''>
 				<method_info nloc='9' complexity='5' token_count='68' nesting_level='3' start_line='225' end_line='235'></method_info>
 			<added_lines>225,226,227,228,229,230,231,232,233,234</added_lines>
 			<deleted_lines>230</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLForward' parameters='s,pgen,pkeep,in_data,out_data'>
 				<method_info nloc='21' complexity='3' token_count='249' nesting_level='3' start_line='105' end_line='128'></method_info>
 			<added_lines>110,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128</added_lines>
 			<deleted_lines>105,106,107,108,111,112,113,114,115,116,117,118,119,120,122,123,124,125,127</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLBackward' parameters='s,pkeep,in_grad,out_data,out_grad'>
 				<method_info nloc='20' complexity='3' token_count='239' nesting_level='3' start_line='131' end_line='151'></method_info>
 			<added_lines>131,133,134,139,140,141,142,143,144,145,146,147,148,149,150,151</added_lines>
 			<deleted_lines>131,132,133,134,135,136,137,138,139,140,141,142,143,145,146,147,148,150</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::CuDNNAvailable' parameters=''>
 				<method_info nloc='3' complexity='2' token_count='17' nesting_level='3' start_line='238' end_line='240'></method_info>
 			<added_lines>238,239,240</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLBackward' parameters='ctx,in_grad,out_data,out_grad'>
 				<method_info nloc='17' complexity='2' token_count='229' nesting_level='3' start_line='139' end_line='156'></method_info>
 			<added_lines>139,140,141,142,143,144,145,146,147,148,149,150,151,153,154</added_lines>
 			<deleted_lines>139,140,141,142,143,145,146,147,148,150,153,154,155,156</deleted_lines>
 		</method>
 		<method name='mxnet::op::CreateDropoutState' parameters='attrs,ctx,in_shapes,in_types'>
 				<method_info nloc='17' complexity='2' token_count='137' nesting_level='2' start_line='492' end_line='508'></method_info>
 			<added_lines>492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutGradCompute' parameters='state,ctx,inputs,req,outputs'>
 				<method_info nloc='17' complexity='1' token_count='176' nesting_level='2' start_line='523' end_line='540'></method_info>
 			<added_lines>523,537</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLBackward' parameters='s,pkeep,in_grad,out_data,out_grad'>
 				<method_info nloc='6' complexity='1' token_count='50' nesting_level='3' start_line='161' end_line='166'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>161,162,163,164,165,166</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::MKLForward' parameters='ctx,in_data,out_data'>
 				<method_info nloc='19' complexity='2' token_count='262' nesting_level='3' start_line='117' end_line='136'></method_info>
 			<added_lines>117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,133,134</added_lines>
 			<deleted_lines>117,118,119,120,122,123,124,125,127,131,132,133,134,135,136</deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::Backward' parameters='ctx,out_grad,out_data,req,in_grad'>
 				<method_info nloc='59' complexity='8' token_count='618' nesting_level='3' start_line='406' end_line='470'></method_info>
 			<added_lines>414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,431,432,433,434,435,436,437,438,439,465,466,467,468</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::op::DropoutOp::Forward' parameters='ctx,in_data,req,out_data'>
 				<method_info nloc='72' complexity='12' token_count='704' nesting_level='3' start_line='327' end_line='404'></method_info>
 			<added_lines>331,338,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,359,362,364,365,366,367,374,380,392,398,399,400,401</added_lines>
 			<deleted_lines>353,354,355,356,357,358,359,360,373,378,380,381,387,392,402,403</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>42,43,48,49,50,68,88,224,237,241,287,325,326,477,479,480,481,482,483,484,485,486,487,488,489,509,544,545</added_lines>
 			<deleted_lines>42,47,103,104,167,168,169,182,287,325</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\dropout.cc' new_name='src\operator\nn\dropout.cc'>
 		<file_info nloc='124' complexity='1' token_count='839'></file_info>
 		<modified_lines>
 			<added_lines>122,123,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,152,158</added_lines>
 			<deleted_lines>122,127,128,129,140</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\operator\nn\dropout.cu' new_name='src\operator\nn\dropout.cu'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>33,36</added_lines>
 			<deleted_lines>33,36</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\resource.cc' new_name='src\resource.cc'>
 		<file_info nloc='335' complexity='58' token_count='2572'></file_info>
 		<method name='mxnet::Resource::get_cudnn_dropout_desc' parameters='dropout_desc,stream,dropout,seed'>
 				<method_info nloc='25' complexity='2' token_count='153' nesting_level='1' start_line='421' end_line='447'></method_info>
 			<added_lines>421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::resource::ResourceManagerImpl::ResourceTempSpace::ResourceTempSpace' parameters='ctx,ncopy'>
 				<method_info nloc='11' complexity='2' token_count='130' nesting_level='4' start_line='261' end_line='271'></method_info>
 			<added_lines>267</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::resource::ResourceManagerImpl::Request' parameters='ctx,req'>
 				<method_info nloc='39' complexity='11' token_count='313' nesting_level='3' start_line='130' end_line='173'></method_info>
 			<added_lines>149,157,158,159,160,161,162,163,164</added_lines>
 			<deleted_lines>142</deleted_lines>
 		</method>
 		<method name='mxnet::resource::ResourceManagerImpl::~ResourceManagerImpl' parameters=''>
 				<method_info nloc='15' complexity='5' token_count='74' nesting_level='3' start_line='108' end_line='127'></method_info>
 			<added_lines>117,118,119</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::resource::ResourceManagerImpl::ResourceManagerImpl' parameters=''>
 				<method_info nloc='16' complexity='2' token_count='149' nesting_level='3' start_line='90' end_line='107'></method_info>
 			<added_lines>96,97,98,103</added_lines>
 			<deleted_lines>99</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>37,249,250,391,398,401,402,403,404,405,406,407,420,448,449</added_lines>
 			<deleted_lines>234,251,375,382</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\cpp\include\test_core_op.h' new_name='tests\cpp\include\test_core_op.h'>
 		<file_info nloc='619' complexity='138' token_count='4875'></file_info>
 		<method name='mxnet::test::op::CoreOpExecutor::AttachResources' parameters='ctx,attrs,op'>
 				<method_info nloc='46' complexity='13' token_count='399' nesting_level='4' start_line='170' end_line='218'></method_info>
 			<added_lines>171,172,175,176,177,178,179,180,181,182,183,184,185,186,189,190,191,192,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214</added_lines>
 			<deleted_lines>173,174,177,178,179,180,181,182,183,184,185,186,188,189,190</deleted_lines>
 		</method>
 		<method name='mxnet::test::op::CoreOpExecutor::ExecuteStateful' parameters=''>
 				<method_info nloc='7' complexity='1' token_count='46' nesting_level='4' start_line='653' end_line='659'></method_info>
 			<added_lines>653,654,655,656,657,658,659</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::test::op::CoreOpExecutor::backward' parameters='count'>
 				<method_info nloc='14' complexity='4' token_count='92' nesting_level='4' start_line='615' end_line='628'></method_info>
 			<added_lines>619,620,621,622,623,624,625,626</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::test::op::CoreOpExecutor::ExecuteBackwardStateful' parameters=''>
 				<method_info nloc='11' complexity='3' token_count='57' nesting_level='4' start_line='700' end_line='711'></method_info>
 			<added_lines>700,701,702,703,704,705,706,707,708,709,710,711</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mxnet::test::op::CoreOpExecutor::Init' parameters='in_args,inputs,outputs,backward_for_op,bwd_node_ptr'>
 				<method_info nloc='204' complexity='45' token_count='1665' nesting_level='4' start_line='345' end_line='586'></method_info>
 			<added_lines>538,539,543,544,545,546,547,548,549,550,551,552,553,554,555,556</added_lines>
 			<deleted_lines>564,565,573,574</deleted_lines>
 		</method>
 		<method name='mxnet::test::op::CoreOpExecutor::forward' parameters='count'>
 				<method_info nloc='13' complexity='4' token_count='85' nesting_level='4' start_line='601' end_line='613'></method_info>
 			<added_lines>604,605,606,607,608,609,610,611</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>650,651,652,660,697,698,699,712,820,821,822,823,824,825,826,827,828,829,830,831</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\cpp\include\test_legacy_op.h' new_name='tests\cpp\include\test_legacy_op.h'>
 		<file_info nloc='412' complexity='78' token_count='3359'></file_info>
 		<method name='mxnet::test::op::LegacyOperatorExecutor::allocateResources' parameters='reqs'>
 				<method_info nloc='39' complexity='10' token_count='286' nesting_level='4' start_line='489' end_line='531'></method_info>
 			<added_lines>497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,521,522,523,524,526,527,528</added_lines>
 			<deleted_lines>497,498,499,500,501,502,503,505,506,507,508,509,510,511,513,514,515</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\unittest\test_operator.py' new_name='tests\python\unittest\test_operator.py'>
 		<file_info nloc='6116' complexity='977' token_count='77047'></file_info>
 		<method name='test_dropout.check_dropout_axes' parameters='ratio,shape,axes,cudnn_off'>
 				<method_info nloc='11' complexity='4' token_count='128' nesting_level='1' start_line='6020' end_line='6030'></method_info>
 			<added_lines>6020,6026</added_lines>
 			<deleted_lines>6020,6026</deleted_lines>
 		</method>
 		<method name='test_dropout.check_dropout_ratio' parameters='ratio,shape'>
 				<method_info nloc='44' complexity='8' token_count='587' nesting_level='1' start_line='5954' end_line='6009'></method_info>
 			<added_lines>5954,5957,5995</added_lines>
 			<deleted_lines>5954,5957,5995</deleted_lines>
 		</method>
 		<method name='test_dropout' parameters=''>
 				<method_info nloc='52' complexity='1' token_count='675' nesting_level='0' start_line='5921' end_line='6087'></method_info>
 			<added_lines>5954,5957,5995,6020,6026,6032,6033,6034,6035,6036,6037,6038,6039,6040,6047,6048,6049,6050,6051,6052,6053,6054,6055,6056,6057,6058,6075,6076,6077,6078,6079,6080,6081,6082,6083,6084,6085,6086,6087</added_lines>
 			<deleted_lines>5954,5957,5995,6020,6026</deleted_lines>
 		</method>
 		<method name='test_dropout.check_dropout_ratio' parameters='ratio,shape,cudnn_off'>
 				<method_info nloc='44' complexity='8' token_count='599' nesting_level='1' start_line='5954' end_line='6009'></method_info>
 			<added_lines>5954,5957,5995</added_lines>
 			<deleted_lines>5954,5957,5995</deleted_lines>
 		</method>
 		<method name='test_dropout.check_dropout_axes' parameters='ratio,shape,axes'>
 				<method_info nloc='11' complexity='4' token_count='120' nesting_level='1' start_line='6020' end_line='6030'></method_info>
 			<added_lines>6020,6026</added_lines>
 			<deleted_lines>6020,6026</deleted_lines>
 		</method>
 		<method name='test_dropout.check_passthrough' parameters='ratio,shape,cudnn_off'>
 				<method_info nloc='7' complexity='1' token_count='84' nesting_level='1' start_line='6032' end_line='6039'></method_info>
 			<added_lines>6032,6033,6034,6035,6036,6037,6038,6039</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>6088</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
