<bug_data>
<bug id='19026' author='sxjscience' open_date='2020-08-27T06:56:44Z' closed_time='2020-08-31T05:08:20Z'>
 	<summary>[Bug] RTC Failed to compile</summary>
 	<description>
 &lt;denchmark-link:https://github.com/ptrendx&gt;@ptrendx&lt;/denchmark-link&gt;
  Let me create an issue and track it in the issue.
 It is reproducible by running the &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/blob/master/tests/test_attention_cell.py&gt;https://github.com/dmlc/gluon-nlp/blob/master/tests/test_attention_cell.py&lt;/denchmark-link&gt;
  script on GPU with GluonNLP.
 Error Message:
 &lt;denchmark-code&gt;&gt;           raise get_last_ffi_error()
 E           mxnet.base.MXNetError: Traceback (most recent call last):
 E             File "../src/operator/fusion/fused_op.cu", line 647
 E           MXNetError: Check failed: compileResult == NVRTC_SUCCESS (6 vs. 0) : NVRTC Compilation failed. Please set environment variable MXNET_USE_FUSION to 0.
 E           clip_Cast_kernel.cu(814): error: identifier "inf" is undefined
 E           
 E           clip_Cast_kernel.cu(795): warning: variable "ndim_output1" was declared but never referenced
 E           
 E           clip_Cast_kernel.cu(797): warning: variable "ndim_output0" was declared but never referenced
 E           
 E           clip_Cast_kernel.cu(798): warning: variable "ndim_input_0" was declared but never referenced
 E           
 E           clip_Cast_kernel.cu(333): warning: variable "op::SQRT_2" was declared but never referenced
 E           
 E           clip_Cast_kernel.cu(393): warning: variable "op::pi" was declared but never referenced
 E           
 E           1 error detected in the compilation of "clip_Cast_kernel.cu".
 
 &lt;/denchmark-code&gt;
 
 Code file obtained after setting MXNET_RTC_VERBOSE =1:
 struct __align__(2) __half {
   __host__ __device__ __half() { }
   unsigned short __x;
 };
 /* Definitions of intrinsics */
 __device__ inline __half __float2half(const float f) {
   __half val;
  asm("{  cvt.rn.f16.f32 %0, %1;}\n" : "=h"(val.__x) : "f"(f));
   return val;
 }
 __device__ inline float __half2float(const __half h) {
   float val;
  asm("{  cvt.f32.f16 %0, %1;}\n" : "=f"(val) : "h"(h.__x));
   return val;
 }
 
 typedef __half half;
 
 template &lt;typename DType&gt;
 struct AccType {
   using type = DType;
 
   __device__ static inline type from(const DType&amp; val) {
     return val;
   }
 
   __device__ static inline DType to(type val) {
     return val;
   }
 
 };
 
 template&lt;&gt;
 struct AccType&lt;half&gt; {
   using type = float;
 
   __device__ static inline type from(const half&amp; val) {
     return __half2float(val);
   }
 
   __device__ static inline half to(type val) {
     return __float2half(val);
   }
 };
 
 
 using float32 = float;
 using float64 = double;
 using float16 = half;
 using uint8 = unsigned char;
 using int8 = char;
 using int32 = int;
 using int64 = long long;
 
 static_assert(sizeof(float32) == 4, "Size of float32 is expected to be 4B");
 static_assert(sizeof(float64) == 8, "Size of float64 is expected to be 8B");
 static_assert(sizeof(float16) == 2, "Size of float16 is expected to be 2B");
 static_assert(sizeof(uint8) == 1, "Size of uint8 is expected to be 1B");
 static_assert(sizeof(int8) == 1, "Size of int8 is expected to be 1B");
 static_assert(sizeof(int32) == 4, "Size of int32 is expected to be 4B");
 static_assert(sizeof(int64) == 8, "Size of int64 is expected to be 8B");
 
 typedef int32 index_t;
 
 // bool and int8 need to be accumulated in index_t
 // but bool needs to be treated in the special way
 // for ops like bitwise_not
 struct bool_t {
   index_t value;
 
   __device__ inline bool_t(const index_t&amp; v) : value(v) {}
   __device__ inline bool_t(const volatile index_t&amp; v) : value(v) {}
   __device__ inline bool_t() : value(0) {}
 
   __device__ inline operator index_t() const volatile { return value; }
   __device__ inline bool_t&amp; operator= (const index_t&amp; v) {
     value = v;
     return *this;
   }
   __device__ inline volatile bool_t&amp; operator= (const index_t&amp; v) volatile {
     value = v;
     return *this;
   }
   __device__ inline bool_t&amp; operator= (const volatile index_t&amp; v) {
     value = v;
     return *this;
   }
 };
 template&lt;&gt;
 struct AccType&lt;bool&gt; {
   using type = bool_t;
 
   __device__ static inline type from(const bool&amp; val) {
     return val;
   }
 
   __device__ static inline bool to(type val) {
     return val;
   }
 };
 
 template&lt;&gt;
 struct AccType&lt;int8&gt; {
   using type = index_t;
 
   __device__ static inline type from(const int8&amp; val) {
     return val;
   }
 
   __device__ static inline int8 to(type val) {
     return val;
   }
 };
 
 template&lt;&gt;
 struct AccType&lt;uint8&gt; {
   using type = index_t;
 
   __device__ static inline type from(const uint8&amp; val) {
     return val;
   }
 
   __device__ static inline uint8 to(type val) {
     return val;
   }
 };
 
 namespace type_util {
 
 struct false_type {
   static constexpr bool value = false;
 };
 
 struct true_type {
   static constexpr bool value = true;
 };
 
 // is_integral
 template &lt;typename T&gt; struct is_integral : false_type {};
 template &lt;&gt; struct is_integral&lt;uint8&gt; : true_type {};
 template &lt;&gt; struct is_integral&lt;int8&gt;  : true_type {};
 template &lt;&gt; struct is_integral&lt;int32&gt; : true_type {};
 template &lt;&gt; struct is_integral&lt;int64&gt; : true_type {};
 template &lt;&gt; struct is_integral&lt;bool&gt;  : true_type {};
 template &lt;&gt; struct is_integral&lt;bool_t&gt;  : true_type {};
 
 // is_unsigned
 template &lt;typename T&gt; struct is_unsigned : false_type {};
 template &lt;&gt; struct is_unsigned&lt;uint8&gt; : true_type {};
 template &lt;&gt; struct is_unsigned&lt;bool&gt;  : true_type {};
 template &lt;&gt; struct is_unsigned&lt;bool_t&gt;  : true_type {};
 
 // is_same
 template &lt;typename T, typename U&gt;
 struct is_same : false_type {};
 template &lt;typename T&gt; struct is_same&lt;T, T&gt; : true_type {};
 
 // has_double
 template &lt;typename... T&gt; struct has_double : false_type {};
 
 template &lt;typename A, typename... B&gt;
 struct has_double&lt;A, B...&gt; {
     static constexpr bool value = is_same&lt;A, double&gt;::value ||
                                   has_double&lt;B...&gt;::value;
 };
 
 // has_double_or_integral
 template &lt;typename... T&gt; struct has_double_or_integral : false_type {};
 
 template &lt;typename A, typename... B&gt;
 struct has_double_or_integral&lt;A, B...&gt; {
     static constexpr bool value = is_same&lt;A, double&gt;::value ||
                                   is_integral&lt;A&gt;::value ||
                                   has_double_or_integral&lt;B...&gt;::value;
 };
 
 template &lt;bool b&gt;
 struct enable_if {};
 
 template &lt;&gt;
 struct enable_if&lt;true&gt; {
   using type = void;
 };
 
 template &lt;typename T, typename U, class Enable = void&gt;
 struct mixed_type;
 
 template &lt;typename T&gt;
 struct mixed_type&lt;T, float64, typename enable_if&lt;!is_same&lt;float64, T&gt;::value&gt;::type&gt; {
   using type = float64;
 };
 
 template &lt;typename T&gt;
 struct mixed_type&lt;float64, T&gt; {
   using type = float64;
 };
 
 template &lt;typename T&gt;
 struct mixed_type&lt;T, float32, typename enable_if&lt;!is_same&lt;float64, T&gt;::value &amp;&amp;
                                                  !is_same&lt;float32, T&gt;::value&gt;::type&gt; {
   using type = float32;
 };
 
 template &lt;typename T&gt;
 struct mixed_type&lt;float32, T, typename enable_if&lt;!is_same&lt;float64, T&gt;::value&gt;::type&gt; {
   using type = float32;
 };
 
 template &lt;typename T&gt;
 struct mixed_type&lt;T, float16, typename enable_if&lt;is_same&lt;float16, T&gt;::value ||
                                                  is_integral&lt;T&gt;::value&gt;::type&gt; {
   using type = float16;
 };
 
 template &lt;typename T&gt;
 struct mixed_type&lt;float16, T, typename enable_if&lt;is_integral&lt;T&gt;::value&gt;::type&gt; {
   using type = float16;
 };
 
 template &lt;typename T, typename U&gt;
 struct mixed_type&lt;T, U, typename enable_if&lt;is_integral&lt;T&gt;::value &amp;&amp;
                                            is_integral&lt;U&gt;::value &amp;&amp;
                                            !is_same&lt;U, bool_t&gt;::value &amp;&amp;
                                            sizeof(T) &lt;= sizeof(U)&gt;::type&gt; {
   using type = U;
 };
 
 template &lt;typename T, typename U&gt;
 struct mixed_type&lt;U, T, typename enable_if&lt;is_integral&lt;T&gt;::value &amp;&amp;
                                            is_integral&lt;U&gt;::value &amp;&amp;
                                            !is_same&lt;U, bool_t&gt;::value &amp;&amp;
                                            sizeof(T) &lt; sizeof(U)&gt;::type&gt; {
   using type = U;
 };
 
 template &lt;typename T&gt;
 struct mixed_type&lt;T, bool_t, typename enable_if&lt;is_integral&lt;T&gt;::value &amp;&amp;
                                                 sizeof(T) &lt; sizeof(bool_t)&gt;::type&gt; {
   using type = index_t;
 };
 
 template &lt;typename T&gt;
 struct mixed_type&lt;bool_t, T, typename enable_if&lt;is_integral&lt;T&gt;::value &amp;&amp;
                                                 sizeof(T) &lt; sizeof(bool_t)&gt;::type&gt; {
   using type = index_t;
 };
 
 template &lt;typename T&gt;
 struct mixed_type&lt;T, bool_t, typename enable_if&lt;is_integral&lt;T&gt;::value &amp;&amp;
                                                 sizeof(T) == sizeof(bool_t)&gt;::type&gt; {
   using type = T;
 };
 
 }  // namespace type_util
 
 
 enum class OpReqType {
   kNullOp,
   kWriteTo,
   kWriteInplace,
   kAddTo
 };
 
 constexpr int kRTCMaxThreadsPerBlock = 512;
 
 namespace util {
 
 constexpr int MAX_DIM = 5;
 
 template &lt;int ndim&gt;
 __device__ inline void unravel_dot(const index_t idx, const index_t (&amp;shape)[MAX_DIM],
   const index_t (&amp;stridej)[MAX_DIM], const index_t (&amp;stridek)[MAX_DIM], index_t* j, index_t* k) {
   *j = 0;
   *k = 0;
   #pragma unroll
   for (index_t i = ndim-1, idx_t = idx; i &gt;=0; --i) {
     const auto tmp = idx_t / shape[i];
     const auto coord = idx_t - tmp*shape[i];
     *j += coord*stridej[i];
     *k += coord*stridek[i];
     idx_t = tmp;
   }
 }
 
 template&lt;int ndim&gt;
 __device__ inline index_t unravel_dot(const index_t idx, const index_t (&amp;shape)[MAX_DIM],
   const index_t (&amp;stride)[MAX_DIM]) {
   index_t ret = 0;
   #pragma unroll
   for (index_t i = ndim-1, j = idx; i &gt;=0; --i) {
     auto tmp = j / shape[i];
     ret += (j - tmp*shape[i])*stride[i];
     j = tmp;
   }
   return ret;
 }
 
 template&lt;int ndim&gt;
 __device__ inline index_t unravel_ravel(const index_t idx, const index_t (&amp;shape1)[MAX_DIM],
                                         const index_t (&amp;shape2)[MAX_DIM]) {
   index_t ret = 0;
   index_t total_shape = 1;
 #pragma unroll
   for (index_t i = ndim-1, j = idx; i &gt;=0; --i) {
     if (i != ndim - 1) {
       total_shape *= shape2[i + 1];
     }
     auto tmp = j / shape1[i];
     const index_t coord = j - tmp*shape1[i];
     ret += total_shape * (shape2[i] &gt; coord) * coord;
     j = tmp;
   }
   return ret;
 }
 
 template&lt;int ndim, int ndim2&gt;
 __device__ inline index_t ravel(const index_t (&amp;coord)[ndim], const index_t (&amp;shape)[ndim2]) {
   index_t ret = 0;
 #pragma unroll
   for (int i = 0; i &lt; ndim; ++i) {
     ret = ret * shape[i] + (shape[i] &gt; coord[i]) * coord[i];
   }
   return ret;
 }
 
 template&lt;int ndim, int ndim2&gt;
 __device__ inline void unravel(const index_t idx,
                                const index_t (&amp;shape)[ndim2],
                                index_t (&amp;coord)[ndim]) {
 #pragma unroll
   for (index_t i = ndim-1, j = idx; i &gt;=0; --i) {
     auto tmp = j / shape[i];
     coord[i] = j - tmp*shape[i];
     j = tmp;
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline bool isinf(volatile const DType &amp;val) {
   return false;
 }
 
 template &lt;&gt;
 __device__ inline bool isinf(volatile const float &amp;val) {
   return ::isinf(val);
 }
 
 template &lt;&gt;
 __device__ inline bool isinf(volatile const double &amp;val) {
   return ::isinf(val);
 }
 
 template &lt;&gt;
 __device__ inline bool isinf(volatile const long double &amp;val) {
   return ::isinf(val);
 }
 
 template &lt;&gt;
 __device__ inline bool isinf(volatile const float16 &amp;val) {
   return ::isinf(__half2float(const_cast&lt;const float16&amp;&gt;(val)));
 }
 
 template &lt;typename DType&gt;
 __device__ inline bool isnan(volatile const DType &amp;val) {
   return false;
 }
 
 template &lt;&gt;
 __device__ inline bool isnan(volatile const float &amp;val) {
   return ::isnan(val);
 }
 
 template &lt;&gt;
 __device__ inline bool isnan(volatile const double &amp;val) {
   return ::isnan(val);
 }
 
 template &lt;&gt;
 __device__ inline bool isnan(volatile const long double &amp;val) {
   return ::isnan(val);
 }
 
 template &lt;&gt;
 __device__ inline bool isnan(volatile const float16 &amp;val) {
   return ::isnan(__half2float(const_cast&lt;const float16&amp;&gt;(val)));
 }
 
 }  // namespace util
 
 
 constexpr double DBL_MAX = 1.7976931348623157081e+308;
 
 namespace op {
 
 namespace special_functions {
 
 template&lt;typename DType&gt;
 __device__ inline static DType trigamma(DType x);
 
 template&lt;&gt;
 __device__ inline double trigamma&lt;double&gt;(double x) {
   double PI(3.14159265358979323846);
   double sign = +1;
   double result = 0;
   if (x &lt; 0.5) {
     sign = -1;
     const double sin_pi_x = sin(PI * x);
     result -= (PI * PI) / (sin_pi_x * sin_pi_x);
     x = 1 - x;
   }
   for (int i = 0; i &lt; 6; ++i) {
     result += 1 / (x * x);
     x += 1;
   }
   const double ixx = 1 / (x*x);
   result += (1 + 1 / (2*x) + ixx * (1./6 - ixx * (1./30 - ixx * (1./42)))) / x;
   return sign * result;
 }
 
 template&lt;&gt;
 __device__ inline float trigamma&lt;float&gt;(float x) {
   float PI(3.14159265358979323846);
   float sign = +1;
   float result = 0;
   if (x &lt; 0.5f) {
     sign = -1;
     const float sin_pi_x = sinf(PI * x);
     result -= (PI * PI) / (sin_pi_x * sin_pi_x);
     x = 1 - x;
   }
   for (int i = 0; i &lt; 6; ++i) {
     result += 1 / (x * x);
     x += 1;
   }
   const float ixx = 1 / (x*x);
   result += (1 + 1 / (2*x) + ixx * (1.f/6 - ixx * (1.f/30 - ixx * (1.f/42)))) / x;
   return sign * result;
 }
 
 struct cephes {
   /*
    * Helper to evaluate a polynomial given an array of coefficients.
    */
   template &lt;typename DType&gt;
   __device__ inline static DType polevl(DType x, const DType coef[], int N) {
     DType ans;
     DType const *p;
     int i;
 
     p = coef;
     ans = *p++;
 
     i = N;
     do {
       ans = ans * x  +  *p++;
     } while ( --i );
 
     return( ans );
   }
 
 
   /*
    * Helper function for psi that handles double/float specific differences
    * in the algorithm.
    */
   template&lt;typename DType&gt;
   __device__ inline static DType psi_helper(DType s);
 
   /*
    *
    *	Psi (digamma) function
    *
    *
    * SYNOPSIS:
    *
    * float x, y, psif();
    *
    * y = psif( x );
    *
    *
    * DESCRIPTION:
    *
    *              d      -
    *   psi(x)  =  -- ln | (x)
    *              dx
    *
    * is the logarithmic derivative of the gamma function.
    * For integer x,
    *                   n-1
    *                    -
    * psi(n) = -EUL  +   &gt;  1/k.
    *                    -
    *                   k=1
    *
    * This formula is used for 0 &lt; n &lt;= 10.  If x is negative, it
    * is transformed to a positive argument by the reflection
    * formula  psi(1-x) = psi(x) + pi cot(pi x).
    * For general positive x, the argument is made greater than 10
    * using the recurrence  psi(x+1) = psi(x) + 1/x.
    * Then the following asymptotic expansion is applied:
    *
    *                           inf.   B
    *                            -      2k
    * psi(x) = log(x) - 1/2x -   &gt;   -------
    *                            -        2k
    *                           k=1   2k x
    *
    * where the B2k are Bernoulli numbers.
    *
    * ACCURACY:
    *    Absolute error,  relative when |psi| &gt; 1 :
    * arithmetic   domain     # trials      peak         rms
    *    IEEE      -33,0        30000      8.2e-7      1.2e-7
    *    IEEE      0,33        100000      7.3e-7      7.7e-8
    *
    * ERROR MESSAGES:
    *     message         condition      value returned
    * psi singularity    x integer &lt;=0      MAXNUMF
    */
   template&lt;typename DType&gt;
   __device__ inline static DType psi(DType x) {
     DType p, q, nz, s, w, y;
     int i, n, negative;
 
     DType EUL(0.57721566490153286061);
     DType PI(3.14159265358979323846);
 
     negative = 0;
     nz = 0.0;
 
     if ( x &lt;= 0.0 ) {
       negative = 1;
       q = x;
       p = ::floor(q);
       if ( p == q ) {
         return DBL_MAX;
       }
       /* Remove the zeros of tan(PI x)
        * by subtracting the nearest integer from x
        */
       nz = q - p;
       if ( nz != 0.5 ) {
         if ( nz &gt; 0.5 ) {
           p += 1.0;
           nz = q - p;
         }
         nz = PI/::tan(PI*nz);
       } else {
         nz = 0.0;
       }
       x = 1.0 - x;
     }
 
     /* check for positive integer up to 10 */
     if ( (x &lt;= 10.0) &amp;&amp; (x == ::floor(x)) ) {
       y = 0.0;
       n = x;
       for ( i = 1; i &lt; n; i++ ) {
         w = i;
         y += 1.0/w;
       }
       y -= EUL;
       goto done;
     }
 
     s = x;
     w = 0.0;
     while ( s &lt; 10.0 ) {
       w += 1.0/s;
       s += 1.0;
     }
 
     y = psi_helper(s);
 
     y = logf(s)  -  (0.5/s)  -  y  -  w;
 
 done:
 
     if ( negative ) {
       y -= nz;
     }
 
     return(y);
   }
 };
 
 
 template&lt;&gt;
 __device__ inline double cephes::psi_helper&lt;double&gt;(double s) {
   double z;
   const double A[] = {
     8.33333333333333333333E-2,
     -2.10927960927960927961E-2,
     7.57575757575757575758E-3,
     -4.16666666666666666667E-3,
     3.96825396825396825397E-3,
     -8.33333333333333333333E-3,
     8.33333333333333333333E-2
   };
 
   if ( s &lt; 1.0e17 ) {
     z = 1.0/(s * s);
     return z * cephes::polevl&lt;double&gt;(z, A, 6);
   } else {
     return 0.0;
   }
 }
 
 template&lt;&gt;
 __device__ inline float cephes::psi_helper&lt;float&gt;(float s) {
   float z;
   const float A[] = {
     -4.16666666666666666667E-3f,
     3.96825396825396825397E-3f,
     -8.33333333333333333333E-3f,
     8.33333333333333333333E-2f
   };
 
   if ( s &lt; 1.0e8 ) {
     z = 1.0/(s * s);
     return z * cephes::polevl&lt;float&gt;(z, A, 3);
   } else {
     return 0.0;
   }
 }
 }  // namespace special_functions
 }  // namespace op
 
 
 
 namespace vector {
 
 template &lt;int size&gt;
 struct VectorType {
     static_assert(size &lt;= 32, "VectorType needs to have size of at most 32B");
 };
 
 template &lt;&gt;
 struct VectorType&lt;1&gt; {
   using type = char;
 };
 
 template &lt;&gt;
 struct VectorType&lt;2&gt; {
   using type = short;
 };
 
 
 template &lt;&gt;
 struct VectorType&lt;4&gt; {
   using type = int;
 };
 
 template &lt;&gt;
 struct VectorType&lt;8&gt; {
   using type = long long;
 };
 
 template &lt;&gt;
 struct VectorType&lt;16&gt; {
   using type = ulonglong2;
 };
 
 template &lt;&gt;
 struct VectorType&lt;32&gt; {
   using type = ulonglong4;
 };
 
 template &lt;typename DType&gt;
 __device__ inline DType add_elem(const DType&amp; x, const DType&amp; y) {
   return x + y;
 }
 
 template &lt;&gt;
 __device__ inline half add_elem(const half&amp; x, const half&amp; y) {
   return __float2half(__half2float(x) + __half2float(y));
 }
 
 /* \brief Helper class that enables storing multiple values of type DType
           as 1 value of type LType.
 */
 template &lt;typename DType, int n&gt;
 class VectorizedStorage {
  public:
   using LType = typename VectorType&lt;sizeof(DType) * n&gt;::type;
   constexpr static int nvec = n;
   union vectorized_storage {
     LType aligned;
     DType separate[nvec];  // NOLINT(*)
 
     inline __device__ vectorized_storage() {}
     inline __device__ ~vectorized_storage() {}
   } scratch_;
 
   inline __device__ VectorizedStorage() {}
   inline __device__ VectorizedStorage (const VectorizedStorage&lt;DType, n&gt;&amp; y2) {
       scratch_.aligned = y2.scratch_.aligned;
   }
   inline __device__ VectorizedStorage (const LType &amp;y2) {
       scratch_.aligned = y2;
   }
   inline __device__ VectorizedStorage&lt;DType, n&gt;&amp; operator+=(
       const VectorizedStorage&lt;DType, n&gt;&amp; rhs) {
     #pragma unroll
     for (int i = 0; i &lt; nvec; ++i) {
       scratch_.separate[i] = add_elem(scratch_.separate[i], rhs.scratch_.separate[i]);
     }
     return *this;
   }
   inline __device__ ~VectorizedStorage() {}
 };
 
 // Returns const LType is DType is const
 template &lt;typename DType, typename LType&gt;
 struct select_const {
   using type = LType;
 };
 
 template &lt;typename DType, typename LType&gt;
 struct select_const&lt;const DType, LType&gt; {
   using type = const LType;
 };
 
 template &lt;typename DType&gt;
 struct remove_const {
   using type = DType;
 };
 
 template &lt;typename DType&gt;
 struct remove_const&lt;const DType&gt; {
   using type = DType;
 };
 
 
 /* \brief Helper class that enables accessing multiple values of type DType
           as 1 value of type LType. Additional aligned template argument
           allows performance optimizations if the pointer and the size of
           the allocation is aligned to sizeof(LType) / sizeof(DType) elements.
 */
 template &lt;typename DType, int nvec, bool aligned = false&gt;
 class VectorizedAccessor {
  public:
   using StorageType = VectorizedStorage&lt;typename remove_const&lt;DType&gt;::type,
                                         nvec&gt;;
   using LType = typename select_const&lt;DType, typename StorageType::LType&gt;::type;
   StorageType storage_;
 
   LType* aligned_ptr_;
   DType* unaligned_ptr_;
   int alignment_;
   index_t n_elems_;
 
   inline __device__ VectorizedAccessor(DType* const ptr, const index_t size) {
     unaligned_ptr_ = ptr;
     if (aligned) {
       alignment_ = 0;
       aligned_ptr_ = reinterpret_cast&lt;LType*&gt;(ptr);
       n_elems_ = (size + nvec- 1) / nvec;
     } else {
       size_t ptr_as_number = reinterpret_cast&lt;size_t&gt;(ptr);
       alignment_ = (ptr_as_number % sizeof(LType)) / sizeof(DType);
       aligned_ptr_ = reinterpret_cast&lt;LType*&gt;(ptr - alignment_);
       n_elems_ = (size + alignment_ + nvec - 1) / nvec;
     }
   }
 
   /* \brief Alignment of the input pointer in elements. */
   inline __device__ int alignment() const {
     return alignment_;
   }
 
   /* \brief Access to separate elements. */
   inline __device__ DType* separate() {
     return storage_.scratch_.separate;
   }
 
   /* \brief Number of aligned elements that span the entire input tensor. */
   inline __device__ index_t num_aligned_elements() const {
     return n_elems_;
   }
 
   /* \brief Load values from the input.
      \param id Aligned index of the element.
      \param N size of the tensor.
   */
   inline __device__ void load(const index_t id, const index_t N) {
     if (aligned) {
       storage_.scratch_.aligned = aligned_ptr_[id];
     } else {
       if (id &gt; 0 &amp;&amp; id &lt; n_elems_ - 1) {
         storage_.scratch_.aligned = aligned_ptr_[id];
       } else {
 #pragma unroll
         for (int j = 0; j &lt; nvec; ++j) {
           DType* ptr = reinterpret_cast&lt;DType*&gt;(&amp;(aligned_ptr_[id])) + j;
           if (reinterpret_cast&lt;size_t&gt;(ptr) &gt;= reinterpret_cast&lt;size_t&gt;(unaligned_ptr_) &amp;&amp;
               reinterpret_cast&lt;size_t&gt;(ptr) &lt; reinterpret_cast&lt;size_t&gt;(unaligned_ptr_ + N)) {
             storage_.scratch_.separate[j] = *ptr;
           }
         }
       }
     }
   }
 };
 
 /* \brief Class used for vectorized read-only access. */
 template &lt;typename DType, int nvec, bool aligned = false&gt;
 class VectorizedLoader : public VectorizedAccessor&lt;const DType, nvec, aligned&gt; {
  public:
   inline __device__ VectorizedLoader(const DType* ptr, const index_t N) :
     VectorizedAccessor&lt;const DType, nvec, aligned&gt;(ptr, N) {
   }
 };
 
 /* \brief Class used for vectorized writable access. */
 template &lt;typename DType, int nvec, bool aligned = false&gt;
 class VectorizedStorer : public VectorizedAccessor&lt;DType, nvec, aligned&gt; {
  public:
   inline __device__ VectorizedStorer(DType* ptr, const index_t N) :
     VectorizedAccessor&lt;DType, nvec, aligned&gt;(ptr, N) {
   }
 
   /* \brief Store values to the output.
      \param id Aligned index of the element.
      \param N size of the tensor.
   */
   inline __device__ void store(const index_t id, const index_t N) {
     if (aligned) {
       this-&gt;aligned_ptr_[id] = this-&gt;storage_.scratch_.aligned;
     } else {
       if (id &gt; 0 &amp;&amp; id &lt; this-&gt;n_elems_ - 1) {
         this-&gt;aligned_ptr_[id] = this-&gt;storage_.scratch_.aligned;
       } else {
 #pragma unroll
         for (int j = 0; j &lt; nvec; ++j) {
           DType* ptr = reinterpret_cast&lt;DType*&gt;(&amp;(this-&gt;aligned_ptr_[id])) + j;
           if (reinterpret_cast&lt;size_t&gt;(ptr) &gt;= reinterpret_cast&lt;size_t&gt;(this-&gt;unaligned_ptr_) &amp;&amp;
               reinterpret_cast&lt;size_t&gt;(ptr) &lt; reinterpret_cast&lt;size_t&gt;(this-&gt;unaligned_ptr_ + N)) {
             *ptr = this-&gt;storage_.scratch_.separate[j];
           }
         }
       }
     }
   }
 };
 
 }  // namespace vector
 
 
 
 
 #define INT_MAX (2147483647)
 
 namespace op {
 
 template &lt;typename DType&gt;
 struct LoadType {
   using Type = DType;
 };
 
 template &lt;&gt;
 struct LoadType&lt;half&gt; {
   using Type = float;
 };
 
 template &lt;typename DType&gt;
 __device__ inline typename LoadType&lt;DType&gt;::Type load(const DType input) {
   return input;
 }
 
 template &lt;&gt;
 __device__ inline float load(const half input) {
   return __half2float(input);
 }
 
 template &lt;typename DType1, typename DType2&gt;
 __device__ inline DType1 store(const DType2 input, DType1* ref) {
   return input;
 }
 
 template &lt;typename DType&gt;
 __device__ inline half store(const DType input, half* ref) {
   return __float2half(input);
 }
 
 template &lt;int ndim&gt;
 struct Shape {
    int x[ndim];
    size_t size;
    __device__ inline const int&amp; operator [](const int i) const {
        return x[i];
    }
    __device__ inline int&amp; operator [](const int i) {
        return x[i];
    }
    __device__ inline void set(const int def) {
        #pragma unroll
        for (int i = 0; i &lt; ndim; i++) {
            x[i] = def;
        }
    }
 };
 
 template &lt;&gt;
 struct Shape&lt;0&gt; {
    size_t size;
 };
 
 template &lt;int nvec, typename DType, int ndim&gt;
 __device__ inline vector::VectorizedStorage&lt;DType, nvec&gt; load_index(const DType * input, int i,
                                                                     const Shape&lt;ndim&gt; &amp;shape) {
   using V = vector::VectorizedStorage&lt;DType, nvec&gt;;
   if (i &lt; shape.size) {
     const auto* vector_input = reinterpret_cast&lt;const typename V::LType *&gt;(input + i);
     return V(*vector_input);
   } else {
     return V({0});
   }
 }
 
 template &lt;int nvec, typename DType, int ndim&gt;
 __device__ inline vector::VectorizedStorage&lt;DType, nvec&gt; global_load_index(const DType * input,
                     int i, const Shape&lt;ndim&gt; &amp;shape) {
   using V = vector::VectorizedStorage&lt;DType, nvec&gt;;
   if (i &lt; shape.size) {
     const auto* vector_input = reinterpret_cast&lt;const typename V::LType *&gt;(input + i);
     return V(__ldg(vector_input));
   } else {
     return V({0});
   }
 }
 
 template &lt;int nvec, typename DType, int ndim&gt;
 __device__ inline vector::VectorizedStorage&lt;DType, nvec&gt; load_slice(const DType * input,
                                                                     const Shape&lt;ndim&gt;&amp; shape,
                                                                     Shape&lt;ndim&gt; begin,
                                                                     Shape&lt;ndim&gt; end,
                                                                     int offset) {
   int idx[nvec];
 
   Shape&lt;ndim&gt; ref_strides;
   Shape&lt;ndim&gt; strides;
   ref_strides[ndim-1] = 1;
   strides[ndim-1] = 1;
   #pragma unroll
   for (int dim = ndim-1; dim &gt;=0; dim--) {
     if (begin[dim] &lt; 0) begin[dim] = shape[dim] + begin[dim];
     if (end[dim] &lt; 0) end[dim] = shape[dim] + end[dim];
     if (end[dim] == INT_MAX) end[dim] = shape[dim];
     if (dim &gt; 0) {
       ref_strides[dim-1] = ref_strides[dim] * (end[dim] - begin[dim]);
       strides[dim-1] = strides[dim] * shape[dim];
     }
   }
   #pragma unroll
   for (int j = 0; j &lt; nvec; j++) {
     idx[j] = 0;
     int ref_idx = offset + j;
     #pragma unroll
     for (int dim = 0; dim &lt; ndim; dim++) {
        int stride = ref_strides[dim];
        if (shape[dim] &gt; 1) {
          idx[j] += (ref_idx / stride + begin[dim]) * strides[dim];
        }
        ref_idx = ref_idx % stride;
     }
   }
   vector::VectorizedStorage&lt;DType, nvec&gt; ret;
   #pragma unroll
   for (int j = 0; j &lt; nvec; j++) {
       ret.scratch_.separate[j] = *(input + idx[j]);
   }
   return ret;
 }
 
 template &lt;int nvec, typename DType, int ndim&gt;
 __device__ inline vector::VectorizedStorage&lt;DType, nvec&gt; fast_load_slice(const DType * input,
                                                                          const Shape&lt;ndim&gt;&amp; shape,
                                                                          Shape&lt;ndim&gt; begin,
                                                                          Shape&lt;ndim&gt; end,
                                                                          int offset) {
   int idx = 0;
 
   Shape&lt;ndim&gt; ref_strides;
   Shape&lt;ndim&gt; strides;
   ref_strides[ndim-1] = 1;
   strides[ndim-1] = 1;
   #pragma unroll
   for (int dim = ndim-1; dim &gt;=0; dim--) {
     if (begin[dim] &lt; 0) begin[dim] = shape[dim] + begin[dim];
     if (end[dim] &lt; 0) end[dim] = shape[dim] + end[dim];
     if (end[dim] == INT_MAX) end[dim] = shape[dim];
     if (dim &gt; 0) {
       ref_strides[dim-1] = ref_strides[dim] * (end[dim] - begin[dim]);
       strides[dim-1] = strides[dim] * shape[dim];
     }
   }
   int ref_idx = offset;
   #pragma unroll
   for (int dim = 0; dim &lt; ndim; dim++) {
      int stride = ref_strides[dim];
      if (shape[dim] &gt; 1) {
        idx += (ref_idx / stride + begin[dim]) * strides[dim];
      }
      ref_idx = ref_idx % stride;
   }
   return global_load_index&lt;nvec&gt;(input, idx, shape);
 }
 
 template &lt;int nvec, typename DType, int ndim&gt;
 __device__ inline void store_index(const vector::VectorizedStorage&lt;DType, nvec&gt; value, int i,
                         DType * output, const Shape&lt;ndim&gt;&amp; shape) {
   if (i &lt; (shape.size + nvec - 1) / nvec) {
     auto vector_output = reinterpret_cast&lt;
                           typename vector::VectorizedStorage&lt;DType, nvec&gt;::LType *&gt;(output);
     vector_output[i] = value.scratch_.aligned;
   }
 }
 
 template &lt;int nvec, typename DType, int ndim&gt;
 __device__ inline void store_add_index(const vector::VectorizedStorage&lt;DType, nvec&gt; value, int i,
                             DType * output, const Shape&lt;ndim&gt;&amp; shape) {
   if (i &lt; (shape.size + nvec - 1) / nvec) {
     auto vector_output = reinterpret_cast&lt;
                           typename vector::VectorizedStorage&lt;DType, nvec&gt;::LType *&gt;(output);
     vector::VectorizedStorage&lt;DType, nvec&gt; ret(vector_output[i]);
     ret += value;
     vector_output[i] = ret.scratch_.aligned;
   }
 }
 
 }  // namespace op
 
 
 namespace op {
 
 template &lt;typename DType&gt;
 __device__ inline bool isnan(const DType val) {
   return util::isnan(val);
 }
 
 template &lt;typename DType&gt;
 __device__ inline bool_t isinf(const DType val) {
   return util::isinf(val);
 }
 
 template &lt;typename DType&gt;
 __device__ inline bool_t isposinf(const DType val) {
   return util::isinf(val) &amp;&amp; (val &gt; 0);
 }
 
 template &lt;typename DType&gt;
 __device__ inline bool_t isneginf(const DType val) {
   return util::isinf(val) &amp;&amp; (val &lt; 0);
 }
 
 template &lt;typename DType&gt;
 __device__ inline bool_t isfinite(const DType val) {
   return !op::isnan(val) &amp;&amp; !op::isinf(val);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 add(const DType a, const DType2 b) {
   return a + b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 sub(const DType a, const DType2 b) {
   return a - b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rsub(const DType a, const DType2 b) {
   return b - a;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 mul(const DType a, const DType2 b) {
   return a * b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 div(const DType a, const DType2 b) {
   return a / b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rdiv(const DType a, const DType2 b) {
   return b / a;
 }
 
 #define DEFINE_BINARY_MATH_FUNC(name, double_version, float_version) \
 template &lt;typename DType, typename DType2&gt; \
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type \
 name (const DType a, const DType2 b) { \
   if (type_util::has_double_or_integral&lt;DType, DType2&gt;::value) { \
     return double_version ((double)a, (double)b); \
   } else { \
     return float_version ((float)a, (float)b); \
   } \
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 power (const DType a, const DType2 b) {
   if (type_util::has_double&lt;DType, DType2&gt;::value) {
     return ::pow ((double)a, (double)b); \
   } else {
     return ::powf ((float)a, (float)b);
   }
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rpow(const DType a, const DType2 b) {
   return power(b, a);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 max(const DType a, const DType2 b) {
   if (isnan(a)) return a;
   return a &gt; b ? a : b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 fmax(const DType a, const DType2 b) {
   if (isnan(b)) return a;
   return a &gt; b ? a : b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 min(const DType a, const DType2 b) {
   if (isnan(a)) return a;
   return a &lt; b ? a : b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 fmin(const DType a, const DType2 b) {
   if (isnan(b)) return a;
   return a &lt; b ? a : b;
 }
 
 DEFINE_BINARY_MATH_FUNC(hypot, ::hypot, ::hypotf)
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 mod(const DType a, const DType2 b) {
   if (b == 0) {
     return 0;
   }
   const double ad = static_cast&lt;double&gt;(a);
   const double bd = static_cast&lt;double&gt;(b);
   if (bd &lt; 0) {
     if (ad &lt; 0) {
       return -::fmod(-ad, -bd);
     } else {
       return ::fmod(ad, -bd) +
              (::fmod(ad, -bd) != 0 ? bd : 0);
     }
   } else {
     if (ad &lt; 0) {
       return -::fmod(-ad, bd) +
               (::fmod(-ad, bd) != 0 ? bd : 0);
     } else {
       return ::fmod(ad, bd);
     }
   }
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 fmod(const DType a, const DType2 b) {
   if (b == 0) {
     return 0;
   }
   return ::fmod(static_cast&lt;double&gt;(a), static_cast&lt;double&gt;(b));
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rmod(const DType a, const DType2 b) {
   return op::mod(b, a);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rfmod(const DType a, const DType2 b) {
   return op::fmod(b, a);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType equal(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a == real_b ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType not_equal(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a != real_b ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType greater(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &gt; real_b ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType greater_equal(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &gt;= real_b ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType less(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &lt; real_b ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType less_equal(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &lt;= real_b ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool_t np_equal(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a == real_b ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool_t np_not_equal(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a != real_b ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool_t np_greater(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &gt; real_b ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool_t np_greater_equal(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &gt;= real_b ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool_t np_less(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &lt; real_b ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool_t np_less_equal(const DType a, const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &lt;= real_b ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType logical_and(const DType a, const DType2 b) {
   return a &amp;&amp; b ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType logical_or(const DType a, const DType2 b) {
   return a || b ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType logical_xor(const DType a, const DType2 b) {
   return ((a || b) &amp;&amp; !(a &amp;&amp; b)) ? 1 : 0;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType copysign(const DType a, const DType2 b) {
   return (a &gt;= 0 &amp;&amp; b &gt;= 0) || (a &lt; 0 &amp;&amp; b &lt; 0) ? a : -a;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType2 rcopysign(const DType a, const DType2 b) {
   return copysign(b, a);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 lcm(const DType a, const DType2 b) {
   if (type_util::is_integral&lt;DType&gt;::value &amp;&amp;
       type_util::is_integral&lt;DType2&gt;::value) {
     DType A = a;
     DType2 B = b;
     // minus cases.
     if (a &lt; 0) {
       A = -a;
     }
     if (b &lt; 0) {
       B = -b;
     }
     // handle zero-valued cases.
     DType c;
     if (a == 0 || b == 0) {
       c = 0;
     } else {
       DType tmp;
       DType tmp_a = A;
       DType tmp_b = B;
       if (A &lt; B) {
         tmp = A;
         A = B;
         B = tmp;
       }
       while (A % B != 0) {
         A = A % B;
         tmp = A;
         A = B;
         B = tmp;
       }
       c = tmp_a / B * tmp_b;
     }
     return c;
   } else {
     return 0;
   }
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type bitwise_xor(const DType a,
                                                                        const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a ^ real_b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type bitwise_or(const DType a,
                                                                        const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a | real_b;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type bitwise_and(const DType a,
                                                                        const DType2 b) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   const mixed_type real_a = a;
   const mixed_type real_b = b;
   return real_a &amp; real_b;
 }
 
 DEFINE_BINARY_MATH_FUNC(arctan2, ::atan2, ::atan2f)
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rarctan2(const DType a, const DType2 b) {
   return arctan2(b, a);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 ldexp(const DType a, const DType2 b) {
   if (type_util::has_double_or_integral&lt;DType, DType2&gt;::value) {
     return a * ::pow(2.0, static_cast&lt;double&gt;(b));
   } else {
     return a * ::powf(2.0f, static_cast&lt;float&gt;(b));
   }
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rldexp(const DType a, const DType2 b) {
   return ldexp(b, a);
 }
 
 #undef DEFINE_BINARY_MATH_FUNC
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool np_logical_and(const DType val, const DType2 val2) {
   return (val &amp;&amp; val2) ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool np_logical_or(const DType val, const DType2 val2) {
   return (val || val2) ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline bool np_logical_xor(const DType val, const DType2 val2) {
   return ((val || val2) &amp;&amp; !(val &amp;&amp; val2)) ? true : false;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType left(const DType left_val, const DType2 right_val) {
   return left_val;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType2 right(const DType left_val, const DType2 right_val) {
   return right_val;
 }
 
 }  // namespace op
 
 
 namespace op {
 
 template &lt;typename DType&gt;
 __device__ inline DType identity(const DType val) {
   return val;
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType negation(const DType val) {
   return -val;
 }
 
 template &lt;typename OutType, typename DType&gt;
 __device__ inline typename LoadType&lt;OutType&gt;::Type cast(const DType val) {
   return static_cast&lt;typename LoadType&lt;OutType&gt;::Type&gt;(val);
 }
 
 // activations
 
 template &lt;typename DType&gt;
 __device__ inline DType relu(const DType val) {
   return (isnan(val) || val &gt; 0) ? val : 0;
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType sigmoid(const DType val) {
   if (type_util::has_double_or_integral&lt;DType&gt;::value) {
     return 1./(1 + ::exp(-val));
   } else {
     return 1.f/(1 + expf(-val));
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType softrelu(const DType val) {
   if (type_util::has_double_or_integral&lt;DType&gt;::value) {
     return ::log(1 + ::exp(val));
   } else {
     return logf(1 + expf(val));
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType softsign(const DType val) {
   if (type_util::has_double_or_integral&lt;DType&gt;::value) {
     return val / (1 + fabs(val));
   } else {
     return val / (1 + fabsf(val));
   }
 }
 
 // exp and log
 
 #define DEFINE_UNARY_MATH_FUNC(name, double_version, float_version) \
 template &lt;typename DType&gt; \
 __device__ inline DType name (const DType a) { \
   if (type_util::has_double_or_integral&lt;DType&gt;::value) { \
     return double_version ((double)a); \
   } else { \
     return float_version (a); \
   } \
 }
 
 DEFINE_UNARY_MATH_FUNC(exp, ::exp, ::expf)
 DEFINE_UNARY_MATH_FUNC(expm1, ::expm1, ::expm1f)
 DEFINE_UNARY_MATH_FUNC(log, ::log, ::logf)
 DEFINE_UNARY_MATH_FUNC(log10, ::log10, ::log10f)
 DEFINE_UNARY_MATH_FUNC(log2, ::log2, ::log2f)
 DEFINE_UNARY_MATH_FUNC(log1p, ::log1p, ::log1pf)
 
 // trigonometric
 
 constexpr double pi = 3.14159265358979323846;
 
 template &lt;typename DType&gt;
 __device__ inline DType degrees(const DType val) {
   if (type_util::has_double_or_integral&lt;DType&gt;::value) {
     return (val / pi) * 180;
   } else {
     return (val / static_cast&lt;float&gt;(pi)) * 180.f;
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType radians(const DType val) {
   if (type_util::has_double_or_integral&lt;DType&gt;::value) {
     return (val / 180.0) * pi;
   } else {
     return (val / 180.0f) * static_cast&lt;float&gt;(pi);
   }
 }
 
 DEFINE_UNARY_MATH_FUNC(sin, ::sin, ::sinf)
 DEFINE_UNARY_MATH_FUNC(cos, ::cos, ::cosf)
 DEFINE_UNARY_MATH_FUNC(tan, ::tan, ::tanf)
 DEFINE_UNARY_MATH_FUNC(arcsin, ::asin, ::asinf)
 DEFINE_UNARY_MATH_FUNC(arccos, ::acos, ::acosf)
 DEFINE_UNARY_MATH_FUNC(arctan, ::atan, ::atanf)
 
 DEFINE_UNARY_MATH_FUNC(sinh, ::sinh, ::sinhf)
 DEFINE_UNARY_MATH_FUNC(cosh, ::cosh, ::coshf)
 DEFINE_UNARY_MATH_FUNC(tanh, ::tanh, ::tanhf)
 DEFINE_UNARY_MATH_FUNC(arcsinh, ::asinh, ::asinhf)
 DEFINE_UNARY_MATH_FUNC(arccosh, ::acosh, ::acoshf)
 DEFINE_UNARY_MATH_FUNC(arctanh, ::atanh, ::atanhf)
 
 // sqrt
 
 DEFINE_UNARY_MATH_FUNC(sqrt, ::sqrt, ::sqrtf)
 DEFINE_UNARY_MATH_FUNC(rsqrt, ::rsqrt, ::rsqrtf)
 DEFINE_UNARY_MATH_FUNC(cbrt, ::cbrt, ::cbrtf)
 DEFINE_UNARY_MATH_FUNC(rcbrt, ::rcbrt, ::rcbrtf)
 
 template &lt;typename DType&gt;
 __device__ inline DType square(const DType val) {
   return val * val;
 }
 
 template &lt;typename DType, typename... DTypes&gt;
 __device__ inline typename LoadType&lt;DType&gt;::Type zero(const DType val, const DTypes... args) {
   return 0;
 }
 
 template &lt;typename DType&gt;
 __device__ inline typename LoadType&lt;DType&gt;::Type zero() {
   return 0;
 }
 
 template &lt;typename DType, typename... DTypes&gt;
 __device__ inline typename LoadType&lt;DType&gt;::Type one(const DType val, const DTypes... args) {
   return 1;
 }
 
 template &lt;typename DType&gt;
 __device__ inline typename LoadType&lt;DType&gt;::Type one() {
   return 1;
 }
 
 template &lt;typename DType, typename... DTypes&gt;
 __device__ inline typename LoadType&lt;DType&gt;::Type negone(const DType val, const DTypes... args) {
   return -1;
 }
 
 template &lt;typename DType&gt;
 __device__ inline typename LoadType&lt;DType&gt;::Type negone() {
   return -1;
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType round(const DType val) {
   if (type_util::has_double&lt;DType&gt;::value) {
     return ::round((double)val);
   } else if (type_util::is_integral&lt;DType&gt;::value) {
     return val;
   } else {
     return ::roundf(val);
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType floor(const DType val) {
   if (type_util::has_double&lt;DType&gt;::value) {
     return ::floor((double)val);
   } else if (type_util::is_integral&lt;DType&gt;::value) {
     return val;
   } else {
     return ::floorf(val);
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType ceil(const DType val) {
   if (type_util::has_double&lt;DType&gt;::value) {
     return ::ceil((double)val);
   } else if (type_util::is_integral&lt;DType&gt;::value) {
     return val;
   } else {
     return ::ceilf(val);
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType rint(const DType val) {
   if (type_util::has_double&lt;DType&gt;::value) {
     return ::rint((double)val);
   } else if (type_util::is_integral&lt;DType&gt;::value) {
     return val;
   } else {
     return ::rintf(val);
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType fix(const DType val) {
   const auto f = floor(val);
   const auto c = ceil(val);
   return (f &gt; 0 ? f : -f) &lt; (c &gt; 0 ? c : -c) ? f : c;
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType trunc(const DType val) {
   if (type_util::has_double&lt;DType&gt;::value) {
     return ::trunc((double)val);
   } else if (type_util::is_integral&lt;DType&gt;::value) {
     return val;
   } else {
     return ::truncf(val);
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType clip(const DType val, const float a_min, const float a_max) {
   return max(min(val, a_max), a_min);
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType sign(const DType val) {
   if (val &lt; 0) return -1;
   return val &gt; 0 ? 1 : 0;
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType reciprocal(const DType val) {
   return 1.0f / val;
 }
 
 DEFINE_UNARY_MATH_FUNC(abs, ::fabs, ::fabsf)
 DEFINE_UNARY_MATH_FUNC(gamma, ::tgamma, ::tgammaf)
 DEFINE_UNARY_MATH_FUNC(gammaln, ::lgamma, ::lgammaf)
 DEFINE_UNARY_MATH_FUNC(erf, ::erf, ::erff)
 DEFINE_UNARY_MATH_FUNC(erfinv, ::erfinv, ::erfinvf)
 
 template &lt;typename DType&gt;
 __device__ inline DType gelu(const DType val) {
   return 0.5f * val * (1.0f + op::erf(val / op::sqrt(2.0f)));
 }
 
 template &lt;typename DType1, typename DType2&gt;
 __device__ inline DType1 smooth_l1(const DType1 val, const DType2 scalar) {
   const auto bsq = scalar * scalar;
   const auto ibsq = 1.0f / bsq;
   if (val &gt; ibsq) {
     return val - 0.5f * ibsq;
   } else if (val &lt; -ibsq) {
     return -val - 0.5f * ibsq;
   } else {
     return 0.5f * val * val * bsq;
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType digamma(const DType val) {
   if (type_util::has_double_or_integral&lt;DType&gt;::value) {
     return special_functions::cephes::psi&lt;double&gt;(val);
   } else {
     return special_functions::cephes::psi&lt;float&gt;(val);
   }
 }
 
 template &lt;typename DType&gt;
 __device__ inline DType logical_not(const DType val) {
   return val != DType(0) ? DType(0) : DType(1);
 }
 
 template &lt;typename DType&gt;
 __device__ inline bool_t np_logical_not(const DType val) {
   return !static_cast&lt;bool&gt;(val);
 }
 
 #undef DEFINE_UNARY_MATH_FUNC
 
 template &lt;typename DType&gt;
 __device__ inline DType bitwise_not(const DType a) {
   if (type_util::is_same&lt;DType, bool_t&gt;::value) {
     return !a;
   } else {
     return ~static_cast&lt;int64&gt;(a);
   }
 }
 
 }  // namespace op
 
 
 
 
 namespace op {
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_relu(const DTypeGrad grad, const DType val) {
   if (isnan(val)) return val;
   return val &gt; 0 ? grad : 0;
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_sigmoid(const DTypeGrad grad, const DType out) {
   return grad * out * (1 - out);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_softrelu(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad * sigmoid(v);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_softsign(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   const auto ap1 = 1 + op::abs(v);
   return grad / (ap1 * ap1);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_abs(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad * op::sign(v);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_exp(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad * op::exp(v);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_expm1(const DTypeGrad grad, const DType val) {
   return backward_exp(grad, val);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_log(const DTypeGrad grad, const DType val) {
   return grad / val;
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_log10(const DTypeGrad grad, const DType val) {
   return grad / (val * op::log(static_cast&lt;DTypeGrad&gt;(10)));
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_log2(const DTypeGrad grad, const DType val) {
   return grad / (val * op::log(static_cast&lt;DTypeGrad&gt;(2)));
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_log1p(const DTypeGrad grad, const DType val) {
   return grad / (1 + val);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_sin(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad * op::cos(v);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_cos(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return -grad * op::sin(v);
 }
 
 // Uses output from tan
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_tan(const DTypeGrad grad, const DType out) {
   return grad * (out * out + 1);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_arcsin(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad / op::sqrt(1 - v*v);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_arccos(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return -grad / op::sqrt(1 - v*v);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_arctan(const DTypeGrad grad, const DType val) {
   return grad / (1 + val*val);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_degrees(const DTypeGrad grad, const DType /* val */) {
   return op::degrees(grad);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_radians(const DTypeGrad grad, const DType /* val */) {
   return op::radians(grad);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_sinh(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad * op::cosh(v);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_cosh(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad * op::sinh(v);
 }
 
 // Uses tanh output
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_tanh(const DTypeGrad grad, const DType out) {
   return grad * (1 - out * out);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_arcsinh(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad / op::sqrt(v * v + 1);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_arccosh(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   return grad / op::sqrt(v * v - 1);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_arctanh(const DTypeGrad grad, const DType val) {
   return grad / (1 - val * val);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_sqrt(const DTypeGrad grad, const DType out) {
   return 0.5 * grad / out;
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_rsqrt(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   const auto inv = 1 / v;
   return -0.5 * grad * op::sqrt(inv) * inv;
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_cbrt(const DTypeGrad grad, const DType out) {
   return grad / (3.0f * out * out);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_rcbrt(const DTypeGrad grad, const DType val) {
   const typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type v = val;
   const auto inv = 1 / v;
   return -1.f/3.f * grad * op::cbrt(inv) * inv;
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_square(const DTypeGrad grad, const DType val) {
   return 2 * val * grad;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rdiv_grad(const DType val,
           const DType2 val2) {
   return -val2 / (val * val);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 div_grad(const DType val,
          const DType2 val2) {
   const typename type_util::mixed_type&lt;DType, DType2&gt;::type temp = val2;
   return op::reciprocal(temp);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType div_rgrad(const DType val,
                                   const DType2 val2) {
   return -val / (val2 * val2);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType mod_grad(const DType val,
                                  const DType2 val2) {
   if (type_util::is_integral&lt;DType&gt;::value) {
     return 0;
   } else {
     return 1;
   }
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType mod_rgrad(const DType val,
                                   const DType2 val2) {
   if (type_util::is_integral&lt;DType&gt;::value) {
     return 0;
   } else {
     return -op::floor(val / val2);
   }
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType rmod_grad(const DType val,
                                   const DType2 val2) {
   if (type_util::is_integral&lt;DType&gt;::value) {
     return 0;
   } else {
     return -op::floor(val2 / val);
   }
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 power_grad(const DType val,
            const DType2 val2) {
   return op::power(val, val2 - 1.f) * val2;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 power_rgrad(const DType val,
             const DType2 val2) {
   const typename type_util::mixed_type&lt;DType, DType2&gt;::type temp = val;
   return op::power(val, val2) * op::log(temp);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rpower_grad(const DType val,
             const DType2 val2) {
   const typename type_util::mixed_type&lt;DType, DType2&gt;::type temp = val2;
   return val * op::log(temp);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 hypot_grad_left(const DType val,
                 const DType2 val2) {
   return val / op::hypot(val, val2);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 hypot_grad_right(const DType val,
                  const DType2 val2) {
   return val2 / op::hypot(val, val2);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 copysign_grad(const DType val,
               const DType2 val2) {
   return (val &gt;= 0 &amp;&amp; val2 &gt;= 0) || (val &lt; 0 &amp;&amp; val2 &lt; 0) ? 1 : -1;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 arctan2_grad(const DType val,
              const DType2 val2) {
   return val2 / (val * val + val2 * val2);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rarctan2_grad(const DType val,
               const DType2 val2) {
   return val / (val * val + val2 * val2);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 arctan2_rgrad(const DType val,
               const DType2 val2) {
   return -rarctan2_grad(val, val2);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 ldexp_grad(const DType val,
            const DType2 val2) {
   return op::power(static_cast&lt;DType&gt;(2), val2);
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline typename type_util::mixed_type&lt;DType, DType2&gt;::type
 rldexp_grad(const DType val,
             const DType2 val2) {
   using mixed_type = typename type_util::mixed_type&lt;DType, DType2&gt;::type;
   return val2 * op::power(static_cast&lt;mixed_type&gt;(2), val) * op::log(static_cast&lt;mixed_type&gt;(2));
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_clip(const DTypeGrad grad, const DType val,
               const float a_min, const float a_max) {
   if (val &gt; a_max || val &lt; a_min) {
     return 0;
   } else {
     return grad;
   }
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_reciprocal(const DTypeGrad grad, const DType val) {
   return -grad / (val * val);
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_erf(const DTypeGrad grad, const DType val) {
   using mixed_type = typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type;
   const mixed_type v = val;
   constexpr mixed_type my_pi = pi;
   return 2.0f / op::sqrt(my_pi) * op::exp(-(v*v)) * grad;
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_erfinv(const DTypeGrad grad, const DType val) {
   using mixed_type = typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type;
   constexpr mixed_type my_pi = pi;
   const mixed_type g = grad;
   const mixed_type v = val;
   return 0.5f * op::sqrt(my_pi) * op::exp(v * v) * g;
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_gamma(const DTypeGrad grad, const DType val) {
   using mixed_type = typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type;
   const mixed_type v = val;
   if (type_util::is_same&lt;DTypeGrad, double&gt;::value) {
     return grad * op::gamma(v) * op::special_functions::cephes::psi&lt;double&gt;(v);
   } else {
     return grad * op::gamma(v) * op::special_functions::cephes::psi&lt;float&gt;(v);
   }
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_gammaln(const DTypeGrad grad, const DType val) {
   using mixed_type = typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type;
   const mixed_type v = val;
   if (type_util::is_same&lt;DTypeGrad, double&gt;::value) {
     return grad * op::special_functions::cephes::psi&lt;double&gt;(v);
   } else {
     return grad * op::special_functions::cephes::psi&lt;float&gt;(v);
   }
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_digamma(const DTypeGrad grad, const DType val) {
   using mixed_type = typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type;
   const mixed_type v = val;
   if (type_util::is_same&lt;DTypeGrad, double&gt;::value) {
     return grad * op::special_functions::trigamma&lt;double&gt;(v);
   } else {
     return grad * op::special_functions::trigamma&lt;float&gt;(v);
   }
 }
 
 template &lt;typename DType, typename DTypeGrad&gt;
 __device__ inline typename type_util::mixed_type&lt;DTypeGrad, DType&gt;::type
 backward_gelu(const DTypeGrad grad, const DType val) {
   return 0.5f * (grad + grad * op::erf(val / op::sqrt(2.0f)) +
                  val * backward_erf(grad, val / op::sqrt(2.0f)) / op::sqrt(2.0f));
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType smooth_l1_grad(const DType val, const DType2 scalar) {
   auto bsq = scalar * scalar;
   auto ibsq = 1.0f / bsq;
   if (val &gt; ibsq) {
     return 1;
   } else if (val &lt; -ibsq) {
     return -1;
   } else {
     return bsq * val;
   }
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType2 xelu_grad(const DType val,
                                    const DType2 val2) {
   return (val &gt; 0) ? 1 : val2;
 }
 
 template &lt;typename DType, typename DType2&gt;
 __device__ inline DType prelu_grad(const DType val,
                                    const DType2 val2) {
   return (val &gt; 0) ? 0 : val;
 }
 
 }  // namespace op
 
 
 
 
 namespace red {
 
 /*! \brief sum reducer */
 struct sum {
   /*! \brief do reduction into dst */
   template&lt;typename DType, typename DType2&gt;
   __device__ inline static void Reduce(volatile DType&amp; dst,  volatile DType2 src) {
     dst = op::add(dst, src);
   }
 
   /*! \brief do stable reduction into dst */
   template&lt;typename DType, typename DType2&gt;
   __device__ inline static void Reduce(volatile DType&amp; dst,  volatile DType2 src,
                                        volatile DType&amp; residual) {
     DType y = op::sub(src, residual);
     DType t = dst + y;
     if (util::isinf(t)) {
       residual = 0;
     } else {
       residual = (t - dst) - y;
     }
     dst = t;
   }
   /*! \brief combine the results of two reducers */
   template&lt;typename DType&gt;
   __device__ inline static void Merge(volatile DType&amp; dst_val, volatile DType&amp; src_val) {
     Reduce(dst_val, src_val);
   }
   /*! \brief combine the results of two reducers */
   template&lt;typename DType&gt;
   __device__ inline static void Merge(volatile DType&amp; dst_val, volatile DType&amp; dst_residual,
                                       volatile DType&amp; src_val, volatile DType&amp; src_residual) {
     DType t1 = dst_val + src_val;
     if (util::isinf(t1)) {
       dst_val = t1;
       dst_residual = 0;
     } else {
       DType e = t1 - dst_val;
       DType t2 = ((src_val - e) + (dst_val - (t1 - e))) + dst_residual + src_residual;
       dst_val = t1 + t2;
       dst_residual = t2 - (dst_val - t1);
     }
   }
   /*! \brief finalize reduction result */
   template&lt;typename DType&gt;
   __device__ inline static void Finalize(volatile DType&amp; dst) {}
   /*! \brief finalize reduction result */
   template&lt;typename DType&gt;
   __device__ inline static void Finalize(volatile DType&amp; dst, volatile DType&amp; none) {}
   /*!
    *\brief set the initial value during reduction
    */
   template&lt;typename DType&gt;
   __device__ inline static void SetInitValue(DType &amp;initv) {
     initv = 0;
   }
   /*!
    *\brief set the initial value during reduction
    */
   template&lt;typename DType&gt;
   __device__ inline static void SetInitValue(DType &amp;initv, DType &amp;residual) {
     SetInitValue(initv);
     residual = 0;
   }
 };
 }  // namespace red
 
 
 using DType_output1 = float;
 static const int ndim_output1 = 2;
 using DType_output0 = int;
 static const int ndim_output0 = 2;
 static const int ndim_input_0 = 2;
 using DType_input_0 = int;
 static const int nvec = 1;
 
 __launch_bounds__(512)
 __global__ void FusedKernel_clip_Cast(size_t N,  const op::Shape&lt;2&gt; input_0_shape,  const op::Shape&lt;2&gt; output0_shape,  const op::Shape&lt;2&gt; output1_shape, DType_input_0* input_0, DType_output0* output0, DType_output1* output1) {
 
 const int tid = threadIdx.x + blockIdx.x * blockDim.x;
 for (int i = tid; i &lt; N; i+= gridDim.x * blockDim.x) {
     int offset = i*nvec;
 
 const auto vec_input_0 = op::load_index&lt;nvec&gt;(input_0, offset, input_0_shape);
 vector::VectorizedStorage&lt;DType_output0, nvec&gt; vec_output0;
 vector::VectorizedStorage&lt;DType_output1, nvec&gt; vec_output1;
 for (int j = 0; j &lt; nvec; j++ ) {
 const auto temp0 = op::load(vec_input_0.scratch_.separate[j]);
 const auto temp2 = op::clip(temp0, 0, inf);
 const auto temp4 = op::cast&lt;float32&gt;(temp2);
 vec_output0.scratch_.separate[j] = op::store(temp2, output0);
 vec_output1.scratch_.separate[j] = op::store(temp4, output1);
 }
 op::store_index(vec_output0, i, output0, output0_shape);
 op::store_index(vec_output1, i, output1, output1_shape);
 
 }
 }
 
 	</description>
 	<comments>
 		<comment id='1' author='sxjscience' date='2020-08-28T00:03:19Z'>
 		Ok, I believe  is generated by the ffi for  here: &lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/src/api/operator/tensor/matrix_op.cc#L52&gt;https://github.com/apache/incubator-mxnet/blob/master/src/api/operator/tensor/matrix_op.cc#L52&lt;/denchmark-link&gt;
 
 I will make PR with support for fusion of clip without a_min or a_max parameters tomorrow.
 		</comment>
 	</comments>
 </bug>
<commit id='e2aacce02b2e09d2bed832810f4aade4d750afcb' author='Przemyslaw Tredak' date='2020-08-30 22:08:18-07:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\common\cuda\rtc\forward_functions-inl.h' new_name='src\common\cuda\rtc\forward_functions-inl.h'>
 		<file_info nloc='891' complexity='0' token_count='43'></file_info>
 		<modified_lines>
 			<added_lines>838,839,840,841,842,843,844</added_lines>
 			<deleted_lines>838</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\common\cuda\rtc\special_functions-inl.h' new_name='src\common\cuda\rtc\special_functions-inl.h'>
 		<file_info nloc='252' complexity='0' token_count='29'></file_info>
 		<modified_lines>
 			<added_lines>54,55,56</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\python\gpu\test_fusion.py' new_name='tests\python\gpu\test_fusion.py'>
 		<file_info nloc='274' complexity='40' token_count='2734'></file_info>
 		<method name='check_unary_ops' parameters=''>
 				<method_info nloc='81' complexity='5' token_count='510' nesting_level='0' start_line='67' end_line='169'></method_info>
 			<added_lines>163,164,165</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
