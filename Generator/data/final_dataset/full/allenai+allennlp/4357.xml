<bug_data>
<bug id='4357' author='12seetharaman' open_date='2020-06-15T00:26:20Z' closed_time='2020-07-13T20:54:55Z'>
 	<summary>Bug on calculating "argmax_predictions". It increases the false positive count for last label.</summary>
 	<description>
 File: &lt;denchmark-link:https://github.com/allenai/allennlp/blob/master/allennlp/training/metrics/fbeta_measure.py&gt;https://github.com/allenai/allennlp/blob/master/allennlp/training/metrics/fbeta_measure.py&lt;/denchmark-link&gt;
 
 Line no: 132
 Prediction tensor is all zero "[0, 0, 0, 0, 0, 0]", when a record is not classified to any of the labels.
 argmax_predictions = predictions.max(dim=-1)[1].float()
 Here, we are calculating argmax predictions by a max value index.
 In the case of all zeros tensor, we will get the index of the last label. It increases the false positive count of the last label and affects the F1 score.
 &lt;denchmark-code&gt;&gt;&gt;&gt; prediction =  torch.zeros(6)
 &gt;&gt;&gt; prediction
 tensor([0., 0., 0., 0., 0., 0.])
 &gt;&gt;&gt; prediction.max(dim=-1)
 (tensor(0.), tensor(5))
 &gt;&gt;&gt; prediction.max(dim=-1)[1]
 tensor(5)
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='12seetharaman' date='2020-06-19T16:24:04Z'>
 		This is definitely a bug. Could you submit a PR to fix it?
 		</comment>
 	</comments>
 </bug>
<commit id='7b188c93b5efe2f417fc541b61f6be29bc2e632f' author='Akshita Bhagia' date='2020-07-13 16:54:54-04:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>32</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\training\metrics\fbeta_measure.py' new_name='allennlp\training\metrics\fbeta_measure.py'>
 		<file_info nloc='181' complexity='19' token_count='1029'></file_info>
 		<modified_lines>
 			<added_lines>132,133,135,136,148</added_lines>
 			<deleted_lines>133,145</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\training\metrics\fbeta_measure_test.py' new_name='tests\training\metrics\fbeta_measure_test.py'>
 		<file_info nloc='276' complexity='21' token_count='2749'></file_info>
 		<method name='test_fbeta_handles_no_prediction_true_all_class' parameters='self,str'>
 				<method_info nloc='12' complexity='1' token_count='135' nesting_level='1' start_line='350' end_line='365'></method_info>
 			<added_lines>350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_fbeta_handles_no_prediction_true_last_class' parameters='self,str'>
 				<method_info nloc='12' complexity='1' token_count='135' nesting_level='1' start_line='314' end_line='329'></method_info>
 			<added_lines>314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_fbeta_handles_no_prediction_true_other_class' parameters='self,str'>
 				<method_info nloc='12' complexity='1' token_count='135' nesting_level='1' start_line='332' end_line='347'></method_info>
 			<added_lines>332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_fbeta_handles_no_prediction_false_last_class' parameters='self,str'>
 				<method_info nloc='12' complexity='1' token_count='135' nesting_level='1' start_line='296' end_line='311'></method_info>
 			<added_lines>296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>294,295,312,313,330,331,348,349</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
