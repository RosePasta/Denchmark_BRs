<bug_data>
<bug id='4666' author='dirkgr' open_date='2020-09-23T22:31:39Z' closed_time='2020-10-07T18:14:35Z'>
 	<summary>When running multiple distributed runs on the same box, AllenNLP says "RuntimeError address already in use‚Äù</summary>
 	<description>
 The workaround is to set "distributed" { "master_port": 29501 } in the training config, but we can do better and automatically find a free port.
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='ae7cf85b8f755f086341a087aeca1ba7c1df3769' author='Evan Pete Walsh' date='2020-10-07 18:14:34+00:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>40</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\commands\train.py' new_name='allennlp\commands\train.py'>
 		<file_info nloc='597' complexity='13' token_count='1992'></file_info>
 		<modified_lines>
 			<added_lines>260,261,262,263,264,265,266,267,268</added_lines>
 			<deleted_lines>260</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\common\util.py' new_name='allennlp\common\util.py'>
 		<file_info nloc='478' complexity='109' token_count='2427'></file_info>
 		<method name='find_open_port' parameters=''>
 				<method_info nloc='8' complexity='1' token_count='44' nesting_level='0' start_line='587' end_line='597'></method_info>
 			<added_lines>587,588,589,590,591,592,593,594,595,596,597</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>598,599</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
