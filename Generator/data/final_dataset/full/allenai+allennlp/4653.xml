<bug_data>
<bug id='4653' author='mahnerak' open_date='2020-09-20T17:21:56Z' closed_time='2020-10-19T18:32:06Z'>
 	<summary>Closing the TensorBoard writer</summary>
 	<description>
 I had noticed that sometimes tensorboard fails to properly read the tfevents files.
 They are mainly in case of runs which I decided to interrupt the training (not sure about other abortion scenarios).
 Then, I wanted to make sure the tensorboard writer is properly closed. I found the close() is called only here, but not inside any with or finally construct:
 
 
 
 allennlp/allennlp/training/trainer.py
 
 
          Line 970
       in
       fbd2ccc
 
 
 
 
 
 
  self._tensorboard.close() 
 
 
 
 
 
 Here we can see the writer is closed just by calling .close() so there's no guarantee that the data is going to be flushed.
 Is there any reason for this implementation? Does this need to be fixed?
 	</description>
 	<comments>
 		<comment id='1' author='mahnerak' date='2020-09-22T17:42:10Z'>
 		Hi &lt;denchmark-link:https://github.com/mahnerak&gt;@mahnerak&lt;/denchmark-link&gt;
 , that seems like an oversight on our part. Would you be interested in making a PR to fix that?
 		</comment>
 		<comment id='2' author='mahnerak' date='2020-09-22T20:32:17Z'>
 		Sure!
 I just don't want to increase the indentation of the train-loop code by adding try/finally and with to train().
 One good option is to add close() method to Trainer so it can handle even multiple handles to be closed. And the trainer instance can be closed from:
 
 
 
 allennlp/allennlp/commands/train.py
 
 
         Lines 503 to 506
       in
       fbd2ccc
 
 
 
 
 
 
  
 
 
 
  def run(self) -&gt; Dict[str, Any]: 
 
 
 
  return self.trainer.train() 
 
 
 
  
 
 
 
 
 
 		</comment>
 		<comment id='3' author='mahnerak' date='2020-09-22T20:54:34Z'>
 		Cool. I think maybe Trainer.clean_up() is a better/more general name for the method?
 		</comment>
 	</comments>
 </bug>
<commit id='00bb6c59b3ac8fdc78dfe8d5b9b645ce8ed085c0' author='Dirk Groeneveld' date='2020-10-19 11:32:05-07:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>84</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\training\trainer.py' new_name='allennlp\training\trainer.py'>
 		<file_info nloc='1046' complexity='126' token_count='4930'></file_info>
 		<method name='_try_train' parameters='self'>
 				<method_info nloc='106' complexity='30' token_count='809' nesting_level='1' start_line='974' end_line='1122'></method_info>
 			<added_lines>974,1078,1079</added_lines>
 			<deleted_lines>1071,1109,1110,1111</deleted_lines>
 		</method>
 		<method name='train' parameters='self'>
 				<method_info nloc='8' complexity='2' token_count='30' nesting_level='1' start_line='964' end_line='972'></method_info>
 			<added_lines>968,969,970,971,972</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>973</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
