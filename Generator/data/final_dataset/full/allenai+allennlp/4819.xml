<bug_data>
<bug id='4819' author='tmcclintock' open_date='2020-11-25T17:31:11Z' closed_time='2020-12-05T06:48:58Z'>
 	<summary>Rename token.py to avoid bugs in certain Python versions</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Checklist&lt;/denchmark-h&gt;
 
 
  I have verified that the issue exists against the master branch of AllenNLP.
  I have read the relevant section in the contribution guide on reporting bugs.
  I have checked the issues list for similar or identical bug reports.
  I have checked the pull requests list for existing proposed fixes.
  I have checked the CHANGELOG and the commit log to find out if the bug was already fixed in the master branch.
  I have included in the "Description" section below a traceback from any exceptions related to this bug.
  I have included in the "Related issues or possible duplicates" section below all related issues and possible duplicate issues (If there are none, check this box anyway).
  I have included in the "Environment" section below the name of the operating system and Python version that I was using when I discovered this bug.
  I have included in the "Environment" section below the output of pip freeze.
  I have included in the "Steps to reproduce" section below a minimally reproducible example.
 
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 In certain version of Python (verified with 3.7.8) attempting to import from the file token.py causes a circular import because there is an identically named file in the dependency tree of the dataclasses module.
 
 Python traceback:
 
 Traceback (most recent call last):
   File "token.py", line 1, in &lt;module&gt;
     from dataclasses import dataclass
   File "/opt/anaconda3/envs/allentest/lib/python3.7/dataclasses.py", line 5, in &lt;module&gt;
     import inspect
   File "/opt/anaconda3/envs/allentest/lib/python3.7/inspect.py", line 40, in &lt;module&gt;
     import linecache
   File "/opt/anaconda3/envs/allentest/lib/python3.7/linecache.py", line 11, in &lt;module&gt;
     import tokenize
   File "/opt/anaconda3/envs/allentest/lib/python3.7/tokenize.py", line 35, in &lt;module&gt;
     from token import *
   File "/Users/tmcclintock/Github/allennlp/allennlp/data/tokenizers/token.py", line 1, in &lt;module&gt;
     from dataclasses import dataclass
 ImportError: cannot import name 'dataclass' from 'dataclasses' (/opt/anaconda3/envs/allentest/lib/python3.7/dataclasses.py)
 
 
 
 &lt;denchmark-h:h2&gt;Related issues or possible duplicates&lt;/denchmark-h&gt;
 
 I was not able to find duplicate issue in the open or closed issues or in the current PRs.
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 OS: OSX
 Python version: 3.7.8
 
 Output of pip freeze:
 
 certifi==2020.11.8
 
 
 
 &lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;
 
 
 Example source:
 
 Begin by creating a fresh environment, cloning, and changing into the relevant directory:
 conda create --name allentest python=3.7.8
 conda activate allentest
 git clone https://github.com/allenai/allennlp.git
 cd allennlp/allennlp/data/tokenizers/
 Attempt to run the file in question:
 python token.py
 
 
 &lt;denchmark-h:h2&gt;Proposed solution&lt;/denchmark-h&gt;
 
 The fix is easy, in that you can just rename the file so there is no collision mv token.py token_class.py and update import statements.
 	</description>
 	<comments>
 		<comment id='1' author='tmcclintock' date='2020-11-25T18:28:04Z'>
 		Huh, that's interesting. The error still happens when you run
 python allennlp/data/tokenizers/token.py
 from the root of the repo, but doesn't happen when import from a Python interpreter:
 python
 &gt;&gt;&gt; from allennlp.data.tokenizers import token
 &gt;&gt;&gt; # all good
 		</comment>
 		<comment id='2' author='tmcclintock' date='2020-11-25T19:28:32Z'>
 		Yes, it's very subtle. The same error occurs in Python 3.9.0 (just checked).
 I think it speaks to how "token" is overloaded. Collisions were inevitable I guess...
 		</comment>
 		<comment id='3' author='tmcclintock' date='2020-11-25T21:14:25Z'>
 		Ok, yes, let's make that change. Would you like to make the PR &lt;denchmark-link:https://github.com/tmcclintock&gt;@tmcclintock&lt;/denchmark-link&gt;
 ?
 		</comment>
 		<comment id='4' author='tmcclintock' date='2020-11-25T21:40:13Z'>
 		Will do. May take until the weekend though.
 		</comment>
 		<comment id='5' author='tmcclintock' date='2020-11-25T21:41:06Z'>
 		No rush.
 		</comment>
 		<comment id='6' author='tmcclintock' date='2020-12-05T06:53:32Z'>
 		My bad. Got busy.
 		</comment>
 	</comments>
 </bug>
<commit id='6c3238ec8e714960174171decc47f9c34d1941f2' author='Evan Pete Walsh' date='2020-12-04 22:48:56-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>16,17,18,19,20</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\common\util.py' new_name='allennlp\common\util.py'>
 		<file_info nloc='488' complexity='110' token_count='2482'></file_info>
 		<method name='sanitize' parameters='Any'>
 				<method_info nloc='32' complexity='13' token_count='204' nesting_level='0' start_line='66' end_line='107'></method_info>
 			<added_lines>72</added_lines>
 			<deleted_lines>72</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\__init__.py' new_name='allennlp\data\__init__.py'>
 		<file_info nloc='14' complexity='0' token_count='107'></file_info>
 		<modified_lines>
 			<added_lines>12</added_lines>
 			<deleted_lines>12,13</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\dataset_readers\dataset_utils\span_utils.py' new_name='allennlp\data\dataset_readers\dataset_utils\span_utils.py'>
 		<file_info nloc='356' complexity='30' token_count='1637'></file_info>
 		<modified_lines>
 			<added_lines>5</added_lines>
 			<deleted_lines>5</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\fields\namespace_swapping_field.py' new_name='allennlp\data\fields\namespace_swapping_field.py'>
 		<file_info nloc='47' complexity='7' token_count='260'></file_info>
 		<modified_lines>
 			<added_lines>8</added_lines>
 			<deleted_lines>8</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\fields\text_field.py' new_name='allennlp\data\fields\text_field.py'>
 		<file_info nloc='129' complexity='32' token_count='831'></file_info>
 		<modified_lines>
 			<added_lines>16</added_lines>
 			<deleted_lines>16</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\token_indexers\elmo_indexer.py' new_name='allennlp\data\token_indexers\elmo_indexer.py'>
 		<file_info nloc='128' complexity='17' token_count='624'></file_info>
 		<modified_lines>
 			<added_lines>7</added_lines>
 			<deleted_lines>7</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\token_indexers\pretrained_transformer_indexer.py' new_name='allennlp\data\token_indexers\pretrained_transformer_indexer.py'>
 		<file_info nloc='196' complexity='28' token_count='1022'></file_info>
 		<modified_lines>
 			<added_lines>9</added_lines>
 			<deleted_lines>9,10</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\token_indexers\pretrained_transformer_mismatched_indexer.py' new_name='allennlp\data\token_indexers\pretrained_transformer_mismatched_indexer.py'>
 		<file_info nloc='109' complexity='15' token_count='555'></file_info>
 		<modified_lines>
 			<added_lines>9</added_lines>
 			<deleted_lines>9</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\token_indexers\single_id_token_indexer.py' new_name='allennlp\data\token_indexers\single_id_token_indexer.py'>
 		<file_info nloc='96' complexity='9' token_count='431'></file_info>
 		<modified_lines>
 			<added_lines>7</added_lines>
 			<deleted_lines>7</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\token_indexers\spacy_indexer.py' new_name='allennlp\data\token_indexers\spacy_indexer.py'>
 		<file_info nloc='55' complexity='5' token_count='287'></file_info>
 		<modified_lines>
 			<added_lines>10</added_lines>
 			<deleted_lines>10</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\token_indexers\token_characters_indexer.py' new_name='allennlp\data\token_indexers\token_characters_indexer.py'>
 		<file_info nloc='123' complexity='10' token_count='687'></file_info>
 		<modified_lines>
 			<added_lines>11</added_lines>
 			<deleted_lines>11,12</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\token_indexers\token_indexer.py' new_name='allennlp\data\token_indexers\token_indexer.py'>
 		<file_info nloc='98' complexity='10' token_count='353'></file_info>
 		<modified_lines>
 			<added_lines>7</added_lines>
 			<deleted_lines>7</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\__init__.py' new_name='allennlp\data\tokenizers\__init__.py'>
 		<file_info nloc='12' complexity='0' token_count='81'></file_info>
 		<modified_lines>
 			<added_lines>6,7</added_lines>
 			<deleted_lines>6</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\character_tokenizer.py' new_name='allennlp\data\tokenizers\character_tokenizer.py'>
 		<file_info nloc='73' complexity='12' token_count='331'></file_info>
 		<modified_lines>
 			<added_lines>5</added_lines>
 			<deleted_lines>5</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\letters_digits_tokenizer.py' new_name='allennlp\data\tokenizers\letters_digits_tokenizer.py'>
 		<file_info nloc='17' complexity='2' token_count='95'></file_info>
 		<modified_lines>
 			<added_lines>6</added_lines>
 			<deleted_lines>6</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\pretrained_transformer_tokenizer.py' new_name='allennlp\data\tokenizers\pretrained_transformer_tokenizer.py'>
 		<file_info nloc='387' complexity='22' token_count='1957'></file_info>
 		<modified_lines>
 			<added_lines>9</added_lines>
 			<deleted_lines>9</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\spacy_tokenizer.py' new_name='allennlp\data\tokenizers\spacy_tokenizer.py'>
 		<file_info nloc='116' complexity='14' token_count='486'></file_info>
 		<modified_lines>
 			<added_lines>8</added_lines>
 			<deleted_lines>8</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='RENAME' old_name='allennlp\data\tokenizers\token.py' new_name='allennlp\data\tokenizers\token_class.py'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\tokenizer.py' new_name='allennlp\data\tokenizers\tokenizer.py'>
 		<file_info nloc='70' complexity='6' token_count='157'></file_info>
 		<modified_lines>
 			<added_lines>5</added_lines>
 			<deleted_lines>5</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\whitespace_tokenizer.py' new_name='allennlp\data\tokenizers\whitespace_tokenizer.py'>
 		<file_info nloc='20' complexity='2' token_count='81'></file_info>
 		<modified_lines>
 			<added_lines>5</added_lines>
 			<deleted_lines>5</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\data\dataset_readers\dataset_utils\span_utils_test.py' new_name='tests\data\dataset_readers\dataset_utils\span_utils_test.py'>
 		<file_info nloc='221' complexity='14' token_count='2476'></file_info>
 		<modified_lines>
 			<added_lines>6</added_lines>
 			<deleted_lines>6,7</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\data\tokenizers\letters_digits_tokenizer_test.py' new_name='tests\data\tokenizers\letters_digits_tokenizer_test.py'>
 		<file_info nloc='57' complexity='10' token_count='261'></file_info>
 		<modified_lines>
 			<added_lines>2</added_lines>
 			<deleted_lines>2,3</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\data\tokenizers\spacy_tokenizer_test.py' new_name='tests\data\tokenizers\spacy_tokenizer_test.py'>
 		<file_info nloc='106' complexity='21' token_count='557'></file_info>
 		<modified_lines>
 			<added_lines>4</added_lines>
 			<deleted_lines>4,5</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
