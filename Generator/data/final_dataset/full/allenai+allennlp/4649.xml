<bug_data>
<bug id='4649' author='ianupright' open_date='2020-09-18T01:26:02Z' closed_time='2020-11-11T00:44:06Z'>
 	<summary>Problem with PretrainedTransformerEmbedder and models such as T5</summary>
 	<description>
 In  PretrainedTransformerEmbedder and PretrainedTransformerTokenizer, there is the line:
 &lt;denchmark-code&gt;    self._num_added_end_tokens = len(tokenizer.single_sequence_end_tokens)
 &lt;/denchmark-code&gt;
 
 In the case of models such as T5, the _num_added_tokens results in zero.
 but then there is code like:
 &lt;denchmark-code&gt;    embeddings = embeddings[
         :, :, self._num_added_start_tokens : -(self._num_added_end_tokens), :
     ]  # truncate segment-level start/end tokens
 &lt;/denchmark-code&gt;
 
 which results in an empty tensor, because I think it should be a -1 to get the last element in the array, instead of -(self._num_added_end_tokens), which results in 0?
 Nevertheless, a T5 model doesn't seem to work with the PretrainedTransformerEmbedder/PretrainedTransformerTokenizer
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='f27ef38b3074ec89a964d9b2d8de110ed75e7cd1' author='Dirk Groeneveld' date='2020-11-10 16:44:05-08:00'>
 	<dmm_unit complexity='0.8333333333333334' interfacing='0.3333333333333333' size='0.8333333333333334'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>39</added_lines>
 			<deleted_lines>39</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\token_indexers\pretrained_transformer_indexer.py' new_name='allennlp\data\token_indexers\pretrained_transformer_indexer.py'>
 		<file_info nloc='197' complexity='28' token_count='1030'></file_info>
 		<method name='_postprocess_output' parameters='self,IndexedTokenList'>
 				<method_info nloc='26' complexity='6' token_count='136' nesting_level='1' start_line='150' end_line='187'></method_info>
 			<added_lines>167,168,169</added_lines>
 			<deleted_lines>167</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\pretrained_transformer_tokenizer.py' new_name='allennlp\data\tokenizers\pretrained_transformer_tokenizer.py'>
 		<file_info nloc='387' complexity='22' token_count='1957'></file_info>
 		<modified_lines>
 			<added_lines>121,122,123,124,125,126,185,186,187,188,189</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\modules\token_embedders\pretrained_transformer_embedder.py' new_name='allennlp\modules\token_embedders\pretrained_transformer_embedder.py'>
 		<file_info nloc='279' complexity='10' token_count='1211'></file_info>
 		<modified_lines>
 			<added_lines>325</added_lines>
 			<deleted_lines>325</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='setup.py' new_name='setup.py'>
 		<file_info nloc='59' complexity='0' token_count='187'></file_info>
 		<modified_lines>
 			<added_lines>67</added_lines>
 			<deleted_lines>67</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\data\dataset_readers\dataset_reader_test.py' new_name='tests\data\dataset_readers\dataset_reader_test.py'>
 		<file_info nloc='291' complexity='36' token_count='2246'></file_info>
 		<method name='mock_collate_fn' parameters='item'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='0' start_line='24' end_line='25'></method_info>
 			<added_lines>24,25</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_caching_with_lazy_reader_in_multi_process_loader' parameters='self'>
 				<method_info nloc='21' complexity='1' token_count='132' nesting_level='1' start_line='186' end_line='213'></method_info>
 			<added_lines>195,211</added_lines>
 			<deleted_lines>191,207</deleted_lines>
 		</method>
 		<method name='test_max_instances_with_multi_process_loader' parameters='self,num_workers'>
 				<method_info nloc='14' complexity='1' token_count='61' nesting_level='1' start_line='229' end_line='242'></method_info>
 			<added_lines>239</added_lines>
 			<deleted_lines>235</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>26,27</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\modules\token_embedders\pretrained_transformer_embedder_test.py' new_name='tests\modules\token_embedders\pretrained_transformer_embedder_test.py'>
 		<file_info nloc='258' complexity='9' token_count='2134'></file_info>
 		<method name='test_end_to_end' parameters='self,bool,bool,bool'>
 				<method_info nloc='5' complexity='1' token_count='16' nesting_level='1' start_line='39' end_line='43'></method_info>
 			<added_lines>40,41,42,43</added_lines>
 			<deleted_lines>39,43</deleted_lines>
 		</method>
 		<method name='test_end_to_end' parameters='self,bool,bool,bool'>
 				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='42' end_line='43'></method_info>
 			<added_lines>42,43</added_lines>
 			<deleted_lines>43</deleted_lines>
 		</method>
 		<method name='test_end_to_end_t5' parameters='self,bool,bool,bool'>
 				<method_info nloc='5' complexity='1' token_count='16' nesting_level='1' start_line='112' end_line='116'></method_info>
 			<added_lines>112,113,114,115,116</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>31,32,33,34,35,36,98,99,100,101,102,103,104,105,106,107,108,109,110,111,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171</added_lines>
 			<deleted_lines>31,32,33,34,35,36,37,38</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
