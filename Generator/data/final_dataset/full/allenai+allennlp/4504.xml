<bug_data>
<bug id='4504' author='bratao' open_date='2020-07-24T03:39:47Z' closed_time='2020-07-31T16:16:43Z'>
 	<summary>After #4470 the output is duplicated and Tqdm effect is lost</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Checklist&lt;/denchmark-h&gt;
 
 
  I have verified that the issue exists against the master branch of AllenNLP.
  I have read the relevant section in the contribution guide on reporting bugs.
  I have checked the issues list for similar or identical bug reports.
  I have checked the pull requests list for existing proposed fixes.
  I have checked the CHANGELOG and the commit log to find out if the bug was already fixed in the master branch.
  I have included in the "Description" section below a traceback from any exceptions related to this bug.
  I have included in the "Related issues or possible duplicates" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).
  I have included in the "Environment" section below the name of the operating system and Python version that I was using when I discovered this bug.
  I have included in the "Environment" section below the output of pip freeze.
  I have included in the "Steps to reproduce" section below a minimally reproducible example.
 
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 In PyCharm console in Windows and in the CI ( Ubuntu 18.04) the output is duplicated. The nice Tqdm bars is lost. The output is repeated like that:
 &lt;denchmark-code&gt;accuracy: 0.9193, accuracy3: 0.9219, precision-overall: 0.3077, recall-overall: 0.2727, f1-measure-overall: 0.2892, loss: 95.4325, reg_loss: 6.7843 ||:  33%|###3      | 1/3 [00:02&lt;00:04,  2.14s/it]
 accuracy: 0.9211, accuracy3: 0.9237, precision-overall: 0.3571, recall-overall: 0.3191, f1-measure-overall: 0.3371, loss: 37.8299, reg_loss: 7.8506 ||: 100%|##########| 3/3 [00:02&lt;00:00,  1.52s/it]
 accuracy: 0.9211, accuracy3: 0.9237, precision-overall: 0.3571, recall-overall: 0.3191, f1-measure-overall: 0.3371, loss: 37.8299, reg_loss: 7.8506 ||: 100%|##########| 3/3 [00:02&lt;00:00,  1.30it/s]
 
 &lt;/denchmark-code&gt;
 
 The &lt;denchmark-link:https://github.com/allenai/allennlp/pull/4470&gt;#4470&lt;/denchmark-link&gt;
  Pull by &lt;denchmark-link:https://github.com/epwalsh&gt;@epwalsh&lt;/denchmark-link&gt;
   checks for sys.stderr.isatty() and in my Pycharm console and in my Gitlab C.I the output is duplicated. Probably because the console is redirected internal. A option to keep the previous behavior would be great
 
 Python traceback:
 
 
 
 
 &lt;denchmark-h:h2&gt;Related issues or possible duplicates&lt;/denchmark-h&gt;
 
 Happened after the &lt;denchmark-link:https://github.com/allenai/allennlp/pull/4470&gt;#4470&lt;/denchmark-link&gt;
  Pull
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 OS: Windows 10 or Ubuntu 18.04
 Python version: 3.8
 
 Output of pip freeze:
 
 
 
 
 &lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;
 
 
 Example source:
 
 
 N/A - Any training code reproduces this error.
 
 
 	</description>
 	<comments>
 		<comment id='1' author='bratao' date='2020-07-24T15:24:32Z'>
 		Ugh, in hindsight, maybe getting rid of the --file-friendly-logging flag was a bad idea. But I guess the main issue is that sys.stderr.isatty() is too crude / not really what we want to check.
 Maybe there's a better way to check when we should automatically switch to FFL? Otherwise I'd vote for re-instating the FFL flag.
 		</comment>
 		<comment id='2' author='bratao' date='2020-07-24T15:38:09Z'>
 		&lt;denchmark-link:https://github.com/bratao&gt;@bratao&lt;/denchmark-link&gt;
  the double output is just the last progress bar, i.e. when it gets to 100%. I've noticed this elsewhere. I think I have a fix for that.
 		</comment>
 		<comment id='3' author='bratao' date='2020-07-24T16:57:35Z'>
 		Thanks &lt;denchmark-link:https://github.com/epwalsh&gt;@epwalsh&lt;/denchmark-link&gt;
  . Yeah, I think a flag would be the best solution. Because  is too fragile. Many console emulators report it wrongly.
 		</comment>
 	</comments>
 </bug>
<commit id='2401282352b244ee8faa7d7bd52e7c09c1a76a2a' author='Evan Pete Walsh' date='2020-07-31 09:16:42-07:00'>
 	<dmm_unit complexity='0.8717948717948718' interfacing='0.9230769230769231' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>19</added_lines>
 			<deleted_lines>13,20</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\commands\evaluate.py' new_name='allennlp\commands\evaluate.py'>
 		<file_info nloc='120' complexity='7' token_count='649'></file_info>
 		<method name='evaluate_from_args' parameters='Namespace'>
 				<method_info nloc='41' complexity='6' token_count='302' nesting_level='0' start_line='100' end_line='156'></method_info>
 			<added_lines>101,102</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='add_subparser' parameters='self,_SubParsersAction'>
 				<method_info nloc='58' complexity='1' token_count='247' nesting_level='1' start_line='28' end_line='97'></method_info>
 			<added_lines>88,89,90,91,92,93</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>15</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\commands\find_learning_rate.py' new_name='allennlp\commands\find_learning_rate.py'>
 		<file_info nloc='291' complexity='8' token_count='1317'></file_info>
 		<method name='find_learning_rate_from_args' parameters='Namespace'>
 				<method_info nloc='16' complexity='1' token_count='78' nesting_level='0' start_line='102' end_line='117'></method_info>
 			<added_lines>106</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='add_subparser' parameters='self,_SubParsersAction'>
 				<method_info nloc='62' complexity='1' token_count='234' nesting_level='1' start_line='34' end_line='99'></method_info>
 			<added_lines>90,91,92,93,94,95</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>19</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\commands\predict.py' new_name='allennlp\commands\predict.py'>
 		<file_info nloc='186' complexity='29' token_count='1089'></file_info>
 		<method name='add_subparser' parameters='self,_SubParsersAction'>
 				<method_info nloc='58' complexity='1' token_count='273' nesting_level='1' start_line='27' end_line='97'></method_info>
 			<added_lines>88,89,90,91,92,93,94</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_predict' parameters='Namespace'>
 				<method_info nloc='16' complexity='3' token_count='81' nesting_level='0' start_line='204' end_line='222'></method_info>
 			<added_lines>205,206</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>15</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\commands\train.py' new_name='allennlp\commands\train.py'>
 		<file_info nloc='580' complexity='13' token_count='1947'></file_info>
 		<method name='_train_worker' parameters='int,Params,str,None,bool,int,str,int,int,None,bool'>
 				<method_info nloc='12' complexity='1' token_count='73' nesting_level='0' start_line='308' end_line='319'></method_info>
 			<added_lines>319</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='add_subparser' parameters='self,_SubParsersAction'>
 				<method_info nloc='51' complexity='1' token_count='197' nesting_level='1' start_line='37' end_line='96'></method_info>
 			<added_lines>87,88,89,90,91,92</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='train_model_from_file' parameters='str,str,str,bool,bool,int,None,bool,bool'>
 				<method_info nloc='10' complexity='1' token_count='65' nesting_level='0' start_line='116' end_line='125'></method_info>
 			<added_lines>125</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='train_model' parameters='Params,str,bool,bool,int,None,bool,bool'>
 				<method_info nloc='9' complexity='1' token_count='54' nesting_level='0' start_line='175' end_line='183'></method_info>
 			<added_lines>183</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='train_model_from_args' parameters='Namespace'>
 				<method_info nloc='12' complexity='1' token_count='67' nesting_level='0' start_line='99' end_line='113'></method_info>
 			<added_lines>112</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>21,152,153,154,171,208,209,210,217,218,232,296,351,352,353,360,361,362</added_lines>
 			<deleted_lines>21,336</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\common\logging.py' new_name='allennlp\common\logging.py'>
 		<file_info nloc='93' complexity='15' token_count='614'></file_info>
 		<modified_lines>
 			<added_lines>47,48,49,50,51,52,53,54,55,56</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='allennlp\common\tqdm.py' new_name='allennlp\common\tqdm.py'>
 		<file_info nloc='62' complexity='15' token_count='330'></file_info>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='12' nesting_level='1' start_line='52' end_line='53'></method_info>
 			<added_lines>53</added_lines>
 			<deleted_lines>53</deleted_lines>
 		</method>
 		<method name='write' parameters='self,message'>
 				<method_info nloc='17' complexity='8' token_count='116' nesting_level='1' start_line='55' end_line='73'></method_info>
 			<added_lines>56,57,58,59,60,62,63,67,68,69</added_lines>
 			<deleted_lines>55,57,58,62,63</deleted_lines>
 		</method>
 		<method name='tqdm' parameters='args,kwargs'>
 				<method_info nloc='8' complexity='2' token_count='48' nesting_level='1' start_line='81' end_line='91'></method_info>
 			<added_lines>82,83,84,85,86,87,88,89</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>7,8,20,21,22</added_lines>
 			<deleted_lines>6,7,50,54,76,77,78</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
