<bug_data>
<bug id='454' author='Timoeller' open_date='2020-07-10T08:22:01Z' closed_time='2020-10-28T17:02:03Z'>
 	<summary>QA inference breaks on large dataset</summary>
 	<description>
 Describe the bug
 QA inference failing on very large dataset
 Error message
 Inferencing Samples: 0 Batches [00:00, ? Batches/s]Traceback (most recent call last):
 File "question_answering_inference.py", line 89, in 
 question_answering()
 File "question_answering_inference.py", line 34, in question_answering
 result = model.inference_from_file(file=filename, return_json=False, multiprocessing_chunksize=1)
 File "/home/ubuntu/pycharm/timosyncNEW/farm/infer.py", line 645, in inference_from_file
 multiprocessing_chunksize=multiprocessing_chunksize, streaming=streaming)
 File "/home/ubuntu/pycharm/timosyncNEW/farm/infer.py", line 345, in inference_from_file
 streaming=streaming,
 File "/home/ubuntu/pycharm/timosyncNEW/farm/infer.py", line 637, in inference_from_dicts
 multiprocessing_chunksize=multiprocessing_chunksize, streaming=streaming)
 File "/home/ubuntu/pycharm/timosyncNEW/farm/infer.py", line 418, in inference_from_dicts
 return list(predictions)
 File "/home/ubuntu/pycharm/timosyncNEW/farm/infer.py", line 489, in _inference_with_multiprocessing
 dataset, tensor_names, baskets
 File "/home/ubuntu/pycharm/timosyncNEW/farm/infer.py", line 576, in _get_predictions_and_aggregate
 for i, batch in enumerate(tqdm(data_loader, desc=f"Inferencing Samples", unit=" Batches", disable=self.disable_tqdm)):
 File "/home/ubuntu/miniconda3/envs/py37/lib/python3.7/site-packages/tqdm/_tqdm.py", line 1060, in iter
 for obj in iterable:
 File "/home/ubuntu/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in next
 data = self._next_data()
 File "/home/ubuntu/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 384, in _next_data
 index = self._next_index()  # may raise StopIteration
 File "/home/ubuntu/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 339, in _next_index
 return next(self._sampler_iter)  # may raise StopIteration
 File "/home/ubuntu/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/sampler.py", line 200, in iter
 for idx in self.sampler:
 File "/home/ubuntu/miniconda3/envs/py37/lib/python3.7/site-packages/torch/utils/data/sampler.py", line 62, in iter
 return iter(range(len(self.data_source)))
 TypeError: object of type 'NoneType' has no len()
 Additional context
 I suspect this has to do with one whole chunk in multiprocessing not being transformed correctly. We should remove empty datasets before sending them to _get_predictions_and_aggregate.
 	</description>
 	<comments>
 		<comment id='1' author='Timoeller' date='2020-09-11T10:34:05Z'>
 		This issue has been automatically marked as stale because it has not had recent activity. It will be closed in 14 days if no further activity occurs.
 		</comment>
 		<comment id='2' author='Timoeller' date='2020-09-24T15:49:25Z'>
 		I have the same problem running inference_from_file on Kubeflow with FARM 0.4.7, but I can't reproduce the same error on Colab
 predictions_json = model.inference_from_file(file=json_eval)
 File "/usr/local/lib/python3.7/site-packages/farm/infer.py", line 379, in inference_from_file
 streaming=streaming,
 File "/usr/local/lib/python3.7/site-packages/farm/infer.py", line 456, in inference_from_dicts
 return list(predictions)
 File "/usr/local/lib/python3.7/site-packages/farm/infer.py", line 531, in _inference_with_multiprocessing
 dataset, tensor_names, baskets
 File "/usr/local/lib/python3.7/site-packages/farm/infer.py", line 610, in _get_predictions_and_aggregate
 for i, batch in enumerate(tqdm(data_loader, desc=f"Inferencing Samples", unit=" Batches", disable=self.disable_tqdm)):
 File "/usr/local/lib/python3.7/site-packages/tqdm/std.py", line 1133, in iter
 for obj in iterable:
 File "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 363, in next
 data = self._next_data()
 File "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 402, in _next_data
 index = self._next_index()  # may raise StopIteration
 File "/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 357, in _next_index
 return next(self._sampler_iter)  # may raise StopIteration
 File "/usr/local/lib/python3.7/site-packages/torch/utils/data/sampler.py", line 208, in iter
 for idx in self.sampler:
 File "/usr/local/lib/python3.7/site-packages/torch/utils/data/sampler.py", line 62, in iter
 return iter(range(len(self.data_source)))
 TypeError: object of type 'NoneType' has no len()
 		</comment>
 		<comment id='3' author='Timoeller' date='2020-09-24T18:35:31Z'>
 		Strange that this error pops up, I thought this happens in very special cases only.
 How many cpu cores are on your Kubeflow instance?
 When working in colab, can you tell if many QA pairs are dismissed and not loaded for modelling?
 		</comment>
 		<comment id='4' author='Timoeller' date='2020-09-25T08:46:03Z'>
 		
 Strange that this error pops up, I thought this happens in very special cases only.
 How many cpu cores are on your Kubeflow instance?
 When working in colab, can you tell if many QA pairs are dismissed and not loaded for modelling?
 
 The Kubeflow node has 7 parallel workers.  It seems there are no qa pairs dismissed In  Colab.
 I realized that I can fix the problem in Kubeflow removing empty qas ( "qas": []) in squad dataset. But I can't figure out why this is not happening in Colab. Both experiments are running without GPU
 		</comment>
 		<comment id='5' author='Timoeller' date='2020-09-29T09:29:28Z'>
 		Thanks for the additional infos. The devil is surprisingly in the details of our framework : )
 When you have 7 workers the data is chunked into smaller parts than when you have only 2 (as in colab). I suspect one of these chunks contained only empty qas lists and therefor a whole chunk does not contain any QA pairs. Do you have a lot of empty lists? And how did you create the annotations?
 		</comment>
 	</comments>
 </bug>
<commit id='c21466c692d7d5d026cda9a6470d8713ca8ac558' author='Timo Moeller' date='2020-10-28 18:02:03+01:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='farm\infer.py' new_name='farm\infer.py'>
 		<file_info nloc='357' complexity='46' token_count='2268'></file_info>
 		<modified_lines>
 			<added_lines>508,509,510,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526</added_lines>
 			<deleted_lines>508,509,510,511,512,514,515,516,517,518,519,520,521,522</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
