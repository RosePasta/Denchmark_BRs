<bug_data>
<bug id='457' author='ftesser' open_date='2020-07-13T20:54:29Z' closed_time='2020-09-14T16:29:26Z'>
 	<summary>Data Handler dataset creation fails if features are not computed for some baskets</summary>
 	<description>
 Describe the bug
 method farm.data_handler.processor.Processor._create_dataset fails if features are not computed for some basket.
 The specific case of the error message below is the training of SQuAD question answering, the context of the issue is the following:
 
 the input SQuAD data contains some "errors" (some misalignment between answer text and selected text in the context);
 this misalignment cause the exclusion of the features computation the _featurize_samples method (see the try-except):  
 
 
 FARM/farm/data_handler/processor.py
 
 
          Line 295
       in
       b8b59c4
 
 
 
 
 
 
  def _featurize_samples(self): 
 
 
 
 
 
 finally in _create_dataset when the basket has no feature  features_flat.extend 
 
 
 FARM/farm/data_handler/processor.py
 
 
          Line 308
       in
       b8b59c4
 
 
 
 
 
 
  features_flat.extend(sample.features) 
 
 
 
 
 
 gives the error message reported below.
 
 Error message
 &lt;denchmark-code&gt;multiprocessing.pool.RemoteTraceback: 
 """
 Traceback (most recent call last):
   File "/usr/lib/python3.8/multiprocessing/pool.py", line 125, in worker
     result = (True, func(*args, **kwds))
   File "/home/fabio/src/git_repositories/FARM/farm/data_handler/data_silo.py", line 124, in _dataset_from_chunk
     dataset = processor.dataset_from_dicts(dicts=dicts, indices=indices)
   File "/home/fabio/src/git_repositories/FARM/farm/data_handler/processor.py", line 1144, in dataset_from_dicts
     dataset, tensor_names = self._create_dataset(keep_baskets=False)
   File "/home/fabio/src/git_repositories/FARM/farm/data_handler/processor.py", line 308, in _create_dataset
     features_flat.extend(sample.features)
 TypeError: 'NoneType' object is not iterable
 """
 
 The above exception was the direct cause of the following exception:
 
 Traceback (most recent call last):
   File "/home/fabio/src/git_repositories/DocumentFeaturesIdentificator/bin/farm_qa", line 10, in &lt;module&gt;
     farm_qa.main()
   File "/home/fabio/src/git_repositories/DocumentFeaturesIdentificator/bin/../documentfeaturesidentificator/farm_utils/farm_qa.py", line 211, in main
     options.func(options)
   File "/home/fabio/src/git_repositories/DocumentFeaturesIdentificator/bin/../documentfeaturesidentificator/farm_utils/farm_qa.py", line 107, in train_general_purpose
     train_mock(options, base_lm_model, out_model_basename, train_filename, dev_filename, test_filename)
   File "/home/fabio/src/git_repositories/DocumentFeaturesIdentificator/bin/../documentfeaturesidentificator/farm_utils/farm_qa.py", line 146, in train_mock
     question_answering(options_mock)
   File "/home/fabio/src/git_repositories/DocumentFeaturesIdentificator/bin/../documentfeaturesidentificator/farm_utils/question_answering.py", line 79, in question_answering
     data_silo = DataSilo(processor=processor, batch_size=batch_size, distributed=False)
   File "/home/fabio/src/git_repositories/FARM/farm/data_handler/data_silo.py", line 105, in __init__
     self._load_data()
   File "/home/fabio/src/git_repositories/FARM/farm/data_handler/data_silo.py", line 207, in _load_data
     self.data["train"], self.tensor_names = self._get_dataset(train_file)
   File "/home/fabio/src/git_repositories/FARM/farm/data_handler/data_silo.py", line 176, in _get_dataset
     for dataset, tensor_names in results:
   File "/usr/lib/python3.8/multiprocessing/pool.py", line 865, in next
     raise value
 TypeError: 'NoneType' object is not iterable
 &lt;/denchmark-code&gt;
 
 Expected behavior
 Logging the errors (perhaps with more information) and automatically exclude the basket with errors from the dataset.
 Additional context
 Add any other context about the problem here, like type of downstream task, part of  etc..
 To Reproduce
 Manually corrupt squad data test (e.g.: add a character in an answer in train-v2.0.json) and then run examples/question_answering.py
 System:
 
 OS: Linux
 GPU/CPU: CPU
 FARM version: 0.4.6
 
 	</description>
 	<comments>
 		<comment id='1' author='ftesser' date='2020-07-13T21:01:59Z'>
 		In order to automatically remove the baskets without features from the dataset I have two proposals: but I am not sure which one is better (or if they are OK with the design of the data pipeline):
 
 remove the baskets without features directly on _featurize_samples;
 remove the baskets without features on _create_dataset.
 
 If you think one of these two approaches  can be ok I can make a PR.
 		</comment>
 		<comment id='2' author='ftesser' date='2020-07-14T09:17:44Z'>
 		Thank you for pointing this out and working on this! Yes I think removing baskets without features is the right move here. I would just opt for 2. since preprocessing could fail at _init_samples_in_baskets() or _featurize_samples(). Removing baskets at _create_dataset() would be able to deal with both cases
 		</comment>
 		<comment id='3' author='ftesser' date='2020-07-14T09:39:17Z'>
 		Issue seems related to &lt;denchmark-link:https://github.com/deepset-ai/FARM/issues/454&gt;#454&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='4' author='ftesser' date='2020-07-14T13:39:23Z'>
 		Ah OK, if this is related to this other issue probably I have not the necessary global overview of the project to fix both (perhaps fixing &lt;denchmark-link:https://github.com/deepset-ai/FARM/issues/454&gt;#454&lt;/denchmark-link&gt;
  will result in the fix of this issue as well?)
 Anyway, if you think should be helpful, I can make a PR for my original solution 2.
 		</comment>
 		<comment id='5' author='ftesser' date='2020-07-14T13:53:53Z'>
 		Lets move forward step by step.
 I think the issue you raised is more localized and easier to tackle. So we should proceed with your PR first.
 Maybe it's even the other way around and &lt;denchmark-link:https://github.com/deepset-ai/FARM/issues/454&gt;#454&lt;/denchmark-link&gt;
  is solved by your PR ;)
 		</comment>
 		<comment id='6' author='ftesser' date='2020-07-14T14:35:01Z'>
 		Ok &lt;denchmark-link:https://github.com/Timoeller&gt;@Timoeller&lt;/denchmark-link&gt;
  :)
 &lt;denchmark-link:https://github.com/brandenchan&gt;@brandenchan&lt;/denchmark-link&gt;
  this last PR is removing baskets at _create_dataset().
 		</comment>
 		<comment id='7' author='ftesser' date='2020-07-14T16:14:13Z'>
 		Hi all, with this last PR the train of the "misaligned train squad file" ends successfully.
 However if I try to predict a "misaligned test squad file" with the model:
 model = QAInferencer.load(save_dir, task_type='question_answering')
 result = model.inference_from_file(file=test_filename)
 the misaligned basket are removed also in case (in the inference case this could be avoided as we just use the context and the questions but this is acceptable as I suppose the same squad data processor is used for train and inference):
 &lt;denchmark-code&gt;07/14/2020 17:48:14 - ERROR - farm.data_handler.processor -   Basket id: id_internal: 1999-0, id_external: 572881704b864d1900164a50
 07/14/2020 17:48:14 - ERROR - farm.data_handler.processor -   Error message: Answer using start/end indices is 'Quattro' while gold label text is 'quattro'
 07/14/2020 17:48:14 - WARNING - farm.data_handler.processor -   Removing the following baskets because of errors in computing features:
 07/14/2020 17:48:14 - WARNING - farm.data_handler.processor -   Basket id: id_internal: 1999-0, id_external: 572881704b864d1900164a50
 &lt;/denchmark-code&gt;
 
 but then I obtained the following error:
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File "&lt;stdin&gt;", line 1, in &lt;module&gt;
   File "/home/test/.local/lib/python3.7/site-packages/farm/infer.py", line 645, in inference_from_file
     multiprocessing_chunksize=multiprocessing_chunksize, streaming=streaming)
   File "/home/test/.local/lib/python3.7/site-packages/farm/infer.py", line 345, in inference_from_file
     streaming=streaming,
   File "/home/test/.local/lib/python3.7/site-packages/farm/infer.py", line 637, in inference_from_dicts
     multiprocessing_chunksize=multiprocessing_chunksize, streaming=streaming)
   File "/home/test/.local/lib/python3.7/site-packages/farm/infer.py", line 418, in inference_from_dicts
     return list(predictions)
   File "/home/test/.local/lib/python3.7/site-packages/farm/infer.py", line 489, in _inference_with_multiprocessing
     dataset, tensor_names, baskets
   File "/home/test/.local/lib/python3.7/site-packages/farm/infer.py", line 600, in _get_predictions_and_aggregate
     baskets=baskets)
   File "/home/test/.local/lib/python3.7/site-packages/farm/modeling/adaptive_model.py", line 104, in formatted_preds
     preds = head.formatted_preds(logits=logits_for_head, **kwargs)
   File "/home/test/.local/lib/python3.7/site-packages/farm/modeling/prediction_head.py", line 1218, in formatted_preds
     preds_d = self.aggregate_preds(preds, passage_start_t, ids, seq_2_start_t)
   File "/home/test/.local/lib/python3.7/site-packages/farm/modeling/prediction_head.py", line 1310, in aggregate_preds
     pred_d = self.pred_to_doc_idxs(preds[sample_idx], curr_passage_start_t)
   File "/home/test/.local/lib/python3.7/site-packages/farm/modeling/prediction_head.py", line 1447, in pred_to_doc_idxs
     assert start &gt;= 0
 AssertionError
 &lt;/denchmark-code&gt;
 
 Perhaps some misalignment between baskets (some baskets has been removed) in the aggregations phase?
 PS: if I try to predict a "correct squad file" with the same model I do not obtain the error.
 		</comment>
 		<comment id='8' author='ftesser' date='2020-07-20T09:31:14Z'>
 		Hmmm this is something to do with the calculation of document indexes. Is there any chance you can send us the input data that you're working with so that we can try to replicate this on our side?
 		</comment>
 		<comment id='9' author='ftesser' date='2020-07-22T11:07:03Z'>
 		Hello &lt;denchmark-link:https://github.com/brandenchan&gt;@brandenchan&lt;/denchmark-link&gt;
 , I have followed your suggestion for this last PR.
 I tested the new code with my "bugged data" and now, I do not obtain any errors in both train and inference.
 So probably there was some misalignment between baskets.
 Regarding the data, if you like to investigate more, I can send you some examples that failed before this PR.
 		</comment>
 		<comment id='10' author='ftesser' date='2020-07-22T12:30:26Z'>
 		Ok great! I think that &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/471&gt;#471&lt;/denchmark-link&gt;
  is certainly an improvement on the error handling front. I also think misalignment between baskets is a likely reason why you were getting the index error so I don't think its necessary to investigate that right now. Thanks for your work on this!
 		</comment>
 	</comments>
 </bug>
<commit id='65932d94628ae5e05fc119225da62e2dd0e79566' author='ftesser' date='2020-07-22 14:31:28+02:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='farm\data_handler\processor.py' new_name='farm\data_handler\processor.py'>
 		<file_info nloc='1209' complexity='198' token_count='6966'></file_info>
 		<method name='_check_sample_features' parameters='basket'>
 				<method_info nloc='6' complexity='3' token_count='26' nesting_level='1' start_line='305' end_line='319'></method_info>
 			<added_lines>305,306,307,308,309,310,311,312,313,314,315,316,317,318,319</added_lines>
 			<deleted_lines>307,308</deleted_lines>
 		</method>
 		<method name='_create_dataset' parameters='self,keep_baskets'>
 				<method_info nloc='18' complexity='7' token_count='113' nesting_level='1' start_line='322' end_line='343'></method_info>
 			<added_lines>324,326,327,328,329,330,331,332,333,334,335,336,337,338</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_featurize_samples' parameters='self'>
 				<method_info nloc='9' complexity='4' token_count='59' nesting_level='1' start_line='295' end_line='303'></method_info>
 			<added_lines>302</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>304,320,1732</added_lines>
 			<deleted_lines>1702</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
