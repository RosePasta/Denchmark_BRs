<bug_data>
<bug id='359' author='aloizel' open_date='2020-05-12T09:04:28Z' closed_time='2020-05-12T13:43:39Z'>
 	<summary>N_added_tokens on XLMRoBERTa</summary>
 	<description>
 Hi guys,
 I'm trying to use a further train XLMRoBERTa and I got the following error :
 &lt;denchmark-code&gt;AssertionError: Vocab size of tokenizer 250002 doesn't match with model 250005. If you added a custom vocabulary to the tokenizer, make sure to supply 'n_added_tokens' to LanguageModel.load() and BertStyleLM.load()
 &lt;/denchmark-code&gt;
 
 So I looked to &lt;denchmark-link:https://github.com/deepset-ai/FARM/blob/master/farm/modeling/language_model.py&gt;language_model.py&lt;/denchmark-link&gt;
  and you have
 &lt;denchmark-code&gt;if language_model_class == 'XLMRoberta':
 TODO: for some reason, the pretrained XLMRoberta has different vocab size in the tokenizer compared to the model this is a hack to resolve that
                 n_added_tokens = 3
 &lt;/denchmark-code&gt;
 
 On line 155, that is unecesary now.
 If you try to load a classic XLMRoBERTa on Farm it's not working anymore because of this line, a fix have been made from transformers. Can you update this please ? Thanks a lot
 	</description>
 	<comments>
 		<comment id='1' author='aloizel' date='2020-05-12T10:26:04Z'>
 		Thanks &lt;denchmark-link:https://github.com/aloizel&gt;@aloizel&lt;/denchmark-link&gt;
 . I can confirm that. Removing these lines will solve the issue (and the nasty hack we implemented in the first place).
 Do you want to create a PR? You were the one who spotted the issue + found the solution. If not I can gladly merge it into master myself.
 		</comment>
 		<comment id='2' author='aloizel' date='2020-05-12T10:27:57Z'>
 		No it's ok you can do it, thanks !
 		</comment>
 		<comment id='3' author='aloizel' date='2020-05-12T13:43:39Z'>
 		K - thanks, solved with &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/360&gt;#360&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='37591d198813c999afe3766be2fa281af26a25e5' author='Timo Moeller' date='2020-05-12 15:42:50+02:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='farm\modeling\language_model.py' new_name='farm\modeling\language_model.py'>
 		<file_info nloc='754' complexity='116' token_count='4706'></file_info>
 		<method name='load' parameters='cls,pretrained_model_name_or_path,n_added_tokens,language_model_class,kwargs'>
 				<method_info nloc='47' complexity='17' token_count='266' nesting_level='1' start_line='82' end_line='180'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>155,156,157,158</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
