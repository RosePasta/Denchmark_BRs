<bug_data>
<bug id='364' author='chunfuchen' open_date='2017-08-07T16:09:54Z' closed_time='2017-08-07T16:26:56Z'>
 	<summary>global_step number is incorrect after resume</summary>
 	<description>
 After resuming a model trained at global_step=475000, the next global_step jumps to 955000 directly. Here is the log:
 &lt;denchmark-code&gt;[0807 10:55:08 @steps.py:71] Start training with global_step=475000
 [0807 10:55:11 @param.py:144] learning_rate at epoch 96 will change to 0.00001000
 [0807 10:55:12 @concurrency.py:36] Starting EnqueueThread ...
 [0807 10:55:12 @input_source.py:418] Pre-filling staging area ...
 [0807 10:55:12 @base.py:200] Start Epoch 96 ...
 100%|############################################################################################|5000/5000[51:14&lt;00:00, 0.66it/s]
 [0807 11:46:26 @base.py:210] Epoch 96 (global_step 955000) finished, time:3074.13 sec.
 &lt;/denchmark-code&gt;
 
 It seems that the global_step is messed after resuming. (955000 = 475000 + 480000, in my training, 5000 iters = 1 epoch); but the learning rate scheduler still wokrs fine and the epoch num is correct.
 Do I need to maintain the global_step by myself?
 Here is the command of my execution:
 &lt;denchmark-code&gt;python3 examples/ResNet/imagenet-resnet.py -d 50 --gpu 0,1,2,3 --load $SOMEWHERE
 &lt;/denchmark-code&gt;
 
 Thanks.
 	</description>
 	<comments>
 		<comment id='1' author='chunfuchen' date='2018-04-03T02:57:43Z'>
 		Actually, I think the number is correct here. Since you are resuming the interrupted training process, not retraining a pretrained model, the epoch number should follow previous process. As in your case, the model is stopped at No. 475000 iteration (475000/5000 = 95 epoch)ï¼Œ the resumed epoch number should be 96. &lt;denchmark-link:https://github.com/chunfuchen&gt;@chunfuchen&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='5b681a95f141c7e2d37114a577d05cc73c33b7c9' author='Yuxin Wu' date='2017-08-07 09:26:35-07:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorpack\train\base.py' new_name='tensorpack\train\base.py'>
 		<file_info nloc='156' complexity='34' token_count='1016'></file_info>
 		<method name='global_step' parameters='self'>
 				<method_info nloc='7' complexity='2' token_count='45' nesting_level='1' start_line='176' end_line='185'></method_info>
 			<added_lines>182</added_lines>
 			<deleted_lines>182</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
