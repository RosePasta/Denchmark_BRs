<bug_data>
<bug id='3468' author='sr-frost' open_date='2020-08-02T19:42:49Z' closed_time='2020-08-06T03:46:40Z'>
 	<summary>mAP@75 returns -1.</summary>
 	<description>
 The tools/test.py was giving correct results a few days ago. Since I am working on google colab, I cloned the most recent  mmdetection repository today. But now the same code returns -1 for mAP@ 75.
 &lt;denchmark-code&gt;Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.571
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.842
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.382
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.876
 &lt;/denchmark-code&gt;
 
 The same code was returning 0.475 for mAP@75 a few days back.
 Reproduction
 
 What command or script did you run?
 
 &lt;denchmark-code&gt;python tools/test.py
 &lt;/denchmark-code&gt;
 
 
 Did you make any modifications on the code or config? Did you understand what you have modified?
 Ans: Yes, I modified the config to use custom coco format datastet with one class.
 
 I suspect recent changes to coco.py (&lt;denchmark-link:https://github.com/open-mmlab/mmdetection/pull/3407&gt;#3407&lt;/denchmark-link&gt;
 ) may have something to do with it. But since I am a new user of mmdetection, I wouldn't know for sure.
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='68d860d6f1a4a1fb687f2512038f2cbce7c6b08d' author='Jerry Jiarui XU' date='2020-08-06 11:46:39+08:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='mmdet\datasets\coco.py' new_name='mmdet\datasets\coco.py'>
 		<file_info nloc='399' complexity='56' token_count='2826'></file_info>
 		<method name='evaluate' parameters='self,results,metric,logger,jsonfile_prefix,classwise,proposal_nums,300,1000'>
 				<method_info nloc='9' complexity='1' token_count='41' nesting_level='1' start_line='364' end_line='372'></method_info>
 			<added_lines>371,372</added_lines>
 			<deleted_lines>371</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>388,389,390,391,392,393,394,395,396,397,398,409,410,411,412,413,414,452,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,480,481,482,483,484,485,486,487,488,528,529,530,531,532,533,534,535,536,537</added_lines>
 			<deleted_lines>387,388,389,440,444,445,446,447,448,449,489,490,491,492,493,494</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
