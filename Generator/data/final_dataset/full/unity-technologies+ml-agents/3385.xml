<bug_data>
<bug id='3385' author='Dastyn' open_date='2020-02-07T15:47:47Z' closed_time='2020-03-09T20:31:57Z'>
 	<summary>Pretraining: batch_size must fit number of experiences in demo file?</summary>
 	<description>
 Hi!
 It seems that when training with pretraining, the batch_size in the yaml config file must be equal to the number of experiences recorded in the corresponding .demo file.
 If not equal, then an exception is raised:
 &lt;denchmark-code&gt;Setting up 2 worker threads for Enlighten.
   Thread -&gt; id: 7fb9e2ffd700 -&gt; priority: 1 
   Thread -&gt; id: 7fb9e27fc700 -&gt; priority: 1 
 ##utp:{"type":"MemoryLeaks","version":2,"phase":"Immediate","time":1581079838307,"processId":26838,"allocatedMemory":4079,"memoryLabels":[{"Default":40},{"Permanent":40},{"NewDelete":112},{"Thread":128},{"Manager":1680},{"GfxDevice":64},{"Physics":32},{"Serialization":40},{"String":311},{"GI":296},{"VR":1992},{"Subsystems":-656}]}
 INFO:mlagents_envs:Environment shut down with return code 0.
 Traceback (most recent call last):
   File "/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1356, in _do_call
     return fn(*args)
   File "/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1341, in _run_fn
     options, feed_dict, fetch_list, target_list, run_metadata)
   File "/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1429, in _call_tf_sessionrun
     run_metadata)
 tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
   (0) Invalid argument: logits and labels must be broadcastable: logits_size=[579,2] labels_size=[573,2]
 	 [[{{node softmax_cross_entropy_with_logits_5}}]]
 	 [[Mean_3/_395]]
   (1) Invalid argument: logits and labels must be broadcastable: logits_size=[579,2] labels_size=[573,2]
 	 [[{{node softmax_cross_entropy_with_logits_5}}]]
 0 successful operations.
 0 derived errors ignored.
 
 During handling of the above exception, another exception occurred:
 
 Traceback (most recent call last):
   File "/home/unity/.local/bin/mlagents-learn", line 11, in &lt;module&gt;
     sys.exit(main())
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 478, in main
     run_training(0, run_seed, options, Queue())
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 316, in run_training
     tc.start_learning(env_manager)
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/trainer_controller.py", line 234, in start_learning
     n_steps = self.advance(env_manager)
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents_envs/timers.py", line 262, in wrapped
     return func(*args, **kwargs)
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/trainer_controller.py", line 321, in advance
     trainer.update_policy()
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/ppo/trainer.py", line 204, in update_policy
     buffer.make_mini_batch(l, l + batch_size), n_sequences
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents_envs/timers.py", line 262, in wrapped
     return func(*args, **kwargs)
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/ppo/policy.py", line 184, in update
     update_vals = self._execute_model(feed_dict, self.update_dict)
   File "/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/tf_policy.py", line 165, in _execute_model
     network_out = self.sess.run(list(out_dict.values()), feed_dict=feed_dict)
   File "/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 950, in run
     run_metadata_ptr)
   File "/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1173, in _run
     feed_dict_tensor, options, run_metadata)
   File "/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1350, in _do_run
     run_metadata)
   File "/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1370, in _do_call
     raise type(e)(node_def, op, message)
 tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
   (0) Invalid argument: logits and labels must be broadcastable: logits_size=[579,2] labels_size=[573,2]
 	 [[node softmax_cross_entropy_with_logits_5 (defined at /lib/python3.6/site-packages/mlagents/trainers/ppo/models.py:295) ]]
 	 [[Mean_3/_395]]
   (1) Invalid argument: logits and labels must be broadcastable: logits_size=[579,2] labels_size=[573,2]
 	 [[node softmax_cross_entropy_with_logits_5 (defined at /lib/python3.6/site-packages/mlagents/trainers/ppo/models.py:295) ]]
 0 successful operations.
 0 derived errors ignored.
 
 Original stack trace for 'softmax_cross_entropy_with_logits_5':
   File "/bin/mlagents-learn", line 11, in &lt;module&gt;
     sys.exit(main())
   File "/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 478, in main
     run_training(0, run_seed, options, Queue())
   File "/lib/python3.6/site-packages/mlagents/trainers/learn.py", line 316, in run_training
     tc.start_learning(env_manager)
   File "/lib/python3.6/site-packages/mlagents/trainers/trainer_controller.py", line 213, in start_learning
     env_manager.external_brains[name_behavior_id]
   File "/lib/python3.6/site-packages/mlagents/trainers/ppo/trainer.py", line 239, in create_policy
     self.load,
   File "/lib/python3.6/site-packages/mlagents/trainers/ppo/policy.py", line 48, in __init__
     brain, trainer_params, reward_signal_configs, is_training, load, seed
   File "/lib/python3.6/site-packages/mlagents/trainers/ppo/policy.py", line 98, in create_model
     trainer_params.get("vis_encode_type", "simple")
   File "/lib/python3.6/site-packages/mlagents/trainers/ppo/models.py", line 61, in __init__
     self.create_dc_actor_critic(h_size, num_layers, vis_encode_type)
   File "/lib/python3.6/site-packages/mlagents/trainers/ppo/models.py", line 295, in create_dc_actor_critic
     for i in range(len(self.act_size))
   File "/lib/python3.6/site-packages/mlagents/trainers/ppo/models.py", line 295, in &lt;listcomp&gt;
     for i in range(len(self.act_size))
   File "/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
     return func(*args, **kwargs)
   File "/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py", line 3151, in softmax_cross_entropy_with_logits_v2_helper
     precise_logits, labels, name=name)
   File "/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 10970, in softmax_cross_entropy_with_logits
     name=name)
   File "/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 788, in _apply_op_helper
     op_def=op_def)
   File "/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
     return func(*args, **kwargs)
   File "/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3616, in create_op
     op_def=op_def)
   File "/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2005, in __init__
     self._traceback = tf_stack.extract_stack()
 &lt;/denchmark-code&gt;
 
 Typically, the demo file actually contained 573 experiences, but in the yaml config file, the batch_size = 579.
 
 OS: Linux Ubuntu 18.4
 ML-Agents version: v0.13.1
 TensorFlow version: 1.14
 
 	</description>
 	<comments>
 		<comment id='1' author='Dastyn' date='2020-02-10T19:52:29Z'>
 		Hi &lt;denchmark-link:https://github.com/Dastyn&gt;@Dastyn&lt;/denchmark-link&gt;
 , thanks for reporting this, I've logged it with internal ID
 MLA-616.
 Basically there needs to be more than batch_size number of experiences in the demo file so that you could train at least one batch of demos. But the error message is pretty cryptic.
 		</comment>
 		<comment id='2' author='Dastyn' date='2020-03-09T20:31:57Z'>
 		This bug has been fixed in the latest master and will be released shortly. Closing this issue for now.
 		</comment>
 	</comments>
 </bug>
<commit id='2b8630f5cb76fc6dd0cfd07e5828be43c87eb43a' author='Ervin T' date='2020-03-09 12:57:55-07:00'>
 	<dmm_unit complexity='1.0' interfacing='0.9285714285714286' size='0.07142857142857142'></dmm_unit>
 	<modification change_type='MODIFY' old_name='com.unity.ml-agents\CHANGELOG.md' new_name='com.unity.ml-agents\CHANGELOG.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>46</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\components\reward_signals\__init__.py' new_name='ml-agents\mlagents\trainers\components\reward_signals\__init__.py'>
 		<file_info nloc='64' complexity='4' token_count='330'></file_info>
 		<method name='evaluate_batch' parameters='self,str'>
 				<method_info nloc='13' complexity='1' token_count='69' nesting_level='1' start_line='42' end_line='54'></method_info>
 			<added_lines>43</added_lines>
 			<deleted_lines>42</deleted_lines>
 		</method>
 		<method name='prepare_update' parameters='self,TFPolicy,str,int'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='56' end_line='57'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>57</deleted_lines>
 		</method>
 		<method name='prepare_update' parameters='self,TFPolicy,AgentBuffer,int'>
 				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='57' end_line='58'></method_info>
 			<added_lines>58</added_lines>
 			<deleted_lines>57</deleted_lines>
 		</method>
 		<method name='evaluate_batch' parameters='self,AgentBuffer'>
 				<method_info nloc='13' complexity='1' token_count='62' nesting_level='1' start_line='43' end_line='55'></method_info>
 			<added_lines>43</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>11</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\components\reward_signals\curiosity\signal.py' new_name='ml-agents\mlagents\trainers\components\reward_signals\curiosity\signal.py'>
 		<file_info nloc='94' complexity='8' token_count='648'></file_info>
 		<method name='evaluate_batch' parameters='self,str'>
 				<method_info nloc='25' complexity='5' token_count='241' nesting_level='1' start_line='44' end_line='69'></method_info>
 			<added_lines>45</added_lines>
 			<deleted_lines>44</deleted_lines>
 		</method>
 		<method name='prepare_update' parameters='self,TFPolicy,str,int'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='82' end_line='83'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>83</deleted_lines>
 		</method>
 		<method name='prepare_update' parameters='self,TFPolicy,AgentBuffer,int'>
 				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='83' end_line='84'></method_info>
 			<added_lines>84</added_lines>
 			<deleted_lines>83</deleted_lines>
 		</method>
 		<method name='evaluate_batch' parameters='self,AgentBuffer'>
 				<method_info nloc='25' complexity='5' token_count='234' nesting_level='1' start_line='45' end_line='70'></method_info>
 			<added_lines>45</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>8</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\components\reward_signals\extrinsic\signal.py' new_name='ml-agents\mlagents\trainers\components\reward_signals\extrinsic\signal.py'>
 		<file_info nloc='18' complexity='2' token_count='124'></file_info>
 		<method name='evaluate_batch' parameters='self,str'>
 				<method_info nloc='3' complexity='1' token_count='46' nesting_level='1' start_line='19' end_line='21'></method_info>
 			<added_lines>20</added_lines>
 			<deleted_lines>19</deleted_lines>
 		</method>
 		<method name='evaluate_batch' parameters='self,AgentBuffer'>
 				<method_info nloc='3' complexity='1' token_count='39' nesting_level='1' start_line='20' end_line='22'></method_info>
 			<added_lines>20</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>5</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\components\reward_signals\gail\signal.py' new_name='ml-agents\mlagents\trainers\components\reward_signals\gail\signal.py'>
 		<file_info nloc='113' complexity='9' token_count='823'></file_info>
 		<method name='evaluate_batch' parameters='self,str'>
 				<method_info nloc='25' complexity='6' token_count='239' nesting_level='1' start_line='64' end_line='90'></method_info>
 			<added_lines>65</added_lines>
 			<deleted_lines>64</deleted_lines>
 		</method>
 		<method name='prepare_update' parameters='self,TFPolicy,str,int'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='103' end_line='104'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>104</deleted_lines>
 		</method>
 		<method name='prepare_update' parameters='self,TFPolicy,AgentBuffer,int'>
 				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='104' end_line='105'></method_info>
 			<added_lines>105</added_lines>
 			<deleted_lines>104</deleted_lines>
 		</method>
 		<method name='evaluate_batch' parameters='self,AgentBuffer'>
 				<method_info nloc='25' complexity='6' token_count='232' nesting_level='1' start_line='65' end_line='91'></method_info>
 			<added_lines>65</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>9,113,115</added_lines>
 			<deleted_lines>112,113,114,115,116,117,118,119,121</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\sac\optimizer.py' new_name='ml-agents\mlagents\trainers\sac\optimizer.py'>
 		<file_info nloc='546' complexity='23' token_count='3412'></file_info>
 		<method name='add_reward_signal_dicts' parameters='self,Tensor,str,str,str,int'>
 				<method_info nloc='7' complexity='1' token_count='48' nesting_level='1' start_line='565' end_line='571'></method_info>
 			<added_lines>570</added_lines>
 			<deleted_lines>570</deleted_lines>
 		</method>
 		<method name='update_reward_signals' parameters='self,str,int'>
 				<method_info nloc='2' complexity='1' token_count='16' nesting_level='1' start_line='539' end_line='540'></method_info>
 			<added_lines>540</added_lines>
 			<deleted_lines>540</deleted_lines>
 		</method>
 		<method name='update_reward_signals' parameters='self,str,int'>
 				<method_info nloc='2' complexity='1' token_count='16' nesting_level='1' start_line='539' end_line='540'></method_info>
 			<added_lines>540</added_lines>
 			<deleted_lines>540</deleted_lines>
 		</method>
 		<method name='add_reward_signal_dicts' parameters='self,Tensor,str,str,str,int'>
 				<method_info nloc='7' complexity='1' token_count='48' nesting_level='1' start_line='565' end_line='571'></method_info>
 			<added_lines>570</added_lines>
 			<deleted_lines>570</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\tests\test_ppo.py' new_name='ml-agents\mlagents\trainers\tests\test_ppo.py'>
 		<file_info nloc='318' complexity='22' token_count='2018'></file_info>
 		<method name='test_ppo_optimizer_update_gail' parameters='gail_dummy_config,dummy_config'>
 				<method_info nloc='26' complexity='1' token_count='183' nesting_level='0' start_line='157' end_line='188'></method_info>
 			<added_lines>157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_ppo_optimizer_update_curiosity' parameters='curiosity_dummy_config,dummy_config,rnn,visual,discrete'>
 				<method_info nloc='2' complexity='1' token_count='11' nesting_level='0' start_line='133' end_line='134'></method_info>
 			<added_lines>133,134</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>17,18,19,20,129,130,131,132,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,189,190</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
