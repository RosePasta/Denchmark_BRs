<bug_data>
<bug id='14942' author='WenmuZhou' open_date='2017-11-28T14:01:08Z' closed_time='2018-02-20T18:40:09Z'>
 	<summary>tensorflow 1.4 is 8 times slower than tensorflow 1.3 when read data</summary>
 	<description>
 &lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;
 
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
 TensorFlow installed from (source or binary): python wheel
 TensorFlow version (use command below): 1.4 and 1.3
 Python version: 3.6.1
 Bazel version (if compiling from source):
 GCC/Compiler version (if compiling from source):
 CUDA/cuDNN version: None
 GPU model and memory: None
 Exact command to reproduce:
 
 when I run tensorflow1.4 script using estimator, the script is 8 times slower than tensorflow 1.3
 &lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;
 
 main script
 #!/usr/bin/env python
 __author__ = 'zj'
 
 import argparse
 import os
 import sys
 import numpy as np
 import time
 try:
     import better_exceptions
 except ImportError:
     pass
 import tensorflow as tf
 from src.model_ori import crnn_fn
 from src.data_handler import data_loader
 from src.config import Params, Alphabet
 from src.input_utils import input_fn
 
 
 def main(unused_argv):
     models_path = FLAGS.input_model_dir
     if not os.path.exists(models_path):
         assert FileNotFoundError
 
     models_list = [os.path.join(models_path, x[:-5]) for x in os.listdir(models_path) if x.endswith('.meta')]
 
     if not os.path.exists(FLAGS.output_model_dir):
         os.makedirs(FLAGS.output_model_dir)
 
     parameters = Params(eval_batch_size=128,
                         input_shape=(32, 304),
                         digits_only=False,
                         alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,
                         alphabet_decoding='same',
                         image_channels=1,
                         csv_delimiter=' ',
                         csv_files_eval=FLAGS.csv_files_eval,
                         output_model_dir=FLAGS.output_model_dir,
                         gpu=FLAGS.gpu
                         )
 
     model_params = {
         'Params': parameters,
     }
 
     os.environ['CUDA_VISIBLE_DEVICES'] = parameters.gpu
     config_sess = tf.ConfigProto()
     config_sess.gpu_options.per_process_gpu_memory_fraction = 0.6
 
     # Config estimator
     est_config = tf.estimator.RunConfig()
     est_config = est_config.replace(session_config=config_sess,
                                     save_summary_steps=100,
                                     model_dir=parameters.output_model_dir)
 
     estimator = tf.estimator.Estimator(model_fn=crnn_fn,
                                        params=model_params,
                                        config=est_config,
                                        model_dir=parameters.output_model_dir,
                                        )
     try:
         with open(FLAGS.output_file, encoding='utf-8', mode='w') as save_file:
             for model in models_list:
                 start = time.time()
                 
                 eval_results = estimator.evaluate(input_fn=data_loader(csv_filename=parameters.csv_files_eval,
                                                                        params=parameters,
                                                                        batch_size=parameters.eval_batch_size,
                                                                        num_epochs=1),
                                                   steps=3,
                                                   checkpoint_path=model)
                 print('time:',time.time() - start)
                 print('model: %s Evaluation results: %s' % (model, str(eval_results)))
                 save_file.write(model + ' ' + str(eval_results) + '\n')
 
     except KeyboardInterrupt:
         print('Interrupted')
 
 
 if __name__ == '__main__':
     parser = argparse.ArgumentParser()
     parser.add_argument('-fe', '--csv_files_eval', required=False, type=str, help='CSV filename for evaluation',
                         nargs='*', default=['E:/val1.csv'])
     parser.add_argument('-o', '--output_model_dir', required=False, type=str,
                         help='Directory for output', default='models_vgg_100K_no_eval')
     parser.add_argument('-m', '--input_model_dir', required=False, type=str,
                         help='Directory for output', default='model_test')
     parser.add_argument('-g', '--gpu', type=str, help="GPU 0,1 or '' ", default='0')
     parser.add_argument('-of', '--output_file', required=False, type=str, default='123.txt', help="the log output file")
 
     tf.logging.set_verbosity(tf.logging.DEBUG)
     FLAGS, unparsed = parser.parse_known_args()
     tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
 data_loader script
 #!/usr/bin/env python
 import tensorflow as tf
 import numpy as np
 from .config import Params, CONST
 from typing import Tuple
 
 
 def data_loader(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,
                 num_epochs: int = None, image_summaries: bool = False):
     def input_fn():
         # Choose case one csv file or list of csv files
         if not isinstance(csv_filename, list):
             filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,
                                                             name='filename_queue')
         elif isinstance(csv_filename, list):
             filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')
 
         # Skip lines that have already been processed
         reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)
         key, value = reader.read(filename_queue, name='file_reading_op')
 
         default_line = [['None'], ['None']]
         path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,
                                     name='csv_reading_op')
 
         image, img_width = image_reading(path, resized_size=params.input_shape, params=params,
                                          data_augmentation=data_augmentation, padding=True)
 
         to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}
         prepared_batch = tf.train.shuffle_batch(to_batch,
                                                 batch_size=batch_size,
                                                 min_after_dequeue=500,
                                                 num_threads=15, capacity=4000,
                                                 allow_smaller_final_batch=False,
                                                 name='prepared_batch_queue')
 
         if image_summaries:
             tf.summary.image('input/image', prepared_batch.get('images'), max_outputs=1)
         tf.summary.text('input/labels', prepared_batch.get('labels')[:10])
         tf.summary.text('input/widths', tf.as_string(prepared_batch.get('images_widths')))
 
         return prepared_batch, prepared_batch.get('labels')
 
     return input_fn
 
 
 def image_reading(path: str, params: Params, resized_size: Tuple[int, int] = None, data_augmentation: bool = False,
                   padding: bool = False) -&gt; Tuple[tf.Tensor, tf.Tensor]:
     # Read image
     image_content = tf.read_file(path, name='image_reader')
     image = tf.cond(tf.equal(tf.string_split([path], '.').values[1], tf.constant('jpg', dtype=tf.string)),
                     true_fn=lambda: tf.image.decode_jpeg(image_content, channels=params.image_channels,
                                                          try_recover_truncated=True),  # TODO channels = 3 ?
                     false_fn=lambda: tf.image.decode_png(image_content, channels=params.image_channels),
                     name='image_decoding')
 
     # Data augmentation
     if data_augmentation:
         image = augment_data(image)
 
     # Padding
     if padding:
         with tf.name_scope('padding'):
             image, img_width = padding_inputs_width(image, resized_size, increment=CONST.DIMENSION_REDUCTION_W_POOLING)
     # Resize
     else:
         image = tf.image.resize_images(image, size=resized_size)
         img_width = tf.shape(image)[1]
 
     with tf.control_dependencies([tf.assert_equal(image.shape[:2], resized_size)]):
         return image, img_width
 
 
 def random_rotation(img: tf.Tensor, max_rotation: float = 0.1, crop: bool = True) -&gt; tf.Tensor:  # from SeguinBe
     with tf.name_scope('RandomRotation'):
         rotation = tf.random_uniform([], -max_rotation, max_rotation)
         rotated_image = tf.contrib.image.rotate(img, rotation, interpolation='BILINEAR')
         if crop:
             rotation = tf.abs(rotation)
             original_shape = tf.shape(rotated_image)[:2]
             h, w = original_shape[0], original_shape[1]
             # see https://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders for formulae
             old_l, old_s = tf.cond(h &gt; w, lambda: [h, w], lambda: [w, h])
             old_l, old_s = tf.cast(old_l, tf.float32), tf.cast(old_s, tf.float32)
             new_l = (old_l * tf.cos(rotation) - old_s * tf.sin(rotation)) / tf.cos(2 * rotation)
             new_s = (old_s - tf.sin(rotation) * new_l) / tf.cos(rotation)
             new_h, new_w = tf.cond(h &gt; w, lambda: [new_l, new_s], lambda: [new_s, new_l])
             new_h, new_w = tf.cast(new_h, tf.int32), tf.cast(new_w, tf.int32)
             bb_begin = tf.cast(tf.ceil((h - new_h) / 2), tf.int32), tf.cast(tf.ceil((w - new_w) / 2), tf.int32)
             rotated_image_crop = rotated_image[bb_begin[0]:h - bb_begin[0], bb_begin[1]:w - bb_begin[1], :]
 
             # If crop removes the entire image, keep the original image
             rotated_image = tf.cond(tf.equal(tf.size(rotated_image_crop), 0),
                                     true_fn=lambda: img,
                                     false_fn=lambda: rotated_image_crop)
 
         return rotated_image
 
 
 def random_padding(image: tf.Tensor, max_pad_w: int = 5, max_pad_h: int = 10) -&gt; tf.Tensor:
     w_pad = list(np.random.randint(0, max_pad_w, size=[2]))
     h_pad = list(np.random.randint(0, max_pad_h, size=[2]))
     paddings = [h_pad, w_pad, [0, 0]]
 
     return tf.pad(image, paddings, mode='REFLECT', name='random_padding')
 
 
 def augment_data(image: tf.Tensor) -&gt; tf.Tensor:
     with tf.name_scope('DataAugmentation'):
         # Random padding
         image = random_padding(image)
 
         image = tf.image.random_brightness(image, max_delta=0.1)
         image = tf.image.random_contrast(image, 0.5, 1.5)
         image = random_rotation(image, 0.05, crop=True)
 
         if image.shape[-1] &gt;= 3:
             image = tf.image.random_hue(image, 0.2)
             image = tf.image.random_saturation(image, 0.5, 1.5)
 
         return image
 
 
 def padding_inputs_width(image: tf.Tensor, target_shape: Tuple[int, int], increment: int) -&gt; Tuple[
     tf.Tensor, tf.Tensor]:
     target_ratio = target_shape[1] / target_shape[0]
     # Compute ratio to keep the same ratio in new image and get the size of padding
     # necessary to have the final desired shape
     shape = tf.shape(image)
     # 计算宽高比
     ratio = tf.divide(shape[1], shape[0], name='ratio')
 
     new_h = target_shape[0]
     new_w = tf.cast(tf.round((ratio * new_h) / increment) * increment, tf.int32)
     f1 = lambda: (new_w, ratio)
     f2 = lambda: (new_h, tf.constant(1.0, dtype=tf.float64))
     new_w, ratio = tf.case({tf.greater(new_w, 0): f1,
                             tf.less_equal(new_w, 0): f2},
                            default=f1, exclusive=True)
     target_w = target_shape[1]
 
     # Definitions for cases
     def pad_fn():
         with tf.name_scope('mirror_padding'):
             pad = tf.subtract(target_w, new_w)
 
             img_resized = tf.image.resize_images(image, [new_h, new_w])
 
             # Padding to have the desired width
             paddings = [[0, 0], [0, pad], [0, 0]]
             pad_image = tf.pad(img_resized, paddings, mode='SYMMETRIC', name=None)
 
             # Set manually the shape
             pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])
 
             return pad_image, (new_h, new_w)
 
     def replicate_fn():
         with tf.name_scope('replication_padding'):
             img_resized = tf.image.resize_images(image, [new_h, new_w])
 
             # If one symmetry is not enough to have a full width
             # Count number of replications needed
             n_replication = tf.cast(tf.ceil(target_shape[1] / new_w), tf.int32)
             img_replicated = tf.tile(img_resized, tf.stack([1, n_replication, 1]))
             pad_image = tf.image.crop_to_bounding_box(image=img_replicated, offset_height=0, offset_width=0,
                                                       target_height=target_shape[0], target_width=target_shape[1])
 
             # Set manually the shape
             pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])
 
             return pad_image, (new_h, new_w)
 
     def simple_resize():
         with tf.name_scope('simple_resize'):
             img_resized = tf.image.resize_images(image, target_shape)
 
             img_resized.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])
 
             return img_resized, target_shape
 
     # 3 cases
     pad_image, (new_h, new_w) = tf.case(
         {  # case 1 : new_w &gt;= target_w
             tf.logical_and(tf.greater_equal(ratio, target_ratio),
                            tf.greater_equal(new_w, target_w)): simple_resize,
             # case 2 : new_w &gt;= target_w/2 &amp; new_w &lt; target_w &amp; ratio &lt; target_ratio
             tf.logical_and(tf.less(ratio, target_ratio),
                            tf.logical_and(tf.greater_equal(new_w, tf.cast(tf.divide(target_w, 2), tf.int32)),
                                           tf.less(new_w, target_w))): pad_fn,
             # case 3 : new_w &lt; target_w/2 &amp; new_w &lt; target_w &amp; ratio &lt; target_ratio
             tf.logical_and(tf.less(ratio, target_ratio),
                            tf.logical_and(tf.less(new_w, target_w),
                                           tf.less(new_w, tf.cast(tf.divide(target_w, 2), tf.int32)))): replicate_fn
         },
         default=simple_resize, exclusive=True)
 
     return pad_image, new_w  # new_w = image width used for computing sequence lengths
 
 
 def preprocess_image_for_prediction(fixed_height: int = 32, min_width: int = 8):
     """
     Input function to use when exporting the model for making predictions (see estimator.export_savedmodel)
     :param fixed_height: height of the input image after resizing
     :param min_width: minimum width of image after resizing
     :return:
     """
 
     def serving_input_fn():
         # define placeholder for input image
         image = tf.placeholder(dtype=tf.float32, shape=[None, None, 1])
 
         shape = tf.shape(image)
         # Assert shape is h x w x c with c = 1
 
         ratio = tf.divide(shape[1], shape[0])
         increment = CONST.DIMENSION_REDUCTION_W_POOLING
         new_width = tf.cast(tf.round((ratio * fixed_height) / increment) * increment, tf.int32)
 
         resized_image = tf.cond(new_width &lt; tf.constant(min_width, dtype=tf.int32),
                                 true_fn=lambda: tf.image.resize_images(image, size=(fixed_height, min_width)),
                                 false_fn=lambda: tf.image.resize_images(image, size=(fixed_height, new_width))
                                 )
 
         # Features to serve
         features = {'images': resized_image[None],  # cast to 1 x h x w x c
                     'images_widths': new_width[None]  # cast to tensor
                     }
 
         # Inputs received
         receiver_inputs = {'images': image}
 
         return tf.estimator.export.ServingInputReceiver(features, receiver_inputs)
 
     return serving_input_fn
 log
 tensorflow1.4
 INFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {
   per_process_gpu_memory_fraction: 0.6
 }
 , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x000002BAAA7A6780&gt;, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
 INFO:tensorflow:Starting evaluation at 2017-11-28-12:21:42
 INFO:tensorflow:Restoring parameters from model_test\model.ckpt-54692
 2017-11-28 20:22:04.720980: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.236689657]
 INFO:tensorflow:Evaluation [1/3]
 2017-11-28 20:28:32.360331: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.238805175]
 INFO:tensorflow:Evaluation [2/3]
 2017-11-28 20:35:41.020994: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.237995088]
 INFO:tensorflow:Evaluation [3/3]
 INFO:tensorflow:Finished evaluation at 2017-11-28-12:43:21
 INFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.0108218, eval/accuracy = 0.929688, global_step = 54692, loss = 0.23783
 time:1306.1133954524994
 model: model_test\model.ckpt-54692 Evaluation results: {'eval/CER': 0.01082176, 'eval/accuracy': 0.9296875, 'loss': 0.23782997, 'global_step': 54692}
 tensorflow 1.3
 INFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': gpu_options {
   per_process_gpu_memory_fraction: 0.6
 }
 , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}
 INFO:tensorflow:Starting evaluation at 2017-11-28-12:49:50
 INFO:tensorflow:Restoring parameters from model_test\model.ckpt-54692
 2017-11-28 20:50:12.841210: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.17519826]
 INFO:tensorflow:Evaluation [1/3]
 2017-11-28 20:51:03.366275: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.2987892]
 INFO:tensorflow:Evaluation [2/3]
 2017-11-28 20:51:49.843030: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.20660429]
 INFO:tensorflow:Evaluation [3/3]
 INFO:tensorflow:Finished evaluation at 2017-11-28-12:52:19
 INFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.01188, eval/accuracy = 0.924479, global_step = 54692, loss = 0.226864
 time:157.26274514198303
 model: model_test\model.ckpt-54692 Evaluation results: {'eval/CER': 0.011879961, 'eval/accuracy': 0.92447919, 'loss': 0.22686392, 'global_step': 54692}
 	</description>
 	<comments>
 		<comment id='1' author='WenmuZhou' date='2017-11-28T18:19:56Z'>
 		&lt;denchmark-link:https://github.com/ispirmustafa&gt;@ispirmustafa&lt;/denchmark-link&gt;
 , any ideas what might be causing this?
 		</comment>
 		<comment id='2' author='WenmuZhou' date='2017-11-28T18:58:52Z'>
 		I'm not aware of any related change within estimator.
 		</comment>
 		<comment id='3' author='WenmuZhou' date='2017-11-28T19:00:27Z'>
 		May be something related to data loader part? &lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
  do you mind to test time difference of input_fn between 1.3 and 1.4?
 		</comment>
 		<comment id='4' author='WenmuZhou' date='2017-11-29T01:54:25Z'>
 		here is the time of input_fn between 1.3 and 1.4
 the script is
 # -*- coding: utf-8 -*-
 # @Time    : 2017/11/29 8:43
 # @Author  : zhoujun
 from src.data_handler import data_loader, input_fn
 from src.config import Params, Alphabet
 import tensorflow as tf
 import time
 
 if __name__ == '__main__':
     parameters = Params(eval_batch_size=128,
                         input_shape=(32, 304),
                         digits_only=False,
                         alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,
                         alphabet_decoding='same',
                         image_channels=1,
                         csv_delimiter=' ',
                         )
 
     featureBatch, labelBatch = input_fn(csv_filename='E:/val1.csv', params=parameters,
                                         batch_size=parameters.eval_batch_size,
                                         num_epochs=1)
 
     global_init = tf.global_variables_initializer()
     loacl_init = tf.local_variables_initializer()
     with tf.Session() as sess:
         sess.run(global_init)
         sess.run(loacl_init)
         coord = tf.train.Coordinator()
         threads = tf.train.start_queue_runners(sess=sess, coord=coord)
 
         start = time.time()
         example, label = sess.run([featureBatch, labelBatch])
         print('time: ',time.time()-start)
         print(len(label))
         coord.request_stop()
         coord.join(threads)
 input_fn is extracted from data_loader function
 def input_fn(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,
                 num_epochs: int = None):
     # Choose case one csv file or list of csv files
     if not isinstance(csv_filename, list):
         filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,
                                                         name='filename_queue')
     elif isinstance(csv_filename, list):
         filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')
 
     # Skip lines that have already been processed
     reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)
     key, value = reader.read(filename_queue, name='file_reading_op')
 
     default_line = [['None'], ['None']]
     path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,
                                 name='csv_reading_op')
 
     image, img_width = image_reading(path, resized_size=params.input_shape, params=params,
                                      data_augmentation=data_augmentation, padding=True)
 
     to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}
     prepared_batch = tf.train.shuffle_batch(to_batch,
                                             batch_size=batch_size,
                                             min_after_dequeue=500,
                                             num_threads=15, capacity=4000,
                                             allow_smaller_final_batch=False,
                                             name='prepared_batch_queue')
     return prepared_batch, prepared_batch.get('labels')
 tf 1.3 log
 time:  0.4531559944152832
 128
 tf 1.4 log
 time:  0.5000338554382324
 128
 		</comment>
 		<comment id='5' author='WenmuZhou' date='2017-11-29T08:30:26Z'>
 		There seems to be a tiny difference in the accuracies, are the runs exactly the same?
 The config for 1.4 seems to include a clusterspec, are you running the 1.4 run locally as well?
 Also are either or both of them using a GPU?
 		</comment>
 		<comment id='6' author='WenmuZhou' date='2017-11-30T01:41:53Z'>
 		both of them ara run using 1080TI，and everything is the same except for the tensorflow version
 		</comment>
 		<comment id='7' author='WenmuZhou' date='2017-11-30T01:42:39Z'>
 		the tf1.4 log of input_fn is error and I have fixed it
 		</comment>
 		<comment id='8' author='WenmuZhou' date='2017-11-30T17:52:14Z'>
 		&lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
  thanks for helping us to investigate this issue.
 To understand the issue better could you please give us following information:
 print est_config.cluster_spec
 print os.environ['TF_CONFIG']
 		</comment>
 		<comment id='9' author='WenmuZhou' date='2017-11-30T18:13:43Z'>
 		Another useful information can be get by using ProfilerHook as follows:
 &lt;denchmark-code&gt;from tensorflow.contrib.hooks.python.training import profiler_hook
 import os
 os.mkdir('/tmp/estimator_debug')
 estimator.evaluate(input_fn=test_input_fn, hooks=[profiler_hook.ProfilerHook(save_steps=1, output_dir='/tmp/estimator_debug')])
 &lt;/denchmark-code&gt;
 
 You can check the output by using catapult as follows:
 &lt;denchmark-code&gt;git clone https://github.com/catapult-project/catapult
 catapult/tracing/bin/trace2html /tmp/estimator_debug/FILENAME.json --output=/tmp/estimator_debug/FILENAME.html
 &lt;/denchmark-code&gt;
 
 Could you please let us know the differences between 1.3 and 1.4 in profiler output?
 		</comment>
 		<comment id='10' author='WenmuZhou' date='2017-12-02T02:34:00Z'>
 		the est_config.cluster_spec is None and there are a error when run
 print os.environ['TF_CONFIG']
 log is
 1.3.0
 Traceback (most recent call last):
   File "Z:/zhoujun/tf-crnn/test_model.py", line 110, in &lt;module&gt;
     tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
   File "C:\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py", line 48, in run
     _sys.exit(main(_sys.argv[:1] + flags_passthrough))
   File "Z:/zhoujun/tf-crnn/test_model.py", line 57, in main
     print('os.environ[\'TF_CONFIG\']',os.environ['TF_CONFIG'])
   File "C:\Anaconda3\lib\os.py", line 669, in __getitem__
     raise KeyError(key) from None
 KeyError: 'TF_CONFIG'
 est_config.cluster_spec None
 and when I import profile_hook, there are a error
 &gt;&gt;&gt; from tensorflow.contrib.hooks.python.training import profiler_hook
 Traceback (most recent call last):
   File "&lt;stdin&gt;", line 1, in &lt;module&gt;
   File "C:\Anaconda3\lib\site-packages\tensorflow\contrib\hooks\__init__.py", line 25, in &lt;module&gt;
     from tensorflow.contrib.hooks.python.training import *
 ModuleNotFoundError: No module named 'tensorflow.contrib.hooks.python'
 		</comment>
 		<comment id='11' author='WenmuZhou' date='2017-12-02T09:21:10Z'>
 		I've seen a similar issue:
 My code snippet to test on tf1.3:
 &lt;denchmark-code&gt;def parser(record, split_name, imagenet_mean):
     assert (split_name == 'train' or split_name == 'train_dev')
     keys_to_features = {
         'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),
         'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),
         'image/class/class_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),
         'image/product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),
     }
     parsed = tf.parse_single_example(record, keys_to_features)
     image = tf.image.decode_jpeg(parsed['image/encoded'])
     image.set_shape([180, 180, 3])
     image = tf.cast(image, tf.float32)
     image = tf.subtract(image, imagenet_mean)
     image = tf.expand_dims(image, axis=0)
     image = tf.image.resize_bicubic(image, [224, 224])
     image = tf.squeeze(image)
     if split_name == 'train':
         image = tf.image.random_flip_left_right(image)
     label = parsed['image/class/class_id']
     product_id = parsed['image/product_id']
     return image, label, product_id
 
 
 def get_dataset(file_patterns, split_name):
     assert (split_name == 'train' or split_name == 'train_dev')
     imagenet_mean = tf.constant([_R_MEAN, _G_MEAN, _B_MEAN])
     d = tf.contrib.data.Dataset.list_files(file_patterns)
     # We choose NUM_SHARDS as buffer_size to ensure that in each epoch we are seeing all the shard TFRecord files
     # with no duplicate or missing ones.
     d = d.shuffle(buffer_size=NUM_SHARDS)
     # cycle_length is set as NUM_SHARDS so in each cycle we will be able to see images from different shards.
     d = d.interleave(lambda x: tf.contrib.data.TFRecordDataset(filenames=x), cycle_length=NUM_SHARDS, block_length=1)
     d = d.map(lambda x: parser(x, split_name, imagenet_mean), num_threads=8192, output_buffer_size=BATCH_SIZE * 20)
     d = d.batch(BATCH_SIZE)
     return d
 
 
 def main():
     config = tf.ConfigProto()
     config.gpu_options.visible_device_list = '0'
     with tf.Graph().as_default() as g:
         with tf.device('/cpu:0'):
             train_set = get_dataset(TRAIN_ON_RAM, 'train')
             train_iter = train_set.make_one_shot_iterator()
             images, labels, product_ids = train_iter.get_next()
     with tf.Session(graph=g, config=config) as sess:
         for _ in tqdm(range(1000)):
             sess.run(images)
 &lt;/denchmark-code&gt;
 
 For tf1.4, I simply changed tf.contrib.data to tf.data, num_threads into num_parallel_calls and output_buffer_size to prefetch. Then I've seen a very significant performance drop:
 On TF 1.3 I get:
 &lt;denchmark-code&gt;100%|███████████████████████████████████████| 1000/1000 [03:14&lt;00:00,  5.14it/s]
 &lt;/denchmark-code&gt;
 
 On TF 1.4 I get:
 &lt;denchmark-code&gt;100%|███████████████████████████████████████| 1000/1000 [05:28&lt;00:00,  3.05it/s]
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='12' author='WenmuZhou' date='2017-12-02T15:06:46Z'>
 		I did another test (using a trained models to predict the image) and also proved that tensorflow1.4 was slower than 1.3 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/15057&gt;#15057&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='13' author='WenmuZhou' date='2017-12-02T20:45:17Z'>
 		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
  may have better ideas about the differences in tf.data performance.
 		</comment>
 		<comment id='14' author='WenmuZhou' date='2017-12-02T21:05:08Z'>
 		It’s not clear what caused the change in performance but num_threads=8192 (or num_parallel_calls=8192) is very unlikely to be optimal, because of the potential for contention from so many parallel work items. Try setting this to a much smaller value (e.g. the number of CPU cores in your test machine) to see if this speeds things up.
 		</comment>
 		<comment id='15' author='WenmuZhou' date='2017-12-03T21:28:44Z'>
 		Thanks &lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 . That code was a  benchmark script I was using when trying to tune the best parameter setting for input. Initially I was using something like 64 which is the number of cores, but I've increased the number of threads all the way from 64, 128, 256 to 8192 and the performance kept improving so that's why I was using 8192 in that script. I can change it back to smaller values and show more results.
 		</comment>
 		<comment id='16' author='WenmuZhou' date='2017-12-04T17:09:06Z'>
 		Thank you &lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
  for adding a test with Predict. That test doesn't use Dataset or Estimator. &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
  who can help us here?
 		</comment>
 		<comment id='17' author='WenmuZhou' date='2017-12-04T21:11:28Z'>
 		&lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
  for your  experiment:
 
 
 Did you do the 64, 128, ..., 8192 scaling using TF 1.3 or TF 1.4? If TF 1.3, could you verify that you see a similar effect for TF 1.4?
 
 
 Could you also add timing information to the parser method to see how much time is spent in this method in TF 1.3 and TF 1.4? I am not aware of any tf.data changes between TF 1.3 and TF 1.4 to the transformations you are using that should result in a performance drop, so I am trying to see if perhaps the slowdown is due to a change in the image parsing logic.
 
 
 		</comment>
 		<comment id='18' author='WenmuZhou' date='2017-12-05T00:22:35Z'>
 		&lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
  re:ProfilerHook, it is available as  in TF1.4. But for 1.3 sorry to here it's not working. Could you please run it only on 1.4? It may give us some info.
 		</comment>
 		<comment id='19' author='WenmuZhou' date='2017-12-05T22:13:59Z'>
 		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
  - I think that's actually my experiment but I'm happy to add more data. :)
 		</comment>
 		<comment id='20' author='WenmuZhou' date='2017-12-06T04:04:54Z'>
 		&lt;denchmark-link:https://github.com/ispirmustafa&gt;@ispirmustafa&lt;/denchmark-link&gt;
   for tf 1.4 the ouput of
 print(est_config.cluster_spec)
 is
 &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x00000226E91666A0&gt;
 but, the output of tf 1.3 is None
 and my python verison is python3 ,can not run
 catapult/tracing/bin/trace2html /tmp/estimator_debug/FILENAME.json --output=/tmp/estimator_debug/FILENAME.html
 		</comment>
 		<comment id='21' author='WenmuZhou' date='2017-12-06T17:02:39Z'>
 		&lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
  please do print(est_config.cluster_spec.as_dict()) to get the content.
 re: catapult, did you clone it? I mean following: git clone https://github.com/catapult-project/catapult
 		</comment>
 		<comment id='22' author='WenmuZhou' date='2017-12-07T01:53:15Z'>
 		&lt;denchmark-link:https://github.com/ispirmustafa&gt;@ispirmustafa&lt;/denchmark-link&gt;
  the output is a None dict
 {}
 I have clone the catapult
 		</comment>
 		<comment id='23' author='WenmuZhou' date='2017-12-22T07:34:19Z'>
 		It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
 		</comment>
 		<comment id='24' author='WenmuZhou' date='2018-01-05T19:07:02Z'>
 		Nagging Awaiting TensorFlower: It has been 14 days with no activityand the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
 		</comment>
 		<comment id='25' author='WenmuZhou' date='2018-01-06T12:56:03Z'>
 		the code I used is in this &lt;denchmark-link:https://github.com/solivr/tf-crnn&gt;https://github.com/solivr/tf-crnn&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='26' author='WenmuZhou' date='2018-01-06T17:43:14Z'>
 		Thanks &lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://github.com/ispirmustafa&gt;@ispirmustafa&lt;/denchmark-link&gt;
  could you please look to reproduce this, and then pull in whoever else is needed.
 		</comment>
 		<comment id='27' author='WenmuZhou' date='2018-01-08T17:58:33Z'>
 		Thanks &lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
 
 Could you also point us an example data set in format expected by your program?
 		</comment>
 		<comment id='28' author='WenmuZhou' date='2018-01-08T20:48:27Z'>
 		I have a similar issue with v1.4.x. However, it goes away with v1.5rc0.
 		</comment>
 		<comment id='29' author='WenmuZhou' date='2018-01-12T05:24:54Z'>
 		&lt;denchmark-link:https://github.com/songgc&gt;@songgc&lt;/denchmark-link&gt;
  v1.5rc0 is slower than 1.3 in my test
 		</comment>
 		<comment id='30' author='WenmuZhou' date='2018-01-12T16:51:26Z'>
 		Hi &lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
  ,
 It would be great to have an example data set in format expected by your program and creates this issue. Would you mind to point us to it?
 		</comment>
 		<comment id='31' author='WenmuZhou' date='2018-01-20T01:35:42Z'>
 		I have update the code to generate dataset
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1648413/hlp.zip&gt;hlp.zip&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='32' author='WenmuZhou' date='2018-01-23T22:59:51Z'>
 		A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.
 		</comment>
 		<comment id='33' author='WenmuZhou' date='2018-01-25T21:04:55Z'>
 		Hi &lt;denchmark-link:https://github.com/WenmuZhou&gt;@WenmuZhou&lt;/denchmark-link&gt;
 
 We've created two environment with GPUS one with TF1.3 and one with TF1.4.
 We've run your data generation script (BTW, there is a small mismatch with between the generated data and what your model expects).
 We've run your model with following command as describe on your github:
 'python train.py -g 1 -ft ../data/10.csv -fe ../data/10.csv -o ./export_model_dir'.
 At the end we couldn't reproduce the issue. Could you please provide us a single script which we can run and which reproduces the slowness.
 		</comment>
 		<comment id='34' author='WenmuZhou' date='2018-01-29T14:20:27Z'>
 		&lt;denchmark-link:https://github.com/ispirmustafa&gt;@ispirmustafa&lt;/denchmark-link&gt;
  I have update a latest &lt;denchmark-link:https://github.com/WenmuZhou/Segmentation-Free_OCR&gt;code&lt;/denchmark-link&gt;
 , the python version I used is python3.5.2, and I have test once and reproduce the issue.
 the environment is
 
 python 3.5.2
 tensorflow 1.3 or 1.4
 
 Some Chinese comments cause the code to no longer run under python2 and if you need to test in python2 you need to comment out these Chinese comments
 		</comment>
 		<comment id='35' author='WenmuZhou' date='2018-02-15T13:14:41Z'>
 		Nagging Awaiting TensorFlower: It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
 		</comment>
 		<comment id='36' author='WenmuZhou' date='2018-02-20T18:40:09Z'>
 		I tried to reproduce your issue with the code you provided but I cannot see any slowdown switching from 1.3 to 1.4.
 The scripts you provided are very complex, many different issues inside and outside TensorFlow could contribute to a slowdown.
 Can you provide a small repro script that isolates the issue and which we can use for debugging?
 I will close this issue as not reproducible, but please reopen this with some more specific information.
 		</comment>
 	</comments>
 </bug>
<commit id='2d4c29cd6a0627fdd71a752e6bd919204c7cb8bf' author='Mustafa Ispir' date='2017-12-07 14:39:27-08:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\python\training\server_lib.py' new_name='tensorflow\python\training\server_lib.py'>
 		<file_info nloc='220' complexity='47' token_count='1233'></file_info>
 		<method name='__str__' parameters='self'>
 				<method_info nloc='5' complexity='2' token_count='48' nesting_level='1' start_line='310' end_line='314'></method_info>
 			<added_lines>310,311,312,313,314</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>315</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\python\training\server_lib_test.py' new_name='tensorflow\python\training\server_lib_test.py'>
 		<file_info nloc='416' complexity='30' token_count='3408'></file_info>
 		<method name='testStringConversion' parameters='self'>
 				<method_info nloc='9' complexity='1' token_count='44' nesting_level='1' start_line='424' end_line='433'></method_info>
 			<added_lines>424,425,426,427,428,429,430,431,432,433</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>434</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
