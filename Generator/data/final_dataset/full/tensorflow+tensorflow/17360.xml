<bug_data>
<bug id='17360' author='kbsriram' open_date='2018-03-01T16:26:37Z' closed_time='2018-03-07T01:17:02Z'>
 	<summary>C++ api: use of op::Attrs methods in gradients</summary>
 	<description>
 The generated op::Attrs struct returns new instances on its chainable methods, and doesn't change the original object.
 
 
 
 tensorflow/tensorflow/cc/framework/cc_op_gen.cc
 
 
          Line 701
       in
       d7d7f4e
 
 
 
 
 
 
  strings::StrAppend(&amp;setters, "      Attrs ret = *this;\n"); 
 
 
 
 
 
 There are a few related issues e.g. 
 
 
 tensorflow/tensorflow/cc/gradients/nn_grad.cc
 
 
          Line 164
       in
       6fdb9ad
 
 
 
 
 
 
  grad_attrs.DataFormat(data_format); 
 
 
 
 
  where the code assumes the underlying object is being mutated and the parameters don't actually pass through.
 I guess there might be a couple of ways forward, depending on how Tensorflow prefers the C++ API:
 
 Decide the Attrs chaining methods mutate the underlying object and fix the code generation.
 Decide the Attrs chaining methods return new instances, and fix the uses.
 
 Suggestions?
 Fwiw if option 2, it might be nice to add TF_MUST_USE_RESULT to the generated API. (Unfortunately a &lt;denchmark-link:https://gcc.gnu.org/bugzilla/show_bug.cgi?id=38172&gt;long-standing bug in gcc&lt;/denchmark-link&gt;
  means this may be unreliable as an actual error across versions of gcc that contributors may use.)
 /cc &lt;denchmark-link:https://github.com/suharshs&gt;@suharshs&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/keveman&gt;@keveman&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='kbsriram' date='2018-03-01T16:44:30Z'>
 		&lt;denchmark-link:https://github.com/kbsriram&gt;@kbsriram&lt;/denchmark-link&gt;
  thanks for pointing out the bug. I am not a fan of mutable state, so my natural inclination is towards option 2. Adding  to the generated API would simply point out the existing erroneous uses as compiler errors.
 		</comment>
 		<comment id='2' author='kbsriram' date='2018-03-01T20:25:50Z'>
 		&lt;denchmark-link:https://github.com/keveman&gt;@keveman&lt;/denchmark-link&gt;
  thanks for the note! Sgtm - don't have a strong opinion on this. But would like to make progress on fixes and (for option 2 as you note) add a bit of a compile-time safety net for new code.
 Tentatively predicated on option 2, suggestions on next steps? If someone is already on it, awesome - otherwise, I can sign up for a pull request on this.
 		</comment>
 	</comments>
 </bug>
<commit id='5279cf29cea96b3ec50df506bb51d8ffabdabac9' author='A. Unique TensorFlower' date='2018-03-05 14:49:23-08:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.8'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\cc\framework\cc_op_gen.cc' new_name='tensorflow\cc\framework\cc_op_gen.cc'>
 		<file_info nloc='952' complexity='198' token_count='7084'></file_info>
 		<method name='tensorflow::OpInfo::GetOpAttrStruct' parameters=''>
 				<method_info nloc='51' complexity='10' token_count='418' nesting_level='2' start_line='667' end_line='726'></method_info>
 			<added_lines>700,701</added_lines>
 			<deleted_lines>700</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\cc\gradients\nn_grad.cc' new_name='tensorflow\cc\gradients\nn_grad.cc'>
 		<file_info nloc='156' complexity='12' token_count='1465'></file_info>
 		<method name='tensorflow::ops::BiasAddGradHelper' parameters='scope,op,grad_inputs,grad_outputs'>
 				<method_info nloc='12' complexity='1' token_count='111' nesting_level='3' start_line='106' end_line='117'></method_info>
 			<added_lines>112,113</added_lines>
 			<deleted_lines>110,113,114</deleted_lines>
 		</method>
 		<method name='tensorflow::ops::LRNGradHelper' parameters='scope,op,grad_inputs,grad_outputs'>
 				<method_info nloc='7' complexity='1' token_count='76' nesting_level='3' start_line='185' end_line='191'></method_info>
 			<added_lines>187,188</added_lines>
 			<deleted_lines>185,186,187,188,189,190,191</deleted_lines>
 		</method>
 		<method name='tensorflow::ops::LogSoftmaxGrad' parameters='scope,op,grad_inputs,grad_outputs'>
 				<method_info nloc='10' complexity='1' token_count='113' nesting_level='3' start_line='50' end_line='59'></method_info>
 			<added_lines>51,52</added_lines>
 			<deleted_lines>51,52</deleted_lines>
 		</method>
 		<method name='tensorflow::ops::MaxPoolGradV2Helper' parameters='scope,op,grad_inputs,grad_outputs'>
 				<method_info nloc='16' complexity='1' token_count='165' nesting_level='3' start_line='167' end_line='182'></method_info>
 			<added_lines>175,176,177</added_lines>
 			<deleted_lines>167,168,169</deleted_lines>
 		</method>
 		<method name='tensorflow::ops::Conv2DGrad' parameters='scope,op,grad_inputs,grad_outputs'>
 				<method_info nloc='25' complexity='1' token_count='237' nesting_level='3' start_line='120' end_line='144'></method_info>
 			<added_lines>132,133,134,135,137,138,139,140,141</added_lines>
 			<deleted_lines>133,134,135,136,137,138,140,141,142,143,144</deleted_lines>
 		</method>
 		<method name='tensorflow::ops::MaxPoolGradHelper' parameters='scope,op,grad_inputs,grad_outputs'>
 				<method_info nloc='18' complexity='1' token_count='183' nesting_level='3' start_line='147' end_line='164'></method_info>
 			<added_lines>159,160,161</added_lines>
 			<deleted_lines>163,164</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>145,165,166,183,184,201,202,203,204,205</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
