<bug_data>
<bug id='23195' author='brianmartin' open_date='2018-10-23T20:21:54Z' closed_time='2018-10-31T01:38:43Z'>
 	<summary>Segfault reading dataset more than once (`make_batched_features_dataset`)</summary>
 	<description>
 System information
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14 Mojave
 Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
 TensorFlow installed from (source or binary): Binary / pip
 TensorFlow version (use command below): ('v1.11.0-rc2-4-gc19e29306c', '1.11.0')
 Python version: 2.7.10
 Bazel version (if compiling from source): NA
 GCC/Compiler version (if compiling from source): NA
 CUDA/cuDNN version: NA
 GPU model and memory: NA
 
 &lt;denchmark-link:https://gist.github.com/brianmartin/2b43dca69453478ed33b49f1029e03fe&gt;Gist of full output of `./tools/tf_env_collect.sh&lt;/denchmark-link&gt;
 
 Exact command to reproduce:
 &lt;denchmark-code&gt;$ wget https://gist.githubusercontent.com/brianmartin/4f221eb838dce8099342f829fb13253d/raw/00c2a1736b9a292f8a6fb88164d240a766468744/gistfile1.txt
 $ python gistfile1.txt
 &lt;/denchmark-code&gt;
 
 Describe the current behavior
 Current behavior in 1.11.0, 1.12.0rcX is that the included script segfaults (11: SIGSEGV).
 Describe the expected behavior
 Expected behavior is no segfault. Version 1.10.1, 1.10.0, and 1.9.0 do not segfault. I have not checked lower versions.
 Code to reproduce the issue
 See a full script which reproduces this issue along two different code paths here: &lt;denchmark-link:https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d&gt;https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d&lt;/denchmark-link&gt;
 
 The segfault occurs when reading the dataset a second time. The first read works as expected.
 For reference the two code samples which produce datasets which cause a segfault on second read are:
     dataset = make_batched_features_dataset(file_pattern=data_file,
                                             batch_size=1,
                                             features=feature_spec)
 I've also dug into make_batched_features_dataset and minified down to this repro:
     from tensorflow.contrib.data.python.ops import parsing_ops
     from tensorflow.python.data.ops import readers
 
     dataset = Dataset.from_tensor_slices([data_file]) \
                      .interleave(readers.TFRecordDataset, cycle_length=1) \
                      .batch(batch_size=1) \
                      .apply(parsing_ops.parse_example_dataset(feature_spec))
 &lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;
 
 Please let me know if there's anything else I can provide or help with! This is blocking us from upgrading to the latest Tensorflow version in &lt;denchmark-link:https://github.com/spotify/spotify-tensorflow&gt;spotify/spotify-tensorflow&lt;/denchmark-link&gt;
 .
 	</description>
 	<comments>
 		<comment id='1' author='brianmartin' date='2018-10-24T06:44:07Z'>
 		Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
 Have I written custom code
 OS Platform and Distribution
 TensorFlow installed from
 Bazel version
 CUDA/cuDNN version
 GPU model and memory
 Exact command to reproduce
 Mobile device
 		</comment>
 		<comment id='2' author='brianmartin' date='2018-10-24T14:28:33Z'>
 		Updated!
 		</comment>
 		<comment id='3' author='brianmartin' date='2018-10-26T01:24:06Z'>
 		&lt;denchmark-link:https://github.com/shivaniag&gt;@shivaniag&lt;/denchmark-link&gt;
  As we discussed offline, can you please take a look at this issue, in case thereâ€™s a bug in ? Thanks!
 		</comment>
 		<comment id='4' author='brianmartin' date='2018-10-30T14:56:30Z'>
 		I've dug in a bit more. For a FixedLenFeature, this test case still succeeds on the first read and fails on the second read -- no change there. But it fails with an exception rather than the segfault we see with VarLenFeature.
 I've updated the gist to reproduce in tensorflow&gt;=1.11.0 here: &lt;denchmark-link:https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d&gt;https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d&lt;/denchmark-link&gt;
 
 The exception on the second, failing read (after seeing the first read succeed):
 &lt;denchmark-code&gt;Attempting first read..
 2018-10-30 10:53:26.766551: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
 {'f0': &lt;tf.Tensor: id=26, shape=(1, 1), dtype=int64, numpy=array([[1]])&gt;}
 Attempting second identical read..
 Traceback (most recent call last):
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py", line 109, in &lt;module&gt;
     main()
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py", line 104, in main
     run(make_it_fail, read_fn, var_len=var_len)
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py", line 79, in run
     _print_first(read_fn(data_file, feature_spec))
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py", line 35, in _print_first
     print next(xs.__iter__())
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py", line 139, in __iter__
     return iterator_ops.EagerIterator(self)
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/data/ops/iterator_ops.py", line 521, in __init__
     ds_variant = dataset._as_variant_tensor()  # pylint: disable=protected-access
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/contrib/data/python/ops/parsing_ops.py", line 90, in _as_variant_tensor
     **dataset_ops.flat_structure(self))
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py", line 3963, in parse_example_dataset
     ctx=_ctx)
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py", line 4015, in parse_example_dataset_eager_fallback
     attrs=_attrs, ctx=_ctx, name=name)
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/eager/execute.py", line 66, in quick_execute
     six.raise_from(core._status_to_exception(e.code, message), None)
   File "/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/six.py", line 737, in raise_from
     raise value
 tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected len(dense_defaults) == len(dense_keys) but got: 1 vs. 0 [Op:ParseExampleDataset]
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='5' author='brianmartin' date='2018-10-31T00:18:08Z'>
 		&lt;denchmark-link:https://github.com/brianmartin&gt;@brianmartin&lt;/denchmark-link&gt;
  Thank you very much for narrowing down the bug, we have fixed it and are going to submit it soon, will update you when that is done.
 		</comment>
 	</comments>
 </bug>
<commit id='95de98b58a35aaac2804716a70979e68596f3dae' author='Shivani Agrawal' date='2018-10-30 18:36:11-07:00'>
 	<dmm_unit complexity='0.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\core\kernels\data\parse_example_dataset_op.cc' new_name='tensorflow\core\kernels\data\parse_example_dataset_op.cc'>
 		<file_info nloc='331' complexity='31' token_count='2518'></file_info>
 		<method name='tensorflow::data::ParseExampleDatasetOp::MakeDataset' parameters='ctx,input,output'>
 				<method_info nloc='73' complexity='7' token_count='606' nesting_level='4' start_line='72' end_line='150'></method_info>
 			<added_lines>145,146,147,148,149</added_lines>
 			<deleted_lines>145,146,147,148,149</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\python\data\experimental\kernel_tests\parse_example_dataset_test.py' new_name='tensorflow\python\data\experimental\kernel_tests\parse_example_dataset_test.py'>
 		<file_info nloc='722' complexity='39' token_count='5625'></file_info>
 		<method name='testSkipEagerSerializedSparseAndSparseFeatureAndDenseWithNoDefault' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='5' nesting_level='1' start_line='537' end_line='538'></method_info>
 			<added_lines>537,538</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testSkipEagerSerializedContainingSparseFeature' parameters='self'>
 				<method_info nloc='32' complexity='2' token_count='280' nesting_level='1' start_line='266' end_line='302'></method_info>
 			<added_lines>266,301,302</added_lines>
 			<deleted_lines>295,297</deleted_lines>
 		</method>
 		<method name='testSerializedContainingVarLenDense' parameters='self'>
 				<method_info nloc='149' complexity='2' token_count='1022' nesting_level='1' start_line='685' end_line='846'></method_info>
 			<added_lines>694,695,697,702,762,763</added_lines>
 			<deleted_lines>685,745</deleted_lines>
 		</method>
 		<method name='testSerializedContainingSparseAndSparseFeatureAndDenseWithNoDefault' parameters='self'>
 				<method_info nloc='52' complexity='2' token_count='424' nesting_level='1' start_line='524' end_line='580'></method_info>
 			<added_lines>534,535,537,538</added_lines>
 			<deleted_lines>524,580</deleted_lines>
 		</method>
 		<method name='testSkipEagerEmptySerializedWithAllDefaults' parameters='self'>
 				<method_info nloc='37' complexity='1' token_count='261' nesting_level='1' start_line='121' end_line='160'></method_info>
 			<added_lines>121,159,160</added_lines>
 			<deleted_lines>155</deleted_lines>
 		</method>
 		<method name='testSerializedContainingSparseFeature' parameters='self'>
 				<method_info nloc='31' complexity='2' token_count='276' nesting_level='1' start_line='260' end_line='295'></method_info>
 			<added_lines>263,264,266</added_lines>
 			<deleted_lines>260,295</deleted_lines>
 		</method>
 		<method name='testSerializedContainingDenseWithConcat' parameters='self'>
 				<method_info nloc='39' complexity='2' token_count='292' nesting_level='1' start_line='430' end_line='473'></method_info>
 			<added_lines>472,473</added_lines>
 			<deleted_lines>462</deleted_lines>
 		</method>
 		<method name='_test' parameters='self,input_tensor,feature_val,expected_values,expected_err'>
 				<method_info nloc='5' complexity='1' token_count='17' nesting_level='1' start_line='78' end_line='82'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>82</deleted_lines>
 		</method>
 		<method name='_testSerializedContainingVarLenDenseLargerBatch' parameters='self,batch_size'>
 				<method_info nloc='42' complexity='8' token_count='317' nesting_level='1' start_line='637' end_line='695'></method_info>
 			<added_lines>694,695</added_lines>
 			<deleted_lines>678,680,685</deleted_lines>
 		</method>
 		<method name='testSerializedContainingDense' parameters='self'>
 				<method_info nloc='30' complexity='2' token_count='233' nesting_level='1' start_line='393' end_line='426'></method_info>
 			<added_lines>425,426</added_lines>
 			<deleted_lines>416</deleted_lines>
 		</method>
 		<method name='testEmptySerializedWithAllDefaults' parameters='self'>
 				<method_info nloc='36' complexity='1' token_count='257' nesting_level='1' start_line='117' end_line='155'></method_info>
 			<added_lines>117,118,119,120,121</added_lines>
 			<deleted_lines>117,155</deleted_lines>
 		</method>
 		<method name='testSerializedContaining3DSparseFeature' parameters='self'>
 				<method_info nloc='36' complexity='2' token_count='327' nesting_level='1' start_line='339' end_line='382'></method_info>
 			<added_lines>344,345,347</added_lines>
 			<deleted_lines>339,382</deleted_lines>
 		</method>
 		<method name='testSkipEagerSerializedContaining3DSparseFeature' parameters='self'>
 				<method_info nloc='37' complexity='2' token_count='331' nesting_level='1' start_line='347' end_line='391'></method_info>
 			<added_lines>347,390,391</added_lines>
 			<deleted_lines>382</deleted_lines>
 		</method>
 		<method name='_test' parameters='self,input_tensor,feature_val,expected_values,expected_err,create_iterator_twice'>
 				<method_info nloc='6' complexity='1' token_count='21' nesting_level='1' start_line='80' end_line='85'></method_info>
 			<added_lines>84,85</added_lines>
 			<deleted_lines>82,83,84,85</deleted_lines>
 		</method>
 		<method name='testSerializedContainingDenseWithDefaults' parameters='self'>
 				<method_info nloc='34' complexity='2' token_count='246' nesting_level='1' start_line='499' end_line='535'></method_info>
 			<added_lines>534,535</added_lines>
 			<deleted_lines>522,524</deleted_lines>
 		</method>
 		<method name='testSerializedContainingVarLenDenseLargerBatch' parameters='self'>
 				<method_info nloc='4' complexity='2' token_count='34' nesting_level='1' start_line='680' end_line='683'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>680</deleted_lines>
 		</method>
 		<method name='testSerializedContainingSparse' parameters='self'>
 				<method_info nloc='37' complexity='2' token_count='312' nesting_level='1' start_line='217' end_line='258'></method_info>
 			<added_lines>222</added_lines>
 			<deleted_lines>217,258</deleted_lines>
 		</method>
 		<method name='testSkipEagerSerializedContainingSparse' parameters='self'>
 				<method_info nloc='38' complexity='2' token_count='316' nesting_level='1' start_line='222' end_line='264'></method_info>
 			<added_lines>222,263,264</added_lines>
 			<deleted_lines>258,260</deleted_lines>
 		</method>
 		<method name='testSkipEagererializedContainingSparseAndSparseFeatureWithReuse' parameters='self'>
 				<method_info nloc='34' complexity='2' token_count='303' nesting_level='1' start_line='597' end_line='635'></method_info>
 			<added_lines>597,634,635</added_lines>
 			<deleted_lines>619</deleted_lines>
 		</method>
 		<method name='testSkipEagerSerializedContainingSparseFeatureReuse' parameters='self'>
 				<method_info nloc='37' complexity='2' token_count='296' nesting_level='1' start_line='304' end_line='345'></method_info>
 			<added_lines>304,344,345</added_lines>
 			<deleted_lines>337,339</deleted_lines>
 		</method>
 		<method name='testSkipEagerSerializedContainingVarLenDenseLargerBatch' parameters='self'>
 				<method_info nloc='4' complexity='2' token_count='34' nesting_level='1' start_line='697' end_line='700'></method_info>
 			<added_lines>697</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testSerializedContainingSparseAndSparseFeatureWithReuse' parameters='self'>
 				<method_info nloc='33' complexity='2' token_count='299' nesting_level='1' start_line='582' end_line='619'></method_info>
 			<added_lines>594,595,597</added_lines>
 			<deleted_lines>582,619</deleted_lines>
 		</method>
 		<method name='testSerializedContainingDenseScalar' parameters='self'>
 				<method_info nloc='20' complexity='2' token_count='124' nesting_level='1' start_line='475' end_line='497'></method_info>
 			<added_lines>496,497</added_lines>
 			<deleted_lines>485</deleted_lines>
 		</method>
 		<method name='testSkipEagerSerializedContainingVarLenDense' parameters='self'>
 				<method_info nloc='150' complexity='2' token_count='1026' nesting_level='1' start_line='702' end_line='864'></method_info>
 			<added_lines>702,762,763</added_lines>
 			<deleted_lines>745</deleted_lines>
 		</method>
 		<method name='testSerializedContainingSparseFeatureReuse' parameters='self'>
 				<method_info nloc='36' complexity='2' token_count='292' nesting_level='1' start_line='297' end_line='337'></method_info>
 			<added_lines>301,302,304</added_lines>
 			<deleted_lines>297,337</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>35,57,77,86,87,88,89,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,109,110,111,112,113,114,115,116</added_lines>
 			<deleted_lines>56,86,87,88,89,90,91,92,93,94,95,98,99,101,103,104,105,106,107,108,109,110,111,112,113,114,115,116</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\python\framework\test_util.py' new_name='tensorflow\python\framework\test_util.py'>
 		<file_info nloc='1062' complexity='259' token_count='7647'></file_info>
 		<method name='run_all_in_graph_and_eager_modes' parameters='cls'>
 				<method_info nloc='7' complexity='5' token_count='60' nesting_level='0' start_line='763' end_line='770'></method_info>
 			<added_lines>767,768</added_lines>
 			<deleted_lines>767</deleted_lines>
 		</method>
 		<method name='decorator' parameters='f'>
 				<method_info nloc='7' complexity='2' token_count='23' nesting_level='1' start_line='832' end_line='872'></method_info>
 			<added_lines>836</added_lines>
 			<deleted_lines>835</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
