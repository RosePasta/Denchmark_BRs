<bug_data>
<bug id='33376' author='rggjan' open_date='2019-10-15T13:32:32Z' closed_time='2019-12-17T21:41:47Z'>
 	<summary>importing tensorflow inside a function/object causes a memory leak</summary>
 	<description>
 System information
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15
 Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
 TensorFlow installed from (source or binary): pip install tensorflow==1.14
 TensorFlow version (use command below): 1.14.0
 Python version: 3.6.8
 Bazel version (if compiling from source): -
 GCC/Compiler version (if compiling from source): -
 CUDA/cuDNN version: -
 GPU model and memory: -
 
 Describe the current behavior
 When importing tensorflow from a function or object, the import statement somehow keeps a reference to the function and increasing it's reference count. The full import stacktrace is never freed, making it impossible for the object (and anything referenced from that object or function) to be freed from memory.
 Describe the expected behavior
 It should be possible to free the function calling import tensorflow. This is not an issue with any other imports (like import logger).
 Code to reproduce the issue
 &lt;denchmark-code&gt;import gc
 
 
 class TFImporter:
     def __init__(self, name):
         self._name = name
         print(f"TFImporter init {self._name}")
 
     def get_tf(self):
         print(f"import tensorflow {self._name}")
         import tensorflow
         print(tensorflow.version.VERSION)
 
     def get_other_module(self):
         print(f"import logging {self._name}")
         import logging
         logging.info("Message")
 
     def __del__(self):
         print(f"TFImporter delete {self._name}")
 
 
 def main():
     importer1 = TFImporter(1)
     importer1.get_other_module()
     del importer1
     print("importer1 deleted")
 
     importer2 = TFImporter(2)
     importer2.get_tf()
     del importer2
     print("importer2 deleted")
 
     importer3 = TFImporter(3)
     importer3.get_tf()
     del importer3
     print("importer3 deleted")
 
     print(f"Garbage collection: {gc.collect()}")
 
     print(f"Waiting for input:")
     input()
 
 
 main()
 &lt;/denchmark-code&gt;
 
 this outputs:
 &lt;denchmark-code&gt;/Users/jan/miniconda/envs/foo/bin/python /Users/jan/code/tensorflow_error.py
 TFImporter init 1
 import logging 1
 TFImporter delete 1
 importer1 deleted
 TFImporter init 2
 import tensorflow 2
 1.14.0
 importer2 deleted
 TFImporter init 3
 import tensorflow 3
 1.14.0
 TFImporter delete 3
 importer3 deleted
 Garbage collection: 22
 Waiting for input:
 foo
 TFImporter delete 2
 
 Process finished with exit code 0
 &lt;/denchmark-code&gt;
 
 So importer2 is only freed after the python application finishes. Neither gc.collect nor deleting the object causes it to be released in python.
 This is not an issue in this toy example, but importer2 could have a reference to a large number of other objects that take considerable space in memory in reality.
 Also, this only happens for the first import. importer3 can be freed without issues.
 
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/3729501/tf_env.txt&gt;tf_env.txt&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='rggjan' date='2019-10-16T06:34:23Z'>
 		Issue replicating for Tf 1.14, kindly for the &lt;denchmark-link:https://colab.sandbox.google.com/gist/oanush/e224d0fa208b982d84e5cb18c1317ce9/33376.ipynb&gt;gist&lt;/denchmark-link&gt;
 .ThThanks!
 		</comment>
 		<comment id='2' author='rggjan' date='2019-12-16T21:11:18Z'>
 		&lt;denchmark-link:https://github.com/annarev&gt;@annarev&lt;/denchmark-link&gt;
  is this related to lazy loaders or estimator/keras integration?
 		</comment>
 		<comment id='3' author='rggjan' date='2019-12-17T00:30:38Z'>
 		It appears to be due to saving error when importing portpicker here:
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L44&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L44&lt;/denchmark-link&gt;
 
 We can probably save the error text instead or import portpicker inside the function that creates a cluster.
 		</comment>
 		<comment id='4' author='rggjan' date='2019-12-17T01:08:20Z'>
 		Yeah, it seems weird that we'd survive the import, only to error out later.
 Let's either import it inside the cluster creation, or print the error
 directly on import (but still continue), and later error with a note to
 look for the earlier error.
 
 Honestly, I think the local import is preferable in this case.
 		</comment>
 		<comment id='5' author='rggjan' date='2019-12-17T21:41:49Z'>
 		Are you satisfied with the resolution of your issue?
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33376&gt;Yes&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33376&gt;No&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='413d0fa9d75e99e02b74bb079465bea728eb3a44' author='Anna R' date='2019-12-17 13:40:41-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\python\framework\test_util.py' new_name='tensorflow\python\framework\test_util.py'>
 		<file_info nloc='1566' complexity='448' token_count='11091'></file_info>
 		<modified_lines>
 			<added_lines>3088</added_lines>
 			<deleted_lines>40,41,42,43,44,45,46,47,3096,3097</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
