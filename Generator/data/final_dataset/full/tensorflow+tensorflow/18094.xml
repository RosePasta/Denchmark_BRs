<bug_data>
<bug id='18094' author='zmjjmz' open_date='2018-03-29T18:13:25Z' closed_time='2018-04-20T23:10:42Z'>
 	<summary>`tf.keras.estimator._create_ordered_io` casts everything to floatx, which breaks non-floatx inputs</summary>
 	<description>
 &lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;
 
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 3.16.36
 TensorFlow installed from (source or binary): Installed via pip
 TensorFlow version (use command below): ('v1.6.0-0-gd2e24b6039', '1.6.0')
 Python version: 2.7.9
 Bazel version (if compiling from source):
 GCC/Compiler version (if compiling from source):
 CUDA/cuDNN version: n/a
 GPU model and memory: n/a
 Exact command to reproduce: Requires significant code, let me know if necessary
 
 &lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;
 
 This is kind of a simple issue with using Keras models as Tensorflow Estimators. I unfortunately need to do this awkward conversion in order to use SageMaker, which is even more awkwardly behind by two versions of Tensorflow. Which is fun.
 Basically, I have a  model that expects a  input , which is then passed through to a Lookup layer for some text embeddings. This works fine as a Keras model and works fine if I extract the input layers myself and connect them into an Estimator. However, if I go to create an estimator from the model using  I run into this code path: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/python/keras/_impl/keras/estimator.py#L80&gt;https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/python/keras/_impl/keras/estimator.py#L80&lt;/denchmark-link&gt;
 
 This conversion then causes the model to break further down the line. I'm not sure why this float cast occurs, but this commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/4c86ece040cb96ea689f5c0d084b6959274eab91#diff-69effda952f96b36c8015cc1a3462d65&gt;4c86ece#diff-69effda952f96b36c8015cc1a3462d65&lt;/denchmark-link&gt;
  seems to imply that Keras models are meant to only take floatx input, which doesn't really seem right.
 Would not doing this cast break anything? If so, is there a way to use a non-float32 input with Keras models that need to be converted to Estimators?
 Thanks!
 &lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;
 
 Here's the exact traceback for the issue:
 &lt;denchmark-code&gt;/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument 
 of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.          
   from ._conv import register_converters as _register_converters                                                                           
 WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp6Wogzk                                                               
 2018-03-29 14:12:41.586292: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow       
 binary was not compiled to use: AVX2 FMA                                                                                                   
 WARNING:tensorflow:Output "final_representation" missing from loss dictionary. We assume this was done on purpose, and we will not be      
 expecting any data to be passed to "final_representation" during training.                                                                 
 WARNING:tensorflow:Output "oov_code" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any    
 data to be passed to "oov_code" during training.                                                                                           
 Testing common_estimator_fns.py locally                                                                                                    
 Making estimator                                                                                                                           
 Model dir: /tmp/tmp6Wogzk                                                                                                                  
 Training estimator                                                                                                                         
 float64                                                                                                                                    
 Tensor("random_shuffle_queue_DequeueMany:1", shape=(32, 1), dtype=string, device=/device:CPU:0)                                            
 Traceback (most recent call last):                                                                                                         
   File "common_estimator_fns.py", line 423, in &lt;module&gt;                                                                                    
     hooks=[tf_debug.LocalCLIDebugHook()])                                                                                                  
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 352, in train 
     loss = self._train_model(input_fn, hooks, saving_listeners)                                                                            
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 812, in       
 _train_model                                                                                                                               
     features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)                                                                            
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 793, in       
 _call_model_fn                                                                                                                             
     model_fn_results = self._model_fn(features=features, **kwargs)                                                                         
   File "common_estimator_fns.py", line 381, in model_fn                                                                                    
     return keras_model_fn(features, labels, mode)                                                                                          
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/estimator.py", line 160,  
 in model_fn                                                                                                                                
     labels)                                                                                                                                
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/estimator.py", line 109,  
 in _clone_and_build_model                                                                                                                  
     model = models.clone_model(keras_model, input_tensors=input_tensors)                                                                   
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/models.py", line 1557, in 
 clone_model                                                                                                                                
     return _clone_functional_model(model, input_tensors=input_tensors)                                                                     
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/models.py", line 1451, in 
 _clone_functional_model                                                                                                                    
     output_tensors = topology._to_list(layer(computed_tensor, **kwargs))                                                                   
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py", line 
 258, in __call__                                                                                                                           
     output = super(Layer, self).__call__(inputs, **kwargs)                                                                                 
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/layers/base.py", line 673, in __call__      
     self._assert_input_compatibility(inputs)                                                                                               
   File "/home/u1/zach/proj/dataplayground2/local/lib/python2.7/site-packages/tensorflow/python/layers/base.py", line 1204, in              
 _assert_input_compatibility                                                                                                                
     ', found dtype=' + str(x.dtype))                                                                                                       
 ValueError: Input 0 of layer lookedup is incompatible with the layer: expected dtype=&lt;dtype: 'string'&gt;, found dtype=&lt;dtype: 'float32'&gt;     
 &lt;/denchmark-code&gt;
 
 I can provide code if absolutely necessary, but it'd take some work to get to a minimal reproduction.
 	</description>
 	<comments>
 		<comment id='1' author='zmjjmz' date='2018-03-29T18:21:19Z'>
 		Looking at the history of this file, using other types were never tested.
 We should use &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/is_numeric_tensor&gt;https://www.tensorflow.org/api_docs/python/tf/is_numeric_tensor&lt;/denchmark-link&gt;
  before casting
 		</comment>
 		<comment id='2' author='zmjjmz' date='2018-04-03T17:05:21Z'>
 		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
  Can you take a look at this?
 		</comment>
 		<comment id='3' author='zmjjmz' date='2018-04-12T00:08:37Z'>
 		I confirm this bug. /cc &lt;denchmark-link:https://github.com/lenlen&gt;@lenlen&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='4' author='zmjjmz' date='2018-04-12T19:09:43Z'>
 		&lt;denchmark-link:https://github.com/yifeif&gt;@yifeif&lt;/denchmark-link&gt;
  what do you think about this issue? Could it be a simple fix?
 		</comment>
 		<comment id='5' author='zmjjmz' date='2018-04-12T19:16:48Z'>
 		I opened a PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/18104&gt;#18104&lt;/denchmark-link&gt;
  as a starting point.
 		</comment>
 	</comments>
 </bug>
<commit id='3fa8795c511931b55a9703956bdf564fde817c2a' author='Frédéric Branchaud-Charron' date='2018-04-20 16:10:41-07:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.47058823529411764'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\python\keras\_impl\keras\estimator.py' new_name='tensorflow\python\keras\_impl\keras\estimator.py'>
 		<file_info nloc='330' complexity='58' token_count='1912'></file_info>
 		<method name='_convert_tensor' parameters='x'>
 				<method_info nloc='6' complexity='3' token_count='39' nesting_level='0' start_line='60' end_line='68'></method_info>
 			<added_lines>60,61,62,63,64,65,66,67,68</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_create_ordered_io' parameters='keras_model,estimator_io,is_input'>
 				<method_info nloc='28' complexity='13' token_count='173' nesting_level='0' start_line='84' end_line='129'></method_info>
 			<added_lines>102,124,129</added_lines>
 			<deleted_lines>89,111,116</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>32,39,69,70,290</added_lines>
 			<deleted_lines>277,278</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\python\keras\_impl\keras\estimator_test.py' new_name='tensorflow\python\keras\_impl\keras\estimator_test.py'>
 		<file_info nloc='451' complexity='40' token_count='3685'></file_info>
 		<method name='test_multi_inputs_multi_outputs' parameters='self'>
 				<method_info nloc='33' complexity='1' token_count='264' nesting_level='1' start_line='347' end_line='391'></method_info>
 			<added_lines>360,361,362,363,364,365,366,373,374,379,380</added_lines>
 			<deleted_lines>361,366</deleted_lines>
 		</method>
 		<method name='test_multi_inputs_multi_outputs.train_input_fn' parameters=''>
 				<method_info nloc='5' complexity='1' token_count='36' nesting_level='2' start_line='372' end_line='376'></method_info>
 			<added_lines>373,374</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_multi_inputs_multi_outputs.eval_input_fn' parameters=''>
 				<method_info nloc='5' complexity='1' token_count='36' nesting_level='2' start_line='378' end_line='382'></method_info>
 			<added_lines>379,380</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='multi_inputs_multi_outputs_model' parameters=''>
 				<method_info nloc='21' complexity='1' token_count='246' nesting_level='0' start_line='145' end_line='167'></method_info>
 			<added_lines>148,150,152,153,154,156,159</added_lines>
 			<deleted_lines>145,151,154</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>33</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
