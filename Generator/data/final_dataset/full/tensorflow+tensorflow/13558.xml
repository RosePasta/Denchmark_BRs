<bug_data>
<bug id='13558' author='yaroslavvb' open_date='2017-10-07T23:40:22Z' closed_time='2018-01-03T19:31:07Z'>
 	<summary>segfaults in GPU tf.matrix_inverse</summary>
 	<description>
 I'm running into segfaults in tf.matrix_inverse
 I'm adding identity*0.001 so matrices should be invertible, and same procedure works fine in numpy and in TensorFlow CPU version.
 &lt;denchmark-link:https://github.com/yaroslavvb/stuff/blob/master/inverse_segfault.py&gt;https://github.com/yaroslavvb/stuff/blob/master/inverse_segfault.py&lt;/denchmark-link&gt;
 
 
 This non-deterministically crashes after 1-2 seconds with various backtraces.
 IE
 &lt;denchmark-code&gt;#0  0x0000000000000001 in ?? ()
 #1  0x00007fe90ed9c652 in tensorflow::Tensor::TotalBytes() const ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
 #2  0x00007fe90ed9c7d6 in tensorflow::Tensor::tensor_data() const ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
 #3  0x00007fe9137adda3 in bool tensorflow::internal::TransposeUsingTile&lt;unsigned int&gt;(Eigen::GpuDevice const&amp;, tensorflow::Tensor const&amp;, tensorflow::gtl::ArraySlice&lt;int&gt;, tensorflow::Tensor*) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
 #4  0x00007fe9137a696c in tensorflow::Status tensorflow::DoTranspose&lt;Eigen::GpuDevice&gt;(Eigen::GpuDevice const&amp;, tensorflow::Tensor const&amp;, tensorflow::gtl::ArraySlice&lt;int&gt;, tensorflow::Tensor*) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
 #5  0x00007fe911ada0fd in tensorflow::SvdOpGpu&lt;float&gt;::PerformSVD_MgeqN(tensorflow::OpKernelContext*, std::function&lt;void ()&gt;, long long, long long, long long, tensorflow::gtl::ArraySlice&lt;int&gt; const&amp;, tensorflow::Tensor const&amp;, tensorflow::Tensor*, tensorflow::Tensor*, tensorflow::Tensor*) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
 #6  0x00007fe911ade897 in tensorflow::SvdOpGpu&lt;float&gt;::ComputeAsync(tensorflow::OpKernelContext*, std::function&lt;void ()&gt;) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
 #7  0x00007fe90f20790b in tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function&lt;void ()&gt;) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
 #8  0x00007fe90f23cf37 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)
     ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
 &lt;/denchmark-code&gt;
 
 or this
 &lt;denchmark-code&gt;#0  0x00007fa89090686a in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
 #1  0x00007fa89091b074 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
 #2  0x00007fa890826e2c in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
 #3  0x00007fa890978880 in cuLaunchKernel ()
    from /usr/lib/x86_64-linux-gnu/libcuda.so.1
 #4  0x00007fa891bf1dc1 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0
 #5  0x00007fa891c0f9cd in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0
 #6  0x00007fa891aa1132 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0
 #7  0x00007fa891aa2b72 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0
 #8  0x00007fa891aa32e3 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0
 #9  0x00007fa891aa36fa in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0
 #10 0x00007fa89190f5f3 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0
 #11 0x00007fa891912375 in ?? () from /usr/local/cuda/lib64/libcusolver.so.8.0
 #12 0x00007fa89aa82c50 in tensorflow::Status tensorflow::CudaSolver::Getrf&lt;float&gt;(int, int, float*, int, int*, int*) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
 #13 0x00007fa89a55f5d6 in tensorflow::MatrixInverseOpGpu&lt;float&gt;::ComputeAsync(tensorflow::OpKernelContext*, std::function&lt;void ()&gt;) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
 #14 0x00007fa897dce90b in tensorflow::BaseGPUDevice::ComputeAsync(tensorflow::AsyncOpKernel*, tensorflow::OpKernelContext*, std::function&lt;void ()&gt;) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
 #15 0x00007fa897e03f37 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)
     ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
 #16 0x00007fa897df1ec5 in std::_Function_handler&lt;void (), std::_Bind&lt;std::_Mem_fn&lt;void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)&gt; (tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)&gt; &gt;::_M_invoke(std::_Any_data const&amp;) ()
    from /home/yaroslav/anaconda3/envs/oct10/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
 
 &lt;/denchmark-code&gt;
 
 TensorFlow commit: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/22a886b&gt;22a886b&lt;/denchmark-link&gt;
 
 NVIDIA-SMI 381.09
 libcudart.so.8.0.44
 libcudnn.so.6.0.21
 Nvidia GTX 1080
 	</description>
 	<comments>
 		<comment id='1' author='yaroslavvb' date='2017-10-09T07:09:42Z'>
 		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
  : Would you have some cycles to look into this?
 		</comment>
 		<comment id='2' author='yaroslavvb' date='2017-12-20T01:11:21Z'>
 		It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
 		</comment>
 		<comment id='3' author='yaroslavvb' date='2018-01-03T19:04:31Z'>
 		It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
 		</comment>
 		<comment id='4' author='yaroslavvb' date='2018-01-03T19:31:07Z'>
 		From the comment on the PR, it looks like the mutex was added.
 		</comment>
 	</comments>
 </bug>
<commit id='3629fc4e98254c37e614ac3f77fa250b75c70f8d' author='codrut3' date='2017-12-28 17:38:27-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\core\kernels\matrix_inverse_op.cc' new_name='tensorflow\core\kernels\matrix_inverse_op.cc'>
 		<file_info nloc='200' complexity='18' token_count='1425'></file_info>
 		<method name='tensorflow::MatrixInverseOpGpu::ComputeAsync' parameters='context,done'>
 				<method_info nloc='132' complexity='13' token_count='999' nesting_level='2' start_line='98' end_line='263'></method_info>
 			<added_lines>213</added_lines>
 			<deleted_lines>213</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
