<bug_data>
<bug id='10519' author='ddtm' open_date='2017-06-08T03:26:09Z' closed_time='2017-06-22T00:34:51Z'>
 	<summary>tf.contrib.data: tf-slim training pipeline gets stuck</summary>
 	<description>
 &lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;
 
 
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
 Yes
 
 
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
 Linux leto28 3.16.0-4-amd64 1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux
 VERSION_ID="8"
 VERSION="8 (jessie)"
 
 
 TensorFlow installed from (source or binary):
 Binary
 
 
 TensorFlow version (use command below):
 tf.VERSION = 1.2.0-rc2
 tf.GIT_VERSION = v1.2.0-rc1-24-gce1d6ec
 tf.COMPILER_VERSION = v1.2.0-rc1-24-gce1d6ec
 
 
 Bazel version (if compiling from source):
 None
 
 
 CUDA/cuDNN version:
 8.0/5.1
 
 
 GPU model and memory:
 TITAN X (Pascal), 12189MiB
 
 
 Exact command to reproduce:
 python ./mwe.py
 
 
 &lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;
 
 I recently ported my dataset handling to the new dataset API from . Now it seems that the  training pipeline stalls if I request just 1 or 2 CPUs for my job (it used to work just fine with the dataset API provided by ). I does work if I grab 4 CPUs. I tried to come up with a MWE (see below). The interesting thing is that it is not getting stuck if I remove one of the s or  at line 39. I suspect this issue is related to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/10369&gt;#10369&lt;/denchmark-link&gt;
 .
 &lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;
 
 import os
 import tensorflow as tf
 import tensorflow.contrib.data as tcd
 import tensorflow.contrib.slim as slim
 
 from tensorflow.contrib.data.python.ops.dataset_ops import _get_file_names
 
 DATASET_DIR = '/path_to_the_dataset'
 FILE_PATTERN = 'shapes_{}_*.tfrecord'
 IMAGE_SHAPE = [48, 48, 3]
 
 
 def _parse_function(example_proto):
     features = {
         "image/encoded": tf.FixedLenFeature(
             (), tf.string, default_value=""),
         'image/annotation/color': tf.FixedLenFeature(
             (), tf.int64, default_value=0),
         'image/annotation/shape': tf.FixedLenFeature(
             (), tf.int64, default_value=0),
     }
     parsed_features = tf.parse_single_example(example_proto, features)
     image_decoded = tf.image.decode_image(parsed_features["image/encoded"])
     color = parsed_features['image/annotation/color']
     shape = parsed_features['image/annotation/shape']
 
     return image_decoded, color, shape
 
 
 def get_batch(batch_size=32, group_size=3, split_name='train'):
     file_pattern = os.path.join(
         DATASET_DIR, FILE_PATTERN.format(split_name))
 
     file_names = _get_file_names(file_pattern, randomize_input=True)
 
     dataset = tcd.TFRecordDataset(file_names)
     dataset = dataset.map(_parse_function)
 
     dataset = dataset.map(lambda image, color, shape: image)
     dataset = dataset.shuffle(buffer_size=10000)
     dataset = dataset.repeat().batch(group_size * batch_size)
 
     iterator = dataset.make_one_shot_iterator()
     images = iterator.get_next()
 
     images = tf.split(images, group_size, axis=0)
     images = [tf.reshape(x, [batch_size] + IMAGE_SHAPE) for x in images]
 
     return images
 
 
 if __name__ == "__main__":
     with tf.Graph().as_default():
         x_1, x_2, x_3 = get_batch(batch_size=32,
                                   group_size=3)
 
         val = tf.reduce_sum(tf.add_n([x_1, x_2, x_3]))
         val = tf.Print(val, [tf.constant(0)], "I'm alive! ")
 
         global_step = slim.get_or_create_global_step()
         with tf.control_dependencies([val]):
             update_global_step_op = tf.assign_add(global_step, 1)
 
         train_op = update_global_step_op
 
         tf.summary.scalar('Summary 1', val)
         tf.summary.scalar('Summary 2', train_op)
 
         logdir = 'mwe_logdir'
         slim.learning.train(
             train_op=train_op,
             logdir=logdir,
             number_of_steps=1000000)
 	</description>
 	<comments>
 		<comment id='1' author='ddtm' date='2017-06-08T05:00:43Z'>
 		Thanks for reporting this... it definitely looks like a bug. I think I've tracked it down to the "OneShotIterator" op, which internally blocks on this line while a function executes to build the dataset:
 
 
 
 tensorflow/tensorflow/core/kernels/iterator_ops.cc
 
 
          Line 248
       in
       91cb809
 
 
 
 
 
 
  n.WaitForNotification(); 
 
 
 
 
 
 That will block one of the inter-op thread pool threads for the (typically short) execution time of the dataset construction function. The number of CPUs determines the default number of threads in that thread pool: when you have only 1 CPU, the system will deadlock as soon as you hit that line (because no more thread pool threads are available to run the function that will unblock it). When you have 2 CPUs, it can work, but slim.learning.train() uses tf.train.Supervisor, which asynchronously runs a background thread... that runs the same "OneShotIterator" op. To ensure that the op only initializes once, the initialization runs under a lock, acquired here:
 
 
 
 tensorflow/tensorflow/core/kernels/iterator_ops.cc
 
 
          Line 194
       in
       91cb809
 
 
 
 
 
 
  mutex_lock l(mu_); 
 
 
 
 
 
 The problem is probably starting to become clear: two concurrent executions of the same "OneShotIterator" kernel will potentially block two inter-op thread pool threads, leading to deadlock in a 2-CPU system, because there are no more threads available to run the function that will unblock them.
 Anyway, mea culpa, and thanks again for finding the bug. I'll be working on a fix, although it might not make it into the final 1.2 release. In the mean time, there are a couple of workarounds:
 
 
 Increase the number of threads to more than 2 in the inter-op thread pool. You can do this by passing session_config=tf.ConfigProto(inter_op_parallelism_threads=3) to slim.learning.train().
 
 
 Use dataset.make_initializable_iterator() instead of dataset.make_one_shot_iterator(). This comes with the additional requirement that you have to run iterator.initializer, which is not completely trivial with slim.learning.train() because you don't have access to the tf.Session. One possibility is to pass local_init_op=tf.group(tf.local_variables_initializer(), tf.tables_initializer(), iterator.initializer) to slim.learning.train().
 
 
 		</comment>
 		<comment id='2' author='ddtm' date='2017-06-08T05:31:29Z'>
 		Wow, thanks for the swift response! The first workaround seems to be working perfectly.
 On a side note, I'm quite happy with the tf.contrib.data. My code has become way cleaner.
 		</comment>
 	</comments>
 </bug>
<commit id='f5fcd1fdcf896f46aed03c7e61525b48b75d1acc' author='Derek Murray' date='2017-06-14 14:09:31-07:00'>
 	<dmm_unit complexity='0.75' interfacing='0.4479166666666667' size='0.125'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\contrib\data\python\kernel_tests\iterator_ops_test.py' new_name='tensorflow\contrib\data\python\kernel_tests\iterator_ops_test.py'>
 		<file_info nloc='237' complexity='44' token_count='2344'></file_info>
 		<method name='testOneShotIteratorNonBlocking.consumer_thread' parameters=''>
 				<method_info nloc='5' complexity='2' token_count='28' nesting_level='3' start_line='150' end_line='154'></method_info>
 			<added_lines>150,151,152,153,154</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testOneShotIteratorNonBlocking' parameters='self'>
 				<method_info nloc='24' complexity='8' token_count='225' nesting_level='1' start_line='133' end_line='167'></method_info>
 			<added_lines>133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testOneShotIteratorInitializerFails' parameters='self'>
 				<method_info nloc='20' complexity='4' token_count='148' nesting_level='1' start_line='169' end_line='196'></method_info>
 			<added_lines>169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testOneShotIteratorInitializerFails.consumer_thread' parameters=''>
 				<method_info nloc='3' complexity='1' token_count='22' nesting_level='3' start_line='186' end_line='188'></method_info>
 			<added_lines>186,187,188</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>23,29,168,197</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\core\kernels\iterator_ops.cc' new_name='tensorflow\core\kernels\iterator_ops.cc'>
 		<file_info nloc='330' complexity='44' token_count='2341'></file_info>
 		<method name='tensorflow::OneShotIteratorOp::Compute' parameters='ctx'>
 				<method_info nloc='68' complexity='5' token_count='557' nesting_level='3' start_line='193' end_line='276'></method_info>
 			<added_lines>200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,222,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276</added_lines>
 			<deleted_lines>193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,272,273,274,275</deleted_lines>
 		</method>
 		<method name='tensorflow::OneShotIteratorOp::Init' parameters='ctx,done'>
 				<method_info nloc='19' complexity='4' token_count='127' nesting_level='3' start_line='226' end_line='246'></method_info>
 			<added_lines>226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246</added_lines>
 			<deleted_lines>226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246</deleted_lines>
 		</method>
 		<method name='tensorflow::OneShotIteratorOp::OneShotIteratorOp' parameters='ctx'>
 				<method_info nloc='19' complexity='1' token_count='146' nesting_level='3' start_line='166' end_line='185'></method_info>
 			<added_lines>166,167,168,169,170,171,172,173,174,180,181,182</added_lines>
 			<deleted_lines>171,172</deleted_lines>
 		</method>
 		<method name='tensorflow::OneShotIteratorOp::ComputeAsync' parameters='ctx,done'>
 				<method_info nloc='15' complexity='4' token_count='100' nesting_level='3' start_line='206' end_line='223'></method_info>
 			<added_lines>206,207,208,209,210,211,212,213,214,215,216,217,218,222</added_lines>
 			<deleted_lines>206,207,208,209,210,211,212,213,214,217,218,219,220,221,222,223</deleted_lines>
 		</method>
 		<method name='tensorflow::OneShotIteratorOp::ProduceOutput' parameters='ctx,done'>
 				<method_info nloc='17' complexity='2' token_count='107' nesting_level='3' start_line='321' end_line='337'></method_info>
 			<added_lines>321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::OneShotIteratorOp::TryInit' parameters='ctx,iterator,cinfo'>
 				<method_info nloc='53' complexity='4' token_count='473' nesting_level='3' start_line='248' end_line='319'></method_info>
 			<added_lines>248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319</added_lines>
 			<deleted_lines>248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,272,273,274,275,279,285</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>23,164,320,338,339,343,344,347,348,349,350,351,352</added_lines>
 			<deleted_lines>163,165,190,191,192</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
