<bug_data>
<bug id='11948' author='riklopfer' open_date='2017-08-01T18:52:55Z' closed_time='2018-02-03T01:35:39Z'>
 	<summary>Memory leak in Java API when using GPU</summary>
 	<description>
 &lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;
 
 
 Custom code: https://github.com/riklopfer/TensorflowJavaGpuMemoryTest
 OS: CentOS 7
 TensorFlow installed from (source or binary): binary
 TensorFlow version (use command below): n/a
 Python version: n/a
 Bazel version (if compiling from source): n/a
 CUDA/cuDNN version: 8.0
 GPU model and memory: GeForce GTX 1080
 Exact command to reproduce: see https://github.com/riklopfer/TensorflowJavaGpuMemoryTest
 
 &lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;
 
 Main memory on the machine is continuously consumed when running on the GPU. Memory consumption hovers around 600M when running on the CPU.
 &lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;
 
 see: &lt;denchmark-link:https://github.com/riklopfer/TensorflowJavaGpuMemoryTest&gt;https://github.com/riklopfer/TensorflowJavaGpuMemoryTest&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='riklopfer' date='2017-08-02T18:00:17Z'>
 		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
  could you please take a look at this.
 		</comment>
 		<comment id='2' author='riklopfer' date='2017-08-29T19:10:22Z'>
 		Sample log output fwiw,
 &lt;denchmark-code&gt;2017-08-29 14:30:27.963729: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-29 14:30:27.963779: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-29 14:30:27.963788: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-29 14:30:27.963795: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-29 14:30:27.963802: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-29 14:30:29.569904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
 name: GeForce GTX 1080
 major: 6 minor: 1 memoryClockRate (GHz) 1.7335
 pciBusID 0000:01:00.0
 Total memory: 7.92GiB
 Free memory: 7.81GiB
 2017-08-29 14:30:29.569957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
 2017-08-29 14:30:29.569965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
 2017-08-29 14:30:29.569981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='3' author='riklopfer' date='2017-08-30T16:04:36Z'>
 		I've added &lt;denchmark-link:http://valgrind.org/info/tools.html#memcheck&gt;valgrind&lt;/denchmark-link&gt;
  output to the test repository: &lt;denchmark-link:https://github.com/riklopfer/TensorflowJavaGpuMemoryTest/blob/master/valgrind.out&gt;https://github.com/riklopfer/TensorflowJavaGpuMemoryTest/blob/master/valgrind.out&lt;/denchmark-link&gt;
 
 I'm not really familiar with this tool, but it seems like it would be useful. The summary makes me think that there definitely is a leak somewhere
 &lt;denchmark-code&gt;==28997== LEAK SUMMARY:
 ==28997==    definitely lost: 257,022 bytes in 1,028 blocks
 ==28997==    indirectly lost: 6,840 bytes in 15 blocks
 ==28997==      possibly lost: 61,716,234 bytes in 14,975 blocks
 ==28997==    still reachable: 397,427,506 bytes in 261,680 blocks
 ==28997==                       of which reachable via heuristic:
 ==28997==                         stdstring          : 2,034,837 bytes in 43,856 blocks
 ==28997==                         newarray           : 22,536 bytes in 1 blocks
 ==28997==         suppressed: 0 bytes in 0 blocks
 ==28997== Reachable blocks (those to which a pointer was found) are not shown.
 ==28997== To see them, rerun with: --leak-check=full --show-leak-kinds=all
 ==28997== 
 ==28997== For counts of detected and suppressed errors, rerun with: -v
 ==28997== ERROR SUMMARY: 1011246 errors from 460 contexts (suppressed: 0 from 0)
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='4' author='riklopfer' date='2017-08-30T16:45:52Z'>
 		&lt;denchmark-link:https://github.com/riklopfer&gt;@riklopfer&lt;/denchmark-link&gt;
  : Thanks very much for getting that information across. Unfortunately not a lot struck out to me.
 I did see 32 bytes of leaks from graph construction, which I will fix, but that happens once - not in a loop so won't explain the increasing usage over time.
 		</comment>
 		<comment id='5' author='riklopfer' date='2017-08-30T23:12:20Z'>
 		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
  thanks for the fixes. Were you able to reproduce the issue of ever-increasing memory consumption? Any idea what the next steps might be?
 		</comment>
 		<comment id='6' author='riklopfer' date='2017-08-31T19:01:20Z'>
 		Updating CUDA and Nvidia drivers seems to have greatly mitigated the problem for me. I added &lt;denchmark-link:https://github.com/riklopfer/TensorflowJavaGpuMemoryTest/blob/master/updated-valgrind.out&gt;updated valgrind output&lt;/denchmark-link&gt;
  to the test repo.
 		</comment>
 		<comment id='7' author='riklopfer' date='2017-09-01T17:06:40Z'>
 		Thanks for the update &lt;denchmark-link:https://github.com/riklopfer&gt;@riklopfer&lt;/denchmark-link&gt;
 
 Sampling the latest output, I'm not sure if there are false positives or actual leaks (e.g., many leaks are reported in , which IIUC has nothing to do with TensorFlow, it's just JVM initialization.
 When you say "greatly mitigated", are you still seeing a monotonic increase in memory usage over time, or does it stabilize?
 		</comment>
 		<comment id='8' author='riklopfer' date='2017-09-06T15:01:08Z'>
 		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
  I no longer see monotonic increase in memory consumption when running my the small test  in the linked repo. However, when I run a longer, more complicated graph on the GPU, it is killed by the OOM killer. I wasn't able to get a valgrind dump for that process. When I have time, I will try increasing the complexity of the test graph until it shows the problem again (or not).
 		</comment>
 		<comment id='9' author='riklopfer' date='2017-12-20T01:17:05Z'>
 		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue? Please update the label and/or status accordingly.
 		</comment>
 		<comment id='10' author='riklopfer' date='2017-12-20T15:55:08Z'>
 		Running with 1.4.0, I still see a slow, monotonic increase in memory consumption. I haven't had a chance to attempt to minimally reproduce the issue.
 		</comment>
 		<comment id='11' author='riklopfer' date='2018-01-04T19:05:47Z'>
 		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue? Please update the label and/or status accordingly.
 		</comment>
 		<comment id='12' author='riklopfer' date='2018-01-23T23:18:11Z'>
 		The original poster has replied to this issue after the stat:awaiting response label was applied.
 		</comment>
 		<comment id='13' author='riklopfer' date='2018-02-03T01:35:39Z'>
 		Closing since the original issue has been fixed. Please file another ticket with a repro if you can. Thanks!
 		</comment>
 	</comments>
 </bug>
<commit id='03d310cc61a864600d24977f73138e643659986c' author='Asim Shankar' date='2017-08-30 12:35:06-07:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='0.5'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\java\src\main\native\operation_builder_jni.cc' new_name='tensorflow\java\src\main\native\operation_builder_jni.cc'>
 		<file_info nloc='213' complexity='43' token_count='1791'></file_info>
 		<method name='Java_org_tensorflow_OperationBuilder_finish' parameters='env,clazz,handle'>
 				<method_info nloc='13' complexity='3' token_count='86' nesting_level='0' start_line='71' end_line='83'></method_info>
 			<added_lines>78,81</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='Java_org_tensorflow_OperationBuilder_setAttrTensorList' parameters='env,clazz,handle,name,tensor_handles'>
 				<method_info nloc='22' complexity='5' token_count='207' nesting_level='0' start_line='220' end_line='242'></method_info>
 			<added_lines>240</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='Java_org_tensorflow_OperationBuilder_setAttrStringList' parameters='env,object,handle,name,values'>
 				<method_info nloc='27' complexity='4' token_count='293' nesting_level='0' start_line='265' end_line='292'></method_info>
 			<added_lines>266,267,275,276,280,281</added_lines>
 			<deleted_lines>270,271,275</deleted_lines>
 		</method>
 		<method name='Java_org_tensorflow_OperationBuilder_setAttrTensor' parameters='env,clazz,handle,name,tensor_handle'>
 				<method_info nloc='14' complexity='3' token_count='112' nesting_level='0' start_line='205' end_line='218'></method_info>
 			<added_lines>216</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>262</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
