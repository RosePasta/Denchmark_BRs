<bug_data>
<bug id='39462' author='ben-arnao' open_date='2020-05-12T15:20:32Z' closed_time='2020-11-13T04:47:47Z'>
 	<summary>ReduceLROnPlateau keeps executing lr reduction block of code after min_lr has been reached</summary>
 	<description>
 Please make sure that this is a bug. As per our
 GitHub Policy,
 we only address code/doc bugs, performance issues, feature requests and
 build/installation issues on GitHub. tag:bug_template
 System information
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
 Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
 TensorFlow installed from (source or binary): through pip
 TensorFlow version (use command below): 2.2
 Python version: 3.7
 Bazel version (if compiling from source): n/a
 GCC/Compiler version (if compiling from source): n/a
 CUDA/cuDNN version: n/a
 GPU model and memory: n/a
 
 You can collect some of this information using our environment capture
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;
 
 You can also obtain the TensorFlow version with:
 
 TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
 TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"
 
 Describe the current behavior
 ReduceLR will execute the part of the code that reduces LR even if lr "equals" min_lr. While this is not a problem if we are just dealing with LR since the value will technically never go below min_lr, it is an issue if you are trying to do any other execution in this block of code (ie. weight decay).
 Given that there is a min check for this block of code, i assume it was not intended for us to enter this block of code if min_lr has already been achieved. Either get rid of the min check if we don't care about re-executing this code for no reason, or make sure this block of code is not executed if lr is at min-lr.
 This issue clearly seems to be a round/precision related issue where
 we set our lr K.set_value(self.model.optimizer.lr, new_lr)
 But then next iteration we fetch the lr
 old_lr = float(K.get_value(self.model.optimizer.lr))
 and get a slightly different value so that
 if old_lr &gt; self.min_lr:
 does not work.
 So yes in a way this does not affect default code, and it only matter if we do custom code, but i still think this is a bug that really shouldn't happen.
 Describe the expected behavior
 Code block that is only supposed to execute if lr does not equal min_lr does not execute if lr equals min_lr
 Standalone code to reproduce the issue
 Provide a reproducible test case that is the bare minimum necessary to generate
 the problem. If possible, please share a link to Colab/Jupyter/any notebook.
 &lt;denchmark-code&gt;x = np.random.normal(size=10)
 y = np.random.normal(size=10)
 
 model = Sequential()
 model.add(Dense(1))
 
 reduce_lr = ReduceLROnPlateau(monitor='loss',
                               min_delta=0.01,
                               patience=3,
                               min_lr=0.001,
                               verbose=2)
 
 model.compile(loss='mse', optimizer=SGD(0.01))
 
 history = model.fit(x,
                     y,
                     epochs=25,
                     verbose=2,
                     shuffle=True,
                     batch_size=1,
                     callbacks=[reduce_lr])
 &lt;/denchmark-code&gt;
 
 Other info / logs Include any logs or source code that would be helpful to
 diagnose the problem. If including tracebacks, please include the full
 traceback. Large logs and files should be attached.
 	</description>
 	<comments>
 		<comment id='1' author='ben-arnao' date='2020-05-13T07:48:15Z'>
 		&lt;denchmark-link:https://github.com/ben-arnao&gt;@ben-arnao&lt;/denchmark-link&gt;
 
 I have tried in colab with TF version 2.2 and i am seeing the error message ().Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/0b2846d4aec8d371afb67e3da83caf17/untitled885.ipynb&gt;here.&lt;/denchmark-link&gt;
 .Thanks!
 		</comment>
 		<comment id='2' author='ben-arnao' date='2020-05-18T14:34:31Z'>
 		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 
 I'm unsure of the way the imports were done in your colab but the code below works and does reproduce this behavior for me...
 &lt;denchmark-code&gt;import numpy as np
 from tensorflow.keras.models import Sequential
 from tensorflow.keras.layers import Dense
 from tensorflow.keras.callbacks import ReduceLROnPlateau
 from tensorflow.keras.optimizers import SGD
 
 x = np.random.normal(size=10)
 y = np.random.normal(size=10)
 
 model = Sequential([Dense(1)])
 
 
 reduce_lr = ReduceLROnPlateau(monitor='loss',
                               min_delta=0.01,
                               patience=3,
                               min_lr=0.001,
                               verbose=2)
 
 model.compile(loss='mse', optimizer=SGD(0.01))
 
 history = model.fit(x,
                     y,
                     epochs=50,
                     verbose=2,
                     shuffle=True,
                     batch_size=1,
                     callbacks=[reduce_lr])
 &lt;/denchmark-code&gt;
 
 Please see &lt;denchmark-link:https://colab.research.google.com/gist/ben-arnao/a241db4603230a60c4425c1bb9852d95/untitled885.ipynb&gt;here&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='ben-arnao' date='2020-05-19T07:33:45Z'>
 		I have tried in colab with TF version 2.2.0 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/3201a4bdecc82391871b4344c79baed2/untitled906.ipynb&gt;here&lt;/denchmark-link&gt;
 . Thanks!
 		</comment>
 		<comment id='4' author='ben-arnao' date='2020-11-13T04:47:49Z'>
 		Are you satisfied with the resolution of your issue?
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39462&gt;Yes&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39462&gt;No&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='b3461c38fd09abc6f31f69ade9bc632fabbdb73a' author='Ben Arnao' date='2020-05-20 14:04:54-04:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\python\keras\callbacks.py' new_name='tensorflow\python\keras\callbacks.py'>
 		<file_info nloc='1705' complexity='414' token_count='9360'></file_info>
 		<method name='on_epoch_end' parameters='self,epoch,logs'>
 				<method_info nloc='28' complexity='9' token_count='226' nesting_level='1' start_line='2244' end_line='2273'></method_info>
 			<added_lines>2264,2265</added_lines>
 			<deleted_lines>2264,2265</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
