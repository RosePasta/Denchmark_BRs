<bug_data>
<bug id='38906' author='jakublipinski' open_date='2020-04-26T08:42:01Z' closed_time='2020-06-05T15:53:21Z'>
 	<summary>MemoryOptimizer produces broken graph with AlreadyExistsError exception while running GRU layer on Tensorflow 2.2.0rc_3</summary>
 	<description>
 System information
 
 Custom model built using keras
 MacBook Pro, 8-Core Intel Core i9, macOS Catalina 10.15.4
 TensorFlow installed from pip in virtual environment
 TensorFlow v2.2.0-rc2-77-gaad398b5e9 2.2.0-rc3
 Python 3.7.5
 Running on CPU
 
 Describe the current behavior
 The code snippet listed below outputs multiple tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource warnings and finally exists with tensorflow.python.framework.errors_impl.AlreadyExistsError exception.
 Note: the code works correctly if the GRU layer size is decreased from 320 to 80. It also works if TensorFlow is downgraded to version 2.0.1.
 The issue is related to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/23780&gt;#23780&lt;/denchmark-link&gt;
  issue reported in 2018. This issue offers code to reproduce it and occurs on the latest version of TensorFlow.
 Describe the expected behavior
 The code should work without exception.
 Standalone code to reproduce the issue
 import numpy as np
 
 from tensorflow.keras.models import Sequential
 from tensorflow.keras.layers import Dense, Flatten, Bidirectional, GRU
 from tensorflow.keras.layers import Conv1D, MaxPooling1D
 
 x = np.random.rand(1000, 401, 17)
 y = np.random.choice([0, 1], size=(1000, 301))
 
 model = Sequential()
 model.add(Conv1D(filters=320, kernel_size=26, activation='relu', input_shape=(401, x.shape[2])))
 model.add(MaxPooling1D(pool_size=13, strides=13))
 model.add(Bidirectional(GRU(320, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))
 model.add(Flatten())
 model.add(Dense(2000, activation="relu"))
 model.add(Dense(301, activation="sigmoid"))
 model.compile(loss="binary_crossentropy", optimizer="rmsprop", metrics=["accuracy"])
 
 model.summary()
 
 model.fit(x=x, y=y, epochs=1, verbose=1)
 The Google Colab notebook is available &lt;denchmark-link:https://colab.research.google.com/drive/1YohTA6Hxi3H6aOQgFj34C0tKErW2V_rL&gt;here&lt;/denchmark-link&gt;
 . The error is reproducible.
 Other info / logs
 The code above generates following output:
 &lt;denchmark-code&gt;Model: "sequential"
 _________________________________________________________________
 Layer (type)                 Output Shape              Param #   
 =================================================================
 conv1d (Conv1D)              (None, 376, 320)          141760    
 _________________________________________________________________
 max_pooling1d (MaxPooling1D) (None, 28, 320)           0         
 _________________________________________________________________
 bidirectional (Bidirectional (None, 28, 640)           1232640   
 _________________________________________________________________
 flatten (Flatten)            (None, 17920)             0         
 _________________________________________________________________
 dense (Dense)                (None, 2000)              35842000  
 _________________________________________________________________
 dense_1 (Dense)              (None, 301)               602301    
 =================================================================
 Total params: 37,818,701
 Trainable params: 37,818,701
 Non-trainable params: 0
 _________________________________________________________________
 2020-04-26 10:19:57.349570: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
 2020-04-26 10:19:57.363399: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_7/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
 2020-04-26 10:19:57.377361: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
 ... (repeated multiple times) ...
 2020-04-26 10:19:57.677304: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/gradient_tape/sequential/bidirectional/forward_gru/while/sequential/bidirectional/forward_gru/while_grad/body/_577/gradients/AddN_7/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
 Traceback (most recent call last):
   File "alreadyexists_err.py", line 21, in &lt;module&gt;
     model.fit(x=x, y=y, epochs=1, verbose=1)
   File "venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 66, in _method_wrapper
     return method(self, *args, **kwargs)
   File "venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 851, in fit
     tmp_logs = train_function(iterator)
   File "venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
     result = self._call(*args, **kwds)
   File "venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 644, in _call
     return self._stateless_fn(*args, **kwds)
   File "venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 2420, in __call__
     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   File "venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 1665, in _filtered_call
     self.captured_inputs)
   File "venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 1746, in _call_flat
     ctx, args, cancellation_manager=cancellation_manager))
   File "venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 598, in call
     ctx=ctx)
   File "venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
     inputs, attrs, num_outputs)
 tensorflow.python.framework.errors_impl.AlreadyExistsError:  Resource __per_step_0/gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
 	 [[{{node gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_8/tmp_var}}]] [Op:__inference_train_function_7551]
 
 Function call stack:
 train_function
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='jakublipinski' date='2020-04-27T09:46:15Z'>
 		I have tried on colab with TF version 2.2.0-rc3 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/8652e1dae44721b792b47b6e9e45052c/untitled828.ipynb&gt;here&lt;/denchmark-link&gt;
 .Thanks!
 		</comment>
 		<comment id='2' author='jakublipinski' date='2020-04-27T16:11:55Z'>
 		Adding &lt;denchmark-link:https://github.com/saxenasaurabh&gt;@saxenasaurabh&lt;/denchmark-link&gt;
  who works on core ops to provide more information about while loop.
 		</comment>
 		<comment id='3' author='jakublipinski' date='2020-04-27T16:26:33Z'>
 		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
  mentioned &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/23780#issuecomment-498334346&gt;here&lt;/denchmark-link&gt;
  that this may be due to a bug in grappler generating non-unique names. &lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/ezhulenev&gt;@ezhulenev&lt;/denchmark-link&gt;
  do you know if this was fixed?
 		</comment>
 		<comment id='4' author='jakublipinski' date='2020-04-28T11:05:30Z'>
 		I dug a bit further into this issue. This is what I found:
 It's indeed an optimizer issue, namely the ScopedAllocatorOptimizer optimizer.
 Interestingly, you cannot turn this optimizer off using tf.config.optimizer.set_experimental_options(). The scoped_allocator_optimization key is treated as Bool at:
 
 
 
 tensorflow/tensorflow/python/eager/context.py
 
 
          Line 958
       in
       109fd38
 
 
 
 
 
 
  rewriter_toggle("scoped_allocator_optimization") 
 
 
 
 
 
 while it's interpreted as int at:
 
 
 
 tensorflow/tensorflow/core/grappler/optimizers/meta_optimizer.cc
 
 
          Line 292
       in
       8e0eecc
 
 
 
 
 
 
  if (cfg_.scoped_allocator_optimization()) { 
 
 
 
 
 
 Should I file another issue for that?
 		</comment>
 		<comment id='5' author='jakublipinski' date='2020-04-29T16:08:15Z'>
 		Let me rename this bug to pointing to ScopedAllocatorOptimizer.
 		</comment>
 		<comment id='6' author='jakublipinski' date='2020-06-05T15:53:21Z'>
 		Verified this is fixed with latest tf-nightly.
 		</comment>
 		<comment id='7' author='jakublipinski' date='2020-06-05T15:53:23Z'>
 		Are you satisfied with the resolution of your issue?
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38906&gt;Yes&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38906&gt;No&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='80a93674eafc224a45cbe96c65e993e9735634a3' author='Eugene Zhulenev' date='2020-06-04 09:42:10-07:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.9090909090909091'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\core\kernels\variable_ops.cc' new_name='tensorflow\core\kernels\variable_ops.cc'>
 		<file_info nloc='155' complexity='24' token_count='1156'></file_info>
 		<method name='tensorflow::TemporaryVariableName' parameters='var_name,control_frame'>
 				<method_info nloc='9' complexity='3' token_count='53' nesting_level='2' start_line='32' end_line='40'></method_info>
 			<added_lines>32,33,34,35,36,37,38,39,40</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::TemporaryVariableOp::Compute' parameters='context'>
 				<method_info nloc='20' complexity='3' token_count='175' nesting_level='2' start_line='106' end_line='125'></method_info>
 			<added_lines>110,114,119</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::DestroyTemporaryVariableOp::Compute' parameters='context'>
 				<method_info nloc='15' complexity='2' token_count='132' nesting_level='2' start_line='154' end_line='171'></method_info>
 			<added_lines>163,166</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>19,23,28,29,30,31,41,42,43</added_lines>
 			<deleted_lines>95,100,146</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
