<bug_data>
<bug id='22039' author='gulingfengze' open_date='2018-09-04T03:49:40Z' closed_time='2020-07-28T12:32:01Z'>
 	<summary>Session.run () takes a long time</summary>
 	<description>
 &lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;
 
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04
 Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A
 TensorFlow installed from (source or binary): source
 TensorFlow version (use command below):1.9.0
 Python version:3.6
 Bazel version (if compiling from source):N/A
 GCC/Compiler version (if compiling from source):6.4.0
 CUDA/cuDNN version:9.0 / 7.0
 GPU model and memory:GeForce GTX960
 Exact command to reproduce:N/A
 
 &lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;
 
 Each time tensorflow performs session.run() for target detection, the detection time of the first image is very long (including some initialization operations, of course), while the detection time of other images is normal. Suppose I detect the image under a certain path (for example, there are ten images), the time of detecting the first image is relatively long, and the remaining nine images are relatively short (basically consistent). However, my operation in practical application is as follows: the session.run() is called every once in a while to detect a picture. I hope that the detection time after the first one is normal except for the long time. However, through my test (guess), after exiting the loop logic of detection, tensorflow redid a series of initialization operations the next time the detection was done, which puzzled me.
 With other frameworks, such as mxnet, initial detection takes longer. And then the detection time is normal, as if it's not doing some initialization anymore. I thought, could tensorflow do the same thing?
 &lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;
 
 2018-09-04 14:48:59.111510: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.57GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
 time：5627.940655ms
 0.9999423027038574
 time：657.650471ms
 0.9996843338012695
 time：676.565170ms
 0.9722122550010681
 0.6320008635520935
 time：667.881966ms
 0.996504545211792
 	</description>
 	<comments>
 		<comment id='1' author='gulingfengze' date='2018-09-05T00:44:11Z'>
 		I met a similar problem. It seems to be caused by some lazy operations. That means some operations will not be executed until the graph actually runs.
 		</comment>
 		<comment id='2' author='gulingfengze' date='2018-09-06T02:39:19Z'>
 		&lt;denchmark-link:https://github.com/bignamehyp&gt;@bignamehyp&lt;/denchmark-link&gt;
  Is there a way to solve this problem?
 		</comment>
 		<comment id='3' author='gulingfengze' date='2019-02-13T21:54:31Z'>
 		&lt;denchmark-link:https://github.com/gulingfengze&gt;@gulingfengze&lt;/denchmark-link&gt;
  is this still an issue? Could you load TF 1.12 (stable) or latest version and check whether the issue persists? It is will be good if you can share a simplified code to reproduce the issue. If it was solved by newer version, please close the issue. Thanks!
 		</comment>
 		<comment id='4' author='gulingfengze' date='2019-02-16T08:18:08Z'>
 		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
  The latest version still has this problem, and my guess is that the program did some initialization like gpu at the beginning of execution.
 		</comment>
 		<comment id='5' author='gulingfengze' date='2019-02-19T17:49:28Z'>
 		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
  I work on XLA, so this is outside of my area of ownership.
 		</comment>
 		<comment id='6' author='gulingfengze' date='2019-02-19T17:50:00Z'>
 		
 my guess is that the program did some initialization like gpu at the beginning of execution.
 
 Quite possibly.  To address this, when you run configure.py, you need to ensure that you tell TF to build for sm_XY corresponding to your machine's GPU.
 		</comment>
 		<comment id='7' author='gulingfengze' date='2020-07-14T11:05:35Z'>
 		&lt;denchmark-link:https://github.com/gulingfengze&gt;@gulingfengze&lt;/denchmark-link&gt;
 
 Please confirm if this is still an issue, or if possible use later stable versions of tf and let us know.
 		</comment>
 		<comment id='8' author='gulingfengze' date='2020-07-21T11:52:04Z'>
 		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
 		</comment>
 		<comment id='9' author='gulingfengze' date='2020-07-28T12:31:58Z'>
 		Closing as stale. Please reopen if you'd like to work on this further.
 		</comment>
 		<comment id='10' author='gulingfengze' date='2020-07-28T12:32:03Z'>
 		Are you satisfied with the resolution of your issue?
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22039&gt;Yes&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22039&gt;No&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='59166604c26b8ffde742389fcd99c8090bf8ec04' author='Feng Liu' date='2019-12-19 14:36:01-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\compiler\mlir\lite\python\graphdef_to_tfl_flatbuffer.cc' new_name='tensorflow\compiler\mlir\lite\python\graphdef_to_tfl_flatbuffer.cc'>
 		<file_info nloc='227' complexity='38' token_count='1402'></file_info>
 		<method name='tensorflow::ConvertGraphDefToTFLiteFlatBuffer' parameters='model_flags,toco_flags,debug_info,input,result'>
 				<method_info nloc='93' complexity='11' token_count='720' nesting_level='1' start_line='169' end_line='289'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>280</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
