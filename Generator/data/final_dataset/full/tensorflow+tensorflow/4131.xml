<bug_data>
<bug id='4131' author='pronobis' open_date='2016-08-31T17:26:25Z' closed_time='2016-09-08T16:51:24Z'>
 	<summary>reduce_max and maximum give different results for negative infinity</summary>
 	<description>
 Using tf.maximum with negative inf inputs as follows:
 &lt;denchmark-code&gt;tf.maximum(-math.inf, -math.inf).eval()
 &lt;/denchmark-code&gt;
 
 gives the expected result -inf
 However, tf.reduce_max, on the same inputs:
 &lt;denchmark-code&gt;tf.reduce_max([-math.inf, -math.inf]).eval()
 &lt;/denchmark-code&gt;
 
 gives: -3.40282e+38 which is the min float32.
 For positive infinity inputs, both functions result in inf.
 &lt;denchmark-h:h3&gt;What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?&lt;/denchmark-h&gt;
 
 I posted this as an SO question first:
 &lt;denchmark-link:http://stackoverflow.com/questions/39211546/bug-in-tensorflow-reduce-max-for-negative-infinity&gt;http://stackoverflow.com/questions/39211546/bug-in-tensorflow-reduce-max-for-negative-infinity&lt;/denchmark-link&gt;
 
 &lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;
 
 Operating System: Ubuntu 16.04
 Installed version of CUDA and cuDNN:
 &lt;denchmark-code&gt;-rw-r--r-- 1 root root   560184 May 25 17:48 /usr/local/cuda-8.0/lib64/libcudadevrt.a
 lrwxrwxrwx 1 root root       16 May 25 17:52 /usr/local/cuda-8.0/lib64/libcudart.so -&gt; libcudart.so.8.0
 lrwxrwxrwx 1 root root       19 May 25 17:52 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.27
 -rw-r--r-- 1 root root   394472 May 25 17:48 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27
 -rw-r--r-- 1 root root   737516 May 25 17:48 /usr/local/cuda-8.0/lib64/libcudart_static.a
 lrwxrwxrwx 1 root root       13 Jul  4 16:22 /usr/local/cuda-8.0/lib64/libcudnn.so -&gt; libcudnn.so.5
 lrwxrwxrwx 1 root root       17 Jul  4 16:22 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -&gt; libcudnn.so.5.0.5
 -rwxr-xr-x 1 root root 78065952 Jul  4 16:22 /usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5
 -rw-r--r-- 1 root root 68709594 Jul  4 16:22 /usr/local/cuda-8.0/lib64/libcudnn_static.a
 
 &lt;/denchmark-code&gt;
 
 Installed from source.
 Commit hash: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/3cb39956e622b322e43547cf2b6e337020643f21&gt;3cb3995&lt;/denchmark-link&gt;
 
 Bazel:
 &lt;denchmark-code&gt;Build label: 0.3.0
 Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
 Build time: Fri Jun 10 11:38:23 2016 (1465558703)
 Build timestamp: 1465558703
 Build timestamp as int: 1465558703
 
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='pronobis' date='2016-08-31T23:51:56Z'>
 		&lt;denchmark-link:https://github.com/pronobis&gt;@pronobis&lt;/denchmark-link&gt;
  Thanks for the bug report. I have fixed the bug internally at Google and in the open source Eigen repository (&lt;denchmark-link:https://bitbucket.org/eigen/eigen/commits/741b932c41cebff49c4419b7e0ef9910ef1b2907&gt;https://bitbucket.org/eigen/eigen/commits/741b932c41cebff49c4419b7e0ef9910ef1b2907&lt;/denchmark-link&gt;
 ). We will have to wait until a few unrelated issues are resolved in Eigen before pushing the fix to open source TensorFlow. Stay tuned! :-)
 		</comment>
 		<comment id='2' author='pronobis' date='2016-09-03T01:33:03Z'>
 		&lt;denchmark-link:https://github.com/pronobis&gt;@pronobis&lt;/denchmark-link&gt;
  Update: The issues in Eigen have been resolved and the fix for this issue will be pushed out on Monday.
 		</comment>
 		<comment id='3' author='pronobis' date='2016-09-05T00:50:24Z'>
 		Great! Thanks!
 		</comment>
 	</comments>
 </bug>
<commit id='fadc1f3c869c15b1890221bb6dfb0f7bd0f7c23d' author='Benoit Steiner' date='2016-09-02 16:17:43-07:00'>
 	<dmm_unit complexity='0.0' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\core\kernels\constant_op_gpu.cu.cc' new_name='tensorflow\core\kernels\constant_op_gpu.cu.cc'>
 		<file_info nloc='58' complexity='6' token_count='348'></file_info>
 		<method name='Eigen::internal::scalar_const_op::packetOp' parameters='Index,Index'>
 				<method_info nloc='3' complexity='1' token_count='23' nesting_level='3' start_line='48' end_line='50'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>48</deleted_lines>
 		</method>
 		<method name='Eigen::internal::scalar_const_op::packetOp' parameters=''>
 				<method_info nloc='3' complexity='1' token_count='18' nesting_level='3' start_line='45' end_line='47'></method_info>
 			<added_lines>45</added_lines>
 			<deleted_lines>46,47</deleted_lines>
 		</method>
 		<method name='Eigen::internal::scalar_const_op::operator ( )' parameters=''>
 				<method_info nloc='3' complexity='1' token_count='12' nesting_level='3' start_line='40' end_line='42'></method_info>
 			<added_lines>40</added_lines>
 			<deleted_lines>40,41,42</deleted_lines>
 		</method>
 		<method name='Eigen::internal::scalar_const_op::operator ( )' parameters='Index,Index'>
 				<method_info nloc='4' complexity='1' token_count='17' nesting_level='3' start_line='41' end_line='44'></method_info>
 			<added_lines>44</added_lines>
 			<deleted_lines>41,42</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\workspace.bzl' new_name='tensorflow\workspace.bzl'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>15,16</added_lines>
 			<deleted_lines>15,16</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
