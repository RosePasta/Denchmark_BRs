<bug_data>
<bug id='9136' author='jdonier' open_date='2017-04-11T12:47:39Z' closed_time='2017-04-20T20:42:34Z'>
 	<summary>Issues when using Queues + tf.train.Server</summary>
 	<description>
 NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.
 &lt;denchmark-h:h3&gt;You must complete this information or else your issue will be closed&lt;/denchmark-h&gt;
 
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?: Yes
 TensorFlow installed from (source or binary)?: binary
 TensorFlow version: 1.0.0 CPU / 1.0.1 (CPU and GPU enabled) / 1.1.0rc1 (CPU)
 Bazel version (if compiling from source):
 CUDA/cuDNN version: N/A
 GPU Model and Memory: N/A
 Exact command to reproduce: cf below.
 
 This problem has been reproduced on both Linux and various Mac OS machines.
 &lt;denchmark-h:h3&gt;Describe the problem clearly&lt;/denchmark-h&gt;
 
 We seem to experience issues when using both queues + tf.train.Server. When executed in a simple python 3.5.3 console, the following script hangs:
 &lt;denchmark-code&gt;import tensorflow as tf
 import time
 
 cluster = tf.train.ClusterSpec({"cpu1" : ['localhost:2222']})
 server = tf.train.Server(cluster, job_name="cpu1", task_index=0)
 
 with tf.Graph().as_default() as graph:
     # Queue
     input_queue = tf.train.input_producer(tf.constant([0.], dtype=tf.float32))
 
     # Useless variable
     variable = tf.Variable(1., dtype=tf.float32, trainable=False, name="variable")
 
     # Session and queue runners
     session = tf.Session(target=server.target)
     session.run(tf.global_variables_initializer())
     tf.train.start_queue_runners(session)
 
 print(session.run(variable))  # this works
 print(session.run(tf.assign(variable, 2)))  # this also works, but only if called directly
 
 # any pause between creating and running the session breaks it
 time.sleep(1)
 
 print(session.run(variable))  # retrieving a variable still works, but...
 print(session.run(tf.assign(variable, 3)))  # ... assigning a variable will make the program hang.
 &lt;/denchmark-code&gt;
 
 It outputs:
 &lt;denchmark-code&gt;1
 2
 2
 &lt;/denchmark-code&gt;
 
 and then hangs forever. The problem vanishes when either commenting the input_queue=... line, or when writing session = tf.Session() instead of passing the server.target.
 The problems seems to happen not only with variable assignments, but also saving the model using tf.train.Saver().save(session, 'my_model') for instance (and possibly other operations). Note that reading a variable works fine.
 In the example script, the time.sleepcommand simulates a pause between creating the session and running it to set a variable. The same effect is achieved, for example, when splitting session creation and running code across two Jupyter notebook cells. When executing the whole code in one cell, it works fine.
 &lt;denchmark-h:h3&gt;Source Code / Logs&lt;/denchmark-h&gt;
 
 The source code to reproduce the problem is displayed above. I have attached a traceback using gdb, which shows that the program is hanging while trying to acquire a lock.
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/913097/tf-issue-gdb-bt.txt&gt;tf-issue-gdb-bt.txt&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/913102/tf-issue-gdb-stack-threads.txt&gt;tf-issue-gdb-stack-threads.txt&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='jdonier' date='2017-04-14T18:09:20Z'>
 		Thanks for the detailed report and stacktraces, this helps a lot and is much appreciated.
 &lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
  pointed out that we might have a bug when graphs are extended in a distributed session while some operations (in this case the enqueue operation) are in progress (See &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/87cdfafd44ff5e332fd820608783432fea83a4c9/tensorflow/core/distributed_runtime/master_session.cc#L1038&gt;master_session.cc:1038&lt;/denchmark-link&gt;
  - that code predates the queue runners).
 &lt;denchmark-link:https://github.com/suharshs&gt;@suharshs&lt;/denchmark-link&gt;
  : Would you have the bandwidth to look into that TODO?
 &lt;denchmark-link:https://github.com/jdonier&gt;@jdonier&lt;/denchmark-link&gt;
  : In the mean time, a workaround for you would be to ensure that the graph isn't modified after the queue runners are started. For example, your snippet above could be rewritten as:
 import tensorflow as tf
 import time
 
 cluster = tf.train.ClusterSpec({"cpu1" : ['localhost:2222']})
 server = tf.train.Server(cluster, job_name="cpu1", task_index=0)
 
 with tf.Graph().as_default() as graph:
     # Queue
     input_queue = tf.train.input_producer(tf.constant([0.], dtype=tf.float32))
 
     # Useless variable
     variable = tf.Variable(1., dtype=tf.float32, trainable=False, name="variable")
 
     # Session and queue runners
     session = tf.Session(target=server.target)
     session.run(tf.global_variables_initializer())
 
     # CHANGE FROM PREVIOUS SNIPPET: Assign operations
     assign2 = tf.assign(variable, 2)
     assign3 = tf.assign(variable, 3)
 
     tf.train.start_queue_runners(session)
 
 print(session.run(variable))
 print(session.run(assign2))
 
 # Freely sleep
 time.sleep(1)
 
 print(session.run(variable))
 print(session.run(assign3))
 FYI &lt;denchmark-link:https://github.com/jhseu&gt;@jhseu&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/saeta&gt;@saeta&lt;/denchmark-link&gt;
  who might like to know about this too.
 		</comment>
 		<comment id='2' author='jdonier' date='2017-04-14T18:44:28Z'>
 		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
  the reason why I want to modify the graph after the queue runners are started is to change some parameters during / after training (e.g. the training rate during training, or dropout rates between training and inference) so this needs to be done after the queue runners have been started. I guess I could define them as placeholders but it's a bit weird to have to feed these values for every computation...
 About the problem with model saving: I was creating a tf.train.Saver() at saving time, which was causing the problem, consistent with your explanation. It all works fine if I define it when I create the graph -- so thanks a lot!
 		</comment>
 		<comment id='3' author='jdonier' date='2017-04-18T23:59:21Z'>
 		I have a change coming soon that should fix this. (Thanks &lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
  for flagging!)
 		</comment>
 	</comments>
 </bug>
<commit id='1f210ad7c2a81fe27196dd1a85c9bb92f19bc94a' author='Brennan Saeta' date='2017-04-19 10:31:38-07:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\core\distributed_runtime\master_session.cc' new_name='tensorflow\core\distributed_runtime\master_session.cc'>
 		<file_info nloc='1132' complexity='204' token_count='8274'></file_info>
 		<method name='tensorflow::MasterSession::Create' parameters='graph_def'>
 				<method_info nloc='16' complexity='2' token_count='95' nesting_level='1' start_line='994' end_line='1011'></method_info>
 			<added_lines>1005,1006,1007,1008,1009</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::ReffedClientGraph::ProcessDeviceStats' parameters='ph,execution_state,ds,is_rpc'>
 				<method_info nloc='36' complexity='9' token_count='277' nesting_level='1' start_line='770' end_line='812'></method_info>
 			<added_lines>798,799</added_lines>
 			<deleted_lines>771,772,783</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::ReffedClientGraph::RunPartitions' parameters='env,step_id,execution_count,pss,call_opts,req,resp,cm,is_last_partial_run'>
 				<method_info nloc='135' complexity='31' token_count='1163' nesting_level='1' start_line='480' end_line='637'></method_info>
 			<added_lines>482</added_lines>
 			<deleted_lines>501,502</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::DoPartialRun' parameters='opts,req,resp'>
 				<method_info nloc='87' complexity='15' token_count='690' nesting_level='1' start_line='1201' end_line='1307'></method_info>
 			<added_lines>1268,1269,1270,1271,1272,1285,1286,1294</added_lines>
 			<deleted_lines>1292,1293,1306,1307</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::ReffedClientGraph::ReffedClientGraph' parameters='handle,bopts,cg,session_opts,stats_publisher_factory,execution_state,is_partial,worker_cache'>
 				<method_info nloc='18' complexity='2' token_count='132' nesting_level='2' start_line='60' end_line='80'></method_info>
 			<added_lines>76,77,78</added_lines>
 			<deleted_lines>76,77,78,79,80</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::ReffedClientGraph::ProcessStats' parameters='step_id,pss,ph,options,resp'>
 				<method_info nloc='39' complexity='12' token_count='274' nesting_level='1' start_line='706' end_line='749'></method_info>
 			<added_lines>706,707,708,709,710,722,728</added_lines>
 			<deleted_lines>726,727,728,729,741,747</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::DoRunWithLocalExecution' parameters='opts,req,resp'>
 				<method_info nloc='58' complexity='8' token_count='450' nesting_level='1' start_line='1309' end_line='1382'></method_info>
 			<added_lines>1353,1354,1359,1360</added_lines>
 			<deleted_lines>1316,1317,1376,1377,1378</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::ReffedClientGraph::RunPartitions' parameters='env,step_id,execution_count,execution_state,pss,call_opts,req,resp,cm,is_last_partial_run'>
 				<method_info nloc='136' complexity='31' token_count='1167' nesting_level='1' start_line='499' end_line='657'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>501,502</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::Extend' parameters='req,resp'>
 				<method_info nloc='27' complexity='4' token_count='147' nesting_level='1' start_line='1028' end_line='1064'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>1038,1039,1040,1041,1042,1043,1044,1045,1046</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::ReffedClientGraph::ProcessStats' parameters='step_id,pss,execution_state,ph,options,resp'>
 				<method_info nloc='38' complexity='12' token_count='282' nesting_level='1' start_line='726' end_line='768'></method_info>
 			<added_lines>728,752,763</added_lines>
 			<deleted_lines>726,727,728,729,741,747</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::ReffedClientGraph::ProcessDeviceStats' parameters='ph,ds,is_rpc'>
 				<method_info nloc='35' complexity='9' token_count='270' nesting_level='1' start_line='751' end_line='792'></method_info>
 			<added_lines>752,763</added_lines>
 			<deleted_lines>771,772,783</deleted_lines>
 		</method>
 		<method name='tensorflow::MasterSession::ReffedClientGraph::RetrieveLogs' parameters='step_id,ss'>
 				<method_info nloc='33' complexity='6' token_count='190' nesting_level='2' start_line='119' end_line='156'></method_info>
 			<added_lines>133,134,135</added_lines>
 			<deleted_lines>149,150</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>167,168</added_lines>
 			<deleted_lines>81,82,83,84,85,86,87,88,89,90,91,92,93,94,182,183,184,185,195,199,1023,1024,1308,1383,1384</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\core\distributed_runtime\master_session.h' new_name='tensorflow\core\distributed_runtime\master_session.h'>
 		<file_info nloc='95' complexity='2' token_count='583'></file_info>
 		<modified_lines>
 			<added_lines>119</added_lines>
 			<deleted_lines>119</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow\python\training\server_lib_test.py' new_name='tensorflow\python\training\server_lib_test.py'>
 		<file_info nloc='339' complexity='26' token_count='2555'></file_info>
 		<method name='testExtendAfterQueueRunners' parameters='self'>
 				<method_info nloc='11' complexity='1' token_count='102' nesting_level='1' start_line='230' end_line='242'></method_info>
 			<added_lines>230,231,232,233,234,235,236,237,238,239,240,241,242</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>37,38,243</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
