<bug_data>
<bug id='41674' author='dansitu' open_date='2020-07-23T20:04:14Z' closed_time='2020-07-25T00:19:47Z'>
 	<summary>TensorFlow Lite for Microcontrollers sigaborts with a MobileNetV2 alpha=0.1 model</summary>
 	<description>
 System information
 
 Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
 OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.5, Linux
 GCC/Compiler version (if compiling from source): Apple clang version 11.0.3 (clang-1103.0.32.62) c++1
 
 Describe the current behavior
 I am using TensorFlow Lite for Microcontrollers at commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/4f69f62c61ecf3cd23286324af62d00643186ec2&gt;4f69f62&lt;/denchmark-link&gt;
 .
 I've trained two MobileNetV2 models in Keras with 48x48 input size and a single input channel, then converted to int8 quantized.
 I am attempting to run both models using TensorFlow Lite for Microcontrollers on x86, built with clang on MacOS and with gcc on Ubuntu.
 The first model has a MobileNetV2 filter scaling factor (a) of 0.35. This model runs perfectly.
 The second model has a scaling factor of 0.1. This model sigaborts during the Invoke() call.
 Strangely, both models run perfectly when executed from the OpenMV H7+ (Arm Cortex-M7), and the smaller model runs perfectly on the H7. It might be worth noting that on the OpenMV devices the model is stored in dynamic memory. That said, I've tried declaring the model without static on x86 and it has no impact.
 I've attached zips containing both model files, plus an example program that exhibits the sigabort.
 To build and run the example with an empty input:
 &lt;denchmark-code&gt;make -f Makefile.tflite
 ./build/edge-impulse-standalone ""
 &lt;/denchmark-code&gt;
 
 Within the example code, the call to Invoke() is on line 260 of edge-impulse-sdk/classifier/ei_run_classifier.h.
 To switch to the 0.35 model, which doesn't sigabort, replace tflite-model, model-parameters, and edge-impulse-sdk directories with the versions contained within 0.35 grayscale.zip.
 Describe the expected behavior
 The a=0.1 model should run successfully on x86, the same as the 0.35 does.
 Standalone code to reproduce the issue
 Example code here:
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4968485/example-standalone-inferencing.zip&gt;example-standalone-inferencing.zip&lt;/denchmark-link&gt;
 
 The  model files are located here:
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4968496/models.zip&gt;models.zip&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='dansitu' date='2020-07-24T09:40:04Z'>
 		The actual crash is here: tensorflow/lite/kernels/internal/reference/integer_ops/add.h in the Add function.
 &lt;denchmark-code&gt;TFLITE_DCHECK_LE(params.input1_offset, int8_max_value);
 &lt;/denchmark-code&gt;
 
 Here params.input1_offset is 128, which is invalid (max is 127). I assume this is a parser or quantization bug.
 Changing this parameter to 127 solves the issue, but I'm not sure where it comes from.
 &lt;denchmark-code&gt;  ArithmeticParams *p = (ArithmeticParams*)&amp;params;
 
   if (p-&gt;input1_offset &gt; 127) {
       p-&gt;input1_offset = 127;
   }
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='2' author='dansitu' date='2020-07-24T17:55:26Z'>
 		Thank you Jan! Since this seems to perhaps be a converter issue, I'm attaching the SavedModel files for both models.
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4973569/0.1-grayscale-savedmodel.zip&gt;0.1-grayscale-savedmodel.zip&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4973570/0.35-grayscale-savedmodel.zip&gt;0.35-grayscale-savedmodel.zip&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='dansitu' date='2020-07-25T00:19:49Z'>
 		Are you satisfied with the resolution of your issue?
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41674&gt;Yes&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41674&gt;No&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='4' author='dansitu' date='2020-08-09T21:28:02Z'>
 		&lt;denchmark-link:https://github.com/dansitu&gt;@dansitu&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://github.com/janjongboom&gt;@janjongboom&lt;/denchmark-link&gt;
 
 Hi, i have run into problems running similar NN to yours.
 `base_model = tf.keras.applications.MobileNetV2(input_shape=(48, 48, 1), alpha=0.35, weights=None, include_top=False)
 x = base_model.output
 x = tf.keras.layers.Flatten()(x)
 x = Dense(2)(x) #final layer with softmax activation for N classes
 preds = tf.keras.layers.Softmax()(x)
 model=Model(inputs=base_model.input,outputs=preds) #specify the inputs and outputs
 converter = tf.lite.TFLiteConverter.from_keras_model(model)
 def representative_dataset():
 for i in range(500):
 yield([np.random.rand(1,48,48,1).astype(np.float32)])
 converter.optimizations = [tf.lite.Optimize.DEFAULT]
 converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
 converter.representative_dataset = representative_dataset
 tflite_model = converter.convert()
 open("mobilenet_test.tflite", "wb").write(tflite_model)
 `
 the model crush on the microcontroller in assert (tflite::PreprocessSoftmaxScaling)
 thanks
 		</comment>
 	</comments>
 </bug>
<commit id='dd918be82cb9702cc9ca022179629fbd8c6d3ed9' author='Nat Jeffries' date='2020-07-24 17:14:38-07:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow\lite\kernels\internal\reference\integer_ops\add.h' new_name='tensorflow\lite\kernels\internal\reference\integer_ops\add.h'>
 		<file_info nloc='100' complexity='9' token_count='739'></file_info>
 		<method name='tflite::reference_integer_ops::Add' parameters='params,input1_shape,input1_data,input2_shape,input2_data,output_shape,output_data'>
 				<method_info nloc='9' complexity='1' token_count='69' nesting_level='2' start_line='67' end_line='77'></method_info>
 			<added_lines>71,72</added_lines>
 			<deleted_lines>69,70,71,72,73</deleted_lines>
 		</method>
 		<method name='tflite::reference_integer_ops::AddElementwise' parameters='size,params,input1_data,input2_data,output_data'>
 				<method_info nloc='26' complexity='2' token_count='203' nesting_level='2' start_line='39' end_line='65'></method_info>
 			<added_lines>42</added_lines>
 			<deleted_lines>64,65</deleted_lines>
 		</method>
 		<method name='tflite::reference_integer_ops::CheckArithmeticParams' parameters='params'>
 				<method_info nloc='8' complexity='1' token_count='96' nesting_level='2' start_line='26' end_line='35'></method_info>
 			<added_lines>26,27,28,29,30,31,32,33,34,35</added_lines>
 			<deleted_lines>31,32,33,34,35</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>36</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
