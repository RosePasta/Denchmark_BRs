<bug_data>
<bug id='746' author='wasiahmad' open_date='2018-06-05T05:50:59Z' closed_time='2018-09-03T12:02:38Z'>
 	<summary>[BUG] dynamic_dict/copy_attn does not work with accum_count &amp;gt; 1</summary>
 	<description>
 I am getting the following error when I tried to train transformer model on CNNDM dataset for summarization.
 
 Loading train dataset from data/cnndm/CNNDM.train.3.pt, number of examples: 33018
 Traceback (most recent call last):
 File "train.py", line 502, in 
 main()
 File "train.py", line 494, in main
 train_model(model, fields, optim, data_type, model_opt)
 File "train.py", line 257, in train_model
 train_stats = trainer.train(train_iter, epoch, report_func)
 File "/home/wasiahmad/workspace/projects/OpenNMT-py/onmt/Trainer.py", line 178, in train
 report_stats, normalization)
 File "/home/wasiahmad/workspace/projects/OpenNMT-py/onmt/Trainer.py", line 311, in _gradient_accumulation
 trunc_size, self.shard_size, normalization)
 File "/home/wasiahmad/workspace/projects/OpenNMT-py/onmt/Loss.py", line 123, in sharded_compute_loss
 loss, stats = self._compute_loss(batch, **shard)
 File "/home/wasiahmad/workspace/projects/OpenNMT-py/onmt/modules/CopyGenerator.py", line 191, in _compute_loss
 batch, self.tgt_vocab, self.cur_dataset.src_vocabs)
 File "/home/wasiahmad/workspace/projects/OpenNMT-py/onmt/io/TextDataset.py", line 116, in collapse_copy_scores
 src_vocab = src_vocabs[index]
 IndexError: list index out of range
 
 The training works fine for the first part of the data but whenever it loads the second part (ex., CNNDM.train.3.pt file), it gives index out of range error. Any idea what is hapenning?
 I have downloaded the dataset from the link mentioned &lt;denchmark-link:http://opennmt.net/OpenNMT-py/Summarization.html&gt;here&lt;/denchmark-link&gt;
  and did the preprocessing without any error. Please help.
 	</description>
 	<comments>
 		<comment id='1' author='wasiahmad' date='2018-06-19T07:29:51Z'>
 		Hi, same problem for me. Anyone knows why?
 		</comment>
 		<comment id='2' author='wasiahmad' date='2018-06-19T16:48:52Z'>
 		I tried a lot but couldn't find the reason behind this error.
 		</comment>
 		<comment id='3' author='wasiahmad' date='2018-08-03T21:24:32Z'>
 		&lt;denchmark-link:https://github.com/vince62s&gt;@vince62s&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/wasiahmad&gt;@wasiahmad&lt;/denchmark-link&gt;
  what was the eventual resolution?
 		</comment>
 		<comment id='4' author='wasiahmad' date='2018-08-03T21:28:01Z'>
 		did you try with the lates code + pytorch 0.4 + torchtext 0.3 ?
 		</comment>
 		<comment id='5' author='wasiahmad' date='2018-08-03T21:29:28Z'>
 		i tried it on master as of 3 days ago, currently rerunning now
 		</comment>
 		<comment id='6' author='wasiahmad' date='2018-08-04T00:18:56Z'>
 		I tried but didn't work and then stopped trying. It was around 1.5 months ago!!
 		</comment>
 		<comment id='7' author='wasiahmad' date='2018-08-30T10:18:46Z'>
 		okay, I can replicate this. We'll look into it.
 		</comment>
 		<comment id='8' author='wasiahmad' date='2018-08-30T18:14:20Z'>
 		Thanks to &lt;denchmark-link:https://github.com/pltrdy&gt;@pltrdy&lt;/denchmark-link&gt;
  who helped figuring it out.
 The issue is as follow:
 When accum_count &gt; 1, when using copy_attn (and therefore dynamic_dict) there is a mismatch if the batches within the "true_batch" = accum_count x batch are accross different shards of the dataset.
 For instance, at the end of the first shard, if we have accum_count = 4, we can have 2 batches loaded from the first shard and the last 2 from the second shard.
 In this context, we have an issue here: &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/modules/copy_generator.py#L195-L197&gt;https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/modules/copy_generator.py#L195-L197&lt;/denchmark-link&gt;
 
 where self.cur_dataset.src_vocabs may refer to the wrong shard.
 This is not easy to solve.
 In the meantime, use only accum_count = 1 with copy_attn and if you can use more GPU.
 I have tried to go back in time and in fact it seems to have never worked.
 So I am a bit confused that the tuto specification with copy_attn + accum_count = 4
 &lt;denchmark-link:https://github.com/srush&gt;@srush&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/sebastianGehrmann&gt;@sebastianGehrmann&lt;/denchmark-link&gt;
   can you check the config of the model you posted for summarization ?
 Thanks.
 		</comment>
 		<comment id='9' author='wasiahmad' date='2018-09-03T12:02:38Z'>
 		fixed in &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/pull/938&gt;#938&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='f45c7cecf3ebee82692b4a1a708905ca4b52e336' author='moses' date='2018-09-03 13:52:10+02:00'>
 	<dmm_unit complexity='0.3333333333333333' interfacing='0.3333333333333333' size='0.6666666666666666'></dmm_unit>
 	<modification change_type='MODIFY' old_name='onmt\inputters\inputter.py' new_name='onmt\inputters\inputter.py'>
 		<file_info nloc='344' complexity='73' token_count='2418'></file_info>
 		<method name='get_cur_dataset' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='1' start_line='443' end_line='445'></method_info>
 			<added_lines>445</added_lines>
 			<deleted_lines>443,444,445</deleted_lines>
 		</method>
 		<method name='_next_dataset_iterator' parameters='self,dataset_iter'>
 				<method_info nloc='12' complexity='2' token_count='70' nesting_level='1' start_line='443' end_line='459'></method_info>
 			<added_lines>445,450,455</added_lines>
 			<deleted_lines>443,444,445,446,449,454,459</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='onmt\modules\copy_generator.py' new_name='onmt\modules\copy_generator.py'>
 		<file_info nloc='152' complexity='10' token_count='996'></file_info>
 		<method name='_compute_loss' parameters='self,batch,output,target,copy_attn,align'>
 				<method_info nloc='26' complexity='2' token_count='282' nesting_level='1' start_line='174' end_line='220'></method_info>
 			<added_lines>193</added_lines>
 			<deleted_lines>197</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>156,157,158,159</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='onmt\trainer.py' new_name='onmt\trainer.py'>
 		<file_info nloc='240' complexity='33' token_count='1436'></file_info>
 		<method name='train' parameters='self,train_iter_fct,valid_iter_fct,train_steps,valid_steps'>
 				<method_info nloc='73' complexity='17' token_count='455' nesting_level='1' start_line='110' end_line='210'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>148,149</deleted_lines>
 		</method>
 		<method name='validate' parameters='self,valid_iter'>
 				<method_info nloc='18' complexity='3' token_count='131' nesting_level='1' start_line='212' end_line='248'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>224,225,226</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
