<bug_data>
<bug id='2611' author='JinZhuXing' open_date='2019-12-19T05:43:14Z' closed_time='2020-03-06T14:52:22Z'>
 	<summary>CRLF in alphabet file breaks usage</summary>
 	<description>
 &lt;denchmark-code&gt;python ./DeepSpeech.py --train_files ../zh-cn/clips/train.csv --dev_files ../zh-cn/clips/dev.csv --test_files ../zh-cn/clips/test.csv
 
 Traceback (most recent call last):
   File "/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py", line 33, in _label_from_string
     return self._str_to_label[string]
 KeyError: '母'
 
 During handling of the above exception, another exception occurred:
 
 Traceback (most recent call last):
   File "/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py", line 130, in text_to_char_array
     transcript = np.asarray(alphabet.encode(series['transcript']))
   File "/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py", line 47, in encode
     res.append(self._label_from_string(char))
   File "/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py", line 39, in _label_from_string
     ).with_traceback(e.__traceback__)
   File "/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py", line 33, in _label_from_string
     return self._str_to_label[string]
 KeyError: "ERROR: Your transcripts contain characters (e.g. '母') which do not occur in data/alphabet.txt! Use util/check_characters.py to see what characters are in your [train,dev,test].csv transcripts, and then add all these to data/alphabet.txt."
 
 During handling of the above exception, another exception occurred:
 
 Traceback (most recent call last):
   File "./DeepSpeech.py", line 965, in &lt;module&gt;
     absl.app.run(main)
   File "/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/absl/app.py", line 299, in run
     _run_main(main, args)
   File "/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/absl/app.py", line 250, in _run_main
     sys.exit(main(argv))
   File "./DeepSpeech.py", line 938, in main
     train()
   File "./DeepSpeech.py", line 438, in train
     train_phase=True)
   File "/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/feeding.py", line 101, in create_dataset
     df['transcript'] = df.apply(text_to_char_array, alphabet=Config.alphabet, result_type='reduce', axis=1)
   File "/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/frame.py", line 6928, in apply           return op.get_result()
   File "/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/apply.py", line 186, in get_result       return self.apply_standard()
   File "/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/apply.py", line 292, in apply_standard
     self.apply_series_generator()
   File "/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/apply.py", line 321, in apply_series_generator
     results[i] = self.f(v)
   File "/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/apply.py", line 112, in f
     return func(x, *args, **kwds)
   File "/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py", line 136, in text_to_char_array
     raise ValueError('While processing: {}\n{}'.format(series['wav_filename'], e))
 ValueError: ('While processing: /mnt/d/FPProject_git/My_Work/speech/mozilla/zh-cn/clips/common_voice_zh-CN_18782225.wav\n"ERROR: Your transcripts contain characters (e.g. \'母\') which do not occur in data/alphabet.txt! Use util/check_characters.py to see what characters are in your [train,dev,test].csv transcripts, and then add all these to data/alphabet.txt."', 'occurred at index 550')
 &lt;/denchmark-code&gt;
 
 I am training deep speech model in chinese.
 I have already downloaded chiense dataset from voice.mozilla.org (Common Voice).
 Then, I tried training as the description in Project Document(&lt;denchmark-link:https://github.com/mozilla/DeepSpeech/blob/master/TRAINING.rst#training-your-own-model&gt;https://github.com/mozilla/DeepSpeech/blob/master/TRAINING.rst#training-your-own-model&lt;/denchmark-link&gt;
 ).
 But when I train data using DeepSpeech.py, it failed with above errors.
 data/alphabet.txt already contains '母'.
 I can't find reason.
 Please help me.
 	</description>
 	<comments>
 		<comment id='1' author='JinZhuXing' date='2019-12-19T07:53:25Z'>
 		
 data/alphabet.txt already contains '母'.
 
 Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?
 How did you generate data/alphabet.txt ? Did you used util/check_characters.py as suggested ?
 		</comment>
 		<comment id='2' author='JinZhuXing' date='2019-12-19T10:13:30Z'>
 		
 
 data/alphabet.txt already contains '母'.
 
 Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?
 How did you generate data/alphabet.txt ? Did you used util/check_characters.py as suggested ?
 
 Yes. I have generated data/alphabet.txt file using util/check_characters.py.
 		</comment>
 		<comment id='3' author='JinZhuXing' date='2019-12-19T10:20:28Z'>
 		
 
 
 data/alphabet.txt already contains '母'.
 
 Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?
 How did you generate data/alphabet.txt ? Did you used util/check_characters.py as suggested ?
 
 Yes. I have generated data/alphabet.txt file using util/check_characters.py.
 
 Well, I can't help more without more data. But you have an unmatched character in your dataset, for sure.
 Maybe you could share more of you data ? The offending transcript as well as the alphabet file ?
 		</comment>
 		<comment id='4' author='JinZhuXing' date='2019-12-19T10:25:43Z'>
 		&lt;denchmark-link:https://github.com/JinZhuXing&gt;@JinZhuXing&lt;/denchmark-link&gt;
  Also, can you verify if the offending character is a unicode multi-byte character?
 		</comment>
 		<comment id='5' author='JinZhuXing' date='2019-12-19T10:36:33Z'>
 		Every Chinese character is multibyte in UTF-8.
 &lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;
 
 
  On 19 Dec 2019, at 10:25, lissyx ***@***.***&gt; wrote:
 
  ﻿
  @JinZhuXing Also, can you verify if the offending character is a unicode multi-byte character?
 
  —
  You are receiving this because you are subscribed to this thread.
  Reply to this email directly, view it on GitHub, or unsubscribe.
 
 
 		</comment>
 		<comment id='6' author='JinZhuXing' date='2019-12-19T10:45:33Z'>
 		
 Every Chinese character is multibyte in UTF-8.
 …
 On 19 Dec 2019, at 10:25, lissyx @.***&gt; wrote: ﻿ @JinZhuXing Also, can you verify if the offending character is a unicode multi-byte character? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or unsubscribe.
 
 Not multi-byte then, but was it multi-point ?
 		</comment>
 		<comment id='7' author='JinZhuXing' date='2019-12-19T11:00:09Z'>
 		&lt;denchmark-link:https://github.com/JinZhuXing&gt;@JinZhuXing&lt;/denchmark-link&gt;
  I also see you are using Anaconda. We're got weird behaviors sometimes, can you reproduce with vanilla Python and a new virtualenv properly setup from scratch ?
 		</comment>
 		<comment id='8' author='JinZhuXing' date='2019-12-23T03:12:01Z'>
 		OK, I will test with vanilla Python.
 Thanks, all of you.
 		</comment>
 		<comment id='9' author='JinZhuXing' date='2020-01-02T11:44:23Z'>
 		
 OK, I will test with vanilla Python.
 Thanks, all of you.
 
 &lt;denchmark-link:https://github.com/JinZhuXing&gt;@JinZhuXing&lt;/denchmark-link&gt;
  Any update ?
 		</comment>
 		<comment id='10' author='JinZhuXing' date='2020-02-13T11:19:34Z'>
 		&lt;denchmark-link:https://github.com/JinZhuXing&gt;@JinZhuXing&lt;/denchmark-link&gt;
  Please, can you give feedback ?
 		</comment>
 		<comment id='11' author='JinZhuXing' date='2020-02-14T05:22:38Z'>
 		
 @JinZhuXing Please, can you give feedback ?
 
 It's the same. I can't do it.
 So I will try with english dataset.
 Thanks.
 		</comment>
 		<comment id='12' author='JinZhuXing' date='2020-02-14T07:03:02Z'>
 		&lt;denchmark-link:https://github.com/JinZhuXing&gt;@JinZhuXing&lt;/denchmark-link&gt;
  Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
 		</comment>
 		<comment id='13' author='JinZhuXing' date='2020-02-14T10:31:26Z'>
 		
 @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
 
 Uploaded.
 &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/files/4204035/alphabet_20200214.zip&gt;alphabet_20200214.zip&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='14' author='JinZhuXing' date='2020-02-29T10:19:12Z'>
 		Make use you have run export LC_ALL="en_US.UTF-8" in your runtime for Python to handle unicode.
 		</comment>
 		<comment id='15' author='JinZhuXing' date='2020-03-02T14:46:38Z'>
 		
 Make use you have run export LC_ALL="en_US.UTF-8" in your runtime for Python to handle unicode.
 
 Same error.
 		</comment>
 		<comment id='16' author='JinZhuXing' date='2020-03-02T15:08:30Z'>
 		
 
 OK, I will test with vanilla Python.
 Thanks, all of you.
 
 @JinZhuXing Any update ?
 
 It's the same. I can't do it.
 So I will try with english dataset.
 Thanks.
 		</comment>
 		<comment id='17' author='JinZhuXing' date='2020-03-02T15:18:44Z'>
 		
 
 @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
 
 Uploaded.
 alphabet_20200214.zip
 
 This does not include the transcript. Please, share debuggable data.
 		</comment>
 		<comment id='18' author='JinZhuXing' date='2020-03-03T02:56:51Z'>
 		
 
 
 @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
 
 Uploaded.
 alphabet_20200214.zip
 
 This does not include the transcript. Please, share debuggable data.
 
 Uploaded transcript.
 &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/files/4279001/zh-cn_trans.zip&gt;zh-cn_trans.zip&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='19' author='JinZhuXing' date='2020-03-05T17:24:20Z'>
 		
 
 
 
 @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
 
 Uploaded.
 alphabet_20200214.zip
 
 This does not include the transcript. Please, share debuggable data.
 
 Uploaded transcript.
 zh-cn_trans.zip
 
 Ok, looking at your alphabet file there are three occurrences of 母. Now I have no knowledge of zh-cn locale, but I suspect this is not expected.
 		</comment>
 		<comment id='20' author='JinZhuXing' date='2020-03-06T01:22:07Z'>
 		
 
 
 
 
 @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
 
 Uploaded.
 alphabet_20200214.zip
 
 This does not include the transcript. Please, share debuggable data.
 
 Uploaded transcript.
 zh-cn_trans.zip
 
 Ok, looking at your alphabet file there are three occurrences of 母. Now I have no knowledge of zh-cn locale, but I suspect this is not expected.
 
 I just removed two '母‘ characters at alphabet file. But the same error occur.
 		</comment>
 		<comment id='21' author='JinZhuXing' date='2020-03-06T08:10:15Z'>
 		
 
 
 
 
 
 @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
 
 Uploaded.
 alphabet_20200214.zip
 
 This does not include the transcript. Please, share debuggable data.
 
 Uploaded transcript.
 zh-cn_trans.zip
 
 Ok, looking at your alphabet file there are three occurrences of 母. Now I have no knowledge of zh-cn locale, but I suspect this is not expected.
 
 I just removed two '母‘ characters at alphabet file. But the same error occur.
 
 Could you please work on a reduced test case that reproduces the issue ?
 99.999% of the time, those bugs are dataset-side.
 		</comment>
 		<comment id='22' author='JinZhuXing' date='2020-03-06T09:18:32Z'>
 		&lt;denchmark-code&gt;$ file issue_2611/alphabet.txt 
 issue_2611/alphabet.txt: UTF-8 Unicode text, with CRLF line terminators
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='23' author='JinZhuXing' date='2020-03-06T09:20:06Z'>
 		&lt;denchmark-link:https://github.com/JinZhuXing&gt;@JinZhuXing&lt;/denchmark-link&gt;
  Just removing  line ending was enough. Training is only tested / supported on Linux so far, as documented. Looks like this was prepared on a Windows system to be with  line endings.
 		</comment>
 		<comment id='24' author='JinZhuXing' date='2020-03-06T09:36:07Z'>
 		Thank you &lt;denchmark-link:https://github.com/lissyx&gt;@lissyx&lt;/denchmark-link&gt;
  .
 Solved.
 Thanks all of you.
 		</comment>
 		<comment id='25' author='JinZhuXing' date='2020-03-06T12:14:32Z'>
 		&lt;denchmark-link:https://github.com/JinZhuXing&gt;@JinZhuXing&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/pull/2813&gt;#2813&lt;/denchmark-link&gt;
  will make sure people producing alphabet on one system and using it on another won't get into troubles.
 		</comment>
 		<comment id='26' author='JinZhuXing' date='2020-04-15T08:16:56Z'>
 		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
 		</comment>
 	</comments>
 </bug>
<commit id='763ed38baeecb07801e90875c222966f622d44b6' author='Alexandre Lissy' date='2020-03-06 15:19:56+01:00'>
 	<dmm_unit complexity='1.0' interfacing='0.2857142857142857' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='.travis.yml' new_name='.travis.yml'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26</added_lines>
 			<deleted_lines>10,11,12,13,14,15,16,17</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='requirements_tests.txt'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='util\test_data\alphabet_macos.txt'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='util\test_data\alphabet_unix.txt'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='util\test_data\alphabet_windows.txt'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='util\test_text.py'>
 		<file_info nloc='27' complexity='7' token_count='219'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='util\text.py' new_name='util\text.py'>
 		<file_info nloc='131' complexity='37' token_count='939'></file_info>
 		<method name='__init__' parameters='self,config_file'>
 				<method_info nloc='15' complexity='5' token_count='108' nesting_level='1' start_line='11' end_line='25'></method_info>
 			<added_lines>17</added_lines>
 			<deleted_lines>18</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>3</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
