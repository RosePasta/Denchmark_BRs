<bug_data>
<bug id='2673' author='senarvi' open_date='2020-09-29T07:51:05Z' closed_time='2020-10-01T19:37:30Z'>
 	<summary>Full-context alignment is broken in transformer_align model</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 transformer_align model, which implements the "Jointly Learning to Align and Translate" paper, supports full-context alignment, meaning that the auto-regressive mask is not applied to decoder self-attention. This feature is broken in the current master. When the --full-context-alignment flag is given to the model, it produces the error message
 &lt;denchmark-code&gt;TypeError: forward() got an unexpected keyword argument 'full_context_alignment'
 &lt;/denchmark-code&gt;
 
 in the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/fairseq/models/transformer_align.py#L69&gt;forward_decoder() method of TransformerAlignModel&lt;/denchmark-link&gt;
 . As far as I can see, this happens because the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/fairseq/models/transformer.py#L638&gt;forward() method of TransformerDecoder&lt;/denchmark-link&gt;
  doesn't have the  argument anymore, that was passed to the extract_features() method by the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/1c6679294848f303a361cba7b306b760e299bd9c/fairseq/models/transformer.py#L514&gt;version of the code at the time the transformer_align model was merged&lt;/denchmark-link&gt;
 .
 Ideally the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/tests/test_binaries.py#L428&gt;test_alignment() unit test&lt;/denchmark-link&gt;
  would also be updated to test this feature.
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 Follow the &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/examples/joint_alignment_translation/README.md&gt;instructions&lt;/denchmark-link&gt;
 , but additionally give the  flag to fairseq-train. It produces the following error message and stack trace:
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File ".../bin/fairseq-train", line 11, in &lt;module&gt;
     load_entry_point('fairseq', 'console_scripts', 'fairseq-train')()
   File ".../fairseq_cli/train.py", line 351, in cli_main
     distributed_utils.call_main(args, main)
   File ".../fairseq/distributed_utils.py", line 254, in call_main
     main(args, **kwargs)
   File ".../fairseq_cli/train.py", line 125, in main
     valid_losses, should_stop = train(args, trainer, task, epoch_itr)
   File "/usr/lib64/python3.6/contextlib.py", line 52, in inner
     return func(*args, **kwds)
   File ".../fairseq_cli/train.py", line 207, in train
     log_output = trainer.train_step(samples)
   File "/usr/lib64/python3.6/contextlib.py", line 52, in inner
     return func(*args, **kwds)
   File ".../fairseq/trainer.py", line 479, in train_step
     ignore_grad=is_dummy_batch,
   File ".../fairseq/tasks/fairseq_task.py", line 408, in train_step
     loss, sample_size, logging_output = criterion(model, sample)
   File ".../lib64/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
     result = self.forward(*input, **kwargs)
   File ".../fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py", line 36, in forward
     net_output = model(**sample['net_input'])
   File ".../lib64/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
     result = self.forward(*input, **kwargs)
   File ".../fairseq/models/transformer_align.py", line 51, in forward
     return self.forward_decoder(prev_output_tokens, encoder_out)
   File ".../fairseq/models/transformer_align.py", line 75, in forward_decoder
     **extra_args,
   File ".../lib64/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
     result = self.forward(*input, **kwargs)
 TypeError: forward() got an unexpected keyword argument 'full_context_alignment'
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 I expect fairseq-train to start training the model, like it does when I don't give the --full-context-alignment flag, but alignment supervised conditioned on the full target context.
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 
 fairseq Version (e.g., 1.0 or master): master
 PyTorch Version (e.g., 1.0): 1.6.0
 OS (e.g., Linux): Linux
 How you installed fairseq (pip, source): pip
 Python version: 3.6.8
 
 	</description>
 	<comments>
 		<comment id='1' author='senarvi' date='2020-09-29T17:00:20Z'>
 		I assume this is how to fix it: &lt;denchmark-link:https://github.com/pytorch/fairseq/pull/2675&gt;#2675&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='c049749c7a7c08cca9e4663c85bd3961f4b260f8' author='Seppo Enarvi' date='2020-10-01 12:37:16-07:00'>
 	<dmm_unit complexity='1.0' interfacing='0.9545454545454546' size='0.045454545454545456'></dmm_unit>
 	<modification change_type='MODIFY' old_name='fairseq\models\transformer.py' new_name='fairseq\models\transformer.py'>
 		<file_info nloc='762' complexity='105' token_count='4957'></file_info>
 		<method name='forward' parameters='self,prev_output_tokens,None,str,str,None,bool,bool,None,None,None,bool'>
 				<method_info nloc='11' complexity='1' token_count='82' nesting_level='1' start_line='638' end_line='648'></method_info>
 			<added_lines>644</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>660,661,672</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\models\transformer_align.py' new_name='fairseq\models\transformer_align.py'>
 		<file_info nloc='71' complexity='7' token_count='416'></file_info>
 		<method name='add_args' parameters='parser'>
 				<method_info nloc='8' complexity='1' token_count='66' nesting_level='1' start_line='28' end_line='36'></method_info>
 			<added_lines>35</added_lines>
 			<deleted_lines>35</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\sequence_generator.py' new_name='fairseq\sequence_generator.py'>
 		<file_info nloc='663' complexity='70' token_count='5177'></file_info>
 		<method name='forward_align' parameters='self,src_tokens,src_lengths,prev_output_tokens'>
 				<method_info nloc='12' complexity='4' token_count='82' nesting_level='1' start_line='951' end_line='962'></method_info>
 			<added_lines>955</added_lines>
 			<deleted_lines>955</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_binaries.py' new_name='tests\test_binaries.py'>
 		<file_info nloc='933' complexity='77' token_count='4699'></file_info>
 		<method name='test_alignment_full_context' parameters='self'>
 				<method_info nloc='21' complexity='1' token_count='89' nesting_level='1' start_line='455' end_line='475'></method_info>
 			<added_lines>455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_alignment' parameters='self'>
 				<method_info nloc='20' complexity='1' token_count='87' nesting_level='1' start_line='434' end_line='453'></method_info>
 			<added_lines>449,450,451,452,453</added_lines>
 			<deleted_lines>449</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>454</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
