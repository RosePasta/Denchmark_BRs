<bug_data>
<bug id='2083' author='eshaan-pathak' open_date='2020-04-30T20:33:44Z' closed_time='2020-05-11T19:43:25Z'>
 	<summary>"argument --distributed-world-size: conflicting option string: --distributed-world-size" Error</summary>
 	<description>
 &lt;denchmark-h:h2&gt;‚ùì Questions and Help&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h3&gt;Before asking:&lt;/denchmark-h&gt;
 
 
 search the issues.
 search the docs.
 
 &lt;denchmark-h:h4&gt;What is your question?&lt;/denchmark-h&gt;
 
 After training my model, I would like to evaluate it; however, I run into an argument parse error, as seen below. I am using the command lines from &lt;denchmark-link:https://github.com/pytorch/fairseq/blob/master/examples/language_model/README.md&gt;here&lt;/denchmark-link&gt;
  and have slightly modified them where I am using a patience of 3, no-epoch-checkpoints, removed fp16, and distributed-world-size of 1 when training. I also changed the paths to reflect my own directory structure. These are the only changes I have made from the link, and I am sure that they are properly formatted. Any help is appreciated. :)
 &lt;denchmark-h:h4&gt;Code&lt;/denchmark-h&gt;
 
 Traceback (most recent call last):
 File "/home/e/miniconda3/envs/eshaan/bin/fairseq-eval-lm", line 11, in 
 load_entry_point('fairseq', 'console_scripts', 'fairseq-eval-lm')()
 File "/srv/home/e/eshaan/fairseq/fairseq_cli/eval_lm.py", line 251, in cli_main
 add_distributed_training_args(parser)
 File "/srv/home/e/eshaan/fairseq/fairseq/options.py", line 356, in add_distributed_training_args
 help='total number of GPUs across all nodes (default: all visible GPUs)')
 File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1352, in add_argument
 return self._add_action(action)
 File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1556, in _add_action
 action = super(_ArgumentGroup, self)._add_action(action)
 File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1366, in _add_action
 self._check_conflict(action)
 File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1505, in _check_conflict
 conflict_handler(action, confl_optionals)
 File "/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py", line 1514, in _handle_conflict_error
 raise ArgumentError(action, message % conflict_string)
 argparse.ArgumentError: argument --distributed-world-size: conflicting option string: --distributed-world-size
 &lt;denchmark-h:h4&gt;What have you tried?&lt;/denchmark-h&gt;
 
 I have tried retraining my model in case it was an issue with how my checkpoints were stored, despite how the output always said my distributed world size is 1. I have also looked at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/8389&gt;this similar error&lt;/denchmark-link&gt;
  to make sure that no other python processes are running.
 &lt;denchmark-h:h4&gt;What's your environment?&lt;/denchmark-h&gt;
 
 
 fairseq Version (e.g., 1.0 or master): 0.9.0
 PyTorch Version (e.g., 1.0): 1.4.0
 OS (e.g., Linux): Ubuntu 16.04.6 LTS (Xenial Xerus)
 How you installed fairseq (pip, source): source
 Build command you used (if compiling from source): pip install -e fairseq/
 Python version: 3.6.10
 CUDA/cuDNN version: CUDA release 10.1, V10.1.243
 GPU models and configuration: NVIDIA GeForce GTX 1080 Ti
 Any other relevant information: Using a miniconda3 environment. There are 8 GPUs on the server that I am SSH'd into, but I am only connected to 1.
 
 	</description>
 	<comments>
 		<comment id='1' author='eshaan-pathak' date='2020-05-02T05:09:33Z'>
 		I encountered this bug as well. Seems like commenting out line 251 (add_distributed_training_args(parser)) in fairseq_cli/eval_lm.py fixes it.
 		</comment>
 		<comment id='2' author='eshaan-pathak' date='2020-05-04T16:21:50Z'>
 		Fixed by &lt;denchmark-link:https://github.com/pytorch/fairseq/commit/b2ee110c853c5effdd8d21f50a8437485bafb285&gt;b2ee110&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='eshaan-pathak' date='2020-05-05T21:51:23Z'>
 		Hi Myle!
 I think there might still be an issue here. When I run eval_lm with the argument "--distributed-world-size 1" it fails:
 File "eval_lm.py", line 11, in 
 cli_main()
 File "fairseq_cli/eval_lm.py", line 252, in cli_main
 distributed_utils.call_main(args, main)
 File "fairseq/distributed_utils.py", line 173, in call_main
 main(args, kwargs)
 TypeError: main() takes 1 positional argument but 2 were given
 		</comment>
 		<comment id='4' author='eshaan-pathak' date='2020-05-12T14:19:54Z'>
 		This should actually be fixed now :)
 		</comment>
 	</comments>
 </bug>
<commit id='6209d7d6b2c41fccb01e00671261be80ba86029a' author='Myle Ott' date='2020-05-11 12:43:14-07:00'>
 	<dmm_unit complexity='1.0' interfacing='0.875' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='fairseq\data\language_pair_dataset.py' new_name='fairseq\data\language_pair_dataset.py'>
 		<file_info nloc='208' complexity='39' token_count='1566'></file_info>
 		<modified_lines>
 			<added_lines>168,169</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\distributed_utils.py' new_name='fairseq\distributed_utils.py'>
 		<file_info nloc='233' complexity='48' token_count='1521'></file_info>
 		<method name='call_main' parameters='args,main,kwargs'>
 				<method_info nloc='27' complexity='6' token_count='188' nesting_level='0' start_line='143' end_line='173'></method_info>
 			<added_lines>173</added_lines>
 			<deleted_lines>173</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\models\transformer.py' new_name='fairseq\models\transformer.py'>
 		<file_info nloc='742' complexity='100' token_count='4934'></file_info>
 		<method name='forward' parameters='self,src_tokens,src_lengths,prev_output_tokens,None,bool,bool,None,None'>
 				<method_info nloc='10' complexity='1' token_count='49' nesting_level='1' start_line='253' end_line='262'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>258</deleted_lines>
 		</method>
 		<method name='forward' parameters='self,src_tokens,src_lengths,None,bool'>
 				<method_info nloc='6' complexity='1' token_count='23' nesting_level='1' start_line='381' end_line='386'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>385</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>273</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\modules\transformer_sentence_encoder.py' new_name='fairseq\modules\transformer_sentence_encoder.py'>
 		<file_info nloc='191' complexity='11' token_count='1108'></file_info>
 		<modified_lines>
 			<added_lines>12,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,234,235,236</added_lines>
 			<deleted_lines>146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,231,232,233,234,235,236</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\options.py' new_name='fairseq\options.py'>
 		<file_info nloc='491' complexity='30' token_count='3964'></file_info>
 		<method name='add_distributed_training_args' parameters='parser'>
 				<method_info nloc='51' complexity='1' token_count='396' nesting_level='0' start_line='353' end_line='412'></method_info>
 			<added_lines>353,356,357,359</added_lines>
 			<deleted_lines>353,357</deleted_lines>
 		</method>
 		<method name='add_distributed_training_args' parameters='parser,default_world_size'>
 				<method_info nloc='53' complexity='2' token_count='408' nesting_level='0' start_line='353' end_line='414'></method_info>
 			<added_lines>353,356,357,359</added_lines>
 			<deleted_lines>353,357</deleted_lines>
 		</method>
 		<method name='get_eval_lm_parser' parameters='default_task'>
 				<method_info nloc='6' complexity='1' token_count='37' nesting_level='0' start_line='45' end_line='50'></method_info>
 			<added_lines>48</added_lines>
 			<deleted_lines>48</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\search.py' new_name='fairseq\search.py'>
 		<file_info nloc='219' complexity='33' token_count='1827'></file_info>
 		<method name='step' parameters='self,int,lprobs'>
 				<method_info nloc='22' complexity='3' token_count='175' nesting_level='1' start_line='55' end_line='83'></method_info>
 			<added_lines>78,79,80,81</added_lines>
 			<deleted_lines>78</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_binaries.py' new_name='tests\test_binaries.py'>
 		<file_info nloc='1052' complexity='93' token_count='5604'></file_info>
 		<method name='test_fconv_lm' parameters='self'>
 				<method_info nloc='17' complexity='1' token_count='81' nesting_level='1' start_line='480' end_line='496'></method_info>
 			<added_lines>492,493,494,495,496</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
