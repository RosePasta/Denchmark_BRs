<bug_data>
<bug id='1622' author='erip' open_date='2020-01-15T02:21:39Z' closed_time='2020-01-24T18:30:50Z'>
 	<summary>Division by zero in Windows builds</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;
 
 With the introduction of the new metrics API, there are issues with division by zero.
 &lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;
 
 To reproduce, run the most minimal  on a Windows machine. The error is also seen in the test failures from &lt;denchmark-link:https://github.com/pytorch/fairseq/pull/1595/checks?check_run_id=390286089&gt;Windows CI&lt;/denchmark-link&gt;
 
 &lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;
 
 N/A
 &lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;
 
 There shouldn't be division by zero errors.
 &lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;
 
 
 fairseq Version (e.g., 1.0 or master): master
 PyTorch Version (e.g., 1.0) 1.3.1
 OS (e.g., Linux): Windows
 How you installed fairseq (pip, source): source
 Build command you used (if compiling from source): See the build script.
 Python version: 3.6.7
 CUDA/cuDNN version: N/A
 GPU models and configuration: N/A
 Any other relevant information: N/A
 
 &lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;
 
 Strangely, this doesn't seem to happen in Unix builds...
 	</description>
 	<comments>
 		<comment id='1' author='erip' date='2020-01-18T13:38:52Z'>
 		I suspect this has something to do with the way TimeMeter.reset is defined -- it's got a different signature than the other Meter subclass's reset. I don't know why it would be platform dependent, but maybe it's an initialization issue, too.
 		</comment>
 		<comment id='2' author='erip' date='2020-01-20T15:23:27Z'>
 		I found the immediate issue: Windows uses a 16ms precision clock, but this in not the case in unix. This can be observed by using this in both windows and unix: python -c "import time; start=time.time(); print(time.time() - start)"
 On Windows, this yields 0.0 consistently; on unix, it yields some tiny delta. An alternative would be to use time.perf_counter. I think there are some slightly nuanced (but likely negligible) differences in semantics -- I'll submit a PR for this and let someone smarter than me review it. üòÑ
 		</comment>
 	</comments>
 </bug>
<commit id='f1d856e006a0fcb2b22afaad2eb456a671204557' author='Elijah Rippeth' date='2020-01-24 10:32:20-08:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='.github\workflows\build.yml' new_name='.github\workflows\build.yml'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>16</added_lines>
 			<deleted_lines>16,18</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='.github\workflows\build_windows.yml'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\speech_recognition\infer.py' new_name='examples\speech_recognition\infer.py'>
 		<file_info nloc='204' complexity='31' token_count='1487'></file_info>
 		<method name='main' parameters='args'>
 				<method_info nloc='71' complexity='12' token_count='570' nesting_level='0' start_line='162' end_line='257'></method_info>
 			<added_lines>189</added_lines>
 			<deleted_lines>189</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\hub_utils.py' new_name='fairseq\hub_utils.py'>
 		<file_info nloc='203' complexity='36' token_count='1762'></file_info>
 		<modified_lines>
 			<added_lines>72</added_lines>
 			<deleted_lines>72</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\meters.py' new_name='fairseq\meters.py'>
 		<file_info nloc='193' complexity='64' token_count='1267'></file_info>
 		<method name='stop' parameters='self,n'>
 				<method_info nloc='5' complexity='2' token_count='38' nesting_level='1' start_line='143' end_line='147'></method_info>
 			<added_lines>145</added_lines>
 			<deleted_lines>145</deleted_lines>
 		</method>
 		<method name='elapsed_time' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='21' nesting_level='1' start_line='120' end_line='121'></method_info>
 			<added_lines>121</added_lines>
 			<deleted_lines>121</deleted_lines>
 		</method>
 		<method name='start' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='14' nesting_level='1' start_line='140' end_line='141'></method_info>
 			<added_lines>141</added_lines>
 			<deleted_lines>141</deleted_lines>
 		</method>
 		<method name='reset' parameters='self,init,n'>
 				<method_info nloc='4' complexity='1' token_count='32' nesting_level='1' start_line='92' end_line='95'></method_info>
 			<added_lines>94</added_lines>
 			<deleted_lines>94</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>175</added_lines>
 			<deleted_lines>175</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\tasks\language_modeling.py' new_name='fairseq\tasks\language_modeling.py'>
 		<file_info nloc='205' complexity='28' token_count='1114'></file_info>
 		<method name='setup_task' parameters='cls,args,kwargs'>
 				<method_info nloc='25' complexity='8' token_count='189' nesting_level='1' start_line='104' end_line='138'></method_info>
 			<added_lines>113</added_lines>
 			<deleted_lines>113</deleted_lines>
 		</method>
 		<method name='load_dataset' parameters='self,split,epoch,combine,kwargs'>
 				<method_info nloc='37' complexity='4' token_count='236' nesting_level='1' start_line='151' end_line='198'></method_info>
 			<added_lines>157</added_lines>
 			<deleted_lines>157</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq\tasks\semisupervised_translation.py' new_name='fairseq\tasks\semisupervised_translation.py'>
 		<file_info nloc='334' complexity='73' token_count='2545'></file_info>
 		<method name='parse_lambda_config' parameters='x'>
 				<method_info nloc='10' complexity='7' token_count='146' nesting_level='0' start_line='40' end_line='57'></method_info>
 			<added_lines>53</added_lines>
 			<deleted_lines>53</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq_cli\eval_lm.py' new_name='fairseq_cli\eval_lm.py'>
 		<file_info nloc='184' complexity='40' token_count='1296'></file_info>
 		<method name='main' parameters='parsed_args'>
 				<method_info nloc='143' complexity='35' token_count='1071' nesting_level='0' start_line='57' end_line='234'></method_info>
 			<added_lines>71</added_lines>
 			<deleted_lines>70</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>13</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq_cli\generate.py' new_name='fairseq_cli\generate.py'>
 		<file_info nloc='174' complexity='42' token_count='1340'></file_info>
 		<method name='_main' parameters='args,output_file'>
 				<method_info nloc='145' complexity='37' token_count='1155' nesting_level='0' start_line='37' end_line='222'></method_info>
 			<added_lines>68</added_lines>
 			<deleted_lines>68</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq_cli\interactive.py' new_name='fairseq_cli\interactive.py'>
 		<file_info nloc='160' complexity='37' token_count='1085'></file_info>
 		<method name='main' parameters='args'>
 				<method_info nloc='93' complexity='22' token_count='689' nesting_level='0' start_line='71' end_line='204'></method_info>
 			<added_lines>94</added_lines>
 			<deleted_lines>93</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>15</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fairseq_cli\train.py' new_name='fairseq_cli\train.py'>
 		<file_info nloc='222' complexity='58' token_count='1615'></file_info>
 		<method name='main' parameters='args,init_distributed'>
 				<method_info nloc='62' complexity='20' token_count='523' nesting_level='0' start_line='36' end_line='127'></method_info>
 			<added_lines>121,122,123,124,125</added_lines>
 			<deleted_lines>120,121,122</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>12</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\speech_recognition\asr_test_base.py' new_name='tests\speech_recognition\asr_test_base.py'>
 		<file_info nloc='390' complexity='105' token_count='2567'></file_info>
 		<method name='get_dummy_input' parameters='T,D,B,K'>
 				<method_info nloc='24' complexity='2' token_count='210' nesting_level='0' start_line='70' end_line='101'></method_info>
 			<added_lines>80,86</added_lines>
 			<deleted_lines>80,86</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
