<bug_data>
<bug id='3755' author='alinaSarwar' open_date='2020-04-29T21:44:11Z' closed_time='2020-07-25T08:41:02Z'>
 	<summary>Error creating onnxruntime session</summary>
 	<description>
 Problem Description
 I'm trying to export the following pytorch model to onnx using torch scripting.
 &lt;denchmark-code&gt;@torch.jit.script
 def get_count(array, thresh):
     count = torch.tensor(0)
     for i in range(5):
        if array[i] &gt; thresh:
         count = count + 1
     return count
 
 class test_model(nn.Module):
     def forward(self, array, thresh):
         return get_count(array, thresh)
 &lt;/denchmark-code&gt;
 
 I use the following to export my model to onnx.
 &lt;denchmark-code&gt;array = torch.tensor([10,11,5,4,6])
 thresh = torch.tensor(5)
 model = test_model()
 
 torch.onnx.export(model=model,
                   args=(array, thresh),
                   f="test_model.onnx",
                   verbose=True,
                   opset_version=11,
                   input_names=['input_data', 'threshold'])
 &lt;/denchmark-code&gt;
 
 Here is the onnx graph that i get after export:
 &lt;denchmark-code&gt;graph(%input_data : Long(5),
       %threshold : Long()):
   %2 : Long() = onnx::Constant[value={1}]()
   %3 : Long() = onnx::Constant[value={5}]()
   %4 : Long() = onnx::Constant[value={0}]()
   %5 : Tensor = onnx::Cast[to=9](%2)
   %6 : Long() = onnx::Loop(%3, %5, %4) # &lt;ipython-input-70-c5725febec4a&gt;:4:4
     block0(%i.1 : Long(), %cond : bool, %count.10 : Tensor):
       %10 : Tensor = onnx::Gather[axis=0](%input_data, %i.1) # &lt;ipython-input-70-c5725febec4a&gt;:5:10
       %11 : Tensor = onnx::Greater(%10, %threshold) # &lt;ipython-input-70-c5725febec4a&gt;:5:10
       %12 : Tensor = onnx::If(%11) # &lt;ipython-input-70-c5725febec4a&gt;:5:7
         block0():
           %13 : Long() = onnx::Constant[value={1}]()
           %14 : LongTensor = onnx::Add(%count.10, %13) # &lt;ipython-input-70-c5725febec4a&gt;:6:16
           -&gt; (%14)
         block1():
           -&gt; (%count.10)
       %15 : Tensor = onnx::Cast[to=9](%2)
       -&gt; (%15, %12)
   return (%6)
 &lt;/denchmark-code&gt;
 
 However, when I create an onnx runtime inference session using
 &lt;denchmark-code&gt; ort_sess = onnxruntime.InferenceSession('test_sort.onnx')
 &lt;/denchmark-code&gt;
 
 I get the following error:
 &lt;denchmark-code&gt;---------------------------------------------------------------------------
 Fail                                      Traceback (most recent call last)
 &lt;ipython-input-73-592f4c5d3a84&gt; in &lt;module&gt;
       3 inputs = (array,threshold)
       4 
 ----&gt; 5 ort_sess = ort.InferenceSession('test_sort.onnx')
       6 
       7 # ort_inputs = {ort_session.get_inputs()[i].name:inpt for i, inpt in enumerate(to_np(inputs))}
 
 /opt/conda/lib/python3.7/site-packages/onnxruntime/capi/session.py in __init__(self, path_or_bytes, sess_options, providers)
      23         self._path_or_bytes = path_or_bytes
      24         self._sess_options = sess_options
 ---&gt; 25         self._load_model(providers)
      26         self._enable_fallback = True
      27 
 
 /opt/conda/lib/python3.7/site-packages/onnxruntime/capi/session.py in _load_model(self, providers)
      41             raise TypeError("Unable to load from type '{0}'".format(type(self._path_or_bytes)))
      42 
 ---&gt; 43         self._sess.load_model(providers)
      44 
      45         self._session_options = self._sess.session_options
 
 Fail: [ONNXRuntimeError] : 1 : FAIL : Exception during loading: /onnxruntime_src/onnxruntime/core/graph/graph.cc:2485 onnxruntime::common::Status onnxruntime::Graph::SetGraphInputsOutputs() node_arg was false. Graph ctor should have created NodeArg for initializer.
 &lt;/denchmark-code&gt;
 
 Urgency
 Moderate.
 System Information
 OS: Linux Ubuntu 16.04
 ONNX runtime version 1.1.0 installed from binary
 Python version: 3.7.4
 Expected Behavior
 Successful creation of onnxruntime session.
 Could someone please help me resolve this error?
 	</description>
 	<comments>
 		<comment id='1' author='alinaSarwar' date='2020-05-04T20:29:49Z'>
 		Can you please share the ONNX model file?
 		</comment>
 		<comment id='2' author='alinaSarwar' date='2020-05-05T08:45:01Z'>
 		&lt;denchmark-link:https://github.com/hariharans29&gt;@hariharans29&lt;/denchmark-link&gt;
  the code runs as is -- I reproduced in a &lt;denchmark-link:https://colab.research.google.com/drive/1YG-lcyW_ZK5IFMkGqllbqRr8rEEdzh7O?usp=sharing&gt;colab notebook&lt;/denchmark-link&gt;
 
 Running the notebook gives you this model: &lt;denchmark-link:https://github.com/microsoft/onnxruntime/files/4579717/onnxruntime_3755.zip&gt;onnxruntime_3755.zip&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='alinaSarwar' date='2020-05-20T05:01:31Z'>
 		There are actually two edge case bugs involved here.
 
 The 'count' input to the Loop subgraph has no type information (which is valid in an ONNX model) and is not used directly in the Loop. It's used inside an If node in the Loop which is a separate nested subgraph. That creates a subtle interaction where we don't create a necessary piece in the Loop subgraph.
 
 After fixing that I hit another issue related to the combination of Loop and If in a trivial graph.
 
 The loop state variable for 'count' is being passed directly to an If node and used directly as the output in one of the branches there. As the loop state variable may change shape across iterations we can't infer a shape, which means we couldn't infer the output shape from the If branch. We do have a way to handle this sort of unknown output shape so a fix was also required to use that.
 
 Once I create some unit tests I'll put the changes in a PR.
 		</comment>
 		<comment id='4' author='alinaSarwar' date='2020-05-21T10:55:36Z'>
 		
 There are actually two edge case bugs involved here.
 
 The 'count' input to the Loop subgraph has no type information (which is valid in an ONNX model) and is not used directly in the Loop. It's used inside an If node in the Loop which is a separate nested subgraph. That creates a subtle interaction where we don't create a necessary piece in the Loop subgraph.
 
 After fixing that I hit another issue related to the combination of Loop and If in a trivial graph.
 
 The loop state variable for 'count' is being passed directly to an If node and used directly as the output in one of the branches there. As the loop state variable may change shape across iterations we can't infer a shape, which means we couldn't infer the output shape from the If branch. We do have a way to handle this sort of unknown output shape so a fix was also required to use that.
 
 Once I create some unit tests I'll put the changes in a PR.
 
 Hi,
 When I run the above code, I met a different error:
 
 onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: /onnxruntime_src/onnxruntime/core/graph/graph.cc:912 void onnxruntime::Graph::InitializeStateFromModelFileGraphProto() This is an invalid model. Graph output (count.10) does not exist in the graph.
 
 I want to know if this error can be fixed in your new merge request &lt;denchmark-link:https://github.com/microsoft/onnxruntime/pull/4004&gt;#4004&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='5' author='alinaSarwar' date='2020-05-26T06:12:08Z'>
 		
 Running the notebook gives you this model: onnxruntime_3755.zip
 @snsun I tested with this model and see no errors. How are you creating the model that fails?
 
 		</comment>
 		<comment id='6' author='alinaSarwar' date='2020-05-26T07:23:27Z'>
 		
 
 Running the notebook gives you this model: onnxruntime_3755.zip
 @snsun I tested with this model and see no errors. How are you creating the model that fails?
 
 
 Tracked it down to being due to the pytorch version. Version 1.4 emits a bad subgraph where a
 graph output is not produced by any nodes in the subgraph. Version 1.5 works fine (which is what produced the graph I tested with).
 		</comment>
 		<comment id='7' author='alinaSarwar' date='2020-05-26T08:38:11Z'>
 		Oh, I am using pytorch 1.4. I will test with pytorch 1.5. Thank you!
 		</comment>
 		<comment id='8' author='alinaSarwar' date='2020-07-25T08:39:52Z'>
 		This issue has been automatically marked as stale due to inactivity and will be closed in 7 days if no further activity occurs. If further support is needed, please provide an update and/or more details.
 		</comment>
 	</comments>
 </bug>
<commit id='2a96be83f629bfbf2aa5c3937e9c6e86e050bdad' author='Scott McKay' date='2020-05-29 14:48:07+10:00'>
 	<dmm_unit complexity='0.5384615384615384' interfacing='0.9076923076923077' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='onnxruntime\core\graph\graph.cc' new_name='onnxruntime\core\graph\graph.cc'>
 		<file_info nloc='2172' complexity='542' token_count='17069'></file_info>
 		<method name='onnxruntime::NodeArg::UpdateTypeAndShape' parameters='input_type,strict,override_types,logger'>
 				<method_info nloc='80' complexity='19' token_count='521' nesting_level='1' start_line='211' end_line='304'></method_info>
 			<added_lines>211,212</added_lines>
 			<deleted_lines>211,212</deleted_lines>
 		</method>
 		<method name='onnxruntime::Graph::InitializeStateFromModelFileGraphProto' parameters=''>
 				<method_info nloc='57' complexity='15' token_count='434' nesting_level='1' start_line='864' end_line='941'></method_info>
 			<added_lines>891</added_lines>
 			<deleted_lines>883</deleted_lines>
 		</method>
 		<method name='onnxruntime::Graph::Graph' parameters='owning_model,graph_proto,domain_to_version,ir_version,schema_registry,parent_graph,parent_node,logger,model_functions'>
 				<method_info nloc='88' complexity='19' token_count='685' nesting_level='1' start_line='739' end_line='854'></method_info>
 			<added_lines>787,788,789,790,791,792,793,794,795,796,797,824</added_lines>
 			<deleted_lines>787,788,789,816</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='onnxruntime\core\providers\cpu\controlflow\if.cc' new_name='onnxruntime\core\providers\cpu\controlflow\if.cc'>
 		<file_info nloc='209' complexity='30' token_count='1617'></file_info>
 		<method name='onnxruntime::IfImpl::AllocateOutputTensors' parameters=''>
 				<method_info nloc='24' complexity='7' token_count='176' nesting_level='1' start_line='245' end_line='278'></method_info>
 			<added_lines>251,253,254,256,257,258,259,260,262,263,265,266,267,268,269,270,271</added_lines>
 			<deleted_lines>251,252,253,254,256,258,259,260,261,262,263,265,266,268</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='onnxruntime\test\providers\cpu\controlflow\loop_test.cc' new_name='onnxruntime\test\providers\cpu\controlflow\loop_test.cc'>
 		<file_info nloc='576' complexity='30' token_count='5319'></file_info>
 		<method name='onnxruntime::test::TEST' parameters='Loop,PassThroughSubgraphInputNoTypeOrShape'>
 				<method_info nloc='57' complexity='2' token_count='602' nesting_level='2' start_line='831' end_line='930'></method_info>
 			<added_lines>831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>578,827,828,829,830,931</added_lines>
 			<deleted_lines>578</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
