<bug_data>
<bug id='5522' author='MarlNox' open_date='2020-10-17T00:52:02Z' closed_time='2020-10-22T02:03:28Z'>
 	<summary>Convert to mobile Error: Onnxruntime_test_all (Failed) - Tests Fail</summary>
 	<description>
 Describe the bug
 While building the compressed mobile version of my model only 67% of the tests succeed. Skipping tests seems to produce no result.
 To Reproduce
 "onnxruntime/build.sh" --config=MinSizeRel --build_shared_lib --minimal_build --disable_ml_ops --disable_exceptions --include_ops_by_config "model/required_operators.config"
 Expected behavior
 Create the compressed mobile model.
 required_operators.config
 Assuming this may have something to do with the operators, I'm posting the contents of the required_operators.config.
 # Generated from --model_path /tmp/tmp0_jsx1i4  com.microsoft;1;FusedConv ai.onnx;9;Add,BatchNormalization,Concat,Conv,ConvTranspose,Relu
 Error Code
 1: [----------] 2 tests from OrtModelOnlyTests 1: [ RUN      ] OrtModelOnlyTests.LoadOrtFormatModel 1: /home/me/Documents/onnxruntime/onnxruntime/test/framework/ort_model_only_test.cc:60: Failure 1: Value of: _tmp_status.IsOK() 1:   Actual: false 1: Expected: true 1: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Failed to find kernel for Loop(11) (node Loop1). Op with name (Loop1) and type (Loop) kernel not found in CPUExecutionProvider. No matching hash for 15949596726138182496 1: [  FAILED  ] OrtModelOnlyTests.LoadOrtFormatModel (11 ms) 1: [ RUN      ] OrtModelOnlyTests.LoadOrtFormatModelFromBuffer 1: /home/me/Documents/onnxruntime/onnxruntime/test/framework/ort_model_only_test.cc:60: Failure 1: Value of: _tmp_status.IsOK() 1:   Actual: false 1: Expected: true 1: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Failed to find kernel for Loop(11) (node Loop1). Op with name (Loop1) and type (Loop) kernel not found in CPUExecutionProvider. No matching hash for 15949596726138182496 1: [  FAILED  ] OrtModelOnlyTests.LoadOrtFormatModelFromBuffer (12 ms) 1: [----------] 2 tests from OrtModelOnlyTests (23 ms total)
 `
 67% tests passed, 1 tests failed out of 3
 Total Test time (real) =   2.97 sec
 The following tests FAILED:
 1 - onnxruntime_test_all (Failed)
 Errors while running CTest
 Traceback (most recent call last):
 File "/home/me/Documents/onnxruntime/tools/ci_build/build.py", line 1949, in 
 sys.exit(main())
 File "/home/me/Documents/onnxruntime/tools/ci_build/build.py", line 1886, in main
 run_onnxruntime_tests(args, source_dir, ctest_path, build_dir, configs)
 File "/home/me/Documents/onnxruntime/tools/ci_build/build.py", line 1344, in run_onnxruntime_tests
 run_subprocess(ctest_cmd, cwd=cwd, dll_path=dll_path)
 File "/home/me/Documents/onnxruntime/tools/ci_build/build.py", line 449, in run_subprocess
 env=my_env, shell=shell)
 File "/home/me/anaconda3/envs/wav2lip/lib/python3.7/subprocess.py", line 512, in run
 output=stdout, stderr=stderr)
 subprocess.CalledProcessError: Command '['/usr/bin/ctest', '--build-config', 'MinSizeRel', '--verbose', '--timeout', '3600']' returned non-zero exit status 8.
 `
 	</description>
 	<comments>
 		<comment id='1' author='MarlNox' date='2020-10-20T21:03:23Z'>
 		The documentation should also specify . It's called out in the info on the reduced build &lt;denchmark-link:https://github.com/microsoft/onnxruntime/blob/master/docs/Reduced_Operator_Kernel_build.md#build-time-reduction&gt;here&lt;/denchmark-link&gt;
 .
 		</comment>
 		<comment id='2' author='MarlNox' date='2020-10-21T19:03:05Z'>
 		
 The documentation should also specify --skip_tests. It's called out in the info on the reduced build here.
 
 I just did and the script ran without errors, but there's no new files being created by the operation.
 Run command:
 "onnxruntime/build.sh" --config=MinSizeRel --build_shared_lib --minimal_build --disable_ml_ops --disable_exceptions --include_ops_by_config "model/required_operators.config" --skip_tests
 &lt;denchmark-code&gt;[ 98%] Linking CXX executable onnxruntime_perf_test
 [100%] Built target onnxruntime_perf_test
 [100%] Built target custom_op_library
 2020-10-21 20:59:39,845 Build [DEBUG] - Subprocess completed. Return code=0
 2020-10-21 20:59:39,846 Build [INFO] - Build complete
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='3' author='MarlNox' date='2020-10-21T21:53:39Z'>
 		&lt;denchmark-link:https://github.com/microsoft/onnxruntime/blob/master/docs/ONNX_Runtime_for_Mobile_Platforms.md#1-create-ort-format-model-and-configuration-file-with-required-operators&gt;https://github.com/microsoft/onnxruntime/blob/master/docs/ONNX_Runtime_for_Mobile_Platforms.md#1-create-ort-format-model-and-configuration-file-with-required-operators&lt;/denchmark-link&gt;
  has details of the step to create the ORT format models.
 build.sh is from the second step which creates the ONNX Runtime shared library (under something like the build/Linux/MinSizeRel directory).
 		</comment>
 		<comment id='4' author='MarlNox' date='2020-10-21T23:01:20Z'>
 		
 
 The documentation should also specify --skip_tests. It's called out in the info on the reduced build here.
 
 I just did and the script ran without errors, but there's no new files being created by the operation.
 Run command:
 "onnxruntime/build.sh" --config=MinSizeRel --build_shared_lib --minimal_build --disable_ml_ops --disable_exceptions --include_ops_by_config "model/required_operators.config" --skip_tests
 [ 98%] Linking CXX executable onnxruntime_perf_test
 [100%] Built target onnxruntime_perf_test
 [100%] Built target custom_op_library
 2020-10-21 20:59:39,845 Build [DEBUG] - Subprocess completed. Return code=0
 2020-10-21 20:59:39,846 Build [INFO] - Build complete
 
 
 Of course I have already performed step one and have the .ort file, and the .config file already.
 The folder Linux/build/MinSizeRel has been created along with all its subfiles/subfolders, however there's no generated model. Are there any further steps to get to the mobile optimized ORT file?
 		</comment>
 		<comment id='5' author='MarlNox' date='2020-10-22T00:05:55Z'>
 		The .ort file contains the model that was converted from ONNX format to the mobile optimized ORT format. This .ort file is what you create the inference session with instead of a .onnx file.
 		</comment>
 		<comment id='6' author='MarlNox' date='2020-10-22T02:03:28Z'>
 		Thanks a lot for the clarification!
 Everything works smoothly now.
 		</comment>
 	</comments>
 </bug>
<commit id='6d35be215fe9e43363d267cf995c747fbeef4d96' author='Scott McKay' date='2020-10-22 08:55:42+10:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='docs\ONNX_Runtime_for_Mobile_Platforms.md' new_name='docs\ONNX_Runtime_for_Mobile_Platforms.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>51,82,86</added_lines>
 			<deleted_lines>51,82,86</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
