<bug_data>
<bug id='36' author='bamos' open_date='2015-10-25T17:07:47Z' closed_time='2016-01-11T21:46:58Z'>
 	<summary>Training: inconsistent tensor size</summary>
 	<description>
 &lt;denchmark-code&gt;training(master*)$ ./main.lua -data ~/openface/data/casia-facescrub/dlib-affine-224-split/ -imgDim 224 -batchSize 20 -nDonkeys -1
 
 ==&gt; doing epoch on training data:
 ==&gt; online epoch # 1
 
 /home/bamos/torch/install/bin/luajit: inconsistent tensor size at /home/bamos/torch/pkg/torch/lib/TH/generic/THTensorCopy.c:7
 stack traceback:
         [C]: at 0x7fecb5c9aa60
         [C]: in function '__newindex'
         /home/bamos/openface/training/train.lua:132: in function 'f2'
         /home/bamos/openface/training/data.lua:36: in function 'addjob'
         /home/bamos/openface/training/train.lua:48: in function 'train'
         ./main.lua:35: in main chunk
         [C]: in function 'dofile'
         ...amos/torch/install/lib/luarocks/rocks/trepl/scm-1/bin/th:131: in main chunk
         [C]: at 0x00406670
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='bamos' date='2015-10-26T20:08:49Z'>
 		hi, any clue how to resolve it? I have the same error.
 		</comment>
 		<comment id='2' author='bamos' date='2015-10-26T20:41:33Z'>
 		Hi, yes, I just looked at this again and it's because I forgot to specify the nn2 model for images sized 224 and the training was defaulting to the nn4 model, which only supports inputs of 96x96. Because of this, the training code was passing in a tensor with 20 images, sized 20,3,224,224 and was receiving back a tensor sized 500,128 instead of 20,128.
 
  This error is very confusing and I'll add a check to prevent mis-matched sizes like this.
 
 -Brandon.
 		</comment>
 		<comment id='3' author='bamos' date='2015-10-28T07:43:07Z'>
 		What is the format of the training data in the folder ~/openface/data/casia-facescrub/dlib-affine-224-split/ ?
 		</comment>
 		<comment id='4' author='bamos' date='2015-10-28T11:53:54Z'>
 		Hi &lt;denchmark-link:https://github.com/Prithviraj7&gt;@Prithviraj7&lt;/denchmark-link&gt;
  -  and  subdirectories containing directories of people with images.
 This can be produced with steps 1 and 2 of 'Training new models' in the README:
 &lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;
 
 
 
 Create a directory for your raw images so that images from different
 people are in different subdirectories. The names of the labels or
 images do not matter, and each person can have a different amount of images.
 The images should be formatted as jpg or png and have
 a lowercase extension.
 $ tree data/mydataset/raw
 person-1
 ├── image-1.jpg
 ├── image-2.png
 ...
 └── image-p.png
 
 ...
 
 person-m
 ├── image-1.png
 ├── image-2.jpg
 ...
 └── image-q.png
 
 
 
 Preprocess the raw images, change 8 to however many
 separate processes you want to run:
 for N in {1..8}; do ./util/align-dlib.py &lt;path-to-raw-data&gt; align affine &lt;path-to-aligned-data&gt; --size 96 &amp;; done.
 Prune out directories with less than N (I use 10) images
 per class with ./util/prune-dataset.py &lt;path-to-aligned-data&gt; --numImagesThreshold &lt;N&gt; and
 then split the dataset into train and val subdirectories
 with ./util/create-train-val-split.py &lt;path-to-aligned-data&gt; &lt;validation-ratio&gt;.
 
 
 		</comment>
 		<comment id='5' author='bamos' date='2016-01-11T21:46:58Z'>
 		I've added an imgDim attribute to model definitions. The training code will error if it's not set or if the command-line option is incorrectly set. I decided to keep the command-line option so the user is aware of this resizing and in case a user's loading from a pre-trained model that they don't have a model definition for.
 -Brandon.
 		</comment>
 	</comments>
 </bug>
<commit id='0479d0e3459633489a3a2a0110be6bd938fbd8b6' author='Brandon Amos' date='2016-01-11 16:44:50-05:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='training\donkey.lua' new_name='training\donkey.lua'>
 		<file_info nloc='60' complexity='2' token_count='401'></file_info>
 		<modified_lines>
 			<added_lines>28,29</added_lines>
 			<deleted_lines>28,29</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='training\model.lua' new_name='training\model.lua'>
 		<file_info nloc='91' complexity='10' token_count='504'></file_info>
 		<modified_lines>
 			<added_lines>85,86</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='training\opts.lua' new_name='training\opts.lua'>
 		<file_info nloc='49' complexity='7' token_count='377'></file_info>
 		<method name='M.parse' parameters='arg'>
 				<method_info nloc='42' complexity='6' token_count='334' nesting_level='0' start_line='11' end_line='65'></method_info>
 			<added_lines>48</added_lines>
 			<deleted_lines>48</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
