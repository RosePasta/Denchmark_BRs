<bug_data>
<bug id='1367' author='patriciacs1994' open_date='2020-12-15T15:45:43Z' closed_time='2020-12-16T18:53:36Z'>
 	<summary>No Expected Model Output dimensions</summary>
 	<description>
 Hello,
 I am using an autoencoder but the output channel dimension of the model does not correspond with the out-channel variable.
 Here is my code:
 &lt;denchmark-code&gt;# create a training data loader
     train_ds = ArrayDataset(img_train[0], train_imtrans, img_train[1], train_segtrans)
     train_loader = DataLoader(train_ds, batch_size=16, num_workers=8, pin_memory=torch.cuda.is_available())
     # create a validation data loader
     val_ds = ArrayDataset(img_val[0], val_imtrans, img_val[1], val_segtrans)
     val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())
     
     # create AE, MSELoss and Adam optimizer
     device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
     model = monai.networks.nets.AutoEncoder(
         dimensions=2,
         in_channels=1,
         out_channels=4,
         channels=(16, 32, 64, 128, 256),
         strides=(2, 2, 2, 2),
         num_res_units = 2
     )
     loss_function = torch.nn.MSELoss()
     optimizer = torch.optim.Adam(model.parameters(), 1e-3)
     lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)
     # start a typical PyTorch training
     val_interval = 2
     best_metric = -1
     best_metric_epoch = -1
     best_val_loss = 10000
     best_val_loss_epoch = 10000
     epoch_loss_values = list()
     val_loss_values = list()
 
     metric_values = list()
     writer = SummaryWriter()
     post_pred = AsDiscrete(argmax=True, to_onehot=True, n_classes=4)
     post_label = AsDiscrete(to_onehot=True, n_classes=4)
     
     for epoch in range(200):
         print("-" * 10)
         print('Epoch {}/{}'.format(epoch + 1, 200))
         model.train()
         epoch_loss = 0
         step = 0
         for batch_data in train_loader:
             metric_sum = 0.0
             metric_count = 0
             metric_batch = 0 
             step += 1
             inputs, labels = batch_data[0], batch_data[1]
             optimizer.zero_grad()
             outputs = model(inputs)
             loss = loss_function(outputs, labels)
             loss.backward()
             optimizer.step()
             epoch_loss += loss.item()
             epoch_len = len(train_ds) // train_loader.batch_size
             outputs1 = post_pred(outputs)
             labels1 = post_label(labels)
             value_train = monai.metrics.compute_meandice(y_pred=outputs1, y=labels1, include_background=False)
             
             metric_count += value_train.shape[1]
             metric_batch += value_train.shape[0]
             metric_sum += value_train.sum().item()
             
             writer.add_scalar("train_loss", loss.item(), epoch_len * epoch + step)
             
         metric1 = metric_sum / (metric_count * metric_batch)        
         epoch_loss /= step
         epoch_loss_values.append(epoch_loss)
         print(f"epoch {epoch + 1} average loss: {epoch_loss:.4f} mean dice: {metric1:.4f}")
 &lt;/denchmark-code&gt;
 
 I am getting this error:
 RuntimeError                              Traceback (most recent call last)
  in 
 224
 225 with tempfile.TemporaryDirectory() as tempdir:
 --&gt; 226     outputs, labels, outputs1, labels1, inputs, labels = main(tempdir, img_train, img_val)
  in main(tempdir, img_train, img_val)
 121             epoch_loss += loss.item()
 122             epoch_len = len(train_ds) // train_loader.batch_size
 --&gt; 123             outputs1 = post_pred(outputs)
 124             labels1 = post_label(labels)
 125             value_train = monai.metrics.compute_meandice(y_pred=outputs1, y=labels1, include_background=False)
 ~\AppData\Local\Programs\Python\Python36\lib\site-packages\monai\transforms\post\array.py in call(self, img, argmax, to_onehot, n_classes, threshold_values, logit_thresh)
 156             _nclasses = self.n_classes if n_classes is None else n_classes
 157             assert isinstance(_nclasses, int), "One of self.n_classes or n_classes must be an integer"
 --&gt; 158             img = one_hot(img, _nclasses)
 159
 160         if threshold_values or self.threshold_values:
 ~\AppData\Local\Programs\Python\Python36\lib\site-packages\monai\networks\utils.py in one_hot(labels, num_classes, dtype, dim)
 45
 46     o = torch.zeros(size=sh, dtype=dtype, device=labels.device)
 ---&gt; 47     labels = o.scatter_(dim=dim, index=labels.long(), value=1)
 48
 49     return labels
 RuntimeError: index 5 is out of bounds for dimension 1 with size 4
 I have checked the input and output shapes of the model and I got the next:
 inputs: torch.Size([16, 1, 256, 256])
 outputs: torch.Size([16, 16, 256, 256])
 Why if I set the out-channel to 4 I got a channel of 16 in the outputs?
 	</description>
 	<comments>
 		<comment id='1' author='patriciacs1994' date='2020-12-16T14:09:45Z'>
 		Hi &lt;denchmark-link:https://github.com/rijobro&gt;@rijobro&lt;/denchmark-link&gt;
  ,
 Could you please help check this issue as you are expert on the AutoEncoder?
 Thanks in advance.
 		</comment>
 		<comment id='2' author='patriciacs1994' date='2020-12-16T15:11:14Z'>
 		Hi,
 I went able to fix it by changing the number of channels:
 &lt;denchmark-code&gt;    model = monai.networks.nets.AutoEncoder(
         dimensions=2,
         in_channels=1,
         out_channels=4,
         channels=(4,8,16, 32),
         strides=(2, 2, 2, 2),
         num_res_units = 2
     )
 &lt;/denchmark-code&gt;
 
 Thank you, anyway.
 		</comment>
 		<comment id='3' author='patriciacs1994' date='2020-12-16T16:27:39Z'>
 		Looks a little bit suspicious to me. I'll look at this, thanks for bringing it to our attention.
 		</comment>
 		<comment id='4' author='patriciacs1994' date='2020-12-16T16:32:30Z'>
 		Ah I see the problem. The number of strides should match the number of channels for the autoencoder, which it doesn't in your first example.
 I'll add a check for this to avoid future confusion.
 		</comment>
 	</comments>
 </bug>
<commit id='e213a89612344d57f898cc81a2cd29c68d04f14b' author='Richard Brown' date='2020-12-16 18:53:35+00:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='monai\networks\nets\autoencoder.py' new_name='monai\networks\nets\autoencoder.py'>
 		<file_info nloc='162' complexity='13' token_count='1159'></file_info>
 		<modified_lines>
 			<added_lines>56,57,58,59</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_autoencoder.py' new_name='tests\test_autoencoder.py'>
 		<file_info nloc='78' complexity='3' token_count='521'></file_info>
 		<method name='test_channel_stride_difference' parameters='self'>
 				<method_info nloc='3' complexity='1' token_count='20' nesting_level='1' start_line='88' end_line='90'></method_info>
 			<added_lines>88,89,90</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>65,66,67,68,69,70,71,72,73,91</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
