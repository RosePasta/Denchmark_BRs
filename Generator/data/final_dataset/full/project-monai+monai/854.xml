<bug_data>
<bug id='854' author='elitap' open_date='2020-08-05T15:06:34Z' closed_time='2020-08-07T10:25:08Z'>
 	<summary>sliding_window_inference uses to much gpu memory if roi_size is small and images to infer large</summary>
 	<description>
 Describe the bug
 sliding_window_inference runns ot of memory if roi_size is small and images to infer large
 To Reproduce
 evaluete a highres3dnet with images larger than 512x512x256 and roi_size of the sliding_window_inference option of [16,16,16] and the required gpu memory exceeds 8gb
 Expected behavior
 less memory should be used
 Environment (please complete the following information):
 MONAI version: 0.2.0
 Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]
 Numpy version: 1.19.0
 Pytorch version: 1.5.0+cu101
 Additional context
 sliding window inference seems to be broken with the current nightlies, a runntime exception occures in monai.networks.utils in to_norm_affine at line: new_affine = src_xform @ affine @ torch.inverse(dst_xform). Seems that the segmentation saver is not correctely reading out the meta data dict from the batch.
 Have the bug fixed at least for version 0.2.0 and will send a pull request
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='8f1c290b58ddfb4f9a9f5810916c3a7d48e26643' author='elitap' date='2020-08-07 11:25:07+01:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='monai\inferers\utils.py' new_name='monai\inferers\utils.py'>
 		<file_info nloc='132' complexity='2' token_count='942'></file_info>
 		<method name='sliding_window_inference' parameters='Tensor,int,float,BlendMode,CONSTANT,PytorchPadMode,CONSTANT,float,None'>
 				<method_info nloc='10' complexity='1' token_count='92' nesting_level='0' start_line='21' end_line='30'></method_info>
 			<added_lines>30</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>12,60,61,62,63,85,86,87,119,126,129,130</added_lines>
 			<deleted_lines>12,111,118,121,122</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_integration_sliding_window.py' new_name='tests\test_integration_sliding_window.py'>
 		<file_info nloc='63' complexity='8' token_count='583'></file_info>
 		<method name='run_test._sliding_window_processor' parameters='_engine,batch'>
 				<method_info nloc='6' complexity='1' token_count='52' nesting_level='1' start_line='43' end_line='48'></method_info>
 			<added_lines>47</added_lines>
 			<deleted_lines>47</deleted_lines>
 		</method>
 		<method name='run_test' parameters='batch_size,img_name,seg_name,output_dir,device'>
 				<method_info nloc='17' complexity='1' token_count='205' nesting_level='0' start_line='33' end_line='60'></method_info>
 			<added_lines>47</added_lines>
 			<deleted_lines>47</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_sliding_window_inference.py' new_name='tests\test_sliding_window_inference.py'>
 		<file_info nloc='37' complexity='4' token_count='521'></file_info>
 		<method name='test_sliding_window_default' parameters='self,image_shape,roi_shape,sw_batch_size,overlap,mode'>
 				<method_info nloc='7' complexity='1' token_count='87' nesting_level='1' start_line='41' end_line='50'></method_info>
 			<added_lines>41,42,43,50</added_lines>
 			<deleted_lines>41,43</deleted_lines>
 		</method>
 		<method name='test_sliding_window_default' parameters='self,image_shape,roi_shape,sw_batch_size,overlap,mode,device'>
 				<method_info nloc='9' complexity='3' token_count='121' nesting_level='1' start_line='50' end_line='61'></method_info>
 			<added_lines>50,52,53,59</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>20,22,24,26,28,30,32,34,35,36,37,38,39,40</added_lines>
 			<deleted_lines>20,22,24,26,28,30,32,34</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
