<bug_data>
<bug id='161' author='cyrusmvahid' open_date='2019-07-01T11:34:32Z' closed_time='2019-08-23T18:24:19Z'>
 	<summary>canonical estimator results in shape error</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 I am trying to run the twit example on other estimators. In this case canonical rnn.
 Here is the code:
 &lt;denchmark-code&gt;canonical_estimator = CanonicalRNNEstimator(freq="5min", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))
 canonical_predictor = canonical_estimator.train(training_data=training_data)
 &lt;/denchmark-code&gt;
 
 I receive shape error.
 &lt;denchmark-code&gt;MXNetError: Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&amp;dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]
 &lt;/denchmark-code&gt;
 
 my context length is 10. It seems as the ndarray has been squeezed somewhere.
 &lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;canonical_estimator = CanonicalRNNEstimator(freq="5min", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))
 canonical_predictor = canonical_estimator.train(training_data=training_data)
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Error Message&lt;/denchmark-h&gt;
 
 I am trying to run the twit example on other estimators. In this case canonical rnn.
 Here is the code:
 &lt;denchmark-code&gt;canonical_estimator = CanonicalRNNEstimator(freq="5min", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))
 canonical_predictor = canonical_estimator.train(training_data=training_data)
 &lt;/denchmark-code&gt;
 
 I receive shape error.
 &lt;denchmark-code&gt;MXNetError: Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&amp;dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]
 &lt;/denchmark-code&gt;
 
 my context length is 10. It seems as the ndarray has been squeezed somewhere.
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 
 Operating system:
 Python version:
 GluonTS version:
 
 (Add as much information about your environment as possible, e.g. dependencies versions.)
 	</description>
 	<comments>
 		<comment id='1' author='cyrusmvahid' date='2019-07-01T11:38:06Z'>
 		I am trying to run the twit example on other estimators. In this case canonical rnn.
 Here is the code:
 &lt;denchmark-code&gt;canonical_estimator = CanonicalRNNEstimator(freq="5min", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))
 canonical_predictor = canonical_estimator.train(training_data=training_data)
 &lt;/denchmark-code&gt;
 
 I receive shape error.
 &lt;denchmark-code&gt;MXNetError: Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&amp;dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]
 &lt;/denchmark-code&gt;
 
 my context length is 10. It seems as the ndarray has been squeezed somewhere.
 Full error:
 &lt;denchmark-code&gt;infer_shape error. Arguments:
   data0: (32, 1)
   data1: (32, 10, 5)
   data2: (32, 10)
 ---------------------------------------------------------------------------
 DeferredInitializationError               Traceback (most recent call last)
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _call_cached_op(self, *args)
     802             cargs = [args[i] if is_arg else i.data()
 --&gt; 803                      for is_arg, i in self._cached_op_args]
     804         except DeferredInitializationError:
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in &lt;listcomp&gt;(.0)
     802             cargs = [args[i] if is_arg else i.data()
 --&gt; 803                      for is_arg, i in self._cached_op_args]
     804         except DeferredInitializationError:
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/parameter.py in data(self, ctx)
     493                                "instead." % (self.name, str(ctx), self._stype))
 --&gt; 494         return self._check_and_get(self._data, ctx)
     495 
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/parameter.py in _check_and_get(self, arr_list, ctx)
     207                 "You can also avoid deferred initialization by specifying in_units, " \
 --&gt; 208                 "num_features, etc., for network layers."%(self.name))
     209         raise RuntimeError(
 
 DeferredInitializationError: Parameter 'rnn8_lstm0_l0_i2h_weight' has not been initialized yet because initialization was deferred. Actual initialization happens during the first forward pass. Please pass one batch of data through the network before accessing Parameters. You can also avoid deferred initialization by specifying in_units, num_features, etc., for network layers.
 
 During handling of the above exception, another exception occurred:
 
 MXNetError                                Traceback (most recent call last)
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _deferred_infer_shape(self, *args)
     788         try:
 --&gt; 789             self.infer_shape(*args)
     790         except Exception as e:
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in infer_shape(self, *args)
     861         """Infers shape of Parameters from inputs."""
 --&gt; 862         self._infer_attrs('infer_shape', 'shape', *args)
     863 
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _infer_attrs(self, infer_fn, attr, *args)
     850             arg_attrs, _, aux_attrs = getattr(out, infer_fn)(
 --&gt; 851                 **{i.name: getattr(j, attr) for i, j in zip(inputs, args)})
     852             if arg_attrs is None:
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/symbol/symbol.py in infer_shape(self, *args, **kwargs)
     995         try:
 --&gt; 996             res = self._infer_shape_impl(False, *args, **kwargs)
     997             if res[1] is None:
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/symbol/symbol.py in _infer_shape_impl(self, partial, *args, **kwargs)
    1125             ctypes.byref(aux_shape_data),
 -&gt; 1126             ctypes.byref(complete)))
    1127         if complete.value != 0:
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/base.py in check_call(ret)
     251     if ret != 0:
 --&gt; 252         raise MXNetError(py_str(_LIB.MXGetLastError()))
     253 
 
 MXNetError: Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&amp;dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]
 
 Stack trace returned 10 entries:
 [bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f935a) [0x7f928cf2a35a]
 [bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f9981) [0x7f928cf2a981]
 [bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x73e45d) [0x7f928d26f45d]
 [bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x7a25b6) [0x7f928d2d35b6]
 [bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x9c33d8) [0x7f928d4f43d8]
 [bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e0e10a) [0x7f928f93f10a]
 [bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e10a84) [0x7f928f941a84]
 [bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(MXSymbolInferShape+0x15ba) [0x7f928f8a79aa]
 [bt] (8) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f92fc62dec0]
 [bt] (9) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f92fc62d87d]
 
 
 
 During handling of the above exception, another exception occurred:
 
 ValueError                                Traceback (most recent call last)
 &lt;ipython-input-143-b6d286edd137&gt; in &lt;module&gt;()
       1 canonical_estimator = CanonicalRNNEstimator(freq="5min", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))
 ----&gt; 2 canonical_predictor = canonical_estimator.train(training_data=training_data)
       3 
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py in train(self, training_data)
     187     def train(self, training_data: Dataset) -&gt; Predictor:
     188 
 --&gt; 189         training_transformation, trained_net = self.train_model(training_data)
     190 
     191         # ensure that the prediction network is created within the same MXNet
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py in train_model(self, training_data)
     180             net=trained_net,
     181             input_names=get_hybrid_forward_input_names(trained_net),
 --&gt; 182             train_iter=training_data_loader,
     183         )
     184 
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/trainer/_base.py in __call__(self, net, input_names, train_iter)
     256 
     257                             with mx.autograd.record():
 --&gt; 258                                 output = net(*inputs)
     259 
     260                                 # network can returns several outputs, the first being always the loss
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in __call__(self, *args)
     538             hook(self, args)
     539 
 --&gt; 540         out = self.forward(*args)
     541 
     542         for hook in self._forward_hooks.values():
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in forward(self, x, *args)
     905             with x.context as ctx:
     906                 if self._active:
 --&gt; 907                     return self._call_cached_op(x, *args)
     908 
     909                 try:
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _call_cached_op(self, *args)
     803                      for is_arg, i in self._cached_op_args]
     804         except DeferredInitializationError:
 --&gt; 805             self._deferred_infer_shape(*args)
     806             cargs = []
     807             for is_arg, i in self._cached_op_args:
 
 ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _deferred_infer_shape(self, *args)
     791             error_msg = "Deferred initialization failed because shape"\
     792                         " cannot be inferred. {}".format(e)
 --&gt; 793             raise ValueError(error_msg)
     794 
     795     def _call_cached_op(self, *args):
 
 ValueError: Deferred initialization failed because shape cannot be inferred. Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&amp;dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]
 
 Stack trace returned 10 entries:
 [bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f935a) [0x7f928cf2a35a]
 [bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f9981) [0x7f928cf2a981]
 [bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x73e45d) [0x7f928d26f45d]
 [bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x7a25b6) [0x7f928d2d35b6]
 [bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x9c33d8) [0x7f928d4f43d8]
 [bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e0e10a) [0x7f928f93f10a]
 [bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e10a84) [0x7f928f941a84]
 [bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(MXSymbolInferShape+0x15ba) [0x7f928f8a79aa]
 [bt] (8) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f92fc62dec0]
 [bt] (9) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f92fc62d87d]
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='2' author='cyrusmvahid' date='2019-07-01T11:40:42Z'>
 		&lt;denchmark-link:https://github.com/cyrusmvahid&gt;@cyrusmvahid&lt;/denchmark-link&gt;
  thanks for submitting this -- could you enclose snippets and error traces in triple ticks (`) to have it formatted nicely?
 &lt;denchmark-code&gt;like this
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='3' author='cyrusmvahid' date='2019-07-01T11:44:10Z'>
 		done
 sorry
 		</comment>
 		<comment id='4' author='cyrusmvahid' date='2019-07-01T11:47:27Z'>
 		
 done
 sorry
 
 Thank you, but remember to put triple ticks (```) one line before and one line after snippets and error traces. Sorry for being so pedantic, but nicely formatted issues are more likely to be looked into.
 		</comment>
 		<comment id='5' author='cyrusmvahid' date='2019-07-01T11:48:16Z'>
 		sure
 &lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;
 
 
 On Mon, Jul 1, 2019 at 1:47 PM Lorenzo Stella ***@***.***&gt; wrote:
  done
  sorry
 
  Thank you, but remember to put *triple* ticks (```) one line before and
  one line after snippets and error traces. Sorry for being so pedantic, but
  nicely formatted issues are more likely to be looked into.
 
  —
  You are receiving this because you were mentioned.
  Reply to this email directly, view it on GitHub
  &lt;#161?email_source=notifications&amp;email_token=ABLOVGPRZVJO6ZER4WFTLVLP5HVFDA5CNFSM4H4ROYDKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODY53ZPY#issuecomment-507231423&gt;,
  or mute the thread
  &lt;https://github.com/notifications/unsubscribe-auth/ABLOVGKEB7UEZ5UDHGYVEXDP5HVFDANCNFSM4H4ROYDA&gt;
  .
 
 
 
 		</comment>
 		<comment id='6' author='cyrusmvahid' date='2019-08-23T18:24:19Z'>
 		Fixed in &lt;denchmark-link:https://github.com/awslabs/gluon-ts/pull/254&gt;#254&lt;/denchmark-link&gt;
 , closing
 		</comment>
 	</comments>
 </bug>
<commit id='4740da09eaec4f819c39eb4c1577188586519515' author='Lorenzo Stella' date='2019-08-23 20:00:50+02:00'>
 	<dmm_unit complexity='0.0' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\gluonts\model\canonical\_network.py' new_name='src\gluonts\model\canonical\_network.py'>
 		<file_info nloc='137' complexity='6' token_count='544'></file_info>
 		<modified_lines>
 			<added_lines>44,110,178</added_lines>
 			<deleted_lines>44,110,111,179,180</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\model\test_models.py' new_name='test\model\test_models.py'>
 		<file_info nloc='228' complexity='15' token_count='1212'></file_info>
 		<method name='test_hybridize' parameters='Estimator,hyperparameters'>
 				<method_info nloc='5' complexity='1' token_count='34' nesting_level='0' start_line='267' end_line='271'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>267,268,269,270,271</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233</added_lines>
 			<deleted_lines>217,218,219,220,221,222,223,224,225,226,227,256,257,258,259,260,261,262,263,264,265,266,272,273</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
