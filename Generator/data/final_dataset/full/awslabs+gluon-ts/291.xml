<bug_data>
<bug id='291' author='AaronSpieler' open_date='2019-09-06T12:57:49Z' closed_time='2020-01-21T10:02:23Z'>
 	<summary>Item metrics dataframe incorrectly formatted</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 The data-frame containing the per time step metrics has a column item_id and filled with NaNs.
 &lt;denchmark-link:https://user-images.githubusercontent.com/25365592/64429596-a2796200-d0b6-11e9-89fd-a77bd31ffcc9.png&gt;&lt;/denchmark-link&gt;
 
 &lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;
 
 For example in the extended tutorial:
 &lt;denchmark-code&gt;evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])
 agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))
 item_metrics.head()
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 
 Operating system: MacOs
 Python version: 3.6.9
 GluonTS version: 0.3.3
 
 	</description>
 	<comments>
 		<comment id='1' author='AaronSpieler' date='2019-09-07T11:30:00Z'>
 		&lt;denchmark-link:https://github.com/AaronSpieler&gt;@AaronSpieler&lt;/denchmark-link&gt;
  I believe that depends on the dataset you use: if the entries in the dataset have an “item_id” field, then that will be used to tag the forecasts and appropriately fill in the associated field in the metrics dataframe.
 What dataset did that occur with? If it’s one of the provided datasets, then the field may be missing or have a different name, which should be fixed.
 		</comment>
 		<comment id='2' author='AaronSpieler' date='2019-09-09T09:31:38Z'>
 		Its the m4_hourly dataset (as used in the quick tutorial).
 		</comment>
 		<comment id='3' author='AaronSpieler' date='2019-10-10T12:22:14Z'>
 		&lt;denchmark-link:https://github.com/AaronSpieler&gt;@AaronSpieler&lt;/denchmark-link&gt;
  can you follow up on this?
 		</comment>
 		<comment id='4' author='AaronSpieler' date='2019-10-22T08:48:20Z'>
 		So all the provided datasets I tested contain a categorical feature called "feat_static_cat", which is equal to the corresponding index of the series.
 &lt;denchmark-link:https://user-images.githubusercontent.com/25365592/67270295-ab809000-f4b8-11e9-85aa-cc05ba93368c.png&gt;&lt;/denchmark-link&gt;
 
 Is this supposed to be renamed to "item_id" &lt;denchmark-link:https://github.com/lostella&gt;@lostella&lt;/denchmark-link&gt;
  ?
 		</comment>
 		<comment id='5' author='AaronSpieler' date='2019-10-22T11:59:36Z'>
 		&lt;denchmark-link:https://github.com/jaheba&gt;@jaheba&lt;/denchmark-link&gt;
  This is probably related to the fact that, unlike in section 1.3 of the Extended Forecasting Tutorial (&lt;denchmark-link:https://gluon-ts.mxnet.io/examples/extended_forecasting_tutorial/extended_tutorial.html#1.3-Use-your-time-series-and-features&gt;here&lt;/denchmark-link&gt;
 ), in version 0.3.3  does not have the  attribute anymore.
 &lt;denchmark-link:https://user-images.githubusercontent.com/32721837/67282999-2a82c200-f4d3-11e9-81df-7087232a0751.png&gt;&lt;/denchmark-link&gt;
 
 &lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;from gluonts.transform import FieldName
 [f"FieldName.{k} = '{v}'" for k, v in FieldName.__dict__.items() if not k.startswith('_')]
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 
 Operating system: CentOS
 Python version: 3.6.1
 GluonTS version: 0.3.3
 
 		</comment>
 		<comment id='6' author='AaronSpieler' date='2019-10-22T12:30:44Z'>
 		Mhhh, I see. Thanks &lt;denchmark-link:https://github.com/matsmaiwald&gt;@matsmaiwald&lt;/denchmark-link&gt;
 
 So FieldName.ITEM_ID was removed.
 However, that does not explain why the values that were stored in "item_id" were moved to "feat_static_cat". As far as I can tell in the case of the provided datasets they really only represent the index.
 Also, all provided datasets seem to be missing any covariates? Was this always the case? &lt;denchmark-link:https://github.com/jaheba&gt;@jaheba&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/lostella&gt;@lostella&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='7' author='AaronSpieler' date='2019-10-23T21:31:00Z'>
 		&lt;denchmark-link:https://github.com/AaronSpieler&gt;@AaronSpieler&lt;/denchmark-link&gt;
  the “item_id” serves a different purpose than feature fields: it is used to identify which time series from a dataset a forecast refers to. So for example, if you create multiple inference scenarios from a time series (like cutting it at two different points in time) you are still able to relate both predictions to the same time series, and for example aggregate evaluation metrics accordingly. Categorical features instead are usually fed into the networks, and setting them to an incremental, 0-based counter (essentially an ID) is one way to go in case no other relevant groupings are there.
 Note however, that a model trained by using such feature will be able to make predictions on time series with the same categorical features values, so the ID case puts some restrictions (no out of sample predictions allowed).
 Also yes, I believe no covariates was always the case for the built in datasets.
 		</comment>
 		<comment id='8' author='AaronSpieler' date='2019-10-23T21:35:20Z'>
 		Note that FieldName.ITEM_ID was not removed, but rather introduced: the documentation website happens to be ahead of 0.3.3, and reflects master instead (and we should get that fixed).
 		</comment>
 		<comment id='9' author='AaronSpieler' date='2019-11-11T17:19:53Z'>
 		Ok, then it seems ITEM_ID is just not properly set for the datasets. I will look into it again and see to it that it gets fixed.
 		</comment>
 		<comment id='10' author='AaronSpieler' date='2019-12-07T14:16:11Z'>
 		Hi &lt;denchmark-link:https://github.com/AaronSpieler&gt;@AaronSpieler&lt;/denchmark-link&gt;
  , do you have any updates on this question yet? In particular on how to include the  to associate a time series with its corresponding error measures (instead of getting NaNs for all ids)?
 Update:
 Simply including an item_id field in the dataset seems to be enough (did not expect it to be that easy):
 &lt;denchmark-link:https://user-images.githubusercontent.com/47742163/70376722-3c49e880-190c-11ea-9238-0638b208e31a.png&gt;&lt;/denchmark-link&gt;
 
 I used the original series id, i.e. W1 for first weekly time series, W2 for second weekly series, and so forth...
 		</comment>
 		<comment id='11' author='AaronSpieler' date='2020-01-01T21:39:18Z'>
 		Fixed by pull request: &lt;denchmark-link:https://github.com/awslabs/gluon-ts/pull/546&gt;#546&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='12' author='AaronSpieler' date='2020-01-19T15:53:13Z'>
 		I think this should be fixed by adjusting the scripts that generate the affected datasets, so that they write the “item_id” field
 		</comment>
 		<comment id='13' author='AaronSpieler' date='2020-01-21T19:11:56Z'>
 		The problem should be gone now if you use the master branch: loading the datasets once with “regenerate=True” should do the trick. This change will be included in the next release.
 		</comment>
 	</comments>
 </bug>
<commit id='1171f9e9e259fdc2cfe11030f0aa15f88c735f97' author='Lorenzo Stella' date='2020-01-21 11:02:22+01:00'>
 	<dmm_unit complexity='0.6666666666666666' interfacing='0.5' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\gluonts\dataset\repository\_gp_copula_2019.py' new_name='src\gluonts\dataset\repository\_gp_copula_2019.py'>
 		<file_info nloc='122' complexity='6' token_count='594'></file_info>
 		<method name='save_dataset' parameters='Path,GPCopulaDataset'>
 				<method_info nloc='16' complexity='2' token_count='91' nesting_level='0' start_line='137' end_line='154'></method_info>
 			<added_lines>150</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\gluonts\dataset\repository\_lstnet.py' new_name='src\gluonts\dataset\repository\_lstnet.py'>
 		<file_info nloc='151' complexity='7' token_count='786'></file_info>
 		<method name='generate_lstnet_dataset' parameters='Path,str'>
 				<method_info nloc='65' complexity='6' token_count='373' nesting_level='0' start_line='120' end_line='202'></method_info>
 			<added_lines>169,196</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\gluonts\dataset\repository\_m4.py' new_name='src\gluonts\dataset\repository\_m4.py'>
 		<file_info nloc='64' complexity='1' token_count='304'></file_info>
 		<modified_lines>
 			<added_lines>75,76,77,78,79,80,88,89,90,91,92,93</added_lines>
 			<deleted_lines>75,83</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\gluonts\dataset\repository\_util.py' new_name='src\gluonts\dataset\repository\_util.py'>
 		<file_info nloc='41' complexity='6' token_count='265'></file_info>
 		<method name='to_dict' parameters='ndarray,str,None'>
 				<method_info nloc='2' complexity='1' token_count='23' nesting_level='0' start_line='22' end_line='23'></method_info>
 			<added_lines>23</added_lines>
 			<deleted_lines>23</deleted_lines>
 		</method>
 		<method name='to_dict' parameters='ndarray,str,None,None'>
 				<method_info nloc='5' complexity='1' token_count='33' nesting_level='0' start_line='22' end_line='26'></method_info>
 			<added_lines>23,24,25,26</added_lines>
 			<deleted_lines>23</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>17,43,44,45</added_lines>
 			<deleted_lines>17</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
