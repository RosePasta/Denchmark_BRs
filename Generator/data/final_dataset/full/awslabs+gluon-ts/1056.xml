<bug_data>
<bug id='1056' author='elenaehrlich' open_date='2020-09-28T13:09:22Z' closed_time='2020-09-30T07:34:09Z'>
 	<summary>NaN handling of distributions' log_prob() for samples outside distribution's support</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 MixtureDistribution with components [Gaussian(..), Gamma(..)]) returns a NaN instead a real-value log-prob for x&lt;=0 (see MWE-1). MixtureDistributionOutput with components [GaussianOutput(..), GammaOutput(..)]) results in a NaN gradient for x&lt;=0 (see MWE-2).
 &lt;denchmark-h:h2&gt;MWE-1&lt;/denchmark-h&gt;
 
 import mxnet as mx
 from scipy import stats
 from gluonts.mx.distribution.mixture import *
 from gluonts.mx.distribution.gaussian import *
 from gluonts.mx.distribution.gamma import *
 
 p = 0.5
 mu, sigma = 0., 2.
 alpha, beta = 0.9, 2.
 
 # The log-prob of x=-1 should return a real-value and not NaN
 x = -1.
 
 scipy_logprob = np.log(p * stats.norm(mu, sigma).pdf(x) + (1-p) * stats.gamma(alpha, 1./beta).pdf(x))
 print('scipy_logprob', scipy_logprob)
 
 gaussian = Gaussian(mx.nd.array([mu]), mx.nd.array([sigma]))
 gamma = Gamma(mx.nd.array([alpha]), mx.nd.array([beta]))
 mixed_dist = MixtureDistribution(mx.nd.array([p,1-p]), [gaussian, gamma])
 gluonts_logprob = mixed_dist.log_prob(mx.nd.array([x]))
 print('gluonts_logprob', gluonts_logprob.asscalar())
 
 assert np.abs(scipy_logprob-gluonts_logprob.asscalar())&lt;1e-6
 &lt;denchmark-h:h2&gt;Error message or code output&lt;/denchmark-h&gt;
 
 AssertionError
 &lt;denchmark-h:h2&gt;MWE-2&lt;/denchmark-h&gt;
 
 import mxnet as mx, numpy as np
 from gluonts.gluonts_tqdm import tqdm
 from gluonts.model.common import Tensor
 from gluonts.mx.distribution.mixture import *
 from gluonts.mx.distribution.mixture import *
 from gluonts.mx.distribution.gaussian import *
 from gluonts.mx.distribution.gamma import *
 
 
 def fit_mixture_distribution(x: Tensor, mdo: MixtureDistributionOutput, variate_dimensionality: int = 1, epochs: Optional[int]=1_000):
 
     args_proj = mdo.get_args_proj()
     args_proj.initialize()
     args_proj.hybridize()
 
     input = mx.nd.ones((variate_dimensionality, 1))
 
 
     trainer = mx.gluon.Trainer(
         args_proj.collect_params(), "sgd", {"learning_rate": 0.02}
     )
     print('trainer.learning_rate',trainer.learning_rate)
 
     t = tqdm(list(range(epochs)))
     for _ in t:
         with mx.autograd.record():
             distr_args = args_proj(input)
             d = mdo.distribution(distr_args)
             loss = d.loss(x).mean()
         loss.backward()
         loss_value = loss.asnumpy()
         t.set_postfix({"loss": loss_value})
         trainer.step(1)
 
     distr_args = args_proj(input)
     d = mdo.distribution(distr_args)
     return d
 
 fit_mixture = fit_mixture_distribution(mx.nd.array([x]), MixtureDistributionOutput([GaussianOutput(), GammaOutput()]), 1, epochs=3)
 
 for ci, c in enumerate(fit_mixture.components):
     for ai, a in enumerate(c.args):
         assert ~np.isnan(a.asnumpy()), \
             f"NaN gradients led to {c}"
 &lt;denchmark-h:h2&gt;Error message or code output&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;AssertionError: NaN gradients led to gluonts.mx.distribution.gamma.Gamma(alpha=mxnet.nd.array([float("{x}")], dtype=numpy.float32), beta=mxnet.nd.array([float("{x}")], dtype=numpy.float32))
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 
 Operating system: MacOS 10.14.6
 Python version: Python 3.8.5
 GluonTS version: 0.5.1.dev102+g88a9832.d20200924
 MXNet version: 1.6.0
 
 	</description>
 	<comments>
 		<comment id='1' author='elenaehrlich' date='2020-09-29T18:58:20Z'>
 		&lt;denchmark-link:https://github.com/elenaehrlich&gt;@elenaehrlich&lt;/denchmark-link&gt;
  solved?
 		</comment>
 		<comment id='2' author='elenaehrlich' date='2020-09-30T07:34:09Z'>
 		&lt;denchmark-link:https://github.com/lostella&gt;@lostella&lt;/denchmark-link&gt;
  many thanks
 		</comment>
 	</comments>
 </bug>
<commit id='2ff399f70e1018b5f28832c04532f8ac011d4a10' author='Elena Ehrlich' date='2020-09-29 14:32:28+02:00'>
 	<dmm_unit complexity='1.0' interfacing='0.38095238095238093' size='0.19047619047619047'></dmm_unit>
 	<modification change_type='ADD' old_name='default.profraw' new_name='default.profraw'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\gluonts\mx\distribution\gamma.py' new_name='src\gluonts\mx\distribution\gamma.py'>
 		<file_info nloc='113' complexity='14' token_count='542'></file_info>
 		<method name='log_prob' parameters='self,Tensor'>
 				<method_info nloc='17' complexity='1' token_count='66' nesting_level='1' start_line='67' end_line='91'></method_info>
 			<added_lines>71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90</added_lines>
 			<deleted_lines>71,72,73,74,75</deleted_lines>
 		</method>
 		<method name='log_prob.gamma_log_prob' parameters='x,alpha,beta'>
 				<method_info nloc='7' complexity='1' token_count='44' nesting_level='2' start_line='71' end_line='77'></method_info>
 			<added_lines>71,72,73,74,75,76,77</added_lines>
 			<deleted_lines>71,72,73,74,75</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\gluonts\mx\distribution\genpareto.py' new_name='src\gluonts\mx\distribution\genpareto.py'>
 		<file_info nloc='138' complexity='16' token_count='754'></file_info>
 		<method name='log_prob.genpareto_log_prob' parameters='x,xi,beta'>
 				<method_info nloc='5' complexity='1' token_count='47' nesting_level='2' start_line='74' end_line='78'></method_info>
 			<added_lines>74,75,76,77,78</added_lines>
 			<deleted_lines>74,76,78</deleted_lines>
 		</method>
 		<method name='log_prob' parameters='self,Tensor'>
 				<method_info nloc='17' complexity='1' token_count='66' nesting_level='1' start_line='70' end_line='92'></method_info>
 			<added_lines>74,75,76,77,78,79,80,81,82,83,84,85,86,87,89,91</added_lines>
 			<deleted_lines>74,76,78</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\distribution\test_mixture.py' new_name='test\distribution\test_mixture.py'>
 		<file_info nloc='309' complexity='10' token_count='2406'></file_info>
 		<method name='fit_mixture_distribution' parameters='Tensor,MixtureDistributionOutput,int,int'>
 				<method_info nloc='5' complexity='1' token_count='22' nesting_level='0' start_line='270' end_line='274'></method_info>
 			<added_lines>270,271,272,273,274</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_inference_mixture_different_families' parameters='MixtureDistribution,MixtureDistributionOutput,int,serialize_fn'>
 				<method_info nloc='5' complexity='1' token_count='16' nesting_level='0' start_line='331' end_line='335'></method_info>
 			<added_lines>331,332,333,334,335</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_mixture_logprob' parameters='Distribution,Tensor,DistributionOutput'>
 				<method_info nloc='4' complexity='1' token_count='14' nesting_level='0' start_line='379' end_line='382'></method_info>
 			<added_lines>379,380,381,382</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>23,25,27,30,32,268,269,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
