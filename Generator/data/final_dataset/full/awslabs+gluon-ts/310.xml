<bug_data>
<bug id='310' author='lcallot' open_date='2019-09-13T13:14:46Z' closed_time='2019-10-11T14:35:24Z'>
 	<summary>Incorrect number of parameters in DeepARTrainingNetwork</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;
 
 The number of parameters in the training network logged by DeepAR is incorrect. The number of parameters
 &lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;
 
 from gluonts.model.deepar import DeepAREstimator
 from gluonts.dataset.common import ListDataset
 from gluonts.trainer import Trainer
 
 import numpy as np
 import pandas as pd
 
 url = "https://raw.githubusercontent.com/numenta/NAB/master/data/realTweets/Twitter_volume_AMZN.csv"
 df = pd.read_csv(url, header=0, index_col=0)
 
 training_data = ListDataset(
     [{"start": df.index[0], "target": df.value[:"2015-04-05 00:00:00"]}],
     freq = "5min"
 )
 
 def count_model_params(net) -&gt; int:
     params = net.collect_params()
     num_params = 0
     for p in params:
         v = params[p]
         num_params += np.prod(v.shape)
     return num_params
 
 trainer = Trainer(epochs=1,batch_size=1,num_batches_per_epoch=1)
 estimator = DeepAREstimator(freq="5min", prediction_length=12, trainer=trainer)
 predictor = estimator.train_model(training_data=training_data)
 npar = count_model_params(net=predictor.trained_net)
 print(f"Number of parameters counted after training: {npar}")
 Output
 &lt;denchmark-code&gt;INFO:root:Using CPU
 INFO:root:Start model training
 INFO:root:Number of parameters in DeepARTrainingNetwork: 13463
 INFO:root:Epoch[0] Learning rate is 0.001
 100%|██████████| 1/1 [00:00&lt;00:00, 13.78it/s, avg_epoch_loss=5.52]
 INFO:root:Epoch[0] Elapsed time 0.074 seconds
 INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=5.524269
 INFO:root:Loading parameters from best epoch (0)
 INFO:root:Final loss: 5.524268627166748 (occurred at epoch 0)
 INFO:root:End model training
 
 Number of parameters counted after training: 29743
 &lt;/denchmark-code&gt;
 
 Changing the length of lags_seq has no effect on the count before training, but does after.
 trainer = Trainer(epochs=1,batch_size=1,num_batches_per_epoch=1)
 estimator = DeepAREstimator(freq="5min", prediction_length=12, trainer=trainer,
                            lags_seq=[1])
 predictor = estimator.train_model(training_data=training_data)
 npar = count_model_params(net=predictor.trained_net)
 print(f"Number of parameters counted after training: {npar}")
 Output
 &lt;denchmark-code&gt;INFO:root:Using CPU
 INFO:root:Start model training
 INFO:root:Number of parameters in DeepARTrainingNetwork: 13463
 INFO:root:Epoch[0] Learning rate is 0.001
 100%|██████████| 1/1 [00:00&lt;00:00, 13.60it/s, avg_epoch_loss=5.18]
 INFO:root:Epoch[0] Elapsed time 0.075 seconds
 INFO:root:Epoch[0] Evaluation metric 'epoch_loss'=5.181353
 INFO:root:Loading parameters from best epoch (0)
 INFO:root:Final loss: 5.181352615356445 (occurred at epoch 0)
 INFO:root:End model training
 
 Number of parameters counted after training: 24463
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;Error Message&lt;/denchmark-h&gt;
 
 No error
 &lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;
 
 
 Operating system: Sagemaker notebook + training job (Amazon Linux?)
 Python version: 3.7
 GluonTS version:3.3
 
 (Add as much information about your environment as possible, e.g. dependencies versions.)
 	</description>
 	<comments>
 		<comment id='1' author='lcallot' date='2019-09-13T13:19:01Z'>
 		The problem is that &lt;denchmark-link:https://github.com/awslabs/gluon-ts/blob/f20cf9e32bd9ae7e96cf87d21925373421fcd55e/src/gluonts/trainer/_base.py#L193-L196&gt;these lines&lt;/denchmark-link&gt;
  should be executed after at least one forward pass, so moved further down in the training loop (with some flag guarding their execution).
 		</comment>
 		<comment id='2' author='lcallot' date='2019-09-30T07:15:55Z'>
 		I would like to take this up &lt;denchmark-link:https://github.com/lcallot&gt;@lcallot&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/lostella&gt;@lostella&lt;/denchmark-link&gt;
   Can you help me in solving this issue?
 Thanks!
 		</comment>
 		<comment id='3' author='lcallot' date='2019-09-30T08:14:36Z'>
 		&lt;denchmark-link:https://github.com/Patil2099&gt;@Patil2099&lt;/denchmark-link&gt;
  sure! Thanks for the help.
 The issue is in &lt;denchmark-link:https://github.com/awslabs/gluon-ts/blob/22da305e8d52d3fccadd4dd3000859b7c48e62e0/src/gluonts/trainer/_base.py#L193-L196&gt;the lines counting the parameters&lt;/denchmark-link&gt;
 : they are invoked before any forward pass on the network is performed, so the number of inputs to the network is unknown, and therfore the number of parameters in the network is inexact.
 The forward pass happens &lt;denchmark-link:https://github.com/awslabs/gluon-ts/blob/22da305e8d52d3fccadd4dd3000859b7c48e62e0/src/gluonts/trainer/_base.py#L252&gt;here&lt;/denchmark-link&gt;
 , so you may want to move the parameter counting after this point. Note however that this should happens only once in the training loop, so you can put a safeguard that makes sure they are invoked only at the first iteration.
 		</comment>
 		<comment id='4' author='lcallot' date='2019-10-11T14:35:23Z'>
 		This PR &lt;denchmark-link:https://github.com/awslabs/gluon-ts/pull/386&gt;#386&lt;/denchmark-link&gt;
  fixes the issue.
 		</comment>
 	</comments>
 </bug>
<commit id='a63d26315a9fb6737a982a4f3176ad5857b815c5' author='timoschowski' date='2019-10-11 16:32:29+02:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\gluonts\trainer\_base.py' new_name='src\gluonts\trainer\_base.py'>
 		<file_info nloc='253' complexity='9' token_count='1137'></file_info>
 		<modified_lines>
 			<added_lines>267,268,269,270,271,272,273</added_lines>
 			<deleted_lines>192,193,194,195,196,197</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
