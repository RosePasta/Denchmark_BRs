<bug_data>
<bug id='1259' author='LiMinghao1994' open_date='2019-09-28T14:11:51Z' closed_time='2019-10-11T03:31:04Z'>
 	<summary>Evaluation minibatches may be calculated repeatedly</summary>
 	<description>
 Currently, each task contains multiple minibatches. In the evaluation phase, workers calculate each minibatch in turn. Every time a minibatch calculation is completed, the worker immediately passes the calculated evaluation metrics to the master. When the worker completes all the minibatches in a task, the worker tells the master the results of the entire task.
 If a worker A is killed in the process of calculating a task, the master will find another worker B to calculate the failed task, but it will not clear the metrics of the minibatch already calculated in the task. So some minibatches are calculated both by worker A and worker B, which will lead to errors in the final evaluation metrics.
 	</description>
 	<comments>
 		<comment id='1' author='LiMinghao1994' date='2019-09-29T14:44:11Z'>
 		Interesting. I think workers should report results per task as the task is the minimum unit watched by the master.
 		</comment>
 		<comment id='2' author='LiMinghao1994' date='2019-09-30T04:32:20Z'>
 		
 Interesting. I think workers should report results per task as the task is the minimum unit watched by the master.
 
 Agree. In evaluation phase, worker should report results per task.
 		</comment>
 	</comments>
 </bug>
<commit id='a68cbb9c6b5ac2cb479eb33f98f54c8b245625c8' author='Chunyang Wen' date='2019-10-11 11:31:03+08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='elasticdl\python\common\constants.py' new_name='elasticdl\python\common\constants.py'>
 		<file_info nloc='26' complexity='0' token_count='107'></file_info>
 		<modified_lines>
 			<added_lines>40</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='elasticdl\python\worker\worker.py' new_name='elasticdl\python\worker\worker.py'>
 		<file_info nloc='443' complexity='83' token_count='2513'></file_info>
 		<method name='_process_eval_task_if_needed' parameters='self'>
 				<method_info nloc='29' complexity='5' token_count='149' nesting_level='1' start_line='459' end_line='494'></method_info>
 			<added_lines>486,487,488,489,490,491,493</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_run_evaluation_task' parameters='self,features,labels'>
 				<method_info nloc='6' complexity='2' token_count='45' nesting_level='1' start_line='399' end_line='404'></method_info>
 			<added_lines>401,402,403,404</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_collect_evaluation_result' parameters='self,outputs,labels'>
 				<method_info nloc='13' complexity='5' token_count='128' nesting_level='1' start_line='385' end_line='397'></method_info>
 			<added_lines>385,386,387,388,389,390,391,392,393,394,395,396,397</added_lines>
 			<deleted_lines>385,386</deleted_lines>
 		</method>
 		<method name='report_evaluation_metrics' parameters='self,model_outputs,labels'>
 				<method_info nloc='10' complexity='2' token_count='94' nesting_level='1' start_line='266' end_line='279'></method_info>
 			<added_lines>273,274,275,276</added_lines>
 			<deleted_lines>270,271,273,274</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>3,118,398</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
