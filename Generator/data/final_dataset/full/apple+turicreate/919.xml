<bug_data>
<bug id='919' author='prashpal' open_date='2018-07-28T00:14:49Z' closed_time='2019-11-13T00:32:19Z'>
 	<summary>Can't get activity classification to work with MPS</summary>
 	<description>
 In OS10.14, activity classification works fine with CPU. I tried to force it to use MPS by setting use_mps() as True in the file _mps_utils.py. But the test case is just crashing.
 Image classification seems to be using MPS, but I am not sure why activity classification is not.
 Has the activity classification been verified to work with MPS? If so, could you share the steps to get it working?
 	</description>
 	<comments>
 		<comment id='1' author='prashpal' date='2018-07-28T06:06:54Z'>
 		Sorry you are having this issue.
 It should work by default. What Mac hardware are you using?
 		</comment>
 		<comment id='2' author='prashpal' date='2018-07-30T17:49:01Z'>
 		I am using a 2016 13 inch MacBook Pro with Intel Iris Graphics 550.
 Below are the steps I followed:
 
 Install MacOS 10.14 public beta version
 Get Turi Create source code: https://github.com/apple/turicreate
 Set use_mps() = True in _mps_utils.py file
 Build Turi
 Run unit test for activity classification:
 ~/turicreate/scripts/run_python_test.sh debug
 
 If I skip step 3, then unit tests run training on CPU and the tests are passing.
 But, with MPS forced, the test crashes.
 		</comment>
 		<comment id='3' author='prashpal' date='2018-07-31T21:07:52Z'>
 		Unfortunately, the GPU acceleration for activity classification (and object detection) requires a discrete GPU, not the Intel Iris chipset. Image classification uses a different framework (via CoreML) to leverage GPU resources.
 Probably we should update our documentation to clarify the requirements, especially since they differ across toolkits
 		</comment>
 		<comment id='4' author='prashpal' date='2018-08-01T03:11:49Z'>
 		Thanks for the clarification. Are there plans to enable activity classification with Intel graphics since MPS can support it?
 		</comment>
 		<comment id='5' author='prashpal' date='2018-08-01T17:28:24Z'>
 		Some testing with our current MPS implementation using Intel graphics did not reveal performance improvements over our MXNet (CPU only) implementation. We do plan to do some more work on activity classification, so we can certainly revisit this question after we've iterated on the implementation some.
 		</comment>
 		<comment id='6' author='prashpal' date='2018-08-02T11:33:56Z'>
 		For future reference - _mps_utils.use_mps() is an internal function, that checks the user config plus relevant hardware availability, not a user facing API.
 The APIish way for enforcing GPU usage would be
 &lt;denchmark-code&gt;tc.config.set_num_gpus(1)
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='7' author='prashpal' date='2018-08-02T18:44:56Z'>
 		Ok thank you &lt;denchmark-link:https://github.com/nickjong&gt;@nickjong&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/igiloh&gt;@igiloh&lt;/denchmark-link&gt;
  . Please keep me updated when support with Intel graphics is available. Even if we do not see perf improvement with Intel graphics, it will be good to have the option of using it.
 		</comment>
 		<comment id='8' author='prashpal' date='2018-08-02T19:08:04Z'>
 		hi &lt;denchmark-link:https://github.com/prashpal&gt;@prashpal&lt;/denchmark-link&gt;
  ,
 If you're building TC from source - you can try modifying  in &lt;denchmark-link:https://github.com/apple/turicreate/blob/master/src/unity/python/turicreate/toolkits/_mps_utils.py#L178&gt;_mps_utils.py&lt;/denchmark-link&gt;
  to return always true. If you're on mac OS 10.14+ - it would use the intel GPU.
 		</comment>
 		<comment id='9' author='prashpal' date='2018-08-02T21:43:32Z'>
 		Yes, I am setting use_mps() = True in _mps_utils.py file to force to use Intel graphics.
 use_mps() seems to be a check for 2 things -  has_fast_mps_support() and _tc_config.get_num_gpus() != 0.
 With the above change, the test seems to be going through Intel graphics, but the validation test crashes. So I wanted to check if the tests were verified to work with Intel graphics?
 Is my understanding correct?
 
 Image classification Training - can use CPU or discrete GPU (via MPS or MXNet)
 Activity classification Training - can use CPU or discrete GPU (via MPS or MXNet)
 Image classification Inference - can use CPU or discrete GPU (via CoreML or MPS or MXNet) or Intel GPU (via CoreML)
 Activity classification Inference - can use CPU or discrete GPU (via MPS or MXNet)
 
 		</comment>
 		<comment id='10' author='prashpal' date='2018-08-08T20:27:01Z'>
 		I have not verified any tests for the Intel graphics MPS code path, since this code path is not currently supported.
 Image classification has two phases: feature extraction using a neural network and logistic regression based on the extracted features. The logistic regression currently always runs on CPU. The feature extraction is the same for both training and inference, and always uses CoreML, which should use GPU or CPU, as available.
 Activity classification training and inference both use either MPS (on Macs with AMD GPUs) or MXNet (using GPU or CPU, as available).
 		</comment>
 		<comment id='11' author='prashpal' date='2018-08-09T20:09:05Z'>
 		Thanks for clarifying &lt;denchmark-link:https://github.com/nickjong&gt;@nickjong&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='12' author='prashpal' date='2018-10-19T22:52:49Z'>
 		We should probably just go ahead and use the Intel GPU anyway, since this is less confusing. Need to verify that this works end-to-end though
 		</comment>
 		<comment id='13' author='prashpal' date='2018-10-26T00:07:29Z'>
 		Ok, thanks for the update.
 		</comment>
 		<comment id='14' author='prashpal' date='2019-02-21T18:10:50Z'>
 		Hi &lt;denchmark-link:https://github.com/nickjong&gt;@nickjong&lt;/denchmark-link&gt;
  , I wanted to check if we have any updates on this.
 		</comment>
 		<comment id='15' author='prashpal' date='2019-03-06T00:47:13Z'>
 		Sorry, nothing concrete to report yet, although activity classification is something we're actively investigating now
 		</comment>
 		<comment id='16' author='prashpal' date='2019-03-13T21:47:17Z'>
 		We currently expect/hope to support Skylake Intel GPUs and later, in June
 		</comment>
 		<comment id='17' author='prashpal' date='2019-10-16T18:52:15Z'>
 		Hi
 Im curious if there is any public documentation on CoreML's device selection heuristic. With the addition of 10.15's CoreML preferredMetalDevice API for MLModelConfig, I imagined it would be possible to force the MTLDevice an MLModel / Vision request runs on.
 In my testing with integrated, discrete and eGPU, it appears only the eGPU consistently runs the CoreML model. My CoreML Model is a pipeline model consisting of a Mobilenet classifier with multiple outputs (multi head classifiers attached to a custom feature extractor).
 Im curious to understand device selection preference for a few reasons:
 a) Id like to ensure my MLModel is fed images CIImages backed by textures local to the device inference will be run on, to limit PCI transfers and keep things local
 b) my model is actually fed frames of video, and WWDC '19 / 10.15 introduces VideoToolbox and AVFoundation API's to help force particular video encoders and decoders on specific GPUs.
 In theory, if all works well, I should be able to specify the same MTLDevice for video decode, preprocessing, CoreML/Vision inference, and subsequent encoding - keeping all IOSurface backed pixel buffers and textures resident on the same GPU.
 Apple has a Pro Apps WWDC video suggesting this is the path forward to fast path Multi GPU support / Afterburner decoder support moving forward.
 Does CoreML ACTUALLY allow suggested device placement to work?
 I am running a retina MacBook Pro 2018 with Vega 20 GPU, and trying various methods to get the Vega 20 to light up.
 
 
 Disabling automatic graphics switching
 
 
 Disabling automatic graphics switching / setting NSSupportsAutomaticGraphicsSwitching to False
 
 
 Disabling automatic graphics switching / setting NSSupportsAutomaticGraphicsSwitching to True
 
 
 Enabling automatic graphics switching / setting NSSupportsAutomaticGraphicsSwitching to False
 
 
 Enabling automatic graphics switching / setting NSSupportsAutomaticGraphicsSwitching to True
 
 
 having a full battery and plugged into my Apple power adaptor
 
 
 having full battery and plugged into my eGPU
 
 
 I can only on occasion get the Vega 20 to 'light up' - but can consistently have CoreML run on the eGPU (Radeon 580)
 I can inspect the CoreML model and see its MLConfig has a preferred device set to the Vega 20, but Instruments, Xcode, and Activity Monitor all report no GPU usage on the Vega 20, and in fact, sometimes no GPU usage at all (not even the integrated GPU).
 Any insight would be most helpful.
 Apologies if this is not the best repository to post my query to.
 Thanks in advance.
 		</comment>
 		<comment id='18' author='prashpal' date='2019-10-17T19:21:29Z'>
 		&lt;denchmark-link:https://github.com/vade&gt;@vade&lt;/denchmark-link&gt;
  - this isn't the right place to ask this question. I suggest reporting the issue here: &lt;denchmark-link:https://developer.apple.com/bug-reporting/&gt;https://developer.apple.com/bug-reporting/&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='19' author='prashpal' date='2019-10-17T19:41:50Z'>
 		I hear you &lt;denchmark-link:https://github.com/TobyRoseman&gt;@TobyRoseman&lt;/denchmark-link&gt;
  - however having these convo's in the open rather than behind closed feedback is helpful to other developers who have similar questions, and leaves a breadcrumb trail to answers. I'm sure you understand!
 But yes, ive asked there and on S/O as well. Appreciate the response!
 		</comment>
 	</comments>
 </bug>
<commit id='f441ea29d86649ceb92e5c6622e485caa8365343' author='Nick Jong' date='2019-11-12 16:32:18-08:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\ml\neural_net\mps_compute_context.hpp' new_name='src\ml\neural_net\mps_compute_context.hpp'>
 		<file_info nloc='32' complexity='0' token_count='241'></file_info>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>31,32,33,34,35,36,37</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ml\neural_net\mps_compute_context.mm' new_name='src\ml\neural_net\mps_compute_context.mm'>
 		<file_info nloc='113' complexity='19' token_count='777'></file_info>
 		<method name='turi::neural_net::mps_compute_context::mps_compute_context' parameters=''>
 				<method_info nloc='11' complexity='2' token_count='53' nesting_level='2' start_line='61' end_line='74'></method_info>
 			<added_lines>61,62,63,64,65,66,67,68,69,70,71,72,73,74</added_lines>
 			<deleted_lines>61,62,63,64,65,66,67,68,69,70,71,72,73,74</deleted_lines>
 		</method>
 		<method name='turi::neural_net::create_mps_compute_context' parameters=''>
 				<method_info nloc='21' complexity='5' token_count='132' nesting_level='3' start_line='42' end_line='76'></method_info>
 			<added_lines>43,44,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75</added_lines>
 			<deleted_lines>46,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
