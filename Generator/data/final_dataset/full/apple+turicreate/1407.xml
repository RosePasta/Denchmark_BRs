<bug_data>
<bug id='1407' author='hoytak' open_date='2019-02-08T00:03:18Z' closed_time='2019-03-15T01:54:25Z'>
 	<summary>Per-class accuracy doesn't make any sense</summary>
 	<description>
 Consider this code from &lt;denchmark-link:https://apple.github.io/turicreate/docs/userguide/evaluation/classification.html&gt;https://apple.github.io/turicreate/docs/userguide/evaluation/classification.html&lt;/denchmark-link&gt;
 
 &lt;denchmark-code&gt;import turicreate as tc
 
 y    = tc.SArray(["cat", "dog", "foosa", "cat"])
 yhat = tc.SArray(["cat", "dog", "cat", "dog"])
 
 print(tc.evaluation.accuracy(y, yhat, average = "micro"))
 print(tc.evaluation.accuracy(y, yhat, average = "macro"))
 print(tc.evaluation.accuracy(y, yhat, average = None))
 &lt;/denchmark-code&gt;
 
 which produces
 &lt;denchmark-code&gt;0.5
 0.666666666667
 {'dog': 0.75, 'foosa': 0.75, 'cat': 0.5}
 &lt;/denchmark-code&gt;
 
 The per class accuracy doesn't make any sense here...
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='112b30731804edae85e771532db2a383100cf599' author='Shantanu Chhabra' date='2019-03-14 18:54:20-07:00'>
 	<dmm_unit complexity='0.5' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\unity\python\turicreate\test\test_evaluation.py' new_name='src\unity\python\turicreate\test\test_evaluation.py'>
 		<file_info nloc='874' complexity='49' token_count='9957'></file_info>
 		<method name='test_accuracy_multi_class_score' parameters='self'>
 				<method_info nloc='52' complexity='2' token_count='503' nesting_level='1' start_line='918' end_line='989'></method_info>
 			<added_lines>969,970,984,985,986,987,988,989</added_lines>
 			<deleted_lines>982,983,984,985,986,987</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\unity\toolkits\evaluation\evaluation_interface-inl.hpp' new_name='src\unity\toolkits\evaluation\evaluation_interface-inl.hpp'>
 		<file_info nloc='1210' complexity='233' token_count='8637'></file_info>
 		<method name='turi::evaluation::flexible_accuracy::get_metric' parameters=''>
 				<method_info nloc='50' complexity='9' token_count='344' nesting_level='3' start_line='1381' end_line='1443'></method_info>
 			<added_lines>1391,1394,1435</added_lines>
 			<deleted_lines>1433</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='userguide\evaluation\classification.md' new_name='userguide\evaluation\classification.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>59,60,74,75,90,91,92</added_lines>
 			<deleted_lines>59,73,74</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
