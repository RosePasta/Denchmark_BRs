<bug_data>
<bug id='1332' author='nickjong' open_date='2019-01-17T18:19:12Z' closed_time='2019-08-09T17:22:42Z'>
 	<summary>Failures in CoreMLExportTest due to undefined behavior (observed on 10.13)</summary>
 	<description>
 For example:
 &lt;denchmark-code&gt;___________________ CoreMLExportTest.test_linear_regression ____________________
 
 self = &lt;turicreate.test.test_coreml_export.CoreMLExportTest testMethod=test_linear_regression&gt;
 
     def test_linear_regression(self):
         for code_string in ["b"*40, "nnnn", "v", "d", "A", "bnsCvAd"]:
             train, test = self.generate_data("regression", 100, code_string)
             model = tc.linear_regression.create(train, "target", validation_set = None)
             model.evaluate(test)  # Previous regression -- this caused errors.
 &gt;           self._test_coreml_export(model, test, True)
 
 test_coreml_export.py:121: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
 test_coreml_export.py:103: in _test_coreml_export
     self.assertAlmostEqual(coreml_prediction["target"], tc_prediction, delta = 1e-5)
 E   AssertionError: 0.3692980279794391 != 0.5474222893547473 within 1e-05 delta
 &lt;/denchmark-code&gt;
 
 Due to discussion offline, this could be due to how we export dictionary features?
 	</description>
 	<comments>
 		<comment id='1' author='nickjong' date='2019-02-22T00:08:09Z'>
 		&lt;denchmark-link:https://github.com/hoytak&gt;@hoytak&lt;/denchmark-link&gt;
  As discussed in triage today, please put up a PR ASAP to skip these tests in master (but keep this bug open and resolve it when the fixes are actually in). It's more important to keep test results in master green in the meantime. (I would do this initial PR to skip the tests, but I'm not sure which tests are affected and on which OSes they need to skip.)
 		</comment>
 		<comment id='2' author='nickjong' date='2019-06-26T21:37:16Z'>
 		We should reenable these tests and reinvestigate -- it's quite possible these have been fixed.
 		</comment>
 		<comment id='3' author='nickjong' date='2019-07-29T22:32:29Z'>
 		This can't be a P1, since we've had this bug for half a year, and we're no longer failing our own tests....
 I did re-enable these tests, and they still fail. Which makes sense, since no fix on the CoreML side recently would affect test results on 10.13.
 Ultimately, if we cannot safely export these models in a way that will work deterministically in CoreML in macOS 10.13 / iOS 11, we should document the dependency on a newer CoreML.
 		</comment>
 		<comment id='4' author='nickjong' date='2019-07-29T22:33:31Z'>
 		&lt;denchmark-link:https://github.com/hoytak&gt;@hoytak&lt;/denchmark-link&gt;
  Not sure anyone else has the necessary context; what precisely is the dependency on CoreML? In what cases should users expect these exported Core ML models to actually work?
 		</comment>
 		<comment id='5' author='nickjong' date='2019-07-30T00:16:06Z'>
 		If we can't get the exported models to work on 10.13, we should update their model spec version so they are limited to newer macOS releases (this will give a better user experience than just a documentation fix, as the exported model will complain in Xcode when targeting earlier macOS/iOS versions).
 		</comment>
 		<comment id='6' author='nickjong' date='2019-08-06T20:09:20Z'>
 		I've been working with Guihao on this one; the issue is with columns that have dictionary features and those with categorical lists.  The way these are unpacked in old versions of CoreML means they are unpacked into uninitialized memory.  He's verified all the tests pass now; is checking today I believe on 10.13.
 @Jarvi-Izana -- is that a correct summary of the status?
 		</comment>
 		<comment id='7' author='nickjong' date='2019-08-07T18:25:39Z'>
 		&lt;denchmark-link:https://github.com/hoytak&gt;@hoytak&lt;/denchmark-link&gt;
  sorry for the late reply. I just finished running the pipeline with relevant  removed and it failed on mac_10_13 environment with python27.
 		</comment>
 		<comment id='8' author='nickjong' date='2019-08-07T22:24:34Z'>
 		Ok, I tried internal pipeline with a macOS10.13 instance and it failed on python3 as well.
 		</comment>
 		<comment id='9' author='nickjong' date='2019-08-08T16:23:36Z'>
 		no code change is needed. We should keep triaging it.
 		</comment>
 		<comment id='10' author='nickjong' date='2019-08-09T17:31:19Z'>
 		We are not going to fix it due to the undefined behavior of CoreML prior to macOS version 10.14. These tests will be still marked as failure for versions prior to version 10.14.
 		</comment>
 	</comments>
 </bug>
<commit id='fedaace1c696528a6cbb0afb50059b6757db8380' author='Zach Nation' date='2019-03-01 14:59:56-08:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\unity\python\turicreate\test\test_coreml_export.py' new_name='src\unity\python\turicreate\test\test_coreml_export.py'>
 		<file_info nloc='269' complexity='80' token_count='2796'></file_info>
 		<method name='test_linear_regression' parameters='self'>
 				<method_info nloc='8' complexity='3' token_count='87' nesting_level='1' start_line='116' end_line='123'></method_info>
 			<added_lines>117,118</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_logistic_multiclass_tiny' parameters='self'>
 				<method_info nloc='8' complexity='3' token_count='87' nesting_level='1' start_line='319' end_line='326'></method_info>
 			<added_lines>320,321</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_logistic_classifier' parameters='self'>
 				<method_info nloc='8' complexity='3' token_count='87' nesting_level='1' start_line='180' end_line='187'></method_info>
 			<added_lines>181,182</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_logistic_multiclass' parameters='self'>
 				<method_info nloc='8' complexity='3' token_count='91' nesting_level='1' start_line='252' end_line='259'></method_info>
 			<added_lines>253,254</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_svm_classifier' parameters='self'>
 				<method_info nloc='8' complexity='3' token_count='91' nesting_level='1' start_line='189' end_line='196'></method_info>
 			<added_lines>190,191</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
