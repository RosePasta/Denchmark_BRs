<bug_data>
<bug id='1205' author='parano' open_date='2020-10-23T19:25:10Z' closed_time='2020-11-11T22:21:54Z'>
 	<summary>OnnxModelArtifact should work when using onnxruntime-gpu package</summary>
 	<description>
 OnnxModelArtifact should work when using onnxruntime-gpu instead of the regular onnxruntime.
 See issue &amp; discussions here for more details: &lt;denchmark-link:https://github.com/bentoml/BentoML/issues/1203#issuecomment-715529579&gt;#1203 (comment)&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='a398f423bc85546ca178f6c34ce1ce551e6b6d68' author='Bozhao' date='2020-11-11 14:21:40-08:00'>
 	<dmm_unit complexity='0.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='bentoml\frameworks\onnx.py' new_name='bentoml\frameworks\onnx.py'>
 		<file_info nloc='174' complexity='28' token_count='521'></file_info>
 		<method name='_get_onnx_inference_session' parameters='self'>
 				<method_info nloc='30' complexity='6' token_count='97' nesting_level='1' start_line='144' end_line='174'></method_info>
 			<added_lines>145,150,151</added_lines>
 			<deleted_lines>148,149</deleted_lines>
 		</method>
 		<method name='set_dependencies' parameters='self,BentoServiceEnv'>
 				<method_info nloc='5' complexity='3' token_count='39' nesting_level='1' start_line='138' end_line='142'></method_info>
 			<added_lines>141,142</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>17</added_lines>
 			<deleted_lines>17,143</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
