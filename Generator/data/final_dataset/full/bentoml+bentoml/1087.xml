<bug_data>
<bug id='1087' author='bojiang' open_date='2020-09-13T09:16:00Z' closed_time='2020-09-21T15:06:05Z'>
 	<summary>Configurable max request body size</summary>
 	<description>
 Is your feature request related to a problem? Please describe.
 How to reproduce:
 
 enable microbatching
 post a large file (for example, 2MB) to the API
 
 got:
 aiohttp.web_exceptions.HTTPRequestEntityTooLarge: Request Entity Too Large
 Describe the solution you'd like
 &lt;denchmark-link:https://docs.aiohttp.org/en/stable/web_reference.html#aiohttp.web.Application&gt;https://docs.aiohttp.org/en/stable/web_reference.html#aiohttp.web.Application&lt;/denchmark-link&gt;
 
 
 enlarge the default client_max_size
 make it configurable
 do the same for flask
 
 Describe alternatives you've considered
 Additional context
 	</description>
 	<comments>
 		<comment id='1' author='bojiang' date='2020-11-24T20:46:13Z'>
 		Hi, I'm running into this issue of aiohttp.web_exceptions.HTTPRequestEntityTooLarge when testing out some micro-batching on an image model (e.g. batching 5 images will do this).
 I noticed there is a PR that was merged but I don't actually see how it can be configured. Looking at &lt;denchmark-link:https://github.com/bojiang/BentoML/blob/ea44748e14a4d208bbb437c9d7d0b7f5c4dd027c/bentoml/server/gunicorn_server.py#L66&gt;https://github.com/bojiang/BentoML/blob/ea44748e14a4d208bbb437c9d7d0b7f5c4dd027c/bentoml/server/gunicorn_server.py#L66&lt;/denchmark-link&gt;
  it seems that it is reading the config file. Is changing that config file the only way to change this value?
 		</comment>
 		<comment id='2' author='bojiang' date='2020-11-25T00:40:19Z'>
 		&lt;denchmark-link:https://github.com/gregd33&gt;@gregd33&lt;/denchmark-link&gt;
  You can also pass the value as an envvar, 
 		</comment>
 	</comments>
 </bug>
<commit id='a7f3e582f51a1ba71390add3f346140d743c73fd' author='bojiang' date='2020-09-21 08:06:04-07:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='bentoml\configuration\default_bentoml.cfg' new_name='bentoml\configuration\default_bentoml.cfg'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>69</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='bentoml\marshal\marshal.py' new_name='bentoml\marshal\marshal.py'>
 		<file_info nloc='248' complexity='29' token_count='1553'></file_info>
 		<method name='make_app' parameters='self'>
 				<method_info nloc='6' complexity='1' token_count='57' nesting_level='1' start_line='301' end_line='306'></method_info>
 			<added_lines>302</added_lines>
 			<deleted_lines>301</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>128</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='bentoml\server\gunicorn_server.py' new_name='bentoml\server\gunicorn_server.py'>
 		<file_info nloc='70' complexity='9' token_count='366'></file_info>
 		<modified_lines>
 			<added_lines>16,66,70</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='bentoml\server\marshal_server.py' new_name='bentoml\server\marshal_server.py'>
 		<file_info nloc='66' complexity='9' token_count='392'></file_info>
 		<modified_lines>
 			<added_lines>54,58</added_lines>
 			<deleted_lines>25</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
