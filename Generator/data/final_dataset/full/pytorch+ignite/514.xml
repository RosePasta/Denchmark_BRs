<bug_data>
<bug id='514' author='marrrcin' open_date='2019-05-02T16:05:17Z' closed_time='2019-05-02T16:50:41Z'>
 	<summary>Tensorboard Logger does not work with layer freezing</summary>
 	<description>
 Consider the following (simplified and self-contained) notebook:
 &lt;denchmark-link:https://gist.github.com/marrrcin/629227cf33d88af6192048871daa3a09&gt;https://gist.github.com/marrrcin/629227cf33d88af6192048871daa3a09&lt;/denchmark-link&gt;
 
 which uses mostly the code from Ignite examples to create  and attach  to training events.
 If you use pre-trained model and freeze some layers, you end up with code that will not work, as Ignite tries to collect gradient histograms/scalars for every model parameter, even though some of them are already disabled from updating.
 The exception thrown is the following:
 &lt;denchmark-code&gt;---------------------------------------------------------------------------
 AttributeError                            Traceback (most recent call last)
 &lt;ipython-input-3-5ffffec84f3c&gt; in &lt;module&gt;
      65     print("Done.")
      66 
 ---&gt; 67 example()
 
 &lt;ipython-input-3-5ffffec84f3c&gt; in example()
      62 
      63 
 ---&gt; 64     trainer.run(DataLoader(FakeDataset(), batch_size=16), max_epochs=5)
      65     print("Done.")
      66 
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/pytorch_ignite-0.2.0-py3.7.egg/ignite/engine/engine.py in run(self, data, max_epochs)
     357         except BaseException as e:
     358             self._logger.error("Engine run is terminating due to exception: %s.", str(e))
 --&gt; 359             self._handle_exception(e)
     360 
     361         return self.state
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/pytorch_ignite-0.2.0-py3.7.egg/ignite/engine/engine.py in _handle_exception(self, e)
     322             self._fire_event(Events.EXCEPTION_RAISED, e)
     323         else:
 --&gt; 324             raise e
     325 
     326     def run(self, data, max_epochs=1):
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/pytorch_ignite-0.2.0-py3.7.egg/ignite/engine/engine.py in run(self, data, max_epochs)
     344                 self.state.epoch += 1
     345                 self._fire_event(Events.EPOCH_STARTED)
 --&gt; 346                 hours, mins, secs = self._run_once_on_dataset()
     347                 self._logger.info("Epoch[%s] Complete. Time taken: %02d:%02d:%02d", self.state.epoch, hours, mins, secs)
     348                 if self.should_terminate:
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/pytorch_ignite-0.2.0-py3.7.egg/ignite/engine/engine.py in _run_once_on_dataset(self)
     311         except BaseException as e:
     312             self._logger.error("Current run is terminating due to exception: %s.", str(e))
 --&gt; 313             self._handle_exception(e)
     314 
     315         time_taken = time.time() - start_time
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/pytorch_ignite-0.2.0-py3.7.egg/ignite/engine/engine.py in _handle_exception(self, e)
     322             self._fire_event(Events.EXCEPTION_RAISED, e)
     323         else:
 --&gt; 324             raise e
     325 
     326     def run(self, data, max_epochs=1):
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/pytorch_ignite-0.2.0-py3.7.egg/ignite/engine/engine.py in _run_once_on_dataset(self)
     304                 self._fire_event(Events.ITERATION_STARTED)
     305                 self.state.output = self._process_function(self, batch)
 --&gt; 306                 self._fire_event(Events.ITERATION_COMPLETED)
     307                 if self.should_terminate or self.should_terminate_single_epoch:
     308                     self.should_terminate_single_epoch = False
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/pytorch_ignite-0.2.0-py3.7.egg/ignite/engine/engine.py in _fire_event(self, event_name, *event_args, **event_kwargs)
     257             for func, args, kwargs in self._event_handlers[event_name]:
     258                 kwargs.update(event_kwargs)
 --&gt; 259                 func(self, *(event_args + args), **kwargs)
     260 
     261     def fire_event(self, event_name):
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/pytorch_ignite-0.2.0-py3.7.egg/ignite/contrib/handlers/tensorboard_logger.py in __call__(self, engine, logger, event_name)
     219             name = name.replace('.', '/')
     220             logger.writer.add_scalar("grads_{}/{}".format(self.reduction.__name__, name),
 --&gt; 221                                      self.reduction(p.grad),
     222                                      global_step)
     223 
 
 /anaconda3/envs/ignite/lib/python3.7/site-packages/torch/functional.py in norm(input, p, dim, keepdim, out, dtype)
     676         (tensor(3.7417), tensor(11.2250))
     677     """
 --&gt; 678     ndim = input.dim()
     679 
     680     # catch default case
 
 AttributeError: 'NoneType' object has no attribute 'dim'
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='marrrcin' date='2019-05-02T16:09:17Z'>
 		&lt;denchmark-link:https://github.com/marrrcin&gt;@marrrcin&lt;/denchmark-link&gt;
  thanks for reporting! Yes, you are correct that there is no checking whether .  If you would like to &lt;denchmark-link:https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md&gt;contribute to ignite&lt;/denchmark-link&gt;
  and fix this bug, it would be awesome !
 		</comment>
 		<comment id='2' author='marrrcin' date='2019-05-02T16:12:15Z'>
 		I was just creating one: &lt;denchmark-link:https://github.com/pytorch/ignite/pull/515&gt;#515&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='fc85e25dc4f938d780b4c425acb2d40f6cac6f24' author='Marcin ZabÅ‚ocki' date='2019-05-02 18:50:40+02:00'>
 	<dmm_unit complexity='1.0' interfacing='0.8918918918918919' size='0.0945945945945946'></dmm_unit>
 	<modification change_type='MODIFY' old_name='ignite\contrib\handlers\tensorboard_logger.py' new_name='ignite\contrib\handlers\tensorboard_logger.py'>
 		<file_info nloc='328' complexity='40' token_count='1004'></file_info>
 		<method name='__call__' parameters='self,engine,logger,event_name'>
 				<method_info nloc='11' complexity='4' token_count='96' nesting_level='1' start_line='136' end_line='149'></method_info>
 			<added_lines>143,144,145</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>183,184,185,225,226,227,264,265,266</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='tests\ignite\contrib\handlers\conftest.py'>
 		<file_info nloc='36' complexity='9' token_count='302'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\ignite\contrib\handlers\test_tensorboard_logger.py' new_name='tests\ignite\contrib\handlers\test_tensorboard_logger.py'>
 		<file_info nloc='352' complexity='33' token_count='3064'></file_info>
 		<method name='test_grads_hist_frozen_layers' parameters='dummy_model_factory'>
 				<method_info nloc='19' complexity='1' token_count='175' nesting_level='0' start_line='404' end_line='427'></method_info>
 			<added_lines>404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_grads_hist_handler' parameters='dummy_model_factory'>
 				<method_info nloc='16' complexity='1' token_count='152' nesting_level='0' start_line='382' end_line='401'></method_info>
 			<added_lines>382,383</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_weights_hist_handler' parameters=''>
 				<method_info nloc='18' complexity='1' token_count='156' nesting_level='0' start_line='233' end_line='264'></method_info>
 			<added_lines>233,234,235,236,237,251,253</added_lines>
 			<deleted_lines>233,234,235,236,237,238,239,240,241,242,243,244,246</deleted_lines>
 		</method>
 		<method name='test_grads_scalar_handler.norm' parameters='x'>
 				<method_info nloc='2' complexity='1' token_count='9' nesting_level='1' start_line='298' end_line='299'></method_info>
 			<added_lines>298,299</added_lines>
 			<deleted_lines>298,299</deleted_lines>
 		</method>
 		<method name='test_grads_scalar_handler' parameters=''>
 				<method_info nloc='19' complexity='1' token_count='138' nesting_level='0' start_line='283' end_line='318'></method_info>
 			<added_lines>283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,317,318</added_lines>
 			<deleted_lines>283,285,287,288,289,290,291,292,293,294,296,298,299,301,311,312,314,315</deleted_lines>
 		</method>
 		<method name='test_weights_scalar_handler' parameters='dummy_model_factory'>
 				<method_info nloc='16' complexity='1' token_count='141' nesting_level='0' start_line='187' end_line='207'></method_info>
 			<added_lines>187,189</added_lines>
 			<deleted_lines>188,189,190,191,192,193,194,195,196,197,198,199</deleted_lines>
 		</method>
 		<method name='test_weights_hist_handler_frozen_layers' parameters='dummy_model_factory'>
 				<method_info nloc='19' complexity='1' token_count='175' nesting_level='0' start_line='274' end_line='298'></method_info>
 			<added_lines>274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298</added_lines>
 			<deleted_lines>283,285,287,288,289,290,291,292,293,294,296,298</deleted_lines>
 		</method>
 		<method name='test_weights_scalar_handler' parameters=''>
 				<method_info nloc='18' complexity='1' token_count='145' nesting_level='0' start_line='186' end_line='217'></method_info>
 			<added_lines>187,189,210,211,212,213,214,215,216,217</added_lines>
 			<deleted_lines>186,188,189,190,191,192,193,194,195,196,197,198,199</deleted_lines>
 		</method>
 		<method name='test_grads_scalar_handler.__init__' parameters='self'>
 				<method_info nloc='8' complexity='1' token_count='93' nesting_level='2' start_line='287' end_line='294'></method_info>
 			<added_lines>287,288,289,290,291,292,293,294</added_lines>
 			<deleted_lines>287,288,289,290,291,292,293,294</deleted_lines>
 		</method>
 		<method name='test_grads_hist_handler' parameters=''>
 				<method_info nloc='22' complexity='1' token_count='228' nesting_level='0' start_line='334' end_line='371'></method_info>
 			<added_lines>334,335,336,337,338,341,342,344,351,360,361,362,363,364,365,366,367</added_lines>
 			<deleted_lines>334,335,336,337,338,339,340,341,342,343,344,345,346,347,357,358,359,360,361,362</deleted_lines>
 		</method>
 		<method name='test_weights_hist_handler.__init__' parameters='self'>
 				<method_info nloc='8' complexity='1' token_count='93' nesting_level='2' start_line='237' end_line='244'></method_info>
 			<added_lines>237</added_lines>
 			<deleted_lines>237,238,239,240,241,242,243,244</deleted_lines>
 		</method>
 		<method name='test_weights_scalar_handler_frozen_layers' parameters='dummy_model_factory'>
 				<method_info nloc='19' complexity='1' token_count='169' nesting_level='0' start_line='210' end_line='235'></method_info>
 			<added_lines>210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235</added_lines>
 			<deleted_lines>233,234,235</deleted_lines>
 		</method>
 		<method name='test_weights_hist_handler' parameters='dummy_model_factory'>
 				<method_info nloc='16' complexity='1' token_count='152' nesting_level='0' start_line='251' end_line='271'></method_info>
 			<added_lines>251,253</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_grads_scalar_handler_frozen_layers' parameters='dummy_model_factory,norm_mock'>
 				<method_info nloc='21' complexity='1' token_count='168' nesting_level='0' start_line='341' end_line='366'></method_info>
 			<added_lines>341,342,344,351,360,361,362,363,364,365,366</added_lines>
 			<deleted_lines>341,342,343,344,345,346,347,357,358,359,360,361,362</deleted_lines>
 		</method>
 		<method name='test_grads_scalar_handler' parameters='dummy_model_factory,norm_mock'>
 				<method_info nloc='18' complexity='1' token_count='145' nesting_level='0' start_line='317' end_line='338'></method_info>
 			<added_lines>317,318,320,321,322,323,324,325,326,327,329,330,331,332,333,334,335,336,337,338</added_lines>
 			<deleted_lines>334,335,336,337,338</deleted_lines>
 		</method>
 		<method name='test_weights_scalar_handler.__init__' parameters='self'>
 				<method_info nloc='8' complexity='1' token_count='93' nesting_level='2' start_line='190' end_line='197'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>190,191,192,193,194,195,196,197</deleted_lines>
 		</method>
 		<method name='test_grads_hist_handler.__init__' parameters='self'>
 				<method_info nloc='8' complexity='1' token_count='93' nesting_level='2' start_line='338' end_line='345'></method_info>
 			<added_lines>338,341,342,344</added_lines>
 			<deleted_lines>338,339,340,341,342,343,344,345</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>6,428,429</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
