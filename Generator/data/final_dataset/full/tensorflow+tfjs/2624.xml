<bug_data>
<bug id='2624' author='MatPoliquin' open_date='2019-12-29T09:10:38Z' closed_time='2020-02-05T15:58:33Z'>
 	<summary>tf.time() kernelMs returns zero in Firefox</summary>
 	<description>
 TensorFlow.js 1.3.1
 FireFox 71.0 (64-bit)
 Chrome 79.0.3945.88 (64-bit)
 Ubuntu 19.10 (64-bit)
 Problem:
 tf.time().kernelMs returns 0 (or sometimes a very low number) on Firefox while always returning the correct timing on Chrome.
 The correct value is typicaly between 100-300 ms, depending on which gpu you have.
 Code:
 
 const matSize = 1024;
 const mat1 = tf.ones([matSize, matSize], tf.float32);
 const mat2 = tf.ones([matSize, matSize], tf.float32);
 const time = await tf.time(() =&gt; tf.matMul(mat1, mat2));
 
 Edit:
 I got the same problem with Edge and Android Chrome
 	</description>
 	<comments>
 		<comment id='1' author='MatPoliquin' date='2020-01-17T23:32:51Z'>
 		&lt;denchmark-link:https://github.com/annxingyuan&gt;@annxingyuan&lt;/denchmark-link&gt;
  seems to be a bug I was able to reproduce the bug in firefox  , please check
 repro code: const matSize = 1024; const mat1 = tf.ones([matSize, matSize], tf.float32); const mat2 = tf.ones([matSize, matSize], tf.float32); const time1 = await tf.time(() =&gt; tf.matMul(mat1, mat2)); console.log(kernelMs: ${time1.kernelMs}, wallTimeMs: ${time1.wallMs});
 		</comment>
 		<comment id='2' author='MatPoliquin' date='2020-02-03T13:13:11Z'>
 		I think the reason kernelMs is inaccurate in Firefox is that Firefox doesn't support WebGL query timers. In this case we just snapshot performance.now() before and after calling the WebGL draw command for that kernel and report kernelMs as the difference.
 &lt;denchmark-link:https://github.com/dsmilkov&gt;@dsmilkov&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
  - do you think it makes sense to omit  from  output if query timers are unavailable?
 		</comment>
 		<comment id='3' author='MatPoliquin' date='2020-02-03T16:21:03Z'>
 		Instead of omitting (which is basically silencing the error), how about we throw an error with a user-friendly msg? Specifically the webgl's backend.time() should throw an error if the query timer is not supported, and that error should propagate through tf.time. WDYT?
 		</comment>
 		<comment id='4' author='MatPoliquin' date='2020-02-03T16:23:34Z'>
 		&lt;denchmark-link:https://github.com/annxingyuan&gt;@annxingyuan&lt;/denchmark-link&gt;
  we actually should use a CPU timer if it's not enabled today. I think it makes to disambiguate and have the error propagate through the tf.time() call.
 		</comment>
 		<comment id='5' author='MatPoliquin' date='2020-02-03T16:35:39Z'>
 		&lt;denchmark-link:https://github.com/dsmilkov&gt;@dsmilkov&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
 
 We do use a CPU timer if query timers are not enabled - but the CPU timer just reports the time elapsed before and after calling WebGL draw (which will always be close to 0).
 I feel like tf.time() shouldn't throw an error if query timers are not enabled because tf.time() also returns wallMs, which is valuable regardless of whether query timers are enabled. I think it makes sense for tf.time() to adapt its return signature depending on the device's capabilities. What do you think?
 		</comment>
 		<comment id='6' author='MatPoliquin' date='2020-02-03T16:39:14Z'>
 		Ah okay, I think that makes sense. Something like gpuKernelMs?
 		</comment>
 		<comment id='7' author='MatPoliquin' date='2020-02-03T16:56:30Z'>
 		&lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
  I think  makes sense for the name because it could be meaningful for the CPU backend. How about just not returning  as part of  if the user is on the WebGL backend and the query timer extension is unavailable?
 		</comment>
 		<comment id='8' author='MatPoliquin' date='2020-02-03T17:42:59Z'>
 		Talked to Nikhil. We decided that we shouldn't silently ignore (omit information) b/c that is not helpful to the user. E.g. if I'm using firefox + webgl and call tf.time, I want to understand why I can't measure the kernel time.
 Here is the proposal. Instead of throwing an error, kernelMs should map to:
 
 if everything works, a number
 if we can't measure it:
 
 {error: 'WebGL query timers are not supported in this environment'}
 		</comment>
 		<comment id='9' author='MatPoliquin' date='2020-02-03T17:53:21Z'>
 		OK - sounds good.
 		</comment>
 	</comments>
 </bug>
<commit id='0db0373720151aedf5608b4c4cde3c81c0aa85ad' author='Ann Yuan' date='2020-02-05 10:58:32-05:00'>
 	<dmm_unit complexity='1.0' interfacing='0.9230769230769231' size='0.9230769230769231'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tfjs-core\src\backends\backend.ts' new_name='tfjs-core\src\backends\backend.ts'>
 		<file_info nloc='547' complexity='6' token_count='3934'></file_info>
 		<modified_lines>
 			<added_lines>28</added_lines>
 			<deleted_lines>28</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tfjs-core\src\backends\webgl\backend_webgl.ts' new_name='tfjs-core\src\backends\webgl\backend_webgl.ts'>
 		<file_info nloc='2414' complexity='69' token_count='15912'></file_info>
 		<method name=']' parameters=''>
 				<method_info nloc='1' complexity='1' token_count='1' nesting_level='0' start_line='535' end_line='535'></method_info>
 			<added_lines>535</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='(anonymous)' parameters=''>
 				<method_info nloc='1' complexity='1' token_count='15' nesting_level='0' start_line='535' end_line='535'></method_info>
 			<added_lines>535</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='getExtraProfileInfo' parameters=''>
 				<method_info nloc='1' complexity='1' token_count='1' nesting_level='0' start_line='530' end_line='530'></method_info>
 			<added_lines>530</added_lines>
 			<deleted_lines>530</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>526,529,531,532,533,534,536,537,538,539,540,541,542,543,554,561,570</added_lines>
 			<deleted_lines>523,524,528,529,531,532,545,552,561</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tfjs-core\src\globals.ts' new_name='tfjs-core\src\globals.ts'>
 		<file_info nloc='81' complexity='23' token_count='569'></file_info>
 		<modified_lines>
 			<added_lines>242,243,244</added_lines>
 			<deleted_lines>242</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tfjs-core\src\profiler.ts' new_name='tfjs-core\src\profiler.ts'>
 		<file_info nloc='74' complexity='16' token_count='579'></file_info>
 		<method name='logKernelProfile' parameters='string,Tensor,TypedArray,NamedTensorMap,string'>
 				<method_info nloc='24' complexity='5' token_count='241' nesting_level='0' start_line='79' end_line='106'></method_info>
 			<added_lines>80,81,82,83,84</added_lines>
 			<deleted_lines>80,81,82</deleted_lines>
 		</method>
 		<method name='logKernelProfile' parameters='string,Tensor,TypedArray,number,NamedTensorMap,string'>
 				<method_info nloc='22' complexity='4' token_count='225' nesting_level='0' start_line='79' end_line='104'></method_info>
 			<added_lines>80,81,82,83,84</added_lines>
 			<deleted_lines>80,81,82</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tfjs-core\src\profiler_test.ts' new_name='tfjs-core\src\profiler_test.ts'>
 		<file_info nloc='140' complexity='21' token_count='1135'></file_info>
 		<method name='(anonymous)' parameters=''>
 				<method_info nloc='11' complexity='1' token_count='91' nesting_level='0' start_line='137' end_line='160'></method_info>
 			<added_lines>137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tf.tensor1d' parameters=''>
 				<method_info nloc='3' complexity='1' token_count='23' nesting_level='0' start_line='149' end_line='159'></method_info>
 			<added_lines>149,150,151,152,153,154,155,156,157,158,159</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>19,134,135,136,161</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
