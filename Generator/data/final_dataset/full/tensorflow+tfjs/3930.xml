<bug_data>
<bug id='3930' author='vladmandic' open_date='2020-09-15T12:54:14Z' closed_time='2020-09-30T17:29:51Z'>
 	<summary>tfjs-node support for saved models does not recognize valid dtypes</summary>
 	<description>
 Simply calling tfnode.node.getMetaGraphsFromSavedModel(path); on a model using uint8 results in error:
 &lt;denchmark-code&gt;(node:2420) UnhandledPromiseRejectionWarning: Error: Unsupported tensor DataType: DT_UINT8, try to modify the model in python to convert the datatype
     at mapTFDtypeToJSDtype (/home/vlado/dev/test-tfjs/node_modules/@tensorflow/tfjs-node/dist/saved_model.js:465:19)
 &lt;/denchmark-code&gt;
 
 However, support for  was added to  via &lt;denchmark-link:https://github.com/tensorflow/tfjs/pull/2981&gt;#2981&lt;/denchmark-link&gt;
  back in March.
 Those newly supported data types should be added throughout  codebase.
 Environment: Ubuntu 20.04 running NodeJS 14.9.0 with TFJS 2.3.0
 	</description>
 	<comments>
 		<comment id='1' author='vladmandic' date='2020-09-17T11:41:42Z'>
 		More details:
 There is an issue with  vs  mapping which causes failure on execution of a  in tfjs.
 Model in question is EfficientDet from TFHub: &lt;denchmark-link:https://tfhub.dev/tensorflow/efficientdet/d0&gt;https://tfhub.dev/tensorflow/efficientdet/d0&lt;/denchmark-link&gt;
 
 I've found your an earlier fix &lt;denchmark-link:https://github.com/tensorflow/tfjs/pull/2981&gt;#2981&lt;/denchmark-link&gt;
  which patches  by mapping  to , but:
 a) Same is also needed in tfjs-node/saved_model:mapTFDtypeToJSDtype() (and possibly in other places)  :
 &lt;denchmark-code&gt;  Error: Unsupported tensor DataType: DT_UINT8, try to modify the model in python to convert the datatype
   at mapTFDtypeToJSDtype (/home/vlado/dev/efficientdet/node_modules/@tensorflow/tfjs-node/dist/saved_model.js:471:19)
 &lt;/denchmark-code&gt;
 
 b) During model execution, model expects to receive uint8, but receives int32 and fails with:
 &lt;denchmark-code&gt;  Error: Session fail to run with error: Expects arg[0] to be uint8 but int32 is provided
   at NodeJSKernelBackend.runSavedModel (/home/vlado/dev/efficientdet/node_modules/@tensorflow/tfjs-node/dist/nodejs_kernel_backend.js:1592:43)  
 &lt;/denchmark-code&gt;
 
 So I'm not sure that simply mapping uint8 to int32 is a fix?
 Referencing previous issue &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/3374&gt;#3374&lt;/denchmark-link&gt;
  closed without resolution.
 Gist with a test code is at &lt;denchmark-link:https://gist.github.com/vladmandic/a7cf75109b7b48f8914a5b18da5c498f&gt;https://gist.github.com/vladmandic/a7cf75109b7b48f8914a5b18da5c498f&lt;/denchmark-link&gt;
 
 Links for direct download of a  are also included.
 		</comment>
 		<comment id='2' author='vladmandic' date='2020-09-30T17:29:51Z'>
 		Thanks &lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 ,
 I've confirmed on several  models that  now works perfectly with  data type.
 Since &lt;denchmark-link:https://github.com/tensorflow/tfjs/pull/3974&gt;#3974&lt;/denchmark-link&gt;
  is already committed to master, I'm closing this issue.
 		</comment>
 		<comment id='3' author='vladmandic' date='2020-09-30T17:29:52Z'>
 		Are you satisfied with the resolution of your issue?
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3930&gt;Yes&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3930&gt;No&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='4' author='vladmandic' date='2020-10-02T16:13:54Z'>
 		
 More details:
 There is an issue with int32 vs uint8 mapping which causes failure on execution of a saved_model in tfjs.
 Model in question is EfficientDet from TFHub: https://tfhub.dev/tensorflow/efficientdet/d0
 I've found your an earlier fix #2981 which patches tfjs-converter by mapping uint8 to int32, but:
 a) Same is also needed in tfjs-node/saved_model:mapTFDtypeToJSDtype() (and possibly in other places) :
   Error: Unsupported tensor DataType: DT_UINT8, try to modify the model in python to convert the datatype
   at mapTFDtypeToJSDtype (/home/vlado/dev/efficientdet/node_modules/@tensorflow/tfjs-node/dist/saved_model.js:471:19)
 
 b) During model execution, model expects to receive uint8, but receives int32 and fails with:
   Error: Session fail to run with error: Expects arg[0] to be uint8 but int32 is provided
   at NodeJSKernelBackend.runSavedModel (/home/vlado/dev/efficientdet/node_modules/@tensorflow/tfjs-node/dist/nodejs_kernel_backend.js:1592:43)  
 
 So I'm not sure that simply mapping uint8 to int32 is a fix?
 Referencing previous issue #3374 closed without resolution.
 Gist with a test code is at https://gist.github.com/vladmandic/a7cf75109b7b48f8914a5b18da5c498f
 Links for direct download of a saved_model are also included.
 
 The same issue happens with DT_INT64 as well:
 &lt;denchmark-code&gt;2020-10-02 17:55:36.860435: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
 2020-10-02 17:55:36.883827: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x119b7b0a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
 2020-10-02 17:55:36.883865: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
 (node:39361) UnhandledPromiseRejectionWarning: Error: Unsupported tensor DataType: DT_INT64, try to modify the model in python to convert the datatype
 &lt;/denchmark-code&gt;
 
 after converting a GraphModel to SavedModel using tensorflowjs_converter.
 		</comment>
 		<comment id='5' author='vladmandic' date='2020-10-02T16:17:27Z'>
 		&lt;denchmark-link:https://github.com/loretoparisi&gt;@loretoparisi&lt;/denchmark-link&gt;
  Yup, I've reported that under &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/4004&gt;#4004&lt;/denchmark-link&gt;
  and it was just fixed in &lt;denchmark-link:https://github.com/tensorflow/tfjs/pull/4008&gt;#4008&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='6' author='vladmandic' date='2020-10-05T10:40:06Z'>
 		Hey &lt;denchmark-link:https://github.com/vladmandic&gt;@vladmandic&lt;/denchmark-link&gt;
  in the meantime  added a support while converting using  in latest version :
 &lt;denchmark-code&gt;$ tfjs_graph_converter --output_format tf_saved_model --compat_mode ./ ./saved/
 TensorFlow.js Graph Model Converter
 
 Graph model:    ./
 Output:         ./saved/
 Target format:  tf_saved_model
 
 Converting.... Done.
 Conversion took 1.667s
 &lt;/denchmark-code&gt;
 
 The GraphModel now converted to SavedModel seems loading fine now:
 const tfjsnode = require('@tensorflow/tfjs-node');
 var loadSavedModel = function (path) {
   return new Promise(function (resolve, reject) {
     tfjsnode.node.loadSavedModel(this.path)
       .then(res =&gt; {
         console.log("loadSavedModel OK");
         resolve(res);
       })
       .catch(err =&gt; reject(err));
   });
 }
 loadSavedModel('/Users/loretoparisi/webservice/toxicity_model/saved')
   .catch(err =&gt; console.error("loadSavedModel", err));
 This works fine:
 2020-10-05 12:38:29.166043: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /Users/loretoparisi/webservice/toxicity_model/saved
 2020-10-05 12:38:29.193234: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
 2020-10-05 12:38:29.252666: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.
 2020-10-05 12:38:29.252729: I tensorflow/cc/saved_model/loader.cc:212] The specified SavedModel has no variables; no checkpoints were restored. File does not exist: /Users/loretoparisi/webservice/toxicity_model/saved/variables/variables.index
 2020-10-05 12:38:29.252752: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 86709 microseconds.
 BUT, if I apply this to the TFJS model wrapper here:
     ToxicityClassifier.prototype.loadModel = function () {
         return __awaiter(this, void 0, void 0, function () {
             return __generator(this, function (_a) {
                 return [2, tfjsnode.node.loadSavedModel(path)];
             });
         });
     };
 it will fail due to another error
 (node:43549) UnhandledPromiseRejectionWarning: Error: SavedModel outputs information is not available yet.
     at TFSavedModel.get [as outputs] (/Users/loretoparisi/Documents/Projects/AI/tensorflow-node-examples/node_modules/@tensorflow/tfjs-node/dist/saved_model.js:265:19)
     at ToxicityClassifier.&lt;anonymous&gt; (/Users/loretoparisi/Documents/Projects/AI/tensorflow-node-examples/toxicity-example/lib/toxicity/dist/index.js:101:35)
 ...
 		</comment>
 		<comment id='7' author='vladmandic' date='2020-10-07T14:07:16Z'>
 		&lt;denchmark-link:https://github.com/loretoparisi&gt;@loretoparisi&lt;/denchmark-link&gt;
  Do you still have the same problem? It works fine for me with int64 and int32 inputs with TFJS v2.5.0 and with int32 inputs in v2.3.0 and v2.4.0.
 		</comment>
 		<comment id='8' author='vladmandic' date='2020-10-07T18:27:10Z'>
 		&lt;denchmark-link:https://github.com/patlevin&gt;@patlevin&lt;/denchmark-link&gt;
  thank you, let me check, they  have just released 
 		</comment>
 		<comment id='9' author='vladmandic' date='2020-10-07T18:50:55Z'>
 		&lt;denchmark-link:https://github.com/patlevin&gt;@patlevin&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/vladmandic&gt;@vladmandic&lt;/denchmark-link&gt;
  So the model correctly loads with tfjs , but, in this example at least, there is a specific error that is
 &lt;denchmark-code&gt;2020-10-07 20:49:15.662525: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: ./toxicity_model/saved
 2020-10-07 20:49:15.702371: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
 2020-10-07 20:49:15.765097: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.
 2020-10-07 20:49:15.765158: I tensorflow/cc/saved_model/loader.cc:212] The specified SavedModel has no variables; no checkpoints were restored. File does not exist: ./toxicity_model/saved/variables/variables.index
 2020-10-07 20:49:15.765180: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 102655 microseconds.
 (node:65757) UnhandledPromiseRejectionWarning: Error: SavedModel outputs information is not available yet.
 &lt;/denchmark-code&gt;
 
 I have opened a specific issue here &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/4035&gt;#4035&lt;/denchmark-link&gt;
 
 Thank you!
 		</comment>
 		<comment id='10' author='vladmandic' date='2020-10-07T19:14:09Z'>
 		&lt;denchmark-link:https://github.com/loretoparisi&gt;@loretoparisi&lt;/denchmark-link&gt;
  Interesting. I used the following code and it worked just fine:
 const tf = require('@tensorflow/tfjs-node')
 
 async function run() {
   const model = await tf.node.loadSavedModel('./models/toxicity_saved/')
   // both indexArray and valueArray are obtained from two preprocessed test phrases that I used to verify
   // model outputs
   const indexArray = [
     [0, 1], [0,2 ], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8],
     [1, 0], [1, 1], [1, 2], [1, 3]
   ]
   const valueArray = [215, 13, 53, 4461, 2951, 519, 1129, 7, 78, 16, 123, 20, 6]
   const indices = tf.tensor2d(indexArray, [indexArray.length, 2], 'int32')
   const values = tf.tensor1d(valueArray, 'int32')
   const modelInputs = {
     Placeholder_1: indices,
     Placeholder: values
   }
   const labels = model.predict(modelInputs)
   indices.dispose()
   values.dispose()
   outputs = []
   for (name in labels) {
    const prediction = labels[name].dataSync()
    const results = []
    for (let input = 0; input &lt; 2; ++input) {
      const probs = prediction.slice(input * 2, input * 2 + 2)
      let match = null
      if (Math.max(probs[0], probs[1]) &gt; 0.9) {
        match = probs[0] &gt; probs[1]
      }
      p= probs.toString() // just to print out the numbers
      results.push({p, match})
    }
    outputs.push({label: name.split('/')[0], results})
   }
   for (x of outputs) {
     console.log(x)
   }
 }
 
 run()
 The model methods outputs() and inputs() aren't implemented yet for the SavmedModel-class, but in case you need them for some reason, outputs and inputs can be obtained using the getMetaGraphsFromSavedModel() and getSignatureDefEntryFromMetaGraphInfo() functions.
 		</comment>
 		<comment id='11' author='vladmandic' date='2020-10-07T19:25:11Z'>
 		&lt;denchmark-link:https://github.com/patlevin&gt;@patlevin&lt;/denchmark-link&gt;
  thanks, I confirm that this way it works!
 &lt;denchmark-code&gt;ip-192-168-178-22:toxicity-example loretoparisi$ node test.js 
 node-pre-gyp info This Node instance does not support builds for N-API version 6
 node-pre-gyp info This Node instance does not support builds for N-API version 6
 2020-10-07 21:16:16.466776: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
 2020-10-07 21:16:16.494477: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11a0dfb60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
 2020-10-07 21:16:16.494524: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
 2020-10-07 21:16:16.624539: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: ./toxicity_model/saved
 2020-10-07 21:16:16.647951: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
 2020-10-07 21:16:16.704225: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.
 2020-10-07 21:16:16.704289: I tensorflow/cc/saved_model/loader.cc:212] The specified SavedModel has no variables; no checkpoints were restored. File does not exist: ./toxicity_model/saved/variables/variables.index
 2020-10-07 21:16:16.704314: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 79774 microseconds.
 {
   label: 'identity_attack',
   results: [
     { p: '0.9964505434036255,0.0035493909381330013', match: true },
     { p: '0.9999773502349854,0.00002267475429107435', match: true }
   ]
 }
 {
   label: 'insult',
   results: [
     { p: '0.013952560722827911,0.9860473871231079', match: false },
     { p: '0.9996521472930908,0.00034789409255608916', match: true }
   ]
 }
 {
   label: 'obscene',
   results: [
     { p: '0.997055172920227,0.002944822423160076', match: true },
     { p: '0.9999693632125854,0.00003068893784075044', match: true }
   ]
 }
 {
   label: 'severe_toxicity',
   results: [
     { p: '0.9999983310699463,0.0000016291029396597878', match: true },
     { p: '1,7.3735777483818765e-9', match: true }
   ]
 }
 {
   label: 'sexual_explicit',
   results: [
     { p: '0.9994053840637207,0.0005946253077127039', match: true },
     { p: '0.9999841451644897,0.00001583264020155184', match: true }
   ]
 }
 {
   label: 'threat',
   results: [
     { p: '0.9994139671325684,0.000586066220421344', match: true },
     { p: '0.9999756813049316,0.000024260229110950604', match: true }
   ]
 }
 {
   label: 'toxicity',
   results: [
     { p: '0.011850903742015362,0.988149106502533', match: false },
     { p: '0.999394416809082,0.0006055471021682024', match: true }
   ]
 }
 &lt;/denchmark-code&gt;
 
 while, according to what you say, using the other way the error
 &lt;denchmark-code&gt;Error: SavedModel outputs information is not available yet.
     at TFSavedModel.get [as outputs] (/Users/loretoparisi/Documents/Projects/AI/tensorflow-node-examples/node_modules/@tensorflow/tfjs-node/dist/saved_model.js:251:19)
 &lt;/denchmark-code&gt;
 
 comes from within the saved_model class, in fact there we have a not implemented error!
 &lt;denchmark-code&gt;Object.defineProperty(TFSavedModel.prototype, "outputs", {
         /**
          * Return the array of output tensor info.
          *
          * @doc {heading: 'Models', subheading: 'SavedModel'}
          */
         get: function () {
             throw new Error('SavedModel outputs information is not available yet.');
         },
         enumerable: true,
         configurable: true
     });
 &lt;/denchmark-code&gt;
 
 hence the offending line in the toxicity example is the following I assume
 this.labels =
                             model.outputs.map(function (d) { return d.name.split('/')[0]; });
                         if (this.toxicityLabels.length === 0) {
                             this.toxicityLabels = this.labels;
                         }
 that must be changed in someway using the getMetaGraphsFromSavedModel method then.
 		</comment>
 		<comment id='12' author='vladmandic' date='2020-10-07T19:30:13Z'>
 		&lt;denchmark-link:https://github.com/loretoparisi&gt;@loretoparisi&lt;/denchmark-link&gt;
  I'll create a pull-request that implements  and  on .
 		</comment>
 		<comment id='13' author='vladmandic' date='2020-10-07T19:39:37Z'>
 		
 @loretoparisi I'll create a pull-request that implements outputs() and inputs() on SavedModel.
 
 super! In the meantime I have found the outputs something as you suggested
 const modelInfo = await tf.node.getMetaGraphsFromSavedModel('./toxicity_model/saved');
 console.dir(modelInfo[0].signatureDefs.serving_default.outputs, { depth: null, maxArrayLength: null });
 		</comment>
 		<comment id='14' author='vladmandic' date='2020-10-07T21:02:30Z'>
 		&lt;denchmark-link:https://github.com/loretoparisi&gt;@loretoparisi&lt;/denchmark-link&gt;
  btw, one advantage of working with  and  is that it shows actual signature names instead just an incrementing array (when model has multiple inputs and/or outputs) that you get from a .
 See &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/3942&gt;#3942&lt;/denchmark-link&gt;
  for details.
 		</comment>
 		<comment id='15' author='vladmandic' date='2020-10-08T10:05:04Z'>
 		
 @loretoparisi Interesting. I used the following code and it worked just fine:
 const tf = require('@tensorflow/tfjs-node')
 
 async function run() {
   const model = await tf.node.loadSavedModel('./models/toxicity_saved/')
   // both indexArray and valueArray are obtained from two preprocessed test phrases that I used to verify
   // model outputs
   const indexArray = [
     [0, 1], [0,2 ], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8],
     [1, 0], [1, 1], [1, 2], [1, 3]
   ]
   const valueArray = [215, 13, 53, 4461, 2951, 519, 1129, 7, 78, 16, 123, 20, 6]
   const indices = tf.tensor2d(indexArray, [indexArray.length, 2], 'int32')
   const values = tf.tensor1d(valueArray, 'int32')
   const modelInputs = {
     Placeholder_1: indices,
     Placeholder: values
   }
   const labels = model.predict(modelInputs)
   indices.dispose()
   values.dispose()
   outputs = []
   for (name in labels) {
    const prediction = labels[name].dataSync()
    const results = []
    for (let input = 0; input &lt; 2; ++input) {
      const probs = prediction.slice(input * 2, input * 2 + 2)
      let match = null
      if (Math.max(probs[0], probs[1]) &gt; 0.9) {
        match = probs[0] &gt; probs[1]
      }
      p= probs.toString() // just to print out the numbers
      results.push({p, match})
    }
    outputs.push({label: name.split('/')[0], results})
   }
   for (x of outputs) {
     console.log(x)
   }
 }
 
 run()
 The model methods outputs() and inputs() aren't implemented yet for the SavmedModel-class, but in case you need them for some reason, outputs and inputs can be obtained using the getMetaGraphsFromSavedModel() and getSignatureDefEntryFromMetaGraphInfo() functions.
 
 &lt;denchmark-link:https://github.com/patlevin&gt;@patlevin&lt;/denchmark-link&gt;
  thanks for the test script.
 I modified it a little bit to user the Universal Sentence Encoder:
 const use = require("@tensorflow-models/universal-sentence-encoder");
 const model = await tf.node.loadSavedModel('./toxicity_model/saved');
 const tokenizer = await use.load();
 const sentences = ['you suck', 'hello how are you?'];
 var codes = await tokenizer.embed(sentences);
 console.log(codes);
 Now I have an array of Tensors like
 &lt;denchmark-code&gt;Tensor {
   kept: false,
   isDisposedInternal: false,
   shape: [ 1, 512 ],
   dtype: 'float32',
   size: 512,
   strides: [ 512 ],
   dataId: {},
   id: 837,
   rankType: '2',
   scopeId: 1289
 }
 &lt;/denchmark-code&gt;
 
 and now I have to turn into indexes and values. I have tried this
 var encodings = await tokenizer.embed(sentences);
 var indicesArr = encodings.map(function (arr, i) { return arr.map(function (d, index) { return [i, index]; }); });
 var flattenedIndicesArr = [];
 for (i = 0; i &lt; indicesArr.length; i++) {
     flattenedIndicesArr =
         flattenedIndicesArr.concat(indicesArr[i]);
 }
 var indices = tf.tensor2d(flattenedIndicesArr, [flattenedIndicesArr.length, 2], 'int32');
 var values = tf.tensor1d(tf.util.flatten(encodings), 'int32');
 But it seems that embed function of the Tokenizers is different from the encode function internally used that I cannot call external (it gives me an undefined if I try tokenizer.encode), so in this case I get an error:
 &lt;denchmark-code&gt;TypeError: encodings.map is not a function
 &lt;/denchmark-code&gt;
 
 Thank you.
 		</comment>
 		<comment id='16' author='vladmandic' date='2020-10-08T21:05:02Z'>
 		&lt;denchmark-link:https://github.com/loretoparisi&gt;@loretoparisi&lt;/denchmark-link&gt;
  The model expects an encoded word vector as input, while the Universal Sentence Encoder (USE) model returns embeddings.
 Basically, you'll want to use the loadTokenizer() function from the previous USE version, but that one requires TFJS 1.x...
 I have a working version locally, but it'd be better to fix the examples instead - see Issue model repo
 Unfortunately &lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 's commit b02310745ceac6b8e4a475719c343da53e3cade2 on the USE-repo broke both the Toxicity  model and your use-case entirely...
 The real problem is that the examples are outdated and some changes broke TFJS 2.x compatibility (in the case of USE I fail to see the reasoning behind the change - might have been a mistake?).
 Meanwhile, I'll create a gist for you that contains all you need to get this working as a single-file solution. I'll get back to you in a bit.
 EDIT: I got confused here, since a similar issue was raised w.r.t. outdated tfjs-examples. The same applies to tfjs-models, though - basically some models are incompatible with TFJS 2.x due to package changes (not for technical reasons).
 		</comment>
 		<comment id='17' author='vladmandic' date='2020-10-09T08:47:56Z'>
 		&lt;denchmark-link:https://github.com/patlevin&gt;@patlevin&lt;/denchmark-link&gt;
  thank you! In fact I have just realized that the after recent updates models examples and core code diverged!
 		</comment>
 	</comments>
 </bug>
<commit id='5e2d3f6151cc27659bfbe3e472d9f758e9853221' author='Ping Yu' date='2020-09-27 07:42:43-07:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tfjs-core\src\base.ts' new_name='tfjs-core\src\base.ts'>
 		<file_info nloc='54' complexity='0' token_count='385'></file_info>
 		<modified_lines>
 			<added_lines>44</added_lines>
 			<deleted_lines>44</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tfjs-core\src\model_types.ts' new_name='tfjs-core\src\model_types.ts'>
 		<file_info nloc='47' complexity='0' token_count='257'></file_info>
 		<modified_lines>
 			<added_lines>44,45,143,144,145,146,147,148,149,150,155</added_lines>
 			<deleted_lines>145,146,147,148</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='tfjs-node-gpu\test_objects\saved_model\uint8_multiply\saved_model.pb' new_name='tfjs-node-gpu\test_objects\saved_model\uint8_multiply\saved_model.pb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='tfjs-node-gpu\test_objects\saved_model\uint8_multiply\variables\variables.data-00000-of-00001' new_name='tfjs-node-gpu\test_objects\saved_model\uint8_multiply\variables\variables.data-00000-of-00001'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='tfjs-node-gpu\test_objects\saved_model\uint8_multiply\variables\variables.index' new_name='tfjs-node-gpu\test_objects\saved_model\uint8_multiply\variables\variables.index'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='None' new_name='tfjs-node\python\unint8_model.py'>
 		<file_info nloc='17' complexity='0' token_count='163'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='tfjs-node\src\nodejs_kernel_backend.ts' new_name='tfjs-node\src\nodejs_kernel_backend.ts'>
 		<file_info nloc='1815' complexity='26' token_count='15079'></file_info>
 		<modified_lines>
 			<added_lines>19,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1922,1925,1926</added_lines>
 			<deleted_lines>19,1907,1910</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tfjs-node\src\saved_model.ts' new_name='tfjs-node\src\saved_model.ts'>
 		<file_info nloc='258' complexity='42' token_count='1910'></file_info>
 		<method name='(anonymous)' parameters=''>
 				<method_info nloc='4' complexity='1' token_count='21' nesting_level='0' start_line='251' end_line='254'></method_info>
 			<added_lines>251,252,253,254</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='getSignatureDefEntryFromMetaGraphInfo' parameters='string'>
 				<method_info nloc='14' complexity='4' token_count='109' nesting_level='0' start_line='175' end_line='188'></method_info>
 			<added_lines>175,176,177,184</added_lines>
 			<deleted_lines>179,180,181,182,183,184,185,186,187,188</deleted_lines>
 		</method>
 		<method name='loadSavedModel' parameters='string,tags,signature'>
 				<method_info nloc='26' complexity='5' token_count='180' nesting_level='0' start_line='383' end_line='413'></method_info>
 			<added_lines>391,392,410</added_lines>
 			<deleted_lines>390,391,392,410</deleted_lines>
 		</method>
 		<method name='outputNodeNames' parameters=''>
 				<method_info nloc='9' complexity='2' token_count='65' nesting_level='0' start_line='245' end_line='256'></method_info>
 			<added_lines>245,246,247,248,249,250,251,252,253,254,255,256</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='getInputAndOutputNodeNameFromMetaGraphInfo' parameters='string'>
 				<method_info nloc='29' complexity='8' token_count='242' nesting_level='0' start_line='171' end_line='199'></method_info>
 			<added_lines>175,176,177,184,198</added_lines>
 			<deleted_lines>171,172,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195</deleted_lines>
 		</method>
 		<method name='constructor' parameters='number,number,NodeJSKernelBackend'>
 				<method_info nloc='5' complexity='1' token_count='44' nesting_level='0' start_line='210' end_line='214'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>212,213</deleted_lines>
 		</method>
 		<method name='mapTFDtypeToJSDtype' parameters='string'>
 				<method_info nloc='19' complexity='7' token_count='61' nesting_level='0' start_line='429' end_line='447'></method_info>
 			<added_lines>434</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='constructor' parameters='number,number,SignatureDefEntry,NodeJSKernelBackend'>
 				<method_info nloc='4' complexity='1' token_count='23' nesting_level='0' start_line='199' end_line='202'></method_info>
 			<added_lines>201</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='getMetaGraphsFromSavedModel' parameters='string'>
 				<method_info nloc='64' complexity='9' token_count='483' nesting_level='0' start_line='85' end_line='164'></method_info>
 			<added_lines>92,93,128,129,130,131,148,149,150,151</added_lines>
 			<deleted_lines>91,92,127,128,129,146,147,163,164</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>18,21,167,168,257,291,297,300,308,311</added_lines>
 			<deleted_lines>18,209,290,296,299,307,310</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tfjs-node\src\saved_model_test.ts' new_name='tfjs-node\src\saved_model_test.ts'>
 		<file_info nloc='388' complexity='30' token_count='3468'></file_info>
 		<method name='(anonymous)' parameters=''>
 				<method_info nloc='10' complexity='1' token_count='80' nesting_level='0' start_line='187' end_line='196'></method_info>
 			<added_lines>190,192,193,194</added_lines>
 			<deleted_lines>190,192,193,194</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>21,397,398,399,400,401,402,403,404,405,406,407</added_lines>
 			<deleted_lines>21</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='ADD' old_name='tfjs-node\test_objects\saved_model\uint8_multiply\saved_model.pb' new_name='tfjs-node\test_objects\saved_model\uint8_multiply\saved_model.pb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='tfjs-node\test_objects\saved_model\uint8_multiply\variables\variables.data-00000-of-00001' new_name='tfjs-node\test_objects\saved_model\uint8_multiply\variables\variables.data-00000-of-00001'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='ADD' old_name='tfjs-node\test_objects\saved_model\uint8_multiply\variables\variables.index' new_name='tfjs-node\test_objects\saved_model\uint8_multiply\variables\variables.index'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 </commit>
</bug_data>
