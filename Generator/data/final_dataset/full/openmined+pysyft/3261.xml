<bug_data>
<bug id='3261' author='AlanAboudib' open_date='2020-03-27T13:48:18Z' closed_time='2020-03-31T19:44:14Z'>
 	<summary>fix_precision() is inplace when applied to a pointer tensor.</summary>
 	<description>
 Description of the bug
 The method fix_precision() applied on pointers is 'inplace'. This should not be the case
 In the following code:
 &lt;denchmark-code&gt;a = torch.Tensor([2., 3.]).send(bob)
 a.fix_precision()
 a = a.get()
 print(type(a))
 &lt;/denchmark-code&gt;
 
 The variable  a after calling get() is a fixed precision tensor which is a bug, because the original variable a defined as torch.Tensor([2., 3.]) is not a fixed precision tensor.
 However, this bug is not existing in case when  a is not a pointer:
 &lt;denchmark-code&gt;a = torch.Tensor([2., 3.])
 a.fix_precision()
 print(type(a))
 &lt;/denchmark-code&gt;
 
 a here is not a fixed precision tensor. which is the desired behavior.
 Desktop:
 
 OS: Archlinux
 Version 0.3.2
 
 	</description>
 	<comments>
 		<comment id='1' author='AlanAboudib' date='2020-03-27T14:05:30Z'>
 		I can take this!!
 		</comment>
 		<comment id='2' author='AlanAboudib' date='2020-03-28T06:50:10Z'>
 		Hey &lt;denchmark-link:https://github.com/AlanAboudib&gt;@AlanAboudib&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/karlhigley&gt;@karlhigley&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/LaRiffle&gt;@LaRiffle&lt;/denchmark-link&gt;
  ,
 so if I understand this correctly,
 x = th.Tensor([1.,2.,3.]).send(bob)
 x_fx = x.fix_precision()
 x = x_fx.get()
 x_fx is a PointerTensor and expected behavior is to be a FixedPrecisionTensor with PointerTensor as child?
 Moreover when we .get() the x_fx, it returns FixedPrecisionTensor, which I think is a correct behavior, as we haven't called float_precision yet.
 		</comment>
 		<comment id='3' author='AlanAboudib' date='2020-03-28T12:32:45Z'>
 		not exactly, fix_precision() should be applied anyway on the remote value when called on a pointer (and it works fine)
 the issue is that currently we have this for pointers:
 &lt;denchmark-code&gt;a = torch.Tensor([2., 3.]).send(bob)
 a_fp = a.fix_precision()
 # a_fp is a pointer to a fixed precision, but a is too!
 &lt;/denchmark-code&gt;
 
 while for non pointers:
 &lt;denchmark-code&gt;a = torch.Tensor([2., 3.])
 a_fp = a.fix_precision()
 # a_fp is a wrapper onto a fixed precision, but a is not!
 &lt;/denchmark-code&gt;
 
 So for pointers, fix_precision behaves as fix_precision_ while it shouldn't
 		</comment>
 	</comments>
 </bug>
<commit id='10374f533f81c11fd2f5f23f63aeabd12849f67a' author='Sukhad Joshi' date='2020-03-31 21:44:13+02:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='syft\frameworks\torch\tensors\interpreters\native.py' new_name='syft\frameworks\torch\tensors\interpreters\native.py'>
 		<file_info nloc='641' complexity='142' token_count='3913'></file_info>
 		<method name='fix_prec' parameters='self,args,storage,field_type,bool,kwargs'>
 				<method_info nloc='49' complexity='10' token_count='309' nesting_level='1' start_line='800' end_line='869'></method_info>
 			<added_lines>816,818,820</added_lines>
 			<deleted_lines>816,818,820</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\torch\pointers\test_pointer_tensor.py' new_name='test\torch\pointers\test_pointer_tensor.py'>
 		<file_info nloc='290' complexity='29' token_count='2862'></file_info>
 		<method name='test_fix_prec_on_pointer_tensor' parameters='workers'>
 				<method_info nloc='10' complexity='1' token_count='93' nesting_level='0' start_line='401' end_line='420'></method_info>
 			<added_lines>404,411,412,414,415,416,417,420</added_lines>
 			<deleted_lines>410,414</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
