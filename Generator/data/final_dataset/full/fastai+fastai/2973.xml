<bug_data>
<bug id='2973' author='muellerzr' open_date='2020-11-11T15:12:07Z' closed_time='2020-11-18T01:32:41Z'>
 	<summary>"only one element tensors can be converted to Python scalars" exception in Siamese Tutorial</summary>
 	<description>
 When following the Siamese tutorial eventually you'll hit a snag on show_results:
 (Also to open a colab notebook with the error see &lt;denchmark-link:https://colab.research.google.com/gist/muellerzr/548abbf2401af5e0716829721df48a79/24_tutorial-siamese.ipynb&gt;here&lt;/denchmark-link&gt;
 
 ---------------------------------------------------------------------------
 ValueError                                Traceback (most recent call last)
 &lt;ipython-input-76-c3b657dcc9ae&gt; in &lt;module&gt;()
 ----&gt; 1 learn.show_results()
 
 4 frames
 /usr/local/lib/python3.6/dist-packages/fastai/learner.py in show_results(self, ds_idx, dl, max_n, shuffle, **kwargs)
     261         b = dl.one_batch()
     262         _,_,preds = self.get_preds(dl=[b], with_decoded=True)
 --&gt; 263         self.dls.show_results(b, preds, max_n=max_n, **kwargs)
     264 
     265     def show_training_loop(self):
 
 /usr/local/lib/python3.6/dist-packages/fastai/data/core.py in show_results(self, b, out, max_n, ctxs, show, **kwargs)
     109         res = (x,x1,None,None) if its is None else (x, y, its, outs.itemgot(slice(self.n_inp,None)))
     110         if not show: return res
 --&gt; 111         show_results(*res, ctxs=ctxs, max_n=max_n, **kwargs)
     112 
     113     @property
 
 /usr/local/lib/python3.6/dist-packages/fastcore/dispatch.py in __call__(self, *args, **kwargs)
     127         elif self.inst is not None: f = MethodType(f, self.inst)
     128         elif self.owner is not None: f = MethodType(f, self.owner)
 --&gt; 129         return f(*args, **kwargs)
     130 
     131     def __get__(self, inst, owner):
 
 &lt;ipython-input-75-32c98030f37b&gt; in show_results(x, y, samples, outs, ctxs, max_n, nrows, ncols, figsize, **kwargs)
       5     for i,ctx in enumerate(ctxs):
       6         print(type(x[2][i]))
 ----&gt; 7         title = f'Actual: {["Not similar","Similar"][x[2][i].item()]} \n Prediction: {["Not similar","Similar"][y[2][i].item()]}'
       8         SiameseImage(x[0][i], x[1][i], title).show(ctx=ctx)
 
 /usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in __torch_function__(self, func, types, args, kwargs)
     315 
     316     def __torch_function__(self, func, types, args=(), kwargs=None):
 --&gt; 317         with torch._C.DisableTorchFunction(): ret = _convert(func(*args, **(kwargs or {})), self.__class__)
     318         if isinstance(ret, TensorBase): ret.set_meta(self, as_copy=True)
     319         return ret
 
 ValueError: only one element tensors can be converted to Python scalars
 &lt;denchmark-link:https://github.com/jph00&gt;@jph00&lt;/denchmark-link&gt;
  likely a torch upgrade issue?
 	</description>
 	<comments>
 		<comment id='1' author='muellerzr' date='2020-11-11T17:28:55Z'>
 		this is pretty weird indeed... if we run %debug just after this, the x  is correct, butt the y vector is wrong.
 &lt;denchmark-code&gt;y[2].shape
 &gt;&gt; (1,3,64,1)
 &lt;/denchmark-code&gt;
 
 The problem comes from get_preds, the output of the model is of type TensorImage. This shouldn't be the case, it is probably linked to the new typed-Tensors, even if you do:
 &lt;denchmark-code&gt;b  = dls.one_batch()
 out = learn.model(b[0], b[1])
 type(out)
 &gt;&gt; TensorImage
 &lt;/denchmark-code&gt;
 
 so TensorImage propagates all through the model, images in, images out...
 		</comment>
 		<comment id='2' author='muellerzr' date='2020-11-12T11:42:55Z'>
 		This fixes the issue:
 def apply_wo_type(func, x, *args, **kwargs):
     "Apply `func` recursively to `x`, passing on args"
     if is_listy(x): return type(x)([apply_wo_type(func, o, *args, **kwargs) for o in x])
     if isinstance(x,dict):  return {k: apply_wo_type(func, v, *args, **kwargs) for k,v in x.items()}
     res = func(x, *args, **kwargs)
     return res
 
 def remove_tensor_type(b):
     "Recursively map lists of int tensors in `b ` to float."
     return apply_wo_type(lambda x: cast(x,typ=Tensor), b)
 
 class RemoveTypeCB(Callback):
     def after_pred(self):
         self.learn.pred = remove_tensor_type(self.pred)
 or a  last Transform that removes types before feeding the model.
 		</comment>
 		<comment id='3' author='muellerzr' date='2020-11-17T20:02:13Z'>
 		Hi &lt;denchmark-link:https://github.com/tcapelle&gt;@tcapelle&lt;/denchmark-link&gt;
  , I've been seeing this issue as well.
 For your proposed fix above, where would that be implemented to get this code working? Or do you have plans to integrate it into this tutorial notebook?
 And as long as we're here, I'm also seeing the below error in response to the last line in this notebook. Possibly related?
 &lt;denchmark-code&gt;---------------------------------------------------------------------------
 RuntimeError                              Traceback (most recent call last)
 &lt;ipython-input-85-97c83ebb6f57&gt; in &lt;module&gt;()
 ----&gt; 1 res = learn.siampredict(siamtest)
 
 1 frames
 &lt;ipython-input-78-c877b0c06524&gt; in siampredict(self, item, rm_type_tfms, with_input)
       2 def siampredict(self:Learner, item, rm_type_tfms=None, with_input=False):
       3     res = self.predict(item, rm_type_tfms=None, with_input=False)
 ----&gt; 4     if res[0] == tensor(0):
       5         SiameseImage(item[0], item[1], 'Prediction: Not similar').show()
       6     else:
 
 /usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in __torch_function__(self, func, types, args, kwargs)
     315 
     316     def __torch_function__(self, func, types, args=(), kwargs=None):
 --&gt; 317         with torch._C.DisableTorchFunction(): ret = _convert(func(*args, **(kwargs or {})), self.__class__)
     318         if isinstance(ret, TensorBase): ret.set_meta(self, as_copy=True)
     319         return ret
 
 RuntimeError: Boolean value of Tensor with more than one value is ambiguous
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='4' author='muellerzr' date='2020-11-17T20:46:17Z'>
 		The issue is it needs to be a proper tensor type. Jeremy and Marii are
 currently working on a fix.
 &lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;
 
 
 On Tue, Nov 17, 2020 at 3:02 PM Scott Butters ***@***.***&gt; wrote:
  Hi @tcapelle &lt;https://github.com/tcapelle&gt; , I've been seeing this issue
  as well.
 
  For your proposed fix above, where would that be implemented to get this
  code working? Or do you have plans to integrate it into this tutorial
  notebook?
 
  And as long as we're here, I'm also seeing the below error in response to
  the last line in this notebook. Possibly related?
 
  ---------------------------------------------------------------------------
  RuntimeError                              Traceback (most recent call last)
  &lt;ipython-input-85-97c83ebb6f57&gt; in &lt;module&gt;()
  ----&gt; 1 res = learn.siampredict(siamtest)
 
  1 frames
  &lt;ipython-input-78-c877b0c06524&gt; in siampredict(self, item, rm_type_tfms, with_input)
        2 def siampredict(self:Learner, item, rm_type_tfms=None, with_input=False):
        3     res = self.predict(item, rm_type_tfms=None, with_input=False)
  ----&gt; 4     if res[0] == tensor(0):
        5         SiameseImage(item[0], item[1], 'Prediction: Not similar').show()
        6     else:
 
  /usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in __torch_function__(self, func, types, args, kwargs)
      315
      316     def __torch_function__(self, func, types, args=(), kwargs=None):
  --&gt; 317         with torch._C.DisableTorchFunction(): ret = _convert(func(*args, **(kwargs or {})), self.__class__)
      318         if isinstance(ret, TensorBase): ret.set_meta(self, as_copy=True)
      319         return ret
 
  RuntimeError: Boolean value of Tensor with more than one value is ambiguous
 
  —
  You are receiving this because you authored the thread.
  Reply to this email directly, view it on GitHub
  &lt;#2973 (comment)&gt;, or
  unsubscribe
  &lt;https://github.com/notifications/unsubscribe-auth/AB3YCV2X5FWKOAAMWELB6S3SQLJFJANCNFSM4TSDLLHQ&gt;
  .
 
 
 
 		</comment>
 		<comment id='5' author='muellerzr' date='2020-11-17T22:13:32Z'>
 		yes, it actually needs to be of Pyotrch tensor type instead of fastai's cutom tensors. My fix does this, removes the type to the output of the model. You can apply this fix, by passing this cb to the learner.
 		</comment>
 		<comment id='6' author='muellerzr' date='2020-11-17T22:15:06Z'>
 		The other option is to fix the bug in fastai itself and cast it to a proper fastai custom tensor instead (which is what they are doing)
 		</comment>
 		<comment id='7' author='muellerzr' date='2020-11-17T22:15:44Z'>
 		but what custom tensor would that be?
 		</comment>
 	</comments>
 </bug>
<commit id='eb98c4a490c319f8136be92cfc1628b5de3f33e2' author='Jeremy Howard' date='2020-11-17 17:32:31-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='fastai\_nbdev.py' new_name='fastai\_nbdev.py'>
 		<file_info nloc='875' complexity='1' token_count='3416'></file_info>
 		<modified_lines>
 			<added_lines>40,293</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fastai\callback\fp16.py' new_name='fastai\callback\fp16.py'>
 		<file_info nloc='129' complexity='50' token_count='1294'></file_info>
 		<modified_lines>
 			<added_lines>141,170</added_lines>
 			<deleted_lines>140,169</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fastai\data\core.py' new_name='fastai\data\core.py'>
 		<file_info nloc='314' complexity='115' token_count='3957'></file_info>
 		<modified_lines>
 			<added_lines>378</added_lines>
 			<deleted_lines>377</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fastai\torch_core.py' new_name='fastai\torch_core.py'>
 		<file_info nloc='556' complexity='237' token_count='5916'></file_info>
 		<method name='distrib_barrier' parameters=''>
 				<method_info nloc='3' complexity='3' token_count='27' nesting_level='0' start_line='639' end_line='641'></method_info>
 			<added_lines>640</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__torch_function__' parameters='self,func,types,args'>
 				<method_info nloc='4' complexity='2' token_count='58' nesting_level='1' start_line='316' end_line='321'></method_info>
 			<added_lines>317,318,319</added_lines>
 			<deleted_lines>317</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>7,8,9,10,357,358,359,360,361,362,363,364,365,366</added_lines>
 			<deleted_lines>7,8,9,10,628</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='fastai\vision\augment.py' new_name='fastai\vision\augment.py'>
 		<file_info nloc='723' complexity='205' token_count='10806'></file_info>
 		<method name='hsv' parameters='TensorImage,func'>
 				<method_info nloc='4' complexity='1' token_count='32' nesting_level='0' start_line='844' end_line='850'></method_info>
 			<added_lines>850</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,fs,kwargs'>
 				<method_info nloc='2' complexity='1' token_count='25' nesting_level='1' start_line='694' end_line='695'></method_info>
 			<added_lines>695</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='affine_grid' parameters='theta,size,align_corners'>
 				<method_info nloc='2' complexity='1' token_count='27' nesting_level='0' start_line='309' end_line='310'></method_info>
 			<added_lines>309,310</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_draw_mask' parameters='x,def_draw,draw,p,neutral,batch'>
 				<method_info nloc='9' complexity='4' token_count='129' nesting_level='0' start_line='446' end_line='454'></method_info>
 			<added_lines>451,454</added_lines>
 			<deleted_lines>448</deleted_lines>
 		</method>
 		<method name='lighting.__init__' parameters='self,fs,space_fn,kwargs'>
 				<method_info nloc='4' complexity='1' token_count='34' nesting_level='1' start_line='674' end_line='677'></method_info>
 			<added_lines>674</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='hsv.__init__' parameters='self,fs,kwargs'>
 				<method_info nloc='2' complexity='1' token_count='25' nesting_level='1' start_line='849' end_line='850'></method_info>
 			<added_lines>850</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>4,5,6,7,8,9,308,311,319,338,339,340,552,585,649,712,741,780,872</added_lines>
 			<deleted_lines>4,5,6,7,8,9,315,334,445,545,578,593,594,595,596,597,598,599,600,601,602,603,653,679,700,716,745,784,855,876</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='nbs\00_torch_core.ipynb' new_name='nbs\00_torch_core.ipynb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>1191,1192,1193,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,2256,2478,2563,2567,2568,2569,2570,2571,2572,2573,2723,2745,2783</added_lines>
 			<deleted_lines>1191,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,2168,2390,2475,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2668,2690,2728</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='nbs\03_data.core.ipynb' new_name='nbs\03_data.core.ipynb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>360,406,441,476,502,1921</added_lines>
 			<deleted_lines>360,406,441,476,502,1920</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='nbs\09_vision.augment.ipynb' new_name='nbs\09_vision.augment.ipynb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>217,349,544,568,702,733,908,940,1043,1076,1136,1244,1276,1309,1342,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1392,1411,1412,1413,1514,1693,1827,1830,1850,1879,1880,1881,1882,1884,2068,2075,2082,2089,2095,2106,2215,2227,2239,2251,2357,2369,2381,2393,2495,2507,2519,2531,2610,2661,2706,2718,2730,2742,2764,2765,2766,2767,2809,2856,2868,2880,2892,3002,3079,3091,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3198,3241,3276,3314,3356,3379,3380,3381,3382,3383,3384,3385,3386,3387,3392,3438,3480,3589,3625,3787,3804,3874,3909,4009,4086,4112,4137,4274,4300,4353,4397,4444</added_lines>
 			<deleted_lines>217,349,544,568,702,733,908,940,1043,1076,1136,1244,1276,1309,1342,1381,1400,1501,1680,1814,1817,1837,1866,1867,1868,1869,1871,1872,1873,2057,2064,2071,2078,2084,2085,2086,2087,2088,2099,2100,2209,2221,2233,2245,2351,2363,2375,2387,2489,2501,2513,2525,2604,2654,2700,2712,2724,2736,2758,2759,2800,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2866,2878,2890,2902,3011,3089,3101,3191,3234,3269,3306,3349,3372,3421,3464,3572,3609,3771,3788,3857,3893,3993,4070,4096,4121,4258,4284,4337,4381,4428</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='nbs\09b_vision.utils.ipynb' new_name='nbs\09b_vision.utils.ipynb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>20,127,128,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,329,330,331,332,333,334,335,336</added_lines>
 			<deleted_lines>46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,144</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='nbs\10_tutorial.pets.ipynb' new_name='nbs\10_tutorial.pets.ipynb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>153,272,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,833,860,1026,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1117,1146,1220,1279,1308,1418,1501,1578</added_lines>
 			<deleted_lines>153,272,770,797,824,990,1019,1045,1074,1148,1207,1236,1346,1429,1506</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='nbs\18_callback.fp16.ipynb' new_name='nbs\18_callback.fp16.ipynb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>419,433,696,697,702,703,708,709,757,758,763,764,769,770,806,832,833,838,839,844,845,891,892,897,898,903,904,1004,1005,1010,1011,1016,1017,1051,1088,1100,1114</added_lines>
 			<deleted_lines>419,433,696,697,702,703,708,709,757,758,763,764,769,770,805,832,833,838,839,844,845,891,892,897,898,903,904,1004,1005,1010,1011,1016,1017,1050</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='nbs\74_callback.cutmix.ipynb' new_name='nbs\74_callback.cutmix.ipynb'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>186,245,257,271,308,310</added_lines>
 			<deleted_lines>186</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
