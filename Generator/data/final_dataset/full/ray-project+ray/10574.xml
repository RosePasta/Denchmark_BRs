<bug_data>
<bug id='10574' author='raoul-khour-ts' open_date='2020-09-04T15:02:14Z' closed_time='2020-09-23T17:19:56Z'>
 	<summary>[Ray] Manual Cluster Setup (not bringing CPUs into available resources).</summary>
 	<description>
 [RAY CORE]
 When following &lt;denchmark-link:https://docs.ray.io/en/latest/cluster/index.html#manual-ray-cluster-setup&gt;https://docs.ray.io/en/latest/cluster/index.html#manual-ray-cluster-setup&lt;/denchmark-link&gt;
 
 on 0.8.7 Once I have connected the remote worker nodes I see the number of available CPUs go up. However on the current 0.9.0.dev CPUs stay at 0
 Ray version and other system information (Python version, TensorFlow version, OS):
 0.9.0.dev seems to currently prevent manual clusters
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 install 0.9.0.dev latest
 on main machine run: ray start --head --num-cpus=0
 on worker machine run: ray start --address=xxx --redis-password=xxx --num-cpus=24
 back on main machine run: 'python3 -c "import ray; ray.init(address='auto');print(ray.available_resources())"
 see no cpus in available resources
 in 0.8.7 and 0.8.6
 after following above I see 24cpus
 	</description>
 	<comments>
 		<comment id='1' author='raoul-khour-ts' date='2020-09-04T17:51:59Z'>
 		I will investigate and mark as P0 once I can reproduce it
 		</comment>
 		<comment id='2' author='raoul-khour-ts' date='2020-09-05T05:38:53Z'>
 		Was unable to reproduce this. What I tried:
 
 
 In EC2 spin up 2 nodes and ensure they're in the same VPC, subnet, security group, etc.
 
 
 Installed the latest nightly wheel on each machine.
 
 
 Ran
 
 
 &lt;denchmark-code&gt;ubuntu@ip~$ /home/ubuntu/.local/bin/ray start --head --num-cpus=0
 Local node IP: 172.31.37.161
 Available RAM
   Workers: 18.26 GiB
   Objects: 9.15 GiB
   
   To adjust these values, use
     ray.init(memory=&lt;bytes&gt;, object_store_memory=&lt;bytes&gt;)
 Dashboard URL: http://localhost:8265
 
 --------------------
 Ray runtime started.
 --------------------
 
 Next steps
   To connect to this Ray runtime from another node, run
     ray start --address='xxx.xxx.xxx.xxx:6379' --redis-password='5241590000000000'
   
   Alternatively, use the following Python code:
     import ray
     ray.init(address='auto', redis_password='5241590000000000')
   
   If connection fails, check your firewall settings other network configuration.
   
   To terminate the Ray runtime, run
     ray stop
 &lt;/denchmark-code&gt;
 
 
 On the other node:
 
 &lt;denchmark-code&gt;ubuntu@ip:~$ .local/bin/ray start --address='xxx.xxx.xxx.xxx:6379' --redis-password='5241590000000000'Local node IP: 172.31.42.67
 Available RAM
   Workers: 21.34 GiB
   Objects: 9.15 GiB
   
   To adjust these values, use
     ray.init(memory=&lt;bytes&gt;, object_store_memory=&lt;bytes&gt;)
 
 --------------------
 Ray runtime started.
 --------------------
 
 To terminate the Ray runtime, run
   ray stop
 &lt;/denchmark-code&gt;
 
 
 Check the resources from the head node:
 
 &lt;denchmark-code&gt;ubuntu@ip:~$ python3
 Python 3.6.9 (default, Jul 17 2020, 12:50:27) 
 [GCC 8.4.0] on linux
 Type "help", "copyright", "credits" or "license" for more information.
 &gt;&gt;&gt; import ray
 &gt;&gt;&gt; ray.init(address="auto")
 2020-09-05 05:25:03,902	INFO worker.py:633 -- Connecting to existing Ray cluster at address: xxx.xxx.xxx.xxx:6379
 {'node_ip_address': 'xxx.xxx.xxx.xxx', 'raylet_ip_address': 'xxx.xxx.xxx.xxx', 'redis_address': 'xxx.xxx.xxx.xxx:6379', 'object_store_address': '/tmp/ray/session_2020-09-05_05-24-24_528207_10923/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2020-09-05_05-24-24_528207_10923/sockets/raylet', 'webui_url': 'localhost:8265', 'session_dir': '/tmp/ray/session_2020-09-05_05-24-24_528207_10923', 'metrics_export_port': 62757}
 &gt;&gt;&gt; ray.available_resources()
 {'memory': 811.0, 'node:xxx.xxx.xxx.xxx': 1.0, 'object_store_memory': 258.0, 'node:xxx.xxx.xxx.xxx': 1.0, 'CPU': 8.0}
 &gt;&gt;&gt; ray.cluster_resources()
 {'CPU': 8.0, 'node:xxx.xxx.xxx.xxx': 1.0, 'memory': 811.0, 'object_store_memory': 258.0, 'node:xxx.xxx.xxx.xxx': 1.0} 
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='3' author='raoul-khour-ts' date='2020-09-05T22:35:00Z'>
 		
 back on main machine run: 'python3 -c "import ray; print(ray.available_resources())"
 
 &lt;denchmark-link:https://github.com/raoul-khour-ts&gt;@raoul-khour-ts&lt;/denchmark-link&gt;
  Is that actually enough to reproduce the issue? Don't you need to call ? Note that if you call  then it won't attach to the cluster, so you'll just see one machine's resources.
 		</comment>
 		<comment id='4' author='raoul-khour-ts' date='2020-09-07T01:07:40Z'>
 		Note that once I do call ray.init(address="auto") I keep getting this in my logs:
 (pid=raylet, ip=xx) service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 127.0.0.1:46515
 		</comment>
 		<comment id='5' author='raoul-khour-ts' date='2020-09-07T01:23:44Z'>
 		&lt;denchmark-link:https://github.com/raoul-khour-ts&gt;@raoul-khour-ts&lt;/denchmark-link&gt;
  can you try the steps I used and verify that works?
 		</comment>
 		<comment id='6' author='raoul-khour-ts' date='2020-09-07T01:30:26Z'>
 		I did exactly that but in our environment (not EC2 but a local farm of machines)
 on 0.8.7 I can recreate your steps all fine and no logs.
 on 0.9.0.dev no cpu's show up in the cluster and the above error message keeps getting logged.
 		</comment>
 		<comment id='7' author='raoul-khour-ts' date='2020-09-07T01:35:43Z'>
 		The remote machine (and local) shows up on my ray dashboard... I just for some reason don't have access to its cpus...
 		</comment>
 		<comment id='8' author='raoul-khour-ts' date='2020-09-07T01:46:23Z'>
 		Could you do a fresh run of this, then share /tmp/ray/session_latest/logs? Also what's your OS, and python version?
 		</comment>
 		<comment id='9' author='raoul-khour-ts' date='2020-09-07T01:53:51Z'>
 		Unfortunately I can not share all my logs. Is there a particular one of the files you are interested in?
 		</comment>
 		<comment id='10' author='raoul-khour-ts' date='2020-09-07T01:54:48Z'>
 		One notable one is the gcs_server.err and out giving these lines:
 network_util.cc:62] Failed to find other valid local IP. Using 127.0.0.1, not possible to go distributed!
 		</comment>
 		<comment id='11' author='raoul-khour-ts' date='2020-09-07T01:55:39Z'>
 		Is there a change between how this occurs between 0.8.7 and 9.0.0.dev?
 		</comment>
 		<comment id='12' author='raoul-khour-ts' date='2020-09-07T01:56:26Z'>
 		I am running python 3.6.10 on a linux machine.
 		</comment>
 		<comment id='13' author='raoul-khour-ts' date='2020-09-07T02:15:40Z'>
 		Just checked that downgrading to 0.8.7 again does not show that gcs_server.err.
 Interestingly I did notice that when I start python and run ray.init(address='auto') on 0.8.7 I get:
 
 
 
 import ray
 ray.init(address='auto')
 WARNING: Logging before InitGoogleLogging() is written to STDERR
 global_state_accessor.cc:25] Redis server address = xx:6379, is test flag = 0
 redis_client.cc:146] RedisClient connected.
 redis_gcs_client.cc:89] RedisGcsClient Connected.
 service_based_gcs_client.cc:193] Reconnected to GCS server: xx:43483
 service_based_accessor.cc:92] Reestablishing subscription for job info.
 ...
 Reestablishing subscription for worker failures.
 ServiceBasedGcsClient Connected.
 ray.cluster_resources()
 {'object_store_memory': 1786.0, 'memory': 5849.0, 'node:xxx': 1.0, 'node:xx': 1.0, 'CPU': 24.0}
 
 
 
 I dont seem to have that in 0.9.0.dev
 		</comment>
 		<comment id='14' author='raoul-khour-ts' date='2020-09-07T02:40:15Z'>
 		
 
 back on main machine run: 'python3 -c "import ray; print(ray.available_resources())"
 
 @raoul-khour-ts Is that actually enough to reproduce the issue? Don't you need to call ray.init(address=...)? Note that if you call ray.init() then it won't attach to the cluster, so you'll just see one machine's resources.
 
 Hey &lt;denchmark-link:https://github.com/robertnishihara&gt;@robertnishihara&lt;/denchmark-link&gt;
 , yeah sorry I forgot to add that to my reproduce guide (but yes I did call ray.init(address='auto')). Updated reproduce guide now.
 		</comment>
 		<comment id='15' author='raoul-khour-ts' date='2020-09-07T02:45:40Z'>
 		another observance:
 if I run the ray start --address='xxx.xxx.xxx.xxx:6379' --redis-password='5241590000000000' --num-cpus=20 on the head then I see 20 cpus in the cluster...
 		</comment>
 		<comment id='16' author='raoul-khour-ts' date='2020-09-07T16:22:09Z'>
 		Are there any errors/stack traces in raylet.err or and of the worker logs?
 		</comment>
 		<comment id='17' author='raoul-khour-ts' date='2020-09-07T21:03:10Z'>
 		raylet.err is empty
 raylet.out looks normal
 Not sure where the worker logs are. are those the python-core-driver-xxx.log?
 if so then nothing different from the 0.8.7 runs.
 		</comment>
 		<comment id='18' author='raoul-khour-ts' date='2020-09-09T02:20:24Z'>
 		There were some changes in finding IP addresses from 0.8.7 =&gt; 0.9.0.dev0
 network_util.cc:62] Failed to find other valid local IP. Using 127.0.0.1, not possible to go distributed!
 I believe this log is something we added lately. What OS are you currently using?
 		</comment>
 		<comment id='19' author='raoul-khour-ts' date='2020-09-09T02:23:40Z'>
 		&lt;denchmark-link:https://github.com/ray-project/ray/pull/10004&gt;#10004&lt;/denchmark-link&gt;
 
 One of possibilities is that your machines are not using any of network interface listed in the PR description. Can you elaborate more about your cluster environment?
 		</comment>
 		<comment id='20' author='raoul-khour-ts' date='2020-09-09T02:27:03Z'>
 		The workaround is to manually set the Redis key so that raylets can find the IP address of GCS. look at this link &lt;denchmark-link:https://github.com/ray-project/ray/issues/8648#issuecomment-664233815&gt;#8648 (comment)&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='21' author='raoul-khour-ts' date='2020-09-09T02:43:42Z'>
 		I'm using Debian 9 and python 3.6.10
 
 The workaround is to manually set the Redis key so that raylets can find the IP address of GCS. look at this link #8648 (comment)
 
 I would be happy to test if this would fix my issue but. I actually have no idea how to set the GcsServerAddress to 10.251.231.121:40531 in redis manually,
 Thank you &lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
  in advance!
 		</comment>
 		<comment id='22' author='raoul-khour-ts' date='2020-09-09T03:02:24Z'>
 		In this case the gcs server address will be  [your head node private ip address]:[gcs_server port], and you can set this by connecting to the Redis in a head node.
 		</comment>
 		<comment id='23' author='raoul-khour-ts' date='2020-09-09T03:17:15Z'>
 		so running python3 -c "import redis; r = redis.Redis(host=xxx, port=yyy, db=0); r.set('GcsServerAddress', 'xxx:zzz')"
 Ill try this tomorrow. Thank you &lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
  Ill let you know how that goes.
 		</comment>
 		<comment id='24' author='raoul-khour-ts' date='2020-09-09T03:26:29Z'>
 		Yeah I think that should work. Don’t forget to specify gcs-server port with “ray start —head —gcs-port=“ so that you don’t need to worry about finding where gcs server has been bound to.
 		</comment>
 		<comment id='25' author='raoul-khour-ts' date='2020-09-09T03:27:29Z'>
 		Btw, it is interesting the new version has some addresses it resolve while 0.8.7 could. We should probably find a solution for this.
 		</comment>
 		<comment id='26' author='raoul-khour-ts' date='2020-09-09T20:00:45Z'>
 		&lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
 
 Sorry about the delay here but it worked!!!:
 ray start --head --gcs-server-port=ddd --cpus=0
 import redis
 r = redis.Redis(host=xxx, port=yyy, password=zzz, db=0)
 r.get('GcsServerAddress')
 &gt;&gt;&gt; 127.0.0.1:ddd
 r.set('GcsServerAddress', xxx:ddd)
 ssh to other_machine
 ray start --address=xxx --redis-password=zzz --num-cpus=24
 back on main machine:
 'python3 -c "import ray; ray.init(address='auto');print(ray.available_resources())"
 
 
 
 {..., cpus:24}
 
 
 
 Now the question is how do we make this work without having to do all this...
 		</comment>
 		<comment id='27' author='raoul-khour-ts' date='2020-09-09T21:07:09Z'>
 		The issue here is your manual cluster’s network interface is probably not typical, and we have trouble resolving addresses. I think I can create a patch that allows you to specify GCS address. What do you think about this solution?
 		</comment>
 		<comment id='28' author='raoul-khour-ts' date='2020-09-09T21:09:52Z'>
 		&lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
  honestly the gcs address is always going to be the --head ip_address for me at least. Shouldn't that be easy to resolve?
 The port seems to be resolving fine...
 		</comment>
 		<comment id='29' author='raoul-khour-ts' date='2020-09-09T21:12:35Z'>
 		Ah, I see. So, the issue is gcs server address is not matching head ip address you specified right?
 		</comment>
 		<comment id='30' author='raoul-khour-ts' date='2020-09-09T21:33:41Z'>
 		Well the gcs server address seems to for some reason fail to connect to head_ip_address then fall back to localhost. However that prevents remote machines from connecting.
 		</comment>
 		<comment id='31' author='raoul-khour-ts' date='2020-09-09T21:35:33Z'>
 		but If i go back into redis and manually set it to head_ip_address everything is fine...
 		</comment>
 		<comment id='32' author='raoul-khour-ts' date='2020-09-17T13:23:07Z'>
 		&lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
  and I have isolated the issue to being an issue with private networks. My machine can not ping out to 8.8.8.8 which makes the GCS configuration fail.
 		</comment>
 		<comment id='33' author='raoul-khour-ts' date='2020-09-19T08:54:27Z'>
 		Note: I will make a PR to use Python code to resolve addresses of GCS servers
 		</comment>
 		<comment id='34' author='raoul-khour-ts' date='2020-09-23T17:19:56Z'>
 		Was able to confirm that &lt;denchmark-link:https://github.com/ray-project/ray/pull/10946&gt;#10946&lt;/denchmark-link&gt;
  fixed the issue.
 Thank you &lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
 . This should make it out to the 1.1.0 release hopefully sometime in November?
 		</comment>
 		<comment id='35' author='raoul-khour-ts' date='2020-09-23T17:37:52Z'>
 		&lt;denchmark-link:https://github.com/raoul-khour-ts&gt;@raoul-khour-ts&lt;/denchmark-link&gt;
  Yes! We have a monthly release cycle, and the 1.0 target date is the end of September, so the next version will be released around Nov! There's a possibility to have a shorter release cycle (though I cannot guarantee). The next version might not be 1.1, but it will be 1.0.1. We might have a new second digit release every quarter.
 		</comment>
 		<comment id='36' author='raoul-khour-ts' date='2020-12-14T19:12:01Z'>
 		&lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
  I am starting to see issues like this again on 1.1.0.dev. Its a little stranger though that it seems like things end up dieing but with similar errors.
 Have y'all moved 1.1.0.dev to distributed or spawning gcs or something? (could be a separate issue)
 		</comment>
 		<comment id='37' author='raoul-khour-ts' date='2020-12-14T19:12:31Z'>
 		either way it seems like the gcs location is being lost... and this is only happening in clusters.
 		</comment>
 		<comment id='38' author='raoul-khour-ts' date='2020-12-14T19:17:19Z'>
 		Are there logs in gcs_server.err?  (/tmp/ray/session_latest/logs)
 		</comment>
 	</comments>
 </bug>
<commit id='390107b6cbe1550defdcd86d4dbf945cadd43372' author='SangBin Cho' date='2020-09-23 01:52:26-07:00'>
 	<dmm_unit complexity='1.0' interfacing='0.8333333333333334' size='0.5'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\ray\node.py' new_name='python\ray\node.py'>
 		<file_info nloc='688' complexity='106' token_count='4251'></file_info>
 		<method name='start_gcs_server' parameters='self'>
 				<method_info nloc='18' complexity='1' token_count='106' nesting_level='1' start_line='670' end_line='689'></method_info>
 			<added_lines>683,684</added_lines>
 			<deleted_lines>683</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\services.py' new_name='python\ray\services.py'>
 		<file_info nloc='1049' complexity='72' token_count='5440'></file_info>
 		<method name='start_gcs_server' parameters='redis_address,stdout_file,stderr_file,redis_password,config,fate_share,gcs_server_port,metrics_agent_port'>
 				<method_info nloc='8' complexity='1' token_count='33' nesting_level='0' start_line='1093' end_line='1100'></method_info>
 			<added_lines>1100</added_lines>
 			<deleted_lines>1100</deleted_lines>
 		</method>
 		<method name='start_gcs_server' parameters='redis_address,stdout_file,stderr_file,redis_password,config,fate_share,gcs_server_port,metrics_agent_port,node_ip_address'>
 				<method_info nloc='9' complexity='1' token_count='37' nesting_level='0' start_line='1093' end_line='1101'></method_info>
 			<added_lines>1100,1101</added_lines>
 			<deleted_lines>1100</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1114,1131</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ray\gcs\gcs_server\gcs_server.cc' new_name='src\ray\gcs\gcs_server\gcs_server.cc'>
 		<file_info nloc='199' complexity='20' token_count='1527'></file_info>
 		<method name='ray::gcs::GcsServer::StoreGcsServerAddressInRedis' parameters=''>
 				<method_info nloc='13' complexity='2' token_count='105' nesting_level='2' start_line='254' end_line='267'></method_info>
 			<added_lines>255,256,257,258,259,260,261</added_lines>
 			<deleted_lines>255,256,257,258,259</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ray\gcs\gcs_server\gcs_server.h' new_name='src\ray\gcs\gcs_server\gcs_server.h'>
 		<file_info nloc='78' complexity='3' token_count='483'></file_info>
 		<modified_lines>
 			<added_lines>37</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ray\gcs\gcs_server\gcs_server_main.cc' new_name='src\ray\gcs\gcs_server\gcs_server_main.cc'>
 		<file_info nloc='67' complexity='3' token_count='534'></file_info>
 		<method name='main' parameters='argc'>
 				<method_info nloc='53' complexity='3' token_count='446' nesting_level='0' start_line='32' end_line='104'></method_info>
 			<added_lines>46,80</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>30</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
