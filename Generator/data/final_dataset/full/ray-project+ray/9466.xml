<bug_data>
<bug id='9466' author='kisuke95' open_date='2020-07-14T06:52:17Z' closed_time='2020-07-27T19:34:06Z'>
 	<summary>Problems about new scheduler</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 Ray version and other system information (Python version, TensorFlow version, OS):
 There are several problems about new scheduler used in raylet.
 
  wrong allocation result for soft resource constraint in ClusterResourceScheduler::AllocateResourceInstances #9467
 
 In the following code (just copy from master), in the first for statement, we do this (*allocation)[i] = 1.; available[i] = 0;, but int the second for statement, we may clear it with (*allocation)[i] = available[i]; (because available[i] maybe set 0 in the first for statement)
 if (remaining_demand &gt;= 1.) {
   for (size_t i = 0; i &lt; available.size(); i++) {
     if (available[i] == 1.) {
       // Allocate a full unit-capacity instance.
       (*allocation)[i] = 1.;
       available[i] = 0;
       remaining_demand -= 1.;
     }
     if (remaining_demand &lt; 1.) {
       break;
     }
   }
 }
 
 if (soft) {
   // Just get as many resources as available.
   for (size_t i = 0; i &lt; available.size(); i++) {
     if (available[i] &gt;= remaining_demand) {
       available[i] -= remaining_demand;
       (*allocation)[i] = remaining_demand;
       return true;
     } else {
       (*allocation)[i] = available[i];
       remaining_demand -= available[i];
       available[i] = 0;
     }
   }
   return true;
 }
 
  we should call new_resource_scheduler_-&gt;RemoveNode(...) in NodeManager::NodeRemoved to remove the resource information of the removed node. If not, the new scheduler may make a wrong schedule decision. #9467
 
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
 If we cannot run your script, we cannot fix your issue.
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='kisuke95' date='2020-07-14T22:37:07Z'>
 		We currently don't pass most python unit tests for Ray. I'm going to work on passing those unit tests first, so there's no need to track bugs which are already covered by unit tests. I think it would be most helpful if we could find bugs which are not already covered by the existing test cases.
 		</comment>
 		<comment id='2' author='kisuke95' date='2020-07-15T01:40:02Z'>
 		&lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;
  I think we can take a look at c++ unit tests.
 		</comment>
 	</comments>
 </bug>
<commit id='4e2e3bd348a6ca10dfdda7f1955a3daee3ac75c3' author='kisuke95' date='2020-07-20 13:09:53-07:00'>
 	<dmm_unit complexity='0.5' interfacing='1.0' size='0.5'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\ray\raylet\node_manager.cc' new_name='src\ray\raylet\node_manager.cc'>
 		<file_info nloc='2827' complexity='508' token_count='21899'></file_info>
 		<method name='ray::raylet::NodeManager::NodeRemoved' parameters='node_info'>
 				<method_info nloc='38' complexity='8' token_count='251' nesting_level='2' start_line='653' end_line='716'></method_info>
 			<added_lines>674,675,676,677,678,679,680,681,682</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ray\raylet\scheduling\cluster_resource_scheduler.cc' new_name='src\ray\raylet\scheduling\cluster_resource_scheduler.cc'>
 		<file_info nloc='981' complexity='241' token_count='7281'></file_info>
 		<method name='ClusterResourceScheduler::AllocateResourceInstances' parameters='demand,soft,available,allocation'>
 				<method_info nloc='68' complexity='18' token_count='414' nesting_level='0' start_line='886' end_line='975'></method_info>
 			<added_lines>941</added_lines>
 			<deleted_lines>932</deleted_lines>
 		</method>
 		<method name='ClusterResourceScheduler::RemoveNode' parameters='node_id_string'>
 				<method_info nloc='7' complexity='2' token_count='41' nesting_level='0' start_line='497' end_line='504'></method_info>
 			<added_lines>497,498,499,500,501,502,503,504</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>505</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ray\raylet\scheduling\cluster_resource_scheduler.h' new_name='src\ray\raylet\scheduling\cluster_resource_scheduler.h'>
 		<file_info nloc='177' complexity='14' token_count='1285'></file_info>
 		<modified_lines>
 			<added_lines>253</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ray\raylet\scheduling\scheduling_test.cc' new_name='src\ray\raylet\scheduling\scheduling_test.cc'>
 		<file_info nloc='784' complexity='53' token_count='6459'></file_info>
 		<modified_lines>
 			<added_lines>945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
