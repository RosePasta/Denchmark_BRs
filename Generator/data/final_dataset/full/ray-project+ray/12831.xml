<bug_data>
<bug id='12831' author='sven1977' open_date='2020-12-13T10:39:32Z' closed_time='2020-12-13T15:15:54Z'>
 	<summary>[RLlib] AttributeError: 'NoneType' object has no attribute 'id' when using custom Atari env.</summary>
 	<description>
 Chris reported the following problem on the discuss.ray.io forum:
 &lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;
 
 Hi,
 I’m just getting started with RLlib and becoming more and more desperate using a modified Atari environment. I want to utilize the gym.ObserverationWrapper for domain adaptation, hence manipulating the observation.
 It works like a charm for Pong and Breakout with observation type == ‘ram’, thus not the actual images.
 As soon as I change the observation type to == ‘image’, I obtain the following error:
 &lt;denchmark-code&gt;  File "/home/chris/.pyenv/versions/test_env/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 404, in __init__
     self.env: EnvType = wrap(self.env)
   File "/home/chris/.pyenv/versions/test_env/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 391, in wrap
     framestack=model_config.get("framestack"))
   File "/home/chris/.pyenv/versions/test_env/lib/python3.6/site-packages/ray/rllib/env/atari_wrappers.py", line 281, in wrap_deepmind
     if "NoFrameskip" in env.spec.id:
 AttributeError: 'NoneType' object has no attribute 'id'
 &lt;/denchmark-code&gt;
 
 I have simplified the code to the following and I am still obtaining the same error:
 &lt;denchmark-code&gt;import ray
 from ray import tune
 import ray.rllib.agents.impala as impala
 from gym.envs.atari import AtariEnv
 
 
 class AugmentedPong(AtariEnv):
     def __init__(self, config):
         super(AugmentedPong, self).__init__(game='pong', obs_type='image')
 
 
 def env_creator(env_config):
     return AtariEnv(game='pong', obs_type='image', frameskip=1)
 
 
 config = impala.DEFAULT_CONFIG.copy()
 
 ray.init()
 trainer = impala.ImpalaTrainer(config=config, env=AugmentedPong)
 &lt;/denchmark-code&gt;
 
 Ray version and other system information (Python version, TensorFlow version, OS):
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 Please provide a short code snippet (less than 50 lines if possible) that can be copy-pasted to reproduce the issue. The snippet should have no external library dependencies (i.e., use fake or mock data / environments):
 If the code snippet cannot be run by itself, the issue will be closed with "needs-repro-script".
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='sven1977' date='2020-12-13T10:41:55Z'>
 		PR that fixes the issue:
 &lt;denchmark-link:https://github.com/ray-project/ray/pull/12832&gt;#12832&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='3c808835a59f461ccebd8f5ea02c2d491b59b5e0' author='Sven Mika' date='2020-12-13 16:15:54+01:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='rllib\env\atari_wrappers.py' new_name='rllib\env\atari_wrappers.py'>
 		<file_info nloc='200' complexity='59' token_count='1641'></file_info>
 		<method name='wrap_deepmind' parameters='env,dim,framestack'>
 				<method_info nloc='12' complexity='5' token_count='100' nesting_level='0' start_line='270' end_line='291'></method_info>
 			<added_lines>281</added_lines>
 			<deleted_lines>281</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
