<bug_data>
<bug id='4593' author='robertnishihara' open_date='2019-04-10T05:33:42Z' closed_time='2019-05-05T23:06:36Z'>
 	<summary>The /tmp/ray directory belongs to the first person to start Ray, which leads to permission errors.</summary>
 	<description>
 To see the issue, do the following:
 
 rm -r /tmp/ray
 python -c "import ray; ray.init()"
 ls -l /tmp/
 
 You will see a line like
 &lt;denchmark-code&gt;drwxr-xr-x  3 rkn  wheel    96B Apr  9 22:31 ray/
 &lt;/denchmark-code&gt;
 
 which shows that the temp directory /tmp/ray created by Ray cannot be written by other users. If another user on the same machine tries to do ray.init(), they may run into errors. On the other hand, if you do
 ls -l /tmp/ray/
 you will see a line like
 &lt;denchmark-code&gt;drwxrwxrwx  4 rkn  wheel   128B Apr  9 22:31 session_2019-04-09_22-31-10_72937/
 &lt;/denchmark-code&gt;
 
 which shows that the session directory inside of /tmp/ray/ is writable by everyone.
 	</description>
 	<comments>
 		<comment id='1' author='robertnishihara' date='2019-04-23T19:02:36Z'>
 		I also see this problem when starting ray on non-head nodes in a cluster with a shared /tmp directory.
 The default for a node seems to be to have /tmp/ray as the temp directory and if I specify a temp dir for a non-head node, then ray raises an error that "When connecting to an existing cluster, temp_dir must not be provided."
 		</comment>
 		<comment id='2' author='robertnishihara' date='2019-04-27T04:24:04Z'>
 		&lt;denchmark-link:https://github.com/robertnishihara&gt;@robertnishihara&lt;/denchmark-link&gt;
  I've been continuing to see this problem a lot with classrooms where students are sharing nodes. The students are having to set temp_dir in ray.init() to avoid this issue. Maybe temp could be automatically set to something like  for user-specific tmp directories?
 		</comment>
 		<comment id='3' author='robertnishihara' date='2019-04-27T23:31:45Z'>
 		cc &lt;denchmark-link:https://github.com/suquark&gt;@suquark&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='4' author='robertnishihara' date='2019-04-29T14:08:27Z'>
 		I think the intent is to have /tmp/ray writeable by everyone and its sub-directories with user-specific permissions. Is that right?
 However, that still wouldn't solve the problem of non-head nodes not being allowed to have their own temp directories. Commenting out the following from worker.py should fix that:
 &lt;denchmark-code&gt;        if temp_dir is not None:
             raise Exception("When connecting to an existing cluster, "
                             "temp_dir must not be provided.")
 
 &lt;/denchmark-code&gt;
 
 Should that be a separate bug?
 		</comment>
 		<comment id='5' author='robertnishihara' date='2019-04-29T17:39:09Z'>
 		This is tricky in that tmp has to accommodate both shared and non shared systems. Could os.stat be run to check the accessibility of tmp and if it doesn't have permission, it creates a user tmp folder for stricter systems that will block ray.init otherwise?
 		</comment>
 		<comment id='6' author='robertnishihara' date='2019-04-29T18:18:36Z'>
 		&lt;denchmark-link:https://github.com/gndctrl2mjrtm&gt;@gndctrl2mjrtm&lt;/denchmark-link&gt;
 , do you anticipate any issues with making  as writable by everyone (but then potentially making its subfolders specific to whichever user created them)?
 If that doesn't work, something like what you're suggesting could work.
 &lt;denchmark-link:https://github.com/RaghuSpaceRajan&gt;@RaghuSpaceRajan&lt;/denchmark-link&gt;
  that potentially looks like a different bug.
 		</comment>
 		<comment id='7' author='robertnishihara' date='2019-04-29T18:54:54Z'>
 		&lt;denchmark-link:https://github.com/robertnishihara&gt;@robertnishihara&lt;/denchmark-link&gt;
  That could work from my understanding of how Ray initializes /tmp directories.
 However, the issue is that this has to be done across every node of the system, which makes me realize that in the situation where a user goes to a compute node and exits that node, all the tmp data is lost since it's stored on the compute node and deleted when the user leaves. While it could be argued that the user should stay on that node, this doesn't work as well on larger systems with many users requesting resources and it also means that the developer has to be aware of this.
 Also, this might solve it for this particular system, but doesn't mean that other systems will not also have this whenever they have shared nodes unless they are also aware of this.
 Why can't /ray be stored in the user's ~/tmp/ray instead of /tmp/ray? That would solve this additional problem as well mentioned above.
 		</comment>
 		<comment id='8' author='robertnishihara' date='2019-04-29T20:27:43Z'>
 		&lt;denchmark-link:https://github.com/gndctrl2mjrtm&gt;@gndctrl2mjrtm&lt;/denchmark-link&gt;
  one setting where  makes more sense is the multi-tenant setting where a single Ray cluster is shared between many users. In that case, it's more natural for users to look in  instead of in the home directory of whichever other user started the Ray cluster.
 		</comment>
 		<comment id='9' author='robertnishihara' date='2019-04-29T21:00:46Z'>
 		&lt;denchmark-link:https://github.com/robertnishihara&gt;@robertnishihara&lt;/denchmark-link&gt;
  What about the case such as the one we have where it's a very large number of users and shared data violates data privacy laws, so there can't be a single Ray cluster? Does the object store have the ability to distinguish whether, for instance, a user has permission to get the value back from a certain object id? Regardless of the technical feasibility of getting another correct object id, the legality might prevent me from making such a global Ray cluster.
 Not to mention having a global /tmp/ray folder where all log files are then stored, but I'm assuming that the correct permissions are automatically set so that only that user can read the logs of their own workers?
 		</comment>
 		<comment id='10' author='robertnishihara' date='2019-05-04T18:15:09Z'>
 		This issue should be fixed by &lt;denchmark-link:https://github.com/ray-project/ray/pull/4605&gt;#4605&lt;/denchmark-link&gt;
  (once it is merged).
 &lt;denchmark-link:https://github.com/gndctrl2mjrtm&gt;@gndctrl2mjrtm&lt;/denchmark-link&gt;
  Currently the object store doesn't check any kind of permissions or do any authentication. Any process running on the same machine can connect to it. To make work really well in the multi-tenant setting with no sharing of information between drivers will take a lot more work. On the other hand, in this case, it might be easier to just start one Ray cluster per user.
 		</comment>
 		<comment id='11' author='robertnishihara' date='2019-05-05T23:06:36Z'>
 		Fixed by &lt;denchmark-link:https://github.com/ray-project/ray/pull/4605&gt;#4605&lt;/denchmark-link&gt;
 .
 		</comment>
 	</comments>
 </bug>
<commit id='bd00735fe877c24b99893651f90d3b43d87578c2' author='Si-Yuan' date='2019-05-05 16:06:15-07:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='doc\source\tempfile.rst' new_name='doc\source\tempfile.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>7,8,10,12,13,14,15,17,18,19,20,22,23,24,25,26,27,28,29,38,55,56,57,58,59</added_lines>
 			<deleted_lines>7,8,10,12,13,14,16,17,18,28,29,30,31,48,49,50,51,52,61</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\node.py' new_name='python\ray\node.py'>
 		<file_info nloc='469' complexity='72' token_count='2901'></file_info>
 		<method name='address_info' parameters='self'>
 				<method_info nloc='9' complexity='1' token_count='45' nesting_level='1' start_line='222' end_line='231'></method_info>
 			<added_lines>230</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_init_temp' parameters='self'>
 				<method_info nloc='14' complexity='2' token_count='128' nesting_level='1' start_line='139' end_line='157'></method_info>
 			<added_lines>144,145,146,147,156</added_lines>
 			<deleted_lines>139,143,144,145,146,147,148,149,151,153,154,156,157</deleted_lines>
 		</method>
 		<method name='get_session_dir_path' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='1' start_line='242' end_line='244'></method_info>
 			<added_lines>242,243,244</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_init_temp' parameters='self,redis_client'>
 				<method_info nloc='17' complexity='3' token_count='162' nesting_level='1' start_line='156' end_line='180'></method_info>
 			<added_lines>156,160,161,162,163,164,165,167,168,169,170,171,172,173,174,176,177,179,180</added_lines>
 			<deleted_lines>156,157</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>65,82,92,93,94,95,96,97,98,99,100,101,102,103,104,245</added_lines>
 			<deleted_lines>90,122</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tests\test_tempfile.py' new_name='python\ray\tests\test_tempfile.py'>
 		<file_info nloc='127' complexity='15' token_count='795'></file_info>
 		<method name='test_session_dir_uniqueness' parameters=''>
 				<method_info nloc='7' complexity='2' token_count='49' nesting_level='0' start_line='147' end_line='153'></method_info>
 			<added_lines>147,148,149,150,151,152,153</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_raylet_tempfiles' parameters=''>
 				<method_info nloc='32' complexity='3' token_count='266' nesting_level='0' start_line='101' end_line='136'></method_info>
 			<added_lines>104,119</added_lines>
 			<deleted_lines>113</deleted_lines>
 		</method>
 		<method name='test_tempdir_privilege' parameters=''>
 				<method_info nloc='6' complexity='1' token_count='47' nesting_level='0' start_line='139' end_line='144'></method_info>
 			<added_lines>139,140,141,142,143,144</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_tempdir_commandline' parameters=''>
 				<method_info nloc='8' complexity='1' token_count='59' nesting_level='0' start_line='51' end_line='58'></method_info>
 			<added_lines>51,52,53,54,55,56,57,58</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_tempdir' parameters=''>
 				<method_info nloc='8' complexity='1' token_count='60' nesting_level='0' start_line='41' end_line='48'></method_info>
 			<added_lines>42,46</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_raylet_socket_name' parameters=''>
 				<method_info nloc='18' complexity='3' token_count='82' nesting_level='0' start_line='61' end_line='78'></method_info>
 			<added_lines>68,77</added_lines>
 			<deleted_lines>62,71</deleted_lines>
 		</method>
 		<method name='test_temp_plasma_store_socket' parameters=''>
 				<method_info nloc='18' complexity='3' token_count='82' nesting_level='0' start_line='81' end_line='98'></method_info>
 			<added_lines>88,97</added_lines>
 			<deleted_lines>82,91,98</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>59,60,137,138,145,146</added_lines>
 			<deleted_lines>12,13,14,15,16,17</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\utils.py' new_name='python\ray\utils.py'>
 		<file_info nloc='254' complexity='75' token_count='1539'></file_info>
 		<method name='try_to_create_directory' parameters='directory_path'>
 				<method_info nloc='19' complexity='6' token_count='105' nesting_level='0' start_line='503' end_line='533'></method_info>
 			<added_lines>503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,523,533</added_lines>
 			<deleted_lines>503,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533</deleted_lines>
 		</method>
 		<method name='try_make_directory_shared' parameters='directory_path'>
 				<method_info nloc='8' complexity='3' token_count='39' nesting_level='0' start_line='503' end_line='515'></method_info>
 			<added_lines>503,504,505,506,507,508,509,510,511,512,513,514,515</added_lines>
 			<deleted_lines>503</deleted_lines>
 		</method>
 		<method name='try_to_create_directory' parameters='directory_path,warn_if_exist'>
 				<method_info nloc='14' complexity='5' token_count='82' nesting_level='0' start_line='518' end_line='540'></method_info>
 			<added_lines>518,523,533,534,535,536,537,538,539,540</added_lines>
 			<deleted_lines>518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\worker.py' new_name='python\ray\worker.py'>
 		<file_info nloc='1378' complexity='201' token_count='7684'></file_info>
 		<method name='connect' parameters='node,mode,log_to_driver,worker,driver_id'>
 				<method_info nloc='5' complexity='1' token_count='21' nesting_level='0' start_line='1693' end_line='1697'></method_info>
 			<added_lines>1697</added_lines>
 			<deleted_lines>1697</deleted_lines>
 		</method>
 		<method name='connect' parameters='node,mode,log_to_driver,worker,driver_id,load_code_from_local'>
 				<method_info nloc='6' complexity='1' token_count='25' nesting_level='0' start_line='1693' end_line='1698'></method_info>
 			<added_lines>1697</added_lines>
 			<deleted_lines>1697,1698</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
