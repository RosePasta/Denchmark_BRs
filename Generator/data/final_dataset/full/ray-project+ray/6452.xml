<bug_data>
<bug id='6452' author='zplizzi' open_date='2019-12-12T08:05:59Z' closed_time='2019-12-12T18:24:18Z'>
 	<summary>[rllib] APEX DQN performance regression?</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 It says in the &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/pong-apex.yaml&gt;pong_apex.yaml&lt;/denchmark-link&gt;
  tuned config:
 &lt;denchmark-code&gt;# This can be expected to reach 20.8 reward within an hour when using a V100 GPU
 # (e.g. p3.2xl instance on AWS, and m4.4xl workers). It also can reach ~21 reward
 # within an hour with fewer workers (e.g. 4-8) but less reliably.
 &lt;/denchmark-code&gt;
 
 I trained this example on an AWS p3.2xlarge instance (4 workers, 8 vec_env per worker) but could not replicate that statement. It took 4.5 hours of training and 10M timesteps sampled and trained on to reach a mean performance of 19.
 But maybe this is just the expected behavior for having less rollout workers? I don't quite know what the expected # of samples to convergence here is.
 For some comparison, training &lt;denchmark-link:https://google.github.io/dopamine/baselines/plots.html&gt;curves&lt;/denchmark-link&gt;
  for Rainbow in Dopamine show good performance in 10*250k=2.5M timesteps, although certainly the algorithm and hyperparameters aren't terribly comparable.
 Here's a full record of the run: &lt;denchmark-link:https://app.wandb.ai/zplizzi/test/runs/2dthszrq?workspace=user-zplizzi&gt;https://app.wandb.ai/zplizzi/test/runs/2dthszrq?workspace=user-zplizzi&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://user-images.githubusercontent.com/5598968/70693629-af3bc200-1c72-11ea-8959-4f34e06fd03e.png&gt;&lt;/denchmark-link&gt;
 
 Ray version and other system information (Python version, TensorFlow version, OS):
 
 Ray nightly wheels as of earlier today
 Tensorflow 1.14.0
 Ubuntu 16.04
 
 &lt;denchmark-h:h3&gt;Reproduction&lt;/denchmark-h&gt;
 
 Here's the exact script used for training. All parameters are directly from the tuned example:
 &lt;denchmark-code&gt;from ray.rllib.agents.dqn import ApexTrainer
 from ray.rllib.agents import dqn
 
 config = dqn.apex.APEX_DEFAULT_CONFIG.copy()
 
 config["env"] = "PongNoFrameskip-v4"
 config["monitor"] = True
 config["env_config"]["wandb"] = {"project": "test", "monitor_gym": True}
 
 config["target_network_update_freq"] = 50000
 config["num_workers"] = 4
 config["num_envs_per_worker"] = 8
 config["gamma"] = 0.99
 config["lr"] = .0001
 
 from ray import tune
 from wandb.ray import WandbLogger
 tune.run(ApexTrainer,
             loggers=[WandbLogger],
             config=config,
             )
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='zplizzi' date='2019-12-12T08:50:58Z'>
 		Note that p3.2x is very wimpy in terms of CPU, you almost certainly want a p3.8xl or above if not using a distributed cluster.
 Btw you can see this file for the APEX runs we run regularly for regression testing: &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/compact-regression-test.yaml&gt;https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/compact-regression-test.yaml&lt;/denchmark-link&gt;
 
 It seems to clock in at ~4.5m timesteps/hr with 10 workers.
 		</comment>
 		<comment id='2' author='zplizzi' date='2019-12-12T17:12:21Z'>
 		Yeah, I agree this was a pretty CPU-limited run. I was more curious if it was expected to take 10M timesteps. As another comparison, the &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/pong-dqn.yaml&gt;tuned DQN pong example&lt;/denchmark-link&gt;
  says
 &lt;denchmark-code&gt;# You can expect ~20 reward within 1.1m timesteps / 2.1 hours on a K80 GPU
 &lt;/denchmark-code&gt;
 
 Is this Apex config expected to be 10x less sample efficient than the DQN config?
 		</comment>
 		<comment id='3' author='zplizzi' date='2019-12-12T17:33:23Z'>
 		Also, is there a mechanism that throttles the trainer to match the sample rate of the sampler? In the graphs above I noticed that the trainer initially was much faster than the sampler, but seems to have been throttled back over the course of the run in two distinct steps (bottom left graph). But perhaps this is some thermal throttling of CPU/GPU.
 		</comment>
 		<comment id='4' author='zplizzi' date='2019-12-12T18:18:06Z'>
 		Yes, Ape-X samples as fast as it can go and usually ends up much less sample efficient, but more real time efficient. In earlier versions of RLlib we used to throttle the sampler with the trainer, but now it is decoupled.
 		</comment>
 		<comment id='5' author='zplizzi' date='2019-12-12T18:24:18Z'>
 		Got it, thanks!
 For what it's worth, I re-ran that test with these modified hyperparams (all else the same):
 &lt;denchmark-code&gt;config["target_network_update_freq"] = 20000
 config["lr"] = .00005
 config["train_batch_size"] = 64
 &lt;/denchmark-code&gt;
 
 and it's performing much better (almost done at 5M training steps/1.5M env steps/40 mins on the same machine). But I could imagine that the original hyperparams are better wall-clock for the 32-worker case that it's designed for.
 		</comment>
 		<comment id='6' author='zplizzi' date='2019-12-12T18:26:54Z'>
 		That's quite a good result, consider updating the tuned example file if you'd like!
 		</comment>
 		<comment id='7' author='zplizzi' date='2019-12-12T18:29:47Z'>
 		Sure, here's a link to the run: &lt;denchmark-link:https://app.wandb.ai/zplizzi/test/runs/ayuuhixr?workspace=user-zplizzi&gt;https://app.wandb.ai/zplizzi/test/runs/ayuuhixr?workspace=user-zplizzi&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='9e9c5248238629a00fb8eeeffcd10fc5e54cf76d' author='Zack Polizzi' date='2019-12-12 10:57:55-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='rllib\tuned_examples\pong-apex.yaml' new_name='rllib\tuned_examples\pong-apex.yaml'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>1,2,3,4,9,10,11,12,13</added_lines>
 			<deleted_lines>1,2,3,8,9,10,11,12</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
