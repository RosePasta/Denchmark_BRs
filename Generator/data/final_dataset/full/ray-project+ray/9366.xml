<bug_data>
<bug id='9366' author='MaximeBouton' open_date='2020-07-09T00:17:39Z' closed_time='2020-07-10T09:23:41Z'>
 	<summary>[rllib] incorrect model output for DQN with torch and dueling=false</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 The output fo the DQN model is not within the action space.
 Something is wrong when constructing the torch model when dueling is off. The output dimension of the model is equal to whatever is passed in "fcnet_hiddens" instead of being of the size of the action space.
 Ray version and other system information (Python version, TensorFlow version, OS):
 
 ray==0.9.0.dev0
 python 3.6.10
 mac OS
 
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 import ray
 from ray import tune
 
 ray.init()
 
 config = {
     "env": "CartPole-v1",
     "num_workers": 1,
     "train_batch_size": 128,
     "learning_starts": 128,
     "model": {"fcnet_hiddens": [32]},
     "dueling": False ,
     "framework": "torch"
 }
 
 tune.run("DQN", name="MWE", config=config, stop={"training_iteration": 100})
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='MaximeBouton' date='2020-07-09T22:11:36Z'>
 		Can you just change the following in your rllib/agents/dqn/dqn_torch_model.py (c'tor) ?
 &lt;denchmark-code&gt;        advantage_module = nn.Sequential()
         value_module = nn.Sequential()
 
         # Dueling case: Build the shared (advantages and value) fc-network.
         if self.dueling:
             for i, n in enumerate(q_hiddens):
                 advantage_module.add_module("dueling_A_{}".format(i),
                                             nn.Linear(ins, n))
                 value_module.add_module("dueling_V_{}".format(i),
                                         nn.Linear(ins, n))
                 # Add activations if necessary.
                 if dueling_activation == "relu":
                     advantage_module.add_module("dueling_A_act_{}".format(i),
                                                 nn.ReLU())
                     value_module.add_module("dueling_V_act_{}".format(i),
                                             nn.ReLU())
                 elif dueling_activation == "tanh":
                     advantage_module.add_module("dueling_A_act_{}".format(i),
                                                 nn.Tanh())
                     value_module.add_module("dueling_V_act_{}".format(i),
                                             nn.Tanh())
 
                 # Add LayerNorm after each Dense.
                 if add_layer_norm:
                     advantage_module.add_module("LayerNorm_A_{}".format(i),
                                                 nn.LayerNorm(n))
                     value_module.add_module("LayerNorm_V_{}".format(i),
                                             nn.LayerNorm(n))
                 ins = n
 
         # Actual Advantages layer (nodes=num-actions) and
         # value layer (nodes=1).
         advantage_module.add_module("A", nn.Linear(ins, action_space.n))
         value_module.add_module("V", nn.Linear(ins, 1))
 &lt;/denchmark-code&gt;
 
 That should fix it. Will PR now ...
 		</comment>
 		<comment id='2' author='MaximeBouton' date='2020-07-09T22:11:47Z'>
 		&lt;denchmark-link:https://github.com/MaximeBouton&gt;@MaximeBouton&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='MaximeBouton' date='2020-07-10T03:49:35Z'>
 		Just saw this, I can give it a try tomorrow morning
 		</comment>
 		<comment id='4' author='MaximeBouton' date='2020-07-10T09:23:40Z'>
 		This PR fixes the issue: &lt;denchmark-link:https://github.com/ray-project/ray/pull/9386&gt;#9386&lt;/denchmark-link&gt;
 
 Will be merged today into master. Thanks for filing this!
 Closing it now. Please feel free to re-open should this still not work on your end.
 		</comment>
 		<comment id='5' author='MaximeBouton' date='2020-07-10T16:36:46Z'>
 		I installed the nightly version and it works, thanks for the quick fix!
 		</comment>
 		<comment id='6' author='MaximeBouton' date='2020-07-10T21:37:24Z'>
 		This has been merged into master.
 		</comment>
 		<comment id='7' author='MaximeBouton' date='2020-07-11T20:07:07Z'>
 		Awesome! Glad it's working. :)
 		</comment>
 	</comments>
 </bug>
<commit id='14160ca58c8d37ea4c08639be12c6569a80eb190' author='Sven Mika' date='2020-07-10 12:43:03+02:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='rllib\agents\dqn\dqn_torch_model.py' new_name='rllib\agents\dqn\dqn_torch_model.py'>
 		<file_info nloc='113' complexity='6' token_count='758'></file_info>
 		<modified_lines>
 			<added_lines>57,58,59,60,61,63,64,65,66,67,69,70,71,72,74,75,77,78,79,81,82,83,84,85,86,90,91,92,93,94</added_lines>
 			<deleted_lines>56,58,59,60,61,62,63,64,66,67,68,69,70,72,73,74,75,78,79,80,81,82,84,85,86,88,89,90,91,92,95</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\examples\parametric_actions_cartpole.py' new_name='rllib\examples\parametric_actions_cartpole.py'>
 		<file_info nloc='63' complexity='0' token_count='316'></file_info>
 		<modified_lines>
 			<added_lines>51</added_lines>
 			<deleted_lines>51</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
