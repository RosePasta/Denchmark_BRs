<bug_data>
<bug id='12382' author='wuisawesome' open_date='2020-11-25T03:10:55Z' closed_time='2020-12-21T18:30:04Z'>
 	<summary>[Autoscaler] Autoscaler counts head node in node specific max workers</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 Given a config like this (with a program that needs 5 GPUs), 4 of them launch, and the final worker cannot launch because there are no remaining nodes which fulfill the resource demand.
 &lt;denchmark-code&gt;min_workers: 4
 max_workers: 4
 initial_workers: 4
 idle_timeout_minutes: 1000
 
 docker: {}
 
 provider:
     type: aws
     region: us-west-2
     availability_zone: us-west-2a, us-west-2b, us-west-2c
 
 available_node_types:
     gpu_1_ondemand:
         max_worker: 4
         node_config:
             InstanceType: g4dn.16xlarge
             TagSpecifications:
               - ResourceType: "instance"
                 Tags:
                   - Key: anyscale-user
                     Value: xmo@anyscale.com
                   - Key: anyscale-expiration
                     Value: "2020-11-30"
 
 # Specify the node type of the head node (as configured above).
 head_node_type: gpu_1_ondemand
 
 # Specify the default type of the worker node (as configured above).
 worker_default_node_type: gpu_1_ondemand
 
 # The default settings for the head node. This will be merged with the per-node
 # type configs given above.
 head_node:
     ImageId: latest_dlami
 
 # The default settings for worker nodes. This will be merged with the per-node
 # type configs given above.
 worker_nodes:
     ImageId: latest_dlami
 
 file_mounts: {
   "/home/ubuntu/workspace": "."
 }
 
 rsync_filter:
     - .gitignore
 
 # How Ray will authenticate with newly launched nodes.
 auth:
     ssh_user: ubuntu
 
 setup_commands:
   - pip install torch torchvision ray[all] pillow
   - pip install -U boto3 botocore
   # Download the pretrained model
   - python -c "from torchvision.models import resnet50; resnet50(pretrained=True)"
   - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-1.1.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl
 &lt;/denchmark-code&gt;
 
 Ray version and other system information (Python version, TensorFlow version, OS):
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
 If we cannot run your script, we cannot fix your issue.
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='wuisawesome' date='2020-12-08T22:39:57Z'>
 		&lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;
  do you mean that only three workers are launched, instead of 4?
 		</comment>
 		<comment id='2' author='wuisawesome' date='2020-12-08T22:41:13Z'>
 		Yeah
 		</comment>
 		<comment id='3' author='wuisawesome' date='2020-12-09T00:16:20Z'>
 		Can you just add +1 if it is a headnode here:
 
 
 
 ray/python/ray/autoscaler/_private/resource_demand_scheduler.py
 
 
          Line 564
       in
       fd4e025
 
 
 
 
 
 
  node_type, 0) &gt;= node_types[node_type].get( 
 
 
 
 
 
 ?
 		</comment>
 	</comments>
 </bug>
<commit id='5e2b850836b893a7276edbcf42079b6759dbd2f0' author='Ameer Haj Ali' date='2020-12-21 10:30:03-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\_private\resource_demand_scheduler.py' new_name='python\ray\autoscaler\_private\resource_demand_scheduler.py'>
 		<file_info nloc='596' complexity='30' token_count='3023'></file_info>
 		<method name='get_nodes_for' parameters='NodeType,NodeType,NodeType,int,bool'>
 				<method_info nloc='6' complexity='1' token_count='49' nesting_level='0' start_line='568' end_line='573'></method_info>
 			<added_lines>570</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>195,196,451,549,594,595,596,597,598,600</added_lines>
 			<deleted_lines>195,547,592,593</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tests\test_resource_demand_scheduler.py' new_name='python\ray\tests\test_resource_demand_scheduler.py'>
 		<file_info nloc='1743' complexity='86' token_count='11653'></file_info>
 		<method name='test_get_nodes_respects_max_limit' parameters=''>
 				<method_info nloc='35' complexity='1' token_count='192' nesting_level='0' start_line='246' end_line='280'></method_info>
 			<added_lines>261,263,266,271,274,276</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_get_nodes_packing_heuristic' parameters=''>
 				<method_info nloc='96' complexity='1' token_count='505' nesting_level='0' start_line='145' end_line='243'></method_info>
 			<added_lines>146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,233,239</added_lines>
 			<deleted_lines>146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,176,182,204,206,209,214,217,219</deleted_lines>
 		</method>
 		<method name='testRequestBundles' parameters='self'>
 				<method_info nloc='34' complexity='2' token_count='254' nesting_level='1' start_line='1408' end_line='1442'></method_info>
 			<added_lines>1415,1440</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
