<bug_data>
<bug id='13403' author='krfricke' open_date='2021-01-13T14:24:56Z' closed_time='2021-01-16T11:49:25Z'>
 	<summary>[core] placement groups do not become `ready()` when too many PGs are requested at the same time</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 MacOS, latest master. Also errors with the latest wheels.
 Does not error with latest release (1.1.0)
 When I start more placement groups than fit on my cluster, pg.ready() futures only become ready for the number of placement groups that immediately fit on the cluster. If I then remove these placement groups, subsequent placement groups do not become ready anymore (but their status is updated to CREATED).
 This only happens when more placement groups are requested than fit on the cluster. E.g. if 2 placement groups fit on the cluster and 4 are requested, it works. If 6 are requested, it doesn't work.
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 This script runs forever:
 &lt;denchmark-code&gt;import ray
 from ray.util.placement_group import placement_group, remove_placement_group, \
     placement_group_table
 
 ray.init(num_cpus=4)
 
 pgs = [
     placement_group([{"CPU": 2}])
     for _ in range(6)  # Works for `range(4)`
 ]
 
 ready_futs = {pg.ready(): pg for pg in pgs}
 
 notready_count = 0
 while ready_futs:
     tbl = placement_group_table()
     print("PGs:", [tbl[pg]["state"] for pg in sorted(tbl)])
 
     ready, _ = ray.wait(list(ready_futs.keys()), timeout=0.5)
     if ready:
         ready_pg = ready_futs[ready[0]]
 
         print(f"Placement group {ready_pg} became ready. Removing.")
         remove_placement_group(ready_pg)
         del ready_futs[ready[0]]
     else:
         notready_count += 1
         print("No placement group ready, yet.")
 
         # This block can be removed, it still doesn't work -
         # i.e. even with new futures they never become ready.
         if notready_count == 4:
             print("Re-scheduling futures")
             ready_futs = {pg.ready(): pg for pg in pgs}
 &lt;/denchmark-code&gt;
 
 Output with range(4) (works):
 &lt;denchmark-code&gt;2021-01-13 15:25:56,793	INFO services.py:1171 -- View the Ray dashboard at http://127.0.0.1:8265
 PGs: ['CREATED', 'PENDING', 'CREATED', 'PENDING']
 Placement group &lt;ray.util.placement_group.PlacementGroup object at 0x11a3d7310&gt; became ready. Removing.
 PGs: ['REMOVED', 'PENDING', 'CREATED', 'PENDING']
 Placement group &lt;ray.util.placement_group.PlacementGroup object at 0x11fa14fd0&gt; became ready. Removing.
 PGs: ['REMOVED', 'PENDING', 'REMOVED', 'PENDING']
 Placement group &lt;ray.util.placement_group.PlacementGroup object at 0x11fa11850&gt; became ready. Removing.
 PGs: ['REMOVED', 'REMOVED', 'REMOVED', 'CREATED']
 Placement group &lt;ray.util.placement_group.PlacementGroup object at 0x11fa14f90&gt; became ready. Removing.
 
 Process finished with exit code 0
 &lt;/denchmark-code&gt;
 
 Output with range(6) (runs forever):
 &lt;denchmark-code&gt;2021-01-13 15:26:48,612	INFO services.py:1171 -- View the Ray dashboard at http://127.0.0.1:8265
 PGs: ['PENDING', 'CREATED', 'PENDING', 'PENDING', 'CREATED', 'PENDING']
 Placement group &lt;ray.util.placement_group.PlacementGroup object at 0x120d08fd0&gt; became ready. Removing.
 PGs: ['PENDING', 'REMOVED', 'PENDING', 'PENDING', 'CREATED', 'PENDING']
 Placement group &lt;ray.util.placement_group.PlacementGroup object at 0x120d08f90&gt; became ready. Removing.
 PGs: ['PENDING', 'REMOVED', 'PENDING', 'PENDING', 'REMOVED', 'PENDING']
 No placement group ready, yet.
 PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']
 No placement group ready, yet.
 PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']
 No placement group ready, yet.
 PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']
 No placement group ready, yet.
 Re-scheduling futures
 PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']
 No placement group ready, yet.
 PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']
 
 (... continues to run with the last two lines forever)
 &lt;/denchmark-code&gt;
 
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 cc &lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='krfricke' date='2021-01-13T17:24:15Z'>
 		cc &lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
  FYI this is blocking Ray Tune usage of placement groups
 		</comment>
 		<comment id='2' author='krfricke' date='2021-01-14T08:39:54Z'>
 		&lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/richard4912&gt;@richard4912&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
  I have find the raylet scheduling bug, and submit a PR( &lt;denchmark-link:https://github.com/ray-project/ray/pull/13452&gt;#13452&lt;/denchmark-link&gt;
  ) to fix it, thx. cc &lt;denchmark-link:https://github.com/clay4444&gt;@clay4444&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='krfricke' date='2021-01-16T02:26:59Z'>
 		&lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;
  Can you verify the fix and close the issue?
 		</comment>
 		<comment id='4' author='krfricke' date='2021-01-16T11:49:25Z'>
 		Everything's working now. Thanks for the quick turnaround!
 		</comment>
 	</comments>
 </bug>
<commit id='4a6c53da46c82d56bfda8bea31cf447928285560' author='fangfengbin' date='2021-01-14 14:50:32+01:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\ray\tests\test_placement_group.py' new_name='python\ray\tests\test_placement_group.py'>
 		<file_info nloc='944' complexity='134' token_count='6201'></file_info>
 		<method name='test_schedule_placement_groups_at_the_same_time.is_all_placement_group_removed' parameters=''>
 				<method_info nloc='9' complexity='3' token_count='63' nesting_level='1' start_line='1299' end_line='1308'></method_info>
 			<added_lines>1299,1300,1301,1302,1303,1304,1305,1306,1307,1308</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_schedule_placement_groups_at_the_same_time' parameters=''>
 				<method_info nloc='6' complexity='3' token_count='54' nesting_level='0' start_line='1292' end_line='1310'></method_info>
 			<added_lines>1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>17,18,1311,1312</added_lines>
 			<deleted_lines>17</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ray\raylet\scheduling\cluster_resource_scheduler.cc' new_name='src\ray\raylet\scheduling\cluster_resource_scheduler.cc'>
 		<file_info nloc='766' complexity='183' token_count='5528'></file_info>
 		<method name='ray::ClusterResourceScheduler::GetBestSchedulableNode' parameters='task_req,actor_creation,total_violations,is_infeasible'>
 				<method_info nloc='61' complexity='19' token_count='393' nesting_level='1' start_line='173' end_line='265'></method_info>
 			<added_lines>177,178,179,180</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
