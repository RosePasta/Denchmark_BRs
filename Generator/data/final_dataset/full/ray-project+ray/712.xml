<bug_data>
<bug id='712' author='robertnishihara' open_date='2017-07-05T22:13:06Z' closed_time='2017-07-18T06:26:40Z'>
 	<summary>Test failure in jenkins tests "psutil.NoSuchProcess process no longer exists".</summary>
 	<description>
 I sometimes see errors like the following in the jenkins tests.
 Traceback (most recent call last):
   File "/ray/test/jenkins_tests/multi_node_tests/remove_driver_test.py", line 264, in &lt;module&gt;
     cleanup_driver(redis_address, driver_index)
   File "/ray/test/jenkins_tests/multi_node_tests/remove_driver_test.py", line 225, in cleanup_driver
     wait_for_pid_to_exit(pid)
   File "/opt/conda/lib/python2.7/site-packages/ray-0.1.2-py2.7-linux-x86_64.egg/ray/test/test_utils.py", line 130, in wait_for_pid_to_exit
     if not _pid_alive(pid):
   File "/opt/conda/lib/python2.7/site-packages/ray-0.1.2-py2.7-linux-x86_64.egg/ray/test/test_utils.py", line 121, in _pid_alive
     if psutil.Process(pid).status() == psutil.STATUS_ZOMBIE:
   File "/opt/conda/lib/python2.7/site-packages/psutil/__init__.py", line 627, in status
     return self._proc.status()
   File "/opt/conda/lib/python2.7/site-packages/psutil/_pslinux.py", line 968, in wrapper
     raise NoSuchProcess(self.pid, self._name)
 psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=22)
 The error can be seen in the following log file &lt;denchmark-link:https://amplab.cs.berkeley.edu/jenkins/job/Ray-PRB/1164/console&gt;https://amplab.cs.berkeley.edu/jenkins/job/Ray-PRB/1164/console&lt;/denchmark-link&gt;
 .
 The following error from &lt;denchmark-link:https://amplab.cs.berkeley.edu/jenkins/job/Ray-PRB/1185/console&gt;https://amplab.cs.berkeley.edu/jenkins/job/Ray-PRB/1185/console&lt;/denchmark-link&gt;
  is possibly related.
 Traceback (most recent call last):
   File "/opt/conda/lib/python2.7/site-packages/ray-0.1.2-py2.7-linux-x86_64.egg/ray/actor.py", line 82, in fetch_and_register_actor
     unpickled_class = pickle.loads(pickled_class)
   File "/opt/conda/lib/python2.7/pickle.py", line 1388, in loads
     return Unpickler(file).load()
   File "/opt/conda/lib/python2.7/pickle.py", line 864, in load
     dispatch[key](self)
   File "/opt/conda/lib/python2.7/pickle.py", line 1139, in load_reduce
     value = func(*args)
   File "/opt/conda/lib/python2.7/site-packages/cloudpickle/cloudpickle.py", line 840, in subimport
     __import__(name)
   File "/opt/conda/lib/python2.7/site-packages/gym/__init__.py", line 48, in &lt;module&gt;
     sanity_check_dependencies()
   File "/opt/conda/lib/python2.7/site-packages/gym/__init__.py", line 17, in sanity_check_dependencies
     import requests
   File "/opt/conda/lib/python2.7/site-packages/requests/__init__.py", line 63, in &lt;module&gt;
     from . import utils
   File "/opt/conda/lib/python2.7/site-packages/requests/utils.py", line 42, in &lt;module&gt;
     if platform.system() == 'Windows':
   File "/opt/conda/lib/python2.7/platform.py", line 1263, in system
     return uname()[0]
   File "/opt/conda/lib/python2.7/platform.py", line 1230, in uname
     processor = _syscmd_uname('-p','')
   File "/opt/conda/lib/python2.7/platform.py", line 965, in _syscmd_uname
     rc = f.close()
 IOError: [Errno 10] No child processes
 The issue may be related to the fact that workers are created by forking the local scheduler, and the local scheduler changes the  handler. Signal handlers shouldn't survive a call to , but &lt;denchmark-link:https://stackoverflow.com/questions/2333637/is-it-possible-to-signal-handler-to-survive-after-exec&gt;https://stackoverflow.com/questions/2333637/is-it-possible-to-signal-handler-to-survive-after-exec&lt;/denchmark-link&gt;
  makes it seem like  may be an exception.
 The connection between the error message and the  handler is suggested by &lt;denchmark-link:https://github.com/tornadoweb/tornado/issues/1160&gt;tornadoweb/tornado#1160&lt;/denchmark-link&gt;
 .
 	</description>
 	<comments>
 		<comment id='1' author='robertnishihara' date='2017-07-18T06:26:40Z'>
 		After experimenting with the issue in &lt;denchmark-link:https://github.com/ray-project/ray/issues/745&gt;#745&lt;/denchmark-link&gt;
  (which is fixed by &lt;denchmark-link:https://github.com/ray-project/ray/pull/713&gt;#713&lt;/denchmark-link&gt;
 ), I think this &lt;denchmark-link:https://github.com/ray-project/ray/pull/713&gt;#713&lt;/denchmark-link&gt;
  really does address this issue, so I'm closing the issue.
 		</comment>
 	</comments>
 </bug>
<commit id='6c45657280f40c36826e456ecfff358519ed81dd' author='Robert Nishihara' date='2017-07-07 14:50:37+00:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='src\local_scheduler\local_scheduler.cc' new_name='src\local_scheduler\local_scheduler.cc'>
 		<file_info nloc='955' complexity='165' token_count='6096'></file_info>
 		<method name='start_worker' parameters='state,actor_id'>
 				<method_info nloc='31' complexity='5' token_count='226' nesting_level='0' start_line='209' end_line='246'></method_info>
 			<added_lines>223,224,225</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
