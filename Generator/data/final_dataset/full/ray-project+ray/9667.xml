<bug_data>
<bug id='9667' author='raphaelavalos' open_date='2020-07-23T15:18:44Z' closed_time='2020-07-28T12:15:04Z'>
 	<summary>[RLlib] Bugs in PyTorch version of DDPG</summary>
 	<description>
 Hello,
 I spotted some bugs in the implementation of DDPG in PyTorch.
 
 
 The gradient clipping is not implemented correctly, it uses the 'grad_norm_clipping' parameter instead of 'grad_clip' and the function ray.rllib.utils.torch_ops.minimize_and_clip which is not correct. All the others algorithms seems to use ray.rllib.agents.a3c.a3c_torch_policy.apply_grad_clipping. I propose to replace minimize_and_clip by the A3C function in torch_ops.
 
 
 In the PyTorch model of DDPG the parameters to bound the action space (range and minimum) are not tracked by PyTorch as they are not registered as parameters. This means that they are not converted to cuda tensors resulting in an error.
 
 
 The target model is placed on the gpu even if ray was not configure to use the gpu.
 
 
 I will make a PR with everything. But I don't know if I should replace minimize_and_clip.
 
  I have verified my script runs in a clean environment and reproduces the issue.
   I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='raphaelavalos' date='2020-07-23T16:24:26Z'>
 		I would add other issue: clamp is used to clamp the action at several places &lt;denchmark-link:https://github.com/ray-project/ray/blob/fcdf410ae1bb5071e7d92174eace7d79be2d4ef9/rllib/utils/exploration/gaussian_noise.py#L157&gt;here&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/ray-project/ray/blob/43043ee4d5c672f7fbc22ac9559e8164731fd053/rllib/agents/ddpg/ddpg_torch_policy.py#L68&gt;here&lt;/denchmark-link&gt;
 , while min/max combinaison should be used instead. Indeed, clamp does not support element-wise operation and this limitation is currently circumvent by clamping with respect to the first low/high bounds of the action space, which does not make any sense.
 		</comment>
 		<comment id='2' author='raphaelavalos' date='2020-07-23T16:40:47Z'>
 		I will add that :)
 		</comment>
 		<comment id='3' author='raphaelavalos' date='2020-07-23T16:45:53Z'>
 		Nice ! Thank you üëç Personally I'm doing this (for example):
 &lt;denchmark-code&gt;policy_tp1_smoothed = torch.min(torch.max(policy_tp1 + clipped_normal_sample,
     torch.tensor(policy.action_space.low, dtype=torch.float32, device=policy_tp1.device)),
     torch.tensor(policy.action_space.high, dtype=torch.float32, device=policy_tp1.device))
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='4' author='raphaelavalos' date='2020-07-23T17:04:20Z'>
 		Note that the problem appears &lt;denchmark-link:https://github.com/ray-project/ray/blob/fcdf410ae1bb5071e7d92174eace7d79be2d4ef9/rllib/utils/exploration/ornstein_uhlenbeck_noise.py#L176&gt;here&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='5' author='raphaelavalos' date='2020-07-24T09:29:11Z'>
 		
 I would add other issue: clamp is used to clamp the action at several places here and here, while min/max combinaison should be used instead. Indeed, clamp does not support element-wise operation and this limitation is currently circumvent by clamping with respect to the first low/high bounds of the action space, which does not make any sense.
 
 Yeah, but one instance of clamping is in the Exploration component (which could be used in any other algorithm) and the other is part of the DDPG algorithm. I think this one is ok here.
 		</comment>
 		<comment id='6' author='raphaelavalos' date='2020-07-24T09:30:02Z'>
 		
 Note that the problem appears here
 
 Perfect, thanks! Will fix this.
 		</comment>
 		<comment id='7' author='raphaelavalos' date='2020-07-24T09:31:42Z'>
 		Looking into minimize_and_clip issue. ...
 I think I changed it so it's more concise because we had a lot of duplicate logic in the grad-clipping code prior to adding eager support.
 		</comment>
 		<comment id='8' author='raphaelavalos' date='2020-07-24T09:34:51Z'>
 		The target model is placed on the gpu even if ray was not configure to use the gpu.
 This should be fixed in the current master.
 		</comment>
 		<comment id='9' author='raphaelavalos' date='2020-07-24T09:41:10Z'>
 		
 Yeah, but one instance of clamping is in the Exploration component (which could be used in any other algorithm) and the other is part of the DDPG algorithm. I think this one is ok here.
 
 What do you mean ? Why would it be ok to clamp wrt to first element bounds only in some cases ?
 		</comment>
 		<comment id='10' author='raphaelavalos' date='2020-07-24T09:42:38Z'>
 		
 
 The target model is placed on the gpu even if ray was not configure to use the gpu.
 
 This should be fixed in the current master.
 
 There is the same problem for the model itself at least for 0.86, and on master as far as I know (since torch.cuda.is_gpu_available is used to choose the device). Is it also fixed ?
 		</comment>
 		<comment id='11' author='raphaelavalos' date='2020-07-24T09:50:51Z'>
 		Yeah, we just made a fix for this a week ago or so.
 I created this PR here to fix all the other problems described above.
 &lt;denchmark-link:https://github.com/ray-project/ray/pull/9680&gt;#9680&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='12' author='raphaelavalos' date='2020-07-24T09:51:20Z'>
 		Please let me know, if I'm missing anything. Leaving this open until merged (probably later today).
 		</comment>
 		<comment id='13' author='raphaelavalos' date='2020-07-24T09:52:07Z'>
 		On the GPU: Yes, we are no longer checking, whether we have a GPU, but whether the config actually says: num_gpus &gt; 0 and only then place the model on the GPU.
 		</comment>
 		<comment id='14' author='raphaelavalos' date='2020-07-24T09:57:55Z'>
 		&lt;denchmark-link:https://github.com/duburcqa&gt;@duburcqa&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/raphaelavalos&gt;@raphaelavalos&lt;/denchmark-link&gt;
 
 Btw, we are very close to setting up daily automatic GPU + "heavy" regression tests (Atari, MuJoCo) to catch these things much earlier than we do right now. Hopefully, this will eliminate issues like the GPU one here altogether.
 		</comment>
 		<comment id='15' author='raphaelavalos' date='2020-07-24T10:05:14Z'>
 		&lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
  we did things differently so I don't know if it is relevant but in my case the tests were failing because we have two new parameters on the model. You can check my last commit (above) it fixed the tests in my case.
 		</comment>
 		<comment id='16' author='raphaelavalos' date='2020-07-24T10:31:21Z'>
 		Yeah, makes sense. If your PR is ready, feel free to ping me here so we can approve and merge it.
 		</comment>
 		<comment id='17' author='raphaelavalos' date='2020-07-24T11:53:48Z'>
 		I spotted yet another issue : the device may be wrong for the noise, it can be on 'cpu' device while the action is on 'gpu' device in some case (I don't know exactly when though, but it happens to me in 0.8.6). It appears &lt;denchmark-link:https://github.com/ray-project/ray/blob/43043ee4d5c672f7fbc22ac9559e8164731fd053/rllib/agents/ddpg/ddpg_torch_policy.py#L63&gt;here&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/ray-project/ray/blob/fcdf410ae1bb5071e7d92174eace7d79be2d4ef9/rllib/utils/exploration/gaussian_noise.py#L155&gt;here&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/ray-project/ray/blob/fcdf410ae1bb5071e7d92174eace7d79be2d4ef9/rllib/utils/exploration/ornstein_uhlenbeck_noise.py#L175&gt;here&lt;/denchmark-link&gt;
 .
 		</comment>
 		<comment id='18' author='raphaelavalos' date='2020-07-25T09:34:50Z'>
 		&lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/raphaelavalos&gt;@raphaelavalos&lt;/denchmark-link&gt;
  Other bug: Pytorch  method is used to get a dict of model parameters, which is wrong.  returns something way more complex than that, including attributes.  should be used instead. Moreover, it is sometimes returning a dict instead of an OrderedDict as it should be. The issue occurs &lt;denchmark-link:https://github.com/ray-project/ray/blob/57544b1ff9f97d4da9f64d25c8ea5a3d8d247ffc/rllib/agents/ddpg/ddpg_torch_model.py#L183&gt;here&lt;/denchmark-link&gt;
  for DDPG. It should be instead:
 &lt;denchmark-code&gt;    def policy_variables(self, as_dict=False):
         """Return the list of variables for the policy net."""
         if as_dict:
             return OrderedDict(self.policy_model.named_parameters())
         return list(self.policy_model.parameters())
 
     def q_variables(self, as_dict=False):
         """Return the list of variables for Q / twin Q nets."""
         if as_dict:
             return OrderedDict((
                 *self.q_model.named_parameters(),
                 *(self.twin_q_model.named_parameters() if self.twin_q_model else [])
             ))
         return [*self.q_model.parameters(),
                 *(self.twin_q_model.parameters() if self.twin_q_model else [])]
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='19' author='raphaelavalos' date='2020-07-27T09:57:07Z'>
 		&lt;denchmark-link:https://github.com/duburcqa&gt;@duburcqa&lt;/denchmark-link&gt;
  I have made to change to parameters but I don't think OrderedDict is needed here.
 		</comment>
 		<comment id='20' author='raphaelavalos' date='2020-07-27T11:15:01Z'>
 		
 @duburcqa I have made to change to parameters but I don't think OrderedDict is needed here.
 
 Yes it is not a big deal in practice.
 		</comment>
 		<comment id='21' author='raphaelavalos' date='2020-07-27T11:21:10Z'>
 		Why not to fix in this PR the clamping issue for the exploration noise I mentioned ? Because it is a more general issue than DDPG alone ?
 		</comment>
 		<comment id='22' author='raphaelavalos' date='2020-07-27T15:51:23Z'>
 		
 Why not to fix in this PR the clamping issue for the exploration noise I mentioned ? Because it is a more general issue than DDPG alone ?
 
 &lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
  Thank you for having taken care of this !
 With those 2 PRs, I think we are good.
 		</comment>
 		<comment id='23' author='raphaelavalos' date='2020-07-30T11:14:21Z'>
 		&lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
  would it be possible to keep the issue open until &lt;denchmark-link:https://github.com/ray-project/ray/pull/9683&gt;#9683&lt;/denchmark-link&gt;
  is merged ?
 		</comment>
 	</comments>
 </bug>
<commit id='ff9c1dac887643e464f5f829c7d8b920b0aa8140' author='Sven Mika' date='2020-07-28 14:15:03+02:00'>
 	<dmm_unit complexity='0.5909090909090909' interfacing='0.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='rllib\agents\ddpg\ddpg_torch_model.py' new_name='rllib\agents\ddpg\ddpg_torch_model.py'>
 		<file_info nloc='127' complexity='13' token_count='717'></file_info>
 		<modified_lines>
 			<added_lines>54,55,56</added_lines>
 			<deleted_lines>54,55,56</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\agents\ddpg\ddpg_torch_policy.py' new_name='rllib\agents\ddpg\ddpg_torch_policy.py'>
 		<file_info nloc='196' complexity='29' token_count='1500'></file_info>
 		<method name='gradients_fn' parameters='policy,optimizer,loss'>
 				<method_info nloc='4' complexity='2' token_count='34' nesting_level='0' start_line='190' end_line='193'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>190,191,192,193</deleted_lines>
 		</method>
 		<method name='ddpg_actor_critic_loss' parameters='policy,model,_,train_batch'>
 				<method_info nloc='99' complexity='14' token_count='775' nesting_level='0' start_line='31' end_line='170'></method_info>
 			<added_lines>67,68,70,71,72,73,74,75,76,77,78,79,80,81</added_lines>
 			<deleted_lines>66,68,69,70</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>4,13,275</added_lines>
 			<deleted_lines>12,194,195,270</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\utils\exploration\gaussian_noise.py' new_name='rllib\utils\exploration\gaussian_noise.py'>
 		<file_info nloc='130' complexity='14' token_count='908'></file_info>
 		<method name='_get_torch_exploration_action' parameters='self,action_dist,explore,timestep'>
 				<method_info nloc='30' complexity='4' token_count='214' nesting_level='1' start_line='139' end_line='177'></method_info>
 			<added_lines>156,157,158,159,160,161,162,163,164,165,166,167,168</added_lines>
 			<deleted_lines>156,157,158,159</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\utils\exploration\ornstein_uhlenbeck_noise.py' new_name='rllib\utils\exploration\ornstein_uhlenbeck_noise.py'>
 		<file_info nloc='138' complexity='12' token_count='952'></file_info>
 		<method name='_get_torch_exploration_action' parameters='self,action_dist,explore,timestep'>
 				<method_info nloc='40' complexity='4' token_count='307' nesting_level='1' start_line='146' end_line='197'></method_info>
 			<added_lines>176,177,178,179,180,181,182,183,184,185,186,187</added_lines>
 			<deleted_lines>176,177,178</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
