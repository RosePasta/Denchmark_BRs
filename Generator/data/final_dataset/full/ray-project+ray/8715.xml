<bug_data>
<bug id='8715' author='stephanie-wang' open_date='2020-06-01T23:13:07Z' closed_time='2020-06-02T23:06:37Z'>
 	<summary>[autoscaler] Cluster becomes unusable when job exits.</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 Ray version and other system information (Python version, TensorFlow version, OS): 0.9dev
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
 If we cannot run your script, we cannot fix your issue.
 I ran with the default AWS autoscaler config (python/ray/autoscaler/aws/example-full.yaml), modified the minimum to 2 workers. Steps to reproduce:
 
 SSH into head node.
 Run a Ray script from bash (while True: ray.get(foo.remote()) works)
 Cancel Ray script with CTRL+C.
 
 Then, in /tmp/ray/session_latest/logs/monitor.err, I get this:
 &lt;denchmark-code&gt;2020-06-01 23:06:52,035 INFO autoscaler.py:619 -- StandardAutoscaler: 2/2 target nodes (0 pending) (2 updating) (bringup=True)
 2020-06-01 23:06:52,035 INFO autoscaler.py:620 -- LoadMetrics: MostDelayedHeartbeats={'172.30.0.103': 0.1708686351776123}, NodeIdleSeconds=Min=0 Mean=0 Max=0, NumNodesConnected=1, NumNodesUsed=0.02, ResourceUsage=1.0/64.0 CPU, 0.0 GiB/178.57 GiB memory, 0.0/1.0 node:172.30.0.103, 0.0 GiB/55.73 GiB object_store_memory, TimeSinceLastHeartbeat=Min=0 Mean=0 Max=0
 2020-06-01 23:06:56,727 INFO updater.py:257 -- NodeUpdater: i-0fe7dc6a0f3fd63be: Running uptime on 172.30.1.111...
 2020-06-01 23:06:56,733 INFO updater.py:257 -- NodeUpdater: i-0a74d5ee1dadf1b74: Running uptime on 172.30.1.30...
 Warning: Permanently added '172.30.1.111' (ECDSA) to the list of known hosts.^M
 Warning: Permanently added '172.30.1.30' (ECDSA) to the list of known hosts.^M
 Error in monitor loop
 Traceback (most recent call last):
   File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/monitor.py", line 277, in run
     self._run()
   File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/monitor.py", line 235, in _run
     self.process_messages()
   File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/monitor.py", line 187, in process_messages
     message_handler(channel, data)
   File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/monitor.py", line 125, in xray_job_notification_handler
     job_data = gcs_entries.entries[0]
 IndexError: list index (0) out of range
 2020-06-01 23:06:56,765 ERROR autoscaler.py:645 -- StandardAutoscaler: kill_workers triggered
 2020-06-01 23:06:56,828 INFO node_provider.py:353 -- AWSNodeProvider: terminating nodes ['i-0fe7dc6a0f3fd63be', 'i-0a74d5ee1dadf1b74'] (spot nodes cannot be stopped, only terminated)
 2020-06-01 23:06:56,997 ERROR autoscaler.py:650 -- StandardAutoscaler: terminated 2 node(s)
 2020-06-01 23:06:57,123 INFO commands.py:93 -- teardown_cluster: Keeping 2 nodes...
 Monitor: Cleanup exception. Trying again...
 mux_client_request_session: read from master failed: Broken pipe^M
 Failed to connect to new control master^M
 mux_client_request_session: read from master failed: Broken pipe^M
 Failed to connect to new control master^M
 2020-06-01 23:06:59,270 INFO commands.py:93 -- teardown_cluster: Keeping 2 nodes...
 Monitor: Cleanup exception. Trying again...
 2020-06-01 23:07:01,385 INFO commands.py:93 -- teardown_cluster: Keeping 2 nodes...
 Monitor: Cleanup exception. Trying again...
 2020-06-01 23:07:02,231 INFO updater.py:257 -- NodeUpdater: i-0a74d5ee1dadf1b74: Running uptime on 172.30.1.30...
 ssh: connect to host 172.30.1.30 port 22: Connection refused^M
 2020-06-01 23:07:02,243 INFO updater.py:257 -- NodeUpdater: i-0fe7dc6a0f3fd63be: Running uptime on 172.30.1.111...
 ssh: connect to host 172.30.1.111 port 22: Connection refused^M
 2020-06-01 23:07:03,513 INFO commands.py:93 -- teardown_cluster: Keeping 2 nodes...
 Monitor: Cleanup exception. Trying again...
 2020-06-01 23:07:05,622 INFO commands.py:93 -- teardown_cluster: Keeping 2 nodes...
 Monitor: Cleanup exception. Trying again...
 &lt;/denchmark-code&gt;
 
 Other times I get the same Python exception and teardown messages, but not the infinitely repeating messages about "Cleanup exception". However, the messages just stop completely and no new worker nodes are started. I didn't confirm, but this might be if I wait for the worker nodes to come up completely before starting the job.
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='stephanie-wang' date='2020-06-01T23:13:32Z'>
 		cc &lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;
 , might be a P0?
 		</comment>
 		<comment id='2' author='stephanie-wang' date='2020-06-01T23:22:53Z'>
 		Actually, this just happened again without a keyboard interrupt, I think because my driver exited.
 		</comment>
 		<comment id='3' author='stephanie-wang' date='2020-06-01T23:28:20Z'>
 		Reproduced the same error with this short script, head node with 0 CPUs, and 2 worker nodes with lots of CPUs:
 &lt;denchmark-code&gt;import ray
 import time
 
 ray.init(address="auto")
 
 
 @ray.remote
 def foo():
     return
 
 
 for _ in range(100):
     ray.get(foo.remote())
     time.sleep(0.1)
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='4' author='stephanie-wang' date='2020-06-02T01:22:47Z'>
 		&lt;denchmark-link:https://github.com/stephanie-wang&gt;@stephanie-wang&lt;/denchmark-link&gt;
  We should find an assignee for this task as it is a release blocker. I will post it in the slack channel!!
 		</comment>
 		<comment id='5' author='stephanie-wang' date='2020-06-02T06:22:08Z'>
 		After this PR is merged, &lt;denchmark-link:https://github.com/ray-project/ray/pull/8401/files&gt;https://github.com/ray-project/ray/pull/8401/files&lt;/denchmark-link&gt;
 , we stopped using AsyncAppend, but we started using Put. This makes this part of code incompatible. &lt;denchmark-link:https://github.com/ffbin&gt;@ffbin&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='6' author='stephanie-wang' date='2020-06-02T06:26:08Z'>
 		I think we should be careful when we start using the store_client next time because it seems like it will change some storing mechanism. =&gt; Seems like autoscaler tests are more like "unit tests".
 		</comment>
 		<comment id='7' author='stephanie-wang' date='2020-06-02T11:35:11Z'>
 		&lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
  Thanks! dashboard.py is also need change, i'll add comments to your PR.
 		</comment>
 		<comment id='8' author='stephanie-wang' date='2020-06-02T16:16:48Z'>
 		&lt;denchmark-link:https://github.com/ffbin&gt;@ffbin&lt;/denchmark-link&gt;
  Thanks for finding that out!
 		</comment>
 	</comments>
 </bug>
<commit id='7c4399110045158daa280be2f6545adc7e03ffa5' author='SangBin Cho' date='2020-06-02 16:06:36-07:00'>
 	<dmm_unit complexity='0.9473684210526315' interfacing='1.0' size='0.10526315789473684'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\ray\dashboard\dashboard.py' new_name='python\ray\dashboard\dashboard.py'>
 		<file_info nloc='1038' complexity='189' token_count='7243'></file_info>
 		<method name='run' parameters='self'>
 				<method_info nloc='76' complexity='8' token_count='608' nesting_level='1' start_line='788' end_line='870'></method_info>
 			<added_lines>847,848</added_lines>
 			<deleted_lines>847</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\monitor.py' new_name='python\ray\monitor.py'>
 		<file_info nloc='224' complexity='40' token_count='1180'></file_info>
 		<method name='xray_job_notification_handler' parameters='self,unused_channel,data'>
 				<method_info nloc='9' complexity='2' token_count='64' nesting_level='1' start_line='117' end_line='131'></method_info>
 			<added_lines>124,125</added_lines>
 			<deleted_lines>124,125</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\state.py' new_name='python\ray\state.py'>
 		<file_info nloc='546' complexity='102' token_count='3223'></file_info>
 		<method name='actor_table' parameters='self,actor_id'>
 				<method_info nloc='20' complexity='4' token_count='125' nesting_level='1' start_line='205' end_line='235'></method_info>
 			<added_lines>219</added_lines>
 			<deleted_lines>219</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tests\test_global_state.py' new_name='python\ray\tests\test_global_state.py'>
 		<file_info nloc='98' complexity='15' token_count='646'></file_info>
 		<method name='test_global_state_actor_entry' parameters='ray_start_regular'>
 				<method_info nloc='16' complexity='1' token_count='148' nesting_level='0' start_line='109' end_line='128'></method_info>
 			<added_lines>109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_global_state_actor_entry.ready' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='6' nesting_level='2' start_line='112' end_line='113'></method_info>
 			<added_lines>112,113</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>129,130</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
