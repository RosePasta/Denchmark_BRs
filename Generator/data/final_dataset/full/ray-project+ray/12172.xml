<bug_data>
<bug id='12172' author='tuxa' open_date='2020-11-19T19:49:22Z' closed_time='2020-11-23T22:29:42Z'>
 	<summary>[tune] PBT checkpoints are not synced to head in GCP using Docker</summary>
 	<description>
 &lt;denchmark-h:h3&gt;System&lt;/denchmark-h&gt;
 
 Using the instance image and docker image from the example config:
 Image: projects/deeplearning-platform-release/global/images/family/tf-1-13-cpu
 Docker Image:  rayproject/ray:latest-gpu
 Ubuntu 18.04
 ray 1.0.1
 python 3.7.7
 Following dependencies are also installed:
 torch==1.7.0
 pytorch-lightning==1.0.6
 torchvision==0.8.1
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 I am trying to deploy the tune-pytorch-lightning with population based training example on the GCP (dockerized). The checkpoints are stored in /root/ray_results/tune_mnist_pbt, but after the perturbation interval, new folders get created directly in  /root/ray_results (e.g. /root/ray_results/2020-11-19_11-26-16i3yoquuf )  to use the weights of the highest performing experiment. The problem is that this folders dont get synced from the workers to the head when doing distributed training on GCP, whereas everything in /root/ray_results/tune_mnist_pbt/ gets synced:
 &lt;denchmark-code&gt;2020-11-19 19:42:27,243 VINFO updater.py:460 -- `rsync`ed /root/ray_results/tune_mnist_pbt/DEFAULT_1d092_00006_6_layer_1_size=128,layer_2_size=64_2020-11-19_19-41-58/ (remote) to /root/ray_results/tune_mn
 ist_pbt/DEFAULT_1d092_00006_6_layer_1_size=128,layer_2_size=64_2020-11-19_19-41-58/ (local)                                                                                                                 
 2020-11-19 19:42:27,247 ERROR trial_runner.py:868 -- Trial DEFAULT_1d092_00006: Error handling checkpoint /root/ray_results/2020-11-19_19-42-24w11y5gdl/checkpoint_1/                                       
 Traceback (most recent call last):
   File "/root/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 864, in _process_trial_save
     trial.on_checkpoint(trial.saving_to)
   File "/root/anaconda3/lib/python3.7/site-packages/ray/tune/trial.py", line 498, in on_checkpoint
     self, checkpoint.value))
 ray.tune.error.TuneError: Trial DEFAULT_1d092_00006: Checkpoint path /root/ray_results/2020-11-19_19-42-24w11y5gdl/checkpoint_1/ not found after successful sync down.
 2020-11-19 19:42:27,250 WARNING util.py:140 -- The `process_trial_save` operation took 1.05049467086792 seconds to complete, which may be a performance bottleneck.
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 Please use ray_cluster.yaml and tune_plt.py to reproduce the issue:
 &lt;denchmark-code&gt;# spawns 1 head and 1 worker
 ray up ray_cluster.yaml -y
 
 # submits ray_cluster.yaml. after the first epoch of the worker node the error can be seen in the terminal
 ray submit ray_cluster.yaml tune_pl.py  --start
 &lt;/denchmark-code&gt;
 
 ray_cluster.yaml
 (set project_id)
 &lt;denchmark-code&gt;cluster_name: default
 min_workers: 1
 max_workers: 1
 initial_workers: 1
 autoscaling_mode: default
 
 docker:
     image: "rayproject/ray:latest-gpu"
     container_name: "ray_container"
 
     pull_before_run: True
     run_options: []
 
 target_utilization_fraction: 0.8
 idle_timeout_minutes: 10
 
 provider:
     type: gcp
     region: europe-west4
     availability_zone: europe-west4-b
     project_id: null
 
 auth:
     ssh_user: ubuntu
 
 head_node:
     machineType: n1-standard-2
     disks:
       - boot: true
         autoDelete: true
         type: PERSISTENT
         initializeParams:
           diskSizeGb: 50
           sourceImage: projects/deeplearning-platform-release/global/images/family/tf-1-13-cpu
     scheduling:
       - onHostMaintenance: TERMINATE
 
 worker_nodes:
     machineType: n1-standard-2
     disks:
       - boot: true
         autoDelete: true
         type: PERSISTENT
         initializeParams:
           diskSizeGb: 50
           sourceImage: projects/deeplearning-platform-release/global/images/family/tf-1-13-cpu
     scheduling:
       - onHostMaintenance: TERMINATE
 
 cluster_synced_files: []
 file_mounts_sync_continuously: True
 initialization_commands: []
 
 rsync_exclude:
     - "**/.git"
     - "**/.git/**"
 
 
 rsync_filter:
     - ".gitignore"
 
 setup_commands:
   - pip install torch==1.7.0
   - pip install pytorch-lightning==1.0.6
   - pip install torchvision==0.8.1
 
 head_setup_commands:
   - pip install google-api-python-client==1.7.8
 
 worker_setup_commands: []
 
 head_start_ray_commands:
     - ray stop
     - &gt;-
       ulimit -n 65536;
       ray start
       --head
       --port=6379
       --object-manager-port=8076
       --autoscaling-config=~/ray_bootstrap_config.yaml
 
 worker_start_ray_commands:
     - ray stop
     - &gt;-
       ulimit -n 65536;
       ray start
       --address=$RAY_HEAD_IP:6379
       --object-manager-port=8076
 
 &lt;/denchmark-code&gt;
 
 tune_pl.py
 &lt;denchmark-code&gt;import torch
 import pytorch_lightning as pl
 from torch.utils.data import DataLoader, random_split
 from torch.nn import functional as F
 from torchvision.datasets import MNIST
 from torchvision import transforms
 import os
 
 import shutil
 from functools import partial
 from tempfile import mkdtemp
 from pytorch_lightning.loggers import TensorBoardLogger
 from pytorch_lightning.utilities.cloud_io import load as pl_load
 from ray import tune
 import ray
 from ray.tune.integration.docker import DockerSyncer
 from ray.tune import CLIReporter
 from ray.tune.schedulers import PopulationBasedTraining
 from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback
 
 class LightningMNISTClassifier(pl.LightningModule):
     """
     This has been adapted from
     https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09
     """
 
     def __init__(self, config, data_dir=None):
         super(LightningMNISTClassifier, self).__init__()
 
         self.data_dir = data_dir or os.getcwd()
 
         self.layer_1_size = config["layer_1_size"]
         self.layer_2_size = config["layer_2_size"]
         self.lr = config["lr"]
         self.batch_size = config["batch_size"]
 
         # mnist images are (1, 28, 28) (channels, width, height)
         self.layer_1 = torch.nn.Linear(28 * 28, self.layer_1_size)
         self.layer_2 = torch.nn.Linear(self.layer_1_size, self.layer_2_size)
         self.layer_3 = torch.nn.Linear(self.layer_2_size, 10)
 
     def forward(self, x):
         batch_size, channels, width, height = x.size()
         x = x.view(batch_size, -1)
 
         x = self.layer_1(x)
         x = torch.relu(x)
 
         x = self.layer_2(x)
         x = torch.relu(x)
 
         x = self.layer_3(x)
         x = torch.log_softmax(x, dim=1)
 
         return x
 
     def cross_entropy_loss(self, logits, labels):
         return F.nll_loss(logits, labels)
 
     def accuracy(self, logits, labels):
         _, predicted = torch.max(logits.data, 1)
         correct = (predicted == labels).sum().item()
         accuracy = correct / len(labels)
         return torch.tensor(accuracy)
 
     def training_step(self, train_batch, batch_idx):
         x, y = train_batch
         logits = self.forward(x)
         loss = self.cross_entropy_loss(logits, y)
         accuracy = self.accuracy(logits, y)
 
         self.log("ptl/train_loss", loss)
         self.log("ptl/train_accuracy", accuracy)
         return loss
 
     def validation_step(self, val_batch, batch_idx):
         x, y = val_batch
         logits = self.forward(x)
         loss = self.cross_entropy_loss(logits, y)
         accuracy = self.accuracy(logits, y)
         return {"val_loss": loss, "val_accuracy": accuracy}
 
     def validation_epoch_end(self, outputs):
         avg_loss = torch.stack([x["val_loss"] for x in outputs]).mean()
         avg_acc = torch.stack([x["val_accuracy"] for x in outputs]).mean()
         self.log("ptl/val_loss", avg_loss)
         self.log("ptl/val_accuracy", avg_acc)
 
 
     @staticmethod
     def download_data(data_dir):
         transform = transforms.Compose([
             transforms.ToTensor(),
             transforms.Normalize((0.1307, ), (0.3081, ))
         ])
         return MNIST(data_dir, train=True, download=True, transform=transform)
 
     def prepare_data(self):
         mnist_train = self.download_data(self.data_dir)
 
         self.mnist_train, self.mnist_val = random_split(
             mnist_train, [55000, 5000])
 
     def train_dataloader(self):
         return DataLoader(self.mnist_train, batch_size=int(self.batch_size))
 
     def val_dataloader(self):
         return DataLoader(self.mnist_val, batch_size=int(self.batch_size))
 
     def configure_optimizers(self):
         optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
         return optimizer
 
 def train_mnist_tune(config, data_dir=None, num_epochs=10, num_gpus=0):
     model = LightningMNISTClassifier(config, data_dir)
     trainer = pl.Trainer(
         max_epochs=num_epochs,
         gpus=num_gpus,
         logger=TensorBoardLogger(
             save_dir=tune.get_trial_dir(), name="", version="."),
         progress_bar_refresh_rate=0,
         callbacks=[
             TuneReportCallback(
                 {
                     "loss": "ptl/val_loss",
                     "mean_accuracy": "ptl/val_accuracy"
                 },
                 on="validation_end")
         ])
     trainer.fit(model)
 
 
 def train_mnist_tune_checkpoint(config,
                                 checkpoint_dir=None,
                                 data_dir=None,
                                 num_epochs=10):
 
     trainer = pl.Trainer(
         max_epochs=num_epochs,
         gpus=0,
         logger=TensorBoardLogger(
             save_dir=tune.get_trial_dir(), name="", version="."),
         progress_bar_refresh_rate=0,
         callbacks=[
             TuneReportCheckpointCallback(
                 metrics={
                     "loss": "ptl/val_loss",
                     "mean_accuracy": "ptl/val_accuracy"
                 },
                 filename="checkpoint",
                 on="validation_end")
         ])
     if checkpoint_dir:
         ckpt = pl_load(
             os.path.join(checkpoint_dir, "checkpoint"),
             map_location=lambda storage, loc: storage)
         model = LightningMNISTClassifier._load_model_state(ckpt, config=config)
         trainer.current_epoch = ckpt["epoch"]
     else:
         model = LightningMNISTClassifier(config=config, data_dir=data_dir)
 
     trainer.fit(model)
 
 
 def tune_mnist_pbt(num_samples=64, num_epochs=3):
 
     data_dir = mkdtemp(prefix="mnist_data_")
 
     LightningMNISTClassifier.download_data(data_dir)
 
     ray.init(address='auto')
 
     config = {
         "layer_1_size": tune.choice([32, 64, 128]),
         "layer_2_size": tune.choice([64, 128, 256]),
         "lr": 1e-3,
         "batch_size": 64,
     }
 
     scheduler = PopulationBasedTraining(
         time_attr="training_iteration",
         metric="loss",
         mode="min",
         perturbation_interval=1, # setting this to 1 so that the sync issue happens immediately after the first epoch
         hyperparam_mutations={
             "lr": tune.loguniform(1e-4, 1e-1),
             "batch_size": [32, 64, 128]
         })
 
     reporter = CLIReporter(
         parameter_columns=["layer_1_size", "layer_2_size", "lr", "batch_size"],
         metric_columns=["loss", "mean_accuracy", "training_iteration"])
 
     sync_config = tune.SyncConfig(
         sync_to_driver=DockerSyncer
     )
 
     tune.run(
         partial(
             train_mnist_tune_checkpoint,
             data_dir=data_dir,
             num_epochs=num_epochs),
         resources_per_trial={
             "cpu": 1,
             "gpu": 0
         },
         config=config,
         sync_config=sync_config,
         num_samples=num_samples,
         scheduler=scheduler,
         progress_reporter=reporter,
         fail_fast=True,
         queue_trials=True,
         reuse_actors=True,
         name="tune_mnist_pbt")
 
     shutil.rmtree(data_dir)
 
 if __name__ == '__main__':
     tune_mnist_pbt()
 &lt;/denchmark-code&gt;
 
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='tuxa' date='2020-11-19T20:03:56Z'>
 		cc &lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;
  it seems like the wrong checkpoint is being synced?
 		</comment>
 		<comment id='2' author='tuxa' date='2020-11-19T20:06:44Z'>
 		Yep, this looks odd. Thanks for raising this issue &lt;denchmark-link:https://github.com/tuxa&gt;@tuxa&lt;/denchmark-link&gt;
 , I'll look into this.
 		</comment>
 		<comment id='3' author='tuxa' date='2020-11-21T00:53:14Z'>
 		OK I'm able to repro this and found one of the key issues. It seems like on the trainable, we're not using a logger-creator and so the logdir that the trainable is using is different from expected:
 &lt;denchmark-code&gt;(pid=raylet, ip=172.31.63.45) 2020-11-21 00:33:00,087	INFO trainable.py:329 -- Restored on 172.31.63.45 from checkpoint: /root/ray_results/2020-11-21_00-32-59b631ud_k/tmpqd39pvc1restore_from_object/checkpoint
 &lt;/denchmark-code&gt;
 
 while the actual checkpoint should be:
 &lt;denchmark-code&gt;2020-11-21 00:33:02,820	DEBUG syncer.py:281 -- Syncing from ('172.31.63.45', '/root/ray_results/pbt_test/PBTBenchmarkExample_15f0c_00004_4_2020-11-21_00-32-50') to /root/ray_results/pbt_test/PBTBenchmarkExample_15f0c_00004_4_2020-11-21_00-32-50/
 &lt;/denchmark-code&gt;
 
 (with the PBTBenchmark prefix)
 		</comment>
 	</comments>
 </bug>
<commit id='e59fe65d3dee1803de2da5ab200059e992de7f9b' author='Richard Liaw' date='2020-11-23 14:29:41-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='doc\source\tune\user-guide.rst' new_name='doc\source\tune\user-guide.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>689</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\_private\cli_logger.py' new_name='python\ray\autoscaler\_private\cli_logger.py'>
 		<file_info nloc='419' complexity='73' token_count='2493'></file_info>
 		<method name='_set_verbosity' parameters='self,x'>
 				<method_info nloc='3' complexity='1' token_count='17' nesting_level='1' start_line='350' end_line='352'></method_info>
 			<added_lines>352</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='__init__' parameters='self'>
 				<method_info nloc='10' complexity='1' token_count='54' nesting_level='1' start_line='282' end_line='296'></method_info>
 			<added_lines>286</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='verbosity' parameters='self'>
 				<method_info nloc='6' complexity='3' token_count='26' nesting_level='1' start_line='343' end_line='348'></method_info>
 			<added_lines>344,345,346</added_lines>
 			<deleted_lines>343</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\_private\commands.py' new_name='python\ray\autoscaler\_private\commands.py'>
 		<file_info nloc='892' complexity='45' token_count='4963'></file_info>
 		<method name='rsync_to_node' parameters='node_id,is_head_node'>
 				<method_info nloc='32' complexity='5' token_count='166' nesting_level='1' start_line='947' end_line='980'></method_info>
 			<added_lines>975,976,977</added_lines>
 			<deleted_lines>975,976</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\sdk.py' new_name='python\ray\autoscaler\sdk.py'>
 		<file_info nloc='216' complexity='15' token_count='816'></file_info>
 		<method name='configure_logging' parameters='None,None,None'>
 				<method_info nloc='3' complexity='1' token_count='30' nesting_level='0' start_line='210' end_line='212'></method_info>
 			<added_lines>210,211,212</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>13,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tune\examples\pbt_example.py' new_name='python\ray\tune\examples\pbt_example.py'>
 		<file_info nloc='104' complexity='8' token_count='504'></file_info>
 		<modified_lines>
 			<added_lines>88,89,90,91,93,94,95,96</added_lines>
 			<deleted_lines>89</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tune\integration\docker.py' new_name='python\ray\tune\integration\docker.py'>
 		<file_info nloc='89' complexity='8' token_count='400'></file_info>
 		<modified_lines>
 			<added_lines>5,8,17,18,19,42,43,44</added_lines>
 			<deleted_lines>5</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tune\ray_trial_executor.py' new_name='python\ray\tune\ray_trial_executor.py'>
 		<file_info nloc='538' complexity='129' token_count='3456'></file_info>
 		<modified_lines>
 			<added_lines>401,402</added_lines>
 			<deleted_lines>401,402</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tune\trainable.py' new_name='python\ray\tune\trainable.py'>
 		<file_info nloc='374' complexity='79' token_count='2279'></file_info>
 		<method name='reset' parameters='self,new_config,logger_creator'>
 				<method_info nloc='26' complexity='3' token_count='155' nesting_level='1' start_line='384' end_line='422'></method_info>
 			<added_lines>394,395,396,397,398,399</added_lines>
 			<deleted_lines>394</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
