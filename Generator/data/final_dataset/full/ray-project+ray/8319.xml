<bug_data>
<bug id='8319' author='ericl' open_date='2020-05-05T00:09:39Z' closed_time='2020-05-08T06:26:32Z'>
 	<summary>[rllib] Vectorization &amp; multi-agent are broken in DDPG (both TF and Torch)</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 ./train.py --run=DDPG --env=MountainCarContinuous-v0 --config='{"num_envs_per_worker": 2}'
 and
 ./train.py --run=DDPG --env=MountainCarContinuous-v0 --config='{"num_envs_per_worker": 2}' --torch
 both currently crash. The issue seems to be that while the input to compute_actions() is a batch of N observations, only 1 action is returned as output. I ran into this while debugging a hang in a multi-agent test case (hung due to a bug in the env triggered by vectorization returning 1 action instead of N actions).
 	</description>
 	<comments>
 		<comment id='1' author='ericl' date='2020-05-05T00:48:34Z'>
 		git bisect run script.sh
 script:
 &lt;denchmark-code&gt;cd python
 sudo SKIP_THIRDPARTY_INSTALL=1 SKIP_PYARROW_INSTALL=1 python setup.py develop
 cd -
 cd rllib
 ./train.py --run=DDPG --env=MountainCarContinuous-v0 --config='{"num_envs_per_worker": 2}' --stop='{"timesteps_total": 1}'
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;83e06cd30a45245c2cb0e9f4bd924224b1581554 is the first bad commit
 commit 83e06cd30a45245c2cb0e9f4bd924224b1581554
 Author: Sven Mika &lt;sven@anyscale.io&gt;
 Date:   Sun Mar 1 20:53:35 2020 +0100
 
     [RLlib] DDPG refactor and Exploration API action noise classes. (#7314)
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='2' author='ericl' date='2020-05-05T00:48:54Z'>
 		&lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
  probably some trivial bug in the new ddpg pol that breaks batching
 		</comment>
 		<comment id='3' author='ericl' date='2020-05-05T06:14:34Z'>
 		Taking a look ...
 		</comment>
 		<comment id='4' author='ericl' date='2020-05-05T09:30:04Z'>
 		Got it, will PR today ...
 		</comment>
 		<comment id='5' author='ericl' date='2020-05-05T13:11:04Z'>
 		Here is the PR that fixes this issue: &lt;denchmark-link:https://github.com/ray-project/ray/pull/8324&gt;#8324&lt;/denchmark-link&gt;
 
 Problem was that Random did not batch  properly (only single item batches produced).
 I also removed the  dependency from the Random exploration class and fixed the torch side as well.
 		</comment>
 		<comment id='6' author='ericl' date='2020-05-05T13:12:31Z'>
 		Leaving this open until merged.
 		</comment>
 	</comments>
 </bug>
<commit id='d7eaacb5fe4188f680c19ae26fa5d0074241ebc4' author='Sven Mika' date='2020-05-08 08:26:32+02:00'>
 	<dmm_unit complexity='0.2727272727272727' interfacing='1.0' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='rllib\agents\ddpg\tests\test_ddpg.py' new_name='rllib\agents\ddpg\tests\test_ddpg.py'>
 		<file_info nloc='395' complexity='57' token_count='2856'></file_info>
 		<method name='test_ddpg_compilation' parameters='self'>
 				<method_info nloc='10' complexity='3' token_count='77' nesting_level='1' start_line='21' end_line='34'></method_info>
 			<added_lines>25,30</added_lines>
 			<deleted_lines>29</deleted_lines>
 		</method>
 		<method name='test_ddpg_loss_function' parameters='self'>
 				<method_info nloc='225' complexity='41' token_count='1429' nesting_level='1' start_line='87' end_line='370'></method_info>
 			<added_lines>370</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>371</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\examples\env\simple_corridor.py' new_name='rllib\examples\env\simple_corridor.py'>
 		<file_info nloc='26' complexity='8' token_count='194'></file_info>
 		<method name='step' parameters='self,action'>
 				<method_info nloc='8' complexity='5' token_count='73' nesting_level='1' start_line='25' end_line='32'></method_info>
 			<added_lines>28,30</added_lines>
 			<deleted_lines>25,31</deleted_lines>
 		</method>
 		<method name='set_corridor_length' parameters='self,length'>
 				<method_info nloc='5' complexity='1' token_count='48' nesting_level='1' start_line='18' end_line='22'></method_info>
 			<added_lines>22</added_lines>
 			<deleted_lines>20,21</deleted_lines>
 		</method>
 		<method name='reset' parameters='self'>
 				<method_info nloc='3' complexity='1' token_count='18' nesting_level='1' start_line='21' end_line='23'></method_info>
 			<added_lines>22</added_lines>
 			<deleted_lines>21</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,config'>
 				<method_info nloc='5' complexity='1' token_count='55' nesting_level='1' start_line='11' end_line='15'></method_info>
 			<added_lines>15</added_lines>
 			<deleted_lines>15</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>16,33</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\models\tf\tf_action_dist.py' new_name='rllib\models\tf\tf_action_dist.py'>
 		<file_info nloc='391' complexity='79' token_count='3045'></file_info>
 		<method name='required_model_output_shape' parameters='action_space,model_config'>
 				<method_info nloc='2' complexity='1' token_count='18' nesting_level='1' start_line='331' end_line='332'></method_info>
 			<added_lines>331,332</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>329,330,333,379,380,381,382,383</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\tests\test_multi_agent_pendulum.py' new_name='rllib\tests\test_multi_agent_pendulum.py'>
 		<file_info nloc='49' complexity='5' token_count='270'></file_info>
 		<method name='test_multi_agent_pendulum' parameters='self'>
 				<method_info nloc='33' complexity='3' token_count='170' nesting_level='1' start_line='18' end_line='52'></method_info>
 			<added_lines>21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,48,49,50,51,52</added_lines>
 			<deleted_lines>20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,41,42,43,44,45,46,47</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>7,8</added_lines>
 			<deleted_lines>5</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\utils\exploration\random.py' new_name='rllib\utils\exploration\random.py'>
 		<file_info nloc='101' complexity='17' token_count='705'></file_info>
 		<method name='__init__' parameters='self,action_space,model,framework,kwargs'>
 				<method_info nloc='8' complexity='1' token_count='48' nesting_level='1' start_line='26' end_line='40'></method_info>
 			<added_lines>39,40</added_lines>
 			<deleted_lines>38,39,40</deleted_lines>
 		</method>
 		<method name='get_tf_exploration_action_op.true_fn' parameters=''>
 				<method_info nloc='11' complexity='2' token_count='72' nesting_level='2' start_line='57' end_line='94'></method_info>
 			<added_lines>58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94</added_lines>
 			<deleted_lines>62,63,64,65,68,69,84,85,86,90,92</deleted_lines>
 		</method>
 		<method name='get_tf_exploration_action_op.false_fn' parameters=''>
 				<method_info nloc='2' complexity='1' token_count='10' nesting_level='2' start_line='96' end_line='97'></method_info>
 			<added_lines>97</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_torch_exploration_action' parameters='self,action_dist,explore'>
 				<method_info nloc='17' complexity='4' token_count='150' nesting_level='1' start_line='110' end_line='128'></method_info>
 			<added_lines>115,117,118,119,120,121,122</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='get_tf_exploration_action_op.get_tf_exploration_action_op.true_fn.random_component' parameters='component'>
 				<method_info nloc='23' complexity='6' token_count='169' nesting_level='3' start_line='68' end_line='90'></method_info>
 			<added_lines>68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90</added_lines>
 			<deleted_lines>68,69,84,85,86,90</deleted_lines>
 		</method>
 		<method name='get_tf_exploration_action_op' parameters='self,action_dist,explore'>
 				<method_info nloc='11' complexity='2' token_count='93' nesting_level='1' start_line='56' end_line='108'></method_info>
 			<added_lines>58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,97</added_lines>
 			<deleted_lines>62,63,64,65,68,69,84,85,86,90,92</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1,12</added_lines>
 			<deleted_lines>1,41,42,43,44</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
