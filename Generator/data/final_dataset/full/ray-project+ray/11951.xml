<bug_data>
<bug id='11951' author='krfricke' open_date='2020-11-11T19:31:25Z' closed_time='2020-11-13T01:22:43Z'>
 	<summary>[autoscaler] restarting ray with `ray up` switches object store location from /dev/shm to /tmp</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 Restarting the ray runtime on a cluster that uses docker with shm moves the plasma object store location to /tmp.
 After starting the cluster the first time (scroll to end):
 &lt;denchmark-code&gt;# ps aux | grep plasma_directory
 root        8435  1.3  0.0 979289612 67788 ?     Sl   11:24   0:03 /root/anaconda3/lib/python3.7/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/tmp/ray/session_2020-11-11_11-24-02_969644_8401/sockets/raylet --store_socket_name=/tmp/ray/session_2020-11-11_11-24-02_969644_8401/sockets/plasma_store --object_manager_port=8076 --min_worker_port=10000 --max_worker_port=10999 --node_manager_port=63984 --node_ip_address=172.31.16.137 --redis_address=172.31.16.137 --redis_port=6379 --num_initial_workers=64 --maximum_startup_concurrency=64 --static_resource_list=node:172.31.16.137,1.0,CPU,64,memory,455,object_store_memory,6580 --config_list=plasma_store_as_thread,True --python_worker_command=/root/anaconda3/bin/python /root/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py --node-ip-address=172.31.16.137 --node-manager-port=63984 --object-store-name=/tmp/ray/session_2020-11-11_11-24-02_969644_8401/sockets/plasma_store --raylet-name=/tmp/ray/session_2020-11-11_11-24-02_969644_8401/sockets/raylet --redis-address=172.31.16.137:6379 --config-list=plasma_store_as_thread,True --temp-dir=/tmp/ray --metrics-agent-port=41883 --redis-password=5241590000000000 --java_worker_command= --cpp_worker_command= --redis_password=5241590000000000 --temp_dir=/tmp/ray --session_dir=/tmp/ray/session_2020-11-11_11-24-02_969644_8401 --metrics-agent-port=41883 --metrics_export_port=63079 --object_store_memory=500000000000 --plasma_directory=/dev/shm --head_node
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-code&gt;ray up -y issue.yaml
 &lt;/denchmark-code&gt;
 
 After restarting (scroll to end):
 &lt;denchmark-code&gt;root       13477  3.1  0.0 491008224 67388 ?     Sl   11:29   0:00 /root/anaconda3/lib/python3.7/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/tmp/ray/session_2020-11-11_11-29-30_982983_13439/sockets/raylet --store_socket_name=/tmp/ray/session_2020-11-11_11-29-30_982983_13439/sockets/plasma_store --object_manager_port=8076 --min_worker_port=10000 --max_worker_port=10999 --node_manager_port=53349 --node_ip_address=172.31.16.137 --redis_address=172.31.16.137 --redis_port=6379 --num_initial_workers=64 --maximum_startup_concurrency=64 --static_resource_list=node:172.31.16.137,1.0,CPU,64,memory,455,object_store_memory,6580 --config_list=plasma_store_as_thread,True --python_worker_command=/root/anaconda3/bin/python /root/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py --node-ip-address=172.31.16.137 --node-manager-port=53349 --object-store-name=/tmp/ray/session_2020-11-11_11-29-30_982983_13439/sockets/plasma_store --raylet-name=/tmp/ray/session_2020-11-11_11-29-30_982983_13439/sockets/raylet --redis-address=172.31.16.137:6379 --config-list=plasma_store_as_thread,True --temp-dir=/tmp/ray --metrics-agent-port=60879 --redis-password=5241590000000000 --java_worker_command= --cpp_worker_command= --redis_password=5241590000000000 --temp_dir=/tmp/ray --session_dir=/tmp/ray/session_2020-11-11_11-29-30_982983_13439 --metrics-agent-port=60879 --metrics_export_port=50207 --object_store_memory=500000000000 --plasma_directory=/tmp --head_node
 root       14852  0.0  0.0   5192  2412 pts/10   S+   11:29   0:00 grep --color=auto plasma_directory
 &lt;/denchmark-code&gt;
 
 issue.yaml
 &lt;denchmark-code&gt;cluster_name: stale_ref_issue
 min_workers: 0
 max_workers: 0
 initial_workers: 0
 autoscaling_mode: default
 docker:
     image: 'anyscale/ray-ml:latest'
     container_name: ray_container
     pull_before_run: false
     run_options:
         - --privileged
         - --shm-size=510000000000
 target_utilization_fraction: 0.8
 idle_timeout_minutes: 5
 provider:
     type: aws
     region: us-west-2
     availability_zone: us-west-2a
     # cache_stopped_nodes: false
 auth:
     ssh_user: ubuntu
 head_node:
     InstanceType: r5.16xlarge
     ImageId: ami-05ac7a76b4c679a79
 
 worker_nodes:
     InstanceType: m5.xlarge
     ImageId: ami-05ac7a76b4c679a79
     InstanceMarketOptions:
         MarketType: spot
 file_mounts: {
     "/root/xgboost-benchmark": "/Users/kai/coding/anyscale/projects/xgboost-benchmark",
 }
 cluster_synced_files:
     - /tmp/ray_tmp_mount/~/xgboost-benchmark
 file_mounts_sync_continuously: true
 initialization_commands: []
 setup_commands: []
 head_setup_commands: 
     - apt install -y lsof
 worker_setup_commands: []
 head_start_ray_commands:
     - ray stop
     - "ulimit -n 65536; ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml --object-store-memory=500000000000 --resources='{\"actor_cpus\": 0}'"
 worker_start_ray_commands:
     - ray stop
     - "ulimit -n 65536; ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076 --resources='{\"actor_cpus\": 4}'"
 metadata:
     anyscale:
         working_dir: ~/xgboost-benchmark
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
 If we cannot run your script, we cannot fix your issue.
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='krfricke' date='2020-11-11T20:13:07Z'>
 		What is the output near the actual  ray start ?
 Is there a message like:
 &lt;denchmark-code&gt;2020-11-11 20:12:52,890 WARNING services.py:1625 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='2' author='krfricke' date='2020-11-11T21:36:19Z'>
 		Yep, there is:
 &lt;denchmark-code&gt;2020-11-11 11:29:31,384	INFO services.py:1166 -- View the Ray dashboard at http://localhost:8265
 2020-11-11 11:29:31,386	WARNING services.py:1625 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 477999988736 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='3' author='krfricke' date='2020-11-11T21:38:04Z'>
 		&lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;
  Was the cluster up when you added the ? You might need to  and  again if that is the case.
 		</comment>
 		<comment id='4' author='krfricke' date='2020-11-11T22:06:42Z'>
 		Yes it was. I think this is actually related to &lt;denchmark-link:https://github.com/ray-project/ray/issues/11950&gt;#11950&lt;/denchmark-link&gt;
 :  is still occupied by 30 GB of stale file handles, which are cleared only after ray is restarted.
 Is the size of /dev/shm checked after ?
 		</comment>
 		<comment id='5' author='krfricke' date='2020-11-11T22:34:15Z'>
 		&lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;
  Oh shoot! I meant  from your laptop to tear the cluster down.
 		</comment>
 		<comment id='6' author='krfricke' date='2020-11-12T09:25:31Z'>
 		Yes, that works. However I was under the impression that running ray up on a running cluster is a viable way to just restart the ray runtime (and run setup commands etc), in fact I was using this quite a lot to save time on node startups.
 		</comment>
 		<comment id='7' author='krfricke' date='2020-11-12T16:16:48Z'>
 		ray up will restart the ray runtime, but to change docker configuration (i.e. add --shm-size), you need to restart the docker runtime :/
 		</comment>
 		<comment id='8' author='krfricke' date='2020-11-12T16:22:30Z'>
 		So the problem here is that I didn't change anything. I.e. --shm-size was set all the time, but only lead to using /dev/shm on the first start, not the second. Though it seems this is just due to /dev/shm still  being occupied by the object spilled from the last session.
 		</comment>
 	</comments>
 </bug>
<commit id='3b56a1a5220fe0c3b522cff43dbb6ef7e33bfd99' author='Ian Rodney' date='2020-11-12 17:22:42-08:00'>
 	<dmm_unit complexity='0.96' interfacing='0.96' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='doc\source\installation.rst' new_name='doc\source\installation.rst'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>281,282</added_lines>
 			<deleted_lines>281</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\_private\command_runner.py' new_name='python\ray\autoscaler\_private\command_runner.py'>
 		<file_info nloc='626' complexity='104' token_count='3882'></file_info>
 		<method name='run_init' parameters='self,as_head,file_mounts'>
 				<method_info nloc='71' complexity='13' token_count='448' nesting_level='1' start_line='684' end_line='766'></method_info>
 			<added_lines>722,723</added_lines>
 			<deleted_lines>719,720</deleted_lines>
 		</method>
 		<method name='_auto_configure_shm' parameters='self'>
 				<method_info nloc='19' complexity='5' token_count='114' nesting_level='1' start_line='787' end_line='806'></method_info>
 			<added_lines>787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>15,16,17,807</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\_private\constants.py' new_name='python\ray\autoscaler\_private\constants.py'>
 		<file_info nloc='20' complexity='2' token_count='109'></file_info>
 		<modified_lines>
 			<added_lines>4,5</added_lines>
 			<deleted_lines>4</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\ray-schema.json' new_name='python\ray\autoscaler\ray-schema.json'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>245,246,247,248,249</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\ray_constants.py' new_name='python\ray\ray_constants.py'>
 		<file_info nloc='116' complexity='12' token_count='492'></file_info>
 		<modified_lines>
 			<added_lines>27,28</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\resource_spec.py' new_name='python\ray\resource_spec.py'>
 		<file_info nloc='228' complexity='51' token_count='1125'></file_info>
 		<method name='resolve' parameters='self,is_head,node_ip_address'>
 				<method_info nloc='77' complexity='18' token_count='424' nesting_level='1' start_line='128' end_line='229'></method_info>
 			<added_lines>182,183,184</added_lines>
 			<deleted_lines>182</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tests\test_autoscaler.py' new_name='python\ray\tests\test_autoscaler.py'>
 		<file_info nloc='1360' complexity='138' token_count='8629'></file_info>
 		<method name='testAutodetectResources' parameters='self'>
 				<method_info nloc='29' complexity='1' token_count='152' nesting_level='1' start_line='1519' end_line='1548'></method_info>
 			<added_lines>1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1549</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
