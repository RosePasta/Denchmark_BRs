<bug_data>
<bug id='9326' author='Nintorac' open_date='2020-07-07T05:13:17Z' closed_time='2020-09-01T20:14:36Z'>
 	<summary>[autoscaler/docker] file_mounts fail when permissions required to create the host directory</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 Ray nightly.
 When trying to create a file mount for the home directory of a container i.e. /root/, cluster creation fails because the host tries to write to /root/ which it does not have permission to do.
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 Use the following cluster.yml
 &lt;denchmark-code&gt;# An unique identifier for the head node and workers of this cluster.
 cluster_name: default
 
 # The minimum number of workers nodes to launch in addition to the head
 # node. This number should be &gt;= 0.
 min_workers: 0
 
 # The maximum number of workers nodes to launch in addition to the head
 # node. This takes precedence over min_workers.
 max_workers: 1
 
 # The initial number of worker nodes to launch in addition to the head
 # node. When the cluster is first brought up (or when it is refreshed with a
 # subsequent `ray up`) this number of nodes will be started.
 initial_workers: 0
 
 # Whether or not to autoscale aggressively. If this is enabled, if at any point
 #   we would start more workers, we start at least enough to bring us to
 #   initial_workers.
 autoscaling_mode: default
 
 # This executes all commands on all nodes in the docker container,
 # and opens all the necessary ports to support the Ray cluster.
 # Empty string means disabled.
 docker:
     image: tensorflow/tensorflow:1.5.0-py3
     container_name: "ray_docker" # e.g. ray_docker
     # If true, pulls latest version of image. Otherwise, `docker run` will only pull the image
     # if no cached version is present.
     # pull_before_run: False
     pull_before_run: True
 
     run_options: []
 
     # # Example of running a GPU head with CPU workers
     # head_image: "tensorflow/tensorflow:1.13.1-gpu-py3"
     head_run_options:  []
     worker_run_options:
         - --runtime=nvidia
 
     # worker_image: "ubuntu:18.04"
 
 
     # run_options:
     #   - --runtime=nvidia
 
 # The autoscaler will scale up the cluster to this target fraction of resource
 # usage. For example, if a cluster of 10 nodes is 100% busy and
 # target_utilization is 0.8, it would resize the cluster to 13. This fraction
 # can be decreased to increase the aggressiveness of upscaling.
 # This value must be less than 1.0 for scaling to happen.
 target_utilization_fraction: 0.8
 
 # If a node is idle for this many minutes, it will be removed.
 idle_timeout_minutes: 5
 
 # Cloud-provider specific configuration.
 provider:
     type: gcp
     region: us-central1
     availability_zone: us-central1-a
     project_id: ray # Globally unique project id
 
 # How Ray will authenticate with newly launched nodes.
 auth:
     ssh_user: ubuntu
 # By default Ray creates a new private keypair, but you can also use your own.
 # If you do so, make sure to also set "KeyName" in the head and worker node
 # configurations below. This requires that you have added the key into the
 # project wide meta-data.
 #    ssh_private_key: /path/to/your/key.pem
 
 # Provider-specific config for the head node, e.g. instance type. By default
 # Ray will auto-configure unspecified fields such as subnets and ssh-keys.
 # For more documentation on available fields, see:
 # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert
 head_node:
     machineType: n1-standard-2
     disks:
       - boot: true
         autoDelete: true
         type: PERSISTENT
         initializeParams:
           diskSizeGb: 50
           # See https://cloud.google.com/compute/docs/images for more images
           diskType: https://www.googleapis.com/compute/v1/projects/ray/zones/us-central1-a/diskTypes/pd-ssd
           sourceImage: projects/deeplearning-platform-release/global/images/common-cu101-v20200630
     # Additional options can be found in in the compute docs at
     # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert
 
     # If the network interface is specified as below in both head and worker
     # nodes, the manual network config is used.  Otherwise an existing subnet is
     # used.  To use a shared subnet, ask the subnet owner to grant permission
     # for 'compute.subnetworks.use' to the ray autoscaler account...
     # networkInterfaces:
     #   - kind: compute#networkInterface
     #     subnetwork: path/to/subnet
     #     aliasIpRanges: []
 
 worker_nodes:
     machineType: n1-standard-8
     disks:
       - boot: true
         autoDelete: true
         type: PERSISTENT
         initializeParams:
           diskSizeGb: 50
           # See https://cloud.google.com/compute/docs/images for more images
           sourceImage: projects/deeplearning-platform-release/global/images/common-cu101-v20200630
           diskType: https://www.googleapis.com/compute/v1/projects/ray/zones/us-west1-a/diskTypes/pd-ssd
     guestAccelerators:
       - acceleratorType: projects/ray/zones/us-central1-a/acceleratorTypes/nvidia-tesla-k80
         acceleratorCount: 1
     metadata:
       items:
         - key: install-nvidia-driver
           value: "True"
     # Run workers on preemtible instance by default.
     # Comment this out to use on-demand.
     scheduling:
       # - preemptible: true
       - onHostMaintenance: TERMINATE
     serviceAccounts:
       - email: ray-worker@ray.iam.gserviceaccount.com
         scopes: ["https://www.googleapis.com/auth/cloud-platform"]
       
     # Additional options can be found in in the compute docs at
     # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert
 
 # Files or directories to copy to the head and worker nodes. The format is a
 # dictionary from REMOTE_PATH: LOCAL_PATH, e.g.
 file_mounts: {
     "/root/data/": "data/",
 }
 
 # List of commands that will be run before `setup_commands`. If docker is
 # enabled, these commands will run outside the container and before docker
 # is setup.
 initialization_commands: []
 
 # List of shell commands to run to set up nodes.
 setup_commands:
   - pip install ray[tune]
     # Note: if you're developing Ray, you probably want to create an AMI that
     # has your Ray repo pre-cloned. Then, you can replace the pip installs
     # below with a git checkout &lt;your_sha&gt; (and possibly a recompile).
     # - echo 'export PATH="$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH"' &gt;&gt; ~/.bashrc
 
     # Install Anaconda.
     # - &gt;-
     #   wget https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh -O ~/anaconda3.sh
     #   || true
     #   &amp;&amp; bash ~/anaconda3.sh -b -p ~/anaconda3 || true
     #   &amp;&amp; rm ~/anaconda3.sh
     #   &amp;&amp; echo 'export PATH="$HOME/anaconda3/bin:$PATH"' &gt;&gt; ~/.profile
 
     # # Install ray
     # # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp27-cp27mu-manylinux1_x86_64.whl
     # # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp35-cp35m-manylinux1_x86_64.whl
     # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl
 
 
 # Custom commands that will be run on the head node after common setup.
 head_setup_commands:
   - pip install google-api-python-client==1.7.8
 
 # Custom commands that will be run on worker nodes after common setup.
 worker_setup_commands: []
 
 
 # Command to start ray on the head node. You don't need to change this.
 head_start_ray_commands:
     - ray stop
     - &gt;-
       ulimit -n 65536;
       ray start
       --head
       --port=6379
       --object-manager-port=8076
       --autoscaling-config=~/ray_bootstrap_config.yaml
 
 # Command to start ray on worker nodes. You don't need to change this.
 worker_start_ray_commands:
     - ray stop
     - &gt;-
       ulimit -n 65536;
       ray start
       --address=$RAY_HEAD_IP:6379
       --object-manager-port=8076
 &lt;/denchmark-code&gt;
 
 results in the following error mkdir: cannot create directory ‘/root’: Permission denied
 full error output here
 &lt;denchmark-code&gt;2020-07-07 04:44:43,207 INFO updater.py:264 -- NodeUpdater: ray-default-head-7347dd6f: Running ssh -tt -i /home/nintorac/.ssh/ray-autoscaler_gcp_us-central1_ray-runner_ubuntu_0.pem -o ConnectTimeout=120s -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_9151b9c88a/c21f969b5f/%C -o ControlPersist=10s -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 ubuntu@34.66.223.160 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; mkdir -p /root/bistableGRU'
 mkdir: cannot create directory ‘/root’: Permission denied
 Shared connection to 34.66.223.160 closed.
 2020-07-07 04:44:43,891 INFO log_timer.py:22 -- NodeUpdater: ray-default-head-7347dd6f: Synced bistableGRU/ to /root/bistableGRU/  [LogTimer=683ms]
 2020-07-07 04:44:43,891 INFO log_timer.py:22 -- NodeUpdater: ray-default-head-7347dd6f: Applied config 9766e837de18583f489ebd562c12bb3d6ead4b5e  [LogTimer=13577ms]
 2020-07-07 04:44:44,497 INFO node_provider.py:21 -- wait_for_compute_zone_operation: Waiting for operation operation-1594097084024-5a9d2a66e4854-99e9b008-3f76ae9f to finish...
 2020-07-07 04:44:49,705 INFO node_provider.py:32 -- wait_for_compute_zone_operation: Operation operation-1594097084024-5a9d2a66e4854-99e9b008-3f76ae9f finished.
 2020-07-07 04:44:49,706 ERROR updater.py:441 -- NodeUpdater: ray-default-head-7347dd6f: Error executing: SSH command Failed. See above for the output from the failure.2020-07-07 04:44:49,817 ERROR commands.py:367 -- get_or_create_head_node: Updating 34.66.223.160 failed
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='Nintorac' date='2020-07-10T23:25:01Z'>
 		&lt;denchmark-link:https://github.com/ijrsvt&gt;@ijrsvt&lt;/denchmark-link&gt;
  Is it supposed to be closed?
 		</comment>
 		<comment id='2' author='Nintorac' date='2020-07-11T01:08:50Z'>
 		&lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
   The PR yes, this issue, no.
 The best workaround for trying to do
 &lt;denchmark-code&gt;file_mounts:
    "/root/item" : "/whatever/item"
 &lt;/denchmark-code&gt;
 
 is to do
 &lt;denchmark-code&gt;file_mounts:
    "/home/item" : "/local_whatever/item"
 
 docker:
    run_options:
        "-v /home/item:/root/item"
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='3' author='Nintorac' date='2020-08-31T12:53:38Z'>
 		One way to allow this to happen would be to have initialization_commands run before file mounts. If that is not feasible for some reason, maybe you could introduce preinitialization_commands.
 Inside these commands, the ray user could run whatever they want, such as sudo mkdir /whatever/directory, since presumably they would know whether or not the user running the ray commands has sudo access.
 		</comment>
 	</comments>
 </bug>
<commit id='283f4d1060060d3a10a62ac5d74c9ca45c596791' author='Ian Rodney' date='2020-09-01 13:14:35-07:00'>
 	<dmm_unit complexity='0.7926829268292683' interfacing='0.7804878048780488' size='0.06097560975609756'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\command_runner.py' new_name='python\ray\autoscaler\command_runner.py'>
 		<file_info nloc='585' complexity='81' token_count='3489'></file_info>
 		<method name='run_rsync_up' parameters='self,source,target,options'>
 				<method_info nloc='15' complexity='3' token_count='90' nesting_level='1' start_line='241' end_line='256'></method_info>
 			<added_lines>241</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='run_rsync_down' parameters='self,source,target,options'>
 				<method_info nloc='15' complexity='3' token_count='90' nesting_level='1' start_line='267' end_line='282'></method_info>
 			<added_lines>267</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='run_rsync_up' parameters='self,str,str,str,None'>
 				<method_info nloc='4' complexity='1' token_count='29' nesting_level='1' start_line='138' end_line='141'></method_info>
 			<added_lines>138,139,140,141</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='run_rsync_down' parameters='self,str,str,str,None'>
 				<method_info nloc='4' complexity='1' token_count='29' nesting_level='1' start_line='150' end_line='153'></method_info>
 			<added_lines>150,151,152,153</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='run_rsync_up' parameters='self,source,target'>
 				<method_info nloc='15' complexity='3' token_count='86' nesting_level='1' start_line='234' end_line='249'></method_info>
 			<added_lines>241</added_lines>
 			<deleted_lines>234</deleted_lines>
 		</method>
 		<method name='run_rsync_down' parameters='self,str,str'>
 				<method_info nloc='8' complexity='1' token_count='18' nesting_level='1' start_line='146' end_line='153'></method_info>
 			<added_lines>150,151,152,153</added_lines>
 			<deleted_lines>146</deleted_lines>
 		</method>
 		<method name='run_rsync_up' parameters='self,str,str'>
 				<method_info nloc='8' complexity='1' token_count='18' nesting_level='1' start_line='137' end_line='144'></method_info>
 			<added_lines>138,139,140,141</added_lines>
 			<deleted_lines>137</deleted_lines>
 		</method>
 		<method name='run_rsync_down' parameters='self,source,target'>
 				<method_info nloc='15' complexity='3' token_count='86' nesting_level='1' start_line='260' end_line='275'></method_info>
 			<added_lines>267</added_lines>
 			<deleted_lines>260</deleted_lines>
 		</method>
 		<method name='run_init' parameters='self,as_head,file_mounts'>
 				<method_info nloc='46' complexity='9' token_count='289' nesting_level='1' start_line='706' end_line='755'></method_info>
 			<added_lines>736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754</added_lines>
 			<deleted_lines>725,726,727,728,729</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>3,6,13,14,17,541,553,619,620,621,622,623,625,626,627,628,629,630,634,636,637,639,640,641,643,644,645,648,649,650,651,652,653</added_lines>
 			<deleted_lines>3,11,13,15,534,546,612,613,614,615,616,618,619,620,624,626,627,629,630,631,632,634,635,636,639,640,641,642</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\commands.py' new_name='python\ray\autoscaler\commands.py'>
 		<file_info nloc='852' complexity='44' token_count='4720'></file_info>
 		<modified_lines>
 			<added_lines>667,670,673,687</added_lines>
 			<deleted_lines>667,670,673,687</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\docker.py' new_name='python\ray\autoscaler\docker.py'>
 		<file_info nloc='62' complexity='16' token_count='421'></file_info>
 		<method name='docker_autoscaler_setup' parameters='cname'>
 				<method_info nloc='11' complexity='2' token_count='75' nesting_level='0' start_line='83' end_line='94'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>83,84,85,86,87,88,89,90,91,92,93,94</deleted_lines>
 		</method>
 		<method name='check_docker_image' parameters='cname'>
 				<method_info nloc='2' complexity='1' token_count='12' nesting_level='0' start_line='65' end_line='66'></method_info>
 			<added_lines>66</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='check_bind_mounts_cmd' parameters='cname'>
 				<method_info nloc='2' complexity='1' token_count='12' nesting_level='0' start_line='61' end_line='62'></method_info>
 			<added_lines>61,62</added_lines>
 			<deleted_lines>62</deleted_lines>
 		</method>
 		<method name='check_docker_running_cmd' parameters='cname'>
 				<method_info nloc='2' complexity='1' token_count='12' nesting_level='0' start_line='57' end_line='58'></method_info>
 			<added_lines>57,58</added_lines>
 			<deleted_lines>57,58</deleted_lines>
 		</method>
 		<method name='docker_start_cmds' parameters='user,image,mount_dict,cname,user_options'>
 				<method_info nloc='15' complexity='4' token_count='152' nesting_level='0' start_line='69' end_line='88'></method_info>
 			<added_lines>70</added_lines>
 			<deleted_lines>81,82,83,84,85,86,87,88</deleted_lines>
 		</method>
 		<method name='_check_helper' parameters='cname,template'>
 				<method_info nloc='5' complexity='1' token_count='32' nesting_level='0' start_line='50' end_line='54'></method_info>
 			<added_lines>50,52,53</added_lines>
 			<deleted_lines>51</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>9,10,59,60,63,64</added_lines>
 			<deleted_lines>1,49,56</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\autoscaler\updater.py' new_name='python\ray\autoscaler\updater.py'>
 		<file_info nloc='347' complexity='52' token_count='2028'></file_info>
 		<method name='rsync_up' parameters='self,source,target'>
 				<method_info nloc='6' complexity='1' token_count='55' nesting_level='1' start_line='416' end_line='422'></method_info>
 			<added_lines>418,422</added_lines>
 			<deleted_lines>416,420</deleted_lines>
 		</method>
 		<method name='rsync_up' parameters='self,source,target,file_mount'>
 				<method_info nloc='8' complexity='1' token_count='73' nesting_level='1' start_line='418' end_line='426'></method_info>
 			<added_lines>418,422,423,424</added_lines>
 			<deleted_lines>420,424</deleted_lines>
 		</method>
 		<method name='sync_file_mounts.do_sync' parameters='remote_path,local_path,allow_non_existing_paths'>
 				<method_info nloc='19' complexity='8' token_count='158' nesting_level='2' start_line='167' end_line='194'></method_info>
 			<added_lines>184,185,186,187,188,189</added_lines>
 			<deleted_lines>184,185,186,187</deleted_lines>
 		</method>
 		<method name='sync_file_mounts' parameters='self,sync_cmd,step_numbers,2'>
 				<method_info nloc='23' complexity='5' token_count='141' nesting_level='1' start_line='157' end_line='212'></method_info>
 			<added_lines>184,185,186,187,188,189</added_lines>
 			<deleted_lines>184,185,186,187</deleted_lines>
 		</method>
 		<method name='rsync_down' parameters='self,source,target,file_mount'>
 				<method_info nloc='8' complexity='1' token_count='73' nesting_level='1' start_line='428' end_line='436'></method_info>
 			<added_lines>428,432,433,434</added_lines>
 			<deleted_lines>428</deleted_lines>
 		</method>
 		<method name='rsync_down' parameters='self,source,target'>
 				<method_info nloc='6' complexity='1' token_count='55' nesting_level='1' start_line='424' end_line='430'></method_info>
 			<added_lines>424,428</added_lines>
 			<deleted_lines>424,428</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tests\test_autoscaler.py' new_name='python\ray\tests\test_autoscaler.py'>
 		<file_info nloc='1092' complexity='125' token_count='7299'></file_info>
 		<method name='__init__' parameters='self,fail_cmds'>
 				<method_info nloc='4' complexity='1' token_count='27' nesting_level='1' start_line='43' end_line='46'></method_info>
 			<added_lines>46</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testContinuousFileMounts' parameters='self'>
 				<method_info nloc='45' complexity='3' token_count='273' nesting_level='1' start_line='1135' end_line='1186'></method_info>
 			<added_lines>1163,1165,1166,1182,1184,1185,1186</added_lines>
 			<deleted_lines>1147,1149,1150,1151,1167,1169,1170,1171</deleted_lines>
 		</method>
 		<method name='testFileMountsNonContinuous' parameters='self'>
 				<method_info nloc='64' complexity='4' token_count='369' nesting_level='1' start_line='1188' end_line='1262'></method_info>
 			<added_lines>1215,1217,1218,1219,1233,1235,1236,1258,1260,1261,1262</added_lines>
 			<deleted_lines>1200,1202,1203,1204,1218,1220,1221,1222,1244,1246,1247,1248</deleted_lines>
 		</method>
 		<method name='respond_to_call' parameters='self,pattern,response,num_times'>
 				<method_info nloc='2' complexity='1' token_count='25' nesting_level='1' start_line='111' end_line='112'></method_info>
 			<added_lines>111,112</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='check_output' parameters='self,cmd'>
 				<method_info nloc='13' complexity='5' token_count='76' nesting_level='1' start_line='54' end_line='67'></method_info>
 			<added_lines>56,57,58,59,60,61,62,63,64,65,66,67</added_lines>
 			<deleted_lines>54</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>15,113</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='python\ray\tests\test_command_runner.py' new_name='python\ray\tests\test_command_runner.py'>
 		<file_info nloc='186' complexity='7' token_count='1023'></file_info>
 		<method name='test_docker_rsync' parameters=''>
 				<method_info nloc='62' complexity='1' token_count='348' nesting_level='0' start_line='145' end_line='224'></method_info>
 			<added_lines>145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>5,225,226</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\ray\core_worker\lib\java\jni_utils.h' new_name='src\ray\core_worker\lib\java\jni_utils.h'>
 		<file_info nloc='337' complexity='47' token_count='2541'></file_info>
 		<method name='JavaByteArrayToId' parameters='env,bytes'>
 				<method_info nloc='9' complexity='1' token_count='101' nesting_level='0' start_line='255' end_line='263'></method_info>
 			<added_lines>260,261</added_lines>
 			<deleted_lines>260</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
