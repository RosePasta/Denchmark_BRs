<bug_data>
<bug id='10117' author='juliusfrost' open_date='2020-08-14T17:54:56Z' closed_time='2020-08-16T18:25:13Z'>
 	<summary>[rllib] Off Policy Estimation breaks with GPU on PyTorch (MARWIL) (Offline API)</summary>
 	<description>
 &lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;
 
 When I use MARWIL with PyTorch and num_gpus: 1, I get an error when computing metrics. This happens because in off policy estimation it uses the torch tensors on gpu instead of numpy arrays. Particularly, I use "input_evaluation": ["is", "wis"] and the error goes away when "input_evaluation": ["simulation"]
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\tune\trial_runner.py", line 497, in _process_trial
     result = self.trial_executor.fetch_result(trial)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\tune\ray_trial_executor.py", line 434, in fetch_result
     result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\worker.py", line 1553, in get
     raise value.as_instanceof_cause()
 ray.exceptions.RayTaskError(AttributeError): ray::MARWIL.train() (pid=9136, ip=10.0.0.18)
   File "python\ray\_raylet.pyx", line 474, in ray._raylet.execute_task
   File "python\ray\_raylet.pyx", line 427, in ray._raylet.execute_task.function_executor
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\function_manager.py", line 567, in actor_method_executor
     raise e
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\function_manager.py", line 559, in actor_method_executor
     method_returns = method(actor, *args, **kwargs)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\rllib\agents\trainer.py", line 522, in train
     raise e
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\rllib\agents\trainer.py", line 508, in train
     result = Trainable.train(self)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\tune\trainable.py", line 337, in train
     result = self.step()
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\rllib\agents\trainer_template.py", line 110, in step
     res = next(self.train_exec_impl)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\util\iter.py", line 758, in __next__
     return next(self.built_iterator)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\util\iter.py", line 793, in apply_foreach
     result = fn(item)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\rllib\execution\metric_ops.py", line 87, in __call__
     res = summarize_episodes(episodes, orig_episodes)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\ray\rllib\evaluation\metrics.py", line 173, in summarize_episodes
     metrics[k] = np.mean(v_list)
   File "&lt;__array_function__ internals&gt;", line 6, in mean
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\numpy\core\fromnumeric.py", line 3335, in mean
     out=out, **kwargs)
   File "C:\Users\Julius\Anaconda3\envs\ray\lib\site-packages\numpy\core\_methods.py", line 161, in _mean
     ret = ret.dtype.type(ret / rcount)
 AttributeError: 'torch.dtype' object has no attribute 'type'
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;
 
 Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
 If we cannot run your script, we cannot fix your issue.
 
  I have verified my script runs in a clean environment and reproduces the issue.
  I have verified the issue also occurs with the latest wheels.
 
 	</description>
 	<comments>
 		<comment id='1' author='juliusfrost' date='2020-08-14T20:50:20Z'>
 		Hmm I think we are missing a call to .cpu().numpy() somewhere and are trying to calculate a np.mean() over torch tensors representing a single element. Do you think you could look into this issue?
 		</comment>
 	</comments>
 </bug>
<commit id='dc659ae89ada171a86a97006d61084513d799d80' author='Julius Frost' date='2020-08-16 11:25:12-07:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='rllib\offline\off_policy_estimator.py' new_name='rllib\offline\off_policy_estimator.py'>
 		<file_info nloc='76' complexity='14' token_count='446'></file_info>
 		<method name='action_prob' parameters='self,SampleBatchType'>
 				<method_info nloc='14' complexity='5' token_count='126' nesting_level='1' start_line='59' end_line='73'></method_info>
 			<added_lines>59,67,73</added_lines>
 			<deleted_lines>64,70</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>4,5,10</added_lines>
 			<deleted_lines>56</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
