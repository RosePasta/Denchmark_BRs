<bug_data>
<bug id='1049' author='ericl' open_date='2017-10-01T06:46:36Z' closed_time='2017-11-20T23:19:12Z'>
 	<summary>ray.get() hangs if you call it on a actor task that calls sys.exit()</summary>
 	<description>
 I was trying to kill actor processes to release GPU resources by having a method that would raise SystemExit. However, ray.get() hangs forever in this case. I see in the console:
 &lt;denchmark-code&gt;Disconnecting client on fd 42                                                                              
 Error in atexit._run_exitfuncs:                                                                            
 Traceback (most recent call last):                                                                         
   File "/home/ubuntu/.local/lib/python3.6/site-packages/ray-0.2.0-py3.6-linux-x86_64.egg/ray/worker.py", li
 ne 1358, in cleanup                                                                                        
 A worker died or was killed while executing a task.                                                        
                                                                                                            
   You can inspect errors by running                                                                        
                                                                                                            
       ray.error_info()                                                                                     
                                                                                                            
   If this driver is hanging, start a new one with                                                          
                                                                                                            
       ray.init(redis_address="127.0.0.1:25614")                                                            
                                                                                                            
     worker.plasma_client.disconnect()                                                                      
   File "/home/ubuntu/.local/lib/python3.6/site-packages/ray-0.2.0-py3.6-linux-x86_64.egg/ray/worker.py", li
 ne 865, in exit                                                                                            
     sys.exit(0)                                                                                            
 SystemExit: 0                                                                                              
 &lt;/denchmark-code&gt;
 
 If you interrupt the driver, you see that it's hanging in the ray.get() for the stop method.
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File "./rllib-eval.py", line 261, in &lt;module&gt;
     runner.process_events()
   File "./rllib-eval.py", line 200, in process_events
     exp.stop()
   File "./rllib-eval.py", line 66, in stop
     ray.get(self.agent.stop.remote())
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='ericl' date='2017-10-01T17:40:58Z'>
 		Good point, I just verified that this also happens for remote functions (though in the remote function case the task gets resubmitted over and over by the local scheduler).
 I think what we want to do here is the following. The local scheduler detects that the worker died, it looks at what task the worker was executing and then there are a couple options.
 
 It can put an object representing a failed task in the object store for the objects that were supposed to be created by the failed task. Whoever calls ray.get on that object will retrieve the object and reraise the exception. This is the normal approach we use when tasks raise exceptions.
 It can stick a key in Redis saying that the task failed (this is easy to implement), but then whoever is waiting for the objects will have to check Redis, which is pretty inconvenient (that is it's not clear what the right way to do this is when you're calling ray.get on one million objects).
 
 		</comment>
 		<comment id='2' author='ericl' date='2017-11-20T23:19:12Z'>
 		Fixed by &lt;denchmark-link:https://github.com/ray-project/ray/pull/1224&gt;#1224&lt;/denchmark-link&gt;
 .
 		</comment>
 	</comments>
 </bug>
<commit id='9233e496ccad1f14925999c003a32160e7b5ddf3' author='Eric Liang' date='2017-11-20 15:18:39-08:00'>
 	<dmm_unit complexity='0.908256880733945' interfacing='0.5688073394495413' size='0.3669724770642202'></dmm_unit>
 	<modification change_type='MODIFY' old_name='python\ray\worker.py' new_name='python\ray\worker.py'>
 		<file_info nloc='1403' complexity='236' token_count='8730'></file_info>
 		<method name='retrieve_and_deserialize' parameters='self,object_ids,timeout,error_timeout'>
 				<method_info nloc='37' complexity='9' token_count='201' nesting_level='1' start_line='361' end_line='408'></method_info>
 			<added_lines>380,381,382,383,384,385,386,387</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\common\state\actor_notification_table.cc' new_name='src\common\state\actor_notification_table.cc'>
 		<file_info nloc='18' complexity='2' token_count='90'></file_info>
 		<method name='actor_table_mark_removed' parameters='db_handle,actor_id'>
 				<method_info nloc='3' complexity='1' token_count='18' nesting_level='0' start_line='19' end_line='21'></method_info>
 			<added_lines>19,20,21</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>18</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\common\state\actor_notification_table.h' new_name='src\common\state\actor_notification_table.h'>
 		<file_info nloc='19' complexity='0' token_count='73'></file_info>
 		<modified_lines>
 			<added_lines>44,45,46,47,48,49,50,51,52</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\common\state\redis.cc' new_name='src\common\state\redis.cc'>
 		<file_info nloc='1218' complexity='205' token_count='9000'></file_info>
 		<method name='redis_actor_table_mark_removed' parameters='db,actor_id'>
 				<method_info nloc='8' complexity='3' token_count='63' nesting_level='0' start_line='1579' end_line='1586'></method_info>
 			<added_lines>1579,1580,1581,1582,1583,1584,1585,1586</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1587</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\common\state\redis.h' new_name='src\common\state\redis.h'>
 		<file_info nloc='66' complexity='0' token_count='424'></file_info>
 		<modified_lines>
 			<added_lines>324,325,326,327,328,329,330,331,332</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\local_scheduler\local_scheduler.cc' new_name='src\local_scheduler\local_scheduler.cc'>
 		<file_info nloc='1054' complexity='182' token_count='6754'></file_info>
 		<method name='kill_worker' parameters='state,worker,cleanup,suppress_warning'>
 				<method_info nloc='54' complexity='11' token_count='423' nesting_level='0' start_line='65' end_line='148'></method_info>
 			<added_lines>83,84</added_lines>
 			<deleted_lines>83,84</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\local_scheduler\local_scheduler_algorithm.cc' new_name='src\local_scheduler\local_scheduler_algorithm.cc'>
 		<file_info nloc='934' complexity='159' token_count='6216'></file_info>
 		<method name='handle_actor_worker_disconnect' parameters='state,algorithm_state,actor_id'>
 				<method_info nloc='6' complexity='1' token_count='29' nesting_level='0' start_line='1265' end_line='1272'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>1267,1268</deleted_lines>
 		</method>
 		<method name='insert_actor_task_queue' parameters='state,algorithm_state,task_entry'>
 				<method_info nloc='43' complexity='9' token_count='283' nesting_level='0' start_line='441' end_line='506'></method_info>
 			<added_lines>449,450,451,452,453,454</added_lines>
 			<deleted_lines>495,496,497,498</deleted_lines>
 		</method>
 		<method name='queue_actor_task' parameters='state,algorithm_state,spec,task_spec_size,from_global_scheduler'>
 				<method_info nloc='19' complexity='3' token_count='129' nesting_level='0' start_line='521' end_line='550'></method_info>
 			<added_lines>545,546,547,548,549</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='finish_killed_task' parameters='state,spec,task_spec_size'>
 				<method_info nloc='20' complexity='4' token_count='157' nesting_level='0' start_line='406' end_line='428'></method_info>
 			<added_lines>406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='handle_actor_worker_disconnect' parameters='state,algorithm_state,worker,cleanup'>
 				<method_info nloc='23' complexity='5' token_count='167' nesting_level='0' start_line='1300' end_line='1329'></method_info>
 			<added_lines>1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>8,403,404,405,429</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\local_scheduler\local_scheduler_algorithm.h' new_name='src\local_scheduler\local_scheduler_algorithm.h'>
 		<file_info nloc='74' complexity='0' token_count='384'></file_info>
 		<modified_lines>
 			<added_lines>200,201,206,207</added_lines>
 			<deleted_lines>200,205</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='src\local_scheduler\local_scheduler_shared.h' new_name='src\local_scheduler\local_scheduler_shared.h'>
 		<file_info nloc='51' complexity='0' token_count='217'></file_info>
 		<modified_lines>
 			<added_lines>51,52,53</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='test\failure_test.py' new_name='test\failure_test.py'>
 		<file_info nloc='278' complexity='48' token_count='2138'></file_info>
 		<method name='testActorWorkerDyingNothingInProgress' parameters='self'>
 				<method_info nloc='12' complexity='1' token_count='99' nesting_level='1' start_line='324' end_line='339'></method_info>
 			<added_lines>324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testActorWorkerDyingFutureTasks' parameters='self'>
 				<method_info nloc='16' complexity='4' token_count='142' nesting_level='1' start_line='300' end_line='322'></method_info>
 			<added_lines>300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testActorWorkerDyingNothingInProgress.getpid' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='11' nesting_level='3' start_line='329' end_line='330'></method_info>
 			<added_lines>329,330</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testActorWorkerDying' parameters='self'>
 				<method_info nloc='13' complexity='1' token_count='117' nesting_level='1' start_line='280' end_line='298'></method_info>
 			<added_lines>280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testActorWorkerDyingFutureTasks.sleep' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='11' nesting_level='3' start_line='308' end_line='309'></method_info>
 			<added_lines>308,309</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testActorWorkerDying.consume' parameters='x'>
 				<method_info nloc='2' complexity='1' token_count='6' nesting_level='2' start_line='289' end_line='290'></method_info>
 			<added_lines>289,290</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testActorWorkerDying.kill' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='9' nesting_level='3' start_line='285' end_line='286'></method_info>
 			<added_lines>285,286</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='testActorWorkerDyingFutureTasks.getpid' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='11' nesting_level='3' start_line='305' end_line='306'></method_info>
 			<added_lines>305,306</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>299,323,340</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
