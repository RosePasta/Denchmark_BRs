<bug_data>
<bug id='7397' author='soundway' open_date='2020-03-02T08:22:54Z' closed_time='2020-03-02T10:29:11Z'>
 	<summary>[rllib] TorchDiagGaussian doesn’t handle multiple actions correctly.</summary>
 	<description>
 This is not a contribution.
 Ray version: 0.8.2
 Python version: 3.6.8
 Pytorch version: 1.4
 OS: Ubuntu 18.04 Docker
 TorchDiagGaussian doesn’t handle multiple actions correctly. As a result, training PPO with Pytorch will crash when the action space has more than 1 action. Here’s minimal reproduction script:
 import gym
 from gym.spaces import Box
 from ray import tune
 
 class ContinuousEnv(gym.Env):
    def __init__(self, config):
        self.action_space = Box(0.0, 1.0, shape=(2,))
        self.observation_space = Box(0.0, 1.0, shape=(1, ))
 
    def reset(self):
        return [0.0]
 
    def step(self, action):
        return [0.0], 1.0, False, {}
 
 tune.run(
    "PPO",
    config={"env": ContinuousEnv, "use_pytorch": True, "num_workers": 1})
 	</description>
 	<comments>
 		<comment id='1' author='soundway' date='2020-03-02T09:03:09Z'>
 		Thanks for filing this. Taking a look ...
 		</comment>
 		<comment id='2' author='soundway' date='2020-03-02T10:29:11Z'>
 		Please try this PR for a fix. This will go into master within the next few days.
 &lt;denchmark-link:https://github.com/ray-project/ray/pull/7398&gt;#7398&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='soundway' date='2020-03-04T03:09:46Z'>
 		This works. Thanks for the quick fix!
 		</comment>
 		<comment id='4' author='soundway' date='2020-03-30T13:38:26Z'>
 		Had the same problem, so i updated to the 0.8.3 version. Now the bug happens in the GAE calculation:
 File "/home/spider-sense01/PycharmProjects/multi-agent-emergence-environments/.venv/lib/python3.6/site-packages/ray/rllib/agents/ppo/ppo_torch_policy.py", line 105, in init
 vf_loss_coeff * vf_loss - entropy_coeff * curr_entropy)
 RuntimeError: The size of tensor a (512) must match the size of tensor b (2) at non-singleton dimension 1
 		</comment>
 	</comments>
 </bug>
<commit id='d8eeb9641314740572e81f9836cbce3e5b8f2b73' author='Sven Mika' date='2020-03-02 10:53:19-08:00'>
 	<dmm_unit complexity='0.25' interfacing='0.375' size='0.375'></dmm_unit>
 	<modification change_type='MODIFY' old_name='rllib\agents\ppo\ppo_torch_policy.py' new_name='rllib\agents\ppo\ppo_torch_policy.py'>
 		<file_info nloc='164' complexity='17' token_count='1137'></file_info>
 		<method name='ppo_surrogate_loss' parameters='policy,model,dist_class,train_batch'>
 				<method_info nloc='28' complexity='2' token_count='181' nesting_level='0' start_line='114' end_line='144'></method_info>
 			<added_lines>118</added_lines>
 			<deleted_lines>116,117,118</deleted_lines>
 		</method>
 		<method name='reduce_mean_valid' parameters='t'>
 				<method_info nloc='2' complexity='1' token_count='14' nesting_level='3' start_line='72' end_line='73'></method_info>
 			<added_lines>72,73</added_lines>
 			<deleted_lines>72</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>70,74,75,76,77,78</added_lines>
 			<deleted_lines>71</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\models\torch\torch_action_dist.py' new_name='rllib\models\torch\torch_action_dist.py'>
 		<file_info nloc='63' complexity='15' token_count='475'></file_info>
 		<method name='logp' parameters='self,actions'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='73' end_line='74'></method_info>
 			<added_lines>74</added_lines>
 			<deleted_lines>74</deleted_lines>
 		</method>
 		<method name='kl' parameters='self,other'>
 				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='81' end_line='82'></method_info>
 			<added_lines>81,82</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='entropy' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='19' nesting_level='1' start_line='77' end_line='78'></method_info>
 			<added_lines>77,78</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>75,76,79,80</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='rllib\tests\test_supported_spaces.py' new_name='rllib\tests\test_supported_spaces.py'>
 		<file_info nloc='269' complexity='51' token_count='1782'></file_info>
 		<method name='check_support' parameters='alg,config,stats,check_bounds,name'>
 				<method_info nloc='58' complexity='20' token_count='353' nesting_level='0' start_line='75' end_line='135'></method_info>
 			<added_lines>80,83,84,92,93,94,99,100,101,102,103,104,106,107,108,109,110,111</added_lines>
 			<deleted_lines>80,81,93,94,96</deleted_lines>
 		</method>
 		<method name='test_pg' parameters='self'>
 				<method_info nloc='8' complexity='1' token_count='51' nesting_level='1' start_line='230' end_line='237'></method_info>
 			<added_lines>231,232,233,234,235,236,237</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_ppo' parameters='self'>
 				<method_info nloc='11' complexity='1' token_count='63' nesting_level='1' start_line='218' end_line='228'></method_info>
 			<added_lines>219,220,221,222,223,224,225,226,227,228</added_lines>
 			<deleted_lines>218,219,220,221,222</deleted_lines>
 		</method>
 		<method name='test_a3c' parameters='self'>
 				<method_info nloc='10' complexity='1' token_count='54' nesting_level='1' start_line='161' end_line='170'></method_info>
 			<added_lines>162,163,164,165,166,167,168,169,170</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>14,15</added_lines>
 			<deleted_lines>147,148,149,150,151,152,153,154,155,204,205,206,207,208,209,210,211,212,213,216,217</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
