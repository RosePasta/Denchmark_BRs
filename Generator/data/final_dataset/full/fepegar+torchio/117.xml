<bug_data>
<bug id='117' author='nwschurink' open_date='2020-04-08T10:16:20Z' closed_time='2020-04-08T14:39:14Z'>
 	<summary>CropOrPad only crops Mask</summary>
 	<description>
 TorchIO version
 0.15.0
 What I did
 Create the following sequence of transforms:
 &lt;denchmark-code&gt;input_H = 160
 input_W = 160
 input_D = 80
 
 transforms = [
     torchio.transforms.ToCanonical(),
     torchio.transforms.Resample(target_spacing=(1,1,1)),
     torchio.transforms.RescaleIntensity(out_min_max=(0,1),percentiles=(0.5,99.5)),
     torchio.transforms.ZNormalization(),
     torchio.transforms.CropOrPad(target_shape=(input_D,input_H,input_W),padding_mode='constant',padding_fill=0,mask_name='mask'),
 ]
 transform = Compose(transforms)
 
 dataset = ImagesDataset(subjects, transform=transform)
 sample = dataset[0]
 &lt;/denchmark-code&gt;
 
 I then checked the size of one of the images in the sample e.g. sample['t2']['data'].shape which returns torch.Size([1, 247, 345, 346]) whereas sample['mask']['data'].shape returns torch.Size([1, 80, 160, 160])
 What I expected to happen
 Both the image and mask have the same size
 What actually happened
 The sizes are different.
 
 In the crop and pad function (&lt;denchmark-link:https://github.com/fepegar/torchio/blob/master/torchio/transforms/preprocessing/spatial/crop_or_pad.py#L224-L225&gt;here&lt;/denchmark-link&gt;
 ) these lines should probably be changed
 &lt;denchmark-code&gt;        padding_params = tuple(padding.tolist()) if padding.any() else None
         cropping_params = tuple(cropping.tolist()) if padding.any() else None
 &lt;/denchmark-code&gt;
 
 should be
 &lt;denchmark-code&gt;        padding_params = tuple(padding.tolist()) if padding.any() else None
         cropping_params = tuple(cropping.tolist()) if cropping.any() else None
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='nwschurink' date='2020-04-08T10:19:08Z'>
 		Hi &lt;denchmark-link:https://github.com/nwschurink&gt;@nwschurink&lt;/denchmark-link&gt;
 . Thanks for reporting. That's obviously me pasting the previous line and messing up. I'll fix that in a sec.
 		</comment>
 		<comment id='2' author='nwschurink' date='2020-04-08T11:00:40Z'>
 		I haven't been able to reproduce your issue with this code:
 from torchio import Image, Subject, ImagesDataset, INTENSITY, LABEL, DATA
 from torchio.transforms import CropOrPad
 
 subject = Subject(
     t1=Image('/tmp/t1.nii.gz', INTENSITY),
     label=Image('/tmp/eyes.nrrd', LABEL),
 )
 transform = CropOrPad((79, 160, 160), mask_name='label')
 dataset = ImagesDataset([subject], transform=transform)
 sample = dataset[0]
 
 for key in sample:
     print(sample[key][DATA].shape)
 
 dataset.save_sample(
     sample,
     dict(t1='/tmp/t1_crop.nii.gz', label='/tmp/eyes_crop.nii.gz'),
 )
 Output:
 torch.Size([1, 80, 160, 160])
 torch.Size([1, 80, 160, 160])
 The shapes are wrong (as I have reported in &lt;denchmark-link:https://github.com/fepegar/torchio/pull/119&gt;#119&lt;/denchmark-link&gt;
 ), but consistent. Can you share a minimal working example and, if possible, some data? You can send it by email if you like.
 		</comment>
 		<comment id='3' author='nwschurink' date='2020-04-08T12:06:23Z'>
 		I think the reason why this happens is related to &lt;denchmark-link:https://github.com/fepegar/torchio/issues/118&gt;issue 118&lt;/denchmark-link&gt;
  and probably can be reproduced by changing the field of view of the mask to its bounding box (before loading it to Subject, e.g. your 'eyes.nrrd').
 The reason for this is that when the field of view of the mask and image are not the same it is possible that padding.any() evaluates to None for the T1 image (when the new crop falls within the field of view of the T1 scan). The result of this is that in the current code tuple(cropping.tolist()) is not assigned to cropping_params because padding returns None, whereas for the mask this line does get executed since the mask apparently needs padding and thus padding.any() is not empty.
 I can check if i can make a minimum working example
 		</comment>
 		<comment id='4' author='nwschurink' date='2020-04-08T12:13:57Z'>
 		
 The reason for this is that when the field of view of the mask and image are not the same
 
 Do you mean the shapes are different? Maybe I misunderstood, but that should be checked in
 
 
 
 torchio/torchio/transforms/preprocessing/spatial/crop_or_pad.py
 
 
         Lines 97 to 106
       in
       992ab56
 
 
 
 
 
 
  @staticmethod 
 
 
 
  def _get_sample_shape(sample: dict) -&gt; TypeShape: 
 
 
 
  """Return the shape of the first image in the sample.""" 
 
 
 
  check_consistent_shape(sample) 
 
 
 
  for image_dict in sample.values(): 
 
 
 
  if not is_image_dict(image_dict): 
 
 
 
  continue 
 
 
 
  data = image_dict[DATA].shape[1:]  # remove channels dimension 
 
 
 
  break 
 
 
 
  return data 
 
 
 
 
 
 		</comment>
 		<comment id='5' author='nwschurink' date='2020-04-08T12:19:33Z'>
 		Ah, ok then I think there must be something going wrong in the check_consistent_shape check.
 I just checked the input size of my images. My T2 image has size (320,320,36) and my mask has size (18,22,6) (i.e. it only contains the bounding box of the segmentation, but is in the same frame of reference)
 		</comment>
 		<comment id='6' author='nwschurink' date='2020-04-08T12:36:49Z'>
 		Hmm, it's weird when I run check_consistent_shape() on my sample subject it returns a Value Error because of inconsistent shapes. So the test should be working
 		</comment>
 		<comment id='7' author='nwschurink' date='2020-04-08T12:42:09Z'>
 		Ah ok I've found out why the check is not working. The shape check is only performed when doing a center crop (e.g  ) (&lt;denchmark-link:https://github.com/fepegar/torchio/blob/992ab56cef58f6e5dd9480da1f9b77b6cce1ca9d/torchio/transforms/preprocessing/spatial/crop_or_pad.py#L161&gt;here&lt;/denchmark-link&gt;
 ). However, the check is not performed when performing a crop on the mask's center (e.g. )
 		</comment>
 		<comment id='8' author='nwschurink' date='2020-04-08T12:46:01Z'>
 		Good catch!
 &lt;denchmark-link:https://github.com/GReguig&gt;@GReguig&lt;/denchmark-link&gt;
  could you please look into this?
 		</comment>
 		<comment id='9' author='nwschurink' date='2020-04-08T12:47:47Z'>
 		Ok, I will give it a look
 		</comment>
 	</comments>
 </bug>
<commit id='f22fd20198590b8a13b327e3d306fbeeca0e8046' author='Fernando Pérez-García' date='2020-04-08 15:39:12+01:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='0.3333333333333333'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tests\transforms\preprocessing\test_crop_pad.py' new_name='tests\transforms\preprocessing\test_crop_pad.py'>
 		<file_info nloc='187' complexity='31' token_count='1471'></file_info>
 		<method name='test_shape_right' parameters='self'>
 				<method_info nloc='7' complexity='2' token_count='54' nesting_level='1' start_line='41' end_line='47'></method_info>
 			<added_lines>45,46,47</added_lines>
 			<deleted_lines>42,43</deleted_lines>
 		</method>
 		<method name='test_only_pad' parameters='self'>
 				<method_info nloc='7' complexity='2' token_count='54' nesting_level='1' start_line='49' end_line='55'></method_info>
 			<added_lines>49,50,51,52,53,54,55</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_different_shape' parameters='self'>
 				<method_info nloc='8' complexity='2' token_count='71' nesting_level='1' start_line='32' end_line='39'></method_info>
 			<added_lines>37,38,39</added_lines>
 			<deleted_lines>35,36</deleted_lines>
 		</method>
 		<method name='test_shape_one' parameters='self'>
 				<method_info nloc='6' complexity='2' token_count='53' nesting_level='1' start_line='77' end_line='82'></method_info>
 			<added_lines>80,81,82</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_mask_only_crop' parameters='self'>
 				<method_info nloc='19' complexity='3' token_count='144' nesting_level='1' start_line='121' end_line='139'></method_info>
 			<added_lines>121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_empty_mask' parameters='self'>
 				<method_info nloc='7' complexity='1' token_count='51' nesting_level='1' start_line='93' end_line='99'></method_info>
 			<added_lines>95</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_only_crop' parameters='self'>
 				<method_info nloc='7' complexity='2' token_count='54' nesting_level='1' start_line='57' end_line='63'></method_info>
 			<added_lines>57,58,59,60,61,62,63</added_lines>
 			<deleted_lines>60,61</deleted_lines>
 		</method>
 		<method name='test_no_changes_mask' parameters='self'>
 				<method_info nloc='12' complexity='2' token_count='109' nesting_level='1' start_line='19' end_line='30'></method_info>
 			<added_lines>27,28,29,30</added_lines>
 			<deleted_lines>27,28</deleted_lines>
 		</method>
 		<method name='test_mask_only_pad' parameters='self'>
 				<method_info nloc='19' complexity='3' token_count='144' nesting_level='1' start_line='101' end_line='119'></method_info>
 			<added_lines>101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>48,56,120,140</added_lines>
 			<deleted_lines>74</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='torchio\transforms\preprocessing\spatial\crop_or_pad.py' new_name='torchio\transforms\preprocessing\spatial\crop_or_pad.py'>
 		<file_info nloc='210' complexity='12' token_count='1067'></file_info>
 		<modified_lines>
 			<added_lines>194,210,213,225</added_lines>
 			<deleted_lines>194,210,213,225</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
