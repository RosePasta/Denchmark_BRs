<bug_data>
<bug id='254' author='Hananel-Hazan' open_date='2019-05-23T19:04:45Z' closed_time='2019-05-31T18:08:13Z'>
 	<summary>Encoder in environment.GymEnvironment</summary>
 	<description>
 Trying to use environment.GymEnvironment in BindsNET without encoder lead to a error in loading.
 &lt;denchmark-link:https://github.com/k-chaney&gt;@k-chaney&lt;/denchmark-link&gt;
 , I think encoder should be an option not mandatory.
 	</description>
 	<comments>
 		<comment id='1' author='Hananel-Hazan' date='2019-05-23T19:09:24Z'>
 		&lt;denchmark-link:https://github.com/BindsNET/bindsnet/pull/255&gt;#255&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='Hananel-Hazan' date='2019-05-23T19:09:56Z'>
 		Yeah, is it possible to default to ? &lt;denchmark-link:https://github.com/BindsNET/bindsnet/pull/255&gt;#255&lt;/denchmark-link&gt;
  seems like it'd work, too. Any thoughts &lt;denchmark-link:https://github.com/k-chaney&gt;@k-chaney&lt;/denchmark-link&gt;
 ?
 By the way, I think spike_encoders.py should be kept in the bindsnet/encoders/ folder, and I think it'd be best if you put all the Encoder classes in bindsnet/encoders/__init__.py.
 		</comment>
 		<comment id='3' author='Hananel-Hazan' date='2019-05-23T20:24:08Z'>
 		I think that by default encoder,  image_encoder and label_encoder need to be set to NullEncoder
 That can solve the issue and my commit need to be cancel
 		</comment>
 		<comment id='4' author='Hananel-Hazan' date='2019-05-27T19:39:21Z'>
 		Sorry about the delay, I've been diving into the other feature I'm working on. This seems like a reasonable change. I just pushed a branch chaney/gym_env_encoder_fix that deals with this as described.
 
 Do we want the encoders to be in their own module or should we leverage the encodings module that already exists?
 For the GymEnvironment the encoder default is NullEncoder.
 For the torchvision.dataset wrapping, we should probably keep them as mandatory positional arguments and just allow None to convert to NullEncoder in the constructor. This maintains the format of bindsnet arguments first and then the dataset specific arguments second and as keyword arguments.
 
 		</comment>
 		<comment id='5' author='Hananel-Hazan' date='2019-05-28T00:01:34Z'>
 		Thanks &lt;denchmark-link:https://github.com/k-chaney&gt;@k-chaney&lt;/denchmark-link&gt;
 .
 Yes, leveraging the encoder module is preferred. 2 and 3 look good.
 		</comment>
 		<comment id='6' author='Hananel-Hazan' date='2019-05-28T15:15:39Z'>
 		Yeah, I think should keep both the functional and class interfaces to the encodings in bindsnet/encoding/__init__.py.
 		</comment>
 		<comment id='7' author='Hananel-Hazan' date='2019-05-29T15:51:52Z'>
 		Just pushed some changes to fix 1. I'll submit a pull request.
 		</comment>
 	</comments>
 </bug>
<commit id='fc889c0c25cbd7cb4fcbf657d6230bbb349cb0b7' author='k-chaney' date='2019-05-27 15:31:38-04:00'>
 	<dmm_unit complexity='1.0' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='bindsnet\datasets\__init__.py' new_name='bindsnet\datasets\__init__.py'>
 		<file_info nloc='33' complexity='0' token_count='207'></file_info>
 		<modified_lines>
 			<added_lines>30</added_lines>
 			<deleted_lines>30</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='bindsnet\datasets\spoken_mnist.py' new_name='bindsnet\datasets\spoken_mnist.py'>
 		<file_info nloc='185' complexity='23' token_count='1603'></file_info>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines>12,13</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='bindsnet\datasets\torchvision_wrapper.py' new_name='bindsnet\datasets\torchvision_wrapper.py'>
 		<file_info nloc='48' complexity='8' token_count='232'></file_info>
 		<method name='torchvision_dataset_wrapper_creator.__getitem__' parameters='self,int'>
 				<method_info nloc='15' complexity='1' token_count='66' nesting_level='2' start_line='57' end_line='75'></method_info>
 			<added_lines>72,73</added_lines>
 			<deleted_lines>65,66,67,68,69</deleted_lines>
 		</method>
 		<method name='torchvision_dataset_wrapper_creator' parameters='ds_type'>
 				<method_info nloc='25' complexity='5' token_count='110' nesting_level='0' start_line='9' end_line='80'></method_info>
 			<added_lines>47,48,49,50,51,52,53,72,73</added_lines>
 			<deleted_lines>65,66,67,68,69</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>7</added_lines>
 			<deleted_lines>7</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='RENAME' old_name='bindsnet\datasets\spike_encoders.py' new_name='bindsnet\encoders\__init__.py'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 	</modification>
 	<modification change_type='MODIFY' old_name='bindsnet\environment\__init__.py' new_name='bindsnet\environment\__init__.py'>
 		<file_info nloc='175' complexity='28' token_count='927'></file_info>
 		<method name='__init__' parameters='self,str,Encoder,kwargs'>
 				<method_info nloc='42' complexity='4' token_count='195' nesting_level='1' start_line='67' end_line='116'></method_info>
 			<added_lines>67,92</added_lines>
 			<deleted_lines>67</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,str,Encoder'>
 				<method_info nloc='42' complexity='4' token_count='199' nesting_level='1' start_line='67' end_line='117'></method_info>
 			<added_lines>67,92</added_lines>
 			<deleted_lines>67</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>5,8</added_lines>
 			<deleted_lines>5,8</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\datasets\conv.py' new_name='examples\datasets\conv.py'>
 		<file_info nloc='80' complexity='0' token_count='559'></file_info>
 		<modified_lines>
 			<added_lines>11,15,57,70,82</added_lines>
 			<deleted_lines>11,15,57,70,82</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\datasets\spoken_mnist.py' new_name='examples\datasets\spoken_mnist.py'>
 		<file_info nloc='37' complexity='0' token_count='337'></file_info>
 		<modified_lines>
 			<added_lines>9</added_lines>
 			<deleted_lines>9</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\mnist\conv_mnist.py' new_name='examples\mnist\conv_mnist.py'>
 		<file_info nloc='159' complexity='0' token_count='1346'></file_info>
 		<modified_lines>
 			<added_lines>11</added_lines>
 			<deleted_lines>11</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\mnist\minimal_mnist.py' new_name='examples\mnist\minimal_mnist.py'>
 		<file_info nloc='26' complexity='0' token_count='151'></file_info>
 		<modified_lines>
 			<added_lines>2</added_lines>
 			<deleted_lines>2</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\mnist\minimal_reservoir.py' new_name='examples\mnist\minimal_reservoir.py'>
 		<file_info nloc='74' complexity='7' token_count='616'></file_info>
 		<modified_lines>
 			<added_lines>8</added_lines>
 			<deleted_lines>8</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\space_invaders\et_space_invaders.py' new_name='examples\space_invaders\et_space_invaders.py'>
 		<file_info nloc='97' complexity='0' token_count='769'></file_info>
 		<modified_lines>
 			<added_lines>6</added_lines>
 			<deleted_lines>6</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\space_invaders\minimal_space_invaders.py' new_name='examples\space_invaders\minimal_space_invaders.py'>
 		<file_info nloc='43' complexity='0' token_count='321'></file_info>
 		<modified_lines>
 			<added_lines>6</added_lines>
 			<deleted_lines>6</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\space_invaders\random_baseline.py' new_name='examples\space_invaders\random_baseline.py'>
 		<file_info nloc='58' complexity='0' token_count='354'></file_info>
 		<modified_lines>
 			<added_lines>19</added_lines>
 			<deleted_lines>7,20</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
