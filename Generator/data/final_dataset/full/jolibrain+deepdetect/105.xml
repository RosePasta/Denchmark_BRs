<bug_data>
<bug id='105' author='voidabhi' open_date='2016-04-18T08:17:58Z' closed_time='2016-05-16T13:40:57Z'>
 	<summary>ERROR - service myserv mllib bad param: no deploy file in ../../models/ggnet for initializing the net</summary>
 	<description>
 I am getting this error while running following command:
 curl -X POST "http://localhost:8080/predict" -d "{\"service\":\"myserv\",\"parameters\":{\"input\":{\"width\":125,\"height\":93},\"output\":{\"best\":3}},\"data\":[\"path/to/image\"]}"
 On doing ls ../../models/ggnet gives
 &lt;denchmark-code&gt;deploy.prototxt  googlenet.prototxt  googlenet_solver.prototxt  model.json
 &lt;/denchmark-code&gt;
 
 i.e deploy.prototxt exists in the path.
 Kindly guide me through this. What am i doing wrong?
 	</description>
 	<comments>
 		<comment id='1' author='voidabhi' date='2016-04-18T08:31:28Z'>
 		Hi, can you share the PUT services call as well as the output from the server ? The server is probably not reading from the repository you are listing files from.
 As a tip, try to not use relative paths for models and data repositories as they can only be relative to the directory the server has been started from.
 		</comment>
 		<comment id='2' author='voidabhi' date='2016-04-18T08:33:37Z'>
 		Thanks for reverting :)
 Here is the python script through which i had created the service
 from dd_client import DD
 dd = DD('localhost')
 dd.set_return_format(dd.RETURN_PYTHON)
 description = 'image classification service'
 mllib = 'caffe'
 model = {'templates':'../templates/caffe/','repository':'../../models/ggnet'}
 parameters_input = {'connector':'image'}
 parameters_mllib = {'template':'googlenet','nclasses':1000}
 parameters_output = {}
 print dd.put_service('myserv',model,description,mllib,
                parameters_input,parameters_mllib,parameters_output)
 		</comment>
 		<comment id='3' author='voidabhi' date='2016-04-18T08:38:32Z'>
 		Try passing an absolute path to repository, that is the most likely error here.
 		</comment>
 		<comment id='4' author='voidabhi' date='2016-04-18T08:40:25Z'>
 		Tried it with /opt/models/ggnet. Getting the same error.
 Also, I am running dd server inside docker (ubuntu) and this script outside. Is that right?
 		</comment>
 		<comment id='5' author='voidabhi' date='2016-04-18T08:45:25Z'>
 		Your docker container cannot read outside of its own filesystem without some work. By default, our docker container mounts /data for internal use. You can either move your model inside the container, or create /data and put it in there to then try to get the server to access it from within the container. In all cases I suggest you read a bit on how to share filesystem between outside and inside docker containers, especially if the two options above do not work easily for you.
 		</comment>
 		<comment id='6' author='voidabhi' date='2016-04-18T08:49:54Z'>
 		I guess i have communicated it wrong.
 The complete dd project including templates and models are inside the docker container filesystem.
 Only the scripts for creating and testing services are outside.
 		</comment>
 		<comment id='7' author='voidabhi' date='2016-04-18T09:01:02Z'>
 		Please come onto &lt;denchmark-link:https://gitter.im/beniz/deepdetect&gt;https://gitter.im/beniz/deepdetect&lt;/denchmark-link&gt;
  as this would take too long within a ticket.
 		</comment>
 		<comment id='8' author='voidabhi' date='2016-04-18T09:06:47Z'>
 		[closed by mistake]
 		</comment>
 		<comment id='9' author='voidabhi' date='2016-05-05T16:24:56Z'>
 		&lt;denchmark-link:https://github.com/voidabhi&gt;@voidabhi&lt;/denchmark-link&gt;
  have you succeeded by yourself (or given up) ?
 		</comment>
 		<comment id='10' author='voidabhi' date='2016-05-07T10:11:57Z'>
 		&lt;denchmark-link:https://github.com/beniz&gt;@beniz&lt;/denchmark-link&gt;
  Unfortunately when i had tried again with my updates in dockerfile it didn't work. Didn't get time in between to resolve the issue.
 		</comment>
 		<comment id='11' author='voidabhi' date='2016-05-15T21:19:30Z'>
 		&lt;denchmark-link:https://github.com/voidabhi&gt;@voidabhi&lt;/denchmark-link&gt;
  my apologies for the delay. So, I've taken time to give it a try and your Python script needs to be modified to not use the  parameter, as below:
 from dd_client import DD
 dd = DD('localhost')
 dd.set_return_format(dd.RETURN_PYTHON)
 description = 'image classification service'
 mllib = 'caffe'
 model = {'repository':'../../models/ggnet'}
 parameters_input = {'connector':'image'}
 parameters_mllib = {'nclasses':1000}
 parameters_output = {}
 print dd.put_service('myserv',model,description,mllib,
                parameters_input,parameters_mllib,parameters_output)
 That is, use the template parameter to create the neural net architecture once, and after that remove it.
 The reason is that there's a pre-trained model in  after the service has been created once. The deepdetect server now includes a protection against using a  when a model and its neural net architecture files are already in a repository (&lt;denchmark-link:https://github.com/beniz/deepdetect/commit/d84ea7f5f92aead307f860a7ce2bc28fc7ace334&gt;beniz@d84ea7f&lt;/denchmark-link&gt;
 ). While this is generating issues to new users, it was a mandatory step to ensure that production systems cannot be broken (and net architecture lost) with a missplaced API call.
 In the case of the docker deepdetect container documentation, I still consider this is a bug. The solution we are slowly converging to is to add an override on/off toggle to the API.
 		</comment>
 		<comment id='12' author='voidabhi' date='2016-05-16T13:40:57Z'>
 		The commit above fixes the issue, and README has been updated. Closing. cc &lt;denchmark-link:https://github.com/voidabhi&gt;@voidabhi&lt;/denchmark-link&gt;
  in case you decide to retry, let us know how it goes.
 		</comment>
 		<comment id='13' author='voidabhi' date='2017-10-12T06:50:23Z'>
 		It seems the files type in docker are read as  DT_UNKNOWN, so add the "DT_UNKNOWN" files to the file list could solver the problem in my case.
 		</comment>
 	</comments>
 </bug>
<commit id='ff7bf26369f32e3496c295b80fb6302633ed86aa' author='Emmanuel Benazera' date='2016-05-16 15:39:40+02:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='docker\README.md' new_name='docker\README.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>40,68</added_lines>
 			<deleted_lines>40,68</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='docker\cpu\Dockerfile' new_name='docker\cpu\Dockerfile'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>33,34</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='docker\gpu\Dockerfile' new_name='docker\gpu\Dockerfile'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>34,35</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
