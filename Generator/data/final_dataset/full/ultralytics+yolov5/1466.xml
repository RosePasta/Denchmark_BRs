<bug_data>
<bug id='1466' author='glenn-jocher' open_date='2020-11-21T11:43:52Z' closed_time='2020-12-09T01:40:50Z'>
 	<summary>mAP bug at higher --conf</summary>
 	<description>
 A recent modification to the PR curve in pull request &lt;denchmark-link:https://github.com/ultralytics/yolov5/pull/1206&gt;#1206&lt;/denchmark-link&gt;
  computation introduced a bug whereby mAP increases at higher --conf thresholds. This was caused by a change to the 'sentinel values' on the P and R vectors here:
     # Append sentinel values to beginning and end
     mrec = recall  # np.concatenate(([0.], recall, [recall[-1] + 1E-3]))
     mpre = precision  # np.concatenate(([0.], precision, [0.]))
 The appropriate solution would be to reinstitute the old code, which drops the curves to zero after their last data point, or to interpolate it to zero at recall = 1. I'll experiment with both and implement a fix soon.
 This does not affect any operations using the default test.py --conf 0.001, so I would imagine almost no users would be impacted by this, but it needs fixing in any case.
 	</description>
 	<comments>
 		<comment id='1' author='glenn-jocher' date='2020-11-21T11:45:22Z'>
 		A third option would be to extrapolate the curves to zero based on their last known derivatives. I think np.interp has an option for this baked in, could be used in conjunction with np.clip(0,1).
 		</comment>
 		<comment id='2' author='glenn-jocher' date='2020-12-08T15:21:12Z'>
 		Update on this. np.interp does not have built in extrapolation capability, we would  need to mode to scipy for that, so I think I will simply turn back the clock on the code updates introduced in PR &lt;denchmark-link:https://github.com/ultralytics/yolov5/pull/1206&gt;#1206&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='0bb43953ebc1145b8a53ce76b8c56c7d6bf4bc7a' author='Glenn Jocher' date='2020-12-08 17:40:49-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='utils\metrics.py' new_name='utils\metrics.py'>
 		<file_info nloc='118' complexity='33' token_count='1538'></file_info>
 		<method name='compute_ap' parameters='recall,precision'>
 				<method_info nloc='12' complexity='2' token_count='171' nesting_level='0' start_line='79' end_line='104'></method_info>
 			<added_lines>80,82,83,85,89,90</added_lines>
 			<deleted_lines>80,81,83,84,86,90,91</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
