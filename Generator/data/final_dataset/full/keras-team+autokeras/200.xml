<bug_data>
<bug id='200' author='chuanmingliu' open_date='2018-09-17T10:00:07Z' closed_time='2019-08-19T05:31:49Z'>
 	<summary>semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown   len(cache))</summary>
 	<description>
 &lt;denchmark-h:h3&gt;Bug Description&lt;/denchmark-h&gt;
 
 Hi, everyone! When I try to use autokeras fit some data and label, I encounter such warnings as:
 "semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown   len(cache))"
 After some iterations, for example, after prompt "Model 9", the program is hanging due to insufficient memory.
 I don't think it has connection with my code, here is my code:
 &lt;denchmark-code&gt;from autokeras.image_supervised import ImageClassifier
 import numpy as np
 
 if __name__ == '__main__':
     x_train = np.load('x_train.npy')
     y_train = np.load('y_train.npy')
     x_test = np.load('x_test.npy')
     y_test = np.load('y_test.npy')
     x_train = x_train.reshape((-1, 32, 32, 3))
     y_train.reshape((-1, 1))
     x_test = x_test.reshape((-1, 32, 32, 3))
     y_test = y_test.reshape((-1, 1))
     clf = ImageClassifier(verbose=True)
     clf.fit(x_train, y_train, time_limit=12*60*60)
     clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)
     pred = clf.evaluate(x_test, y_test)
     print(pred)
 &lt;/denchmark-code&gt;
 
 The magnitude of my dataset is similar to CIFAR10.
 I want to know, how to fix this warning and following memory issue? Does anyone has experience in fixing such things? Thanks in advance.
 &lt;denchmark-h:h3&gt;Reproducing Steps&lt;/denchmark-h&gt;
 
 Steps to reproduce the behavior:
 
 Step 1: ...
 Step 2: ...
 
 &lt;denchmark-h:h3&gt;Expected Behavior&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h3&gt;Setup Details&lt;/denchmark-h&gt;
 
 Include the details about the versions of:
 
 OS type and version: Ubuntu 16.04
 Python: 3.6
 autokeras: 
 scikit-learn:
 numpy:
 keras: 2.2.2
 scipy:
 tensorflow: 1.10.0
 pytorch:
 All requirements are installed by "pip install autokeras" and I run my code in a Docker instance,
 Some info on my Docker environment:
 chuanming@Galadriel:~$ nvidia-docker version
 NVIDIA Docker: 2.0.3
 Client:
 Version: 18.03.1-ce
 API version: 1.37
 Go version: go1.9.5
 Git commit: 9ee9f40
 Built: Thu Apr 26 07:17:20 2018
 OS/Arch: linux/amd64
 Experimental: false
 Orchestrator: swarm
 
 Server:
 Engine:
 Version: 18.03.1-ce
 API version: 1.37 (minimum version 1.12)
 Go version: go1.9.5
 Git commit: 9ee9f40
 Built: Thu Apr 26 07:15:30 2018
 OS/Arch: linux/amd64
 Experimental: false
 &lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='chuanmingliu' date='2018-09-25T03:50:17Z'>
 		I experienced the same warning.
 UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown
 len(cache))
 		</comment>
 		<comment id='2' author='chuanmingliu' date='2018-10-21T11:12:42Z'>
 		Same issue here. But how long will autokeras terminate on MNIST training? It's training on my mac in 8 hours. As screenshot below.
 &lt;denchmark-link:https://user-images.githubusercontent.com/6853884/47266158-3efd4900-d565-11e8-8a0f-d93aaa3037be.png&gt;&lt;/denchmark-link&gt;
 
 How to get the resulted model? Which path does these models save?
 		</comment>
 		<comment id='3' author='chuanmingliu' date='2019-08-12T04:55:31Z'>
 		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
 		</comment>
 	</comments>
 </bug>
<commit id='b2fc09bef6c6609a0bea421cd09a641d1ed5c873' author='tl-yang' date='2018-12-21 08:43:29-06:00'>
 	<dmm_unit complexity='1.0' interfacing='0.7708333333333334' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='autokeras\bayesian.py' new_name='autokeras\bayesian.py'>
 		<file_info nloc='312' complexity='91' token_count='2594'></file_info>
 		<method name='generate' parameters='self,descriptors,timeout,sync_message'>
 				<method_info nloc='55' complexity='17' token_count='430' nesting_level='1' start_line='310' end_line='381'></method_info>
 			<added_lines>310,316,350</added_lines>
 			<deleted_lines>310,316,350</deleted_lines>
 		</method>
 		<method name='generate' parameters='self,descriptors,timeout,multiprocessing_queue'>
 				<method_info nloc='55' complexity='16' token_count='416' nesting_level='1' start_line='310' end_line='381'></method_info>
 			<added_lines>310,316,350</added_lines>
 			<deleted_lines>310,316,350</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>6</added_lines>
 			<deleted_lines>6</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='autokeras\nn\layers.py' new_name='autokeras\nn\layers.py'>
 		<file_info nloc='368' complexity='119' token_count='2887'></file_info>
 		<modified_lines>
 			<added_lines>516,517,518,519,520,521,522,523,524,525,526,527</added_lines>
 			<deleted_lines>516,517,518,519,520,521,522,523,524,525,526,527</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='autokeras\nn\model_trainer.py' new_name='autokeras\nn\model_trainer.py'>
 		<file_info nloc='317' complexity='40' token_count='1820'></file_info>
 		<method name='_train' parameters='self'>
 				<method_info nloc='22' complexity='7' token_count='160' nesting_level='1' start_line='155' end_line='179'></method_info>
 			<added_lines>167,168</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='train_model' parameters='self,max_iter_num,max_no_improvement_num,timeout'>
 				<method_info nloc='4' complexity='1' token_count='17' nesting_level='1' start_line='54' end_line='57'></method_info>
 			<added_lines>56,57</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_test' parameters='self'>
 				<method_info nloc='27' complexity='7' token_count='242' nesting_level='1' start_line='181' end_line='214'></method_info>
 			<added_lines>196,197</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='train_model' parameters='self,max_iter_num,max_no_improvement_num'>
 				<method_info nloc='3' complexity='1' token_count='13' nesting_level='1' start_line='50' end_line='52'></method_info>
 			<added_lines>51</added_lines>
 			<deleted_lines>52</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>2,4,7,12,61,97,98,104,121,282,283</added_lines>
 			<deleted_lines>1,91,269</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='autokeras\search.py' new_name='autokeras\search.py'>
 		<file_info nloc='220' complexity='49' token_count='1666'></file_info>
 		<method name='sp_search' parameters='self,graph,other_info,model_id,train_data,test_data,timeout'>
 				<method_info nloc='12' complexity='5' token_count='125' nesting_level='1' start_line='240' end_line='270'></method_info>
 			<added_lines>240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270</added_lines>
 			<deleted_lines>244,247,248,249,266</deleted_lines>
 		</method>
 		<method name='train' parameters='q,graph,train_data,test_data,trainer_args,metric,loss,verbose,path'>
 				<method_info nloc='23' complexity='6' token_count='161' nesting_level='0' start_line='266' end_line='289'></method_info>
 			<added_lines>266,267,268,269,270,271,285,288,289</added_lines>
 			<deleted_lines>266</deleted_lines>
 		</method>
 		<method name='generate' parameters='self,remaining_time,multiprocessing_queue'>
 				<method_info nloc='8' complexity='2' token_count='69' nesting_level='1' start_line='244' end_line='263'></method_info>
 			<added_lines>244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263</added_lines>
 			<deleted_lines>244,247,248,249</deleted_lines>
 		</method>
 		<method name='generate' parameters='self,multiprocessing_queue'>
 				<method_info nloc='9' complexity='2' token_count='80' nesting_level='1' start_line='285' end_line='304'></method_info>
 			<added_lines>285,288,289,296</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='train' parameters='q,graph,train_data,test_data,trainer_args,metric,loss,verbose,path,timeout'>
 				<method_info nloc='27' complexity='8' token_count='189' nesting_level='0' start_line='320' end_line='347'></method_info>
 			<added_lines>320,344,345,346,347</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='_search_common' parameters='self,mp_queue'>
 				<method_info nloc='11' complexity='2' token_count='77' nesting_level='1' start_line='306' end_line='317'></method_info>
 			<added_lines>306,307,308,309,310,311,312,313,314,315,316,317</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mp_search' parameters='self,graph,other_info,model_id,train_data,test_data,timeout'>
 				<method_info nloc='19' complexity='6' token_count='183' nesting_level='1' start_line='199' end_line='238'></method_info>
 			<added_lines>199,200,203,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226</added_lines>
 			<deleted_lines>199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217</deleted_lines>
 		</method>
 		<method name='search' parameters='self,train_data,test_data,timeout'>
 				<method_info nloc='15' complexity='5' token_count='160' nesting_level='1' start_line='164' end_line='197'></method_info>
 			<added_lines>183,193,194,196,197</added_lines>
 			<deleted_lines>176,190,192,195</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1,5,7,8,91,94,95,198,318</added_lines>
 			<deleted_lines>7,9,10,90,198</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='examples\mnist.py' new_name='examples\mnist.py'>
 		<file_info nloc='11' complexity='0' token_count='120'></file_info>
 		<modified_lines>
 			<added_lines>6,7</added_lines>
 			<deleted_lines>6,7</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\nn\test_model_trainer.py' new_name='tests\nn\test_model_trainer.py'>
 		<file_info nloc='48' complexity='4' token_count='348'></file_info>
 		<method name='test_model_trainer_timout' parameters=''>
 				<method_info nloc='13' complexity='1' token_count='87' nesting_level='0' start_line='44' end_line='56'></method_info>
 			<added_lines>44,45,46,47,48,49,50,51,52,53,54,55,56</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>8,42,43</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\test_search.py' new_name='tests\test_search.py'>
 		<file_info nloc='83' complexity='12' token_count='739'></file_info>
 		<method name='test_bayesian_searcher_sp' parameters='_,_1,_2,_3'>
 				<method_info nloc='11' complexity='2' token_count='101' nesting_level='0' start_line='32' end_line='42'></method_info>
 			<added_lines>32,33,34,35,36,37,38,39,40,41,42</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>28,29,30,31,43,44</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
