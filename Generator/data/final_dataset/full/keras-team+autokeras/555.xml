<bug_data>
<bug id='555' author='kylechang523' open_date='2019-02-26T22:31:02Z' closed_time='2019-03-26T22:30:59Z'>
 	<summary>Why Mlp module use conv.py?</summary>
 	<description>
 &lt;denchmark-h:h3&gt;Bug Description&lt;/denchmark-h&gt;
 
 When I using the Mlp module for training the dataset with shape (897000,43), it can work for some model. However when i extend the training time, there is a bug saying 'weight should at least have at  least two dimensions' appearing. We check the source code and this because the mlp module using convolution method in pytorch. This seems very strange.
 May I ask how to solve this problem?
 &lt;denchmark-h:h3&gt;Reproducing Steps&lt;/denchmark-h&gt;
 
 Steps to reproduce the behavior:
 
 Step 1: ...
 Step 2: ...
 
 &lt;denchmark-h:h3&gt;Expected Behavior&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h3&gt;Setup Details&lt;/denchmark-h&gt;
 
 Include the details about the versions of:
 
 OS type and version:
 Python: 3.6
 autokeras: 0.3.7
 scikit-learn: 0.20.2
 numpy:
 keras:
 scipy:
 tensorflow: 1.12.0
 pytorch:
 
 &lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='kylechang523' date='2019-02-28T07:57:19Z'>
 		I have the exact same issue using the MlpModule. The training work for a few models and then throws an error saying weight should have at least two dimensions.
 Any ideas will be appreciated.
 Here is the traceback:
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File "py36/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
     self.run()
   File "py36/lib/python3.6/multiprocessing/process.py", line 93, in run
     self._target(*self._args, **self._kwargs)
   File "py36/lib/python3.6/site-packages/autokeras/search.py", line 350, in train
     raise e
   File "py36/lib/python3.6/site-packages/autokeras/search.py", line 343, in train
     verbose=verbose).train_model(**trainer_args)
   File "py36/lib/python3.6/site-packages/autokeras/nn/model_trainer.py", line 137, in train_model
     self._train()
   File "py36/lib/python3.6/site-packages/autokeras/nn/model_trainer.py", line 173, in _train
     outputs = self.model(inputs)
   File "py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
     result = self.forward(*input, **kwargs)
   File "py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 123, in forward
     outputs = self.parallel_apply(replicas, inputs, kwargs)
   File "py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 133, in parallel_apply
     return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
   File "py36/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 77, in parallel_apply
     raise output
   File "py36/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 53, in _worker
     output = module(*input, **kwargs)
   File "py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
     result = self.forward(*input, **kwargs)
   File "py36/lib/python3.6/site-packages/autokeras/nn/graph.py", line 686, in forward
     temp_tensor = torch_layer(edge_input_tensor)
   File "py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
     result = self.forward(*input, **kwargs)
   File "py36/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 421, in forward
     self.padding, self.dilation, self.groups)
 RuntimeError: weight should have at least two dimensions
 &lt;/denchmark-code&gt;
 
 		</comment>
 		<comment id='2' author='kylechang523' date='2019-02-28T13:32:52Z'>
 		After more extensive testing, I'm able to add some information:
 Each time the error is thrown, the last added operation in the log is either to_add_skip_model or to_concat_skip_model. It's also the first time they are called.
 I'm able to reproduce the bug easily with the small iris dataset in less than 5 minutes with the following code:
 from sklearn import datasets
 from sklearn.preprocessing import OneHotEncoder
 from sklearn.model_selection import train_test_split
 from autokeras import MlpModule
 from autokeras.nn.loss_function import classification_loss
 from autokeras.nn.metric import Accuracy
 from autokeras.preprocessor import DataTransformerMlp
 
 iris = datasets.load_iris()
 
 X = iris.data
 Y = iris.target.reshape(-1, 1)
 
 encoder = OneHotEncoder(sparse=False)
 encoder.fit(Y)
 Y_encoded = encoder.transform(Y)
 n_classes = len(Y_encoded[0])
 
 x_train, x_test, y_train, y_test = train_test_split(
         X,
         Y_encoded,
         test_size=0.33)
 
 data_transformer = DataTransformerMlp(x_train)
 train_data = data_transformer.transform_train(x_train, y_train)
 test_data = data_transformer.transform_test(x_test, y_test)
 
 clf = MlpModule(loss=classification_loss,
                 metric=Accuracy,
                 searcher_args={},
                 verbose=True,
                 path='./result_tmp/')
 
 clf.fit(n_output_node=n_classes,
         input_shape=train_data.dataset.dataset.shape,
         train_data=train_data,
         test_data=test_data,
         time_limit=1 * 5 * 60)
 
 clf.final_fit(train_data,
               test_data,
               retrain=False,
               trainer_args={
                   'max_iter_num': 20,
                   'max_no_improvement_num': 5
                   })
 Unfortunately, my knowledge on the project is too low for me to dig deeper.
 		</comment>
 		<comment id='3' author='kylechang523' date='2019-03-02T20:46:54Z'>
 		I think this is a bug. we need to figure out a way to prevent it from calling these two functions in the MLP module.
 		</comment>
 		<comment id='4' author='kylechang523' date='2019-03-08T02:27:49Z'>
 		This sounds similar to the bug I just opened &lt;denchmark-link:https://github.com/keras-team/autokeras/issues/570&gt;#570&lt;/denchmark-link&gt;
 , except that it complains that i should have at least three dimensions. Also, mine occurred at line 451 in conv.py but looks like same area.
 		</comment>
 		<comment id='5' author='kylechang523' date='2019-03-15T15:55:23Z'>
 		Stuck here with the same bug. To add on, hoping it might help: for me it stops with the exact same exception and it does so consistently on the third model training ("training model 2") irrespective of the input regression data.
 Just to let you know: very much looking forward to using this when fixed. Your project's very much appreciated.
 		</comment>
 	</comments>
 </bug>
<commit id='a575fa5515840958c78adecd242651a369fe95a7' author='Yashwanth Reddy' date='2019-03-26 17:30:58-05:00'>
 	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='autokeras\bayesian.py' new_name='autokeras\bayesian.py'>
 		<file_info nloc='313' complexity='91' token_count='2606'></file_info>
 		<method name='generate' parameters='self,descriptors,timeout,sync_message'>
 				<method_info nloc='55' complexity='17' token_count='431' nesting_level='1' start_line='311' end_line='382'></method_info>
 			<added_lines>360</added_lines>
 			<deleted_lines>359</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,searcher,t_min,metric,beta,skip_conn'>
 				<method_info nloc='8' complexity='2' token_count='67' nesting_level='1' start_line='292' end_line='299'></method_info>
 			<added_lines>292,299</added_lines>
 			<deleted_lines>292</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,searcher,t_min,metric,beta'>
 				<method_info nloc='7' complexity='2' token_count='58' nesting_level='1' start_line='292' end_line='298'></method_info>
 			<added_lines>292</added_lines>
 			<deleted_lines>292</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='autokeras\net_module.py' new_name='autokeras\net_module.py'>
 		<file_info nloc='115' complexity='21' token_count='868'></file_info>
 		<method name='__init__' parameters='self,loss,metric,searcher_args,path,verbose'>
 				<method_info nloc='3' complexity='1' token_count='56' nesting_level='1' start_line='161' end_line='163'></method_info>
 			<added_lines>162</added_lines>
 			<deleted_lines>161</deleted_lines>
 		</method>
 		<method name='fit' parameters='self,n_output_node,input_shape,train_data,test_data,time_limit'>
 				<method_info nloc='29' complexity='8' token_count='251' nesting_level='1' start_line='45' end_line='87'></method_info>
 			<added_lines>68</added_lines>
 			<deleted_lines>67</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,loss,metric,searcher_args,path,verbose,search_type'>
 				<method_info nloc='12' complexity='4' token_count='100' nesting_level='1' start_line='31' end_line='42'></method_info>
 			<added_lines>31</added_lines>
 			<deleted_lines>31</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,loss,metric,searcher_args,path,verbose,search_type,skip_conn'>
 				<method_info nloc='13' complexity='4' token_count='109' nesting_level='1' start_line='31' end_line='43'></method_info>
 			<added_lines>31,43</added_lines>
 			<deleted_lines>31</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='autokeras\net_transformer.py' new_name='autokeras\net_transformer.py'>
 		<file_info nloc='89' complexity='32' token_count='736'></file_info>
 		<method name='transform' parameters='graph,skip_conn'>
 				<method_info nloc='16' complexity='9' token_count='115' nesting_level='0' start_line='102' end_line='120'></method_info>
 			<added_lines>102,105</added_lines>
 			<deleted_lines>102,105</deleted_lines>
 		</method>
 		<method name='transform' parameters='graph'>
 				<method_info nloc='16' complexity='8' token_count='107' nesting_level='0' start_line='102' end_line='120'></method_info>
 			<added_lines>102,105</added_lines>
 			<deleted_lines>102,105</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='autokeras\search.py' new_name='autokeras\search.py'>
 		<file_info nloc='262' complexity='59' token_count='1909'></file_info>
 		<method name='__init__' parameters='self,n_output_node,input_shape,path,metric,loss,generators,verbose,trainer_args,default_model_len,default_model_width,t_min'>
 				<method_info nloc='4' complexity='1' token_count='35' nesting_level='1' start_line='292' end_line='295'></method_info>
 			<added_lines></added_lines>
 			<deleted_lines>295</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,n_output_node,input_shape,path,metric,loss,generators,verbose,trainer_args,default_model_len,default_model_width,t_min,skip_conn'>
 				<method_info nloc='4' complexity='1' token_count='39' nesting_level='1' start_line='295' end_line='298'></method_info>
 			<added_lines>298</added_lines>
 			<deleted_lines>295</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,n_output_node,input_shape,path,metric,loss,generators,verbose,trainer_args,default_model_len,default_model_width,skip_conn'>
 				<method_info nloc='5' complexity='1' token_count='35' nesting_level='1' start_line='48' end_line='52'></method_info>
 			<added_lines>51,52</added_lines>
 			<deleted_lines>51</deleted_lines>
 		</method>
 		<method name='__init__' parameters='self,n_output_node,input_shape,path,metric,loss,generators,verbose,trainer_args,default_model_len,default_model_width'>
 				<method_info nloc='4' complexity='1' token_count='31' nesting_level='1' start_line='48' end_line='51'></method_info>
 			<added_lines>51</added_lines>
 			<deleted_lines>51</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>83,84,304,305,308</added_lines>
 			<deleted_lines>301,304</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\common.py' new_name='tests\common.py'>
 		<file_info nloc='229' complexity='31' token_count='2248'></file_info>
 		<method name='simple_transform' parameters='graph,skip_conn'>
 				<method_info nloc='3' complexity='1' token_count='24' nesting_level='0' start_line='299' end_line='301'></method_info>
 			<added_lines>299</added_lines>
 			<deleted_lines>299</deleted_lines>
 		</method>
 		<method name='simple_transform' parameters='graph'>
 				<method_info nloc='3' complexity='1' token_count='20' nesting_level='0' start_line='299' end_line='301'></method_info>
 			<added_lines>299</added_lines>
 			<deleted_lines>299</deleted_lines>
 		</method>
 		<method name='simple_transform_mlp' parameters='graph,skip_conn'>
 				<method_info nloc='3' complexity='1' token_count='24' nesting_level='0' start_line='304' end_line='306'></method_info>
 			<added_lines>304</added_lines>
 			<deleted_lines>304</deleted_lines>
 		</method>
 		<method name='simple_transform_mlp' parameters='graph'>
 				<method_info nloc='3' complexity='1' token_count='20' nesting_level='0' start_line='304' end_line='306'></method_info>
 			<added_lines>304</added_lines>
 			<deleted_lines>304</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
