<bug_data>
<bug id='4705' author='jtfogarty' open_date='2020-01-30T20:27:49Z' closed_time='2020-02-05T22:35:58Z'>
 	<summary>Jupyter UI shows error while waiting for pod to bind PVC</summary>
 	<description>
 /kind bug
 What steps did you take and what happened:
 Created a Notebook Server using Rook/Ceph as the storage layer.
 Pod created but the UI shows a red X in the status.
 &lt;denchmark-link:https://user-images.githubusercontent.com/6708730/73487270-43213480-436c-11ea-8bf9-a91892cfa9d6.png&gt;&lt;/denchmark-link&gt;
 
 What did you expect to happen:
 Pod to start without issue
 Environment:
 
 Kubeflow version: (version number can be found at the bottom left corner of the Kubeflow dashboard):
 kfctl version:  v1.0-rc.1-0-g963c787
 Kubernetes platform: v1.15.7
 Kubernetes version: v1.15.7
 OS (e.g. from /etc/os-release): NAME="CentOS Linux"
 VERSION="7 (Core)"
 
 	</description>
 	<comments>
 		<comment id='1' author='jtfogarty' date='2020-01-30T20:27:59Z'>
 		Issue-Label Bot is automatically applying the labels:
 
 
 
 Label
 Probability
 
 
 
 
 kind/bug
 0.98
 
 
 
 Please mark this comment with  or  to give our bot feedback!
 Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/marketplace/issue-label-botdata/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
  for this bot.
 		</comment>
 		<comment id='2' author='jtfogarty' date='2020-01-30T20:29:09Z'>
 		/area front-end
 /priority p0
 		</comment>
 		<comment id='3' author='jtfogarty' date='2020-01-30T20:29:52Z'>
 		The pod eventually starts and the status turns green
 		</comment>
 		<comment id='4' author='jtfogarty' date='2020-02-01T17:47:22Z'>
 		&lt;denchmark-link:https://github.com/jtfogarty&gt;@jtfogarty&lt;/denchmark-link&gt;
  is this still an issue?
 I suspect this is because the Rook (Ceph) provisioner is taking some time to provision the Persistent Volume, so in the meantime you get this message.
 		</comment>
 		<comment id='5' author='jtfogarty' date='2020-02-03T17:28:50Z'>
 		Downgrading to P1 because this doesn't seem like its release blocking.
 		</comment>
 		<comment id='6' author='jtfogarty' date='2020-02-03T19:53:27Z'>
 		&lt;denchmark-link:https://github.com/yanniszark&gt;@yanniszark&lt;/denchmark-link&gt;
  Yes, this is still an issue
 		</comment>
 		<comment id='7' author='jtfogarty' date='2020-02-04T06:14:49Z'>
 		I observed the same behavior on GCP using the default storage class (not ROK).
 Bump back to P0; I think this is going to confuse a lot of people.
 &lt;denchmark-link:https://github.com/fediazgon&gt;@fediazgon&lt;/denchmark-link&gt;
  &lt;denchmark-link:https://github.com/kimwnasptd&gt;@kimwnasptd&lt;/denchmark-link&gt;
  Is this related to the changes in the UI to surface events? Is there an easy way to show something less confusing to users?
 		</comment>
 		<comment id='8' author='jtfogarty' date='2020-02-04T07:42:03Z'>
 		Yes, it is related to &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/4214/files#diff-d575d8cda5f10ed63f52ac8e7a65b733R328&gt;this change&lt;/denchmark-link&gt;
 . Right now the UI shows that status when the event matches the following predicate .
 One solution would be to limit the events that are shown by looking at the event's description. &lt;denchmark-link:https://github.com/kimwnasptd&gt;@kimwnasptd&lt;/denchmark-link&gt;
  WDYT?
 		</comment>
 		<comment id='9' author='jtfogarty' date='2020-02-05T03:17:44Z'>
 		&lt;denchmark-link:https://github.com/fediazgon&gt;@fediazgon&lt;/denchmark-link&gt;
  thanks. What if we just returned STATUS_WAITING rather than STATUS_ERROR
 &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/4214/files#diff-d575d8cda5f10ed63f52ac8e7a65b733R329&gt;https://github.com/kubeflow/kubeflow/pull/4214/files#diff-d575d8cda5f10ed63f52ac8e7a65b733R329&lt;/denchmark-link&gt;
 
 I guess the downside is that we might get stuck in waiting mode even for permanent errors. But that seems preferable to always showing an error.
 		</comment>
 		<comment id='10' author='jtfogarty' date='2020-02-05T12:15:43Z'>
 		I'm also in favor of &lt;denchmark-link:https://github.com/fediazgon&gt;@fediazgon&lt;/denchmark-link&gt;
  's proposal. I think returning STATUS_WAITING will take us back from where we started when we would show the spinner even if the underlying Pod would fail to be created.
 Looking at the description of the events seems a little dirty and in the future we might bump into another event that we hadn't anticipated and need to extend the description pattern matching.
 But given the current API I think its our only option if we want to be able to treat specific Warning Type Events as non warning/error ones.
 		</comment>
 		<comment id='11' author='jtfogarty' date='2020-02-05T12:58:42Z'>
 		I think we can do both. We can be explicit about the error events that we are expecting and, if we find any unknown error event we just return STATUS_WAITING but we still show the message in the UI.
 I tried to replicate the behaviour in GCP using the default storage class, with the changes in &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/4729&gt;#4729&lt;/denchmark-link&gt;
 , now it shows like this:
 &lt;denchmark-link:https://user-images.githubusercontent.com/12219405/73843649-4fe7d180-481f-11ea-9e38-ce248549cdbb.png&gt;&lt;/denchmark-link&gt;
 
 But it will still display "Insufficient X" or "error looking up service account" as STATUS_ERROR.
 		</comment>
 		<comment id='12' author='jtfogarty' date='2020-02-05T13:01:13Z'>
 		
 Will we be able to do a good job distinguishing permanent from temporary errors?
 Don't we ultimately need to surface events to the user so they can remedy the situation? So rather than trying to classify events as warnings or errors; shouldn't we focus on them?
 
 If Kubernetes is classifying it as a warning and not an error, should we be treating it as an error?
 Here's my failed pod
 &lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4159468/jlewi-0.pod.txt&gt;jlewi-0.pod.txt&lt;/denchmark-link&gt;
 
 In this case the event is
 &lt;denchmark-code&gt;  Warning  FailedScheduling        18m (x2 over 18m)  default-scheduler                                             pod has unbound 
 immediate PersistentVolumeClaims (repeated 2 times)
 &lt;/denchmark-code&gt;
 
 I'm using a default storage class so this will get provisioned automatically. However, if a user attaches an existing PVC or deletes a PVC wouldn't they get similar events? How would you distinguish between a PVC that will eventually get bound and a PVC that will never get bound?
 Similarly, in the case of FailedScheduling if a POD doesn't get scheduled because of CPU that might be permanent or if a user has autoscaling enabled they might just need to wait for autoscaling to kick in.
 Trying to correctly classify errors based on the message seems like we could end up playing wack a mole.
 Would a better medium (i.e. post 1.0) solution be to provide an improved UI to see all events for a notebook?
 Going back to the original issue &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/3673&gt;#3673&lt;/denchmark-link&gt;
  the goal was to surface errors to the user so they could figure out to fix it. So I think we need to surface the events to the user.
 I think right now we accomplish that because if they hover over the spinner they see the message as &lt;denchmark-link:https://github.com/jtfogarty&gt;@jtfogarty&lt;/denchmark-link&gt;
  shows in his screenshot.
 So I think if we showed the waiting icon with the same pop instead of an error we achieve the same goal without confusing users.
 		</comment>
 		<comment id='13' author='jtfogarty' date='2020-02-05T13:26:52Z'>
 		
 Trying to correctly classify errors based on the message seems like we could end up playing wack a mole.
 Would a better medium (i.e. post 1.0) solution be to provide an improved UI to see all events for a notebook?
 
 Sounds fine to me. Let's keep it simple then.
 		</comment>
 		<comment id='14' author='jtfogarty' date='2020-02-05T21:00:07Z'>
 		Confirmed this is working on master now
 &lt;denchmark-link:https://github.com/kubeflow/manifests/tree/830e1a0&gt;https://github.com/kubeflow/manifests/tree/830e1a0&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://user-images.githubusercontent.com/777219/73882705-62f6a380-4817-11ea-9f8e-6d4a3a20ca06.png&gt;&lt;/denchmark-link&gt;
 
 Will LGTM the cherry pick into the 1.0 branch.
 		</comment>
 		<comment id='15' author='jtfogarty' date='2020-02-05T21:01:07Z'>
 		&lt;denchmark-link:https://github.com/kubeflow/manifests/pull/868&gt;kubeflow/manifests#868&lt;/denchmark-link&gt;
 
 Just need to wait for it land in auto-deployed cluster so I can verify on 1.0.
 		</comment>
 		<comment id='16' author='jtfogarty' date='2020-02-05T22:34:48Z'>
 		v1
 &lt;denchmark-link:https://github.com/kubeflow/manifests/tree/7abafe2&gt;https://github.com/kubeflow/manifests/tree/7abafe2&lt;/denchmark-link&gt;
 
 Looks good
 &lt;denchmark-link:https://user-images.githubusercontent.com/777219/73889480-a4da1680-4824-11ea-998f-30ea1a0bb596.png&gt;&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='0c496710150553784f7ebbbd3070cc9c26bfb39c' author='Fernando Diaz' date='2020-02-05 10:33:55-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='components\jupyter-web-app\backend\kubeflow_jupyter\common\utils.py' new_name='components\jupyter-web-app\backend\kubeflow_jupyter\common\utils.py'>
 		<file_info nloc='383' complexity='86' token_count='2586'></file_info>
 		<method name='add_notebook_volume_secret' parameters='nb,secret,secret_name,mnt_path,mode'>
 				<method_info nloc='13' complexity='1' token_count='94' nesting_level='0' start_line='525' end_line='541'></method_info>
 			<added_lines>532</added_lines>
 			<deleted_lines>532</deleted_lines>
 		</method>
 		<method name='find_error_event' parameters='rsrc_events'>
 				<method_info nloc='5' complexity='3' token_count='39' nesting_level='0' start_line='317' end_line='330'></method_info>
 			<added_lines>323,324,328,329</added_lines>
 			<deleted_lines>323,324,328,329</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
