<bug_data>
<bug id='675' author='amybachir' open_date='2020-09-21T19:25:48Z' closed_time='2020-09-24T23:07:55Z'>
 	<summary>fit_summary Error KeyError: 'trial_info'</summary>
 	<description>
 I'm trying autogluon for the first time with a dataset of 75,000 data points and labels.
 autogluon version 0.0.13
 OS:
 Distributor ID: Ubuntu
 Description:    Ubuntu 18.04.4 LTS
 Release:        18.04
 Codename:       bionic
 Here is my predictor, it is a TabularPrediction with hyperparameter_tune turned on:
 predictor = task.fit(train_data=train_data, label=label_column, output_directory=savedir, problem_type='binary', eval_metric='accuracy', hyperparameter_tune=True )
 I tried with hyperparameter_tune  off and the task finished with no problem. Once I turned on hyperparameter_tune, it errored with the following error:
 &lt;denchmark-code&gt;*** Details of Hyperparameter optimization ***
 ---------------------------------------------------------------------------
 KeyError                                  Traceback (most recent call last)
 &lt;ipython-input-2-1b709fc952c0&gt; in &lt;module&gt;
      11 predictor = task.fit(train_data=train_data, label=label_column, output_directory=savedir, problem_type='binary', eval_metric='accuracy', hyperparameter_tune=True )
 ---&gt; 13 results = predictor.fit_summary()
      14 
      15 # Inference time:
 
 /usr/local/lib/python3.6/dist-packages/autogluon/task/tabular_prediction/predictor.py in fit_summary(self, verbosity)
     414                     hpo_model = hpo_results[model_type]
     415                     print("HPO for %s model:  Num. configurations tried = %s, Time spent = %s, Search strategy = %s"
 --&gt; 416                           % (model_type, len(hpo_model['trial_info']), hpo_model['total_time'], hpo_model['search_strategy']))
     417                     print("Best hyperparameter-configuration (validation-performance: %s = %s):"
     418                           % (self.eval_metric, hpo_model['validation_performance']))
 
 KeyError: 'trial_info'
 
 &lt;/denchmark-code&gt;
 
 	</description>
 	<comments>
 		<comment id='1' author='amybachir' date='2020-09-22T06:43:27Z'>
 		Thanks for pointing out this bug. I believe it should be fixed in this PR:  &lt;denchmark-link:https://github.com/awslabs/autogluon/pull/678&gt;#678&lt;/denchmark-link&gt;
 
 if you'd like to install that version of autogluon locally and try it out.
 Also just FYI:  hyperparameter_tune is currently not typically the best way to maximize accuracy in TabularPrediction. Instead consider specifying: task.fit(..., presets='best_quality') which utilizes stack-ensembling instead of HPO.
 &lt;denchmark-link:https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html#maximizing-predictive-performance&gt;https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html#maximizing-predictive-performance&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='amybachir' date='2020-09-22T13:32:32Z'>
 		
 Thanks for pointing out this bug. I believe it should be fixed in this PR: #678
 if you'd like to install that version of autogluon locally and try it out.
 Also just FYI: hyperparameter_tune is currently not typically the best way to maximize accuracy in TabularPrediction. Instead consider specifying: task.fit(..., presets='best_quality') which utilizes stack-ensembling instead of HPO.
 https://autogluon.mxnet.io/tutorials/tabular_prediction/tabular-quickstart.html#maximizing-predictive-performance
 
 Thanks for the tip &lt;denchmark-link:https://github.com/jwmueller&gt;@jwmueller&lt;/denchmark-link&gt;
  ! I will try that out!
 		</comment>
 	</comments>
 </bug>
<commit id='ff86985c5038a1b80188780d51a8ce591c8071ac' author='Jonas Mueller' date='2020-09-24 16:07:52-07:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='autogluon\task\tabular_prediction\predictor.py' new_name='autogluon\task\tabular_prediction\predictor.py'>
 		<file_info nloc='468' complexity='90' token_count='2622'></file_info>
 		<method name='fit_summary' parameters='self,verbosity'>
 				<method_info nloc='97' complexity='26' token_count='639' nesting_level='1' start_line='319' end_line='438'></method_info>
 			<added_lines>424,425,426,427</added_lines>
 			<deleted_lines>424,425,426,427,428</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
