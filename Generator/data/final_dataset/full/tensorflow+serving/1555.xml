<bug_data>
<bug id='1555' author='ericmclachlan' open_date='2020-02-17T12:26:03Z' closed_time='2020-05-28T22:22:45Z'>
 	<summary>TensorFlow Serving "version_labels" do not work as documented for the HTTP REST API</summary>
 	<description>
 &lt;denchmark-h:h2&gt;Bug Report&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;
 
 
 OS Platform and Distribution: Windows 10 and Linux Ubuntu 18.04 in WSL
 TensorFlow Serving installed from: Docker image (binary)
 TensorFlow Serving version: Docker image tensorflow/serving:latest (downloaded around January 20th)
 
 &lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;
 
 At a high level, the version_labels feature appears not to work correctly. (This feature is illustrated with the "canary" vs "stable" version labels example in the TensorFlow &lt;denchmark-link:https://www.tensorflow.org/tfx/serving/serving_config&gt;documentation&lt;/denchmark-link&gt;
 ).
 More specifically, it may only work with simple numeric version labels.
 The following URL will be rejected by TensorFlow Serving: host/v1/models/my_model/versions/1.0:predict
 with a Malformed request... error.
 &lt;denchmark-h:h3&gt;Exact Steps to Reproduce&lt;/denchmark-h&gt;
 
 I believe that any kind of non-numeric version label will fail. (i.e. The "canary" vs "stable" example itself should fail.)
 &lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;
 
 &lt;denchmark-link:https://github.com/tensorflow/serving/blob/e085cb37b4b5c62154aa063dcbb781b24d5b3fd4/tensorflow_serving/model_servers/http_rest_api_handler.cc#L57&gt;http_rest_api_handler.cc&lt;/denchmark-link&gt;
  seems to define a regular expression used to parse the URL. Note that, after "versions", the regular expression defines an expectation for a numeric version.
 prediction_api_regex_(
           R"((?i)/v1/models/([^/:]+)(?:/versions/(\d+))?:(classify|regress|predict))")
 It's possible that I misread the code, but this interpretation agrees with an observation on &lt;denchmark-link:https://stackoverflow.com/questions/59237402/how-to-specify-the-model-version-label-in-a-rest-api-request&gt;StackOverflow&lt;/denchmark-link&gt;
  that numeric versions are handled correctly whereas text version labels are not.
 	</description>
 	<comments>
 		<comment id='1' author='ericmclachlan' date='2020-02-18T06:47:10Z'>
 		&lt;denchmark-link:https://github.com/ericmclachlan&gt;@ericmclachlan&lt;/denchmark-link&gt;
 ,
 Can you please confirm if you have tried Inference using Numeric Version Labels and using Non-Numeric Version Labels.
 And if you observed that Numeric Labels are working fine and Non-Numeric Version Labels are resulting in error, can you please provide the Commands which you have used in both the cases (Numeric and Non-Numeric), and the respective Output or the Error. Thanks!
 		</comment>
 		<comment id='2' author='ericmclachlan' date='2020-02-18T06:48:39Z'>
 		Also, you can look at &lt;denchmark-link:https://medium.com/@brianschardt/how-to-setup-tensorflow-serving-for-production-3cc2abf7efa&gt;this article&lt;/denchmark-link&gt;
  for more information about Configuring Different Versions for Serving.
 		</comment>
 		<comment id='3' author='ericmclachlan' date='2020-02-18T07:24:59Z'>
 		Hi &lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 
 Thank you for the link but we already have TensorFlow Serving working in production. The problem lies specifically in trying to use the version_labels feature as described in the documentation.
 I have just confirmed that sending requests like the following yields predictions:
 &lt;denchmark-code&gt;http://localhost:8501/v1/models/model1/versions/1579843026:predict
 &lt;/denchmark-code&gt;
 
 However, using a URL like this does not:
 &lt;denchmark-code&gt;http://localhost:8501/v1/models/model1/versions/test:predict
 &lt;/denchmark-code&gt;
 
 The only difference between these two is that this one uses the version_labels instead of the version itself.
 The exact error message I receive in the POST response is:
 &lt;denchmark-code&gt;{ "error": "Malformed request: POST /v1/models/model1/versions/test:predict" }
 &lt;/denchmark-code&gt;
 
 This is despite the model.config file containing the following version_labels definition:
 &lt;denchmark-code&gt;config {
     name: 'model1'
     base_path: '/models/model1/'
     model_platform: "tensorflow"
     model_version_policy {
       specific {
         versions: 1579843026
       }
     }
     version_labels {
       key: 'test'
       value: 1579843026
     }
   }
 &lt;/denchmark-code&gt;
 
 I'm 99% sure this specific error message is being reported because &lt;denchmark-link:https://github.com/tensorflow/serving/blob/e085cb37b4b5c62154aa063dcbb781b24d5b3fd4/tensorflow_serving/model_servers/http_rest_api_handler.cc#L94&gt;this line in the code&lt;/denchmark-link&gt;
  is failing; causing the "Malformed request" error defined in the previous few lines to be reported for this POST request.
 Thanks for your help in investigating this problem.
 		</comment>
 		<comment id='4' author='ericmclachlan' date='2020-02-18T08:30:23Z'>
 		&lt;denchmark-link:https://github.com/ericmclachlan&gt;@ericmclachlan&lt;/denchmark-link&gt;
 ,
 Can you please confirm that you have invoked the Tensorflow Model Server along with the Config File, as shown below. Thanks!
 tensorflow_model_server --port=8500 --rest_api_port=8501 --model_config_file=/home/configs/models.conf 
 		</comment>
 		<comment id='5' author='ericmclachlan' date='2020-02-18T08:39:36Z'>
 		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 : I'm deploying the TensorFlow Server using docker-compose. Below is a simplied version:
 &lt;denchmark-code&gt;tensorflow-servings:
     image: tensorflow/serving:latest
     ports:
       - 8500:8500
       - 8501:8501
     command:
       - --allow_version_labels_for_unavailable_models
       - --batching_parameters_file=/config/batching_parameters.txt
       - --enable_batching=true
       - --model_config_file=/config/all_models.config
       - --model_config_file_poll_wait_seconds=10
       - --monitoring_config_file=/config/monitoring_config.txt
       - --rest_api_timeout_in_ms=30000
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;
 
 This &lt;denchmark-link:https://github.com/tensorflow/serving/issues/1413&gt;issue&lt;/denchmark-link&gt;
  on GitHub confirms my observation and suggests:
 
 Re: not being able to access the version using labels via HTTP - this is something that's not possible today (AFAIR) - only through the grpc interface can you declare labels :(
 
 This makes me sad. The limitations of the HTTP implementation should be made more transparent. This investigation has now needlessly cost my company money; as I'm sure it will continue to do for others.
 I'm not upset with you as an individual of course. But it is nonetheless a frustrating situation.
 		</comment>
 		<comment id='6' author='ericmclachlan' date='2020-02-18T21:28:40Z'>
 		&lt;denchmark-link:https://github.com/ericmclachlan&gt;@ericmclachlan&lt;/denchmark-link&gt;
  just out of curiosity - how does the  /config/batching_parameters.txt look like?
 		</comment>
 		<comment id='7' author='ericmclachlan' date='2020-02-19T05:34:49Z'>
 		Hi &lt;denchmark-link:https://github.com/Arnold1&gt;@Arnold1&lt;/denchmark-link&gt;
 
 The batching_parameters.txt looks like this:
 &lt;denchmark-code&gt;max_batch_size { value: 1024 }
 batch_timeout_micros { value: 100 }
 num_batch_threads { value: 4 }
 pad_variable_length_inputs: true
 &lt;/denchmark-code&gt;
 
 Please let me know if anything seems off.
 		</comment>
 		<comment id='8' author='ericmclachlan' date='2020-02-20T02:51:22Z'>
 		Same problemÔºÅ
 		</comment>
 		<comment id='9' author='ericmclachlan' date='2020-03-05T22:51:19Z'>
 		TensorFlow Serving "version_labels" only works using GRPC not REST API.
 		</comment>
 		<comment id='10' author='ericmclachlan' date='2020-03-06T07:19:53Z'>
 		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 : It would probably be helpful if the &lt;denchmark-link:https://www.tensorflow.org/tfx/serving/serving_config&gt;documentation&lt;/denchmark-link&gt;
  describing labels mentioned this limitation upfront.
 It's less an issue of "This doesn't work" as much an issue of "I've just implemented REST and now I've discovered that this documented feature doesn't work unless I don't use REST."
 		</comment>
 		<comment id='11' author='ericmclachlan' date='2020-03-07T02:27:02Z'>
 		&lt;denchmark-link:https://github.com/ericmclachlan&gt;@ericmclachlan&lt;/denchmark-link&gt;
  thanks for pointing out the lack of documentation on this - I've added a note [1] clarifying that version labels don't work for REST.
 &lt;denchmark-link:https://github.com/christisg&gt;@christisg&lt;/denchmark-link&gt;
  how do we feel about fixing this? It's not a lot of work and I'd be happy to take it. We'd have 2 options:
 
 Keep the current path [2] try to parse the version as an int, if failed, use it as a version_label.
 Add a new path (model/&lt;&gt;/version_label/&lt;&gt;) for directing a request to a model using its version label.
 
 Option 1) has the drawback of kinda odd behavior in that it implicitly disallows having version labels that can be parsed as int64 - which is currently undocumented behavior.
 Option 2) has the drawback of deviating greatly from REST principles as the path model/&lt;&gt;/version_label/&lt;&gt; URI no longer really represents a resource hosted by the server (the version_label is an attribute of a specific version of the model, not an identifier).
 WDYT?
 /cc &lt;denchmark-link:https://github.com/netfs&gt;@netfs&lt;/denchmark-link&gt;
  in case he's thought about this before.
 [1] &lt;denchmark-link:https://github.com/tensorflow/serving/commit/9781ed1857ab0b1195107821ad0f3720872546a1&gt;9781ed1&lt;/denchmark-link&gt;
 
 [2] 
 
 		</comment>
 		<comment id='12' author='ericmclachlan' date='2020-03-07T06:48:36Z'>
 		Thanks &lt;denchmark-link:https://github.com/misterpeddy&gt;@misterpeddy&lt;/denchmark-link&gt;
 !
 How about Option 3) keep the current path and use explicit prefix for labels, i.e models/&lt;model_name&gt;/versions/label=&lt;version_label&gt; ?
 The explicit prefix makes it less error prone, and it also allows assigning numerical labels like "1" and "2" if one prefers to.
 		</comment>
 		<comment id='13' author='ericmclachlan' date='2020-03-07T10:25:10Z'>
 		&lt;denchmark-link:https://github.com/misterpeddy&gt;@misterpeddy&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/christisg&gt;@christisg&lt;/denchmark-link&gt;
 : I don't want to dilute the conversation too much; I just wanted to say thanks for seriously considering the suggestion. And thanks for all the work you're are doing for the community.
 		</comment>
 		<comment id='14' author='ericmclachlan' date='2020-03-19T23:46:57Z'>
 		Just a note that I have a preliminary implementation for the awesome idea &lt;denchmark-link:https://github.com/christisg&gt;@christisg&lt;/denchmark-link&gt;
  mentioned and will resume with testing and merging it once we get some of our build breakage (due to incompatibilities with recent changes in upstream TF) under control.
 		</comment>
 		<comment id='15' author='ericmclachlan' date='2020-04-16T00:16:20Z'>
 		&lt;denchmark-link:https://github.com/misterpeddy&gt;@misterpeddy&lt;/denchmark-link&gt;
  Any update on this? Also, We have not moved to Tensorflow 2.0 yet. So, I was wondering if you guys will backport this fix to the older version of TFServing also.
 		</comment>
 	</comments>
 </bug>
<commit id='3df036223b66738de1b873e9b163230fb7661cb4' author='Pedram Pejman' date='2020-05-28 15:22:36-07:00'>
 	<dmm_unit complexity='0.9186046511627907' interfacing='0.7674418604651163' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='tensorflow_serving\g3doc\api_rest.md' new_name='tensorflow_serving\g3doc\api_rest.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>30,33,34,51,54,55,72,75,76,169,172,173</added_lines>
 			<deleted_lines>30,33,34,51,54,55,72,75,168,171</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_serving\g3doc\serving_config.md' new_name='tensorflow_serving\g3doc\serving_config.md'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>137,211,212,213,214,215,216,217,218,219,220,221,222,223,224</added_lines>
 			<deleted_lines>131,132,133,140,141</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_serving\model_servers\http_rest_api_handler.cc' new_name='tensorflow_serving\model_servers\http_rest_api_handler.cc'>
 		<file_info nloc='283' complexity='38' token_count='1784'></file_info>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessModelMetadataRequest' parameters='model_name,model_version,model_version_label,output'>
 				<method_info nloc='57' complexity='6' token_count='355' nesting_level='2' start_line='259' end_line='328'></method_info>
 			<added_lines>261,262,263,267,270,271,272</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessPredictRequest' parameters='model_name,model_version,model_version_label,request_body,output'>
 				<method_info nloc='23' complexity='1' token_count='170' nesting_level='2' start_line='202' end_line='226'></method_info>
 			<added_lines>205,208,209,210,211</added_lines>
 			<deleted_lines>202,203,204,205,206,225,226</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::HttpRestApiHandler' parameters='run_options,core'>
 				<method_info nloc='10' complexity='1' token_count='45' nesting_level='2' start_line='54' end_line='63'></method_info>
 			<added_lines>60,62</added_lines>
 			<deleted_lines>58,60</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::FillModelSpecWithNameVersionAndLabel' parameters='model_name,model_version,model_version_label,model_spec'>
 				<method_info nloc='20' complexity='5' token_count='146' nesting_level='3' start_line='73' end_line='94'></method_info>
 			<added_lines>73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94</added_lines>
 			<deleted_lines>86,87,88,89,90,91,92,93,94</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessPredictRequest' parameters='model_name,model_version,request_body,output'>
 				<method_info nloc='24' complexity='2' token_count='183' nesting_level='2' start_line='163' end_line='187'></method_info>
 			<added_lines>168,171,172,173,187</added_lines>
 			<deleted_lines>168,169,170,171,172</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessModelStatusRequest' parameters='model_name,model_version,model_version_label,output'>
 				<method_info nloc='25' complexity='3' token_count='156' nesting_level='2' start_line='228' end_line='257'></method_info>
 			<added_lines>230,231,232,238,239,240,241,242</added_lines>
 			<deleted_lines>230,233,234,235,236,237,238,239,240</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessClassifyRequest' parameters='model_name,model_version,model_version_label,request_body,output'>
 				<method_info nloc='17' complexity='1' token_count='123' nesting_level='2' start_line='165' end_line='182'></method_info>
 			<added_lines>168,171,172,173</added_lines>
 			<deleted_lines>168,169,170,171,172</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessRequest' parameters='http_method,request_path,request_body,headers,output'>
 				<method_info nloc='60' complexity='15' token_count='390' nesting_level='2' start_line='98' end_line='163'></method_info>
 			<added_lines>107,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,133,134,135,136,137,138,139,140,142,143,145,146,148,149,151,153,154,156,157</added_lines>
 			<deleted_lines>99,100,102,103,105,106,108,109,110,111,113,114,116,129,130,131,132,133,149,150,151,152,153</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessRegressRequest' parameters='model_name,model_version,model_version_label,request_body,output'>
 				<method_info nloc='16' complexity='1' token_count='123' nesting_level='2' start_line='184' end_line='200'></method_info>
 			<added_lines>187,190,191,192</added_lines>
 			<deleted_lines>191,192,198,199,200</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessModelStatusRequest' parameters='model_name,model_version_str,output'>
 				<method_info nloc='29' complexity='5' token_count='192' nesting_level='2' start_line='189' end_line='221'></method_info>
 			<added_lines>190,191,192,205,208,209,210,211</added_lines>
 			<deleted_lines>191,192,198,199,200,201,202,203,204,205,206</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessModelMetadataRequest' parameters='model_name,model_version_str,output'>
 				<method_info nloc='61' complexity='8' token_count='391' nesting_level='2' start_line='223' end_line='296'></method_info>
 			<added_lines>230,231,232,238,239,240,241,242,261,262,263,267,270,271,272</added_lines>
 			<deleted_lines>225,226,230,233,234,235,236,237,238,239,240</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessRegressRequest' parameters='model_name,model_version,request_body,output'>
 				<method_info nloc='17' complexity='2' token_count='136' nesting_level='2' start_line='144' end_line='161'></method_info>
 			<added_lines>145,146,148,149,151,153,154,156,157</added_lines>
 			<deleted_lines>149,150,151,152,153</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandler::ProcessClassifyRequest' parameters='model_name,model_version,request_body,output'>
 				<method_info nloc='18' complexity='2' token_count='136' nesting_level='2' start_line='124' end_line='142'></method_info>
 			<added_lines>124,125,126,127,128,129,130,131,133,134,135,136,137,138,139,140,142</added_lines>
 			<deleted_lines>129,130,131,132,133</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>26,31,95</added_lines>
 			<deleted_lines>95,96</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_serving\model_servers\http_rest_api_handler.h' new_name='tensorflow_serving\model_servers\http_rest_api_handler.h'>
 		<file_info nloc='62' complexity='0' token_count='366'></file_info>
 		<modified_lines>
 			<added_lines>88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112</added_lines>
 			<deleted_lines>88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tensorflow_serving\model_servers\http_rest_api_handler_test.cc' new_name='tensorflow_serving\model_servers\http_rest_api_handler_test.cc'>
 		<file_info nloc='420' complexity='26' token_count='3039'></file_info>
 		<method name='tensorflow::serving::TEST_F' parameters='HttpRestApiHandlerTest,UnsupportedApiCalls'>
 				<method_info nloc='63' complexity='1' token_count='637' nesting_level='3' start_line='175' end_line='250'></method_info>
 			<added_lines>227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::serving::HttpRestApiHandlerTest::CreateServerCore' parameters='server_core'>
 				<method_info nloc='22' complexity='1' token_count='165' nesting_level='4' start_line='82' end_line='112'></method_info>
 			<added_lines>106,107,108,109,110,111</added_lines>
 			<deleted_lines>104</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::TEST_F' parameters='HttpRestApiHandlerTest,Predict'>
 				<method_info nloc='46' complexity='1' token_count='361' nesting_level='3' start_line='319' end_line='373'></method_info>
 			<added_lines>342,343,344,345,346,347,348,349,350,351</added_lines>
 			<deleted_lines>363,366,367</deleted_lines>
 		</method>
 		<method name='tensorflow::serving::TEST_F' parameters='HttpRestApiHandlerTest,Regress'>
 				<method_info nloc='30' complexity='1' token_count='235' nesting_level='3' start_line='375' end_line='409'></method_info>
 			<added_lines>398,399,400,401,402,403,404,405,406,407,408</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::serving::TEST_F' parameters='HttpRestApiHandlerTest,Classify'>
 				<method_info nloc='21' complexity='1' token_count='163' nesting_level='3' start_line='411' end_line='434'></method_info>
 			<added_lines>424,427,428</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::serving::TEST_F' parameters='HttpRestApiHandlerTest,GetStatus'>
 				<method_info nloc='60' complexity='1' token_count='253' nesting_level='3' start_line='436' end_line='501'></method_info>
 			<added_lines>480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='tensorflow::serving::TEST_F' parameters='HttpRestApiHandlerTest,PredictRequestErrors'>
 				<method_info nloc='33' complexity='1' token_count='277' nesting_level='3' start_line='275' end_line='317'></method_info>
 			<added_lines>301,302,303,304,305,306,307,308,309,310</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>56,57</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
