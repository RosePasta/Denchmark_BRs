<bug_data>
<bug id='9434' author='elcombato' open_date='2018-02-20T15:49:58Z' closed_time='2018-02-21T18:52:02Z'>
 	<summary>Error with multiprocessing on Sequence in fit_generator()</summary>
 	<description>
 I'm trying to use a Sequence as the generator for model.fit_generator().
 With use_multiprocessing=False it works fine, but with use_multiprocessing=True an error is produced.
 Minimal working example:
 from keras.utils import Sequence
 from keras.models import Sequential
 from keras.layers import Dense
 from keras.utils import to_categorical
 import numpy as np
 
 class DummySequence(Sequence):
     
     def __init__(self, x_set, y_set, batch_size):
         self.x, self.y = x_set, y_set
         self.batch_size = batch_size
 
     def __len__(self):
         return int(np.ceil(len(self.x) / float(self.batch_size)))
 
     def __getitem__(self, idx):
         batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
         batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
 
         return np.array(batch_x), np.array(batch_y)
 
 if __name__ == '__main__':
 
     x = np.random.random((100, 3))
     y = to_categorical(np.random.random(100) &gt; .5).astype(int)
 
     seq = DummySequence(x, y, 10)
 
     model = Sequential()
     model.add(Dense(32, input_dim=3))
     model.add(Dense(2, activation='softmax'))
     model.compile(optimizer='rmsprop',
                   loss='categorical_crossentropy',
                   metrics=['accuracy'])
 
     model.fit_generator(generator=seq, workers=2, use_multiprocessing=True)
 Error:
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File "C:\Users\elcombato\AppData\Local\Continuum\Anaconda3\envs\ml\lib\multiprocessing\pool.py", line 119, in worker
     result = (True, func(*args, **kwds))
   File "C:\Users\elcombato\AppData\Local\Continuum\Anaconda3\envs\ml\lib\site-packages\keras\utils\data_utils.py", line 392, in get_index
     return _SHARED_SEQUENCES[uid][i]
 KeyError: 0
 &lt;/denchmark-code&gt;
 
 Setup
 Windows 10
 Python 3.6.4
 Keras 2.1.3
 Tensorflow 1.2.1
 	</description>
 	<comments>
 		<comment id='1' author='elcombato' date='2018-02-20T16:15:17Z'>
 		I think that because on Windows, python has to spawn instead of forking, it may cause a mis-representation on the shared Variable. I'll work on it and try to test it on Windows.
 		</comment>
 		<comment id='2' author='elcombato' date='2018-02-20T16:27:01Z'>
 		If you have time, could you try again with this branch while I try to find a pc with Windows? Would be awesome!
 &lt;denchmark-link:https://github.com/Dref360/keras/tree/mp_windows&gt;https://github.com/Dref360/keras/tree/mp_windows&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='3' author='elcombato' date='2018-02-20T16:39:21Z'>
 		Yes that branch is working with multiprocessing!
 		</comment>
 		<comment id='4' author='elcombato' date='2018-02-20T16:45:14Z'>
 		Okay, I'll try something to guarantee that we test all multiprocessing tests on Windows. (At least on python3) and then I'll submit a PR
 		</comment>
 	</comments>
 </bug>
<commit id='ff0690ab533b7b882301f8b836ccfda8fd4f7f21' author='Frédéric Branchaud-Charron' date='2018-02-21 10:52:01-08:00'>
 	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
 	<modification change_type='MODIFY' old_name='keras\utils\data_utils.py' new_name='keras\utils\data_utils.py'>
 		<file_info nloc='472' complexity='100' token_count='2478'></file_info>
 		<method name='_run' parameters='self'>
 				<method_info nloc='17' complexity='6' token_count='119' nesting_level='1' start_line='534' end_line='558'></method_info>
 			<added_lines>542</added_lines>
 			<deleted_lines>534</deleted_lines>
 		</method>
 		<method name='start' parameters='self,workers,max_queue_size'>
 				<method_info nloc='13' complexity='2' token_count='108' nesting_level='1' start_line='505' end_line='525'></method_info>
 			<added_lines>514,515,516,518,519</added_lines>
 			<deleted_lines>509,511</deleted_lines>
 		</method>
 		<method name='init_pool' parameters='seqs'>
 				<method_info nloc='3' complexity='1' token_count='10' nesting_level='0' start_line='376' end_line='378'></method_info>
 			<added_lines>376,377,378</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>379,380</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='tests\keras\utils\data_utils_test.py' new_name='tests\keras\utils\data_utils_test.py'>
 		<file_info nloc='266' complexity='55' token_count='2121'></file_info>
 		<method name='use_spawn' parameters='func'>
 				<method_info nloc='4' complexity='1' token_count='17' nesting_level='0' start_line='28' end_line='38'></method_info>
 			<added_lines>28,29,30,31,32,33,34,35,36,37,38</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='use_spawn.wrapper' parameters='args,kwargs'>
 				<method_info nloc='7' complexity='2' token_count='60' nesting_level='1' start_line='31' end_line='37'></method_info>
 			<added_lines>31,32,33,34,35,36,37</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>9,12,39,40,236,256,268,313</added_lines>
 			<deleted_lines>9</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
