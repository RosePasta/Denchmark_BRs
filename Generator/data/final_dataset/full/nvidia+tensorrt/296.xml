<bug_data>
<bug id='296' author='NHZlX' open_date='2019-12-25T05:24:05Z' closed_time='2020-01-25T23:45:37Z'>
 	<summary>There might be memory leak in instanceNormalizationPlugin</summary>
 	<description>
 There are two places that can cause leaks
 First, every enqueue calls cudamalloc without releasing
 
 
 
 TensorRT/plugin/instanceNormalizationPlugin/instanceNormalizationPlugin.cpp
 
 
          Line 211
       in
       572d54f
 
 
 
 
 
 
  CHECK_CUDA(cudaMalloc((void**) &amp;_d_bias, n * nchan_bytes)); 
 
 
 
 
 
 Second,  cudnn_handle will also be created every time
 
 
 
 TensorRT/plugin/instanceNormalizationPlugin/instanceNormalizationPlugin.cpp
 
 
          Line 217
       in
       572d54f
 
 
 
 
 
 
  CHECK_CUDNN(cudnnCreate(&amp;_cudnn_handle)); 
 
 
 
 
 
 	</description>
 	<comments>
 		<comment id='1' author='NHZlX' date='2019-12-29T14:44:54Z'>
 		May be related: &lt;denchmark-link:https://devtalk.nvidia.com/default/topic/1068998/memory-leak-in-tensorrt-instancenormalization/?offset=2&gt;https://devtalk.nvidia.com/default/topic/1068998/memory-leak-in-tensorrt-instancenormalization/?offset=2&lt;/denchmark-link&gt;
 
 CC &lt;denchmark-link:https://github.com/rajeevsrao&gt;@rajeevsrao&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='NHZlX' date='2020-01-06T11:18:49Z'>
 		Not sure if this is the same, but I have observed a memory leak in OnnxRuntime using TensorRT as can be seen &lt;denchmark-link:https://github.com/microsoft/onnxruntime/issues/2773&gt;microsoft/onnxruntime#2773&lt;/denchmark-link&gt;
 
 Although this model uses BatchNormalization and not InstanceNormalization.
 		</comment>
 		<comment id='3' author='NHZlX' date='2020-01-25T23:45:37Z'>
 		Fixed per &lt;denchmark-link:https://github.com/NVIDIA/TensorRT/pull/315&gt;#315&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='713475808dd6a9dbcca82b8be33cb4d001dce072' author='Rajeev Rao' date='2020-01-06 10:59:55-08:00'>
 	<dmm_unit complexity='None' interfacing='1.0' size='1.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='plugin\instanceNormalizationPlugin\instanceNormalizationPlugin.cpp' new_name='plugin\instanceNormalizationPlugin\instanceNormalizationPlugin.cpp'>
 		<file_info nloc='313' complexity='59' token_count='2236'></file_info>
 		<method name='InstanceNormalizationPlugin::enqueue' parameters='inputDesc,outputDesc,inputs,outputs,workspace,stream'>
 				<method_info nloc='33' complexity='2' token_count='376' nesting_level='0' start_line='199' end_line='239'></method_info>
 			<added_lines>236,237</added_lines>
 			<deleted_lines>217,218,219,220</deleted_lines>
 		</method>
 		<method name='InstanceNormalizationPlugin::terminate' parameters=''>
 				<method_info nloc='14' complexity='2' token_count='50' nesting_level='0' start_line='176' end_line='189'></method_info>
 			<added_lines>176</added_lines>
 			<deleted_lines>185,186</deleted_lines>
 		</method>
 		<method name='InstanceNormalizationPlugin::initialize' parameters=''>
 				<method_info nloc='9' complexity='1' token_count='50' nesting_level='0' start_line='170' end_line='178'></method_info>
 			<added_lines>173,174,175,176</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
