<bug_data>
<bug id='3810' author='phoenix-meadowlark' open_date='2020-11-13T00:05:07Z' closed_time='2020-12-23T21:14:29Z'>
 	<summary>DeduplicateExecutablesPass is ignoring operands and producing incorrect programs</summary>
 	<description>
 While working on new tests for the tensorflow integrations I found two examples of MLIR files with identical functions that appear to be affected by the presence of other function defs during compilation.
 In one case the error happens after compiling a function  to VMLA. In the &lt;denchmark-link:https://gist.github.com/phoenix-meadowlark/ae43e87e3e35490fb77507e08290d842&gt;first file&lt;/denchmark-link&gt;
 , compiling  with only  also in the file behaves as expected. In the &lt;denchmark-link:https://gist.github.com/phoenix-meadowlark/9d8b87bd10c3750b5cdfa4e1b847faeb#file-iree_input__multiple_functions__multiply-mlir-L574&gt;second file&lt;/denchmark-link&gt;
 , compiling  produces a function which incorrectly returns all zeros:
 &lt;denchmark-code&gt;Trace of tf/math/multiple_functions__iree_vmla/static_dims compiled to 'iree_vmla' on function 'multiply_float32':
   1. Method: multiply_float32
     Inputs: 1x1x1x2x2x2x2xf32, 1x1x1x2x2x2x2xf32
       [[[[[[[ 0.09762701  0.43037874]
             [ 0.20552675  0.08976637]]
 
            [[-0.1526904   0.29178822]
             [-0.12482557  0.78354603]]]
 
 
           [[[ 0.92732555 -0.23311697]
             [ 0.5834501   0.05778984]]
 
            [[ 0.13608912  0.85119325]
             [-0.85792786 -0.8257414 ]]]]]]]
       [[[[[[[-0.9595632   0.6652397 ]
             [ 0.5563135   0.74002427]]
 
            [[ 0.9572367   0.59831715]
             [-0.07704128  0.56105834]]]
 
 
           [[[-0.76345116  0.27984205]
             [-0.71329343  0.88933784]]
 
            [[ 0.04369664 -0.17067613]
             [-0.47088876  0.5484674 ]]]]]]]
     Outputs: 1x1x1x2x2x2x2xf32
       [[[[[[[0. 0.]
             [0. 0.]]
 
            [[0. 0.]
             [0. 0.]]]
 
 
           [[[0. 0.]
             [0. 0.]]
 
            [[0. 0.]
             [0. 0.]]]]]]]
     Tolerances:
       rtol=1e-06, atol=1e-06
 &lt;/denchmark-code&gt;
 
 In one case the error happens while compiling a function  to LLVM or Vulkan. In the &lt;denchmark-link:https://gist.github.com/phoenix-meadowlark/0145f1967257a1d817e152548c96cf98&gt;first file&lt;/denchmark-link&gt;
 , compiling  with only  also in the file behaves as expected. In the &lt;denchmark-link:https://gist.github.com/phoenix-meadowlark/26c4b532ba644d18e83e6044381e8267#file-iree_input__multiple_functions__square-mlir-L741&gt;second file&lt;/denchmark-link&gt;
 , compilation results in the following mangled stack trace:
 &lt;denchmark-code&gt;*** END MANGLED STACK TRACE ***
 
 *** Begin stack trace ***
         tensorflow::CurrentStackTrace()
 
 
         iree::hal::vmla::Buffer::MakeRange(unsigned int, unsigned int) const
         iree::StatusOr&lt;absl::lts_2020_02_25::Span&lt;unsigned char&gt; &gt; iree::hal::vmla::Buffer::RangeAs&lt;unsigned char&gt;(unsigned int, unsigned int)
 
 
 
 
 
         iree_vm_bytecode_dispatch
 
 
         iree_vm_invoke
         iree::hal::vmla::VMLAExecutable::DispatchTile(iree::hal::HostExecutable::DispatchState*, std::array&lt;unsigned int, 3ul&gt;)
         iree::hal::host::SerialCommandProcessor::DispatchGrid(iree::hal::Executable*, int, std::array&lt;unsigned int, 3ul&gt;)
         iree::hal::host::SerialCommandProcessor::Dispatch(iree::hal::Executable*, int, std::array&lt;unsigned int, 3ul&gt;)
         iree::hal::host::InProcCommandBuffer::ProcessCmd(iree::hal::host::InProcCommandBuffer::CmdHeader*, iree::hal::CommandBuffer*) const
         iree::hal::host::InProcCommandBuffer::Process(iree::hal::CommandBuffer*) const
 
 
         iree::hal::host::SerialSubmissionQueue::ProcessBatch(iree::hal::host::SerialSubmissionQueue::PendingBatch const&amp;, std::function&lt;iree::Status (absl::lts_2020_02_25::Span&lt;iree::hal::CommandBuffer* const&gt;)&gt; const&amp;)
         iree::hal::host::SerialSubmissionQueue::ProcessBatches(std::function&lt;iree::Status (absl::lts_2020_02_25::Span&lt;iree::hal::CommandBuffer* const&gt;)&gt;)
         iree::hal::host::AsyncCommandQueue::ThreadMain()
 
 
         clone
 *** End stack trace ***
 &lt;/denchmark-code&gt;
 
 From what I understand the MLIR files should be enough for reproducibility, but I'll also add instructions for reproducing from within the integrations once the code that generates these files is landed.
 	</description>
 	<comments>
 		<comment id='1' author='phoenix-meadowlark' date='2020-11-22T06:18:47Z'>
 		How are you running these? I'm skeptical this may be related to anything in either the compiler or runtime and is more likely in the runner.
 		</comment>
 		<comment id='2' author='phoenix-meadowlark' date='2020-11-22T19:22:18Z'>
 		I was able to narrow down the bug to a minimal set of mutually exclusive functions, which let me use iree-run-mlir more reasonably. I listed a number of reproducers below. For the generated IR I removed the f32 functions and reduced the rank to 1, and the bug persists.
 &lt;denchmark-h:h4&gt;Failing: via bazel&lt;/denchmark-h&gt;
 
 bazel run integrations/tensorflow/e2e/math:math_test_manual -- \
   --target_backends=iree_vmla \
   --functions=multiply,square
 This reproduces the stack trace above.
 &lt;denchmark-h:h4&gt;iree_input.mlir for --functions=multiply,square&lt;/denchmark-h&gt;
 
 module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, producer = 586 : i32}}  {
   func @multiply__2_2__i32__uniform(%arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"}, %arg1: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_1"}) -&gt; tensor&lt;2xi32&gt; attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I12!S9!k0_0k1_1R3!_0"}, tf._input_shapes = [#tf.shape&lt;2&gt;, #tf.shape&lt;2&gt;]} {
     %0 = mhlo.multiply %arg0, %arg1 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
   func @square__2__i32__uniform(%arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"}) -&gt; tensor&lt;2xi32&gt; attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I8!S5!k0_0R3!_0"}, tf._input_shapes = [#tf.shape&lt;2&gt;]} {
     %0 = mhlo.multiply %arg0, %arg0 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
 }
 &lt;denchmark-h:h4&gt;Passing: iree_input.mlir for --functions=multiply&lt;/denchmark-h&gt;
 
 module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, producer = 586 : i32}}  {
   func @multiply__2_2__i32__uniform(%arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"}, %arg1: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_1"}) -&gt; tensor&lt;2xi32&gt; attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I12!S9!k0_0k1_1R3!_0"}, tf._input_shapes = [#tf.shape&lt;2&gt;, #tf.shape&lt;2&gt;]} {
     %0 = mhlo.multiply %arg0, %arg1 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
 }
 bazel run iree/tools:iree-run-mlir -- \
   -export-all -iree-hal-target-backends=vmla \
   -function-input='2xi32=2 3' \
   -function-input='2xi32=5 7' \
   /tmp/iree/modules/tf/math/multiply/static_dims/iree_input.mlir
 &lt;denchmark-code&gt;I iree/tools/iree-run-mlir-main.cc:205] Compiling for target backend 'vmla*'...
 I iree/tools/iree-run-mlir-main.cc:325] Evaluating all functions in module for driver 'vmla'...
 I iree/tools/utils/vm_util.cc:227] Creating driver and device for 'vmla'...
 EXEC @multiply__2_2__i32__uniform
 I iree/tools/utils/vm_util.cc:172] result[0]: Buffer&lt;sint32[2]&gt;
 2xi32=10 21
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h4&gt;Passing: iree_input.mlir for --functions=square&lt;/denchmark-h&gt;
 
 module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, producer = 586 : i32}}  {
   func @square__2__i32__uniform(%arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"}) -&gt; tensor&lt;2xi32&gt; attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I8!S5!k0_0R3!_0"}, tf._input_shapes = [#tf.shape&lt;2&gt;]} {
     %0 = mhlo.multiply %arg0, %arg0 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
 }
 bazel run iree/tools:iree-run-mlir -- \
   -export-all -iree-hal-target-backends=vmla \
   -function-input='2xi32=2 3' \
   /tmp/iree/modules/tf/math/square/static_dims/iree_input.mlir
 &lt;denchmark-code&gt;I iree/tools/iree-run-mlir-main.cc:205] Compiling for target backend 'vmla*'...
 I iree/tools/iree-run-mlir-main.cc:325] Evaluating all functions in module for driver 'vmla'...
 I iree/tools/utils/vm_util.cc:227] Creating driver and device for 'vmla'...
 EXEC @square__2__i32__uniform
 I iree/tools/utils/vm_util.cc:172] result[0]: Buffer&lt;sint32[2]&gt;
 2xi32=4 9
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h4&gt;Failing: iree_input.mlir for --functions=multiply,square modified to work with iree-run-mlir&lt;/denchmark-h&gt;
 
 module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, producer = 586 : i32}}  {
   func @multiply__2_2__i32__uniform(%arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"}, %arg1: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_1"}) -&gt; tensor&lt;2xi32&gt; attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I12!S9!k0_0k1_1R3!_0"}, tf._input_shapes = [#tf.shape&lt;2&gt;, #tf.shape&lt;2&gt;]} {
     %0 = mhlo.multiply %arg0, %arg1 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
   func @square__2__i32__uniform(%arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"}, %unused0: tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt; attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I8!S5!k0_0R3!_0"}, tf._input_shapes = [#tf.shape&lt;2&gt;]} {
     %0 = mhlo.multiply %arg0, %arg0 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
 }
 bazel run iree/tools:iree-run-mlir -- \
   -export-all \
   -iree-hal-target-backends=vmla \
   -function-input='2xi32=2 3' \
   -function-input='2xi32=5 7' \
   multiply_square_iree_input.mlir
 &lt;denchmark-code&gt;I iree/tools/iree-run-mlir-main.cc:205] Compiling for target backend 'vmla*'...
 I iree/tools/iree-run-mlir-main.cc:325] Evaluating all functions in module for driver 'vmla'...
 I iree/tools/utils/vm_util.cc:227] Creating driver and device for 'vmla'...
 EXEC @multiply__2_2__i32__uniform
 I iree/tools/utils/vm_util.cc:172] result[0]: Buffer&lt;sint32[2]&gt;
 2xi32=10 21
 EXEC @square__2__i32__uniform
 PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace.
 Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):
 .../iree/tools/iree-run-mlir[0x2fbf722]
 .../iree/tools/iree-run-mlir[0x2fbd765]
 .../iree/tools/iree-run-mlir[0x2fbfa9a]
 /lib/x86_64-linux-gnu/libpthread.so.0(+0x14140)[0x7f8862a36140]
 .../iree/tools/iree-run-mlir[0x2d938d9]
 .../iree/tools/iree-run-mlir[0x2da8c39]
 .../iree/tools/iree-run-mlir[0x2d94ec6]
 .../iree/tools/iree-run-mlir[0x2da8460]
 .../iree/tools/iree-run-mlir[0x2dd8f6d]
 .../iree/tools/iree-run-mlir[0x2e7fd3d]
 .../iree/tools/iree-run-mlir[0x2e7f633]
 .../iree/tools/iree-run-mlir[0x2e7e1cd]
 .../iree/tools/iree-run-mlir[0x2e7bfca]
 .../iree/tools/iree-run-mlir[0x2e82c7b]
 .../iree/tools/iree-run-mlir[0x2e8297f]
 .../iree/tools/iree-run-mlir[0x2d92652]
 .../iree/tools/iree-run-mlir[0x2debb6e]
 .../iree/tools/iree-run-mlir[0x2deb8fe]
 .../iree/tools/iree-run-mlir[0x2df1dfd]
 .../iree/tools/iree-run-mlir[0x2df190e]
 .../iree/tools/iree-run-mlir[0x2de9b21]
 .../iree/tools/iree-run-mlir[0x2deab27]
 .../iree/tools/iree-run-mlir[0x2deec9d]
 .../iree/tools/iree-run-mlir[0x2dee33d]
 .../iree/tools/iree-run-mlir[0x2dea6be]
 /lib/x86_64-linux-gnu/libstdc++.so.6(+0xcec60)[0x7f8862c5cc60]
 /lib/x86_64-linux-gnu/libpthread.so.0(+0x8ea7)[0x7f8862a2aea7]
 /lib/x86_64-linux-gnu/libc.so.6(clone+0x3f)[0x7f8862940eaf]
 [1]    169344 segmentation fault  bazel run iree/tools:iree-run-mlir -- -export-all  -function-input='2xi32=2 3
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h4&gt;Passing: iree_input.mlir for --functions=multiply,square modified to work with iree-run-mlir and with square modified to use mhlo.add instead.&lt;/denchmark-h&gt;
 
 module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, producer = 586 : i32}}  {
   func @multiply__2_2__i32__uniform(%arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"}, %arg1: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_1"}) -&gt; tensor&lt;2xi32&gt; attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I12!S9!k0_0k1_1R3!_0"}, tf._input_shapes = [#tf.shape&lt;2&gt;, #tf.shape&lt;2&gt;]} {
     %0 = mhlo.multiply %arg0, %arg1 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
   func @square__2__i32__uniform(%arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"}, %unused0: tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt; attributes {iree.module.export, iree.reflection = {abi = "sip", abiv = 1 : i32, sip = "I8!S5!k0_0R3!_0"}, tf._input_shapes = [#tf.shape&lt;2&gt;]} {
     %0 = mhlo.add %arg0, %arg0 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
 }
 bazel run iree/tools:iree-run-mlir -- \
   -export-all \
   -iree-hal-target-backends=vmla \
   -function-input='2xi32=2 3' \
   -function-input='2xi32=5 7' \
   multiply_square_as_add_iree_input.mlir
 &lt;denchmark-code&gt;I iree/tools/iree-run-mlir-main.cc:205] Compiling for target backend 'vmla*'...
 I iree/tools/iree-run-mlir-main.cc:325] Evaluating all functions in module for driver 'vmla'...
 I iree/tools/utils/vm_util.cc:227] Creating driver and device for 'vmla'...
 EXEC @multiply__2_2__i32__uniform
 I iree/tools/utils/vm_util.cc:172] result[0]: Buffer&lt;sint32[2]&gt;
 2xi32=10 21
 EXEC @square__2__i32__uniform
 I iree/tools/utils/vm_util.cc:172] result[0]: Buffer&lt;sint32[2]&gt;
 2xi32=4 6
 &lt;/denchmark-code&gt;
 
 (Mostly confirms that I added %unused0 correctly).
 		</comment>
 		<comment id='3' author='phoenix-meadowlark' date='2020-11-22T21:29:07Z'>
 		Fantastic &lt;denchmark-link:https://github.com/phoenix-meadowlark&gt;@phoenix-meadowlark&lt;/denchmark-link&gt;
  I'll start debugging :)
 		</comment>
 		<comment id='4' author='phoenix-meadowlark' date='2020-11-22T21:37:36Z'>
 		(woo reproduced and in a debugger at the stack thanks to your iree-run-mlir command lines :)
 		</comment>
 		<comment id='5' author='phoenix-meadowlark' date='2020-11-22T22:26:13Z'>
 		ok, confirmed this is an issue in the runner and not in compiler/runtime (whew).
 The issue is that you are calling two functions with the same set of 2 arguments but one function takes two inputs (multiply) and one takes one input (square). You can't do that :)
 scratch that, ☕ kicking in and those silly tf._user_specified_name attributes are making it really hard to read. I see your unused argument.
 		</comment>
 		<comment id='6' author='phoenix-meadowlark' date='2020-11-22T22:28:39Z'>
 		(incidentally, this is another good reason to not have the python test runner call into IREE directly but instead shell out to a tool like iree-run-module, which does perform this validation in a consistent way)
 		</comment>
 		<comment id='7' author='phoenix-meadowlark' date='2020-11-22T22:36:32Z'>
 		Likely unrelated to the actual issue by sheer luck, but worth noting:
 module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, producer = 586 : i32}}  {
   func @multiply__2_2__i32__uniform(
     %arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"},
     %arg1: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_1"}) -&gt; tensor&lt;2xi32&gt;
     attributes {
       iree.module.export,
       iree.reflection = {
         abi = "sip",
         abiv = 1 : i32,
         sip = "I12!S9!k0_0k1_1R3!_0"
       },
       tf._input_shapes = [#tf.shape&lt;2&gt;, #tf.shape&lt;2&gt;]
     } {
     %0 = mhlo.multiply %arg0, %arg1 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
   func @square__2__i32__uniform(
     %arg0: tensor&lt;2xi32&gt; {tf._user_specified_name = "args_0"},
     %unused0: tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt;
     attributes {
       iree.module.export,
       iree.reflection = {
         abi = "sip",
         abiv = 1 : i32,
         sip = "I8!S5!k0_0R3!_0"
       },
       tf._input_shapes = [#tf.shape&lt;2&gt;]
     } {
     %0 = mhlo.multiply %arg0, %arg0 : tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
 }
 The multiply one has both arguments k0_0k1_1R3 in its sip signature while the square one has only one k0_0R3. iree-run-mlir does not use the sip stuff, but python does AFAIK. So we may just be lucking out and seeing the same error in both places as I expect behavior to be undefined on the python side if your sip signature does not match the actual function signature. Not the root cause here but something to watch out for in the future if trying to modify MLIR and then running it through the python runner.
 Will keep digging.
 		</comment>
 		<comment id='8' author='phoenix-meadowlark' date='2020-11-22T22:43:53Z'>
 		ok scratch that "scratch that" - vm_util does use the sip stuff. that has its own whole set of issues we'll need to unwind at some point.
 		</comment>
 		<comment id='9' author='phoenix-meadowlark' date='2020-11-22T22:58:01Z'>
 		ruh roh &lt;denchmark-link:https://github.com/ScottTodd&gt;@ScottTodd&lt;/denchmark-link&gt;
  this is a bug in DeduplicateExecutablesPass :P
 // *** IR Dump After mlir::iree_compiler::IREE::Flow::OutlineDispatchRegionsPass ***
 flow.executable @multiply__2_2__i32__uniform_ex_dispatch_0 attributes {sym_visibility = "private"} {
   flow.dispatch.entry @multiply__2_2__i32__uniform_ex_dispatch_0
   module  {
     func @multiply__2_2__i32__uniform_ex_dispatch_0(%arg0: tensor&lt;2xi32&gt;, %arg1: tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt; {
       %0 = mhlo.multiply %arg0, %arg1 : tensor&lt;2xi32&gt;
       return %0 : tensor&lt;2xi32&gt;
     }
   }
 }
 func @multiply__2_2__i32__uniform(%arg0: tensor&lt;2xi32&gt;, %arg1: tensor&lt;2xi32&gt;) -&gt; (tensor&lt;2xi32&gt;) {
   %c2 = constant 2 : index
   %0 = flow.dispatch @multiply__2_2__i32__uniform_ex_dispatch_0::@multiply__2_2__i32__uniform_ex_dispatch_0[%c2 : index](%arg0, %arg1) : (tensor&lt;2xi32&gt;, tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt;
   return %0 : tensor&lt;2xi32&gt;
 }
 flow.executable @square__2__i32__uniform_ex_dispatch_0 attributes {sym_visibility = "private"} {
   flow.dispatch.entry @square__2__i32__uniform_ex_dispatch_0
   module  {
     func @square__2__i32__uniform_ex_dispatch_0(%arg0: tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt; {
       %0 = mhlo.multiply %arg0, %arg0 : tensor&lt;2xi32&gt;
       return %0 : tensor&lt;2xi32&gt;
     }
   }
 }
 func @square__2__i32__uniform(%arg0: tensor&lt;2xi32&gt;, %arg1: tensor&lt;2xi32&gt;) -&gt; (tensor&lt;2xi32&gt;) {
   %c2 = constant 2 : index
   %0 = flow.dispatch @square__2__i32__uniform_ex_dispatch_0::@square__2__i32__uniform_ex_dispatch_0[%c2 : index](%arg0) : (tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt;
   return %0 : tensor&lt;2xi32&gt;
 }
 // *** IR Dump After mlir::iree_compiler::IREE::Flow::DeduplicateExecutablesPass ***
 module attributes {
   flow.executable @multiply__2_2__i32__uniform_ex_dispatch_0 attributes {sym_visibility = "private"} {
     flow.dispatch.entry @multiply__2_2__i32__uniform_ex_dispatch_0
     module  {
       func @multiply__2_2__i32__uniform_ex_dispatch_0(%arg0: tensor&lt;2xi32&gt;, %arg1: tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt; {
         %0 = mhlo.multiply %arg0, %arg1 : tensor&lt;2xi32&gt;
         return %0 : tensor&lt;2xi32&gt;
       }
     }
   }
   func @multiply__2_2__i32__uniform(%arg0: tensor&lt;2xi32&gt;, %arg1: tensor&lt;2xi32&gt;) -&gt; (tensor&lt;2xi32&gt;) {
     %c2 = constant 2 : index
     %0 = flow.dispatch @multiply__2_2__i32__uniform_ex_dispatch_0::@multiply__2_2__i32__uniform_ex_dispatch_0[%c2 : index](%arg0, %arg1) : (tensor&lt;2xi32&gt;, tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
   func @square__2__i32__uniform(%arg0: tensor&lt;2xi32&gt;) -&gt; (tensor&lt;2xi32&gt;) {
     %c2 = constant 2 : index
     %0 = flow.dispatch @multiply__2_2__i32__uniform_ex_dispatch_0::@multiply__2_2__i32__uniform_ex_dispatch_0[%c2 : index](%arg0) : (tensor&lt;2xi32&gt;) -&gt; tensor&lt;2xi32&gt;
     return %0 : tensor&lt;2xi32&gt;
   }
 }
 So these two different executables are getting deduped even though their contents differ: %0 = mhlo.multiply %arg0, %arg1 : tensor&lt;2xi32&gt; vs. %0 = mhlo.multiply %arg0, %arg0 : tensor&lt;2xi32&gt;. So the IR comparison is busted.
 This would cause a whole set of issues like this! Kind of shocking we weren't already seeing it (or maybe we are and just don't know it).
 Will fix and add this example as test case for the deduping pass. The reason changing the op from multiply to add fixes it is that it's likely bailing on the de-dupe earlier before it gets to the point where it's the same op with different operands.
 Confirmed by disabling the deduplication pass; things work fine.
 		</comment>
 		<comment id='10' author='phoenix-meadowlark' date='2020-11-22T23:00:39Z'>
 		(again, this is a really really good find &lt;denchmark-link:https://github.com/phoenix-meadowlark&gt;@phoenix-meadowlark&lt;/denchmark-link&gt;
  and thank you for narrowing down the issue!)
 		</comment>
 		<comment id='11' author='phoenix-meadowlark' date='2020-11-23T23:12:21Z'>
 		Tackling this now; will try to get something that works to fix this and then upstream it as part of &lt;denchmark-link:https://github.com/google/iree/issues/3996&gt;#3996&lt;/denchmark-link&gt;
 .
 		</comment>
 	</comments>
 </bug>
<commit id='40c66b4e3cd8bd330673a3fc3c334a7e4319ebfc' author='Ben Vanik' date='2020-12-23 13:14:28-08:00'>
 	<dmm_unit complexity='0.5454545454545454' interfacing='0.0' size='0.22727272727272727'></dmm_unit>
 	<modification change_type='MODIFY' old_name='iree\compiler\Dialect\Flow\Transforms\DeduplicateExecutables.cpp' new_name='iree\compiler\Dialect\Flow\Transforms\DeduplicateExecutables.cpp'>
 		<file_info nloc='224' complexity='52' token_count='1763'></file_info>
 		<method name='mlir::iree_compiler::IREE::Flow::replaceEntryPointUses' parameters='moduleOp,replacements'>
 				<method_info nloc='12' complexity='3' token_count='94' nesting_level='5' start_line='231' end_line='242'></method_info>
 			<added_lines>231,232,233,234,235,236,237,238,239,240,241,242</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mlir::iree_compiler::IREE::Flow::areExecutablesEquivalent' parameters='lhs,rhs'>
 				<method_info nloc='21' complexity='5' token_count='176' nesting_level='5' start_line='200' end_line='227'></method_info>
 			<added_lines>207,208,209,210,211,212,215,216,217,218,219,220,221,222,223</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mlir::iree_compiler::IREE::Flow::isStructurallyEquivalentTo' parameters='lhs,rhs,parentMapping'>
 				<method_info nloc='48' complexity='19' token_count='484' nesting_level='5' start_line='129' end_line='198'></method_info>
 			<added_lines>129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,196</added_lines>
 			<deleted_lines>155,156,157</deleted_lines>
 		</method>
 		<method name='mlir::iree_compiler::IREE::Flow::compare_ranges' parameters='lhs,rhs,pred'>
 				<method_info nloc='11' complexity='5' token_count='100' nesting_level='5' start_line='33' end_line='45'></method_info>
 			<added_lines>33,34,35,36,37,39,40,41,42,43,44</added_lines>
 			<deleted_lines>33,34,35,36,37,38,39,43,44,45</deleted_lines>
 		</method>
 		<method name='mlir::iree_compiler::IREE::Flow::areRegionsEquivalent' parameters='lhs,rhs'>
 				<method_info nloc='36' complexity='10' token_count='307' nesting_level='5' start_line='43' end_line='90'></method_info>
 			<added_lines>43,44,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90</added_lines>
 			<deleted_lines>43,44,45,48,51,52,53,54,55,56,57,58,60,63,64,68,69,70,71,72,73,75,76,77,78,79,80,81,82,83,84,85</deleted_lines>
 		</method>
 		<method name='mlir::iree_compiler::IREE::Flow::DeduplicateExecutablesPass::runOnOperation' parameters=''>
 				<method_info nloc='38' complexity='6' token_count='307' nesting_level='5' start_line='252' end_line='307'></method_info>
 			<added_lines>266,267,268</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='mlir::iree_compiler::IREE::Flow::isStructurallyEquivalentTo' parameters='lhs,rhs,mapping'>
 				<method_info nloc='44' complexity='10' token_count='387' nesting_level='5' start_line='77' end_line='128'></method_info>
 			<added_lines>77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,100,101,102,103,104,105,106,107,108,109,110,111,112,113,117,120,123,124,126,127,128</added_lines>
 			<deleted_lines>77,78,79,80,81,82,83,84,85,96,97,98,99,100,104,105,106,107,108,109,110,111,112,115,116,117,118,119,120,121,122,123,124,125,126,127</deleted_lines>
 		</method>
 		<method name='mlir::iree_compiler::IREE::Flow::isStructurallyEquivalentTo' parameters='lhs,rhs'>
 				<method_info nloc='4' complexity='1' token_count='25' nesting_level='5' start_line='72' end_line='75'></method_info>
 			<added_lines>72,73,74,75</added_lines>
 			<deleted_lines>72,73,75</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>17,18,20,22,32,229,230,243</added_lines>
 			<deleted_lines>28,29,30,31,32</deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='iree\compiler\Dialect\Flow\Transforms\test\deduplicate_executables.mlir' new_name='iree\compiler\Dialect\Flow\Transforms\test\deduplicate_executables.mlir'>
 		<file_info nloc='None' complexity='None' token_count='None'></file_info>
 		<modified_lines>
 			<added_lines>67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318</added_lines>
 			<deleted_lines>145</deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
