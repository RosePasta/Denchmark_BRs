<bug_data>
<bug id='986' author='addisonklinke' open_date='2020-11-06T18:05:13Z' closed_time='2020-11-06T23:30:12Z'>
 	<summary>PyTorch topk not supported after mention in release notes</summary>
 	<description>
 &lt;denchmark-h:h2&gt;üêûDescribe the bug&lt;/denchmark-h&gt;
 
 I am converting a PyTorch model that uses their  operator and I get a runtime error that is is unsupported. Contrary to this, the release &lt;denchmark-link:https://github.com/apple/coremltools/releases/tag/4.0b4&gt;notes&lt;/denchmark-link&gt;
  for 4.0b4 explicitly say support was added. I have installed coremltools v4.0 which came after that pre-release, so I assume topk should also be supported in my version
 &lt;denchmark-h:h2&gt;Trace&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;Traceback (most recent call last):
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3331, in run_code
     exec(code_obj, self.user_global_ns, self.user_ns)
   File "&lt;ipython-input-9-21395711530d&gt;", line 1, in &lt;module&gt;
     mlmodel = ct.convert(traced_model, inputs=[ct.ImageType(name='images', shape=dummy.shape)])
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/coremltools/converters/_converters_entry.py", line 183, in convert
     **kwargs
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/coremltools/converters/mil/converter.py", line 129, in mil_convert
     ConverterRegistry, **kwargs)
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/coremltools/converters/mil/converter.py", line 171, in mil_convert_to_proto
     prog = frontend_converter(model, **kwargs)
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/coremltools/converters/mil/converter.py", line 85, in __call__
     return load(*args, **kwargs)
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/coremltools/converters/mil/frontend/torch/load.py", line 83, in load
     raise e
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/coremltools/converters/mil/frontend/torch/load.py", line 75, in load
     prog = converter.convert()
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/coremltools/converters/mil/frontend/torch/converter.py", line 224, in convert
     convert_nodes(self.context, self.graph)
   File "/home/addison/miniconda3/envs/coreml/lib/python3.6/site-packages/coremltools/converters/mil/frontend/torch/ops.py", line 53, in convert_nodes
     "PyTorch convert function for op '{}' not implemented.".format(node.kind)
 RuntimeError: PyTorch convert function for op 'topk' not implemented.
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;
 
 If torch.topk is still not supported, that is okay and I do not need to upload a model and conversion script. I am mainly opening the issue to point out the discrepancy between release notes and actual behavior
 &lt;denchmark-h:h2&gt;System environment (please complete the following information):&lt;/denchmark-h&gt;
 
 
 coremltools version: 4.0
 OS: Ubuntu 18.04
 macOS version (if applicable): NA
 XCode version (if applicable): NA
 How you install python: anaconda
 python version: 3.6.9
 PyTorch: 1.4.0
 
 	</description>
 	<comments>
 		<comment id='1' author='addisonklinke' date='2020-11-06T18:11:39Z'>
 		yeah that seems to be a gap in testing and a bug.
 The  op was added to the torch  but it lacks the decorator , hence it fails to register.
 A temporary workaround is to install coremltools from source and add  &lt;denchmark-link:https://github.com/apple/coremltools/blob/157c1b06997d1f61ea90075e7ad7f5efcb075875/coremltools/converters/mil/frontend/torch/ops.py#L2356&gt;here&lt;/denchmark-link&gt;
 
 		</comment>
 		<comment id='2' author='addisonklinke' date='2020-11-06T18:22:27Z'>
 		&lt;denchmark-link:https://github.com/aseemw&gt;@aseemw&lt;/denchmark-link&gt;
  Thank you for the quick workaround! I was able to run the conversion by simply editing the Python code without needing to reinstall. Shall we leave this open until the official release is fixed?
 		</comment>
 	</comments>
 </bug>
<commit id='b6684ec5c5c338eaba0a87563462a5378dc0fc43' author='Aseem Wadhwa' date='2020-11-06 15:30:11-08:00'>
 	<dmm_unit complexity='1.0' interfacing='0.18181818181818182' size='0.18181818181818182'></dmm_unit>
 	<modification change_type='MODIFY' old_name='coremltools\converters\mil\frontend\torch\ops.py' new_name='coremltools\converters\mil\frontend\torch\ops.py'>
 		<file_info nloc='1634' complexity='373' token_count='14001'></file_info>
 		<modified_lines>
 			<added_lines>2356</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='coremltools\converters\mil\frontend\torch\test\test_torch_ops.py' new_name='coremltools\converters\mil\frontend\torch\test\test_torch_ops.py'>
 		<file_info nloc='1267' complexity='112' token_count='9076'></file_info>
 		<method name='test_topk.forward' parameters='self,x'>
 				<method_info nloc='2' complexity='1' token_count='24' nesting_level='3' start_line='1459' end_line='1460'></method_info>
 			<added_lines>1459,1460</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_topk' parameters='self,backend,largest,shape_dim_k'>
 				<method_info nloc='18' complexity='1' token_count='90' nesting_level='1' start_line='1450' end_line='1472'></method_info>
 			<added_lines>1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_topk.__init__' parameters='self'>
 				<method_info nloc='2' complexity='1' token_count='15' nesting_level='3' start_line='1456' end_line='1457'></method_info>
 			<added_lines>1456,1457</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
