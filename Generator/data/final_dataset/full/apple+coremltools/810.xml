<bug_data>
<bug id='810' author='leovinus2001' open_date='2020-07-23T17:30:38Z' closed_time='2020-08-12T17:15:38Z'>
 	<summary>PyTorch to CoreML LSTM model conversion v4 fails with ValueError: Layer with name "_lstm_h0_reshaped_expanded" has already been added. Please use a unique name.</summary>
 	<description>
 Relevance:-----------------------------------------------------------
 While there other open issues in the coremltools v4 TOT repo regarding PyTorch trained LSTMs, such as &lt;denchmark-link:https://github.com/apple/coremltools/issues/755&gt;#755&lt;/denchmark-link&gt;
  (multi layer LSTM) and &lt;denchmark-link:https://github.com/apple/coremltools/issues/776&gt;#776&lt;/denchmark-link&gt;
  (handling of LSTM initials h0/c0), I was looking for workarounds on how to build multi-layer bidirectional LSTMs. Now I ran into a blocking bug with error:
 
 Layer with name "_lstm_h0_reshaped_expanded" has already been added. Please use a unique name.
 
 In other words, another blocker on the conversion of PyTorch multilayer LSTMs (potential GRU/RNN as well).
 On the good side, a little digging in the conversion code leads to potential fix as well (see code and potential solution below) but I need your please to help to assess whether this approach is best, whether the unidirectional LSTM and GRU also need fixes, etc.
 Reproducible:-----------------------------------------------------------
 Yes
 Testcase:-----------------------------------------------------------
 Attached. Run e.g. as
 python3 -O ../testLstmTwoLayer.py
 &lt;denchmark-link:https://github.com/apple/coremltools/files/4967763/testLstmTwoLayer.txt&gt;testLstmTwoLayer.txt&lt;/denchmark-link&gt;
 
 Setup:-----------------------------------------------------------
 Torch version : 1.5.1
 CoreML tools version : TOT  &lt;denchmark-link:https://github.com/apple/coremltools/commit/705244e2be26c3fb7881fd7a731d25a55f5e4765&gt;705244e&lt;/denchmark-link&gt;
  July 23
 Log:-----------------------------------------------------------
 Torch version : 1.5.1
 CoreML tools version : 4.0b1
 small_model(
 (lstm1): LSTM(28, 16, batch_first=True, bidirectional=True)
 (lstm2): LSTM(32, 8, batch_first=True, bidirectional=True)
 (fc1): Linear(in_features=16, out_features=11, bias=True)
 )
 Converting Frontend ==&gt; MIL Ops:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 46/47 [00:00&lt;00:00, 218.23 ops/s]
 Running MIL optimization passes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00&lt;00:00, 17.78 passes/s]
 Translating MIL ==&gt; MLModel Ops:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                 | 22/32 [00:00&lt;00:00, 14936.01 ops/s]
 Traceback (most recent call last):
 File "../testLstmTwoLayer.py", line 74, in 
 inputs=[ ct.TensorType(name="input1", shape=dummy_input.shape) ],
 File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/_converters_entry.py", line 299, in convert
 **kwargs
 File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/converter.py", line 122, in _convert
 out = backend_converter(prog, **kwargs)
 File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/converter.py", line 72, in call
 return load(*args, **kwargs)
 File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/backend/nn/load.py", line 239, in load
 prog.functions["main"].outputs,
 File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/backend/nn/op_mapping.py", line 50, in convert_ops
 mapper(const_context, builder, op)
 File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/backend/nn/op_mapping.py", line 1399, in lstm
 _expand_dim(builder, initial_h + postfix, initial_h, [2, 3, 4])
 File "/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/backend/nn/op_mapping.py", line 208, in _expand_dim
 name=node_name, input_name=input_name, output_name=node_name, axes=axes
 File "/Library/Python/3.7/lib/python/site-packages/coremltools/models/neural_network/builder.py", line 7056, in add_expand_dims
 spec_layer = self._add_generic_layer(name, [input_name], [output_name])
 File "~/Library/Python/3.7/lib/python/site-packages/coremltools/models/neural_network/builder.py", line 1029, in _add_generic_layer
 % name
 ValueError: Layer with name "_lstm_h0_reshaped_expanded" has already been added. Please use a unique name.
 Interpretation and potential fix: -----------------------------------------------------------
 This is observed with git coremltools, TOT &lt;denchmark-link:https://github.com/apple/coremltools/commit/705244e2be26c3fb7881fd7a731d25a55f5e4765&gt;705244e&lt;/denchmark-link&gt;
  July 23
 The error
 
 Layer with name "_lstm_h0_reshaped_expanded" has already been added. Please use a unique name.
 
 seems to indicate that the naming scheme in the converter is using a global name scheme.
 While the testcase runs fine with ONE layer (set flag twoLayerModelFlag to False) when you run with TWO layers (twoLayerModelFlag=True) ) (or more presumably) the error occurs.
 Originally, you have on TOT the use of fixed postfixes like "_expanded" (for h0) and "_expanded2" (for c0) which leads to the issue it seems. When you have 2 layers or more, it seems the same variable name is generated multiple times.
 The line 1399 in coremltools/converters/mil/backend/nn/op_mapping.py
 points to the code below (The line numbers might be a little off due to my logging lines).
 Original code:
 def lstm(const_context, builder, op):
 ...
 &lt;denchmark-h:h1&gt;Roughly Line 1375 et al&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h1&gt;&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;elif direction == "bidirectional":
     # Expand initial_h and initial_c
     _expand_dim(builder, initial_h + "_expanded", initial_h, [2, 3, 4]) # &lt;------------------
      initial_h += "_expanded"
     
     # initial_h may have the same name as initial_c (e.g., same Var)
     _expand_dim(builder, initial_c + "_expanded2", initial_c, [2, 3, 4])  # &lt;------------------
     initial_c += "_expanded2"
 &lt;/denchmark-code&gt;
 
 Therefore, I tried a quick randomization fix along the lines below to generate UNIQUE names every time you handle a new BLSTM layer.
 Potential fix:
 def lstm(const_context, builder, op):
 ...
 &lt;denchmark-h:h1&gt;Roughly Line 1375 et al&lt;/denchmark-h&gt;
 
 &lt;denchmark-h:h1&gt;&lt;/denchmark-h&gt;
 
 &lt;denchmark-code&gt;elif direction == "bidirectional":
     # Expand initial_h and initial_c
     if 1:
         # New
         import random
         mymax = 10000000 # Better, use sys.maxint
         n = random.randrange(1,mymax)
         postfix = "_expanded_" + str(n)
         
         n2 = random.randrange(1,mymax)
         postfix2 = "_expanded2_" + str(n2)
 
         mynodename = initial_h + "_expanded"
         print ("nodename " + str(mynodename))
         print ("postfix" + str(postfix))
         print ("postfix2" + str(postfix2))
     else:
 		#ORG
         postfix  = "_expanded"
         postfix2 = "_expanded2"
         
     _expand_dim(builder, initial_h + postfix, initial_h, [2, 3, 4])  # &lt;------------------
     initial_h += postfix
     
     # initial_h may have the same name as initial_c (e.g., same Var)
     _expand_dim(builder, initial_c + postfix2, initial_c, [2, 3, 4])  # &lt;------------------
     initial_c += postfix2
 &lt;/denchmark-code&gt;
 
 While the conversion now completes, I have not checked whether "everything" is fine. which is why I ask for your help for a proper fix please. Note we might need a fix for other uniLSTM, GRU or RNN in the same file as well.
 As the other issues  &lt;denchmark-link:https://github.com/apple/coremltools/issues/755&gt;#755&lt;/denchmark-link&gt;
  (multi layer LSTM) and &lt;denchmark-link:https://github.com/apple/coremltools/issues/776&gt;#776&lt;/denchmark-link&gt;
  (handling of initials h0/c0) are still blocking us, it would be an immense help if we could fix this new issue quickly such that I can properly stack multiple BLSTMs. Thanks.
 Here is the output WITH the fix above:
 python3 -O ../testLstmTwoLayer.py
 WARNING:root:Keras version 2.4.3 detected. Last version known to be fully compatible of Keras is 2.2.4 .
 Torch version : 1.5.1
 CoreML tools version : 4.0b1
 small_model(
 (lstm1): LSTM(28, 16, batch_first=True, bidirectional=True)
 (lstm2): LSTM(32, 8, batch_first=True, bidirectional=True)
 (fc1): Linear(in_features=16, out_features=11, bias=True)
 )
 Converting Frontend ==&gt; MIL Ops:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 46/47 [00:00&lt;00:00, 213.31 ops/s]
 Running MIL optimization passes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00&lt;00:00, 17.83 passes/s]
 Translating MIL ==&gt; MLModel Ops:   0%|                                                                                                                                                                                                                                                                               | 0/32 [00:00&lt;?, ? ops/s]
 nodename _lstm_h0_reshaped_expanded
 postfix_expanded_6035530			# &lt;------------------ randomized
 postfix2_expanded2_4582868			# &lt;------------------ randomized
 nodename _lstm_h0_reshaped_expanded
 postfix_expanded_3955283
 postfix2_expanded2_1781011
 Translating MIL ==&gt; MLModel Ops: 100%
 	</description>
 	<comments>
 		<comment id='1' author='leovinus2001' date='2020-08-05T16:15:17Z'>
 		Updated testcase for PR &lt;denchmark-link:https://github.com/apple/coremltools/pull/843&gt;#843&lt;/denchmark-link&gt;
 
 &lt;denchmark-link:https://github.com/apple/coremltools/files/5029648/testLstmTwoLayer.txt&gt;testLstmTwoLayer.txt&lt;/denchmark-link&gt;
 
 		</comment>
 	</comments>
 </bug>
<commit id='4b81a5e4954e39c78c351d3fe9d9b425549fc56e' author='leovinus2001' date='2020-08-12 10:15:37-07:00'>
 	<dmm_unit complexity='0.75' interfacing='0.25' size='0.75'></dmm_unit>
 	<modification change_type='MODIFY' old_name='coremltools\converters\mil\backend\nn\op_mapping.py' new_name='coremltools\converters\mil\backend\nn\op_mapping.py'>
 		<file_info nloc='2413' complexity='377' token_count='17415'></file_info>
 		<method name='lstm' parameters='const_context,builder,op'>
 				<method_info nloc='145' complexity='12' token_count='1169' nesting_level='0' start_line='1299' end_line='1509'></method_info>
 			<added_lines>1378,1379,1380,1381,1382,1383,1384,1386,1387,1388,1389</added_lines>
 			<deleted_lines>1378,1379,1380,1382,1383</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='coremltools\converters\mil\frontend\torch\test\test_torch_ops.py' new_name='coremltools\converters\mil\frontend\torch\test\test_torch_ops.py'>
 		<file_info nloc='532' complexity='55' token_count='3776'></file_info>
 		<method name='__init__' parameters='self,flagReturnTuple_'>
 				<method_info nloc='3' complexity='1' token_count='22' nesting_level='1' start_line='498' end_line='500'></method_info>
 			<added_lines>498,499,500</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='forward' parameters='self,x'>
 				<method_info nloc='2' complexity='2' token_count='24' nesting_level='1' start_line='502' end_line='505'></method_info>
 			<added_lines>502,503,504,505</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<method name='test_lstm' parameters='self,input_size,hidden_size,num_layers,bias,batch_first,dropout,bidirectional,backend'>
 				<method_info nloc='10' complexity='1' token_count='20' nesting_level='1' start_line='513' end_line='522'></method_info>
 			<added_lines>513,514,515,516,517,518,519,520,521,522</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>494,495,496,497,501,506,507,508,509,510,511,512,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
