<bug_data>
<bug id='1829' author='StellaASchlotter' open_date='2020-07-01T12:41:00Z' closed_time='2020-07-23T19:10:06Z'>
 	<summary>TFRecord file is missing the sha256 feature</summary>
 	<description>
 &lt;denchmark-h:h3&gt;My actions before raising this issue&lt;/denchmark-h&gt;
 
 
  Read/searched the docs
  Searched past issues
 
 I want to export a dataset as tfrecords format und use that to train a model with the TF Object Detection API. I encountered problems doing so because the exported records file does not contain a sha256 key.
 &lt;denchmark-h:h3&gt;Expected Behaviour&lt;/denchmark-h&gt;
 
 I expected that the examples in the tfrecords file contain a feature like that:
 &lt;denchmark-code&gt;feature {
     key: "image/key/sha256"
     value {
       bytes_list {
         value: "20bc63f9dc7604c9bb6d157669957325cf5c7d026c2222534a14d42f5fae1c6e"
       }
     }
   }
 &lt;/denchmark-code&gt;
 
 &lt;denchmark-h:h3&gt;Current Behaviour&lt;/denchmark-h&gt;
 
 Currently the key is missing resulting in the following error when starting training with the TF Object Detection API
 &lt;denchmark-code&gt;ValueError: in converted code:
     relative to /home/benji/ObjectDetectionAPI/venv/lib/python3.6/site-packages/tensorflow_core/python:
 
     data/ops/readers.py:336 __init__
         filenames, compression_type, buffer_size, num_parallel_reads)
     data/ops/readers.py:296 __init__
         filenames = _create_or_validate_filenames_dataset(filenames)
     data/ops/readers.py:56 _create_or_validate_filenames_dataset
         filenames = ops.convert_to_tensor(filenames, dtype=dtypes.string)
     framework/ops.py:1184 convert_to_tensor
         return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
     framework/ops.py:1242 convert_to_tensor_v2
         as_ref=False)
     framework/ops.py:1273 internal_convert_to_tensor
         (dtype.name, value.dtype.name, value))
 
     ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: &lt;tf.Tensor 'args_0:0' shape=() dtype=float32&gt;
 &lt;/denchmark-code&gt;
 
 I verified that this bug does not happen when I manually create the tfrecord file with the tools provided by the TF Object Detection API. The manually created tfrecords file only differs in the sha256  key.
 &lt;denchmark-h:h3&gt;Steps to Reproduce (for bugs)&lt;/denchmark-h&gt;
 
 
 setup tf object detection api with branch r1.13.0. The recent branches don't support training yet
 setup training. I followed the guide at https://gilberttanner.com/blog/creating-your-own-objectdetector. Except for creating the tfrecords files.
 export a dataset as tfrecords
 start training
 
 &lt;denchmark-h:h3&gt;Your Environment&lt;/denchmark-h&gt;
 
 
 Git hash commit (git log -1): d293876
 Docker version: 19.03.12, build 48a66213fe
 Are you using Docker Swarm or Kubernetes? no
 Operating System and version: Ubuntu 18.04
 
 	</description>
 	<comments>
 	</comments>
 </bug>
<commit id='a3448a20ade0306c10b9d76c036b92f865161413' author='zhiltsov-max' date='2020-07-23 22:10:05+03:00'>
 	<dmm_unit complexity='0.0' interfacing='0.75' size='0.0'></dmm_unit>
 	<modification change_type='MODIFY' old_name='datumaro\datumaro\plugins\tf_detection_api_format\converter.py' new_name='datumaro\datumaro\plugins\tf_detection_api_format\converter.py'>
 		<file_info nloc='172' complexity='41' token_count='1350'></file_info>
 		<method name='_make_tf_example' parameters='self,item'>
 				<method_info nloc='38' complexity='7' token_count='290' nesting_level='1' start_line='162' end_line='207'></method_info>
 			<added_lines>184,185,190,195</added_lines>
 			<deleted_lines>183</deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines>8</added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 	<modification change_type='MODIFY' old_name='datumaro\datumaro\plugins\tf_detection_api_format\extractor.py' new_name='datumaro\datumaro\plugins\tf_detection_api_format\extractor.py'>
 		<file_info nloc='158' complexity='31' token_count='1301'></file_info>
 		<method name='_parse_tfrecord_file' parameters='cls,filepath,subset,images_dir'>
 				<method_info nloc='100' complexity='17' token_count='889' nesting_level='1' start_line='79' end_line='195'></method_info>
 			<added_lines>88,89,90,91</added_lines>
 			<deleted_lines></deleted_lines>
 		</method>
 		<modified_lines>
 			<added_lines></added_lines>
 			<deleted_lines></deleted_lines>
 		</modified_lines>
 	</modification>
 </commit>
</bug_data>
