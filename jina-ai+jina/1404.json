{"BR": {"BR_id": "1404", "BR_author": "Kavan72", "BRopenT": "2020-12-07T08:59:46Z", "BRcloseT": "2020-12-07T21:32:34Z", "BR_text": {"BRsummary": "top_k is not working on multiple shards", "BRdescription": "\n Describe the bug\n Problem is on query time. when i've multiple shards (>1) and if i set top_k == (total len of docs) on quey time than it's not returning all docs result. i also passing polling='all' and uses_reducing='_merge_all' on query flow still not working.\n Environment\n <denchmark-code>jina                          0.8.3\n jina-proto                    0.0.76\n jina-vcs-tag                  (unset)\n libzmq                        4.3.3\n pyzmq                         1.19.4\n protobuf                      3.14.0\n proto-backend                 cpp\n grpcio                        1.33.2\n ruamel.yaml                   0.16.12\n python                        3.7.9\n platform                      Linux\n platform-release              5.4.0-56-generic\n platform-version              #62~18.04.1-Ubuntu SMP Tue Nov 24 10:07:50 UTC 2020\n architecture                  x86_64\n processor                     x86_64\n jina-resources                /media/kavan/WORK/Job/jina_search_engine/venv/lib/python3.7/site-packages/jina/resources\n JINA_ARRAY_QUANT              (unset)\n JINA_BINARY_DELIMITER         (unset)\n JINA_CONTRIB_MODULE           (unset)\n JINA_CONTRIB_MODULE_IS_LOADING(unset)\n JINA_CONTROL_PORT             (unset)\n JINA_DB_COLLECTION            (unset)\n JINA_DB_HOSTNAME              (unset)\n JINA_DB_NAME                  (unset)\n JINA_DB_PASSWORD              (unset)\n JINA_DB_USERNAME              (unset)\n JINA_DEFAULT_HOST             (unset)\n JINA_DISABLE_UVLOOP           (unset)\n JINA_EXECUTOR_WORKDIR         (unset)\n JINA_FULL_CLI                 (unset)\n JINA_IPC_SOCK_TMP             (unset)\n JINA_LOG_CONFIG               (unset)\n JINA_LOG_NO_COLOR             (unset)\n JINA_POD_NAME                 (unset)\n JINA_PROFILING                (unset)\n JINA_RANDOM_PORTS             (unset)\n JINA_SOCKET_HWM               (unset)\n JINA_TEST_GPU                 (unset)\n JINA_TEST_PRETRAINED          (unset)\n JINA_VCS_VERSION              (unset)\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Kavan72", "commentT": "2020-12-07T09:39:08Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/Kavan72>@Kavan72</denchmark-link>\n , could you give an example of the flow u are working with and the total length that you mean? Are you using any segmenter? Is the search done at root level or at chunk level?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Kavan72", "commentT": "2020-12-07T10:18:26Z", "comment_text": "\n \t\tmy index flow:-\n <denchmark-code>!Flow\n pods:\n   extractor:\n     uses: pods/extract.yml\n   encoder:\n     uses: pods/encode.yml\n     timeout_ready: 1200000\n     read_only: true\n   indexer:\n     uses: pods/index.yml\n     shards: 8\n     separated_workspace: true\n </denchmark-code>\n \n my query flow:-\n <denchmark-code>!Flow\n with:\n   read_only: true\n   port_expose: $JINA_PORT\n pods:\n   encoder:\n     uses: pods/encode.yml\n     timeout_ready: 60000\n     read_only: true\n   indexer:\n     uses: pods/index.yml\n     polling: all\n     uses_reducing: _merge_all\n     shards: 8\n     separated_workspace: true\n </denchmark-code>\n \n \n with this flow i started index on 100 docs and after when i start query on this index that time i'm only getting only 50 to 60 result(even if i set top_k == 100, is working on shards=1 )\n i'm not using any segmenter.\n search done on root level.\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Kavan72", "commentT": "2020-12-07T11:40:28Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/Kavan72>@Kavan72</denchmark-link>\n ,\n What is happening here is the following:\n top_k works at shard level, and since you are adding a lot of sharding, your documents are split in different shards. So in this case, every shard will return all the documents it has in their index.\n And then at merge time, it is failing to accumulate all the top_k of every shard.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Kavan72", "commentT": "2020-12-07T11:47:20Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/Kavan72>@Kavan72</denchmark-link>\n  ,\n Can you try changing uses_reducing for uses_after? It is a change that happened a few versions back and we may have forgotten to adapt southpark for it\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Kavan72", "commentT": "2020-12-07T11:53:23Z", "comment_text": "\n \t\tOpened <denchmark-link:https://github.com/jina-ai/jina/pull/1406>#1406</denchmark-link>\n  to fix this issue, but you will need to change also for \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Kavan72", "commentT": "2020-12-07T11:54:53Z", "comment_text": "\n \t\tAnd opened <denchmark-link:https://github.com/jina-ai/examples/pull/315>jina-ai/examples#315</denchmark-link>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Kavan72", "commentT": "2020-12-07T21:34:17Z", "comment_text": "\n \t\they <denchmark-link:https://github.com/Kavan72>@Kavan72</denchmark-link>\n  if you get the latest version and use  it will work as expected.\n thank you very much\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "Kavan72", "commentT": "2020-12-08T05:21:49Z", "comment_text": "\n \t\tthank you <denchmark-link:https://github.com/JoanFM>@JoanFM</denchmark-link>\n  i'll test\n \t\t"}}}, "commit": {"commit_id": "f3165afb5995ee48a891296d5ebc9525b9b7ae9b", "commit_author": "Joan Fontanals", "commitT": "2020-12-07 22:32:32+01:00", "changed_files": {"file_0": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "jina\\resources\\executors._merge_chunks.yml"}, "file_1": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "jina\\resources\\executors._merge_matches.yml"}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\integration\\issues\\github_1229\\test_sharding_empty_index.py", "file_new_name": "tests\\integration\\issues\\github_1229\\test_sharding_empty_index.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "28", "deleted_lines": "28", "method_info": {"method_name": "get_search_flow", "method_params": "", "method_startline": "21", "method_endline": "32"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\integration\\multimodal\\flow-embedding-multimodal-parallel.yml", "file_new_name": "tests\\integration\\multimodal\\flow-embedding-multimodal-parallel.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "13", "deleted_lines": "13"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\integration\\multimodal\\flow-multimodal-all-types-parallel.yml", "file_new_name": "tests\\integration\\multimodal\\flow-multimodal-all-types-parallel.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "19", "deleted_lines": "19"}}}}}}