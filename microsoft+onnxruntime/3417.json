{"BR": {"BR_id": "3417", "BR_author": "vuvko", "BRopenT": "2020-04-03T11:41:07Z", "BRcloseT": "2020-04-13T22:02:19Z", "BR_text": {"BRsummary": "Segmentation fault on loading quantized model", "BRdescription": "\n Describe the bug\n Onnxruntime raises SIGSEGV signal on loading the quantized model.\n Urgency\n If there are particular important use cases blocked by this or strict project-related timelines, please share more information and dates. If there are no hard deadlines, please specify none.\n System information\n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\n ONNX Runtime installed from (source or binary): binary\n ONNX Runtime version: 1.2.0\n Python version: 3.6.9\n Visual Studio version (if applicable): not applicable\n GCC/Compiler version (if compiling from source): not applicable\n CUDA/cuDNN version: not applicable\n GPU model and memory: not applicable\n \n \n Google Colab <denchmark-link:https://colab.research.google.com/drive/1mk9b-_5dlAiSsMYqWvxcYfqxjhi4juRq>link</denchmark-link>\n  for reproduction.\n Github Gist <denchmark-link:https://gist.github.com/vuvko/e5fa172387f9a12b6936e8505cded394>link</denchmark-link>\n  for the reference (<denchmark-link:https://drive.google.com/open?id=1HJP28RcVym3bj70pK_k4LMUQnBj6uoQN>model file</denchmark-link>\n ).\n Run all cells for the colab notebook, or run the script from Gist with a saved model file as .\n Expected behavior\n Expected to see an input0 to be printed (it's an input layer's name).\n \n The original model is a modified face detector in PyTorch (<denchmark-link:https://drive.google.com/open?id=1Ni8WfR1gdhvz-T2fdfuC5gc_E_7xo6B3>params file</denchmark-link>\n ). It was converted using  (<denchmark-link:https://drive.google.com/open?id=1lje7hI0Eiatk_SjHGk5lyjADQU-YMVMG>converted model</denchmark-link>\n ). The converted model can be used as it is but after quantization with <denchmark-link:https://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/quantization>quantization tool</denchmark-link>\n  it cannot be loaded with onnxruntime.\n This was tested on google colab, and ArchLinux machine (python 3.8, gcc 9.3, building from source and binary provided by PyPi).\n Running this with gdb shows this stack:\n <denchmark-code>[New Thread 0x7fffe2ffd700 (LWP 669857)]\n [New Thread 0x7fffe27fc700 (LWP 669858)]\n [New Thread 0x7fffe1ffb700 (LWP 669859)]\n [New Thread 0x7fffe17fa700 (LWP 669860)]\n [New Thread 0x7fffe0ff9700 (LWP 669861)]\n \n Thread 1 \"python\" received signal SIGSEGV, Segmentation fault.\n onnxruntime::DequantizeLinear<unsigned char>::Compute (this=0x55555607f5e0, \n     ctx=0x7fffffffc5b0)\n     at /home/andrey/libs/onnxruntime/include/onnxruntime/core/framework/tensor_shape.h:47\n 47\t    return std::vector<int64_t>::operator[](static_cast<int>(idx));\n \n </denchmark-code>\n \n I tested loading other quantized models, and everything works with <denchmark-link:https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/quantization/E2E_example_model/resnet50_v1.onnx>resnet50_v1</denchmark-link>\n  model.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "vuvko", "commentT": "2020-04-03T12:24:27Z", "comment_text": "\n \t\tApparently, switching the optimization off with GraphOptimizationLevel::ORT_DISABLE_ALL  allow to load the model, but sess.run raises SIGSEGV.\n Code to reproduce:\n <denchmark-code>import numpy as np\n import onnxruntime as rt\n \n \n sess_options = rt.SessionOptions()\n sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_DISABLE_ALL\n sess = rt.InferenceSession('model_q.onnx', sess_options)\n input_name = sess.get_inputs()[0].name\n \n print(input_name)\n \n np_inputs = np.zeros((1, 3, 320, 320), dtype=np.float32)\n \n onnx_res = sess.run(None, {input_name: np_inputs})\n print(np.max(onnx_res[0]))\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "vuvko", "commentT": "2020-04-03T17:06:20Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/yufenglee>@yufenglee</denchmark-link>\n  <denchmark-link:https://github.com/zhanghuanrong>@zhanghuanrong</denchmark-link>\n  The implementation of DequantizeLinear is overly complicated: it has support for an axis attribute that doesn't exist in the ONNX spec. This is probably based on the old QuantizeLinear implementation in the com.ms namespace that also had an axis attribute. In this case, the input tensor is a scalar and the \"broadcastDim=x_shape[axis]\" faults. This could be fixed by stripping out all the axis code. Something one of you wants to fix?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "vuvko", "commentT": "2020-04-13T22:02:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/vuvko>@vuvko</denchmark-link>\n  A fix for this has been checked into master. Thanks for reporting the problem!\n A couple comments about your model: you may want to run the model through an ONNX optimizer before quantizing. This will allow the Conv+BatchNormalization nodes to be fused. Also, you may now see better performance using QLinearOps as the quantization mode.\n As things currently stand, the model will be switching between quantized and float formats to do LeakyRelu. The runtime still needs to implement a quantized LeakyRelu to further streamline the model.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "vuvko", "commentT": "2020-04-22T08:19:37Z", "comment_text": "\n \t\tThank you for your fix and the comments!\n \t\t"}}}, "commit": {"commit_id": "5aab2671f8346a1489ac8ebf4b364544c6707062", "commit_author": "Tracy Sharpe", "commitT": "2020-04-13 14:52:52-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "onnxruntime\\contrib_ops\\cpu\\quantize_ops.cc", "file_new_name": "onnxruntime\\contrib_ops\\cpu\\quantize_ops.cc", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "5,15,16,24,25,33,34,37", "deleted_lines": "5,6,16,17,18,19,20,28,29,30,31,32,40,41,42,43,44,47"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "onnxruntime\\core\\providers\\cpu\\tensor\\quantize_linear.cc", "file_new_name": "onnxruntime\\core\\providers\\cpu\\tensor\\quantize_linear.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "33,35,36,37,40,41,42,43,46,47,49,50,51,52,63,64,65,66,68,69", "deleted_lines": "28,29,38,41,42,43,46,47,48,51,52,59,60,61,67,68,69,70,71,72,73,75", "method_info": {"method_name": "onnxruntime::DequantizeLinear<T>::Compute", "method_params": "ctx", "method_startline": "28", "method_endline": "75"}}, "hunk_1": {"Ismethod": 1, "added_lines": "102,104,105,106,108,109,110,111,112,114,115,116,117,118,119,120,121,122,125,127,128,129,130,132,133,134,135,137,138,139,140,142,143,144,145,147", "deleted_lines": "102,103,104,113,116,117,119,120,121,122,124,125,126,130,131,132,133,134,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155", "method_info": {"method_name": "onnxruntime::QuantizeLinear<T>::Compute", "method_params": "ctx", "method_startline": "97", "method_endline": "155"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "onnxruntime\\test\\providers\\cpu\\tensor\\quantize_linear_test.cc", "file_new_name": "onnxruntime\\test\\providers\\cpu\\tensor\\quantize_linear_test.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "103", "deleted_lines": null, "method_info": {"method_name": "onnxruntime::test::TEST", "method_params": "QuantizeLinearOpTest,QuantizeLinear_2D", "method_startline": "103", "method_endline": "117"}}, "hunk_1": {"Ismethod": 1, "added_lines": "49,50,51,52,53,54,55,56", "deleted_lines": null, "method_info": {"method_name": "onnxruntime::test::TEST", "method_params": "DequantizeLinearOpTest,DequantizeLinear_Scalar", "method_startline": "49", "method_endline": "56"}}, "hunk_2": {"Ismethod": 1, "added_lines": "32", "deleted_lines": "32", "method_info": {"method_name": "onnxruntime::test::TEST", "method_params": "DequantizeLinearOpTest,DequantizeLinear_2", "method_startline": "32", "method_endline": "46"}}, "hunk_3": {"Ismethod": 1, "added_lines": "103", "deleted_lines": "94", "method_info": {"method_name": "onnxruntime::test::TEST", "method_params": "QuantizeLinearOpTest,QuantizeLinear_1", "method_startline": "94", "method_endline": "108"}}, "hunk_4": {"Ismethod": 1, "added_lines": "120,121,122,123,124,125,126,127", "deleted_lines": null, "method_info": {"method_name": "onnxruntime::test::TEST", "method_params": "QuantizeLinearOpTest,QuantizeLinear_Scalar", "method_startline": "120", "method_endline": "127"}}, "hunk_5": {"Ismethod": 1, "added_lines": "32", "deleted_lines": "32", "method_info": {"method_name": "onnxruntime::test::TEST", "method_params": "DequantizeLinearOpTest,DequantizeLinear_2D", "method_startline": "32", "method_endline": "46"}}}}}}}