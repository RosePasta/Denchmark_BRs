{"BR": {"BR_id": "1030", "BR_author": "MaximilianPavon", "BRopenT": "2020-09-10T08:32:17Z", "BRcloseT": "2020-10-14T10:22:31Z", "BR_text": {"BRsummary": "Usage of DateSplitter with max_history", "BRdescription": "\n Hi,\n I am trying to use the DateSplitter together with max_history in order to make the test data shorter and would love to get some help.\n The documentation <denchmark-link:https://gluon-ts.mxnet.io/api/gluonts/gluonts.dataset.split.splitter.html>here</denchmark-link>\n  says the following about :\n <denchmark-code>If given, all entries in the test-set have a max-length of max_history. \n This can be sued to produce smaller file-sizes.\n </denchmark-code>\n \n But when I set this value to e.g. 3 weeks of hourly data () I am getting AssertionErrors from <denchmark-link:https://github.com/awslabs/gluon-ts/blob/18ab342a3abd7cfb1b6460dacfffd42b64fbefde/src/gluonts/dataset/split/splitter.py#L228>this</denchmark-link>\n  line, here is the relevant code block:\n def split(self, items: List[DataEntry]) -> TrainTestSplit:\n     split = TrainTestSplit()\n \n     for item in map(TimeSeriesSlice.from_data_entry, items):\n \n         train = self._train_slice(item)\n         test = self._trim_history(self._test_slice(item))\n \n         split._add_train_slice(train)\n \n         assert len(test) - len(train) >= getattr(self, \"prediction_length\")\n         split._add_test_slice(test)\n \n     return split\n So the length of the test slice minus the length of the train slice is not greater or equal to the defined prediction length.\n When debugging this code line by line, the problem seems to originate from the function , implemented a few <denchmark-link:https://github.com/awslabs/gluon-ts/blob/18ab342a3abd7cfb1b6460dacfffd42b64fbefde/src/gluonts/dataset/split/splitter.py#L212-L216>lines</denchmark-link>\n  above:\n def _trim_history(self, item: TimeSeriesSlice) -> TimeSeriesSlice:\n     if getattr(self, \"max_history\") is not None:\n         return item[: -getattr(self, \"max_history\")]\n     else:\n         return item\n Currently _trim_history() disregards the last max_history data points from the test slice. Considering that the test slice is exactly prediction_length data points longer than the training slice, this is bound to run into the mentioned AssertionError.\n Is this the expected behaviour of this parameter or am I doing something wrong?\n Here is some example code to replicate this:\n import gluonts\n from gluonts.dataset.field_names import FieldName\n from gluonts.dataset.split import DateSplitter\n import numpy as np\n import pandas as pd\n \n print(f\"gluonts version: {gluonts.__version__}\")  # gluonts version: 0.5.2\n \n prediction_length = 72\n \n start_date = pd.Timestamp(\"2020-01-01\", freq=\"1H\")\n split_date = start_date + 30 * pd.Timedelta(\"1D\")\n print(f\"start_date: {start_date}\\nsplit_date: {split_date}\")\n # start_date: 2020-01-01 00:00:00\n # split_date: 2020-01-31 00:00:00\n \n toy_data = [\n     {\n         FieldName.START: start_date,\n         FieldName.TARGET: np.arange(0, 10000),\n         \"item\": \"my_item\",\n         # FieldName.ITEM_ID unfortunately does not work, since the TimeSeriesSlice expects 'item' and not 'item_id':\n         # https://github.com/awslabs/gluon-ts/blob/18ab342a3abd7cfb1b6460dacfffd42b64fbefde/src/gluonts/dataset/split/splitter.py#L100\n     }\n ]\n \n \n for max_history in (None, 1, 2, 10, 20, 30):\n     try:\n         splitter = DateSplitter(prediction_length=prediction_length, split_date=split_date, max_history=max_history)\n         train_validation_split = splitter.split(items=toy_data)\n         print(f\"\\tNo problems when splitting with max_history={max_history}\")\n     except AssertionError as err:\n         print(f\"\\tWhoopsie, something went wrong when splitting with max_history={max_history}\")\n \n # \tNo problems when splitting with max_history=None\n # \tWhoopsie, something went wrong when splitting with max_history=1\n # \tWhoopsie, something went wrong when splitting with max_history=2\n # \tWhoopsie, something went wrong when splitting with max_history=10\n # \tWhoopsie, something went wrong when splitting with max_history=20\n # \tWhoopsie, something went wrong when splitting with max_history=30\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "MaximilianPavon", "commentT": "2020-10-13T09:04:45Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/MaximilianPavon>@MaximilianPavon</denchmark-link>\n ,\n thank you for the detailed report and sorry for leaving this open for so long. You are using the  parameter as intended but there are two bugs:\n \n _trim_history needs to return item[-getattr(self, \"max_history\"):]\n instead of item[:-getattr(self, \"max_history\")]\n the assertion needs be guarded:\n \n if getattr(self, \"max_history\") is None:\n     assert len(test) - len(train) >= getattr(self, \"prediction_length\")\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "MaximilianPavon", "commentT": "2020-10-14T10:22:05Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/MaximilianPavon>@MaximilianPavon</denchmark-link>\n  the fix for this was merge to , and will be included in the next release 0.6.0 (coming soon)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "MaximilianPavon", "commentT": "2020-10-14T10:52:42Z", "comment_text": "\n \t\tThanks a lot <denchmark-link:https://github.com/PascalIversen>@PascalIversen</denchmark-link>\n   and <denchmark-link:https://github.com/lostella>@lostella</denchmark-link>\n !\n We managed to get around this issue by over-writing the problematic functions in a similar way, but still had to ditch the use of the  due to <denchmark-link:https://github.com/awslabs/gluon-ts/issues/997>#997</denchmark-link>\n .\n \t\t"}}}, "commit": {"commit_id": "a289ca9428e20641609b883ab5f51572c13ebe39", "commit_author": "Pascal", "commitT": "2020-10-14 11:13:51+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "src\\gluonts\\dataset\\split\\splitter.py", "file_new_name": "src\\gluonts\\dataset\\split\\splitter.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "215", "deleted_lines": "215", "method_info": {"method_name": "_trim_history", "method_params": "self,TimeSeriesSlice", "method_startline": "213", "method_endline": "217"}}, "hunk_1": {"Ismethod": 1, "added_lines": "229,230,231,232", "deleted_lines": "229", "method_info": {"method_name": "split", "method_params": "self", "method_startline": "219", "method_endline": "235"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "test\\dataset\\split\\test_split.py", "file_new_name": "test\\dataset\\split\\test_split.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80", "deleted_lines": null, "method_info": {"method_name": "test_splitter", "method_params": "", "method_startline": "41", "method_endline": "80"}}}}}}}