{"BR": {"BR_id": "1787", "BR_author": "rui2016", "BRopenT": "2020-05-03T23:01:12Z", "BRcloseT": "2020-11-18T03:15:37Z", "BR_text": {"BRsummary": "Memory leak running registration_ransac_based_on_feature_matching in loop", "BRdescription": "\n Describe the bug\n Hi, we were using the following code piece to align multiple point cloud pairs in a loop. As I remember the code was borrowed from one of open3d's examples. Everything worked before, but after I did some update, e.g. update pytorch from 1.2 to 1.4, update CUDA to 10.1 etc. the same code now has memory leak (the memory actually increases very fast, for point cloud size of around 14000, it increases 1GB in seconds). We did some tracking and it seems the issue comes from the function registration_ransac_based_on_feature_matching. Has anybody got similar issue or can provide some hints?\n <denchmark-code>def align_pc(pcloud1, pcloud2, reflectance1=None, reflectance2=None):    \n     pc1 = open3d.geometry.PointCloud()\n     pc1.points = open3d.utility.Vector3dVector(pcloud1)\n     pc2 = open3d.geometry.PointCloud()\n     pc2.points = open3d.utility.Vector3dVector(pcloud2)\n \n     if reflectance1 is not None and reflectance2 is not None:\n         max_ref = max(reflectance1.max(), reflectance2.max())\n         reflectance1 = reflectance1 / float(max_ref)\n         reflectance2 = reflectance2 / float(max_ref)\n \n         ref1 = np.expand_dims(reflectance1, axis=1)\n         ref1 = np.repeat(ref1, 3, axis=1)\n         pc1.colors = open3d.utility.Vector3dVector(ref1)\n \n         ref2 = np.expand_dims(reflectance2, axis=1)\n         ref2 = np.repeat(ref2, 3, axis=1)\n         pc2.colors = open3d.utility.Vector3dVector(ref2)\n \n     voxel_size = 0.2\n     normal_radius = 4 * voxel_size\n     open3d.geometry.PointCloud.estimate_normals(pc1, search_param=open3d.geometry.KDTreeSearchParamHybrid(\n         radius=normal_radius, max_nn=30))\n     open3d.geometry.PointCloud.estimate_normals(pc2, search_param=open3d.geometry.KDTreeSearchParamHybrid(\n         radius=normal_radius, max_nn=30))\n \n     feature_radius = 10 * voxel_size\n     pc1_fpfh = open3d.registration.compute_fpfh_feature(pc1, open3d.geometry.KDTreeSearchParamHybrid(\n         radius=feature_radius, max_nn=100))\n     pc2_fpfh = open3d.registration.compute_fpfh_feature(pc2, open3d.geometry.KDTreeSearchParamHybrid(\n         radius=feature_radius, max_nn=100))\n \n     # 3D feature based registration.\n     dist_threshold = 3 * voxel_size\n     result = open3d.registration.registration_ransac_based_on_feature_matching(\n         source=pc1, target=pc2, source_feature=pc1_fpfh, target_feature=pc2_fpfh,\n         max_correspondence_distance=dist_threshold,\n         estimation_method=open3d.registration.TransformationEstimationPointToPoint(False),\n         ransac_n=4,\n         checkers=[open3d.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n                   open3d.registration.CorrespondenceCheckerBasedOnDistance(dist_threshold)],\n         criteria=open3d.registration.RANSACConvergenceCriteria(4000000, 500))\n </denchmark-code>\n \n Expected behavior\n When using the above function align_pc in a loop to align point cloud pairs, the memory should not keep increasing.\n Environment (please complete the following information):\n \n OS: Ubuntu 16.04\n Python version: 3.7\n Open3D version: 0.9.0.0\n Is this remote workstation?: no\n How did you install Open3D?: pip\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "rui2016", "commentT": "2020-05-08T13:36:12Z", "comment_text": "\n \t\tCould you provide a minimal self-contained script and data, where running the script can reproduce the issue?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "rui2016", "commentT": "2020-05-12T14:14:41Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/yxlao>@yxlao</denchmark-link>\n  ,\n it seems the memory leak is related to the order of importing open3d. In my case, importing it before numpy has no problem, while changing the order gives memory increase. The following code can be used to verify it on my machine. As I mentioned, the issue appeared after some update, so not sure if it is generally reproducible on every machine. The data used in the example can be found here:\n <denchmark-link:https://drive.google.com/drive/folders/1-sE1OcNgCIFYiX-p-NLluLy3NGkvou19?usp=sharing>https://drive.google.com/drive/folders/1-sE1OcNgCIFYiX-p-NLluLy3NGkvou19?usp=sharing</denchmark-link>\n \n import open3d\n import numpy as np\n \n # import numpy as np\n # import open3d\n \n \n def align(pcloud1, pcloud2):\n     pc1 = open3d.geometry.PointCloud()\n     pc1.points = open3d.utility.Vector3dVector(pcloud1)\n     pc2 = open3d.geometry.PointCloud()\n     pc2.points = open3d.utility.Vector3dVector(pcloud2)\n \n     voxel_size = 0.2\n     normal_radius = 4 * voxel_size\n     open3d.geometry.PointCloud.estimate_normals(pc1, search_param=open3d.geometry.KDTreeSearchParamHybrid(\n         radius=normal_radius, max_nn=30))\n     open3d.geometry.PointCloud.estimate_normals(pc2, search_param=open3d.geometry.KDTreeSearchParamHybrid(\n         radius=normal_radius, max_nn=30))\n \n     feature_radius = 10 * voxel_size\n     pc1_fpfh = open3d.registration.compute_fpfh_feature(pc1, open3d.geometry.KDTreeSearchParamHybrid(\n         radius=feature_radius, max_nn=100))\n     pc2_fpfh = open3d.registration.compute_fpfh_feature(pc2, open3d.geometry.KDTreeSearchParamHybrid(\n         radius=feature_radius, max_nn=100))\n \n     # 3D feature based registration.\n     dist_threshold = 3 * voxel_size\n     result = open3d.registration.registration_ransac_based_on_feature_matching(\n         source=pc1, target=pc2, source_feature=pc1_fpfh, target_feature=pc2_fpfh,\n         max_correspondence_distance=dist_threshold,\n         estimation_method=open3d.registration.TransformationEstimationPointToPoint(False),\n         ransac_n=4,\n         checkers=[open3d.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n                   open3d.registration.CorrespondenceCheckerBasedOnDistance(dist_threshold)],\n         criteria=open3d.registration.RANSACConvergenceCriteria(4000000, 500))\n \n     result_icp2 = open3d.registration.registration_icp(\n         pc1, pc2, 0.25, result.transformation,\n         open3d.registration.TransformationEstimationPointToPlane())\n \n     return result_icp2.transformation, result_icp2.fitness, result_icp2.inlier_rmse\n \n \n if __name__ == '__main__':\n     pc1 = np.load('pc1.npy')\n     pc2 = np.load('pc2.npy')\n \n     for i in range(200):\n         print(i)\n         align(pc1, pc2)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "rui2016", "commentT": "2020-06-01T11:31:02Z", "comment_text": "\n \t\tHello, I got the same issue.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "rui2016", "commentT": "2020-10-28T00:07:51Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/yxlao>@yxlao</denchmark-link>\n  Hey, is there any update on this issue? The problem still exists in the latest version 0.11.1.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "rui2016", "commentT": "2020-10-30T21:17:12Z", "comment_text": "\n \t\tI don't see a memory leak on my system with the above test code, whatever the import order is, but there seem to be more memory leaks elsewhere, as the \"reconstruction system\" tutorial fails on a machine with 256Gb RAM (keeping the default config parameters).   seems to be responsible for this.\n This is probably the same memory leak notified in <denchmark-link:https://github.com/intel-isl/Open3D/issues/2107>#2107</denchmark-link>\n \n Note that 0.10.0 works fine, so if you have this issue, I would recommend downgrading to 0.10.0.\n <denchmark-code>...\n Fragment 002 / 013 :: integrate rgbd frame 287 (88 of 100).\n Traceback (most recent call last):\n   File \"run_system.py\", line 68, in <module>\n     make_fragments.run(config)\n   File \".../Open3D/examples/python/reconstruction_system/make_fragments.py\", line 182, in run\n     Parallel(n_jobs=MAX_THREAD)(delayed(process_single_fragment)(\n   File \".../lib/python3.8/site-packages/joblib/parallel.py\", line 1061, in __call__\n     self.retrieve()\n   File \".../lib/python3.8/site-packages/joblib/parallel.py\", line 940, in retrieve\n     self._output.extend(job.get(timeout=self.timeout))\n   File \".../lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n     return future.result(timeout=timeout)\n   File \".../lib/python3.8/concurrent/futures/_base.py\", line 439, in result\n     return self.__get_result()\n   File \".../lib/python3.8/concurrent/futures/_base.py\", line 388, in __get_result\n     raise self._exception\n joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n \n The exit codes of the workers are {SIGKILL(-9)}\n </denchmark-code>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "rui2016", "commentT": "2020-11-03T20:40:55Z", "comment_text": "\n \t\tThis problem can be reproduced with open3d==0.11.1, numpy==1.19.1. Investigating.\n Update:\n \n the problem could be potentially from OpenMP. With the OpenMP flags disabled in RANSACBasedOnFeatureMapping, memory issue is not observed.\n with BUILD_CUDA_MODULE=OFF, the issue is still observable.\n somehow after I upgrade numpy to 1.19.4 and downgrade to 1.19.1, I cannot reproduce the problem anymore.\n this problem cannot be reproduced in a new environment. So potentially this problem might be related to internal package management.\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "rui2016", "commentT": "2020-11-03T23:11:37Z", "comment_text": "\n \t\tFor now, we cannot reproduce the problem if we create a new Conda environment. The problem is only partially reproducible in an old environment that has been created before October. (pip has changed the way to resolve conflicts after October 2020).\n <denchmark-link:https://github.com/rui2016>@rui2016</denchmark-link>\n  <denchmark-link:https://github.com/jbjeong>@jbjeong</denchmark-link>\n  <denchmark-link:https://github.com/shiyoung77>@shiyoung77</denchmark-link>\n  please kindly let us know if you can still reproduce the problem in a newly created environment. Thanks!\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "rui2016", "commentT": "2020-11-04T00:23:54Z", "comment_text": "\n \t\tI observe mo memory leak in a fresh pyenv with open3d-master installed, so I guess the leak was caused by some faulty numpy or something.\n <denchmark-link:https://github.com/rui2016>@rui2016</denchmark-link>\n  <denchmark-link:https://github.com/jbjeong>@jbjeong</denchmark-link>\n  <denchmark-link:https://github.com/shiyoung77>@shiyoung77</denchmark-link>\n   can you also test with the valgrind command below (if you're on linux)?\n <denchmark-code>$ PYTHONMALLOC=malloc valgrind --tool=memcheck --leak-check=yes --leak-resolution=high ~/.pyenv/versions/open3d-master/bin/python3.8 open3d_issue_1787.py\n ...\n ==19826== LEAK SUMMARY:\n ==19826==    definitely lost: 72,917 bytes in 323 blocks\n ==19826==    indirectly lost: 520 bytes in 8 blocks\n ==19826==      possibly lost: 1,216,903 bytes in 4,801 blocks\n ==19826==    still reachable: 3,056,092 bytes in 26,984 blocks\n ==19826==                       of which reachable via heuristic:\n ==19826==                         stdstring          : 14,844 bytes in 165 blocks\n ==19826==                         newarray           : 32 bytes in 1 blocks\n ==19826==         suppressed: 0 bytes in 0 blocks\n </denchmark-code>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "rui2016", "commentT": "2020-11-04T01:23:10Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/theNded>@theNded</denchmark-link>\n  <denchmark-link:https://github.com/devernay>@devernay</denchmark-link>\n  I pip installed open3d in a new conda environment and now the issue is gone. It seems to be a problem of internal package management by the old version of pip/conda. Thanks for looking into that.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "rui2016", "commentT": "2020-11-18T03:15:37Z", "comment_text": "\n \t\tThis issue will be closed for now. Please feel free to reopen, or continue discussions in the aforementioned issues that are still open.\n \t\t"}}}, "commit": {"commit_id": "c8fc4a09129745c7d245147f53d31bd74384b86b", "commit_author": "Wei Dong", "commitT": "2020-11-02 23:55:01-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "cpp\\open3d\\pipelines\\odometry\\Odometry.cpp", "file_new_name": "cpp\\open3d\\pipelines\\odometry\\Odometry.cpp", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "436", "deleted_lines": "436", "method_info": {"method_name": "open3d::pipelines::odometry::DoSingleIteration", "method_params": "iter,level,source,target,source_xyz,target_dx,target_dy,intrinsic,extrinsic_initial,jacobian_method,option", "method_startline": "417", "method_endline": "460"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "examples\\python\\reconstruction_system\\make_fragments.py", "file_new_name": "examples\\python\\reconstruction_system\\make_fragments.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "177", "deleted_lines": "177", "method_info": {"method_name": "run", "method_params": "config", "method_startline": "169", "method_endline": "188"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "examples\\python\\reconstruction_system\\refine_registration.py", "file_new_name": "examples\\python\\reconstruction_system\\refine_registration.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "150", "deleted_lines": "150", "method_info": {"method_name": "make_posegraph_for_refined_scene", "method_params": "ply_file_names,config", "method_startline": "137", "method_endline": "184"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "examples\\python\\reconstruction_system\\register_fragments.py", "file_new_name": "examples\\python\\reconstruction_system\\register_fragments.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "152", "deleted_lines": "152", "method_info": {"method_name": "make_posegraph_for_scene", "method_params": "ply_file_names,config", "method_startline": "141", "method_endline": "181"}}}}}}}