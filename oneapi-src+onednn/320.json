{"BR": {"BR_id": "320", "BR_author": "srikanthparupati", "BRopenT": "2018-09-11T18:50:57Z", "BRcloseT": "2018-09-28T23:53:24Z", "BR_text": {"BRsummary": "Memory reorder of (10 x 1 x 390 x 590) tensor size is taking about 250ms", "BRdescription": "\n I am benchmarking MKL DNN convolution performance for 10 filters with 11x11 kernel size against 600 x 400 image. Convolution is taking on average about 16 - 20 ms but memory reordering of convolution output to user memory is taking about 250ms. I am not sure how to get rid of memory reorder time, can you please help figuring out the issue?\n <denchmark-h:hr></denchmark-h>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n \n CPU make and model - 2.8 GHz Intel Core i7\n OS version - OS X 10.13\n Compiler - Clang\n MKLROOT - mklml_mac_2019.0.20180710\n MKLDNN - 0.16\n \n <denchmark-h:h3>Code snippet to reproduce the issue:</denchmark-h>\n \n void convolution_perfnet(int times = 1000) {\n <denchmark-code>auto cpu_engine = engine(engine::cpu, 0);\n \n std::vector<primitive> net;\n std::vector<primitive> net_weights;\n \n const int batch = 1;\n \n const int inW = 600;\n const int inH = 400;\n const int nPlanes = 1;\n \n const int nFilters = 10;\n const int kernelSize = 11;\n \n const int outW = 590;\n const int outH = 390;\n \n memory::dims conv1_src_tz = { batch, nPlanes, inH, inW };\n memory::dims conv1_weights_tz = { nFilters, nPlanes, kernelSize, kernelSize };\n memory::dims conv1_bias_tz = { nFilters };\n memory::dims conv1_dst_tz = { batch, nFilters, outH, outW };\n memory::dims conv1_strides = { 1, 1 };\n auto conv1_padding = { 0, 0 };\n \n std::vector<float> user_src(batch * nPlanes * inH * inW);\n std::vector<float> user_dst(batch * nFilters * outH * outW);\n \n std::vector<float> conv1_weights(std::accumulate(conv1_weights_tz.begin(), conv1_weights_tz.end(), 1, std::multiplies<uint32_t>()));\n std::vector<float> conv1_bias(std::accumulate(conv1_bias_tz.begin(), conv1_bias_tz.end(), 1, std::multiplies<uint32_t>()));\n \n // create memory for user data\n auto user_src_memory = memory({ { { conv1_src_tz }, memory::data_type::f32, memory::format::nchw }, cpu_engine }, user_src.data());\n \n auto user_weights_memory = memory({ { { conv1_weights_tz }, memory::data_type::f32, memory::format::oihw }, cpu_engine }, conv1_weights.data());\n auto user_bias_memory = memory({ { { conv1_bias_tz }, memory::data_type::f32, memory::format::x }, cpu_engine }, conv1_bias.data());\n \n auto user_dst_memory = memory({ { { conv1_dst_tz }, memory::data_type::f32, memory::format::nchw }, cpu_engine }, user_dst.data());\n \n // create memory descriptors for convolution data w/ no specified format\n auto conv1_src_md = memory::desc({ conv1_src_tz }, memory::data_type::f32, memory::format::any);\n auto conv1_bias_md = memory::desc({ conv1_bias_tz }, memory::data_type::f32, memory::format::any);\n auto conv1_weights_md = memory::desc({ conv1_weights_tz }, memory::data_type::f32, memory::format::any);\n auto conv1_dst_md = memory::desc({ conv1_dst_tz }, memory::data_type::f32, memory::format::any);\n \n // Create convolution descriptor\n  auto conv1_desc = convolution_forward::desc(prop_kind::forward_inference, convolution_direct, conv1_src_md,\n  conv1_weights_md, conv1_bias_md, conv1_dst_md, conv1_strides, conv1_padding, conv1_padding, padding_kind::zero);\n \n \n auto conv1_prim_desc = convolution_forward::primitive_desc(conv1_desc, cpu_engine);\n \n // create reorders for data and weights if layout requested by convolution is different from NCHW/OIHW\n auto conv1_src_memory = user_src_memory;\n if (memory::primitive_desc(conv1_prim_desc.src_primitive_desc()) != user_src_memory.get_primitive_desc()) {\n     conv1_src_memory = memory(conv1_prim_desc.src_primitive_desc());\n     net.push_back(reorder(user_src_memory, conv1_src_memory));\n }\n \n auto conv1_weights_memory = user_weights_memory;\n if (memory::primitive_desc(conv1_prim_desc.weights_primitive_desc()) != user_weights_memory.get_primitive_desc()) {\n     conv1_weights_memory = memory(conv1_prim_desc.weights_primitive_desc());\n     net_weights.push_back(reorder(user_weights_memory, conv1_weights_memory));\n }\n \n auto conv1_dst_memory = user_dst_memory; //\n // create reorder between output convolution output and user output memory\n if (memory::primitive_desc(conv1_prim_desc.dst_primitive_desc()) != user_dst_memory.get_primitive_desc()) {\n     conv1_dst_memory = memory(conv1_prim_desc.dst_primitive_desc());\n }\n \n // Create convolution primitive and add it to net \n net.push_back(convolution_forward(conv1_prim_desc, conv1_src_memory, conv1_weights_memory, user_bias_memory, conv1_dst_memory));\n \n // Memory reorder is taking about 250 ms - 10 x 1 x 390 x 590\n if (conv1_dst_memory != user_dst_memory) {\n     net.push_back(reorder(conv1_dst_memory, user_dst_memory));\n }\n \n \n // Run inference\n stream(stream::kind::eager).submit(net_weights).wait();\n for (int j = 0; j < times; ++j) {\n     stream(stream::kind::eager).submit(net).wait();\n }\n </denchmark-code>\n \n }\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "srikanthparupati", "commentT": "2018-09-11T19:03:37Z", "comment_text": "\n \t\tHi,\n Could you please post the output of the program run with MKLDNN_VERBOSE=1 (environment variable)?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "srikanthparupati", "commentT": "2018-09-11T20:58:50Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/emfomenk>@emfomenk</denchmark-link>\n   please find the MKL DNN output for 2 runs\n mkldnn_verbose,exec,reorder,simple:any,undef,in:f32_oihw out:f32_Ohwi8o,num:1,10x1x11x11,0.165039\n mkldnn_verbose,exec,convolution,jit:avx2,forward_inference,fsrc:nchw fwei:Ohwi8o fbia:x fdst:nChw8c,alg:convolution_direct,mb1_g1ic1oc10_ih400oh390kh11sh1dh0ph0_iw600ow590kw11sw1dw0pw0,17.4231\n mkldnn_verbose,exec,reorder,simple:any,undef,in:f32_nChw8c out:f32_nchw,num:1,1x10x390x590,287.683\n mkldnn_verbose,exec,convolution,jit:avx2,forward_inference,fsrc:nchw fwei:Ohwi8o fbia:x fdst:nChw8c,alg:convolution_direct,mb1_g1ic1oc10_ih400oh390kh11sh1dh0ph0_iw600ow590kw11sw1dw0pw0,12.832\n mkldnn_verbose,exec,reorder,simple:any,undef,in:f32_nChw8c out:f32_nchw,num:1,1x10x390x590,276.932\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "srikanthparupati", "commentT": "2018-09-11T21:12:28Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/srikanthparupati>@srikanthparupati</denchmark-link>\n ,\n Really weird. I will take a look.\n One more question. Do you use OpenMP? Or clang that you use doesn't support OpenMP?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "srikanthparupati", "commentT": "2018-09-11T21:14:38Z", "comment_text": "\n \t\tAnd just to confirm -- did you build a RELEASE or DEBUG version?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "srikanthparupati", "commentT": "2018-09-11T22:27:10Z", "comment_text": "\n \t\tThank you <denchmark-link:https://github.com/emfomenk>@emfomenk</denchmark-link>\n  . I am using OS X default Clang compiler, I do no think it supports OpenMP by default. I am using modified version of simplnet.cpp in MKL-DNN examples directory, it is getting linked with libomp5.dylib in MKL DNN libs directory.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "srikanthparupati", "commentT": "2018-09-12T00:58:34Z", "comment_text": "\n \t\tI built it in release mode\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "srikanthparupati", "commentT": "2018-09-21T17:01:36Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/emfomenk>@emfomenk</denchmark-link>\n  Did you get a chance to look into the issue?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "srikanthparupati", "commentT": "2018-09-21T20:17:52Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/srikanthparupati>@srikanthparupati</denchmark-link>\n ,\n Sorry for delay.\n Could you please try the following fix?\n $ git diff\n diff --git a/src/cpu/cpu_reorder.cpp b/src/cpu/cpu_reorder.cpp\n index 4c5f5c9a..829acca5 100644\n --- a/src/cpu/cpu_reorder.cpp\n +++ b/src/cpu/cpu_reorder.cpp\n @@ -74,6 +74,7 @@ static const rpd_create_f cpu_reorder_impl_list[] = {\n      jit_uni_reorder_create,\n \n      /* fp32: flat <-> blocked with tail */\n +    REG_SR_BIDIR(f32, any, f32, nChw8c),\n      REG_SR_BIDIR(f32, any, f32, nChw16c),\n      REG_SR_BIDIR(f32, any, f32, nCdhw16c),\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "srikanthparupati", "commentT": "2018-09-22T02:19:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/emfomenk>@emfomenk</denchmark-link>\n   Thanks a lot for the fix. It worked and reorder time dropped from 250ms to 3 ms.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "srikanthparupati", "commentT": "2018-09-22T03:00:48Z", "comment_text": "\n \t\tThanks for confirming!\n I will keep this open until promote the fix to the master.\n \t\t"}}}, "commit": {"commit_id": "d5b95233cbf352eff9da310d1be64e091e71d71f", "commit_author": "Fomenko, Evarist M", "commitT": "2018-09-27 19:03:23+00:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "src\\cpu\\cpu_reorder.cpp", "file_new_name": "src\\cpu\\cpu_reorder.cpp", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "77,78,79,80,81,82,91,92,93,94,95,96,97,98,111,112,113,114,115,116,117,118", "deleted_lines": null}}}}}}