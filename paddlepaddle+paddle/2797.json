{"BR": {"BR_id": "2797", "BR_author": "XinyuZhou-1014", "BRopenT": "2017-07-10T22:26:35Z", "BRcloseT": "2017-07-11T07:16:44Z", "BR_text": {"BRsummary": "Very slow (exponential) parsing speed when having a large depth of addto_layer", "BRdescription": "\n When there's a lot of addto_layers in a network, it will takes exponential parsing time.\n E.G. 1:\n <denchmark-code>def whole_network(src_embedding):\n     enc = src_embedding\n     for i in range(depth):\n         enc = addto_layer([enc, enc])\n \n     pred = fc_layer(input=fc_layer(\n                         input=enc,\n                         size=dim_embedding,\n                         act=ReluActivation()\n                         ),\n                     size=label_dict_len,\n                     act=SoftmaxActivation())\n     return pred\n </denchmark-code>\n \n E.G. 2:\n <denchmark-code>def whole_network(src_embedding):\n     enc = src_embedding\n     for i in range(depth):\n         enc_res = fc_layer(input=enc, size=dim_embedding)\n         enc_res = fc_layer(input=enc_res, size=dim_embedding)\n         enc = addto_layer([enc, enc_res])\n \n     pred = fc_layer(input=fc_layer(\n                         input=enc,\n                         size=dim_embedding,\n                         act=ReluActivation()\n                         ),\n                     size=label_dict_len,\n                     act=SoftmaxActivation())\n     return pred\n </denchmark-code>\n \n Both will costs a huge amount of time to parse (test by the nest_diagram tool).\n My parsing time:\n <denchmark-code>depth: 4,   parsing time: 0.16.\n depth: 8,   parsing time: 0.16.\n depth: 12, parsing time: 0.33.\n depth: 16, parsing time: 2.02.\n depth: 20, parsing time: 32.08.\n depth: 21, parsing time: 67.05.\n depth: 22, parsing time: 131.48.\n depth: 23, parsing time: 268.82.\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "XinyuZhou-1014", "commentT": "2017-07-11T00:11:49Z", "comment_text": "\n \t\tJust mark that \" parsing time means the time used for parsing and generating the protobuf\".\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "XinyuZhou-1014", "commentT": "2017-07-11T07:19:38Z", "comment_text": "\n \t\tThis issue is fixed by <denchmark-link:https://github.com/PaddlePaddle/Paddle/pull/2802>#2802</denchmark-link>\n . It because when we parsing network topology by , it just runs a depth-first search without any optimization.\n In <denchmark-link:https://github.com/PaddlePaddle/Paddle/pull/2802>#2802</denchmark-link>\n , if a node is visited before, that node is just skipped. It will fix this issue.\n You can just change  in paddle python package by this <denchmark-link:https://github.com/PaddlePaddle/Paddle/pull/2802/files#diff-a06e8d6c21eec2ca486aa4ce1099273a>patch</denchmark-link>\n .\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "XinyuZhou-1014", "commentT": "2017-07-11T18:29:20Z", "comment_text": "\n \t\tThanks a lot!\n \t\t"}}}, "commit": {"commit_id": "313e9f551fe0db22cbf5ccbeee5a744eab5892ed", "commit_author": "Yu Yang", "commitT": "2017-07-11 13:57:05+08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\paddle\\trainer_config_helpers\\networks.py", "file_new_name": "python\\paddle\\trainer_config_helpers\\networks.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1411,1412,1424,1425,1426,1427,1428", "deleted_lines": null, "method_info": {"method_name": "outputs", "method_params": "layers,args", "method_startline": "1401", "method_endline": "1489"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\paddle\\trainer_config_helpers\\tests\\configs\\file_list.sh", "file_new_name": "python\\paddle\\trainer_config_helpers\\tests\\configs\\file_list.sh", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9,10", "deleted_lines": "9"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\paddle\\trainer_config_helpers\\tests\\configs\\protostr\\test_cost_layers_with_weight.protostr", "file_new_name": "python\\paddle\\trainer_config_helpers\\tests\\configs\\protostr\\test_cost_layers_with_weight.protostr", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "134,158", "deleted_lines": null}}}, "file_3": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "python\\paddle\\trainer_config_helpers\\tests\\configs\\protostr\\test_recursive_topology.protostr"}, "file_4": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "python\\paddle\\trainer_config_helpers\\tests\\configs\\test_recursive_topology.py"}}}}