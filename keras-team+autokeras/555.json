{"BR": {"BR_id": "555", "BR_author": "kylechang523", "BRopenT": "2019-02-26T22:31:02Z", "BRcloseT": "2019-03-26T22:30:59Z", "BR_text": {"BRsummary": "Why Mlp module use conv.py?", "BRdescription": "\n <denchmark-h:h3>Bug Description</denchmark-h>\n \n When I using the Mlp module for training the dataset with shape (897000,43), it can work for some model. However when i extend the training time, there is a bug saying 'weight should at least have at  least two dimensions' appearing. We check the source code and this because the mlp module using convolution method in pytorch. This seems very strange.\n May I ask how to solve this problem?\n <denchmark-h:h3>Reproducing Steps</denchmark-h>\n \n Steps to reproduce the behavior:\n \n Step 1: ...\n Step 2: ...\n \n <denchmark-h:h3>Expected Behavior</denchmark-h>\n \n <denchmark-h:h3>Setup Details</denchmark-h>\n \n Include the details about the versions of:\n \n OS type and version:\n Python: 3.6\n autokeras: 0.3.7\n scikit-learn: 0.20.2\n numpy:\n keras:\n scipy:\n tensorflow: 1.12.0\n pytorch:\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "kylechang523", "commentT": "2019-02-28T07:57:19Z", "comment_text": "\n \t\tI have the exact same issue using the MlpModule. The training work for a few models and then throws an error saying weight should have at least two dimensions.\n Any ideas will be appreciated.\n Here is the traceback:\n <denchmark-code>Traceback (most recent call last):\n   File \"py36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n     self.run()\n   File \"py36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n     self._target(*self._args, **self._kwargs)\n   File \"py36/lib/python3.6/site-packages/autokeras/search.py\", line 350, in train\n     raise e\n   File \"py36/lib/python3.6/site-packages/autokeras/search.py\", line 343, in train\n     verbose=verbose).train_model(**trainer_args)\n   File \"py36/lib/python3.6/site-packages/autokeras/nn/model_trainer.py\", line 137, in train_model\n     self._train()\n   File \"py36/lib/python3.6/site-packages/autokeras/nn/model_trainer.py\", line 173, in _train\n     outputs = self.model(inputs)\n   File \"py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 123, in forward\n     outputs = self.parallel_apply(replicas, inputs, kwargs)\n   File \"py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 133, in parallel_apply\n     return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n   File \"py36/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 77, in parallel_apply\n     raise output\n   File \"py36/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 53, in _worker\n     output = module(*input, **kwargs)\n   File \"py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"py36/lib/python3.6/site-packages/autokeras/nn/graph.py\", line 686, in forward\n     temp_tensor = torch_layer(edge_input_tensor)\n   File \"py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"py36/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 421, in forward\n     self.padding, self.dilation, self.groups)\n RuntimeError: weight should have at least two dimensions\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "kylechang523", "commentT": "2019-02-28T13:32:52Z", "comment_text": "\n \t\tAfter more extensive testing, I'm able to add some information:\n Each time the error is thrown, the last added operation in the log is either to_add_skip_model or to_concat_skip_model. It's also the first time they are called.\n I'm able to reproduce the bug easily with the small iris dataset in less than 5 minutes with the following code:\n from sklearn import datasets\n from sklearn.preprocessing import OneHotEncoder\n from sklearn.model_selection import train_test_split\n from autokeras import MlpModule\n from autokeras.nn.loss_function import classification_loss\n from autokeras.nn.metric import Accuracy\n from autokeras.preprocessor import DataTransformerMlp\n \n iris = datasets.load_iris()\n \n X = iris.data\n Y = iris.target.reshape(-1, 1)\n \n encoder = OneHotEncoder(sparse=False)\n encoder.fit(Y)\n Y_encoded = encoder.transform(Y)\n n_classes = len(Y_encoded[0])\n \n x_train, x_test, y_train, y_test = train_test_split(\n         X,\n         Y_encoded,\n         test_size=0.33)\n \n data_transformer = DataTransformerMlp(x_train)\n train_data = data_transformer.transform_train(x_train, y_train)\n test_data = data_transformer.transform_test(x_test, y_test)\n \n clf = MlpModule(loss=classification_loss,\n                 metric=Accuracy,\n                 searcher_args={},\n                 verbose=True,\n                 path='./result_tmp/')\n \n clf.fit(n_output_node=n_classes,\n         input_shape=train_data.dataset.dataset.shape,\n         train_data=train_data,\n         test_data=test_data,\n         time_limit=1 * 5 * 60)\n \n clf.final_fit(train_data,\n               test_data,\n               retrain=False,\n               trainer_args={\n                   'max_iter_num': 20,\n                   'max_no_improvement_num': 5\n                   })\n Unfortunately, my knowledge on the project is too low for me to dig deeper.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "kylechang523", "commentT": "2019-03-02T20:46:54Z", "comment_text": "\n \t\tI think this is a bug. we need to figure out a way to prevent it from calling these two functions in the MLP module.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "kylechang523", "commentT": "2019-03-08T02:27:49Z", "comment_text": "\n \t\tThis sounds similar to the bug I just opened <denchmark-link:https://github.com/keras-team/autokeras/issues/570>#570</denchmark-link>\n , except that it complains that i should have at least three dimensions. Also, mine occurred at line 451 in conv.py but looks like same area.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "kylechang523", "commentT": "2019-03-15T15:55:23Z", "comment_text": "\n \t\tStuck here with the same bug. To add on, hoping it might help: for me it stops with the exact same exception and it does so consistently on the third model training (\"training model 2\") irrespective of the input regression data.\n Just to let you know: very much looking forward to using this when fixed. Your project's very much appreciated.\n \t\t"}}}, "commit": {"commit_id": "a575fa5515840958c78adecd242651a369fe95a7", "commit_author": "Yashwanth Reddy", "commitT": "2019-03-26 17:30:58-05:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "autokeras\\bayesian.py", "file_new_name": "autokeras\\bayesian.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "360", "deleted_lines": "359", "method_info": {"method_name": "generate", "method_params": "self,descriptors,timeout,sync_message", "method_startline": "311", "method_endline": "382"}}, "hunk_1": {"Ismethod": 1, "added_lines": "292,299", "deleted_lines": "292", "method_info": {"method_name": "__init__", "method_params": "self,searcher,t_min,metric,beta,skip_conn", "method_startline": "292", "method_endline": "299"}}, "hunk_2": {"Ismethod": 1, "added_lines": "292", "deleted_lines": "292", "method_info": {"method_name": "__init__", "method_params": "self,searcher,t_min,metric,beta", "method_startline": "292", "method_endline": "298"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "autokeras\\net_module.py", "file_new_name": "autokeras\\net_module.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "162", "deleted_lines": "161", "method_info": {"method_name": "__init__", "method_params": "self,loss,metric,searcher_args,path,verbose", "method_startline": "161", "method_endline": "163"}}, "hunk_1": {"Ismethod": 1, "added_lines": "68", "deleted_lines": "67", "method_info": {"method_name": "fit", "method_params": "self,n_output_node,input_shape,train_data,test_data,time_limit", "method_startline": "45", "method_endline": "87"}}, "hunk_2": {"Ismethod": 1, "added_lines": "31", "deleted_lines": "31", "method_info": {"method_name": "__init__", "method_params": "self,loss,metric,searcher_args,path,verbose,search_type", "method_startline": "31", "method_endline": "42"}}, "hunk_3": {"Ismethod": 1, "added_lines": "31,43", "deleted_lines": "31", "method_info": {"method_name": "__init__", "method_params": "self,loss,metric,searcher_args,path,verbose,search_type,skip_conn", "method_startline": "31", "method_endline": "43"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "autokeras\\net_transformer.py", "file_new_name": "autokeras\\net_transformer.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "102,105", "deleted_lines": "102,105", "method_info": {"method_name": "transform", "method_params": "graph,skip_conn", "method_startline": "102", "method_endline": "120"}}, "hunk_1": {"Ismethod": 1, "added_lines": "102,105", "deleted_lines": "102,105", "method_info": {"method_name": "transform", "method_params": "graph", "method_startline": "102", "method_endline": "120"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "autokeras\\search.py", "file_new_name": "autokeras\\search.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "295", "method_info": {"method_name": "__init__", "method_params": "self,n_output_node,input_shape,path,metric,loss,generators,verbose,trainer_args,default_model_len,default_model_width,t_min", "method_startline": "292", "method_endline": "295"}}, "hunk_1": {"Ismethod": 1, "added_lines": "298", "deleted_lines": "295", "method_info": {"method_name": "__init__", "method_params": "self,n_output_node,input_shape,path,metric,loss,generators,verbose,trainer_args,default_model_len,default_model_width,t_min,skip_conn", "method_startline": "295", "method_endline": "298"}}, "hunk_2": {"Ismethod": 1, "added_lines": "51,52", "deleted_lines": "51", "method_info": {"method_name": "__init__", "method_params": "self,n_output_node,input_shape,path,metric,loss,generators,verbose,trainer_args,default_model_len,default_model_width,skip_conn", "method_startline": "48", "method_endline": "52"}}, "hunk_3": {"Ismethod": 1, "added_lines": "51", "deleted_lines": "51", "method_info": {"method_name": "__init__", "method_params": "self,n_output_node,input_shape,path,metric,loss,generators,verbose,trainer_args,default_model_len,default_model_width", "method_startline": "48", "method_endline": "51"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tests\\common.py", "file_new_name": "tests\\common.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "299", "deleted_lines": "299", "method_info": {"method_name": "simple_transform", "method_params": "graph,skip_conn", "method_startline": "299", "method_endline": "301"}}, "hunk_1": {"Ismethod": 1, "added_lines": "299", "deleted_lines": "299", "method_info": {"method_name": "simple_transform", "method_params": "graph", "method_startline": "299", "method_endline": "301"}}, "hunk_2": {"Ismethod": 1, "added_lines": "304", "deleted_lines": "304", "method_info": {"method_name": "simple_transform_mlp", "method_params": "graph,skip_conn", "method_startline": "304", "method_endline": "306"}}, "hunk_3": {"Ismethod": 1, "added_lines": "304", "deleted_lines": "304", "method_info": {"method_name": "simple_transform_mlp", "method_params": "graph", "method_startline": "304", "method_endline": "306"}}}}}}}