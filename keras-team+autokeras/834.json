{"BR": {"BR_id": "834", "BR_author": "pezdorado", "BRopenT": "2019-11-13T10:29:59Z", "BRcloseT": "2020-01-19T20:38:45Z", "BR_text": {"BRsummary": "AutoKeras 1.0 much slower than 0.4 on Google Colab", "BRdescription": "\n When I try to run a simple MNIST example on Google Colab with GPU with Autokeras 0.4 it runs very fast (1 epoch of the first model takes < 2 s) but with 1.0 it runs much slower (1 epoch of the first model takes > 80 s). When I disable the GPU 0.4 runs as slow as 1.0 which suggests that 1.0 isn\u2019t using the GPU. How can I make Autokeras 1.0 run as fast as 0.4 with GPU?\n To reproduce go to <denchmark-link:url>colab.research.google.com</denchmark-link>\n , choose a Python 3 runtime with GPU accelerator, and execute the following\n 0.4 code\n <denchmark-code>%tensorflow_version 1.x\n \n !pip install autokeras\n \n import autokeras\n import tensorflow\n \n ( ( x, y ), validation_data ) = tensorflow.keras.datasets.mnist.load_data( )\n model = autokeras.ImageClassifier( verbose = True )\n model.fit( x, y )\n </denchmark-code>\n \n 1.0 code\n <denchmark-code>%tensorflow_version 2.x\n \n !pip install git+git://github.com/keras-team/keras-tuner@master#egg=keras-tuner\n !pip install git+git://github.com/keras-team/autokeras@master#egg=autokeras\n \n import tensorflow\n import autokeras\n \n ( ( x, y ), validation_data ) = tensorflow.keras.datasets.mnist.load_data( )\n model = autokeras.ImageClassifier( )\n model.fit( x, y, validation_data = validation_data )\n </denchmark-code>\n \n The issue is breakdown to the following issues.\n After solving them, the speed should be improved.\n <denchmark-link:https://github.com/keras-team/autokeras/issues/906>#906</denchmark-link>\n , <denchmark-link:https://github.com/keras-team/autokeras/issues/907>#907</denchmark-link>\n , <denchmark-link:https://github.com/keras-team/autokeras/issues/908>#908</denchmark-link>\n , <denchmark-link:https://github.com/keras-team/autokeras/issues/909>#909</denchmark-link>\n , <denchmark-link:https://github.com/keras-team/autokeras/issues/910>#910</denchmark-link>\n .\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "pezdorado", "commentT": "2019-11-14T09:38:03Z", "comment_text": "\n \t\tIn your 1.0 code, you have validation_data, so it does make sense.\n You still need to validate it, it takes more time.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "pezdorado", "commentT": "2019-11-14T12:53:56Z", "comment_text": "\n \t\t\n In your 1.0 code, you have validation_data, so it does make sense.\n You still need to validate it, it takes more time.\n \n The validation_data is only a small fraction of the training data (10000 versus 60000 samples I believe) and does not explain the speed factor of > 40. When I use validation_split = 0.2 instead of validation_data the speed difference remains (I understand 0.4 also implicitly uses a validation split but I cannot find what fraction).\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "pezdorado", "commentT": "2019-11-15T04:13:42Z", "comment_text": "\n \t\tThank you for the issue. We are trying to solve it.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "pezdorado", "commentT": "2019-12-05T07:05:40Z", "comment_text": "\n \t\tThank you for reopening this and trying to solve this.\n In <denchmark-link:https://github.com/keras-team/autokeras/issues/847>#847</denchmark-link>\n  it was suggested that this problem has to do with data augmentation.\n I'm having a hard time understanding how this could explain the fact that without GPU 0.4 and 1.0 are equally fast but with GPU 0.4 is much faster and 1.0 is still as slow as without GPU.\n Also I didn't know AutoKeras did image augmentation. I tried to find more information about this, and I found that the 0.4 ImageClassifier( ) has an augment parameter that defaults to False but the 1.0 ImageClassifier( ) doesn't seem to have an augment parameter. Does 1.0 do augmentation and if so is there a way to switch it off?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "pezdorado", "commentT": "2019-12-05T07:54:53Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/pezdorado>@pezdorado</denchmark-link>\n  You can turn off the augmentation by using the functional API of 1.0. The image block has that arg. Please refer to the tutorial on the official website. Thanks\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "pezdorado", "commentT": "2019-12-09T13:54:47Z", "comment_text": "\n \t\tI've tried the functional API with an ImageBlock( augment = False ) but it's as slow as the task API. I hope I applied the functional API correctly since the tutorial is quite sparse\n <denchmark-code>!pip install git+git://github.com/keras-team/autokeras@master#egg=autokeras\n \n import tensorflow\n import autokeras\n \n ( ( x, y ), validation_data ) = tensorflow.keras.datasets.mnist.load_data( )\n \n inputs = autokeras.ImageInput( )\n blocks = autokeras.hypermodel.hyperblock.ImageBlock( augment = False )( inputs )\n outputs = autokeras.ClassificationHead( )( blocks )\n \n model = autokeras.GraphAutoModel(\n     inputs = inputs,\n     outputs = outputs\n )\n \n model.fit( x, y, validation_split = 0.1, batch_size = 128 )\n </denchmark-code>\n \n Did I apply the functional API correctly and did I correctly turn off augmentation? If so, then the problem does not seem to be caused by augmentation.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "pezdorado", "commentT": "2019-12-09T16:36:28Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/pezdorado>@pezdorado</denchmark-link>\n  You did it correctly. Thank you!\n You can further break down the ImageBlock into [Normalization] + [ImageAugmentation] + [ConvBlock, ResNetBlock, XceptionBlock]. In this way, we can see which one is the slow one.\n I remember I tried just ConvBlock + ClassificationHead. It was fast.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "pezdorado", "commentT": "2019-12-13T12:02:54Z", "comment_text": "\n \t\t@jhfjhfj1 Thank you for your answers. I measured the execution times of the different blocks for 1 epoch both with and without GPU\n <denchmark-code>inputs = autokeras.ImageInput( )\n # t1 = autokeras.hypermodel.preprocessor.Normalization( )( inputs )\n # t1 = autokeras.hypermodel.preprocessor.ImageAugmentation( )( inputs )\n # t1 = autokeras.hypermodel.block.ConvBlock( )( inputs )\n # t1 = autokeras.hypermodel.block.XceptionBlock( )( inputs )\n t1 = autokeras.hypermodel.block.ResNetBlock( )( inputs )\n outputs = autokeras.ClassificationHead( )( t1 )\n \n model = autokeras.GraphAutoModel(\n     inputs = inputs,\n     outputs = outputs\n )\n </denchmark-code>\n \n The results are as follows\n With GPU\n Normalization( ): 85 s\n ImageAugmentation( ): 278 s\n ConvBlock( ): 11 s\n ResNetBlock( ): 45 s\n XceptionBlock( ): 42 s\n Without GPU:\n Normalization( ): 33 s\n ImageAugmentation( ): 80 s\n ConvBlock( ): 111 s\n ResNetBlock( ): 3882 s\n XceptionBlock( ): 2659 s\n So on 1.0 the GPU makes ConvBlock( ), ResNetBlock( ) and XceptionBlock( ) much faster but Normalization( ) and ImageAugmentation( ) slower. However the 1.0 ConvBlock( ) with GPU is still is much slower than the 0.4 full ImageClassifier( ) that only takes 2 s.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "pezdorado", "commentT": "2019-12-17T06:57:22Z", "comment_text": "\n \t\tThere is no option to export/save a model in autokeras 1.0. How can we save the model for deployment ?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "pezdorado", "commentT": "2020-01-19T20:37:34Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/KalidindiMounika>@KalidindiMounika</denchmark-link>\n  We have the function  in the new release now.\n It can export everything except for the preprocessors.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "pezdorado", "commentT": "2020-01-19T20:38:43Z", "comment_text": "\n \t\tThis issue has been breakdown to multiple parts in the AutoKeras Project.\n After adopting the preprocessing layers the issue should be resolved.\n \t\t"}}}, "commit": {"commit_id": "3771879b509e05fb8c192a0f7caff6080e875b1c", "commit_author": "Haifeng Jin", "commitT": "2019-11-29 14:31:46-06:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "autokeras\\hypermodel\\graph.py", "file_new_name": "autokeras\\hypermodel\\graph.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "283,284", "deleted_lines": "283,284,285", "method_info": {"method_name": "_compile_keras_model", "method_params": "self,hp,model", "method_startline": "280", "method_endline": "290"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 8, "file_old_name": "autokeras\\hypermodel\\preprocessor.py", "file_new_name": "autokeras\\hypermodel\\preprocessor.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "584", "method_info": {"method_name": "set_config", "method_params": "self,config", "method_startline": "574", "method_endline": "585"}}, "hunk_1": {"Ismethod": 1, "added_lines": "506,507,508,509,510,511,512", "deleted_lines": "506,507,508,509,510,511,512", "method_info": {"method_name": "_rotate", "method_params": "self,x", "method_startline": "506", "method_endline": "512"}}, "hunk_2": {"Ismethod": 1, "added_lines": "501,502,503,504", "deleted_lines": "499,500,502,503,504", "method_info": {"method_name": "transform", "method_params": "self,x,fit", "method_startline": "499", "method_endline": "504"}}, "hunk_3": {"Ismethod": 1, "added_lines": "561,562", "deleted_lines": "571", "method_info": {"method_name": "get_config", "method_params": "self", "method_startline": "561", "method_endline": "572"}}, "hunk_4": {"Ismethod": 1, "added_lines": "525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,552,555,556,557,558,559,560,561,562", "deleted_lines": "525,526,527,528,529,530,531,532,533,534,535,536,537,540,543,544,545,546,547,548,549,550", "method_info": {"method_name": "_augment", "method_params": "self,x", "method_startline": "525", "method_endline": "564"}}, "hunk_5": {"Ismethod": 1, "added_lines": "514,515,516,517,518,519,520,521,522,523", "deleted_lines": "514,515,516,517,518,519,520,521,522,523", "method_info": {"method_name": "_random_crop", "method_params": "self,x", "method_startline": "514", "method_endline": "523"}}, "hunk_6": {"Ismethod": 1, "added_lines": "441", "deleted_lines": "451", "method_info": {"method_name": "__init__", "method_params": "self,rotation_range,random_crop,brightness_range,saturation_range,contrast_range,translation,horizontal_flip,vertical_flip,gaussian_noise,seed,kwargs", "method_startline": "441", "method_endline": "452"}}, "hunk_7": {"Ismethod": 1, "added_lines": "441", "deleted_lines": "451", "method_info": {"method_name": "__init__", "method_params": "self,percentage,rotation_range,random_crop,brightness_range,saturation_range,contrast_range,translation,horizontal_flip,vertical_flip,gaussian_noise,kwargs", "method_startline": "440", "method_endline": "451"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "autokeras\\tuner.py", "file_new_name": "autokeras\\tuner.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "60", "deleted_lines": "60,67", "method_info": {"method_name": "_prepare_run", "method_params": "self,preprocess_graph,fit_kwargs,fit", "method_startline": "53", "method_endline": "67"}}}}, "file_3": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "examples\\cifar10.py"}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\autokeras\\hypermodel\\preprocessor_test.py", "file_new_name": "tests\\autokeras\\hypermodel\\preprocessor_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "86", "deleted_lines": "86", "method_info": {"method_name": "test_augment", "method_params": "", "method_startline": "83", "method_endline": "90"}}}}}}}