{"BR": {"BR_id": "4656", "BR_author": "sug4ndh", "BRopenT": "2020-10-16T14:59:37Z", "BRcloseT": "2020-11-19T13:37:36Z", "BR_text": {"BRsummary": "Federated Learning examples give \"RuntimeError: Websocket connection closed and creation of new connection failed.\" error when using Websocket client workers.", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n I am following PySyft tutorials and I keep getting \"RuntimeError: Websocket connection closed and creation of new connection failed.\" error when I use remote workers through websockets instead of VirtualWorkers. I have 2 vms running which act as Websocket client worker and a third vm where I run jupyter notebooks. I start the websocket server on the vms using run_websocket_server.py. Whenever I try to train a model in a notebook for Federated learning, for e.g. Federated learning with websockets and federated averaging.ipynb or Federated Recurrent Neural Network.ipynb, I get \"RuntimeError: Websocket connection closed and creation of new connection failed.\" error. The full error in the notebook is as follows:\n <denchmark-code>RuntimeError                              Traceback (most recent call last)\n <ipython-input-17-dec9889208dd> in <module>\n      1 for epoch in range(1, args.epochs + 1):\n      2     print(\"Starting epoch {}/{}\".format(epoch, args.epochs))\n ----> 3     model = rwc.train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches)\n      4     rwc.test(model, device, test_loader)\n ~/PySyft/examples/tutorials/advanced/websockets_mnist/run_websocket_client.py in train(model, device, federated_train_loader, lr, federate_after_n_batches, abort_after_one)\n    134             if curr_batches:\n    135                 models[worker], loss_values[worker] = train_on_batches(\n --> 136                     worker, curr_batches, model, device, lr\n    137                 )\n    138             else:\n ~/PySyft/examples/tutorials/advanced/websockets_mnist/run_websocket_client.py in train_on_batches(worker, batches, model_in, device, lr)\n     68         optimizer.step()\n     69         if batch_idx % LOG_INTERVAL == 0:\n ---> 70             loss = loss.get()  # <-- NEW: get the loss back\n     71             loss_local = True\n     72             logger.debug(\n ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in get(self, inplace, user, reason, *args, **kwargs)\n    646             tensor = self.child.get(*args, **kwargs)\n    647         else:  # Remote tensor/chain\n --> 648             tensor = self.child.get(*args, user=user, reason=reason, **kwargs)\n    649 \n    650         # Clean the wrapper\n ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/pointer_tensor.py in get(self, user, reason, deregister_ptr)\n    324             object used to point to #on a remote machine.\n    325         \"\"\"\n --> 326         tensor = ObjectPointer.get(self, user=user, reason=reason, deregister_ptr=deregister_ptr)\n    327 \n    328         # TODO: remove these 3 lines\n ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py in get(self, user, reason, deregister_ptr)\n    267         else:\n    268             # get tensor from location\n --> 269             obj = self.owner.request_obj(self.id_at_location, self.location, user, reason)\n    270 \n    271         # Remove this pointer by default\n ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in request_obj(self, obj_id, location, user, reason)\n    603             A torch Tensor or Variable object.\n    604         \"\"\"\n --> 605         obj = self.send_msg(ObjectRequestMessage(obj_id, user, reason), location)\n    606         return obj\n    607 \n ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/base.py in send_msg(self, message, location)\n    314 \n    315         # Step 2: send the message and wait for a response\n --> 316         bin_response = self._send_msg(bin_message, location)\n    317 \n    318         # Step 3: deserialize the response\n ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/virtual.py in _send_msg(self, message, location)\n     10         \"\"\"send message to worker location\"\"\"\n     11 \n ---> 12         return location._recv_msg(message)\n     13 \n     14     def _recv_msg(self, message: bin) -> bin:\n ~/anaconda3/envs/pysyft/lib/python3.7/site-packages/syft/workers/websocket_client.py in _recv_msg(self, message)\n    115             if not self.ws.connected:\n    116                 raise RuntimeError(\n --> 117                     \"Websocket connection closed and creation of new connection failed.\"\n    118                 )\n    119         return response\n RuntimeError: Websocket connection closed and creation of new connection failed.\n </denchmark-code>\n \n The trace on one of the worker vm is below:\n <denchmark-code>2020-10-16 13:44:20,707 ERROR base_events.py(l:1619, p:2157) - Task exception was never retrieved\n future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/sug/PySyft/syft/workers/websocket_server.py:93> exception=IndexError('tuple index out of range')>\n Traceback (most recent call last):\n   File \"/home/sug/PySyft/syft/workers/websocket_server.py\", line 111, in _producer_handler\n     response = self._recv_msg(message)\n   File \"/home/sug/PySyft/syft/workers/websocket_server.py\", line 122, in _recv_msg\n     return self.recv_msg(message)\n   File \"/home/sug/PySyft/syft/workers/base.py\", line 338, in recv_msg\n     msg = sy.serde.deserialize(bin_message, worker=self)\n   File \"/home/sug/PySyft/syft/serde/serde.py\", line 78, in deserialize\n     return strategy(binary, worker)\n   File \"/home/sug/PySyft/syft/serde/msgpack/serde.py\", line 383, in deserialize\n     return _deserialize_msgpack_simple(simple_objects, worker)\n   File \"/home/sug/PySyft/syft/serde/msgpack/serde.py\", line 374, in _deserialize_msgpack_simple\n     return _detail(worker, simple_objects)\n   File \"/home/sug/PySyft/syft/serde/msgpack/serde.py\", line 517, in _detail\n     val = msgpack_global_state.detailers[obj[0]](worker, obj[1], **kwargs)\n   File \"/home/sug/PySyft/syft/messaging/message.py\", line 385, in detail\n     sy.serde.msgpack.serde._detail(worker, msg_tuple[3]),\n IndexError: tuple index out of range\n 2020-10-16 13:44:20,941 ERROR base_events.py(l:1619, p:2157) - Task exception was never retrieved\n future: <Task finished coro=<WebsocketServerWorker._producer_handler() done, defined at /home/sug/PySyft/syft/workers/websocket_server.py:93> exception=IndexError('tuple index out of range')>\n Traceback (most recent call last):\n   File \"/home/sug/PySyft/syft/workers/websocket_server.py\", line 111, in _producer_handler\n     response = self._recv_msg(message)\n   File \"/home/sug/PySyft/syft/workers/websocket_server.py\", line 122, in _recv_msg\n     return self.recv_msg(message)\n   File \"/home/sug/PySyft/syft/workers/base.py\", line 338, in recv_msg\n     msg = sy.serde.deserialize(bin_message, worker=self)\n   File \"/home/sug/PySyft/syft/serde/serde.py\", line 78, in deserialize\n     return strategy(binary, worker)\n   File \"/home/sug/PySyft/syft/serde/msgpack/serde.py\", line 383, in deserialize\n     return _deserialize_msgpack_simple(simple_objects, worker)\n   File \"/home/sug/PySyft/syft/serde/msgpack/serde.py\", line 374, in _deserialize_msgpack_simple\n     return _detail(worker, simple_objects)\n   File \"/home/sug/PySyft/syft/serde/msgpack/serde.py\", line 517, in _detail\n     val = msgpack_global_state.detailers[obj[0]](worker, obj[1], **kwargs)\n   File \"/home/sug/PySyft/syft/messaging/message.py\", line 385, in detail\n     sy.serde.msgpack.serde._detail(worker, msg_tuple[3]),\n IndexError: tuple index out of range\n </denchmark-code>\n \n I have found some old issues here from folks had similar problem but the issues are either stale now or no solution has been posted yet!\n Any help is really appreciated!\n Thanks!\n <denchmark-h:h2>How to Reproduce</denchmark-h>\n \n \n Create 3 systems/vms with access to each other.\n Follow the instructions on PySyfts gtihub page to install pySyft, pyTorch on all three systems:\n \n <denchmark-code>conda create -n pysyft python=3.7\n conda activate pysyft # some older version of conda require \"source activate pysyft\" instead.\n conda install jupyter notebook==5.7.8 tornado==4.5\n conda activate pysyft\n pip install 'syft[udacity]'\n </denchmark-code>\n \n \n Clone PySyft github repo on all 3 systems\n On the 2 systems acting as websocket workers, execute:\n cd PySyft; python3 run_websocket_server.py --host \"host-ip\" --port \"port-number\" --id \"replace-with-name\"\n a) On the 3rd system, change directories to go to the tutorial subdir inside PySyft.\n b) Run jupyter notebook\n c) Open Federated Recurrent Neural Network.ipynb or  Federated learning with websockets and federated averaging.ipynb\n d) Replace the following lines\n \n <denchmark-code>              hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra\n               alice = sy.VirtualWorker(hook, id=\"alice\")  \n               bob = sy.VirtualWorker(hook, id=\"bob\")  \n               # charlie = sy.VirtualWorker(hook, id=\"charlie\") \n               workers_virtual = [alice, bob]\n </denchmark-code>\n \n <denchmark-code>     with these and execute the notebook:\n </denchmark-code>\n \n <denchmark-code>             hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra\n              kwargs_websocket_alice = {\"host\": \"ip_alice\", \"hook\": hook}\n              alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket_alice)\n              kwargs_websocket_bob = {\"host\": \"ip_bob\", \"hook\": hook}\n              bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket_bob)\n              workers_virtual = [alice, bob] \n </denchmark-code>\n \n <denchmark-h:h2>Expected Behavior</denchmark-h>\n \n The notebook should run without giving any errors.\n <denchmark-h:h2>System Information</denchmark-h>\n \n \n OS: Ubuntu\n OS Version: 18.04\n Language Version: Python 3.7\n Package Manager Version:  Conda 4.8.3\n Browser (if applicable): Firefox for jupyter notebook\n Browser Version (if applicable): 81.02\n \n <denchmark-h:h2>Additional Context</denchmark-h>\n \n I have also tried to run the above scenario with python-3.6.7 but I still get the same error.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "sug4ndh", "commentT": "2020-10-17T08:50:26Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/IonesioJunior>@IonesioJunior</denchmark-link>\n  any idea?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "sug4ndh", "commentT": "2020-10-18T08:01:16Z", "comment_text": "\n \t\tHi, just wondering: do you get this error also when replacing the Web Workers with local \"dummy\" Virtual Workers?\n FYI: The PySyft version I was using in the tutorial linked <denchmark-link:https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis/>https://blog.openmined.org/federated-learning-of-a-rnn-on-raspberry-pis/</denchmark-link>\n , was v0.1.19A1\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "sug4ndh", "commentT": "2020-10-19T12:01:31Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/DanyEle>@DanyEle</denchmark-link>\n , no, with virtualworkers most of the stuff runs as expected. The problem starts to occur when PySyft is being used in a pseudo realistic/realistic setup.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "sug4ndh", "commentT": "2020-10-20T07:08:15Z", "comment_text": "\n \t\t\n Hi @DanyEle, no, with virtualworkers most of the stuff runs as expected. The problem starts to occur when PySyft is being used in a pseudo realistic/realistic setup.\n \n Yeah, that's indeed the problem I noticed as well... I will try to see if I managed replicate the problem on my end with this example. Are you sure you're using exactly the same PySyft build version on both web workers? Did you try not to use conda, and building PySyft from source instead?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "sug4ndh", "commentT": "2020-10-21T10:20:33Z", "comment_text": "\n \t\t\n Yeah, that's indeed the problem I noticed as well... I will try to see if I managed replicate the problem on my end with this example. Are you sure you're using exactly the same PySyft build version on both web workers? Did you try not to use conda, and building PySyft from source instead?\n \n I am not using v1.19a1 or rather I can't. When I search for tagged releases, I get results from hydrogen and onwards, there is no v1.19a1. I did use hydrogen release though and made sure that all my systems were using the same version but that did not help either. I did not try to build it from source. I might give that a shot!\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "sug4ndh", "commentT": "2020-10-21T10:28:40Z", "comment_text": "\n \t\tYeah, between August 2019 and 2017 there  don't seem to be any versions tracked. The most similar version could be: 0.1.23a though <denchmark-link:https://github.com/OpenMined/PySyft/releases/tag/0.1.23a>https://github.com/OpenMined/PySyft/releases/tag/0.1.23a</denchmark-link>\n  dating back to August 2019. From what I remember, this version was working with my example\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "sug4ndh", "commentT": "2020-10-21T11:27:05Z", "comment_text": "\n \t\tAh okay, I dont think I tried that version. I will try and see if it works. But I guess folks over at slack are recommending to use grid now.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "sug4ndh", "commentT": "2020-10-22T07:08:55Z", "comment_text": "\n \t\tSo, I just cloned the latest version of PySyft and ran it all locally on an Ubuntu Virtual Machine from my local Windows. I then proceeded to start the websockets locally, and ran the example \"Federated Recurrent Neural Network\".\n The only thing I changed was removed any reference to \"device\", which in my case led to a lot of problems, as I don't have CUDA installed. So I made the following changes:\n <denchmark-code>#device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n model = RNN(n_letters, n_hidden, n_categories)#.to(device)\n </denchmark-code>\n \n And from:\n <denchmark-code>    line_reshaped, category_single = line_reshaped.to(device), category_single.to(device)\n </denchmark-code>\n \n to:\n <denchmark-code>line_reshaped, category_single = line_reshaped, category_single\n </denchmark-code>\n \n Then, everything went well, and the training went just fine. I suppose the problem you mentioned may arise when working with distributed machines instead of local ones? That's kinda weird though: from my experience, if something worked on local websockets, it worked on remote websockets just as well.\n <denchmark-link:https://user-images.githubusercontent.com/4907418/96837052-1b1bb900-1446-11eb-941d-16480933e3d7.png></denchmark-link>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "sug4ndh", "commentT": "2020-10-22T08:33:07Z", "comment_text": "\n \t\tI'm going to open a Pull Request with the new changes shortly\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "sug4ndh", "commentT": "2020-10-24T18:31:18Z", "comment_text": "\n \t\t\n I suppose the problem you mentioned may arise when working with distributed machines instead of local ones?\n \n Yeah, I believe so as well. With virtual workers things are working pretty much as expected.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "sug4ndh", "commentT": "2020-10-26T10:46:32Z", "comment_text": "\n \t\tOnce PR <denchmark-link:https://github.com/OpenMined/PySyft/pull/4697>#4697</denchmark-link>\n  gets approved and merged, could you please try and see if the issue got resolved for websockets as well?\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "sug4ndh", "commentT": "2020-10-28T22:25:53Z", "comment_text": "\n \t\tSure!\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "sug4ndh", "commentT": "2020-11-19T13:37:36Z", "comment_text": "\n \t\tHello! Just letting you know that we are no longer planning on supporting anything on the 0.2.x product line and that all work should be ported over to 0.3.x, which is considered a complete rebuild of PySyft. Because of that, I\u2019ll be closing this issue. If you feel this is a mistake, or if the issue actually applies to 0.3.x as well, please feel free to ping me on Slack and I\u2019ll reopen the issue.\n \t\t"}}}, "commit": {"commit_id": "e37b0fe7a7f834092e28ca933bc98f0770c24ab3", "commit_author": "Daniele Gadler", "commitT": "2020-11-02 17:46:10+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "INSTALLATION.md", "file_new_name": "INSTALLATION.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "106,107,108,109", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\tutorials\\advanced\\Federated Recurrent Neural Network.ipynb", "file_new_name": "examples\\tutorials\\advanced\\Federated Recurrent Neural Network.ipynb", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "29,31,32,33,34,36,38,39,40,41,51,67,76,120,122,123,124,125,126,127,128,129,130,175,200,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,260,301,329,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,368,370,371,372,373,374,375,376,377,378,379,380,381,382,416,418,419,420,421,422,423,424,425,426,427,463,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,545,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,599,601,602,603,604,605,606,607,608,609,610,632,634,635,636,637,638,639,640,641,642,680,710,712,713,714,715,716,717,718,719,720,721,722,723,724,743,750,758,766,771,773,780,807,829,845,891,917,919,920,921,922,923,924,925,926,927,943,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1010,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1054,1067,1094,1104,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1135,1136,1138,1139,1205", "deleted_lines": "29,31,32,33,34,36,38,39,40,41,51,67,76,120,122,167,192,194,226,267,295,297,313,315,349,351,387,389,437,439,469,471,493,495,533,563,565,584,591,592,600,608,613,615,622,649,671,686,688,734,760,762,778,780,788,790,809,822,849,859,861,863,864,866,867,933"}}}}}}