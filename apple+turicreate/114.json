{"BR": {"BR_id": "114", "BR_author": "res0nat0r", "BRopenT": "2017-12-17T18:55:30Z", "BRcloseT": "2018-02-14T00:34:44Z", "BR_text": {"BRsummary": "object_detector.create operands could not be broadcast together", "BRdescription": "\n Hi all,\n I'm trying to follow the object detection tutorial on some image data I have, I have\n an SFrame with my images labeled with annotations. explore() shows the bounding\n boxes properly setup, but I'm getting the error below when trying to create a model.\n Any suggestions would be great, or if this is a bug I'd be happy to help debug further.\n In [20]: images\n Out[20]:\n Columns:\n \timage\tImage\n \tannotations\tlist\n \ttruth\tImage\n \n Rows: 23\n \n Data:\n +------------------------+-------------------------------+\n |         image          |          annotations          |\n +------------------------+-------------------------------+\n | Height: 100 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 104 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 100 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 100 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 100 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 100 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 104 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 104 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 104 Width: 100 | [{'coordinates': {'y': 50,... |\n | Height: 104 Width: 100 | [{'coordinates': {'y': 50,... |\n +------------------------+-------------------------------+\n +------------------------+\n |         truth          |\n +------------------------+\n | Height: 100 Width: 100 |\n | Height: 104 Width: 100 |\n | Height: 100 Width: 100 |\n | Height: 100 Width: 100 |\n | Height: 100 Width: 100 |\n | Height: 100 Width: 100 |\n | Height: 104 Width: 100 |\n | Height: 104 Width: 100 |\n | Height: 104 Width: 100 |\n | Height: 104 Width: 100 |\n +------------------------+\n [23 rows x 3 columns]\n Note: Only the head of the SFrame is printed.\n You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n In [21]: images[0]\n Out[21]:\n {'annotations': [{'coordinates': {'height': 95, 'width': 95, 'x': 50, 'y': 50},\n    'label': 'elixir'}],\n  'image': Height: 100px\n  Width: 100px\n  Channels: 4,\n  'truth': Height: 100px\n  Width: 100px\n  Channels: 4}\n Model failure:\n model = tc.object_detector.create(images,feature='image', annotations='annotations')\n ...\n -> 1428         return fn_array(lhs, rhs)\n    1429     else:\n    1430         raise TypeError('type %s not supported' % str(type(rhs)))\n \n /Users/hovland/.pyenv/versions/2.7.10/envs/turicreate/lib/python2.7/site-packages/mxnet/ndarray.pyc in broadcast_mul(lhs, rhs, out, name, **kwargs)\n \n /Users/hovland/.pyenv/versions/2.7.10/envs/turicreate/lib/python2.7/site-packages/mxnet/_ctypes/ndarray.pyc in _imperative_invoke(handle, ndargs, keys, vals, out)\n      87         ctypes.c_int(len(keys)),\n      88         c_array(ctypes.c_char_p, [c_str(key) for key in keys]),\n ---> 89         c_array(ctypes.c_char_p, [c_str(str(val)) for val in vals])))\n      90\n      91     if original_output is not None:\n \n /Users/hovland/.pyenv/versions/2.7.10/envs/turicreate/lib/python2.7/site-packages/mxnet/base.pyc in check_call(ret)\n     127     \"\"\"\n     128     if ret != 0:\n --> 129         raise MXNetError(py_str(_LIB.MXGetLastError()))\n     130\n     131 if sys.version_info[0] < 3:\n \n MXNetError: [13:55:21] src/operator/tensor/./elemwise_binary_broadcast_op.h:66: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (416,416,4) (1,1,3)\n \n Stack trace returned 7 entries:\n [bt] (0) 0   libmxnet.so                         0x0000000116600ad8 _ZN4dmlc15LogMessageFatalD2Ev + 40\n [bt] (1) 1   libmxnet.so                         0x000000011685c990 _ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPNSt3__16vectorINS1_6TShapeENS5_9allocatorIS7_EEEESB_ + 1392\n [bt] (2) 2   libmxnet.so                         0x0000000116cf8fcc _Z12SetShapeTypePKN4nnvm2OpERKNS_9NodeAttrsERKN5mxnet7ContextERKNSt3__16vectorINS6_7NDArrayENSA_9allocatorISC_EEEEPSF_ + 1260\n [bt] (3) 3   libmxnet.so                         0x0000000116cff650 _Z20ImperativeInvokeImplRKN5mxnet7ContextERKN4nnvm9NodeAttrsEPNSt3__16vectorINS_7NDArrayENS7_9allocatorIS9_EEEESD_ + 688\n [bt] (4) 4   libmxnet.so                         0x0000000116d007f1 MXImperativeInvoke + 433\n [bt] (5) 5   _ctypes.so                          0x000000010f0b7627 ffi_call_unix64 + 79\n [bt] (6) 6   ???                                 0x00007ffee1653470 0x0 + 140732679926896\n \n \n In [23]:\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "res0nat0r", "commentT": "2017-12-18T17:32:27Z", "comment_text": "\n \t\tThanks for trying out the object detector! I really appreciate the detailed report of this bug, since it made it very easy for me to understand the issue. The problem is that we are not handling images with 4 channels (RGB + opacity channel) correctly.\n I will work on a fix and in the meantime let's discuss work-arounds to get your model working. If you want to train the model to leverage the opacity channel, then the current version will unfortunately not support that. However, if you get rid of the opacity channel then this error message will disappear. You can either manually convert your images before loading them, or you can do it through Turi Create:\n def drop_alpha(image):\n     return tc.Image(_image_data=image.pixel_data[..., :3].tobytes(),\n                     _width=image.width,\n                     _height=image.height,\n                     _channels=3,\n                     _format_enum=2,\n                     _image_data_size=image.width * image.height * 3)\n \n sf['image_rgb'] = sf['image'].apply(drop_alpha)\n Removing the opacity channel of an image can be done in several ways. The question is, do we replace the transparent background with white or black, or something else? The above method is blunt and simply drops the opacity channel. This will work if most of your images do not actually use the extra channel. However, if they do use it, it may lead to visual artifacts so I encourage you to check the new images manually with explore(). Let me know how it works out!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "res0nat0r", "commentT": "2017-12-18T19:07:06Z", "comment_text": "\n \t\tHi,\n Thanks for the feedback. I can look into manually fixing the images as a workaround. I've tried the fix above but am also getting the below error:\n #!/usr/bin/env python\n \n import turicreate as tc\n \n def drop_alpha(image):\n   return tc.Image(_image_data=image.pixel_data[..., :3].tobytes(),\n       _width=image.width,\n       _height=image.height,\n       _channels=3,\n       _format_enum=2,\n       _image_data_size=image.width * image.height * 3)\n \n images = tc.SFrame('clash.sframe')\n \n images['rgb'] = images['image'].apply(drop_alpha)\n $ ./convert.py\n Traceback (most recent call last):\n   File \"./convert.py\", line 16, in <module>\n     images['rgb'] = images['image'].apply(drop_alpha)\n   File \"/Users/hovland/.pyenv/versions/turicreate/lib/python2.7/site-packages/turicreate/data_structures/sarray.py\", line 1881, in apply\n     return SArray(_proxy=self.__proxy__.transform(fn, dtype, skip_na, seed))\n   File \"/Users/hovland/.pyenv/versions/turicreate/lib/python2.7/site-packages/turicreate/cython/context.py\", line 49, in __exit__\n     raise exc_type(exc_value)\n RuntimeError: Runtime Exception. Exception in python callback function evaluation:\n UnpicklingError('NEWOBJ class argument has NULL tp_new',):\n Traceback (most recent call last):\n   File \"turicreate/cython/cy_pylambda_workers.pyx\", line 398, in turicreate.cython.cy_pylambda_workers._init_lambda\n   File \"turicreate/cython/cy_pylambda_workers.pyx\", line 138, in turicreate.cython.cy_pylambda_workers.lambda_evaluator.__init__\n UnpicklingError: NEWOBJ class argument has NULL tp_new\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "res0nat0r", "commentT": "2017-12-18T19:33:25Z", "comment_text": "\n \t\tThat looks like another bug unfortunately (thanks for finding these!). I can't seem to reproduce it though. There is probably something different between your images and my test images. Perhaps it will give us a more informative error message (or none at all) if you run this as a slower for loop:\n rgbs = []\n for row in images:\n     rgb = drop_alpha(row['image'])\n     rgbs.append(rgb)\n images['rgb'] = rgbs\n Sorry again for this and thanks for your patience! Any additional information that can help us track this down is greatly appreciated.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "res0nat0r", "commentT": "2017-12-18T23:16:51Z", "comment_text": "\n \t\tInterestingly the code above seems to work fine. I'm able to run it and then modify my model create statement  to point to the rgb column and I see the model generation output status updates now.\n Here is just a print of the images['rgb'] column after running the above:\n ['Height: 100 Width: 100', 'Height: 104 Width: 100', 'Height: 100 Width: 100', 'Height: 100 Width: 100', 'Height: 100 Width: 100', 'Height: 100 Width: 100', 'Height: 104 Width: 100', 'Height: 104 Width: 100', 'Height: 104 Width: 100', 'Height: 104 Width: 100', 'Height: 104 Width: 100', 'Height: 104 Width: 100', 'Height: 100 Width: 100', 'Height: 100 Width: 100', 'Height: 104 Width: 100', 'Height: 104 Width: 100', 'Height: 104 Width: 100', 'Height: 100 Width: 100', 'Height: 104 Width: 100', 'Height: 100 Width: 100', 'Height: 100 Width: 100', 'Height: 100 Width: 100', 'Height: 100 Width: 100']```\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "res0nat0r", "commentT": "2017-12-19T05:40:00Z", "comment_text": "\n \t\tGreat! Does that mean the detector is training now?\n I would love to investigate the second bug some more. If you have time, it would be great if you could check if sf['image'][:1].apply(drop_alpha) also throws an error. If it doesn't, then try to adjust [:1] to find a subset that reproduces the error.\n If you find an SFrame with a single image that breaks it, I would love to get more info on that particular image (or ideally the file itself, but I understand completely if you do not want to share it). Thanks again for finding these things, <denchmark-link:https://github.com/res0nat0r>@res0nat0r</denchmark-link>\n !\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "res0nat0r", "commentT": "2017-12-19T17:52:53Z", "comment_text": "\n \t\tYep, I was able to get a model to generate now. :)\n Actually here is the entire SFrame if you'd like to download it and look. It is just a handful\n of iOS game images and is only ~1.2MB so I have no problem sharing it.\n Feel free to download below, let me know if you need anything else. Thanks for the help.\n <denchmark-link:https://stefhen.s3.amazonaws.com/clash.sframe.tar>https://stefhen.s3.amazonaws.com/clash.sframe.tar</denchmark-link>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "res0nat0r", "commentT": "2017-12-19T19:52:33Z", "comment_text": "\n \t\tThat is super helpful, thank you so much <denchmark-link:https://github.com/res0nat0r>@res0nat0r</denchmark-link>\n . I am now able to reproduce the error. I have filed a separate issue <denchmark-link:https://github.com/apple/turicreate/issues/124>#124</denchmark-link>\n  so as not to confuse it with the original issue of not being able to use the detector on RGBA images.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "res0nat0r", "commentT": "2017-12-19T20:36:23Z", "comment_text": "\n \t\tAwesome thanks!\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "res0nat0r", "commentT": "2018-01-31T09:24:37Z", "comment_text": "\n \t\tHi res0nat0r,\n I am trying to generate model for object detection. While generating model i am also getting same error as you got.\n i.e.  MXNetError: [13:55:21] src/operator/tensor/./elemwise_binary_broadcast_op.h:66: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (416,416,4) (1,1,3)\n i tried to add the code you and gustavla discussed above but i am still getting the error. Following is my convert.py code. Can you help me how to solve this issue.\n import sys\n import pandas as pd\n import math\n import os\n if len(sys.argv) < 2:\n quit(\"Require input file\")\n fileIn = sys.argv[1]\n objectLabel = 'Object'\n csv = pd.read_csv(fileIn, names = [\"image\", \"id\", \"label\", \"xMin\", \"xMax\", \"yMin\", \"yMax\", \"annotations\"],\n dtype={\"annotations\": str})\n for i, item in csv.iterrows():\n height = csv.iat[i, 6] - csv.iat[i, 5]\n width = csv.iat[i, 4] - csv.iat[i, 3]\n x = csv.iat[i, 3] + math.floor(width / 2)\n y = csv.iat[i, 5] + math.floor(height / 2)\n <denchmark-code>props = {'label': objectLabel, 'type': 'rectangle'}\n props['coordinates'] = {'height': height, 'width': width, 'x': x, 'y': y}\n csv.iat[i, 7] = [props]\n </denchmark-code>\n \n csv.to_csv('annotations.csv')\n Thank you.\n \t\t"}}}, "commit": {"commit_id": "866cc6dc73b9673137311170e79c472a036a4c5d", "commit_author": "Gustav Larsson", "commitT": "2018-02-13 16:34:43-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\unity\\python\\turicreate\\toolkits\\object_detector\\_sframe_loader.py", "file_new_name": "src\\unity\\python\\turicreate\\toolkits\\object_detector\\_sframe_loader.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "20,21", "deleted_lines": "20,21", "method_info": {"method_name": "_convert_image_to_raw", "method_params": "image", "method_startline": "19", "method_endline": "21"}}}}}}}