{"BR": {"BR_id": "1236", "BR_author": "dumitrescustefan", "BRopenT": "2020-03-25T19:02:05Z", "BRcloseT": "2020-03-29T18:56:37Z", "BR_text": {"BRsummary": "AdvancedProfiler error", "BRdescription": "\n Hi, as others have pointed out, the Profiler doesn't seem to work (it prints nothing), and trying out the AdvancedProfiler as in <denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/profiler.html>https://pytorch-lightning.readthedocs.io/en/latest/profiler.html</denchmark-link>\n  like:\n <denchmark-code>from pytorch_lightning.profiler import AdvancedProfiler\n     profiler = AdvancedProfiler(output_filename=\"prof.txt\")\n     trainer = Trainer(profiler=profiler, (other params here)\n </denchmark-code>\n \n gives me the following error:\n <denchmark-code>Validation sanity check: 50it [00:00, 212.11it/s]             Traceback (most recent call last):\n   File \"/Users/sdumitre/work/style/training.py\", line 177, in <module>\n     main(hparams)\n   File \"/Users/sdumitre/work/style/training.py\", line 77, in main\n     trainer.fit(model)\n   File \"/Users/sdumitre/virtual/p3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 630, in fit\n     self.run_pretrain_routine(model)\n   File \"/Users/sdumitre/virtual/p3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 810, in run_pretrain_routine\n     _, _, _, callback_metrics, _ = self.process_output(eval_results)\n   File \"/Users/sdumitre/virtual/p3/lib/python3.7/site-packages/pytorch_lightning/trainer/logging.py\", line 117, in process_output\n     callback_metrics[k] = v.item()\n ValueError: only one element tensors can be converted to Python scalars\n                                                  \n Process finished with exit code 1\n </denchmark-code>\n \n Any pointers?\n My env: torch 1.4 installed with pip, Python 3.7, no GPU, on, MacOS.\n Thanks for the great lib you're developing!\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "dumitrescustefan", "commentT": "2020-03-25T19:46:36Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jeremyjordan>@jeremyjordan</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "dumitrescustefan", "commentT": "2020-03-26T00:17:17Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/dumitrescustefan>@dumitrescustefan</denchmark-link>\n  thanks for submitting this issue.\n \n as others have pointed out, the Profiler doesn't seem to work\n \n If there are other Github Issues please reference them here\n \n the Profiler doesn't seem to work (it prints nothing)\n \n Did you configure logging? I usually do this in the root __init__.py of my projects.\n eg.\n <denchmark-code>import logging\n logging.basicConfig(level=logging.INFO)\n </denchmark-code>\n \n Finally, this seems unrelated to the AdvancedProfiler.\n <denchmark-code> File \"/Users/sdumitre/virtual/p3/lib/python3.7/site-packages/pytorch_lightning/trainer/logging.py\", line 117, in process_output\n     callback_metrics[k] = v.item()\n ValueError: only one element tensors can be converted to Python scalars\n </denchmark-code>\n \n Can you show what your training_step and validation_step code looks like?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "dumitrescustefan", "commentT": "2020-03-26T04:48:18Z", "comment_text": "\n \t\tbtw I have value error but not in profiler. I was using loguru instead of logging.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "dumitrescustefan", "commentT": "2020-03-26T08:32:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jeremyjordan>@jeremyjordan</denchmark-link>\n  thanks for the tips! I put logging into .py, and tried with the \"basic\" profiler again, now I get the same error.\n Here are the train/val_steps:\n <denchmark-code>    def training_step(self, batch: tuple, batch_nb: int, *args, **kwargs) -> dict:\n         x_tensor, x_lengths, y_tensor = batch\n \n         model_out = self.forward(x_tensor, x_lengths)\n         loss_val = self.loss(model_out, y_tensor)\n \n         tqdm_dict = {\"train_loss\": loss_val}\n         output = OrderedDict(\n             {\"loss\": loss_val, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n         )\n         return output\n \n     def validation_step(self, batch: tuple, batch_nb: int, *args, **kwargs) -> dict:\n         x_tensor, x_lengths, y_tensor = batch\n \n         model_out = self.forward(x_tensor, x_lengths)\n         loss_val = self.loss(model_out, y_tensor)\n \n         output = OrderedDict({\"val_loss\": loss_val})\n \n         return output\n </denchmark-code>\n \n All the code (except the forward and the model params) is copy-pasted from a lightning tutorial. Without the profiler everything seems to work okay. The trainer is initialised with:\n <denchmark-code>trainer = Trainer(\n         logger=setup_testube_logger(),\n         checkpoint_callback=True,\n         early_stop_callback=early_stop_callback,\n         default_save_path=\"experiments/\",\n         gpus=hparams.gpus,\n         distributed_backend=hparams.distributed_backend,\n         use_amp=hparams.use_16bit,\n         max_epochs=hparams.max_epochs,\n         min_epochs=hparams.min_epochs,\n         accumulate_grad_batches=hparams.accumulate_grad_batches,\n         log_gpu_memory=hparams.log_gpu_memory,\n         val_percent_check=hparams.val_percent_check,\n         profiler=True <-- this is what I added\n     )\n </denchmark-code>\n \n IMHO, shouldn't the profiler be agnostic to what I do in the code? Actually the in-built profiler is one of the main features that made me try out Lightning. I would be most grateful to have it work :) Please tell me what piece of code I could provide. The model itself aims at predicting a set of n values (floats) based on a number of sentences (embedded with BPE as ints). There is a sentence-level RNN that encodes each sentence, and then a \"document\" level RNN that runs over each sentence. This gets into a hidden->n linear layer and the error is MSELoss(). This is a baseline I created and I'd like to build from here, but I need to get past these initial errors. I don't know if this info is useful for you, I can provide all the code if required.\n Thanks!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "dumitrescustefan", "commentT": "2020-03-26T09:58:08Z", "comment_text": "\n \t\tMy bad. I did 2 things, I added the profiler and then I also added reduction='none' (in MSELoss) and in the loss function I forgot to do the reduction myself; thus the loss function returned a 2D tensor instead of a scalar, which broke the pytorch_lightning/trainer/logging.py, which led me to believe it was a logging error. I'm usually careful with changing more than a single item per run, but hey, blame the new lib I'm learning to use :)\n I'm not closing this issue because even though now the AdvancedProfiler works (dumps to a file), the basic one still doesn't want to print anything onscreen, even after adding level=DEBUG.\n If logging is required, maybe the docs could be updated ( <denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/profiler.html>https://pytorch-lightning.readthedocs.io/en/latest/profiler.html</denchmark-link>\n  ).\n Should I do anything more besides adding logging to init?\n <denchmark-code>import logging\n logging.basicConfig(level=logging.DEBUG)\n </denchmark-code>\n \n and in the Trainer object:\n <denchmark-code>profiler=True\n </denchmark-code>\n \n Thanks!\n Thanks and sorry for the time taken on my mistake!\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "dumitrescustefan", "commentT": "2020-03-27T03:14:05Z", "comment_text": "\n \t\t\n IMHO, shouldn't the profiler be agnostic to what I do in the code?\n \n yes! that's why i was confused about your error :)\n \n then I also added reduction='none' (in MSELoss) and in the loss function I forgot to do the reduction myself; thus the loss function returned a 2D tensor instead of a scalar, which broke the pytorch_lightning/trainer/logging.py\n \n but this makes perfect sense\n <denchmark-h:hr></denchmark-h>\n \n \n Actually the in-built profiler is one of the main features that made me try out Lightning. I would be most grateful to have it work :)\n \n that's great to hear! definitely want to help you get this figured out.\n i tried reproducing your error but it's working for me - check out this colab notebook\n <denchmark-link:https://colab.research.google.com/drive/1wSwMd5xGb36zdNS-5yk6ptHNEXqa1IMi>https://colab.research.google.com/drive/1wSwMd5xGb36zdNS-5yk6ptHNEXqa1IMi</denchmark-link>\n \n could you perhaps share a colab notebook where this is failing?\n btw i agree we should add a note to the documentation about enabling the logger, i believe we used to configure logging within the library but that was removed at one point\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "dumitrescustefan", "commentT": "2020-03-27T09:36:22Z", "comment_text": "\n \t\tsimilar question about missing logging table was raised also by <denchmark-link:https://github.com/dumitrescustefan>@dumitrescustefan</denchmark-link>\n \n I would suggest adding also a method  returning string of the stats\n so we avoid this confusion with logging init and a user can simply use:\n <denchmark-code>print(trainer.profiler.summary())\n </denchmark-code>\n \n <denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  <denchmark-link:https://github.com/jeremyjordan>@jeremyjordan</denchmark-link>\n  ^^\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "dumitrescustefan", "commentT": "2020-03-27T11:11:34Z", "comment_text": "\n \t\t\n \n if logging is required, let\u2019s just auto configure it for the user? not doing so goes against our principles.\n \n \n i think a problem with the logger is that i think it prints when training completes. if you stop training early (early stopping), or just ctrl c, i suspect you won\u2019t see it?\n \n \n adding that print suggestion i think is also yet another thing the user has to remember which goes against our principles haha.\n \n \n If (2) is true, then let\u2019s just make a limit of 2 epochs when profiler is enabled?\n Another option is to always run the basic profiler for the sanity check. Then profiler=True would run it for training as well. but i think the sanity check profiler won\u2019t reflect the true speed bc it doesn\u2019t backprop?\n <denchmark-link:https://github.com/jeremyjordan>@jeremyjordan</denchmark-link>\n  can we prioritize making these fixes as this is a key feature?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "dumitrescustefan", "commentT": "2020-03-28T00:55:48Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n \n \n if logging is required, let\u2019s just auto configure it for the user? not doing so goes against our principles.\n \n at the time when the feature was merged, we were configuring logging. i went back to <denchmark-link:https://github.com/jeremyjordan/pytorch-lightning/blob/feature/profiling/pytorch_lightning/__init__.py#L29>the branch</denchmark-link>\n  and verified that it was working out of the box. there was a later PR (<denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/767>#767</denchmark-link>\n ) which removed this.\n \n i think a problem with the logger is that i think it prints when training completes. if you stop training early (early stopping), or just ctrl c, i suspect you won\u2019t see it?\n \n actually, we still do show it :) in both cases (early stopping + keyboard interrupt)\n \n can we prioritize making these fixes as this is a key feature?\n \n yeah for sure. as i understand, this should just involve adding the logging config back in\n \t\t"}}}, "commit": {"commit_id": "54507f417eaf3317a798b3303c398152a4e35a18", "commit_author": "Jeremy Jordan", "commitT": "2020-03-29 14:56:36-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\__init__.py", "file_new_name": "pytorch_lightning\\__init__.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "13,15,16", "deleted_lines": "13,15"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tests\\test_profiler.py", "file_new_name": "tests\\test_profiler.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "77,81", "deleted_lines": "77", "method_info": {"method_name": "test_simple_profiler_describe", "method_params": "caplog,simple_profiler", "method_startline": "77", "method_endline": "81"}}, "hunk_1": {"Ismethod": 1, "added_lines": "77", "deleted_lines": "77", "method_info": {"method_name": "test_simple_profiler_describe", "method_params": "simple_profiler", "method_startline": "77", "method_endline": "79"}}}}}}}