{"BR": {"BR_id": "3811", "BR_author": "ananthsub", "BRopenT": "2020-10-03T01:14:40Z", "BRcloseT": "2020-10-03T16:33:30Z", "BR_text": {"BRsummary": "ModelCheckpoint not picking up metrics logged from lightning module", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n The Model Checkpoint raises a misconfiguration error because metrics logged from validation epoch end are mysteriously unavailable to the callback\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n <denchmark-code>from typing import Optional\n import torch\n from pytorch_lightning import Trainer, LightningModule\n from pytorch_lightning.callbacks import ModelCheckpoint\n from torch.utils.data.dataset import Dataset\n class RandomDataset(Dataset):\n     def __init__(self, size, length):\n         self.len = length\n         self.data = torch.randn(length, size)\n     def __getitem__(self, index):\n         return self.data[index]\n     def __len__(self):\n         return self.len\n class TestModule(LightningModule):\n     def __init__(self, epoch_min_loss_override: Optional[int] = None):\n         \"\"\"LightningModule for testing purposes\n         Args:\n             epoch_min_loss_override (int, optional): Pass in an epoch that will be set to the minimum\n                 validation loss for testing purposes (zero based). If None this is ignored. Defaults to None.\n         \"\"\"\n         super().__init__()\n         self.layer = torch.nn.Linear(32, 2)\n         self.epoch_min_loss_override = epoch_min_loss_override\n     def forward(self, x):\n         return self.layer(x)\n     def loss(self, batch, prediction):\n         # An arbitrary loss to have a loss that updates the model weights during `Trainer.fit` calls\n         return torch.nn.functional.mse_loss(prediction, torch.ones_like(prediction))\n     def training_step(self, batch, batch_idx):\n         output = self.forward(batch)\n         loss = self.loss(batch, output)\n         return {\"output\": output, \"loss\": loss, \"checkpoint_on\": loss}\n     def validation_step(self, batch, batch_idx):\n         output = self.forward(batch)\n         loss = self.loss(batch, output)\n         return {\"output\": output, \"loss\": loss, \"checkpoint_on\": loss}\n     def test_step(self, batch, batch_idx):\n         output = self.forward(batch)\n         loss = self.loss(batch, output)\n         return {\"output\": output, \"loss\": loss}\n     def training_epoch_end(self, outputs) -> None:\n         avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n         self.log(\"avg_loss\", avg_loss)\n     def validation_epoch_end(self, outputs) -> None:\n         avg_val_loss = torch.stack(\n             [torch.randn(1, requires_grad=True) for _ in outputs]\n         ).mean()\n         # For testing purposes allow a nominated epoch to have a low loss\n         if self.current_epoch == self.epoch_min_loss_override:\n             avg_val_loss -= 1e10\n         self.log(\"avg_val_loss\", avg_val_loss)\n         self.log(\"checkpoint_on\", avg_val_loss)\n     def test_epoch_end(self, outputs) -> None:\n         avg_loss = torch.stack(\n             [torch.randn(1, requires_grad=True) for _ in outputs]\n         ).mean()\n         self.log(\"val_loss\", avg_loss)\n     def configure_optimizers(self):\n         optimizer = torch.optim.SGD(self.layer.parameters(), lr=0.1)\n         lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n         return [optimizer], [lr_scheduler]\n     def train_dataloader(self):\n         return torch.utils.data.DataLoader(RandomDataset(32, 64))\n     def val_dataloader(self):\n         return torch.utils.data.DataLoader(RandomDataset(32, 64))\n     def test_dataloader(self):\n         return torch.utils.data.DataLoader(RandomDataset(32, 64))\n def train():\n     checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"avg_val_loss\")\n     trainer = Trainer(\n         max_epochs=epoch_min_loss_override + 2,\n         logger=False,\n         checkpoint_callback=checkpoint_callback,\n     )\n     model = TestModule(epoch_min_loss_override=2)\n     lightning_trainer.fit(model)\n </denchmark-code>\n \n this is the error I see\n <denchmark-code>raise MisconfigurationException(m)\n pytorch_lightning.utilities.exceptions.MisconfigurationException: ModelCheckpoint(monitor='avg_val_loss') not found in the returned metrics: ['avg_loss']. HINT: Did you call self.log('avg_val_loss', tensor) in the LightningModule?\n </denchmark-code>\n \n Full stacktrace:\n <denchmark-code>    lightning_trainer.fit(model)                                                                                                        File \"pytorch_lightning/trainer/trainer.py\", line 442, in fit\n     results = self.accelerator_backend.train()\n   File \"pytorch_lightning/accelerators/cpu_backend.py\", line 47, in train\n     results = self.train_or_test()\n   File \"pytorch_lightning/accelerators/base_backend.py\", line 43, in train_or_test\n     results = self.trainer.train()\n   File \"pytorch_lightning/trainer/trainer.py\", line 489, in train\n     self.train_loop.run_training_epoch()\n   File \"pytorch_lightning/trainer/training_loop.py\", line 538, in run_training_epoch\n     self.trainer.run_evaluation(test_mode=False)\n   File \"pytorch_lightning/trainer/trainer.py\", line 611, in run_evaluation\n     self.evaluation_loop.on_evaluation_end()\n   File \"pytorch_lightning/trainer/evaluation_loop.py\", line 95, in on_evaluation_end\n     self.trainer.call_hook('on_validation_end', *args, **kwargs)\n   File \"pytorch_lightning/trainer/trainer.py\", line 800, in call_hook\n     trainer_hook(*args, **kwargs)\n   File \"pytorch_lightning/trainer/callback_hook.py\", line 177, in on_validation_end\n     callback.on_validation_end(self, self.get_model())\n   File \"pytorch_lightning/callbacks/model_checkpoint.py\", line 167, in on_validation_end\n     self.save_checkpoint(trainer, pl_module)\n   File \"pytorch_lightning/callbacks/model_checkpoint.py\", line 197, in save_checkpoint\n     self._validate_monitor_key(trainer)\n   File \"pytorch_lightning/callbacks/model_checkpoint.py\", line 440, in _validate_monitor_key\n     raise MisconfigurationException(m)\n pytorch_lightning.utilities.exceptions.MisconfigurationException: ModelCheckpoint(monitor='avg_val_loss') not found in the returned me\n trics: ['avg_loss']. HINT: Did you call self.log('avg_val_loss', tensor) in the LightningModule?\n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n We can save the top-1 checkpoint with the monitor based on \"avg_val_loss\"\n <denchmark-h:h3>Environment</denchmark-h>\n \n This is based on Lightning git revision <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/commit/0c12065efd3cad98857895da43e02c6850317405>0c12065</denchmark-link>\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ananthsub", "commentT": "2020-10-03T02:28:14Z", "comment_text": "\n \t\tFor me this is happening only when no logs are created in validation_step: <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/3000#issuecomment-702978090>#3000 (comment)</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "d9bc95f83e163f1ef0e64012ad086d4448410817", "commit_author": "William Falcon", "commitT": "2020-10-03 12:33:29-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\callbacks\\early_stopping.py", "file_new_name": "pytorch_lightning\\callbacks\\early_stopping.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "109,111", "deleted_lines": "110,111", "method_info": {"method_name": "_validate_condition_metric", "method_params": "self,logs", "method_startline": "107", "method_endline": "122"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\connectors\\logger_connector.py", "file_new_name": "pytorch_lightning\\trainer\\connectors\\logger_connector.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "174,175,176,177", "deleted_lines": "174", "method_info": {"method_name": "_track_callback_metrics", "method_params": "self,eval_results,using_eval_result", "method_startline": "173", "method_endline": "211"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\connectors\\optimizer_connector.py", "file_new_name": "pytorch_lightning\\trainer\\connectors\\optimizer_connector.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "46,47,48,49,50,51,52,63", "deleted_lines": "46,57", "method_info": {"method_name": "update_learning_rates", "method_params": "self,str,monitor_metrics", "method_startline": "28", "method_endline": "92"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\evaluation_loop.py", "file_new_name": "pytorch_lightning\\trainer\\evaluation_loop.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "231,232,233,234", "deleted_lines": null, "method_info": {"method_name": "__run_eval_epoch_end", "method_params": "self,num_dataloaders,using_eval_result", "method_startline": "192", "method_endline": "238"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "pytorch_lightning\\trainer\\optimizers.py", "file_new_name": "pytorch_lightning\\trainer\\optimizers.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "98,101,102,103,104,105,106,107,108,109", "deleted_lines": "100,101,102,103", "method_info": {"method_name": "configure_schedulers", "method_params": "self,list,str", "method_startline": "98", "method_endline": "129"}}, "hunk_1": {"Ismethod": 1, "added_lines": "98,101,102,103,104,105,106,107,108,109", "deleted_lines": "97,100,101,102,103", "method_info": {"method_name": "configure_schedulers", "method_params": "self,list", "method_startline": "97", "method_endline": "123"}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\training_loop.py", "file_new_name": "pytorch_lightning\\trainer\\training_loop.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "534,535,536,537,538", "deleted_lines": "541,542,543,544,545", "method_info": {"method_name": "run_training_epoch", "method_params": "self", "method_startline": "494", "method_endline": "594"}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\base\\__init__.py", "file_new_name": "tests\\base\\__init__.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "5", "deleted_lines": null}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\base\\model_valid_epoch_ends.py", "file_new_name": "tests\\base\\model_valid_epoch_ends.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "54", "deleted_lines": "54", "method_info": {"method_name": "validation_epoch_end", "method_params": "self,outputs", "method_startline": "33", "method_endline": "56"}}}}, "file_8": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tests\\base\\simple_model.py"}, "file_9": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\callbacks\\test_early_stopping.py", "file_new_name": "tests\\callbacks\\test_early_stopping.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "162", "deleted_lines": "162", "method_info": {"method_name": "test_early_stopping_functionality.validation_epoch_end", "method_params": "self,outputs", "method_startline": "159", "method_endline": "162"}}, "hunk_1": {"Ismethod": 1, "added_lines": "40", "deleted_lines": "40", "method_info": {"method_name": "test_resume_early_stopping_from_checkpoint", "method_params": "tmpdir", "method_startline": "32", "method_endline": "69"}}, "hunk_2": {"Ismethod": 1, "added_lines": "162,168", "deleted_lines": "162,168", "method_info": {"method_name": "test_early_stopping_functionality", "method_params": "tmpdir", "method_startline": "156", "method_endline": "173"}}}}, "file_10": {"file_change_type": "MODIFY", "file_Nmethod": 10, "file_old_name": "tests\\callbacks\\test_model_checkpoint.py", "file_new_name": "tests\\callbacks\\test_model_checkpoint.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "185", "deleted_lines": "185", "method_info": {"method_name": "test_model_checkpoint_save_last", "method_params": "tmpdir", "method_startline": "180", "method_endline": "198"}}, "hunk_1": {"Ismethod": 1, "added_lines": "159,161,164,168,172,175", "deleted_lines": "159,161,164,168,172,175", "method_info": {"method_name": "test_model_checkpoint_format_checkpoint_name", "method_params": "tmpdir", "method_startline": "140", "method_endline": "177"}}, "hunk_2": {"Ismethod": 1, "added_lines": "127", "deleted_lines": "127", "method_info": {"method_name": "test_model_checkpoint_no_extraneous_invocations", "method_params": "tmpdir", "method_startline": "123", "method_endline": "137"}}, "hunk_3": {"Ismethod": 1, "added_lines": "307", "deleted_lines": "307", "method_info": {"method_name": "test_model_checkpoint_topk_all", "method_params": "tmpdir", "method_startline": "302", "method_endline": "319"}}, "hunk_4": {"Ismethod": 1, "added_lines": "416", "deleted_lines": "416", "method_info": {"method_name": "test_model_checkpoint_save_last_warning", "method_params": "tmpdir,caplog,max_epochs,should_validate,save_last", "method_startline": "409", "method_endline": "420"}}, "hunk_5": {"Ismethod": 1, "added_lines": "393", "deleted_lines": "393", "method_info": {"method_name": "test_ckpt_metric_names_results", "method_params": "tmpdir", "method_startline": "375", "method_endline": "403"}}, "hunk_6": {"Ismethod": 1, "added_lines": "429", "deleted_lines": "429", "method_info": {"method_name": "test_model_checkpoint_save_last_checkpoint_contents", "method_params": "tmpdir", "method_startline": "423", "method_endline": "459"}}, "hunk_7": {"Ismethod": 1, "added_lines": "48", "deleted_lines": "48", "method_info": {"method_name": "test_model_checkpoint_to_yaml", "method_params": "tmpdir,save_top_k", "method_startline": "43", "method_endline": "57"}}, "hunk_8": {"Ismethod": 1, "added_lines": "28", "deleted_lines": "28", "method_info": {"method_name": "test_model_checkpoint_with_non_string_input", "method_params": "tmpdir,save_top_k", "method_startline": "23", "method_endline": "39"}}, "hunk_9": {"Ismethod": 1, "added_lines": "333", "deleted_lines": "333", "method_info": {"method_name": "test_ckpt_metric_names", "method_params": "tmpdir", "method_startline": "322", "method_endline": "343"}}}}, "file_11": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\core\\test_datamodules.py", "file_new_name": "tests\\core\\test_datamodules.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "230", "deleted_lines": null, "method_info": {"method_name": "test_dm_checkpoint_save", "method_params": "tmpdir", "method_startline": "220", "method_endline": "238"}}}}, "file_12": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\loggers\\test_all.py", "file_new_name": "tests\\loggers\\test_all.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "85,86,87,88,89,90,91,92,94,95,96,97,98,99", "deleted_lines": "85,86,87,88,89,91,92,93", "method_info": {"method_name": "test_loggers_fit_test", "method_params": "wandb,tmpdir,monkeypatch,logger_class", "method_startline": "44", "method_endline": "99"}}}}, "file_13": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\models\\test_amp.py", "file_new_name": "tests\\models\\test_amp.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "13,174", "deleted_lines": null}}}, "file_14": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\models\\test_restore.py", "file_new_name": "tests\\models\\test_restore.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "165", "deleted_lines": "165", "method_info": {"method_name": "test_load_model_from_checkpoint", "method_params": "tmpdir,model_template", "method_startline": "155", "method_endline": "193"}}}}, "file_15": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\data_flow\\__init__.py", "file_new_name": "tests\\trainer\\data_flow\\__init__.py"}, "file_16": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_eval_loop_flow_1_0.py", "file_new_name": "tests\\trainer\\data_flow\\test_eval_loop_flow_1_0.py"}, "file_17": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_train_loop_flow_dict_1_0.py", "file_new_name": "tests\\trainer\\data_flow\\test_train_loop_flow_dict_1_0.py"}, "file_18": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_train_loop_flow_scalar_1_0.py", "file_new_name": "tests\\trainer\\data_flow\\test_train_loop_flow_scalar_1_0.py"}, "file_19": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\legacy_deprecate_flow_log_tests\\__init__.py", "file_new_name": "tests\\trainer\\legacy_deprecate_flow_log_tests\\__init__.py"}, "file_20": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_eval_loop_dict_return.py", "file_new_name": "tests\\trainer\\legacy_deprecate_flow_log_tests\\test_eval_loop_dict_return.py"}, "file_21": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_trainer_steps_dict_return.py", "file_new_name": "tests\\trainer\\legacy_deprecate_flow_log_tests\\test_trainer_steps_dict_return.py"}, "file_22": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_trainer_steps_result_return.py", "file_new_name": "tests\\trainer\\legacy_deprecate_flow_log_tests\\test_trainer_steps_result_return.py"}, "file_23": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_trainer_steps_scalar_return.py", "file_new_name": "tests\\trainer\\legacy_deprecate_flow_log_tests\\test_trainer_steps_scalar_return.py"}, "file_24": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_validation_steps_result_return.py", "file_new_name": "tests\\trainer\\legacy_deprecate_flow_log_tests\\test_validation_steps_result_return.py"}, "file_25": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\logging\\__init__.py", "file_new_name": "tests\\trainer\\logging\\__init__.py"}, "file_26": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_eval_loop_logging_1_0.py", "file_new_name": "tests\\trainer\\logging\\test_eval_loop_logging_1_0.py"}, "file_27": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "tests\\trainer\\test_train_loop_logging_1_0.py", "file_new_name": "tests\\trainer\\logging\\test_train_loop_logging_1_0.py"}, "file_28": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tests\\trainer\\test_optimizers.py", "file_new_name": "tests\\trainer\\test_optimizers.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "138,139,140,141", "deleted_lines": null, "method_info": {"method_name": "test_reduce_lr_on_plateau_scheduling.configure_optimizers", "method_params": "self", "method_startline": "138", "method_endline": "141"}}, "hunk_1": {"Ismethod": 1, "added_lines": "115,121,122,123,124,125,126,127,128,129,130,131", "deleted_lines": "131", "method_info": {"method_name": "test_reduce_lr_on_plateau_scheduling_missing_monitor", "method_params": "tmpdir", "method_startline": "115", "method_endline": "131"}}, "hunk_2": {"Ismethod": 1, "added_lines": "134,135,136,137,138,139,140,141,142,143,144,156", "deleted_lines": null, "method_info": {"method_name": "test_reduce_lr_on_plateau_scheduling", "method_params": "tmpdir", "method_startline": "134", "method_endline": "158"}}, "hunk_3": {"Ismethod": 1, "added_lines": "195,203,214", "deleted_lines": "170,178,189", "method_info": {"method_name": "test_optimizer_return_options", "method_params": "", "method_startline": "161", "method_endline": "215"}}}}, "file_29": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\trainer\\test_trainer.py", "file_new_name": "tests\\trainer\\test_trainer.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "668", "deleted_lines": "668", "method_info": {"method_name": "test_test_checkpoint_path", "method_params": "tmpdir,ckpt_path,save_top_k", "method_startline": "660", "method_endline": "692"}}, "hunk_1": {"Ismethod": 1, "added_lines": "511", "deleted_lines": "511", "method_info": {"method_name": "test_resume_from_checkpoint_epoch_restored", "method_params": "monkeypatch,tmpdir,tmpdir_server,url_ckpt", "method_startline": "474", "method_endline": "543"}}, "hunk_2": {"Ismethod": 1, "added_lines": "435", "deleted_lines": "435", "method_info": {"method_name": "test_model_checkpoint_only_weights", "method_params": "tmpdir", "method_startline": "426", "method_endline": "462"}}}}}}}