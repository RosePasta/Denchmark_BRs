{"BR": {"BR_id": "3253", "BR_author": "ShomyLiu", "BRopenT": "2020-08-29T09:06:08Z", "BRcloseT": "2020-09-03T10:27:33Z", "BR_text": {"BRsummary": "**gather_all_tensors_if_available**  share the same underlying storage for all GPUs", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n Hi, one of new features in   <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2528>#2528</denchmark-link>\n   has a   copy bug,  and this would lead that tensors in all GPUs  are the wrongly same as one GPU,  since they share the same storage:\n <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/metrics/converters.py#L304>https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/metrics/converters.py#L304</denchmark-link>\n \n <denchmark-code>gathered_result = world_size * [torch.zeros_like(result)]\n </denchmark-code>\n \n change into:\n <denchmark-code>gathered_result = [torch.zeros_like(result) for _ in range(world_size)]\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ShomyLiu", "commentT": "2020-09-01T14:53:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/justusschock>@justusschock</denchmark-link>\n  <denchmark-link:https://github.com/SkafteNicki>@SkafteNicki</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ShomyLiu", "commentT": "2020-09-01T15:21:15Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ShomyLiu>@ShomyLiu</denchmark-link>\n  good catch, would you be up for sending a PR? Please, note that the function is not used anywhere yet, but are there for future changes to the metric package.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ShomyLiu", "commentT": "2020-09-01T15:31:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/SkafteNicki>@SkafteNicki</denchmark-link>\n   it's my pleasure for a PR. I will finish this as soon as possible.\n Yeah, it's a new function to wrap the torch.distributed.all_gather.  But I think it is a very common use case;  especially, when using DDP mode, we always need to gather all the outputs cross all the GPUs.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "ShomyLiu", "commentT": "2020-09-01T15:35:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ShomyLiu>@ShomyLiu</denchmark-link>\n  Yes, I agree that it is a common use case.\n Please ping me when PR is ready.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "ShomyLiu", "commentT": "2020-09-02T04:47:06Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/SkafteNicki>@SkafteNicki</denchmark-link>\n   Hi, I have sent a PR jus now for your review   <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3319>#3319</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "d521c1b1787930dd4f6375a3c61a25579ca59ee5", "commit_author": "HT Liu", "commitT": "2020-09-03 12:27:32+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\metrics\\converters.py", "file_new_name": "pytorch_lightning\\metrics\\converters.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "304", "deleted_lines": "304"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tests\\metrics\\test_converters.py", "file_new_name": "tests\\metrics\\test_converters.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "180,181,182,183,184,185,186", "deleted_lines": null, "method_info": {"method_name": "test_gather_all_tensors_ddp", "method_params": "", "method_startline": "180", "method_endline": "186"}}, "hunk_1": {"Ismethod": 1, "added_lines": "138,139,140,141,142,143,144,145,146", "deleted_lines": null, "method_info": {"method_name": "_ddp_test_gather_all_tensors", "method_params": "rank,worldsize", "method_startline": "138", "method_endline": "146"}}}}}}}