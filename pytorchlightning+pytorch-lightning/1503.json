{"BR": {"BR_id": "1503", "BR_author": "rmrao", "BRopenT": "2020-04-15T17:12:50Z", "BRcloseT": "2020-05-12T04:14:36Z", "BR_text": {"BRsummary": "Do not configure python logging", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n pytorch-lightning right now configures the python logging module (<denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/8322f1b039c890b8ccdbfe29bf42056e5273d74f/pytorch_lightning/__init__.py#L16>here</denchmark-link>\n ). This is generally not recommended when writing a library as it makes it difficult for users to modify logging format (see <denchmark-link:https://docs.python.org/3/howto/logging.html#configuring-logging-for-a-library>python docs</denchmark-link>\n , Stack Overflow <denchmark-link:https://stackoverflow.com/questions/27016870/how-should-logging-be-used-in-a-python-package>post</denchmark-link>\n ). I would suggest deleting the configuration line.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "rmrao", "commentT": "2020-04-15T18:05:05Z", "comment_text": "\n \t\tI agree. Logging configuration should be disabled by default. We could still set up the logging configuration manually just after importing PL.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "rmrao", "commentT": "2020-04-15T21:21:46Z", "comment_text": "\n \t\twe had the discussion here <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/1267#discussion_r399640416>#1267 (comment)</denchmark-link>\n  <denchmark-link:https://github.com/jeremyjordan>@jeremyjordan</denchmark-link>\n  ^^\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "rmrao", "commentT": "2020-04-15T21:29:41Z", "comment_text": "\n \t\tHmm... ok. In that case, could I potentially suggest that the call to basicConfig be placed in Trainer's __init__? Otherwise you require the user to configure logging before importing pytorch lightning. There are a couple problems with this:\n \n imports should generally be placed at the top of a file. Configuring logging before importing pytorch-lightning means users have to violate PEP8 at some point.\n It's even more difficult when using DDP, since it's not possible to configure the logging for a DDP process before importing pytorch lightning.\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "rmrao", "commentT": "2020-04-15T23:56:00Z", "comment_text": "\n \t\t\n We could still set up the logging configuration manually just after importing PL.\n \n <denchmark-link:https://github.com/hadim>@hadim</denchmark-link>\n  isn't that what we do now? we configure logging when pytorch-lightning is imported\n \n could I potentially suggest that the call to basicConfig be placed in Trainer's init?\n \n <denchmark-link:https://github.com/rmrao>@rmrao</denchmark-link>\n  i'm not sure this would help you since we import  in the project's root \n however, if you configure logging as you wish in your project's root __init__.py, by the time lightning is imported the root handler will already be configured and basicConfig will not run.\n tagging <denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  since we had this discussion <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/1236#issuecomment-604943375>here</denchmark-link>\n  already. would prefer not to keep going back and forth on how we configure logging for the project.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "rmrao", "commentT": "2020-04-16T00:05:57Z", "comment_text": "\n \t\t\n \n We could still set up the logging configuration manually just after importing PL.\n \n @hadim isn't that what we do now? we configure logging when pytorch-lightning is imported\n \n now it sets the level for all logging not just for this lightning logger, that is what I was talking before...\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "rmrao", "commentT": "2020-04-16T00:19:31Z", "comment_text": "\n \t\tjust doing something like\n <denchmark-code>logger = logging.getLogger(__name__)\n logger.setLevel(logging.INFO)\n </denchmark-code>\n \n doesn't actually set up a handler to send the log messages.\n however, we could just simply add a line to configure a stream handler\n <denchmark-code>logger = logging.getLogger(__name__)\n logger.addHandler(logging.StreamHandler())\n logger.setLevel(logging.INFO)\n </denchmark-code>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "rmrao", "commentT": "2020-04-28T15:39:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jeremyjordan>@jeremyjordan</denchmark-link>\n  my suggestion is actually to put  inside of the Trainer's  function. This would only call basicConfig when an instance of  is created (not when it's imported). You could even include the log level as an argument to .\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "rmrao", "commentT": "2020-04-30T00:26:26Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rmrao>@rmrao</denchmark-link>\n  ah i see, i misunderstood your suggestion. i think that's a fine solution\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "rmrao", "commentT": "2020-05-01T14:34:26Z", "comment_text": "\n \t\tI was having problems because of this. It would duplicate my log messages.\n I understand this will be solved soon, but in case anyone has the same problem, this is how I circumvented it. When first defining the root logger, I do:\n <denchmark-code>    logger = logging.getLogger()\n     # if there is already a handler, remove it.\n     if logger.handlers:\n         logger.handlers.pop()\n </denchmark-code>\n \n (logging is the python logging package, not pl's)\n \t\t"}}}, "commit": {"commit_id": "1df0d2dc97e20b9646cbe0f42060a57f99f397fc", "commit_author": "Jeremy Jordan", "commitT": "2020-05-12 00:14:35-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\__init__.py", "file_new_name": "pytorch_lightning\\__init__.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "37,38", "deleted_lines": "37"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\trainer\\trainer.py", "file_new_name": "pytorch_lightning\\trainer\\trainer.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "3", "deleted_lines": null}}}}}}