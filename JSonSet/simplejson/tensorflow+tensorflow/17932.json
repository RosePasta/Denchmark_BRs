{"BR": {"BR_id": "17932", "BR_author": "lhlmgr", "BRopenT": "2018-03-22T19:22:53Z", "BRcloseT": "2018-03-26T18:20:41Z", "BR_text": {"BRsummary": "tf.contrib.data.bucket_by_sequence_length fails for nested Dataset element", "BRdescription": "\n Hello everyone,\n I just tried the new function to group variable length inputs for the dataset API, namely: tf.contrib.data.bucket_by_sequence_length, for a small Estimator-Model.\n I implemented the  such that it returns a dataset, where each element is a tuple <denchmark-link:https://www.tensorflow.org/get_started/premade_estimators#create_input_functions>(feature-dict, label)</denchmark-link>\n . However, when I run it, I get following exception:\n \n Traceback (most recent call last):\n ...\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 960, in apply\n dataset = transformation_func(self)\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py\", line 198, in _apply_fn\n window_size_func=window_size_fn))\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 960, in apply\n dataset = transformation_func(self)\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py\", line 90, in _apply_fn\n window_size_func)\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py\", line 239, in init\n self._make_key_func(key_func, input_dataset)\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py\", line 289, in _make_key_func\n self._key_func.add_to_graph(ops.get_default_graph())\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 488, in add_to_graph\n self._create_definition_if_needed()\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 321, in _create_definition_if_needed\n self._create_definition_if_needed_impl()\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\", line 338, in _create_definition_if_needed_impl\n outputs = self._func(*inputs)\n File \"/home/leo/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/grouping.py\", line 279, in tf_key_func\n ret = key_func(*nested_args)\n TypeError: element_to_bucket_id() takes 1 positional argument but 2 were given\n \n Here is a <denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/grouping.py#L143>link</denchmark-link>\n  to the function.\n Here is a code snipped to reproduce the error:\n import tensorflow as tf\n \n def input_fn():\n   def generator():\n     text = [[1, 2, 3],\n             [3, 4, 5, 6, 7],\n             [1, 2],\n             [8, 9, 0, 2, 3]]\n     label = [1, 2, 1, 2]\n \n     for x, y in zip(text, label):\n       yield (x, y)\n \n   dataset = tf.data.Dataset.from_generator(generator=generator,\n                                            output_shapes=(tf.TensorShape([None]), tf.TensorShape([])),\n                                            output_types=(tf.int32, tf.int32))\n \n   dataset = dataset.map(parse_example)\n   dataset = dataset.apply(tf.contrib.data.bucket_by_sequence_length(element_length_func=element_length_fn,\n                                                                     bucket_batch_sizes=[2, 2, 2],\n                                                                     bucket_boundaries=[0, 8],\n                                                                     pad_to_bucket_boundary=False))\n \n   return dataset\n \n def parse_example(x, y):\n   return dict(\n     x=x\n   ), y\n \n def element_length_fn(element):\n   features, label = element\n   return tf.shape(features[\"x\"])[0]\n \n if __name__ == '__main__':\n   with tf.Session() as sess:\n     dataset = input_fn()\n     iter = dataset.make_one_shot_iterator()\n \n     print(sess.run(iter.get_next()))\n My Env-Specs are logged in: <denchmark-link:https://github.com/tensorflow/tensorflow/files/1838947/tf_env.txt>tf_env.txt</denchmark-link>\n \n Thanks in advance!\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "lhlmgr", "commentT": "2018-03-23T00:59:03Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rsepassi>@rsepassi</denchmark-link>\n  Can you take a look, please?\n /cc <denchmark-link:https://github.com/ebrevdo>@ebrevdo</denchmark-link>\n  FYI.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "lhlmgr", "commentT": "2018-03-23T11:37:59Z", "comment_text": "\n \t\tYes, looking into it.\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Thu, Mar 22, 2018 at 9:02 PM Derek Murray ***@***.***> wrote:\n  @rsepassi <https://github.com/rsepassi> Can you take a look, please?\n \n  /cc @ebrevdo <https://github.com/ebrevdo> FYI.\n \n  \u2014\n  You are receiving this because you were mentioned.\n \n \n  Reply to this email directly, view it on GitHub\n  <#17932 (comment)>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/ABEGW-jtSsBu9OcEFUz8J3yEIi4AdEo5ks5thEmIgaJpZM4S3plo>\n  .\n \n \n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "lhlmgr", "commentT": "2018-03-23T15:59:21Z", "comment_text": "\n \t\tThis is consistent with the behavior of all callables in  with  inputs. The function <denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L1769>_should_unpack_args</denchmark-link>\n  is used to determine whether inputs to a user-supplied callable should be unpacked (i.e. called as ) and is  if the inputs are a . If the elements of a  are tuples, as they are in the example in this thread, then callables must expect the arguments to be passed unpacked.\n For example, here's a Dataset where the elements are tuples and a call to map fails when the map_fn expects only 1 element.\n <denchmark-code>    def data_gen():\n       text = [[1, 2, 3], [3, 4, 5, 6, 7], [1, 2], [8, 9, 0, 2, 3]]\n       label = [1, 2, 1, 2]\n       for x, y in zip(text, label):\n         yield (x, y)\n \n     dataset = tf.data.Dataset.from_generator(\n         generator=data_gen,\n         output_shapes=(tensor_shape.TensorShape([None]), tensor_shape.TensorShape([])),\n         output_types=(dtypes.int32, dtypes.int32))\n \n     # Fails\n     dataset.map(lambda el: el)\n </denchmark-code>\n \n We may want to update this behavior but that's where it stands right now.\n Fix right now would be to use a dict going in and apply a map to turn into a tuple afterwards.\n <denchmark-link:https://github.com/mrry>@mrry</denchmark-link>\n , should we look into updating the behavior of Dataset callables?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "lhlmgr", "commentT": "2018-03-23T16:12:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rsepassi>@rsepassi</denchmark-link>\n  Right, that example should fail, and we can't change this even if we wanted to. It works if you instead do .\n I think there might be a missing  in the  code, because making the equivalent change to <denchmark-link:https://github.com/lhlmgr>@lhlmgr</denchmark-link>\n 's program doesn't fix things, i.e.:\n def element_length_fn(features, label):\n   return tf.shape(features[\"x\"])[0]\n ...still yields the same error:\n \n TypeError: element_to_bucket_id() takes exactly 1 argument (2 given)\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "lhlmgr", "commentT": "2018-03-23T19:28:56Z", "comment_text": "\n \t\tYup, found the issue. Have a fix out. bucket_by_sequence_length was not correctly handling tupleized elements.\n \t\t"}}}, "commit": {"commit_id": "2219b88a3d5154b9158a1902b061cad6cae2d0a8", "commit_author": "A. Unique TensorFlower", "commitT": "2018-03-25 03:00:00-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tensorflow\\contrib\\data\\python\\kernel_tests\\bucketing_test.py", "file_new_name": "tensorflow\\contrib\\data\\python\\kernel_tests\\bucketing_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "473,474,475,476,477", "deleted_lines": null, "method_info": {"method_name": "testTupleElements.elements_gen", "method_params": "", "method_startline": "473", "method_endline": "477"}}, "hunk_1": {"Ismethod": 1, "added_lines": "479,480,481", "deleted_lines": null, "method_info": {"method_name": "testTupleElements.element_length_fn", "method_params": "x,y", "method_startline": "479", "method_endline": "481"}}, "hunk_2": {"Ismethod": 1, "added_lines": "471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494", "deleted_lines": null, "method_info": {"method_name": "testTupleElements", "method_params": "self", "method_startline": "471", "method_endline": "494"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\contrib\\data\\python\\ops\\grouping.py", "file_new_name": "tensorflow\\contrib\\data\\python\\ops\\grouping.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "143,145", "deleted_lines": "143,145", "method_info": {"method_name": "element_to_bucket_id", "method_params": "args", "method_startline": "143", "method_endline": "155"}}, "hunk_1": {"Ismethod": 1, "added_lines": "143,145", "deleted_lines": "143,145", "method_info": {"method_name": "element_to_bucket_id", "method_params": "element", "method_startline": "143", "method_endline": "155"}}}}}}}