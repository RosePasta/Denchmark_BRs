{"BR": {"BR_id": "36624", "BR_author": "durandg12", "BRopenT": "2020-02-10T14:48:15Z", "BRcloseT": "2020-02-18T22:19:59Z", "BR_text": {"BRsummary": "LSTM return_state=True fail with tf.keras.Sequencial model", "BRdescription": "\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6\n TensorFlow installed from (source or binary): binary\n TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\n Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14\n \n Describe the current behavior\n The call method of a tf.keras.Sequential object fails and throws an error when one layer is an instance of the tf.keras.layers.LSTM class constructed with return_state=True. Given the error message, I believe it is because the output of the call method of such LSTM layer is a list instead of a Tensor, and the call method of Sequential does not know what to do with a list.\n Describe the expected behavior\n I think that the call method of Sequential should know that the Tensor output of LSTM is the first element of the list when return_state=True.\n Code to reproduce the issue\n Setting :\n <denchmark-code>import tensorflow as tf\n import numpy as np\n \n print('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))\n \n batch_size = 3\n ts = 9\n input_dim = 2\n nump = np.arange(examples*batch_size*ts*input_dim, dtype=np.float32).reshape(batch_size, ts, input_dim)\n dataset = tf.data.Dataset.from_tensor_slices(nump).batch(batch_size)\n for x in dataset:\n     print(x.shape)\n return_state = True\n </denchmark-code>\n \n Output:\n <denchmark-code>Using Tensorflow version 2.1.0 (git version v2.1.0-rc2-17-ge5bf8de410)\n (3, 9, 2)\n </denchmark-code>\n \n Error with Sequential:\n <denchmark-code>model_seq = tf.keras.Sequential([tf.keras.layers.LSTM(3, return_state=return_state)])\n for x in dataset:\n     print(model_seq(x))\n </denchmark-code>\n \n Output:\n <denchmark-code>---------------------------------------------------------------------------\n AttributeError                            Traceback (most recent call last)\n <ipython-input-57-5500870ab2fc> in <module>\n       1 model_seq = tf.keras.Sequential([tf.keras.layers.LSTM(3, return_state=return_state)])\n       2 for x in dataset:\n ----> 3     print(model_seq(x))\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\n     820           with base_layer_utils.autocast_context_manager(\n     821               self._compute_dtype):\n --> 822             outputs = self.call(cast_inputs, *args, **kwargs)\n     823           self._handle_activity_regularization(inputs, outputs)\n     824           self._set_mask_metadata(inputs, outputs, input_masks)\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py in call(self, inputs, training, mask)\n     283       # `outputs` will be the inputs to the next layer.\n     284       inputs = outputs\n --> 285       mask = outputs._keras_mask\n     286 \n     287     return outputs\n \n AttributeError: 'list' object has no attribute '_keras_mask'\n </denchmark-code>\n \n It works when constructing the model with the Functional API:\n <denchmark-code>def lstm_model(return_state, ts, input_dim):\n     inp = tf.keras.Input(shape=(ts, input_dim))\n     out = tf.keras.layers.LSTM(3, return_state=return_state)(inp)\n     return tf.keras.Model(inputs=inp, outputs=out)\n     \n model_func = lstm_model(return_state, ts, input_dim)\n \n for x in dataset:\n     print(model_func(x))\n </denchmark-code>\n \n Output:\n <denchmark-code>[<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n array([[-8.8475537e-01,  2.9517543e-03, -9.9753261e-01],\n        [-9.7553629e-01,  9.5521700e-06, -9.9959475e-01],\n        [-9.9497062e-01,  3.0903845e-08, -9.9979442e-01]], dtype=float32)>, <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n array([[-8.8475537e-01,  2.9517543e-03, -9.9753261e-01],\n        [-9.7553629e-01,  9.5521700e-06, -9.9959475e-01],\n        [-9.9497062e-01,  3.0903845e-08, -9.9979442e-01]], dtype=float32)>, <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n array([[-7.6066346e+00,  2.9581292e-03, -3.3488092e+00],\n        [-8.9999275e+00,  9.5521846e-06, -4.2520967e+00],\n        [-9.0000000e+00,  3.0903848e-08, -4.5915442e+00]], dtype=float32)>]\n </denchmark-code>\n \n Related question\n In my Functional API example, lstm_modelfails if I use inp = tf.keras.Input(shape=(ts, None)) instead of providing the explicit input dimension. The error message I get is:\n <denchmark-code>---------------------------------------------------------------------------\n TypeError                                 Traceback (most recent call last)\n <ipython-input-64-9b042ffca48d> in <module>\n       4     return tf.keras.Model(inputs=inp, outputs=out)\n       5 \n ----> 6 model_func = lstm_model(return_state, ts, input_dim)\n       7 \n       8 for x in dataset:\n \n <ipython-input-64-9b042ffca48d> in lstm_model(return_state, ts, input_dim)\n       1 def lstm_model(return_state, ts, input_dim):\n       2     inp = tf.keras.Input(shape=(ts, None))\n ----> 3     out = tf.keras.layers.LSTM(3, return_state=return_state)(inp)\n       4     return tf.keras.Model(inputs=inp, outputs=out)\n       5 \n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)\n     642 \n     643     if initial_state is None and constants is None:\n --> 644       return super(RNN, self).__call__(inputs, **kwargs)\n     645 \n     646     # If any of `initial_state` or `constants` are specified and are Keras\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\n     746           # Build layer if applicable (if the `build` method has been\n     747           # overridden).\n --> 748           self._maybe_build(inputs)\n     749           cast_inputs = self._maybe_cast_inputs(inputs)\n     750 \n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _maybe_build(self, inputs)\n    2114         # operations.\n    2115         with tf_utils.maybe_init_scope(self):\n -> 2116           self.build(input_shapes)\n    2117       # We must set self.built since user defined build functions are not\n    2118       # constrained to set self.built.\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent.py in build(self, input_shape)\n     562     if isinstance(self.cell, Layer):\n     563       if not self.cell.built:\n --> 564         self.cell.build(step_input_shape)\n     565 \n     566     # set or validate state_spec\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py in wrapper(instance, input_shape)\n     304     if input_shape is not None:\n     305       input_shape = convert_shapes(input_shape, to_tuples=True)\n --> 306     output_shape = fn(instance, input_shape)\n     307     # Return shapes from `fn` as TensorShapes.\n     308     if output_shape is not None:\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent.py in build(self, input_shape)\n    2299         regularizer=self.kernel_regularizer,\n    2300         constraint=self.kernel_constraint,\n -> 2301         caching_device=default_caching_device)\n    2302     self.recurrent_kernel = self.add_weight(\n    2303         shape=(self.units, self.units * 4),\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\n     444         synchronization=synchronization,\n     445         aggregation=aggregation,\n --> 446         caching_device=caching_device)\n     447     backend.track_variable(variable)\n     448 \n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\n     742         dtype=dtype,\n     743         initializer=initializer,\n --> 744         **kwargs_for_getter)\n     745 \n     746     # If we set an initializer and the variable processed it, tracking will not\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\n     140       synchronization=synchronization,\n     141       aggregation=aggregation,\n --> 142       shape=variable_shape if variable_shape else None)\n     143 \n     144 \n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variables.py in __call__(cls, *args, **kwargs)\n     256   def __call__(cls, *args, **kwargs):\n     257     if cls is VariableV1:\n --> 258       return cls._variable_v1_call(*args, **kwargs)\n     259     elif cls is Variable:\n     260       return cls._variable_v2_call(*args, **kwargs)\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\n     217         synchronization=synchronization,\n     218         aggregation=aggregation,\n --> 219         shape=shape)\n     220 \n     221   def _variable_v2_call(cls,\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variables.py in <lambda>(**kwargs)\n     195                         shape=None):\n     196     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\n --> 197     previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n     198     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\n     199       previous_getter = _make_getter(getter, previous_getter)\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)\n    2594         synchronization=synchronization,\n    2595         aggregation=aggregation,\n -> 2596         shape=shape)\n    2597   else:\n    2598     return variables.RefVariable(\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variables.py in __call__(cls, *args, **kwargs)\n     260       return cls._variable_v2_call(*args, **kwargs)\n     261     else:\n --> 262       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n     263 \n     264 \n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\n    1409           aggregation=aggregation,\n    1410           shape=shape,\n -> 1411           distribute_strategy=distribute_strategy)\n    1412 \n    1413   def _init_from_args(self,\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\n    1540           with ops.name_scope(\"Initializer\"), device_context_manager(None):\n    1541             initial_value = ops.convert_to_tensor(\n -> 1542                 initial_value() if init_from_fn else initial_value,\n    1543                 name=\"initial_value\", dtype=dtype)\n    1544           if shape is not None:\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in <lambda>()\n     120           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n     121         initializer = initializer()\n --> 122       init_val = lambda: initializer(shape, dtype=dtype)\n     123       variable_dtype = dtype.base_dtype\n     124   if use_resource is None:\n \n ~/path/to/python3.6/site-packages/tensorflow_core/python/ops/init_ops_v2.py in __call__(self, shape, dtype)\n     413       scale /= max(1., fan_out)\n     414     else:\n --> 415       scale /= max(1., (fan_in + fan_out) / 2.)\n     416     if self.distribution == \"truncated_normal\":\n     417       # constant from scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n \n TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'\n </denchmark-code>\n \n Is it normal? If so, why is that?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "durandg12", "commentT": "2020-02-11T11:06:24Z", "comment_text": "\n \t\tWas able to reproduce the issue. Please find the Gist <denchmark-link:https://colab.sandbox.google.com/gist/amahendrakar/895c54df8a066fec5cfd7fdf27fc431a/36624.ipynb>here</denchmark-link>\n . Thanks!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "durandg12", "commentT": "2020-02-14T22:42:59Z", "comment_text": "\n \t\tSo for Sequential model, we expect the layer within it only have one input and one output. The LSTM layer with return_states=True will cause it to return more than 1 output, which violate this rule.\n I think the sequential model code need to be updated to show more explicit error for this case. We already show it if your model has the input_shape (which trigger model build under the hood), but we missed it in the deferred build case (input_shape is not provided by layers, but inferred when actual input is provided).\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "durandg12", "commentT": "2020-02-18T22:20:01Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36624>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36624>No</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "619ca02f2d9ff61aedf7de6e6b43116e859f6913", "commit_author": "Scott Zhu", "commitT": "2020-02-14 16:21:39-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\python\\keras\\engine\\sequential.py", "file_new_name": "tensorflow\\python\\keras\\engine\\sequential.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "203,214", "deleted_lines": "198,199,200,201,212,213,214,215", "method_info": {"method_name": "add", "method_params": "self,layer", "method_startline": "148", "method_endline": "231"}}, "hunk_1": {"Ismethod": 1, "added_lines": "288,289", "deleted_lines": null, "method_info": {"method_name": "call", "method_params": "self,inputs,training,mask", "method_startline": "268", "method_endline": "294"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tensorflow\\python\\keras\\engine\\sequential_test.py", "file_new_name": "tensorflow\\python\\keras\\engine\\sequential_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "224,225", "method_info": {"method_name": "test_invalid_use_cases.compute_output_shape", "method_params": "self,input_shape", "method_startline": "224", "method_endline": "225"}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233", "method_info": {"method_name": "test_invalid_use_cases", "method_params": "self", "method_startline": "212", "method_endline": "233"}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "221,222", "method_info": {"method_name": "test_invalid_use_cases.call", "method_params": "self,inputs", "method_startline": "221", "method_endline": "222"}}, "hunk_3": {"Ismethod": 1, "added_lines": "391,392,393,394,395,396,397,398,399,400", "deleted_lines": null, "method_info": {"method_name": "test_multi_output_layer_not_accepted", "method_params": "self", "method_startline": "380", "method_endline": "400"}}}}}}}