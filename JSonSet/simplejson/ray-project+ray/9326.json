{"BR": {"BR_id": "9326", "BR_author": "Nintorac", "BRopenT": "2020-07-07T05:13:17Z", "BRcloseT": "2020-09-01T20:14:36Z", "BR_text": {"BRsummary": "[autoscaler/docker] file_mounts fail when permissions required to create the host directory", "BRdescription": "\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n Ray nightly.\n When trying to create a file mount for the home directory of a container i.e. /root/, cluster creation fails because the host tries to write to /root/ which it does not have permission to do.\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n Use the following cluster.yml\n <denchmark-code># An unique identifier for the head node and workers of this cluster.\n cluster_name: default\n \n # The minimum number of workers nodes to launch in addition to the head\n # node. This number should be >= 0.\n min_workers: 0\n \n # The maximum number of workers nodes to launch in addition to the head\n # node. This takes precedence over min_workers.\n max_workers: 1\n \n # The initial number of worker nodes to launch in addition to the head\n # node. When the cluster is first brought up (or when it is refreshed with a\n # subsequent `ray up`) this number of nodes will be started.\n initial_workers: 0\n \n # Whether or not to autoscale aggressively. If this is enabled, if at any point\n #   we would start more workers, we start at least enough to bring us to\n #   initial_workers.\n autoscaling_mode: default\n \n # This executes all commands on all nodes in the docker container,\n # and opens all the necessary ports to support the Ray cluster.\n # Empty string means disabled.\n docker:\n     image: tensorflow/tensorflow:1.5.0-py3\n     container_name: \"ray_docker\" # e.g. ray_docker\n     # If true, pulls latest version of image. Otherwise, `docker run` will only pull the image\n     # if no cached version is present.\n     # pull_before_run: False\n     pull_before_run: True\n \n     run_options: []\n \n     # # Example of running a GPU head with CPU workers\n     # head_image: \"tensorflow/tensorflow:1.13.1-gpu-py3\"\n     head_run_options:  []\n     worker_run_options:\n         - --runtime=nvidia\n \n     # worker_image: \"ubuntu:18.04\"\n \n \n     # run_options:\n     #   - --runtime=nvidia\n \n # The autoscaler will scale up the cluster to this target fraction of resource\n # usage. For example, if a cluster of 10 nodes is 100% busy and\n # target_utilization is 0.8, it would resize the cluster to 13. This fraction\n # can be decreased to increase the aggressiveness of upscaling.\n # This value must be less than 1.0 for scaling to happen.\n target_utilization_fraction: 0.8\n \n # If a node is idle for this many minutes, it will be removed.\n idle_timeout_minutes: 5\n \n # Cloud-provider specific configuration.\n provider:\n     type: gcp\n     region: us-central1\n     availability_zone: us-central1-a\n     project_id: ray # Globally unique project id\n \n # How Ray will authenticate with newly launched nodes.\n auth:\n     ssh_user: ubuntu\n # By default Ray creates a new private keypair, but you can also use your own.\n # If you do so, make sure to also set \"KeyName\" in the head and worker node\n # configurations below. This requires that you have added the key into the\n # project wide meta-data.\n #    ssh_private_key: /path/to/your/key.pem\n \n # Provider-specific config for the head node, e.g. instance type. By default\n # Ray will auto-configure unspecified fields such as subnets and ssh-keys.\n # For more documentation on available fields, see:\n # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert\n head_node:\n     machineType: n1-standard-2\n     disks:\n       - boot: true\n         autoDelete: true\n         type: PERSISTENT\n         initializeParams:\n           diskSizeGb: 50\n           # See https://cloud.google.com/compute/docs/images for more images\n           diskType: https://www.googleapis.com/compute/v1/projects/ray/zones/us-central1-a/diskTypes/pd-ssd\n           sourceImage: projects/deeplearning-platform-release/global/images/common-cu101-v20200630\n     # Additional options can be found in in the compute docs at\n     # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert\n \n     # If the network interface is specified as below in both head and worker\n     # nodes, the manual network config is used.  Otherwise an existing subnet is\n     # used.  To use a shared subnet, ask the subnet owner to grant permission\n     # for 'compute.subnetworks.use' to the ray autoscaler account...\n     # networkInterfaces:\n     #   - kind: compute#networkInterface\n     #     subnetwork: path/to/subnet\n     #     aliasIpRanges: []\n \n worker_nodes:\n     machineType: n1-standard-8\n     disks:\n       - boot: true\n         autoDelete: true\n         type: PERSISTENT\n         initializeParams:\n           diskSizeGb: 50\n           # See https://cloud.google.com/compute/docs/images for more images\n           sourceImage: projects/deeplearning-platform-release/global/images/common-cu101-v20200630\n           diskType: https://www.googleapis.com/compute/v1/projects/ray/zones/us-west1-a/diskTypes/pd-ssd\n     guestAccelerators:\n       - acceleratorType: projects/ray/zones/us-central1-a/acceleratorTypes/nvidia-tesla-k80\n         acceleratorCount: 1\n     metadata:\n       items:\n         - key: install-nvidia-driver\n           value: \"True\"\n     # Run workers on preemtible instance by default.\n     # Comment this out to use on-demand.\n     scheduling:\n       # - preemptible: true\n       - onHostMaintenance: TERMINATE\n     serviceAccounts:\n       - email: ray-worker@ray.iam.gserviceaccount.com\n         scopes: [\"https://www.googleapis.com/auth/cloud-platform\"]\n       \n     # Additional options can be found in in the compute docs at\n     # https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert\n \n # Files or directories to copy to the head and worker nodes. The format is a\n # dictionary from REMOTE_PATH: LOCAL_PATH, e.g.\n file_mounts: {\n     \"/root/data/\": \"data/\",\n }\n \n # List of commands that will be run before `setup_commands`. If docker is\n # enabled, these commands will run outside the container and before docker\n # is setup.\n initialization_commands: []\n \n # List of shell commands to run to set up nodes.\n setup_commands:\n   - pip install ray[tune]\n     # Note: if you're developing Ray, you probably want to create an AMI that\n     # has your Ray repo pre-cloned. Then, you can replace the pip installs\n     # below with a git checkout <your_sha> (and possibly a recompile).\n     # - echo 'export PATH=\"$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH\"' >> ~/.bashrc\n \n     # Install Anaconda.\n     # - >-\n     #   wget https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh -O ~/anaconda3.sh\n     #   || true\n     #   && bash ~/anaconda3.sh -b -p ~/anaconda3 || true\n     #   && rm ~/anaconda3.sh\n     #   && echo 'export PATH=\"$HOME/anaconda3/bin:$PATH\"' >> ~/.profile\n \n     # # Install ray\n     # # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp27-cp27mu-manylinux1_x86_64.whl\n     # # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp35-cp35m-manylinux1_x86_64.whl\n     # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n \n \n # Custom commands that will be run on the head node after common setup.\n head_setup_commands:\n   - pip install google-api-python-client==1.7.8\n \n # Custom commands that will be run on worker nodes after common setup.\n worker_setup_commands: []\n \n \n # Command to start ray on the head node. You don't need to change this.\n head_start_ray_commands:\n     - ray stop\n     - >-\n       ulimit -n 65536;\n       ray start\n       --head\n       --port=6379\n       --object-manager-port=8076\n       --autoscaling-config=~/ray_bootstrap_config.yaml\n \n # Command to start ray on worker nodes. You don't need to change this.\n worker_start_ray_commands:\n     - ray stop\n     - >-\n       ulimit -n 65536;\n       ray start\n       --address=$RAY_HEAD_IP:6379\n       --object-manager-port=8076\n </denchmark-code>\n \n results in the following error mkdir: cannot create directory \u2018/root\u2019: Permission denied\n full error output here\n <denchmark-code>2020-07-07 04:44:43,207 INFO updater.py:264 -- NodeUpdater: ray-default-head-7347dd6f: Running ssh -tt -i /home/nintorac/.ssh/ray-autoscaler_gcp_us-central1_ray-runner_ubuntu_0.pem -o ConnectTimeout=120s -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_9151b9c88a/c21f969b5f/%C -o ControlPersist=10s -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 ubuntu@34.66.223.160 bash --login -c -i 'true && source ~/.bashrc && export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore && mkdir -p /root/bistableGRU'\n mkdir: cannot create directory \u2018/root\u2019: Permission denied\n Shared connection to 34.66.223.160 closed.\n 2020-07-07 04:44:43,891 INFO log_timer.py:22 -- NodeUpdater: ray-default-head-7347dd6f: Synced bistableGRU/ to /root/bistableGRU/  [LogTimer=683ms]\n 2020-07-07 04:44:43,891 INFO log_timer.py:22 -- NodeUpdater: ray-default-head-7347dd6f: Applied config 9766e837de18583f489ebd562c12bb3d6ead4b5e  [LogTimer=13577ms]\n 2020-07-07 04:44:44,497 INFO node_provider.py:21 -- wait_for_compute_zone_operation: Waiting for operation operation-1594097084024-5a9d2a66e4854-99e9b008-3f76ae9f to finish...\n 2020-07-07 04:44:49,705 INFO node_provider.py:32 -- wait_for_compute_zone_operation: Operation operation-1594097084024-5a9d2a66e4854-99e9b008-3f76ae9f finished.\n 2020-07-07 04:44:49,706 ERROR updater.py:441 -- NodeUpdater: ray-default-head-7347dd6f: Error executing: SSH command Failed. See above for the output from the failure.2020-07-07 04:44:49,817 ERROR commands.py:367 -- get_or_create_head_node: Updating 34.66.223.160 failed\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Nintorac", "commentT": "2020-07-10T23:25:01Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ijrsvt>@ijrsvt</denchmark-link>\n  Is it supposed to be closed?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Nintorac", "commentT": "2020-07-11T01:08:50Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n   The PR yes, this issue, no.\n The best workaround for trying to do\n <denchmark-code>file_mounts:\n    \"/root/item\" : \"/whatever/item\"\n </denchmark-code>\n \n is to do\n <denchmark-code>file_mounts:\n    \"/home/item\" : \"/local_whatever/item\"\n \n docker:\n    run_options:\n        \"-v /home/item:/root/item\"\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Nintorac", "commentT": "2020-08-31T12:53:38Z", "comment_text": "\n \t\tOne way to allow this to happen would be to have initialization_commands run before file mounts. If that is not feasible for some reason, maybe you could introduce preinitialization_commands.\n Inside these commands, the ray user could run whatever they want, such as sudo mkdir /whatever/directory, since presumably they would know whether or not the user running the ray commands has sudo access.\n \t\t"}}}, "commit": {"commit_id": "283f4d1060060d3a10a62ac5d74c9ca45c596791", "commit_author": "Ian Rodney", "commitT": "2020-09-01 13:14:35-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 9, "file_old_name": "python\\ray\\autoscaler\\command_runner.py", "file_new_name": "python\\ray\\autoscaler\\command_runner.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "241", "deleted_lines": null, "method_info": {"method_name": "run_rsync_up", "method_params": "self,source,target,options", "method_startline": "241", "method_endline": "256"}}, "hunk_1": {"Ismethod": 1, "added_lines": "267", "deleted_lines": null, "method_info": {"method_name": "run_rsync_down", "method_params": "self,source,target,options", "method_startline": "267", "method_endline": "282"}}, "hunk_2": {"Ismethod": 1, "added_lines": "138,139,140,141", "deleted_lines": null, "method_info": {"method_name": "run_rsync_up", "method_params": "self,str,str,str,None", "method_startline": "138", "method_endline": "141"}}, "hunk_3": {"Ismethod": 1, "added_lines": "150,151,152,153", "deleted_lines": null, "method_info": {"method_name": "run_rsync_down", "method_params": "self,str,str,str,None", "method_startline": "150", "method_endline": "153"}}, "hunk_4": {"Ismethod": 1, "added_lines": "241", "deleted_lines": "234", "method_info": {"method_name": "run_rsync_up", "method_params": "self,source,target", "method_startline": "234", "method_endline": "249"}}, "hunk_5": {"Ismethod": 1, "added_lines": "150,151,152,153", "deleted_lines": "146", "method_info": {"method_name": "run_rsync_down", "method_params": "self,str,str", "method_startline": "146", "method_endline": "153"}}, "hunk_6": {"Ismethod": 1, "added_lines": "138,139,140,141", "deleted_lines": "137", "method_info": {"method_name": "run_rsync_up", "method_params": "self,str,str", "method_startline": "137", "method_endline": "144"}}, "hunk_7": {"Ismethod": 1, "added_lines": "267", "deleted_lines": "260", "method_info": {"method_name": "run_rsync_down", "method_params": "self,source,target", "method_startline": "260", "method_endline": "275"}}, "hunk_8": {"Ismethod": 1, "added_lines": "736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754", "deleted_lines": "725,726,727,728,729", "method_info": {"method_name": "run_init", "method_params": "self,as_head,file_mounts", "method_startline": "706", "method_endline": "755"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\ray\\autoscaler\\commands.py", "file_new_name": "python\\ray\\autoscaler\\commands.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "667,670,673,687", "deleted_lines": "667,670,673,687"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "python\\ray\\autoscaler\\docker.py", "file_new_name": "python\\ray\\autoscaler\\docker.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "83,84,85,86,87,88,89,90,91,92,93,94", "method_info": {"method_name": "docker_autoscaler_setup", "method_params": "cname", "method_startline": "83", "method_endline": "94"}}, "hunk_1": {"Ismethod": 1, "added_lines": "66", "deleted_lines": null, "method_info": {"method_name": "check_docker_image", "method_params": "cname", "method_startline": "65", "method_endline": "66"}}, "hunk_2": {"Ismethod": 1, "added_lines": "61,62", "deleted_lines": "62", "method_info": {"method_name": "check_bind_mounts_cmd", "method_params": "cname", "method_startline": "61", "method_endline": "62"}}, "hunk_3": {"Ismethod": 1, "added_lines": "57,58", "deleted_lines": "57,58", "method_info": {"method_name": "check_docker_running_cmd", "method_params": "cname", "method_startline": "57", "method_endline": "58"}}, "hunk_4": {"Ismethod": 1, "added_lines": "70", "deleted_lines": "81,82,83,84,85,86,87,88", "method_info": {"method_name": "docker_start_cmds", "method_params": "user,image,mount_dict,cname,user_options", "method_startline": "69", "method_endline": "88"}}, "hunk_5": {"Ismethod": 1, "added_lines": "50,52,53", "deleted_lines": "51", "method_info": {"method_name": "_check_helper", "method_params": "cname,template", "method_startline": "50", "method_endline": "54"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "python\\ray\\autoscaler\\updater.py", "file_new_name": "python\\ray\\autoscaler\\updater.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "418,422", "deleted_lines": "416,420", "method_info": {"method_name": "rsync_up", "method_params": "self,source,target", "method_startline": "416", "method_endline": "422"}}, "hunk_1": {"Ismethod": 1, "added_lines": "418,422,423,424", "deleted_lines": "420,424", "method_info": {"method_name": "rsync_up", "method_params": "self,source,target,file_mount", "method_startline": "418", "method_endline": "426"}}, "hunk_2": {"Ismethod": 1, "added_lines": "184,185,186,187,188,189", "deleted_lines": "184,185,186,187", "method_info": {"method_name": "sync_file_mounts.do_sync", "method_params": "remote_path,local_path,allow_non_existing_paths", "method_startline": "167", "method_endline": "194"}}, "hunk_3": {"Ismethod": 1, "added_lines": "184,185,186,187,188,189", "deleted_lines": "184,185,186,187", "method_info": {"method_name": "sync_file_mounts", "method_params": "self,sync_cmd,step_numbers,2", "method_startline": "157", "method_endline": "212"}}, "hunk_4": {"Ismethod": 1, "added_lines": "428,432,433,434", "deleted_lines": "428", "method_info": {"method_name": "rsync_down", "method_params": "self,source,target,file_mount", "method_startline": "428", "method_endline": "436"}}, "hunk_5": {"Ismethod": 1, "added_lines": "424,428", "deleted_lines": "424,428", "method_info": {"method_name": "rsync_down", "method_params": "self,source,target", "method_startline": "424", "method_endline": "430"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "python\\ray\\tests\\test_autoscaler.py", "file_new_name": "python\\ray\\tests\\test_autoscaler.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "46", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,fail_cmds", "method_startline": "43", "method_endline": "46"}}, "hunk_1": {"Ismethod": 1, "added_lines": "1163,1165,1166,1182,1184,1185,1186", "deleted_lines": "1147,1149,1150,1151,1167,1169,1170,1171", "method_info": {"method_name": "testContinuousFileMounts", "method_params": "self", "method_startline": "1135", "method_endline": "1186"}}, "hunk_2": {"Ismethod": 1, "added_lines": "1215,1217,1218,1219,1233,1235,1236,1258,1260,1261,1262", "deleted_lines": "1200,1202,1203,1204,1218,1220,1221,1222,1244,1246,1247,1248", "method_info": {"method_name": "testFileMountsNonContinuous", "method_params": "self", "method_startline": "1188", "method_endline": "1262"}}, "hunk_3": {"Ismethod": 1, "added_lines": "111,112", "deleted_lines": null, "method_info": {"method_name": "respond_to_call", "method_params": "self,pattern,response,num_times", "method_startline": "111", "method_endline": "112"}}, "hunk_4": {"Ismethod": 1, "added_lines": "56,57,58,59,60,61,62,63,64,65,66,67", "deleted_lines": "54", "method_info": {"method_name": "check_output", "method_params": "self,cmd", "method_startline": "54", "method_endline": "67"}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\tests\\test_command_runner.py", "file_new_name": "python\\ray\\tests\\test_command_runner.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224", "deleted_lines": null, "method_info": {"method_name": "test_docker_rsync", "method_params": "", "method_startline": "145", "method_endline": "224"}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\ray\\core_worker\\lib\\java\\jni_utils.h", "file_new_name": "src\\ray\\core_worker\\lib\\java\\jni_utils.h", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "260,261", "deleted_lines": "260", "method_info": {"method_name": "JavaByteArrayToId", "method_params": "env,bytes", "method_startline": "255", "method_endline": "263"}}}}}}}