{"BR": {"BR_id": "8368", "BR_author": "duburcqa", "BRopenT": "2020-05-08T13:04:03Z", "BRcloseT": "2020-05-23T17:54:19Z", "BR_text": {"BRsummary": "\"lr_schedule\" option ignored using torch framework and PPO algorithm", "BRdescription": "\n Ray version and other system information (Python version, TensorFlow version, OS):\n \n Ray: 0.9.0.dev0 (2c599dbf05e41e338920ee2fbe692658bcbec4dd)\n CUDA: 10.1\n Pytorch: 1.4.0 with GPU support\n Ubuntu 18.04\n Python 3.6\n \n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n Setting the hyperparameter \"lr_schedule\" as no effect when using PyTorch as backend framework and PPO learning algorithm.\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n <denchmark-code>import ray \n from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG \n  \n config = DEFAULT_CONFIG.copy() \n for key, val in { \n     \"env\": \"CartPole-v0\", \n     \"num_workers\": 0, \n     \"use_pytorch\": False, \n     \"lr\": 1.0e-5, \n     \"lr_schedule\": [ \n         [0, 1.0e-6], \n         [1, 1.0e-7], \n     ] \n }.items(): config[key] = val \n  \n ray.init() \n \n for use_pytorch in [False, True]: \n     config[\"use_pytorch\"] = use_pytorch \n     agent = PPOTrainer(config, \"CartPole-v0\") \n     for _ in range(2): \n         result = agent.train() \n         print(f\"use_pytorch: {use_pytorch} - Current learning rate: \"\\\n               f\"{result['info']['learner']['default_policy']['cur_lr']}\")\n </denchmark-code>\n \n \n  I have verified my script runs in a clean environment and reproduces the issue.\n  I have verified the issue also occurs with the latest wheels.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "duburcqa", "commentT": "2020-05-08T15:19:55Z", "comment_text": "\n \t\tThanks for filing this issue <denchmark-link:https://github.com/duburcqa>@duburcqa</denchmark-link>\n  . Will take a look ...\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "duburcqa", "commentT": "2020-05-21T18:09:03Z", "comment_text": "\n \t\tcc <denchmark-link:https://github.com/krfricke>@krfricke</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "duburcqa", "commentT": "2020-05-23T09:06:28Z", "comment_text": "\n \t\tI can confirm this - would appreciate an update on it\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "duburcqa", "commentT": "2020-05-23T10:12:06Z", "comment_text": "\n \t\tLooks like the lr and entropy coeff schedule mixin was not added in the Torch PPO policy. This simple PR fixes it:\n <denchmark-code>use_pytorch: False - Current learning rate: 9.999999747378752e-06\n use_pytorch: False - Current learning rate: 1.0000000116860974e-07\n use_pytorch: True - Current learning rate: 1e-05\n use_pytorch: True - Current learning rate: 1e-07\n </denchmark-code>\n \n Interesting though that the learning rates seem to differ slightly between torch and tf\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "duburcqa", "commentT": "2020-05-23T10:59:15Z", "comment_text": "\n \t\tNice, thank you ! The learning rate using tensorflow comes from a conversion from float32 to float64 that must be done somewhere. If you want to check:\n <denchmark-code>import numpy as np\n print(np.float64(np.float32(1.0e-5)))\n print(np.float64(np.float32(1.0e-7)))\n </denchmark-code>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "duburcqa", "commentT": "2020-05-23T12:49:35Z", "comment_text": "\n \t\tHmmm I made some more experiments and I am not convinced that the lr is actually properly updated... Is it possible that the learning rate in cur_lr is different from the actual learning rate?\n \t\t"}}}, "commit": {"commit_id": "d6f78f58dc7548217b46565a3dd42cd2e0133e66", "commit_author": "Jan Blumenkamp", "commitT": "2020-05-23 10:54:18-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\agents\\ppo\\ppo_torch_policy.py", "file_new_name": "rllib\\agents\\ppo\\ppo_torch_policy.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "226,227,228,229", "deleted_lines": "226"}}}}}}