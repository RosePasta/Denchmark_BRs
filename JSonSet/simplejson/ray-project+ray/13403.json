{"BR": {"BR_id": "13403", "BR_author": "krfricke", "BRopenT": "2021-01-13T14:24:56Z", "BRcloseT": "2021-01-16T11:49:25Z", "BR_text": {"BRsummary": "[core] placement groups do not become `ready()` when too many PGs are requested at the same time", "BRdescription": "\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n MacOS, latest master. Also errors with the latest wheels.\n Does not error with latest release (1.1.0)\n When I start more placement groups than fit on my cluster, pg.ready() futures only become ready for the number of placement groups that immediately fit on the cluster. If I then remove these placement groups, subsequent placement groups do not become ready anymore (but their status is updated to CREATED).\n This only happens when more placement groups are requested than fit on the cluster. E.g. if 2 placement groups fit on the cluster and 4 are requested, it works. If 6 are requested, it doesn't work.\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n This script runs forever:\n <denchmark-code>import ray\n from ray.util.placement_group import placement_group, remove_placement_group, \\\n     placement_group_table\n \n ray.init(num_cpus=4)\n \n pgs = [\n     placement_group([{\"CPU\": 2}])\n     for _ in range(6)  # Works for `range(4)`\n ]\n \n ready_futs = {pg.ready(): pg for pg in pgs}\n \n notready_count = 0\n while ready_futs:\n     tbl = placement_group_table()\n     print(\"PGs:\", [tbl[pg][\"state\"] for pg in sorted(tbl)])\n \n     ready, _ = ray.wait(list(ready_futs.keys()), timeout=0.5)\n     if ready:\n         ready_pg = ready_futs[ready[0]]\n \n         print(f\"Placement group {ready_pg} became ready. Removing.\")\n         remove_placement_group(ready_pg)\n         del ready_futs[ready[0]]\n     else:\n         notready_count += 1\n         print(\"No placement group ready, yet.\")\n \n         # This block can be removed, it still doesn't work -\n         # i.e. even with new futures they never become ready.\n         if notready_count == 4:\n             print(\"Re-scheduling futures\")\n             ready_futs = {pg.ready(): pg for pg in pgs}\n </denchmark-code>\n \n Output with range(4) (works):\n <denchmark-code>2021-01-13 15:25:56,793\tINFO services.py:1171 -- View the Ray dashboard at http://127.0.0.1:8265\n PGs: ['CREATED', 'PENDING', 'CREATED', 'PENDING']\n Placement group <ray.util.placement_group.PlacementGroup object at 0x11a3d7310> became ready. Removing.\n PGs: ['REMOVED', 'PENDING', 'CREATED', 'PENDING']\n Placement group <ray.util.placement_group.PlacementGroup object at 0x11fa14fd0> became ready. Removing.\n PGs: ['REMOVED', 'PENDING', 'REMOVED', 'PENDING']\n Placement group <ray.util.placement_group.PlacementGroup object at 0x11fa11850> became ready. Removing.\n PGs: ['REMOVED', 'REMOVED', 'REMOVED', 'CREATED']\n Placement group <ray.util.placement_group.PlacementGroup object at 0x11fa14f90> became ready. Removing.\n \n Process finished with exit code 0\n </denchmark-code>\n \n Output with range(6) (runs forever):\n <denchmark-code>2021-01-13 15:26:48,612\tINFO services.py:1171 -- View the Ray dashboard at http://127.0.0.1:8265\n PGs: ['PENDING', 'CREATED', 'PENDING', 'PENDING', 'CREATED', 'PENDING']\n Placement group <ray.util.placement_group.PlacementGroup object at 0x120d08fd0> became ready. Removing.\n PGs: ['PENDING', 'REMOVED', 'PENDING', 'PENDING', 'CREATED', 'PENDING']\n Placement group <ray.util.placement_group.PlacementGroup object at 0x120d08f90> became ready. Removing.\n PGs: ['PENDING', 'REMOVED', 'PENDING', 'PENDING', 'REMOVED', 'PENDING']\n No placement group ready, yet.\n PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']\n No placement group ready, yet.\n PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']\n No placement group ready, yet.\n PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']\n No placement group ready, yet.\n Re-scheduling futures\n PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']\n No placement group ready, yet.\n PGs: ['CREATED', 'REMOVED', 'CREATED', 'PENDING', 'REMOVED', 'PENDING']\n \n (... continues to run with the last two lines forever)\n </denchmark-code>\n \n \n  I have verified my script runs in a clean environment and reproduces the issue.\n  I have verified the issue also occurs with the latest wheels.\n \n cc <denchmark-link:https://github.com/ericl>@ericl</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "krfricke", "commentT": "2021-01-13T17:24:15Z", "comment_text": "\n \t\tcc <denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n  FYI this is blocking Ray Tune usage of placement groups\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "krfricke", "commentT": "2021-01-14T08:39:54Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/krfricke>@krfricke</denchmark-link>\n  <denchmark-link:https://github.com/richard4912>@richard4912</denchmark-link>\n  <denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n  I have find the raylet scheduling bug, and submit a PR( <denchmark-link:https://github.com/ray-project/ray/pull/13452>#13452</denchmark-link>\n  ) to fix it, thx. cc <denchmark-link:https://github.com/clay4444>@clay4444</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "krfricke", "commentT": "2021-01-16T02:26:59Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/krfricke>@krfricke</denchmark-link>\n  Can you verify the fix and close the issue?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "krfricke", "commentT": "2021-01-16T11:49:25Z", "comment_text": "\n \t\tEverything's working now. Thanks for the quick turnaround!\n \t\t"}}}, "commit": {"commit_id": "4a6c53da46c82d56bfda8bea31cf447928285560", "commit_author": "fangfengbin", "commitT": "2021-01-14 14:50:32+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\tests\\test_placement_group.py", "file_new_name": "python\\ray\\tests\\test_placement_group.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1299,1300,1301,1302,1303,1304,1305,1306,1307,1308", "deleted_lines": null, "method_info": {"method_name": "test_schedule_placement_groups_at_the_same_time.is_all_placement_group_removed", "method_params": "", "method_startline": "1299", "method_endline": "1308"}}, "hunk_1": {"Ismethod": 1, "added_lines": "1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310", "deleted_lines": null, "method_info": {"method_name": "test_schedule_placement_groups_at_the_same_time", "method_params": "", "method_startline": "1292", "method_endline": "1310"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\ray\\raylet\\scheduling\\cluster_resource_scheduler.cc", "file_new_name": "src\\ray\\raylet\\scheduling\\cluster_resource_scheduler.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "177,178,179,180", "deleted_lines": null, "method_info": {"method_name": "ray::ClusterResourceScheduler::GetBestSchedulableNode", "method_params": "task_req,actor_creation,total_violations,is_infeasible", "method_startline": "173", "method_endline": "265"}}}}}}}