{"BR": {"BR_id": "1784", "BR_author": "sjfleming", "BRopenT": "2019-03-18T18:24:48Z", "BRcloseT": "2019-03-21T15:55:42Z", "BR_text": {"BRsummary": "[bug] JIT plus .mask() errors when batch_size changes", "BRdescription": "\n <denchmark-h:h3>Issue Description</denchmark-h>\n \n When using JIT, there is typically no problem passing in a minibatch with smaller batch size (as would happen for the last minibatch in a dataloader).  However, when there is a masked distribution in the guide, an error appears which complains that tensor sizes do not match.\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n OS: reproduced on Mac 10.13.6 and Ubuntu 16.04\n Python version: 3.6.5\n PyTorch version: 1.0.0\n Pyro version: 0.3.0\n \n <denchmark-h:h3>Code Snippet</denchmark-h>\n \n The error can be replicated using this code snippet.  (The model and data have no real meaning... I was just going for a minimal snippet to reproduce the error.)\n With USE_JIT=False, the code runs without error.\n With USE_JIT=True, the code produces an error.\n With USE_JIT=True, if you manually comment out the .mask() statement in the guide, the code runs without error.\n import pyro\n import pyro.distributions as dist\n from pyro.infer import SVI, Trace_ELBO, JitTrace_ELBO\n from pyro.optim import Adam\n import torch\n \n USE_JIT = True\n \n def model(x):\n     with pyro.plate(\"data\", size=x.shape[0]):\n         z = pyro.sample(\"z\", dist.Normal(0., 5.).expand(x.shape).to_event(1))\n         x = pyro.sample(\"obs\", dist.Normal(z, 1.).to_event(1), obs=x)\n \n def guide(x):\n     offset = pyro.param(\"offset\", torch.Tensor([0.]))\n     with pyro.plate(\"data\", size=x.shape[0]):\n         masking = dist.Bernoulli(logits=x.sum(dim=-1, keepdim=False)).sample()\n         z = pyro.sample(\"z\", dist.Normal(offset, 0.1).expand(x.shape).to_event(1).mask(masking))\n \n pyro.clear_param_store()\n pyro.enable_validation(True)\n \n loss = JitTrace_ELBO() if USE_JIT else Trace_ELBO()\n svi = SVI(model, guide, optim=Adam({'lr': 1e-2}), loss=loss)\n \n offset_param = 5.\n \n for i in range(5):\n     normalizer = 0.\n     epoch_loss = 0.\n     for _ in range(200):\n         # generate a fake minibatch of data\n         x = torch.randn((10, 200)) \n         x = x + 2 * offset_param * (x.sum(dim=-1, keepdim=True) > 0).float()\n         # train\n         epoch_loss += svi.step(x)\n         normalizer += x.shape[0]\n \n     print(f'epoch {i} loss = {epoch_loss/normalizer}')\n     \n print(f'\\noffset = {pyro.param(\"offset\").detach()}')\n \n # now pass in a minibatch of data with smaller size\n x = torch.randn((5, 200))\n svi.step(x)  # induces error\n The error message is the following:\n <denchmark-code>RuntimeError: \n The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 0 (infer_size at /Users/administrator/nightlies/pytorch-1.0.0/wheel_build_dirs/wheel_3.6/pytorch/aten/src/ATen/ExpandUtils.cpp:22)\n frame #0: c10::Error::Error(c10::SourceLocation, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) + 135 (0x116583f47 in libc10.dylib)\n frame #1: at::infer_size(c10::ArrayRef<long long>, c10::ArrayRef<long long>) + 523 (0x11b66a43b in libcaffe2.dylib)\n frame #2: at::TensorIterator::compute_shape() + 466 (0x11b8a52a2 in libcaffe2.dylib)\n frame #3: at::TensorIterator::Builder::build() + 39 (0x11b8a4697 in libcaffe2.dylib)\n frame #4: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&) + 454 (0x11b8a4216 in libcaffe2.dylib)\n frame #5: at::native::sub_out(at::Tensor&, at::Tensor const&, at::Tensor const&, c10::Scalar) + 745 (0x11b732d19 in libcaffe2.dylib)\n frame #6: at::native::sub_(at::Tensor&, at::Tensor const&, c10::Scalar) + 48 (0x11b7335b0 in libcaffe2.dylib)\n frame #7: at::TypeDefault::sub_(at::Tensor&, at::Tensor const&, c10::Scalar) const + 247 (0x11bb356f7 in libcaffe2.dylib)\n frame #8: torch::autograd::VariableType::sub_(at::Tensor&, at::Tensor const&, c10::Scalar) const + 1101 (0x1246a5add in libtorch.1.dylib)\n frame #9: std::__1::__function::__func<torch::jit::(anonymous namespace)::$_494, std::__1::allocator<torch::jit::(anonymous namespace)::$_494>, int (std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue> >&)>::operator()(std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue> >&) + 163 (0x124bb5293 in libtorch.1.dylib)\n frame #10: torch::jit::InterpreterStateImpl::runImpl(std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue> >&) + 245 (0x124c2a2e5 in libtorch.1.dylib)\n frame #11: torch::jit::InterpreterStateImpl::run(std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue> >&) + 28 (0x124c229dc in libtorch.1.dylib)\n frame #12: torch::jit::GraphExecutorImpl::run(std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue> >&) + 4389 (0x124bf1ad5 in libtorch.1.dylib)\n frame #13: torch::jit::script::Method::run(std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue> >&) + 216 (0x116156d48 in libtorch_python.dylib)\n frame #14: torch::jit::invokeScriptMethodFromPython(torch::jit::script::Method&, torch::jit::tuple_slice, pybind11::kwargs) + 163 (0x116156bb3 in libtorch_python.dylib)\n frame #15: void pybind11::cpp_function::initialize<torch::jit::script::initJitScriptBindings(_object*)::$_21, pybind11::object, pybind11::args, pybind11::kwargs, pybind11::name, pybind11::is_method, pybind11::sibling>(torch::jit::script::initJitScriptBindings(_object*)::$_21&&, pybind11::object (*)(pybind11::args, pybind11::kwargs), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 269 (0x1161580cd in libtorch_python.dylib)\n frame #16: pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 3348 (0x115dadb34 in libtorch_python.dylib)\n <omitting python frames>\n :\n operation failed in interpreter:\n /anaconda3/lib/python3.6/site-packages/pyro/distributions/util.py(189): scale_and_mask\n /anaconda3/lib/python3.6/site-packages/pyro/distributions/score_parts.py(23): scale_and_mask\n /anaconda3/lib/python3.6/site-packages/pyro/distributions/torch_distribution.py(278): score_parts\n /anaconda3/lib/python3.6/site-packages/pyro/poutine/trace_struct.py(192): compute_score_parts\n /anaconda3/lib/python3.6/site-packages/pyro/infer/enum.py(52): get_importance_trace\n /anaconda3/lib/python3.6/site-packages/pyro/infer/trace_elbo.py(52): _get_trace\n /anaconda3/lib/python3.6/site-packages/pyro/infer/elbo.py(163): _get_traces\n /anaconda3/lib/python3.6/site-packages/pyro/infer/trace_elbo.py(170): loss_and_surrogate_loss\n /anaconda3/lib/python3.6/site-packages/pyro/poutine/messenger.py(27): _wraps\n /anaconda3/lib/python3.6/site-packages/pyro/ops/jit.py(84): compiled\n /anaconda3/lib/python3.6/site-packages/torch/jit/__init__.py(635): trace\n /anaconda3/lib/python3.6/site-packages/pyro/ops/jit.py(87): __call__\n /anaconda3/lib/python3.6/site-packages/pyro/infer/trace_elbo.py(203): loss_and_surrogate_loss\n /anaconda3/lib/python3.6/site-packages/pyro/infer/trace_elbo.py(212): loss_and_grads\n /anaconda3/lib/python3.6/site-packages/pyro/infer/svi.py(99): step\n <ipython-input-7-a390225aa054>(36): <module>\n /anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3267): run_code\n /anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3185): run_ast_nodes\n /anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3020): run_cell_async\n /anaconda3/lib/python3.6/site-packages/IPython/core/async_helpers.py(67): _pseudo_sync_runner\n /anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2845): _run_cell\n /anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2819): run_cell\n /anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py(537): run_cell\n /anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py(208): do_execute\n /anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py(399): execute_request\n /anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py(233): dispatch_shell\n /anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py(283): dispatcher\n /anaconda3/lib/python3.6/site-packages/tornado/stack_context.py(276): null_wrapper\n /anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py(432): _run_callback\n /anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py(480): _handle_recv\n /anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py(450): _handle_events\n /anaconda3/lib/python3.6/site-packages/tornado/stack_context.py(276): null_wrapper\n /anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py(117): _handle_events\n /anaconda3/lib/python3.6/asyncio/events.py(145): _run\n /anaconda3/lib/python3.6/asyncio/base_events.py(1432): _run_once\n /anaconda3/lib/python3.6/asyncio/base_events.py(422): run_forever\n /anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py(127): start\n /anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py(486): start\n /anaconda3/lib/python3.6/site-packages/traitlets/config/application.py(658): launch_instance\n /anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py(16): <module>\n /anaconda3/lib/python3.6/runpy.py(85): _run_code\n /anaconda3/lib/python3.6/runpy.py(193): _run_module_as_main\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "sjfleming", "commentT": "2019-03-18T21:19:59Z", "comment_text": "\n \t\tThanks for the clear bug report <denchmark-link:https://github.com/sjfleming>@sjfleming</denchmark-link>\n  !\n This appears to be a bug in <denchmark-link:https://github.com/pyro-ppl/pyro/blob/1ca4bfa/pyro/distributions/util.py#L171>scale_and_mask()</denchmark-link>\n . I am confused, since I thought we fixed this, and we even have a <denchmark-link:https://github.com/pyro-ppl/pyro/blob/7a25559/tests/infer/test_jit.py#L130>test_masked_fill()</denchmark-link>\n  that exercises resizing. <denchmark-link:https://github.com/neerajprad>@neerajprad</denchmark-link>\n  any ideas?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "sjfleming", "commentT": "2019-03-19T01:49:44Z", "comment_text": "\n \t\tThanks for the bug report. We'll add this as a test to test_jit.py, and debug further.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "sjfleming", "commentT": "2019-03-20T19:00:14Z", "comment_text": "\n \t\tI have filed an issue for this in PyTorch - the problem is with the ~ operator which doesn't seem to generalize to different tensor shapes under JIT, and we use ~mask in the scale_and_mask function. I suppose we could work around by passing the inverted mask directly, but I don't think there is a backward compatible workaround that we could put in Pyro's dev branch.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "sjfleming", "commentT": "2019-03-20T19:14:46Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/neerajprad>@neerajprad</denchmark-link>\n  would  or  serve as a workaround for ? Nice sleuthing!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "sjfleming", "commentT": "2019-03-20T19:57:56Z", "comment_text": "\n \t\t(mask == 0) works great! I can add that with a test.\n \t\t"}}}, "commit": {"commit_id": "9bda9b782558bd1ec0e7047c6f9cfe9f2c0f3791", "commit_author": "Neeraj Pradhan", "commitT": "2019-03-21 08:55:23-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pyro\\distributions\\util.py", "file_new_name": "pyro\\distributions\\util.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "189", "deleted_lines": "189", "method_info": {"method_name": "scale_and_mask", "method_params": "tensor,scale,mask", "method_startline": "171", "method_endline": "190"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pyro\\ops\\packed.py", "file_new_name": "pyro\\ops\\packed.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "139", "deleted_lines": "139", "method_info": {"method_name": "scale_and_mask", "method_params": "tensor,scale,mask", "method_startline": "119", "method_endline": "141"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\infer\\test_jit.py", "file_new_name": "tests\\infer\\test_jit.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "132,133,134,135,136,137,138,139,140,141,142,143,144", "deleted_lines": null, "method_info": {"method_name": "test_scale_and_mask.f", "method_params": "tensor,scale,mask", "method_startline": "132", "method_endline": "144"}}}}}}}