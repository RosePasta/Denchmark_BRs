{"BR": {"BR_id": "175", "BR_author": "eric-haibin-lin", "BRopenT": "2019-12-11T22:23:05Z", "BRcloseT": "2019-12-13T10:08:40Z", "BR_text": {"BRsummary": "mxnet distributed trainer broadcast leads to corrupted model", "BRdescription": "\n Describe the bug\n With byteps and mxnet, running model forward and bps.broadcast leads to a corrupted model checkpoint.\n To Reproduce\n Steps to reproduce the behavior:\n \n nvidia-docker run -it --shm-size=32768m haibinlin/worker_mxnet:broadcast-debug bash\n cd bps\n bash bps.sh\n After it's done, run python3 diff.py\n \n <denchmark-code>root@33909ea812c2:~/bps# bash bps.sh\n 0,1,2,3,4,5,6,7\n BytePS launching worker\n INFO:root:Loading step 7038 checkpoints from ./0007038.params.\n INFO:root:Saving model params to out/1.b.params.\n INFO:root:Loading step 7038 checkpoints from ./0007038.params.\n INFO:root:Saving model params to out/2.b.params.\n INFO:root:Loading step 7038 checkpoints from ./0007038.params.\n INFO:root:Loading step 7038 checkpoints from ./0007038.params.\n INFO:root:Saving model params to out/0.b.params.\n INFO:root:Saving model params to out/3.b.params.\n INFO:root:Loading step 7038 checkpoints from ./0007038.params.\n INFO:root:Saving model params to out/7.b.params.\n INFO:root:Loading step 7038 checkpoints from ./0007038.params.\n INFO:root:Saving model params to out/5.b.params.\n INFO:root:Loading step 7038 checkpoints from ./0007038.params.\n INFO:root:Saving model params to out/6.b.params.\n INFO:root:Loading step 7038 checkpoints from ./0007038.params.\n INFO:root:Saving model params to out/4.b.params.\n INFO:root:Saving model params to out/3.params.\n INFO:root:Saving model params to out/4.params.\n INFO:root:Saving model params to out/2.params.\n INFO:root:Saving model params to out/7.params.\n INFO:root:Saving model params to out/6.params.\n INFO:root:Saving model params to out/0.params.\n INFO:root:Saving model params to out/1.params.\n INFO:root:Saving model params to out/5.params.\n INFO:root:DONE\n INFO:root:DONE\n INFO:root:DONE\n INFO:root:DONE\n INFO:root:DONE\n INFO:root:DONE\n INFO:root:DONE\n INFO:root:DONE\n \n KeyboardInterrupt\n </denchmark-code>\n \n diff.py compares the checkpoint after bps.broadcast across ranks. It finds that non-root rank has different values for the below layers:\n <denchmark-code>root@33909ea812c2:~/bps# python3 diff.py\n rank: 1, key: encoder.transformer_cells.23.attention_cell.proj_key.weight, diff norm: 39.02976608276367, nb: 36.71388244628906, nf: 36.59696578979492\n rank: 1, key: encoder.transformer_cells.14.attention_cell.proj_key.bias, diff norm: 6.859381755930372e-06, nb: 3.8649077970139e-13, nf: 6.859382665425073e-06\n rank: 1, key: encoder.transformer_cells.8.attention_cell.proj_query.bias, diff norm: 1.123531205848849e-06, nb: 1.123531205848849e-06, nf: 1.481958341307578e-14\n rank: 1, key: encoder.transformer_cells.19.attention_cell.proj_query.weight, diff norm: 39.61576461791992, nb: 35.85917282104492, nf: 35.545345306396484\n rank: 1, key: encoder.transformer_cells.21.attention_cell.proj_query.weight, diff norm: 37.944026947021484, nb: 35.591148376464844, nf: 35.3133430480957\n rank: 1, key: encoder.transformer_cells.13.attention_cell.proj_query.bias, diff norm: 4.619259925675578e-06, nb: 4.619259925675578e-06, nf: 5.754620955103484e-13\n rank: 1, key: encoder.transformer_cells.12.attention_cell.proj_query.weight, diff norm: 40.113712310791016, nb: 35.786197662353516, nf: 35.00009536743164\n rank: 1, key: encoder.transformer_cells.8.attention_cell.proj_key.bias, diff norm: 1.123531205848849e-06, nb: 1.481958341307578e-14, nf: 1.123531205848849e-06\n rank: 1, key: encoder.transformer_cells.16.attention_cell.proj_query.bias, diff norm: 8.280058864329476e-06, nb: 8.280059773824178e-06, nf: 1.8791344348623173e-12\n rank: 1, key: encoder.transformer_cells.15.attention_cell.proj_key.weight, diff norm: 41.19209671020508, nb: 35.788639068603516, nf: 36.156333923339844\n rank: 1, key: encoder.transformer_cells.4.attention_cell.proj_query.weight, diff norm: 36.333168029785156, nb: 32.318485260009766, nf: 32.2811393737793\n rank: 1, key: encoder.transformer_cells.14.attention_cell.proj_query.weight, diff norm: 40.3658447265625, nb: 35.735233306884766, nf: 35.127044677734375\n rank: 1, key: encoder.transformer_cells.10.attention_cell.proj_query.weight, diff norm: 37.8535270690918, nb: 32.95439529418945, nf: 33.227943420410156\n rank: 1, key: encoder.transformer_cells.1.attention_cell.proj_key.weight, diff norm: 37.501007080078125, nb: 32.635005950927734, nf: 32.58321762084961\n rank: 1, key: encoder.transformer_cells.6.attention_cell.proj_key.bias, diff norm: 1.1221915201531374e-06, nb: 7.162688478901287e-15, nf: 1.1221915201531374e-06\n rank: 1, key: encoder.transformer_cells.17.attention_cell.proj_query.weight, diff norm: 40.339942932128906, nb: 35.35428237915039, nf: 35.33856201171875\n rank: 1, key: encoder.transformer_cells.22.attention_cell.proj_query.weight, diff norm: 37.40335464477539, nb: 36.057472229003906, nf: 36.14318084716797\n rank: 1, key: encoder.transformer_cells.11.attention_cell.proj_key.weight, diff norm: 40.31818771362305, nb: 35.152015686035156, nf: 35.4107551574707\n rank: 1, key: encoder.transformer_cells.3.attention_cell.proj_key.bias, diff norm: 1.4873155578243313e-06, nb: 3.780505402272653e-15, nf: 1.4873155578243313e-06\n rank: 1, key: encoder.transformer_cells.19.attention_cell.proj_query.bias, diff norm: 1.4409441064344719e-05, nb: 1.440944197383942e-05, nf: 1.7610712150714636e-12\n rank: 1, key: encoder.transformer_cells.21.attention_cell.proj_key.bias, diff norm: 2.0166795366094448e-05, nb: 6.449742649683454e-12, nf: 2.016679718508385e-05\n rank: 1, key: encoder.transformer_cells.18.attention_cell.proj_query.bias, diff norm: 1.2316013453528285e-05, nb: 1.23160207294859e-05, nf: 4.357850191816226e-11\n rank: 1, key: encoder.transformer_cells.10.attention_cell.proj_key.weight, diff norm: 37.8535270690918, nb: 33.227943420410156, nf: 32.95439529418945\n rank: 1, key: encoder.transformer_cells.15.attention_cell.proj_query.weight, diff norm: 41.19209671020508, nb: 36.156333923339844, nf: 35.788639068603516\n rank: 1, key: encoder.transformer_cells.11.attention_cell.proj_key.bias, diff norm: 2.7654434688884066e-06, nb: 3.2795877016704444e-13, nf: 2.7654434688884066e-06\n rank: 1, key: encoder.transformer_cells.22.attention_cell.proj_query.bias, diff norm: 3.814337105723098e-05, nb: 3.8143425626913086e-05, nf: 1.6758665288829633e-10\n rank: 1, key: encoder.transformer_cells.12.attention_cell.proj_key.weight, diff norm: 40.113712310791016, nb: 35.00009536743164, nf: 35.786197662353516\n rank: 1, key: encoder.transformer_cells.16.attention_cell.proj_key.weight, diff norm: 40.717308044433594, nb: 35.357940673828125, nf: 35.64064025878906\n rank: 1, key: encoder.transformer_cells.2.attention_cell.proj_key.weight, diff norm: 39.24470901489258, nb: 33.398414611816406, nf: 33.62086486816406\n rank: 1, key: encoder.transformer_cells.16.attention_cell.proj_query.weight, diff norm: 40.717308044433594, nb: 35.64064025878906, nf: 35.357940673828125\n rank: 1, key: encoder.transformer_cells.22.attention_cell.proj_key.bias, diff norm: 3.814337105723098e-05, nb: 1.6758665288829633e-10, nf: 3.8143425626913086e-05\n rank: 1, key: encoder.transformer_cells.4.attention_cell.proj_key.weight, diff norm: 36.333168029785156, nb: 32.2811393737793, nf: 32.318485260009766\n rank: 1, key: encoder.transformer_cells.11.attention_cell.proj_query.bias, diff norm: 2.7654434688884066e-06, nb: 2.7654434688884066e-06, nf: 3.2795877016704444e-13\n rank: 1, key: encoder.transformer_cells.14.attention_cell.proj_key.weight, diff norm: 40.3658447265625, nb: 35.127044677734375, nf: 35.735233306884766\n rank: 1, key: encoder.transformer_cells.2.attention_cell.proj_query.weight, diff norm: 39.24470901489258, nb: 33.62086486816406, nf: 33.398414611816406\n rank: 1, key: encoder.transformer_cells.5.attention_cell.proj_key.weight, diff norm: 37.988746643066406, nb: 33.328914642333984, nf: 33.444881439208984\n rank: 1, key: encoder.transformer_cells.15.attention_cell.proj_key.bias, diff norm: 7.84763597039273e-06, nb: 1.9577089515471213e-12, nf: 7.847636879887432e-06\n rank: 1, key: encoder.transformer_cells.23.attention_cell.proj_query.bias, diff norm: 2.405718078080099e-05, nb: 2.4057295377133414e-05, nf: 2.109027619212611e-09\n rank: 1, key: encoder.transformer_cells.11.attention_cell.proj_query.weight, diff norm: 40.31818771362305, nb: 35.4107551574707, nf: 35.152015686035156\n rank: 1, key: encoder.transformer_cells.18.attention_cell.proj_query.weight, diff norm: 40.16281509399414, nb: 35.64668655395508, nf: 35.45383834838867\n rank: 1, key: encoder.transformer_cells.0.attention_cell.proj_query.bias, diff norm: 5.219881859375164e-05, nb: 5.219881859375164e-05, nf: 1.3961561907396749e-14\n rank: 1, key: encoder.transformer_cells.7.attention_cell.proj_key.weight, diff norm: 37.99515151977539, nb: 32.930233001708984, nf: 32.93650436401367\n rank: 1, key: encoder.transformer_cells.20.attention_cell.proj_query.weight, diff norm: 38.52753448486328, nb: 35.338340759277344, nf: 34.977725982666016\n rank: 1, key: encoder.transformer_cells.9.attention_cell.proj_query.bias, diff norm: 2.3641650841454975e-06, nb: 2.3641650841454975e-06, nf: 2.152752531358465e-14\n rank: 1, key: encoder.transformer_cells.1.attention_cell.proj_query.bias, diff norm: 1.964456714631524e-06, nb: 1.964456714631524e-06, nf: 2.6298249077130785e-15\n rank: 1, key: encoder.transformer_cells.13.attention_cell.proj_query.weight, diff norm: 40.07020568847656, nb: 35.93701934814453, nf: 35.18865966796875\n rank: 1, key: encoder.transformer_cells.7.attention_cell.proj_query.weight, diff norm: 37.99515151977539, nb: 32.93650436401367, nf: 32.930233001708984\n rank: 1, key: encoder.transformer_cells.5.attention_cell.proj_query.weight, diff norm: 37.988746643066406, nb: 33.444881439208984, nf: 33.328914642333984\n rank: 1, key: encoder.transformer_cells.4.attention_cell.proj_query.bias, diff norm: 1.1234318435526802e-06, nb: 1.1234318435526802e-06, nf: 4.248931562763226e-15\n rank: 1, key: encoder.transformer_cells.10.attention_cell.proj_key.bias, diff norm: 2.656188144101179e-06, nb: 2.3076955927778253e-13, nf: 2.656188144101179e-06\n rank: 1, key: encoder.transformer_cells.20.attention_cell.proj_query.bias, diff norm: 1.7522628695587628e-05, nb: 1.752263051457703e-05, nf: 2.1600804478438818e-11\n rank: 1, key: encoder.transformer_cells.8.attention_cell.proj_query.weight, diff norm: 38.681243896484375, nb: 33.23417663574219, nf: 32.778865814208984\n rank: 1, key: encoder.transformer_cells.6.attention_cell.proj_key.weight, diff norm: 38.68321228027344, nb: 33.43061447143555, nf: 33.287593841552734\n rank: 1, key: encoder.transformer_cells.2.attention_cell.proj_query.bias, diff norm: 1.1131372730233124e-06, nb: 1.1131372730233124e-06, nf: 2.8156973941420886e-15\n rank: 1, key: encoder.transformer_cells.4.attention_cell.proj_key.bias, diff norm: 1.1234318435526802e-06, nb: 4.248931562763226e-15, nf: 1.1234318435526802e-06\n rank: 1, key: encoder.transformer_cells.6.attention_cell.proj_query.weight, diff norm: 38.68321228027344, nb: 33.287593841552734, nf: 33.43061447143555\n rank: 1, key: encoder.transformer_cells.17.attention_cell.proj_query.bias, diff norm: 1.1298162462480832e-05, nb: 1.1298162462480832e-05, nf: 6.353233369081612e-13\n rank: 1, key: encoder.transformer_cells.23.attention_cell.proj_key.bias, diff norm: 2.405718078080099e-05, nb: 2.109027619212611e-09, nf: 2.4057295377133414e-05\n \n ...\n </denchmark-code>\n \n Expected behavior\n A clear and concise description of what you expected to happen.\n Screenshots\n If applicable, add screenshots to help explain your problem.\n Environment (please complete the following information):\n \n OS: Linux\n GCC version: gcc (Ubuntu 4.9.3-13ubuntu2) 4.9.3\n CUDA and NCCL version:\n Framework (TF, PyTorch, MXNet): mxnet\n \n Additional context\n Add any other context about the problem here.\n essential test code in the docker image:\n <denchmark-code>... \n     next_batch = next(iter(get_dummy_dataloader(batch_size, 512, 80)))\n     data_list = list(split_and_load(next_batch, ctxs))\n     classified, decoded, ls1, ls2, num_masks = model(*data_list[0])\n     ls = ls1 + ls2\n     mx.nd.waitall()\n     # <------------ removing the line below leads to correct models\n     trainer._init_params() \n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "eric-haibin-lin", "commentT": "2019-12-12T08:21:48Z", "comment_text": "\n \t\tSee this PR <denchmark-link:https://github.com/bytedance/byteps/pull/176>#176</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "7cde360f41c4a3d35efea1c141d3e59e4a794861", "commit_author": "Haibin Lin", "commitT": "2019-12-13 18:08:39+08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "byteps\\mxnet\\__init__.py", "file_new_name": "byteps\\mxnet\\__init__.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "62,66", "deleted_lines": "62,66", "method_info": {"method_name": "_do_push_pull_param", "method_params": "self,index,delta_weight", "method_startline": "59", "method_endline": "68"}}, "hunk_1": {"Ismethod": 1, "added_lines": "172,173,174,175,176,178,185,186,187,188", "deleted_lines": "173,184", "method_info": {"method_name": "__init__", "method_params": "self,params,optimizer,optimizer_params,root_rank", "method_startline": "166", "method_endline": "188"}}, "hunk_2": {"Ismethod": 1, "added_lines": "119", "deleted_lines": "119", "method_info": {"method_name": "broadcast_parameters", "method_params": "params,root_rank", "method_startline": "102", "method_endline": "139"}}, "hunk_3": {"Ismethod": 1, "added_lines": "51,55", "deleted_lines": "51,55", "method_info": {"method_name": "_do_push_pull", "method_params": "self,index,grad", "method_startline": "48", "method_endline": "57"}}, "hunk_4": {"Ismethod": 1, "added_lines": "188,189", "deleted_lines": "196", "method_info": {"method_name": "_init_params", "method_params": "self", "method_startline": "188", "method_endline": "204"}}, "hunk_5": {"Ismethod": 1, "added_lines": "185,186", "deleted_lines": "184", "method_info": {"method_name": "_allreduce_grads", "method_params": "self", "method_startline": "181", "method_endline": "186"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "byteps\\mxnet\\ops.cc", "file_new_name": "byteps\\mxnet\\ops.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "129", "deleted_lines": "129", "method_info": {"method_name": "byteps::mxnet::byteps_mxnet_declare_tensor", "method_params": "tensor,name", "method_startline": "129", "method_endline": "133"}}, "hunk_1": {"Ismethod": 1, "added_lines": "129", "deleted_lines": "129", "method_info": {"method_name": "byteps::mxnet::byteps_mxnet_declare_tensor", "method_params": "name", "method_startline": "129", "method_endline": "133"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "byteps\\mxnet\\ops.h", "file_new_name": "byteps\\mxnet\\ops.h", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "40", "deleted_lines": "40"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "byteps\\mxnet\\ops.py", "file_new_name": "byteps\\mxnet\\ops.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "79,80", "deleted_lines": "79,80", "method_info": {"method_name": "byteps_declare_tensor", "method_params": "name", "method_startline": "79", "method_endline": "80"}}, "hunk_1": {"Ismethod": 1, "added_lines": "79,80", "deleted_lines": "79,80", "method_info": {"method_name": "byteps_declare_tensor", "method_params": "tensor,name", "method_startline": "79", "method_endline": "80"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\run_byteps_test.sh", "file_new_name": "tests\\run_byteps_test.sh", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "5,6,7,8,9,12", "deleted_lines": "7"}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tests\\test_mxnet.py", "file_new_name": "tests\\test_mxnet.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "79,90,95", "deleted_lines": "73,78,84,92", "method_info": {"method_name": "test_byteps_push_pull", "method_params": "self", "method_startline": "73", "method_endline": "95"}}, "hunk_1": {"Ismethod": 1, "added_lines": "105,113,136", "deleted_lines": "118,130", "method_info": {"method_name": "test_byteps_push_pull_inplace", "method_params": "self", "method_startline": "98", "method_endline": "136"}}, "hunk_2": {"Ismethod": 1, "added_lines": "152", "deleted_lines": null, "method_info": {"method_name": "test_byteps_broadcast", "method_params": "self", "method_startline": "139", "method_endline": "180"}}, "hunk_3": {"Ismethod": 1, "added_lines": "50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71", "deleted_lines": "52,57,68", "method_info": {"method_name": "test_byteps_trainer_param_order", "method_params": "self", "method_startline": "50", "method_endline": "71"}}}}}}}