{"BR": {"BR_id": "848", "BR_author": "dcferreira", "BRopenT": "2020-06-26T10:10:05Z", "BRcloseT": "2020-06-30T16:40:35Z", "BR_text": {"BRsummary": "\"OSError address already in use\" when running \"bentoml serve\" with --enable-microbatch", "BRdescription": "\n Describe the bug\n The microbatch functionality is broken with the latest update.\n From the error message, I'd guess that some service is bound to port 5000, and the microbatch service also tries to bind itself to that port.\n To Reproduce\n Steps to reproduce the behavior:\n \n Make any bentoml server.\n Run it with --enable-microbatch.\n \n Expected behavior\n In v0.8.1, a server is launched, and serves the docs in port 5000.\n Requests to the endpoint are processed.\n In v0.8.2, a server is launched, the docs are served.\n However, requests to the endpoint just return 500 error without any message.\n The logs don't even show accesses to the endpoint (though they show accesses to the docs page).\n Without --enable-microbatch, everything works correctly.\n Screenshots/Logs\n Logs when starting server, looking at docs, and trying a simple request (which isn't logged, as explained above):\n <denchmark-code>\u25b6 bentoml serve TestSizer:latest --enable-microbatch --debug             \n [2020-06-26 12:06:14,843] DEBUG - Setting debug mode: ON for current session\n [2020-06-26 12:06:14,873] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2df2e28a10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n [2020-06-26 12:06:14,878] DEBUG - Creating local YataiService instance\n [2020-06-26 12:06:15,044] DEBUG - Upgrading tables to the latest revision\n [2020-06-26 12:06:15,052] INFO - Getting latest version TestSizer:20200626120040_ACEF2A\n [2020-06-26 12:06:15,055] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2df1dee590>: Failed to establish a new connection: [Errno 111] Connection refused'))\n [2020-06-26 12:06:15,083] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2df4f35290>: Failed to establish a new connection: [Errno 111] Connection refused'))\n [2020-06-26 12:06:15,106] INFO - Micro batch enabled for API `size`\n [2020-06-26 12:06:15,107] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n [2020-06-26 12:06:15,114] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2df1cd79d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n [2020-06-26 12:06:15,117] INFO - Running micro batch service on :5000\n ======== Running on http://0.0.0.0:5000 ========\n (Press CTRL+C to quit)\n [2020-06-26 12:06:15,121] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f2df1cec3d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n  * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\n  * Serving Flask app \"TestSizer\" (lazy loading)\n  * Environment: production\n    WARNING: This is a development server. Do not use it in a production deployment.\n    Use a production WSGI server instead.\n  * Debug mode: on\n  * Running on http://127.0.0.1:44513/ (Press CTRL+C to quit)\n  * Restarting with stat\n [2020-06-26 12:06:16,076] DEBUG - Setting debug mode: ON for current session\n [2020-06-26 12:06:16,106] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb8b39321d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n [2020-06-26 12:06:16,111] DEBUG - Creating local YataiService instance\n [2020-06-26 12:06:16,268] DEBUG - Upgrading tables to the latest revision\n [2020-06-26 12:06:16,276] INFO - Getting latest version TestSizer:20200626120040_ACEF2A\n [2020-06-26 12:06:16,279] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb8b28de810>: Failed to establish a new connection: [Errno 111] Connection refused'))\n [2020-06-26 12:06:16,310] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb8b28b7050>: Failed to establish a new connection: [Errno 111] Connection refused'))\n [2020-06-26 12:06:16,332] INFO - Micro batch enabled for API `size`\n [2020-06-26 12:06:16,333] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n [2020-06-26 12:06:16,341] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb8b27c8a90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n [2020-06-26 12:06:16,344] INFO - Running micro batch service on :5000\n [2020-06-26 12:06:16,349] DEBUG - HTTPSConnectionPool(host='api.amplitude.com', port=443): Max retries exceeded with url: /httpapi (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb8b27df490>: Failed to establish a new connection: [Errno 111] Connection refused'))\n Process Process-1:\n  * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\n Traceback (most recent call last):\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n     self.run()\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/multiprocessing/process.py\", line 99, in run\n     self._target(*self._args, **self._kwargs)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/marshal/marshal.py\", line 301, in fork_start_app\n     aiohttp.web.run_app(app, port=port)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/aiohttp/web.py\", line 433, in run_app\n     reuse_port=reuse_port))\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/asyncio/base_events.py\", line 583, in run_until_complete\n     return future.result()\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/aiohttp/web.py\", line 359, in _run_app\n     await site.start()\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/aiohttp/web_runner.py\", line 104, in start\n     reuse_port=self._reuse_port)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/asyncio/base_events.py\", line 1385, in create_server\n     % (sa, err.strerror.lower())) from None\n OSError: [Errno 98] error while attempting to bind on address ('0.0.0.0', 5000): address already in use\n  * Debugger is active!\n  * Debugger PIN: 335-153-800\n 127.0.0.1 - - [26/Jun/2020 12:06:16] \"GET / HTTP/1.1\" 200 -\n 127.0.0.1 - - [26/Jun/2020 12:06:16] \"GET /docs.json HTTP/1.1\" 200 -\n </denchmark-code>\n \n Environment:\n \n BentoML version: 0.8.2\n \n Additional context\n As far as I can tell, this isn't dependent on my code/service, but a general issue for all services.\n I'd guess this would have been caught early with <denchmark-link:https://github.com/bentoml/BentoML/issues/805>#805</denchmark-link>\n  .\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "dcferreira", "commentT": "2020-06-26T17:41:27Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/dcferreira>@dcferreira</denchmark-link>\n  - I've noticed this issue too, it only appears when you use  command tho, which is meant for development use only.  The  (soon to be renamed as ) should still work for \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "dcferreira", "commentT": "2020-06-26T20:27:19Z", "comment_text": "\n \t\tFor what it's worth, I first noticed it in the docker container, rather than bentoml serve.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "dcferreira", "commentT": "2020-06-26T22:29:06Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/dcferreira>@dcferreira</denchmark-link>\n , I tried with the API server docker container but can not reproduce it. Did you change the docker container's  to ?\n For example, I have built a docker image called parano/test with the IrisClassifier example in the quick start guide, and with the following docker run, I can not reproduce the issue:\n docker run -p 3000:5000 parano/test:latest --debug --enable-microbatch\n or the equivalent:\n docker run -p 3000:5000 parano/test:latest bentoml serve-gunicorn /bento --debug --enable-microbatch\n I can, however, reproduce the issue with bentoml serve command:\n docker run -p 3000:5000 parano/test:latest bentoml serve /bento --debug --enable-microbatch\n [2020-06-26 22:24:54,380] DEBUG - Setting debug mode: ON for current session\n [2020-06-26 22:24:55,555] INFO - Micro batch enabled for API `predict`\n [2020-06-26 22:24:55,556] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n [2020-06-26 22:24:55,756] INFO - Running micro batch service on :5000\n  * Serving Flask app \"IrisClassifier\" (lazy loading)\n  * Environment: production\n    WARNING: This is a development server. Do not use it in a production deployment.\n    Use a production WSGI server instead.\n  * Debug mode: on\n  * Running on http://127.0.0.1:34101/ (Press CTRL+C to quit)\n  * Restarting with stat\n [2020-06-26 22:24:57,248] DEBUG - Setting debug mode: ON for current session\n [2020-06-26 22:24:58,371] INFO - Micro batch enabled for API `predict`\n [2020-06-26 22:24:58,372] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n [2020-06-26 22:24:58,567] INFO - Running micro batch service on :5000\n Process Process-1:\n Traceback (most recent call last):\n   File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n     self.run()\n   File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n     self._target(*self._args, **self._kwargs)\n   File \"/opt/conda/lib/python3.8/site-packages/bentoml/marshal/marshal.py\", line 301, in fork_start_app\n     aiohttp.web.run_app(app, port=port)\n   File \"/opt/conda/lib/python3.8/site-packages/aiohttp/web.py\", line 419, in run_app\n     loop.run_until_complete(_run_app(app,\n   File \"/opt/conda/lib/python3.8/asyncio/base_events.py\", line 616, in run_until_complete\n     return future.result()\n   File \"/opt/conda/lib/python3.8/site-packages/aiohttp/web.py\", line 359, in _run_app\n     await site.start()\n   File \"/opt/conda/lib/python3.8/site-packages/aiohttp/web_runner.py\", line 100, in start\n     self._server = await loop.create_server(  # type: ignore\n   File \"/opt/conda/lib/python3.8/asyncio/base_events.py\", line 1463, in create_server\n     raise OSError(err.errno, 'error while attempting '\n OSError: [Errno 98] error while attempting to bind on address ('0.0.0.0', 5000): address already in use\n  * Debugger is active!\n  * Debugger PIN: 814-079-434\n ^C======== Running on http://0.0.0.0:5000 ========\n (Press CTRL+C to quit)\n Is that the same case on your end?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "dcferreira", "commentT": "2020-06-27T07:49:55Z", "comment_text": "\n \t\tI quickly checked it again with my example to make sure, and it doesn't work. I can devote some more time to this on Monday.\n But for now, I used the example service in <denchmark-link:https://github.com/bentoml/BentoML/issues/812>#812</denchmark-link>\n , and built the docker image .\n <denchmark-code>\u25b6 docker run -p 5000:5000 testserver --debug --enable-microbatch                                  \n [2020-06-27 07:42:01,638] DEBUG - Setting debug mode: ON for current session\n [2020-06-27 07:42:02,796] INFO - get_gunicorn_num_of_workers: 5, calculated by cpu count\n [2020-06-27 07:42:02,832] INFO - Running micro batch service on :5000\n [2020-06-27 07:42:03,822] DEBUG - Setting up prometheus_multiproc_dir: /root/bentoml/prometheus_multiproc_dir\n [2020-06-27 07:42:03,829] DEBUG - Setting up prometheus_multiproc_dir: /root/bentoml/prometheus_multiproc_dir\n [2020-06-27 07:42:03 +0000] [15] [INFO] Starting gunicorn 20.0.4\n [2020-06-27 07:42:03 +0000] [1] [INFO] Starting gunicorn 20.0.4\n [2020-06-27 07:42:03 +0000] [15] [INFO] Listening at: http://0.0.0.0:5000 (15)\n [2020-06-27 07:42:03 +0000] [15] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n [2020-06-27 07:42:03 +0000] [1] [INFO] Listening at: http://0.0.0.0:51123 (1)\n [2020-06-27 07:42:03 +0000] [1] [INFO] Using worker: sync\n [2020-06-27 07:42:03 +0000] [16] [INFO] Booting worker with pid: 16\n [2020-06-27 07:42:03 +0000] [17] [INFO] Booting worker with pid: 17\n [2020-06-27 07:42:03 +0000] [18] [INFO] Booting worker with pid: 18\n [2020-06-27 07:42:03 +0000] [19] [INFO] Booting worker with pid: 19\n [2020-06-27 07:42:03 +0000] [20] [INFO] Booting worker with pid: 20\n [2020-06-27 07:42:03,993] INFO - Micro batch enabled for API `size`\n [2020-06-27 07:42:03,993] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n [2020-06-27 07:42:04 +0000] [21] [INFO] Booting worker with pid: 21\n </denchmark-code>\n \n Then access the UI on port 5000, and send a request; a 500 error is output, without any record of it in the logs.\n You can also try the client code from the same example, with the same result.\n Running without --enable-microbatch works as expected.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "dcferreira", "commentT": "2020-06-29T16:40:43Z", "comment_text": "\n \t\tThanks again for reporting this <denchmark-link:https://github.com/dcferreira>@dcferreira</denchmark-link>\n \n I think there are actually two issues here:\n \n DataframeInput has some issue handling micro-batching requests, which caused the 500 error. I can reproduce the same on my local machine with the quickstart sklearn example. cc @bojiang\n Running bentoml serve with --enable-microbatch locally will always fail with the address already in use error\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "dcferreira", "commentT": "2020-06-29T20:20:04Z", "comment_text": "\n \t\tAh ok, then I was unfortunate that the symptoms were the same :P\n Thanks for checking this.\n If you prefer, I can open a new issue for the DataframeInput.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "dcferreira", "commentT": "2020-06-29T21:23:24Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/dcferreira>@dcferreira</denchmark-link>\n  that'd be great! I will look into a fix later today\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "dcferreira", "commentT": "2020-06-30T06:05:29Z", "comment_text": "\n \t\tFor port conflict:\n ref: <denchmark-link:https://flask.palletsprojects.com/en/1.1.x/server/#in-code>https://flask.palletsprojects.com/en/1.1.x/server/#in-code</denchmark-link>\n \n <denchmark-code>The reason for this is that due to how the reload mechanism works there are some bizarre side-effects (like executing certain code twice, sometimes crashing without message or dying when a syntax or import error happens).\n </denchmark-code>\n \n \t\t"}}}, "commit": {"commit_id": "2968cbe850c680e2789bc35a9d3b67ba928d23c5", "commit_author": "bojiang", "commitT": "2020-06-30 09:40:34-07:00", "changed_files": {"file_0": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": ".coveragerc"}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "bentoml\\server\\bento_api_server.py", "file_new_name": "bentoml\\server\\bento_api_server.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "108,109,110", "deleted_lines": "108", "method_info": {"method_name": "start", "method_params": "self", "method_startline": "100", "method_endline": "110"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "travis\\onnx_integration_tests.sh", "file_new_name": "travis\\onnx_integration_tests.sh", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "14", "deleted_lines": "14"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "travis\\pytorch_integration_tests.sh", "file_new_name": "travis\\pytorch_integration_tests.sh", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "14", "deleted_lines": "14"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "travis\\unit_tests.sh", "file_new_name": "travis\\unit_tests.sh", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "12", "deleted_lines": "12"}}}}}}