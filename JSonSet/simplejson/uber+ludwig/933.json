{"BR": {"BR_id": "933", "BR_author": "catr1ne55", "BRopenT": "2020-09-30T13:01:26Z", "BRcloseT": "2020-10-01T00:59:25Z", "BR_text": {"BRsummary": "Multi-label classification for Text throws an error on /predict when \"ludwig serve\"", "BRdescription": "\n Describe the bug\n When I am trying to serve a trained ludwig model for multi-label classification, on /predict I always get an Internal server error\n To Reproduce\n Steps to reproduce the behavior:\n \n \n create a model_definition.yaml:\n input_features:\n     - level: \"word\"\n       name: \"content\"\n       type: \"text\"\n output_features:\n     - name: tags\n       type: set\n \n \n \n create a text_data.csv\n \"content\",\"tags\"\n \"hello world\",\"hello, world, stupid\"\n \"my name is Bob\",\"name, hello\"\n \n \n \n train the model\n ludwig experiment --data_csv text_data.csv --model_definition_file model_definition.yaml\n \n \n \n start serve command on the newly created model\n ludwig serve --model_path ./results/experiment_run/model\n \n \n \n Run /predict request\n curl http://localhost:8000/predict -X POST -F \"content=something\"\n \n \n \n Expected behavior\n I'd expect to see the 200 OK status with result of prediction\n Observed behavior\n Request fails with 500 Internal Server Error\n Logs of the ludwig:\n <denchmark-code>INFO:     Started server process [753]\n INFO:     Waiting for application startup.\n INFO:     Application startup complete.\n INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n Error: Object of type 'float32' is not JSON serializable\n ERROR:ludwig.serve:Error: Object of type 'float32' is not JSON serializable\n INFO:     172.17.0.1:57522 - \"POST /predict HTTP/1.1\" 500 Internal Server Error\n </denchmark-code>\n \n Environment (please complete the following information):\n \n Docker base image: tensorflow/tensorflow:1.15.2-py3\n Python version 3.6.9\n Ludwig version tested on v0.2.2 and v0.2.2.8\n \n Additional context\n Error doesn't happen on ludwig predict, it happens only when ludwig serve + /predict request\n From debugging I realized that  field is a list of  numbers, which are not convertable to JSON via  - so error is thrown exactly on this line: <denchmark-link:https://github.com/uber/ludwig/blob/v0.2.2.8/ludwig/serve.py#L76>https://github.com/uber/ludwig/blob/v0.2.2.8/ludwig/serve.py#L76</denchmark-link>\n \n I assume that the easiest way to fix it would be to convert values into  somewhere here: <denchmark-link:https://github.com/uber/ludwig/blob/v0.2.2.8/ludwig/data/postprocessing.py#L108>https://github.com/uber/ludwig/blob/v0.2.2.8/ludwig/data/postprocessing.py#L108</denchmark-link>\n   because when  is , result is processed in this else branch\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "catr1ne55", "commentT": "2020-09-30T20:24:49Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/catr1ne55>@catr1ne55</denchmark-link>\n  thank you for posting this and for the detailed instruction for reproducing. Ludwig had a JSONEncoder that deals with numpy arrays (utils/data_utils.py::NumpyEncoder). We'll replace the current JSON decoder with that and this should work fine. Will keep you posted.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "catr1ne55", "commentT": "2020-10-01T01:01:45Z", "comment_text": "\n \t\tPushed a commit that solves the issue. Please confirm if you can by using the code on master.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "catr1ne55", "commentT": "2020-10-01T01:04:13Z", "comment_text": "\n \t\tSome minor comments on you example that may be useful:\n \n you don't need the \" in the YAML file\n When you have a set column, you cna format it in many ways, by default it is formatted with whitespace, meaning your column value should look like: \"hello world stupid\"\n you don't need the quotes in the CSV unless the specific value contains a comma\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "catr1ne55", "commentT": "2020-10-01T08:58:14Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/w4nderlust>@w4nderlust</denchmark-link>\n  After updating and retraining model everything works as expected.\n Thank you very much for quick fix and comments!\n \t\t"}}}, "commit": {"commit_id": "14f35f86a77818eccff2b9238ab41aa0813a4397", "commit_author": "w4nderlust", "commitT": "2020-09-30 17:59:04-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "ludwig\\serve.py", "file_new_name": "ludwig\\serve.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "83,84,85", "deleted_lines": "80", "method_info": {"method_name": "server.predict", "method_params": "Request", "method_startline": "71", "method_endline": "92"}}, "hunk_1": {"Ismethod": 1, "added_lines": "83,84,85,108,109,110", "deleted_lines": "80,103", "method_info": {"method_name": "server", "method_params": "model", "method_startline": "59", "method_endline": "119"}}, "hunk_2": {"Ismethod": 1, "added_lines": "108,109,110", "deleted_lines": "103", "method_info": {"method_name": "server.batch_predict", "method_params": "Request", "method_startline": "95", "method_endline": "117"}}}}}}}