{"BR": {"BR_id": "364", "BR_author": "nlebreton", "BRopenT": "2019-06-05T08:12:17Z", "BRcloseT": "2019-06-05T20:51:03Z", "BR_text": {"BRsummary": "Try to load english spacy model while french's one is configured", "BRdescription": "\n Cannot load the French spacy model\n I need to preprocess text input with a French tokenizer.\n To Reproduce\n The French model was installed using the following command:\n python -m spacy download fr\n I was able to check that fr-core-news-sm is properly installed and that no other spacy module is installed.\n pip freeze output attached\n <denchmark-link:https://github.com/uber/ludwig/files/3256071/pip_freeze_output.txt>pip_freeze_output.txt</denchmark-link>\n \n While calling the following command:\n ludwig train --data_csv 20_cate.csv --model_definition \"{input_features: [{name: DESCRIPTION_DEMANDE, type: text, preprocessing: {word_format: french_tokenize}}], output_features: [{name: ID_DOMAINE, type: category}]}\"\n \n Loading NLP pipeline\n Unable to load spacy model en_core_web_sm. Make sure to download it with: python -m spacy download en_core_web_sm\n \n The full output of Ludwig is attached.\n <denchmark-link:https://github.com/uber/ludwig/files/3256070/ludwig_output.txt>ludwig_output.txt</denchmark-link>\n \n No word_format: french_<something> works.\n Environment:\n \n Windows 10 Enterprise\n spacy 2.1.4\n Python 3.6.8\n Ludwig 0.1.2\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "nlebreton", "commentT": "2019-06-05T09:43:55Z", "comment_text": "\n \t\tI replaced in the previous command the word format french_tokenize by an unexisting value (for example, french_tokenizzzzzzzzzzzze),\n ludwig train --data_csv 20_cate.csv --model_definition \"{input_features: [{name: DESCRIPTION_DEMANDE, type: text, preprocessing: {word_format: french_tokenizzzzzzzzzzzze}}], output_features: [{name: ID_DOMAINE, type: category}]}\"\n And got the following output:\n ValueError: Key french_tokenizzzzzzzzzzzze not supported, available options: dict_keys(['characters', 'json', 'space', 'space_punct', 'underscore', 'comma', 'untokenized', 'stripped', 'english_tokenize', 'english_tokenize_filter', 'english_tokenize_remove_stopwords', 'english_lemmatize', 'english_lemmatize_filter', 'english_lemmatize_remove_stopwords', 'italian_tokenize', 'italian_tokenize_filter', 'italian_tokenize_remove_stopwords', 'italian_lemmatize', 'italian_lemmatize_filter', 'italian_lemmatize_remove_stopwords', 'spanish_tokenize', 'spanish_tokenize_filter', 'spanish_tokenize_remove_stopwords', 'spanish_lemmatize', 'spanish_lemmatize_filter', 'spanish_lemmatize_remove_stopwords', 'german_tokenize', 'german_tokenize_filter', 'german_tokenize_remove_stopwords', 'german_lemmatize', 'german_lemmatize_filter', 'german_lemmatize_remove_stopwords', 'french_tokenize', 'french_tokenize_filter', 'french_tokenize_remove_stopwords', 'french_lemmatize', 'french_lemmatize_filter', 'french_lemmatize_remove_stopwords', 'portuguese_tokenize', 'portuguese_tokenize_filter', 'portuguese_tokenize_remove_stopwords', 'portuguese_lemmatize', 'portuguese_lemmatize_filter', 'portuguese_lemmatize_remove_stopwords', 'dutch_tokenize', 'dutch_tokenize_filter', 'dutch_tokenize_remove_stopwords', 'dutch_lemmatize', 'dutch_lemmatize_filter', 'dutch_lemmatize_remove_stopwords', 'greek_tokenize', 'greek_tokenize_filter', 'greek_tokenize_remove_stopwords', 'greek_lemmatize', 'greek_lemmatize_filter', 'greek_lemmatize_remove_stopwords', 'multi_tokenize', 'multi_tokenize_filter', 'multi_tokenize_remove_stopwords', 'multi_lemmatize', 'multi_lemmatize_filter', 'multi_lemmatize_remove_stopwords'])\n I shows that:\n \n the parameter word_format is taken into account\n the value french_tokenize is supposed to be taken into account\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "nlebreton", "commentT": "2019-06-05T20:52:15Z", "comment_text": "\n \t\tFixed it, can you please install from the current master with pip install git+https://github.com/uber/ludwig.git and confirm that it solves your problem? Thank you.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "nlebreton", "commentT": "2019-06-06T07:36:36Z", "comment_text": "\n \t\tI installed your patch calling pip install git+https://github.com/uber/ludwig.git.\n <denchmark-link:https://github.com/uber/ludwig/files/3260407/patched_ludwig_install.txt>patched_ludwig_install.txt</denchmark-link>\n \n I then called ludwig train --data_csv 20_cate.csv --model_definition \"{input_features: [{name: DESCRIPTION_DEMANDE, type: text, preprocessing: {word_format: french_tokenize_filter}}], output_features: [{name: ID_DOMAINE, type: category}]}\"  and got the same result.\n \n Loading NLP pipeline\n Unable to load spacy model en_core_web_sm. Make sure to download it with: python -m spacy download en_core_web_sm\n \n The details of the output:\n <denchmark-link:https://github.com/uber/ludwig/files/3260421/patched_ludwig_output.txt>patched_ludwig_output.txt</denchmark-link>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "nlebreton", "commentT": "2019-06-06T07:53:41Z", "comment_text": "\n \t\tI have tried to set preprocessing -> text -> word_format instead of input_features -> preprocessing -> word_format and got the same result.\n I have tried to set italian_tokenize instead of french_tokenize (knowing that italian's spacy module is not installed) and got the same message about English spacy model.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "nlebreton", "commentT": "2019-06-06T19:29:35Z", "comment_text": "\n \t\tIn my tests I replicated exactly your command with fake data and it works fine.\n Are you sure you are using the latest code for master? As the version number is the same it may have not replaced the regular version, try uninstalling and reinstalling using the git master.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "nlebreton", "commentT": "2019-06-07T07:12:34Z", "comment_text": "\n \t\tThe pip install output was misleading. The version of the file ludwig/utils/strings_utils.py actually was the older one. Uninstall/reinstall solved this and I can confirm that your patch allows to use French word formats. Thx.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "nlebreton", "commentT": "2019-06-10T20:04:32Z", "comment_text": "\n \t\tYou're welcome!\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "nlebreton", "commentT": "2019-07-02T12:53:39Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/w4nderlust>@w4nderlust</denchmark-link>\n \n The release version-0.1.2 still has the typo where only english processing is used even for other languages in format_registry of string_utils.py.\n Master branch though has the changes.  Will you be having those changes in the next release and for now it is better to install master?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "nlebreton", "commentT": "2019-07-03T19:00:19Z", "comment_text": "\n \t\tYes, the next release will include these changes (it will come soon), for now I suggest using master.\n \t\t"}}}, "commit": {"commit_id": "62f949fe57dbb79c2eac6241b03dbe688fd53bd9", "commit_author": "piero", "commitT": "2019-06-05 13:50:45-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ludwig\\utils\\strings_utils.py", "file_new_name": "ludwig\\utils\\strings_utils.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "23,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589", "deleted_lines": "20,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589"}}}}}}