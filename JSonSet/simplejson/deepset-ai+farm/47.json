{"BR": {"BR_id": "47", "BR_author": "bnic24", "BRopenT": "2019-08-06T17:06:19Z", "BRcloseT": "2019-08-06T18:18:00Z", "BR_text": {"BRsummary": "LM finetuning example missing data", "BRdescription": "\n Trying to run examples/lm_finetuning.py results in FileNotFoundError: [Errno 2] No such file or directory: '../data/finetune_sample/train.txt'. The other examples seem to be able to automatically download the dataset if it's not present.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "bnic24", "commentT": "2019-08-06T18:07:27Z", "comment_text": "\n \t\tYep, there's already a PR in the making: <denchmark-link:https://github.com/deepset-ai/FARM/pull/44>#44</denchmark-link>\n \n It's currently under review but will be merged soon :)\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "bnic24", "commentT": "2019-08-06T18:17:44Z", "comment_text": "\n \t\tJust merged it! You should have some dataset containing NIPS papers now for running the example. Just be aware that data preprocessing is currently sequential and therefore rather slow on large datasets. We are already working on speeding things up via multiprocessing in <denchmark-link:https://github.com/deepset-ai/FARM/pull/45>#45</denchmark-link>\n . Should be ready within the next days ...\n \t\t"}}}, "commit": {"commit_id": "ded5f4612ae83d4f3b6fbbf440b4a2eb8d914280", "commit_author": "Malte Pietsch", "commitT": "2019-08-06 20:13:51+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\lm_finetuning.py", "file_new_name": "examples\\lm_finetuning.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "35,44,89", "deleted_lines": "35,44,89"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "farm\\data_handler\\processor.py", "file_new_name": "farm\\data_handler\\processor.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "205", "deleted_lines": "204", "method_info": {"method_name": "_featurize_samples", "method_params": "self", "method_startline": "204", "method_endline": "207"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "farm\\data_handler\\samples.py", "file_new_name": "farm\\data_handler\\samples.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "126", "deleted_lines": "124", "method_info": {"method_name": "create_samples_sentence_pairs", "method_params": "baskets", "method_startline": "122", "method_endline": "138"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "farm\\data_handler\\utils.py", "file_new_name": "farm\\data_handler\\utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "147,148", "method_info": {"method_name": "print_example_with_features", "method_params": "example,tokens,input_ids,padding_mask,segment_ids,label_ids,initial_mask", "method_startline": "147", "method_endline": "148"}}, "hunk_1": {"Ismethod": 1, "added_lines": "120,121,126,129,130,131,132,133,134,135,136,141", "deleted_lines": "122,124,127,128,129,130,132,133,134,136,139,141,142,143", "method_info": {"method_name": "read_docs_from_txt", "method_params": "filename,delimiter,encoding", "method_startline": "118", "method_endline": "143"}}, "hunk_2": {"Ismethod": 1, "added_lines": "229,231,232,236,237", "deleted_lines": null, "method_info": {"method_name": "_get_random_sentence", "method_params": "docs,forbidden_doc", "method_startline": "220", "method_endline": "239"}}}}}}}