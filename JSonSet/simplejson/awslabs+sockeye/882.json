{"BR": {"BR_id": "882", "BR_author": "graftim", "BRopenT": "2020-09-22T10:08:06Z", "BRcloseT": "2020-09-24T07:59:12Z", "BR_text": {"BRsummary": "Incompatibility  &gt;=2.1.17 vs. &lt;=2.1.16", "BRdescription": "\n Hi everyone,\n In an attempt of getting the latest and greatest with MXNet 1.7.0 I noticed that models trained with Sockeye 2.1.16 and smaller have issues when translating with Sockeye 2.1.17 and greater. When I don't change anything I receive the following error:\n <denchmark-code>AssertionError: Parameter 'decoder.layers.0.autoregr_layer.ff_out.weight' is missing in file\n 'model_fixed_preprocessing_big/params.best', which contains parameters: 'output_layer.weight',\n 'embedding_source.factor0_weight', 'encoder.pos_embedding.weight', ..., 'decoder.layers.1.ff.ff2.bias',\n 'decoder.final_process.layer_norm.gamma', 'decoder.final_process.layer_norm.beta', 'output_layer.bias'. \n Set allow_missing=True to ignore missing parameters.\n </denchmark-code>\n \n When I set allow_missing=True, The translation starts and finishes without throwing an Error, but the output has lots of repetitions:\n Output when translating with 2.1.16:\n \u2581Feuer \u2581gel\u00f6scht \u2581in \u2581einem \u2581franz\u00f6sischen \u2581Chemie werk\n Output when translating with 2.1.17 or higher (with a model on 2.1.16):\n \u2581Feuer \u2581gel\u00f6scht es \u2581Feuer \u2581gel\u00f6scht es \u2581Feuer \u2581in \u2581einem \u2581franz\u00f6sischen \u2581Chemie werk \u2581gel\u00f6scht\n Is there a possible fix for this or did <denchmark-link:https://github.com/awslabs/sockeye/pull/851>#851</denchmark-link>\n  perform changes that lead to incompatibility, so that 2.1.17 should actually be 2.2.0?\n Thanks in advance\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "graftim", "commentT": "2020-09-22T10:10:47Z", "comment_text": "\n \t\tThanks for reporting! What was the command you used for training? (specifically, did you set the --decoder parameter?)\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "graftim", "commentT": "2020-09-22T10:25:50Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/tdomhan>@tdomhan</denchmark-link>\n \n Thanks for the quick response! here are all the model-specifi parameters that were used for the training, and yes --decoder was set to transformer:\n <denchmark-code>    --encoder=transformer \\\n     --decoder=transformer \\\n     --num-layers=20:2 \\\n     --transformer-model-size 1024 \\\n     --transformer-attention-heads=8 \\\n     --transformer-feed-forward-num-hidden 4096 \\\n     --transformer-positional-embedding-type=fixed \\\n     --transformer-preprocess=n \\\n     --transformer-postprocess=dr \\\n     --transformer-dropout-attention=0.1 \\\n     --transformer-dropout-act=0.1 \\\n     --transformer-dropout-prepost=0.1 \\\n     --weight-tying-type=src_trg_softmax \\\n     --weight-init=xavier \\\n     --weight-init-scale=3.0 \\\n     --weight-init-xavier-factor-type=avg \\\n     --num-embed 1024 \\\n     --optimizer adam \\\n     --optimized-metric=perplexity \\\n     --label-smoothing=0.1 \\\n     --gradient-clipping-threshold=-1 \\\n     --initial-learning-rate=0.0002 \\\n     --learning-rate-reduce-num-not-improved=8 \\\n     --learning-rate-warmup 16000 \\\n     --learning-rate-reduce-factor=0.7 \\\n     --learning-rate-scheduler-type=plateau-reduce \\\n     --max-num-checkpoint-not-improved=32 \\\n     --batch-type=word \\\n     --batch-size 10000 \\\n     --update-interval 2 \\\n     --amp \\\n     --bucket-width 8 \\\n     --batch-sentences-multiple-of 8 \\\n     --pad-vocab-to-multiple-of 8 \\\n     --env=OMP_NUM_THREADS=2 \\\n     --checkpoint-interval=5000 \\\n     --max-num-epochs 10 \\\n     --keep-last-params=5 \\\n     --max-seq-len=150\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "graftim", "commentT": "2020-09-23T10:43:03Z", "comment_text": "\n \t\tThanks! It seems that the SSRU change inadvertently added a model incompatibility.  allow_missing=True will lead to some parameters being randomly initialized instead of loaded from disk, which explains the odd model behavior. Sorry for the inconvenience!\n Note that you should be able to use Sockeye 2.1.16 with MXNet 1.7.0 as well (i.e. manually updating your MXNet installation).\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "graftim", "commentT": "2020-09-23T11:52:41Z", "comment_text": "\n \t\tAlright, thanks for investigating and for the hint!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "graftim", "commentT": "2020-09-23T13:17:41Z", "comment_text": "\n \t\tThis PR will fix the problem: <denchmark-link:https://github.com/awslabs/sockeye/pull/885>#885</denchmark-link>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "graftim", "commentT": "2020-09-23T15:09:54Z", "comment_text": "\n \t\tCan you check if the latest version works for you?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "graftim", "commentT": "2020-09-24T07:59:12Z", "comment_text": "\n \t\tWorks like a charm, thank you very much!\n \t\t"}}}, "commit": {"commit_id": "f809d8970fcdf41fb633fa98f13a40617f48f244", "commit_author": "Tobias Domhan", "commitT": "2020-09-23 17:09:31+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15,16,17,18,19,20", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "MANIFEST.in", "file_new_name": "MANIFEST.in", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "10,11,12,13,14,15", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "sockeye\\__init__.py", "file_new_name": "sockeye\\__init__.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "14", "deleted_lines": "14"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "sockeye\\transformer.py", "file_new_name": "sockeye\\transformer.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "161,162,163,164,165,166,167,168,169", "deleted_lines": null}}}, "file_4": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\data\\model_2.1.x\\README.md"}, "file_5": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\data\\model_2.1.x\\config"}, "file_6": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\data\\model_2.1.x\\model_input"}, "file_7": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "test\\data\\model_2.1.x\\params.best", "file_new_name": "test\\data\\model_2.1.x\\params.best"}, "file_8": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\data\\model_2.1.x\\version"}, "file_9": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\data\\model_2.1.x\\vocab.src.0.json"}, "file_10": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\data\\model_2.1.x\\vocab.trg.0.json"}, "file_11": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\integration\\test_backwards_compatibility.py"}}}}