{"BR": {"BR_id": "4322", "BR_author": "hyz-xmaster", "BRopenT": "2020-12-18T00:12:41Z", "BRcloseT": "2021-01-24T15:34:00Z", "BR_text": {"BRsummary": "APs of YOLOv3 pretrained models drop over 0.9 after updating to v2.7 and some other detectors drop 0.1", "BRdescription": "\n Checklist\n \n I have searched related issues but cannot get the expected help.\n The bug has not been fixed in the latest version.\n \n \n In MMDetection v2.7, the APs of pre-trained models of <denchmark-link:https://github.com/open-mmlab/mmdetection/tree/master/configs/yolo>YOLOv3</denchmark-link>\n  drop significantly. For YOLOv3-320, the AP falls from 27.9 to 27.0; YOLOv3-416, the AP falls from 30.9 to 29.8; YOLOv3-608, 33.4 -> 32.3.\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.469\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.278\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.101\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.290\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.426\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.355\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.355\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.154\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.374\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.536\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.502\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.313\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.136\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.321\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.438\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.386\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.386\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.189\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.410\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.549\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.535\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.344\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.184\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.351\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.426\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.414\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.414\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.244\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.436\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.544\n For fcos_r50_caffe_fpn_gn-head_4x4_1x_coco.py, the AP drops from 36.6 to 36.5 and the same issue can be found with other detectors like Mask RCNN.\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.556\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.388\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.206\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.401\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.474\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.526\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.526\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.526\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.318\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.670\n Reproduction\n \n What command or script did you run?\n \n <denchmark-code>python tools/test.py configs/yolo/yolov3_d53_320_273e_coco.py  checkpoints/yolov3/yolov3_d53_320_273e_coco-421362b6.pth --eval bbox\n \n python tools/test.py configs/yolo/yolov3_d53_mstrain-416_273e_coco.py  checkpoints/yolov3/yolov3_d53_mstrain-416_273e_coco-2b60fcd9.pth --eval bbox\n \n python tools/test.py configs/yolo/yolov3_d53_mstrain-608_273e_coco.py  checkpoints/yolov3/yolov3_d53_mstrain-608_273e_coco-139f5633.pth --eval bbox\n \n python tools/test.py configs/fcos/fcos_r50_caffe_fpn_gn-head_4x4_1x_coco.py  checkpoints/fcos/fcos_r50_caffe_fpn_gn-head_4x4_1x_coco/fcos_r50_caffe_fpn_gn_1x_4gpu_20200218-7831950c.pth --eval bbox\n \n </denchmark-code>\n \n \n \n Did you make any modifications on the code or config? Did you understand what you have modified?\n NO\n \n \n What dataset did you use?\n COCO\n \n \n Environment\n \n Please run python mmdet/utils/collect_env.py to collect necessary environment information and paste it here.\n \n sys.platform: linux\n Python: 3.7.5 (default, Oct 25 2019, 15:51:11) [GCC 7.3.0]\n CUDA available: True\n GPU 0: GeForce GTX 1080\n CUDA_HOME: /usr/local/cuda\n NVCC: Cuda compilation tools, release 10.1, V10.1.243\n GCC: gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\n PyTorch: 1.6.0\n PyTorch compiling details: PyTorch built with:\n \n \n GCC 7.3\n \n \n C++ Version: 201402\n \n \n Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n \n \n Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n \n \n OpenMP 201511 (a.k.a. OpenMP 4.5)\n \n \n NNPACK is enabled\n \n \n CPU capability usage: AVX2\n \n \n CUDA Runtime 10.1\n \n \n NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n \n \n CuDNN 7.6.3\n \n \n Magma 2.5.2\n \n \n Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,\n \n \n TorchVision: 0.7.0\n OpenCV: 4.2.0\n MMCV: 1.1.5\n MMCV Compiler: GCC 7.3\n MMCV CUDA Compiler: 10.1\n MMDetection: 2.7.0+2983c05\n Bug fix\n I think the bug might be related to evaluation code as the AP drop happens to many detectors.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "hyz-xmaster", "commentT": "2020-12-18T04:40:48Z", "comment_text": "\n \t\tThanks for reporting the issue. We will check that.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "hyz-xmaster", "commentT": "2021-01-02T03:53:04Z", "comment_text": "\n \t\tIn the regression benchmark, the performance of YOLO indeed dropped. We will check this issue in January.\n \t\t"}}}, "commit": {"commit_id": "60312064e4d7eb62470977bffff75c46f4080a22", "commit_author": "Jerry Jiarui XU", "commitT": "2021-01-24 23:33:59+08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "mmdet\\core\\post_processing\\bbox_nms.py", "file_new_name": "mmdet\\core\\post_processing\\bbox_nms.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "53,54,55,56,57,58,59,60", "deleted_lines": "43,44"}}}}}}