{"BR": {"BR_id": "4199", "BR_author": "jevenail", "BRopenT": "2020-11-29T08:45:47Z", "BRcloseT": "2021-01-18T01:45:02Z", "BR_text": {"BRsummary": "ValueError: need at least one array to concatenate", "BRdescription": "\n I tried it on windows 10 platform,and when I want to train my dataset,error occurs .And here is the log.\n How can I solve my problem?\n <denchmark-h:h2>'tail' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\n \u6216\u6279\u5904\u7406\u6587\u4ef6\u3002\n 'gcc' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4\uff0c\u4e5f\u4e0d\u662f\u53ef\u8fd0\u884c\u7684\u7a0b\u5e8f\n \u6216\u6279\u5904\u7406\u6587\u4ef6\u3002\n fatal: not a git repository (or any of the parent directories): .git\n 2020-11-29 16:17:53,347 - mmdet - INFO - Environment info:</denchmark-h>\n \n sys.platform: win32\n Python: 3.6.12 |Anaconda, Inc.| (default, Sep  9 2020, 00:29:25) [MSC v.1916 64 bit (AMD64)]\n CUDA available: True\n GPU 0: GeForce RTX 2060 with Max-Q Design\n CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\n NVCC: Not Available\n GCC: n/a\n PyTorch: 1.6.0+cu101\n PyTorch compiling details: PyTorch built with:\n \n C++ Version: 199711\n MSVC 192628806\n Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191125 for Intel(R) 64 architecture applications\n Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n OpenMP 2019\n CPU capability usage: AVX2\n CUDA Runtime 10.1\n NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n CuDNN 7.6.4\n Magma 2.5.2\n Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -openmp:experimental -DNDEBUG -DUSE_FBGEMM -DUSE_VULKAN_WRAPPER, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,\n \n <denchmark-h:h2>TorchVision: 0.7.0+cu101\n OpenCV: 4.4.0\n MMCV: 1.1.5\n MMCV Compiler: MSVC 192729111\n MMCV CUDA Compiler: 10.1\n MMDetection: 2.6.0+</denchmark-h>\n \n 2020-11-29 16:17:54,254 - mmdet - INFO - Distributed training: False\n 2020-11-29 16:17:55,219 - mmdet - INFO - Config:\n model = dict(\n type='CascadeRCNN',\n pretrained='torchvision://resnet50',\n backbone=dict(\n type='ResNet',\n depth=50,\n num_stages=4,\n out_indices=(0, 1, 2, 3),\n frozen_stages=1,\n norm_cfg=dict(type='BN', requires_grad=True),\n norm_eval=True,\n style='pytorch'),\n neck=dict(\n type='FPN',\n in_channels=[256, 512, 1024, 2048],\n out_channels=256,\n num_outs=5),\n rpn_head=dict(\n type='RPNHead',\n in_channels=256,\n feat_channels=256,\n anchor_generator=dict(\n type='AnchorGenerator',\n scales=[8],\n ratios=[0.5, 1.0, 2.0],\n strides=[4, 8, 16, 32, 64]),\n bbox_coder=dict(\n type='DeltaXYWHBBoxCoder',\n target_means=[0.0, 0.0, 0.0, 0.0],\n target_stds=[1.0, 1.0, 1.0, 1.0]),\n loss_cls=dict(\n type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n loss_bbox=dict(\n type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n roi_head=dict(\n type='CascadeRoIHead',\n num_stages=3,\n stage_loss_weights=[1, 0.5, 0.25],\n bbox_roi_extractor=dict(\n type='SingleRoIExtractor',\n roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n out_channels=256,\n featmap_strides=[4, 8, 16, 32]),\n bbox_head=[\n dict(\n type='Shared2FCBBoxHead',\n in_channels=256,\n fc_out_channels=1024,\n roi_feat_size=7,\n num_classes=94,\n bbox_coder=dict(\n type='DeltaXYWHBBoxCoder',\n target_means=[0.0, 0.0, 0.0, 0.0],\n target_stds=[0.1, 0.1, 0.2, 0.2]),\n reg_class_agnostic=True,\n loss_cls=dict(\n type='CrossEntropyLoss',\n use_sigmoid=False,\n loss_weight=1.0),\n loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n loss_weight=1.0)),\n dict(\n type='Shared2FCBBoxHead',\n in_channels=256,\n fc_out_channels=1024,\n roi_feat_size=7,\n num_classes=94,\n bbox_coder=dict(\n type='DeltaXYWHBBoxCoder',\n target_means=[0.0, 0.0, 0.0, 0.0],\n target_stds=[0.05, 0.05, 0.1, 0.1]),\n reg_class_agnostic=True,\n loss_cls=dict(\n type='CrossEntropyLoss',\n use_sigmoid=False,\n loss_weight=1.0),\n loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n loss_weight=1.0)),\n dict(\n type='Shared2FCBBoxHead',\n in_channels=256,\n fc_out_channels=1024,\n roi_feat_size=7,\n num_classes=94,\n bbox_coder=dict(\n type='DeltaXYWHBBoxCoder',\n target_means=[0.0, 0.0, 0.0, 0.0],\n target_stds=[0.033, 0.033, 0.067, 0.067]),\n reg_class_agnostic=True,\n loss_cls=dict(\n type='CrossEntropyLoss',\n use_sigmoid=False,\n loss_weight=1.0),\n loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n ]))\n train_cfg = dict(\n rpn=dict(\n assigner=dict(\n type='MaxIoUAssigner',\n pos_iou_thr=0.7,\n neg_iou_thr=0.3,\n min_pos_iou=0.3,\n match_low_quality=True,\n ignore_iof_thr=-1),\n sampler=dict(\n type='RandomSampler',\n num=256,\n pos_fraction=0.5,\n neg_pos_ub=-1,\n add_gt_as_proposals=False),\n allowed_border=0,\n pos_weight=-1,\n debug=False),\n rpn_proposal=dict(\n nms_across_levels=False,\n nms_pre=2000,\n nms_post=2000,\n max_num=2000,\n nms_thr=0.7,\n min_bbox_size=0),\n rcnn=[\n dict(\n assigner=dict(\n type='MaxIoUAssigner',\n pos_iou_thr=0.5,\n neg_iou_thr=0.5,\n min_pos_iou=0.5,\n match_low_quality=False,\n ignore_iof_thr=-1),\n sampler=dict(\n type='RandomSampler',\n num=512,\n pos_fraction=0.25,\n neg_pos_ub=-1,\n add_gt_as_proposals=True),\n pos_weight=-1,\n debug=False),\n dict(\n assigner=dict(\n type='MaxIoUAssigner',\n pos_iou_thr=0.6,\n neg_iou_thr=0.6,\n min_pos_iou=0.6,\n match_low_quality=False,\n ignore_iof_thr=-1),\n sampler=dict(\n type='RandomSampler',\n num=512,\n pos_fraction=0.25,\n neg_pos_ub=-1,\n add_gt_as_proposals=True),\n pos_weight=-1,\n debug=False),\n dict(\n assigner=dict(\n type='MaxIoUAssigner',\n pos_iou_thr=0.7,\n neg_iou_thr=0.7,\n min_pos_iou=0.7,\n match_low_quality=False,\n ignore_iof_thr=-1),\n sampler=dict(\n type='RandomSampler',\n num=512,\n pos_fraction=0.25,\n neg_pos_ub=-1,\n add_gt_as_proposals=True),\n pos_weight=-1,\n debug=False)\n ])\n test_cfg = dict(\n rpn=dict(\n nms_across_levels=False,\n nms_pre=1000,\n nms_post=1000,\n max_num=1000,\n nms_thr=0.7,\n min_bbox_size=0),\n rcnn=dict(\n score_thr=0.05,\n nms=dict(type='nms', iou_threshold=0.5),\n max_per_img=100))\n dataset_type = 'VOCDataset'\n data_root = 'data/VOCdevkit/'\n img_norm_cfg = dict(\n mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n train_pipeline = [\n dict(type='LoadImageFromFile'),\n dict(type='LoadAnnotations', with_bbox=True),\n dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),\n dict(type='RandomFlip', flip_ratio=0.5),\n dict(\n type='Normalize',\n mean=[123.675, 116.28, 103.53],\n std=[58.395, 57.12, 57.375],\n to_rgb=True),\n dict(type='Pad', size_divisor=32),\n dict(type='DefaultFormatBundle'),\n dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n ]\n test_pipeline = [\n dict(type='LoadImageFromFile'),\n dict(\n type='MultiScaleFlipAug',\n img_scale=(1000, 600),\n flip=False,\n transforms=[\n dict(type='Resize', keep_ratio=True),\n dict(type='RandomFlip'),\n dict(\n type='Normalize',\n mean=[123.675, 116.28, 103.53],\n std=[58.395, 57.12, 57.375],\n to_rgb=True),\n dict(type='Pad', size_divisor=32),\n dict(type='ImageToTensor', keys=['img']),\n dict(type='Collect', keys=['img'])\n ])\n ]\n data = dict(\n samples_per_gpu=2,\n workers_per_gpu=2,\n train=dict(\n type='RepeatDataset',\n times=3,\n dataset=dict(\n type='VOCDataset',\n ann_file=['data/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt'],\n img_prefix=['data/VOCdevkit/VOC2007/'],\n pipeline=[\n dict(type='LoadImageFromFile'),\n dict(type='LoadAnnotations', with_bbox=True),\n dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),\n dict(type='RandomFlip', flip_ratio=0.5),\n dict(\n type='Normalize',\n mean=[123.675, 116.28, 103.53],\n std=[58.395, 57.12, 57.375],\n to_rgb=True),\n dict(type='Pad', size_divisor=32),\n dict(type='DefaultFormatBundle'),\n dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n ])),\n val=dict(\n type='VOCDataset',\n ann_file='data/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt',\n img_prefix='data/VOCdevkit/VOC2007/',\n pipeline=[\n dict(type='LoadImageFromFile'),\n dict(\n type='MultiScaleFlipAug',\n img_scale=(1000, 600),\n flip=False,\n transforms=[\n dict(type='Resize', keep_ratio=True),\n dict(type='RandomFlip'),\n dict(\n type='Normalize',\n mean=[123.675, 116.28, 103.53],\n std=[58.395, 57.12, 57.375],\n to_rgb=True),\n dict(type='Pad', size_divisor=32),\n dict(type='ImageToTensor', keys=['img']),\n dict(type='Collect', keys=['img'])\n ])\n ]),\n test=dict(\n type='VOCDataset',\n ann_file='data/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt',\n img_prefix='data/VOCdevkit/VOC2007/',\n pipeline=[\n dict(type='LoadImageFromFile'),\n dict(\n type='MultiScaleFlipAug',\n img_scale=(1000, 600),\n flip=False,\n transforms=[\n dict(type='Resize', keep_ratio=True),\n dict(type='RandomFlip'),\n dict(\n type='Normalize',\n mean=[123.675, 116.28, 103.53],\n std=[58.395, 57.12, 57.375],\n to_rgb=True),\n dict(type='Pad', size_divisor=32),\n dict(type='ImageToTensor', keys=['img']),\n dict(type='Collect', keys=['img'])\n ])\n ]))\n evaluation = dict(interval=1, metric='mAP')\n optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n optimizer_config = dict(grad_clip=None)\n lr_config = dict(\n policy='step',\n warmup='linear',\n warmup_iters=500,\n warmup_ratio=0.001,\n step=[8, 11])\n total_epochs = 12\n checkpoint_config = dict(interval=1)\n log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n dist_params = dict(backend='nccl')\n log_level = 'INFO'\n load_from = None\n resume_from = None\n workflow = [('train', 1)]\n work_dir = 'hudie_workdir'\n gpu_ids = range(0, 1)\n 2020-11-29 16:17:56,399 - mmdet - INFO - load model from: torchvision://resnet50\n 2020-11-29 16:17:56,992 - mmdet - WARNING - The model and loaded state dict do not match exactly\n unexpected key in source state_dict: fc.weight, fc.bias\n fatal: not a git repository (or any of the parent directories): .git\n 2020-11-29 16:18:01,446 - mmdet - INFO - Start running, host: ASUS@LAPTOP-AC34UT2N, work_dir: D:\\PycharmProjects\\mmd2\\hudie_workdir\n 2020-11-29 16:18:01,447 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n Traceback (most recent call last):\n File \"tools/train.py\", line 181, in \n main()\n File \"tools/train.py\", line 177, in main\n meta=meta)\n File \"c:\\users\\asus\\mmdetection\\mmdet\\apis\\train.py\", line 150, in train_detector\n runner.run(data_loaders, cfg.workflow, cfg.total_epochs)\n File \"D:\\anaconda\\envs\\mmd2\\lib\\site-packages\\mmcv\\runner\\epoch_based_runner.py\", line 125, in run\n epoch_runner(data_loaders[i], **kwargs)\n File \"D:\\anaconda\\envs\\mmd2\\lib\\site-packages\\mmcv\\runner\\epoch_based_runner.py\", line 47, in train\n for i, data_batch in enumerate(self.data_loader):\n File \"D:\\anaconda\\envs\\mmd2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 291, in iter\n return _MultiProcessingDataLoaderIter(self)\n File \"D:\\anaconda\\envs\\mmd2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 764, in init\n self._try_put_index()\n File \"D:\\anaconda\\envs\\mmd2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 994, in _try_put_index\n index = self._next_index()\n File \"D:\\anaconda\\envs\\mmd2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 357, in _next_index\n return next(self._sampler_iter)  # may raise StopIteration\n File \"D:\\anaconda\\envs\\mmd2\\lib\\site-packages\\torch\\utils\\data\\sampler.py\", line 208, in iter\n for idx in self.sampler:\n File \"c:\\users\\asus\\mmdetection\\mmdet\\datasets\\samplers\\group_sampler.py\", line 36, in iter\n indices = np.concatenate(indices)\n File \"<array_function internals>\", line 6, in concatenate\n ValueError: need at least one array to concatenate\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jevenail", "commentT": "2020-12-01T14:36:52Z", "comment_text": "\n \t\tI have tried many times during those days,but it did't work at all.Please someone help me?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jevenail", "commentT": "2020-12-03T02:46:54Z", "comment_text": "\n \t\tIt looks like I am having the same issue. Here is my bug report:\n Describe the bug\n I get the following error when I run train.py:\n <denchmark-code>Traceback (most recent call last):\n   File \"tools/train.py\", line 181, in <module>\n     main()\n   File \"tools/train.py\", line 177, in main\n     meta=meta)\n   File \"/mmdetection/mmdet/apis/train.py\", line 150, in train_detector\n     runner.run(data_loaders, cfg.workflow, cfg.total_epochs)\n   File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 125, in run\n     epoch_runner(data_loaders[i], **kwargs)\n   File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 47, in train\n     for i, data_batch in enumerate(self.data_loader):\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 291, in __iter__\n     return _MultiProcessingDataLoaderIter(self)\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 764, in __init__\n     self._try_put_index()\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 994, in _try_put_index\n     index = self._next_index()\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 357, in _next_index\n     return next(self._sampler_iter)  # may raise StopIteration\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/sampler.py\", line 208, in __iter__\n     for idx in self.sampler:\n   File \"/mmdetection/mmdet/datasets/samplers/group_sampler.py\", line 36, in __iter__\n     indices = np.concatenate(indices)\n   File \"<__array_function__ internals>\", line 6, in concatenate\n ValueError: need at least one array to concatenate\n Error in atexit._run_exitfuncs:\n Traceback (most recent call last):\n   File \"/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n     pid, sts = os.waitpid(self.pid, flag)\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n     _error_if_any_worker_fails()\n RuntimeError: DataLoader worker (pid 49) is killed by signal: Terminated.\n </denchmark-code>\n \n Reproduction\n \n What command or script did you run?\n \n <denchmark-code>python tools/train.py configs/custom_dataset_ssd.py\n </denchmark-code>\n \n \n Did you make any modifications on the code or config? Did you understand what you have modified?\n \n \n I made a custom config based on SSD. As far as I know, the only thing I changed was the location fo the dataset and the number of classes:\n \n <denchmark-code># configs/custom_dataset_ssd.py\n \n _base_ = 'ssd/ssd300_coco.py'\n \n model = dict(\n     bbox_head=dict(num_classes=1))\n \n dataset_type = 'COCODataset'\n classes = ('pupil',)\n data = dict(\n     train=dict(\n         img_prefix='/coco/train/',\n         classes=classes,\n         ann_file='/coco/train/annotation_coco.json',\n         dataset=dict(\n             ann_file='/coco/train/annotation_coco.json',\n             img_prefix='/coco/train/')),\n     val=dict(\n         img_prefix='/coco/val/',\n         classes=classes,\n         ann_file='/coco/val/annotation_coco.json'),\n     test=dict(\n         img_prefix='/coco/val/',\n         classes=classes,\n         ann_file='/coco/val/annotation_coco.json'))\n </denchmark-code>\n \n \n What dataset did you use?\n \n \n A custom COCO-format dataset with only one class.\n \n Environment\n \n Please run python mmdet/utils/collect_env.py to collect necessary environment information and paste it here.\n \n <denchmark-code>sys.platform: linux\n Python: 3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]\n CUDA available: True\n GPU 0: Tesla K80\n CUDA_HOME: /usr/local/cuda\n NVCC: Cuda compilation tools, release 10.1, V10.1.243\n GCC: gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\n PyTorch: 1.6.0\n PyTorch compiling details: PyTorch built with:\n   - GCC 7.3\n   - C++ Version: 201402\n   - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications\n   - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n   - OpenMP 201511 (a.k.a. OpenMP 4.5)\n   - NNPACK is enabled\n   - CPU capability usage: AVX2\n   - CUDA Runtime 10.1\n   - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n   - CuDNN 7.6.3\n   - Magma 2.5.2\n   - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF,\n \n TorchVision: 0.7.0\n OpenCV: 4.4.0\n MMCV: 1.2.1\n MMCV Compiler: GCC 7.3\n MMCV CUDA Compiler: 10.1\n MMDetection: 2.7.0+3e902c3\n </denchmark-code>\n \n \n You may add addition that may be helpful for locating the problem, such as\n \n How you installed PyTorch [e.g., pip, conda, source]\n Other environment variables that may be related (such as $PATH, $LD_LIBRARY_PATH, $PYTHONPATH, etc.)\n \n \n \n \n I am using nvidia-docker with the included Dockerfile. My dataset is mounted at /coco/\n \n Error traceback\n If applicable, paste the error trackback here.\n <denchmark-code>2020-12-03 02:36:20,424 - mmdet - INFO - Distributed training: False\n 2020-12-03 02:36:20,828 - mmdet - INFO - Config:\n input_size = 300\n model = dict(\n     type='SingleStageDetector',\n     pretrained='open-mmlab://vgg16_caffe',\n     backbone=dict(\n         type='SSDVGG',\n         input_size=300,\n         depth=16,\n         with_last_pool=False,\n         ceil_mode=True,\n         out_indices=(3, 4),\n         out_feature_indices=(22, 34),\n         l2_norm_scale=20),\n     neck=None,\n     bbox_head=dict(\n         type='SSDHead',\n         in_channels=(512, 1024, 512, 256, 256, 256),\n         num_classes=1,\n         anchor_generator=dict(\n             type='SSDAnchorGenerator',\n             scale_major=False,\n             input_size=300,\n             basesize_ratio_range=(0.15, 0.9),\n             strides=[8, 16, 32, 64, 100, 300],\n             ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]]),\n         bbox_coder=dict(\n             type='DeltaXYWHBBoxCoder',\n             target_means=[0.0, 0.0, 0.0, 0.0],\n             target_stds=[0.1, 0.1, 0.2, 0.2])))\n cudnn_benchmark = True\n train_cfg = dict(\n     assigner=dict(\n         type='MaxIoUAssigner',\n         pos_iou_thr=0.5,\n         neg_iou_thr=0.5,\n         min_pos_iou=0.0,\n         ignore_iof_thr=-1,\n         gt_max_assign_all=False),\n     smoothl1_beta=1.0,\n     allowed_border=-1,\n     pos_weight=-1,\n     neg_pos_ratio=3,\n     debug=False)\n test_cfg = dict(\n     nms=dict(type='nms', iou_threshold=0.45),\n     min_bbox_size=0,\n     score_thr=0.02,\n     max_per_img=200)\n dataset_type = 'COCODataset'\n data_root = 'data/coco/'\n img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[1, 1, 1], to_rgb=True)\n train_pipeline = [\n     dict(type='LoadImageFromFile', to_float32=True),\n     dict(type='LoadAnnotations', with_bbox=True),\n     dict(\n         type='PhotoMetricDistortion',\n         brightness_delta=32,\n         contrast_range=(0.5, 1.5),\n         saturation_range=(0.5, 1.5),\n         hue_delta=18),\n     dict(\n         type='Expand',\n         mean=[123.675, 116.28, 103.53],\n         to_rgb=True,\n         ratio_range=(1, 4)),\n     dict(\n         type='MinIoURandomCrop',\n         min_ious=(0.1, 0.3, 0.5, 0.7, 0.9),\n         min_crop_size=0.3),\n     dict(type='Resize', img_scale=(300, 300), keep_ratio=False),\n     dict(\n         type='Normalize',\n         mean=[123.675, 116.28, 103.53],\n         std=[1, 1, 1],\n         to_rgb=True),\n     dict(type='RandomFlip', flip_ratio=0.5),\n     dict(type='DefaultFormatBundle'),\n     dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n ]\n test_pipeline = [\n     dict(type='LoadImageFromFile'),\n     dict(\n         type='MultiScaleFlipAug',\n         img_scale=(300, 300),\n         flip=False,\n         transforms=[\n             dict(type='Resize', keep_ratio=False),\n             dict(\n                 type='Normalize',\n                 mean=[123.675, 116.28, 103.53],\n                 std=[1, 1, 1],\n                 to_rgb=True),\n             dict(type='ImageToTensor', keys=['img']),\n             dict(type='Collect', keys=['img'])\n         ])\n ]\n data = dict(\n     samples_per_gpu=8,\n     workers_per_gpu=3,\n     train=dict(\n         type='RepeatDataset',\n         times=5,\n         dataset=dict(\n             type='CocoDataset',\n             ann_file='/coco/train/annotation_coco.json',\n             img_prefix='/coco/train/',\n             pipeline=[\n                 dict(type='LoadImageFromFile', to_float32=True),\n                 dict(type='LoadAnnotations', with_bbox=True),\n                 dict(\n                     type='PhotoMetricDistortion',\n                     brightness_delta=32,\n                     contrast_range=(0.5, 1.5),\n                     saturation_range=(0.5, 1.5),\n                     hue_delta=18),\n                 dict(\n                     type='Expand',\n                     mean=[123.675, 116.28, 103.53],\n                     to_rgb=True,\n                     ratio_range=(1, 4)),\n                 dict(\n                     type='MinIoURandomCrop',\n                     min_ious=(0.1, 0.3, 0.5, 0.7, 0.9),\n                     min_crop_size=0.3),\n                 dict(type='Resize', img_scale=(300, 300), keep_ratio=False),\n                 dict(\n                     type='Normalize',\n                     mean=[123.675, 116.28, 103.53],\n                     std=[1, 1, 1],\n                     to_rgb=True),\n                 dict(type='RandomFlip', flip_ratio=0.5),\n                 dict(type='DefaultFormatBundle'),\n                 dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n             ]),\n         img_prefix='/coco/train/',\n         classes=('pupil', ),\n         ann_file='/coco/train/annotation_coco.json'),\n     val=dict(\n         type='CocoDataset',\n         ann_file='/coco/val/annotation_coco.json',\n         img_prefix='/coco/val/',\n         pipeline=[\n             dict(type='LoadImageFromFile'),\n             dict(\n                 type='MultiScaleFlipAug',\n                 img_scale=(300, 300),\n                 flip=False,\n                 transforms=[\n                     dict(type='Resize', keep_ratio=False),\n                     dict(\n                         type='Normalize',\n                         mean=[123.675, 116.28, 103.53],\n                         std=[1, 1, 1],\n                         to_rgb=True),\n                     dict(type='ImageToTensor', keys=['img']),\n                     dict(type='Collect', keys=['img'])\n                 ])\n         ],\n         classes=('pupil', )),\n     test=dict(\n         type='CocoDataset',\n         ann_file='/coco/val/annotation_coco.json',\n         img_prefix='/coco/val/',\n         pipeline=[\n             dict(type='LoadImageFromFile'),\n             dict(\n                 type='MultiScaleFlipAug',\n                 img_scale=(300, 300),\n                 flip=False,\n                 transforms=[\n                     dict(type='Resize', keep_ratio=False),\n                     dict(\n                         type='Normalize',\n                         mean=[123.675, 116.28, 103.53],\n                         std=[1, 1, 1],\n                         to_rgb=True),\n                     dict(type='ImageToTensor', keys=['img']),\n                     dict(type='Collect', keys=['img'])\n                 ])\n         ],\n         classes=('pupil', )))\n evaluation = dict(interval=1, metric='bbox')\n optimizer = dict(type='SGD', lr=0.002, momentum=0.9, weight_decay=0.0005)\n optimizer_config = dict()\n lr_config = dict(\n     policy='step',\n     warmup='linear',\n     warmup_iters=500,\n     warmup_ratio=0.001,\n     step=[16, 22])\n total_epochs = 24\n checkpoint_config = dict(interval=1)\n log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n dist_params = dict(backend='nccl')\n log_level = 'INFO'\n load_from = None\n resume_from = None\n workflow = [('train', 1)]\n classes = ('pupil', )\n work_dir = './work_dirs/custom_dataset_ssd'\n gpu_ids = range(0, 1)\n \n 2020-12-03 02:36:21,016 - mmdet - INFO - load model from: open-mmlab://vgg16_caffe\n 2020-12-03 02:36:21,062 - mmdet - WARNING - The model and loaded state dict do not match exactly\n \n missing keys in source state_dict: extra.0.weight, extra.0.bias, extra.1.weight, extra.1.bias, extra.2.weight, extra.2.bias, extra.3.weight, extra.3.bias, extra.4.weight, extra.4.bias, extra.5.weight, extra.5.bias, extra.6.weight, extra.6.bias, extra.7.weight, extra.7.bias, l2_norm.weight\n \n 2020-12-03 02:36:22,395 - mmdet - INFO - Start running, host: root@2acc5a4c80fa, work_dir: /mmdetection/work_dirs/custom_dataset_ssd\n 2020-12-03 02:36:22,395 - mmdet - INFO - workflow: [('train', 1)], max: 24 epochs\n loading annotations into memory...\n Done (t=0.00s)\n creating index...\n index created!\n loading annotations into memory...\n Done (t=0.00s)\n creating index...\n index created!\n Traceback (most recent call last):\n   File \"tools/train.py\", line 181, in <module>\n     main()\n   File \"tools/train.py\", line 177, in main\n     meta=meta)\n   File \"/mmdetection/mmdet/apis/train.py\", line 150, in train_detector\n     runner.run(data_loaders, cfg.workflow, cfg.total_epochs)\n   File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 125, in run\n     epoch_runner(data_loaders[i], **kwargs)\n   File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\", line 47, in train\n     for i, data_batch in enumerate(self.data_loader):\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 291, in __iter__\n     return _MultiProcessingDataLoaderIter(self)\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 764, in __init__\n     self._try_put_index()\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 994, in _try_put_index\n     index = self._next_index()\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 357, in _next_index\n     return next(self._sampler_iter)  # may raise StopIteration\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/sampler.py\", line 208, in __iter__\n     for idx in self.sampler:\n   File \"/mmdetection/mmdet/datasets/samplers/group_sampler.py\", line 36, in __iter__\n     indices = np.concatenate(indices)\n   File \"<__array_function__ internals>\", line 6, in concatenate\n ValueError: need at least one array to concatenate\n Error in atexit._run_exitfuncs:\n Traceback (most recent call last):\n   File \"/opt/conda/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n     pid, sts = os.waitpid(self.pid, flag)\n   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n     _error_if_any_worker_fails()\n RuntimeError: DataLoader worker (pid 117) is killed by signal: Terminated. ```\n </denchmark-code>\n \n Bug fix\n If you have already identified the reason, you can provide the information here. If you are willing to create a PR to fix it, please also leave a comment here and that would be much appreciated!\n \n The indices array seems to be empty when it is concatenated. The only way that could happen is if every group size was zero. It seems like that means dataset.flag must be empty. I'm not sure under what circumstances that would happen.\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jevenail", "commentT": "2020-12-03T03:08:04Z", "comment_text": "\n \t\tIn mmdetection/mmdet/datasets/samplers/group_sampler.py, it looks like dataset is a mmdet.datasets.dataset_wrappers.RepeatDataset and dataset.flag is, indeed [].\n datset.CLASSES is also a list of what looks like the COCO classes. That seems like it could be a problem -- maybe I needed to declare my classes somewhere else??\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jevenail", "commentT": "2020-12-03T11:26:35Z", "comment_text": "\n \t\tAfter lots of  failsure,I have given up .Later I have tried a similar  framework --\"detectron2\".\n And  found it's easier to config .More importantly, there are no such bugs.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jevenail", "commentT": "2020-12-07T03:50:55Z", "comment_text": "\n \t\tsame problems when training yolo with my own dataset converted to coco format\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "jevenail", "commentT": "2020-12-07T03:59:36Z", "comment_text": "\n \t\t\n same problems when training yolo with my own dataset converted to coco format\n \n OK, problem solved by Explicitly specify the classes in the config  file\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "jevenail", "commentT": "2020-12-07T13:32:46Z", "comment_text": "\n \t\tit met the same question, it must be some problems in your CLASSES in mmdet/datasets/coco.py and num_classes in config_file\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "jevenail", "commentT": "2020-12-07T17:19:25Z", "comment_text": "\n \t\tIt looks like <denchmark-link:https://github.com/Luoxsh6>@Luoxsh6</denchmark-link>\n  was right. The problem was that I put my classes list in the  config dict (where it is in the example) instead of the  dict. Apparently that is required for SSD at least.\n Bad:\n <denchmark-code>data = dict(\n     ...\n     train=dict(\n         classes=(...),\n         ...\n </denchmark-code>\n \n Good:\n <denchmark-code>data = dict(\n     ...\n     train=dict(\n         ...\n         dataset=(\n             classes=(...),\n         ...\n </denchmark-code>\n \n I put it in both places to be safe. It doesn't seem to complain about unused config fields.\n A better error message (or more consistent config format) would be really good though.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "jevenail", "commentT": "2020-12-08T04:20:14Z", "comment_text": "\n \t\tOKay\uff0cI am changing to use Detectron2.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "jevenail", "commentT": "2020-12-08T20:19:19Z", "comment_text": "\n \t\tI could do it following <denchmark-link:https://mmdetection.readthedocs.io/en/latest/tutorials/customize_dataset.html>the custom dataset tutorial</denchmark-link>\n  religiously and adding my custom dataset to  It seems that they changed the cfg object a lot from previous versions so very much attention should be put on it\n With respect to adding my dataset to , in addition to what is done in <denchmark-link:https://mmdetection.readthedocs.io/en/latest/tutorials/customize_dataset.html>the custom dataset tutorial</denchmark-link>\n , I add it to  to export it properly as the others datasets are exported in there\n By the way my datasets use COCO format for which I copy ~/mmdetection/mmdet/datasets/coco.py as a template, modify its class name to be the one of my dataset and the variable CLASSES to be equal to the names of the 'categories' specified in my COCO annotation (json) files\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "jevenail", "commentT": "2020-12-14T22:31:32Z", "comment_text": "\n \t\tI am getting the same error. Here is my config file ssd model:\n `base = [\n '../base/models/ssd300.py', '../base/datasets/coco_detection.py',\n '../base/schedules/schedule_2x.py', '../base/default_runtime.py'\n ]\n model = dict(\n bbox_head=dict(num_classes=2),\n )\n classes = ('truck', 'coupler')\n <denchmark-h:h1>dataset settings</denchmark-h>\n \n dataset_type = 'CocoDataset'\n data_root = '/home/bita/mmdetection/configs/ssd_coupler/multilevel/'\n img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[1, 1, 1], to_rgb=True)\n train_pipeline = [\n dict(type='LoadImageFromFile', to_float32=True),\n dict(type='LoadAnnotations', with_bbox=True),\n dict(\n type='PhotoMetricDistortion',\n brightness_delta=32,\n contrast_range=(0.5, 1.5),\n saturation_range=(0.5, 1.5),\n hue_delta=18),\n dict(\n type='Expand',\n mean=img_norm_cfg['mean'],\n to_rgb=img_norm_cfg['to_rgb'],\n ratio_range=(1, 4)),\n dict(\n type='MinIoURandomCrop',\n min_ious=(0.1, 0.3, 0.5, 0.7, 0.9),\n min_crop_size=0.3),\n dict(type='Resize', img_scale=(300, 300), keep_ratio=False),\n dict(type='Normalize', **img_norm_cfg),\n dict(type='RandomFlip', flip_ratio=0.5),\n dict(type='DefaultFormatBundle'),\n dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n ]\n test_pipeline = [\n dict(type='LoadImageFromFile'),\n dict(\n type='MultiScaleFlipAug',\n img_scale=(300, 300),\n flip=False,\n transforms=[\n dict(type='Resize', keep_ratio=False),\n dict(type='Normalize', **img_norm_cfg),\n dict(type='ImageToTensor', keys=['img']),\n dict(type='Collect', keys=['img']),\n ])\n ]\n data = dict(\n samples_per_gpu=1,\n workers_per_gpu=0,\n train=dict(\n type=dataset_type,\n ann_file=data_root + 'train/annotations_train_multi.json',\n img_prefix=data_root + 'train/',\n pipeline=train_pipeline,\n ),\n val=dict(\n type=dataset_type,\n ann_file=data_root + 'val/annotations_val_multi.json',\n img_prefix=data_root + 'val2017/',\n pipeline=test_pipeline),\n test=dict(\n type=dataset_type,\n ann_file=data_root + 'test/annotations_test_multi.json',\n img_prefix=data_root + 'test/',\n pipeline=test_pipeline))\n <denchmark-h:h1>optimizer</denchmark-h>\n \n optimizer = dict(type='SGD', lr=2e-3, momentum=0.9, weight_decay=5e-4)\n optimizer_config = dict(delete=True)\n `\n the error traceback:\n Traceback (most recent call last): File \"tools/train.py\", line 181, in <module> main() File \"tools/train.py\", line 170, in main train_detector( File \"/home/bita/mmdetection/mmdet/apis/train.py\", line 150, in train_detector runner.run(data_loaders, cfg.workflow, cfg.total_epochs) File \"/home/bita/anaconda3/envs/open-mmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 125, in run epoch_runner(data_loaders[i], **kwargs) File \"/home/bita/anaconda3/envs/open-mmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 47, in train for i, data_batch in enumerate(self.data_loader): File \"/home/bita/anaconda3/envs/open-mmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__ data = self._next_data() File \"/home/bita/anaconda3/envs/open-mmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 474, in _next_data index = self._next_index()  # may raise StopIteration File \"/home/bita/anaconda3/envs/open-mmlab/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 427, in _next_index return next(self._sampler_iter)  # may raise StopIteration File \"/home/bita/anaconda3/envs/open-mmlab/lib/python3.8/site-packages/torch/utils/data/sampler.py\", line 227, in __iter__ for idx in self.sampler: File \"/home/bita/mmdetection/mmdet/datasets/samplers/group_sampler.py\", line 36, in __iter__ indices = np.concatenate(indices) File \"<__array_function__ internals>\", line 5, in concatenate ValueError: need at least one array to concatenate\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "jevenail", "commentT": "2020-12-15T14:25:03Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/ZwwWayne>@ZwwWayne</denchmark-link>\n \n I am also having the same issue with training after transforming my labeled custom data into COCO format with only one class.\n Other threads with the same issue have been closed (e.g. <denchmark-link:https://github.com/open-mmlab/mmdetection/issues/210>#210</denchmark-link>\n , <denchmark-link:https://github.com/open-mmlab/mmdetection/issues/2198>#2198</denchmark-link>\n , <denchmark-link:https://github.com/open-mmlab/mmdetection/issues/3628>#3628</denchmark-link>\n ), but none of the proposed solutions fix my error.\n I am using /configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py.\n Done (t=0.46s)\n creating index...\n index created!\n 2020-12-15 13:38:59,283 - mmdet - INFO - Start running, host: root@e6ed65f77dcc, work_dir: /content/drive/My Drive/mmdetection/work_dirs/faster_rcnn_r50_fpn_1x_coco\n 2020-12-15 13:38:59,283 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n 2020-12-15 13:38:59.488541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n Traceback (most recent call last):\n File \"tools/train.py\", line 181, in \n main()\n File \"tools/train.py\", line 177, in main\n meta=meta)\n File \"/usr/local/lib/python3.6/dist-packages/mmdet-2.7.0-py3.6.egg/mmdet/apis/train.py\", line 150, in train_detector\n runner.run(data_loaders, cfg.workflow, cfg.total_epochs)\n File \"/usr/local/lib/python3.6/dist-packages/mmcv/runner/epoch_based_runner.py\", line 125, in run\n epoch_runner(data_loaders[i], **kwargs)\n File \"/usr/local/lib/python3.6/dist-packages/mmcv/runner/epoch_based_runner.py\", line 47, in train\n for i, data_batch in enumerate(self.data_loader):\n File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 352, in iter\n return self._get_iterator()\n File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 294, in _get_iterator\n return _MultiProcessingDataLoaderIter(self)\n File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 827, in init\n self._reset(loader, first_iter=True)\n File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 857, in _reset\n self._try_put_index()\n File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1091, in _try_put_index\n index = self._next_index()\n File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 427, in _next_index\n return next(self._sampler_iter)  # may raise StopIteration\n File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py\", line 227, in iter\n for idx in self.sampler:\n File \"/usr/local/lib/python3.6/dist-packages/mmdet-2.7.0-py3.6.egg/mmdet/datasets/samplers/group_sampler.py\", line 36, in iter\n indices = np.concatenate(indices)\n File \"<array_function internals>\", line 6, in concatenate\n ValueError: need at least one array to concatenate\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "jevenail", "commentT": "2021-01-04T03:41:06Z", "comment_text": "\n \t\tI modify the CLASSES in ~/mmdetection/mmdet/datasets/coco.py to adapt to my dataset, and do not specify the classes in the config file. It worked. Then I met another error. So I comment out the corresponding code. It start training normally.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "jevenail", "commentT": "2021-01-07T02:49:40Z", "comment_text": "\n \t\t\n I modify the CLASSES in ~/mmdetection/mmdet/datasets/coco.py to adapt to my dataset, and do not specify the classes in the config file. It worked. Then I met another error. So I comment out the corresponding code. It start training normally.\n \n Please tell me how to modify it. Thank you very much\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "jevenail", "commentT": "2021-01-18T01:43:36Z", "comment_text": "\n \t\tWe have updated <denchmark-link:https://github.com/open-mmlab/mmdetection/blob/master/docs/tutorials/customize_dataset.md>docs</denchmark-link>\n  for training your own customized dataset with COCO format.\n There are two steps to train your own customized dataset with COCO format:\n \n Modify the config file for using the customized dataset.\n Check the annotations of the customized dataset.\n \n See <denchmark-link:https://github.com/open-mmlab/mmdetection/blob/master/docs/tutorials/customize_dataset.md>Reorganize new data formats to existing format</denchmark-link>\n  for more detailed suggestions.\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "jevenail", "commentT": "2021-01-21T02:52:48Z", "comment_text": "\n \t\t\n \n I modify the CLASSES in ~/mmdetection/mmdet/datasets/coco.py to adapt to my dataset, and do not specify the classes in the config file. It worked. Then I met another error. So I comment out the corresponding code. It start training normally.\n \n Please tell me how to modify it. Thank you very much\n \n The file ~/mmdetection/mmdet/datasets/coco.py contains the category of coco data set, change it to the category of custom data set\n \t\t"}}}, "commit": {"commit_id": "9b2c208d517534e249bd688f10764beadf5dd1a9", "commit_author": "Qiaofei Li", "commitT": "2021-01-13 10:53:12+08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "docs\\tutorials\\customize_dataset.md", "file_new_name": "docs\\tutorials\\customize_dataset.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "52,53,54,55,56,57,58,59,60,61,62,63,64,69,70,71,72,73,81,83,84,87,89,90,93,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152", "deleted_lines": "52,53,58,59,62,69,70,74,75,79,80,81"}}}}}}