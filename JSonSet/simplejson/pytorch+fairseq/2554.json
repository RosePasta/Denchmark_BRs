{"BR": {"BR_id": "2554", "BR_author": "vadimkantorov", "BRopenT": "2020-09-01T13:17:58Z", "BRcloseT": "2020-10-13T15:11:18Z", "BR_text": {"BRsummary": "get_normalized_probs_scriptable seems broken", "BRdescription": "\n <denchmark-link:https://github.com/pytorch/fairseq/blob/2887663/fairseq/models/fairseq_model.py#L59>https://github.com/pytorch/fairseq/blob/2887663/fairseq/models/fairseq_model.py#L59</denchmark-link>\n :\n   def get_normalized_probs_scriptable(\n         self,\n         net_output: Tuple[Tensor, Optional[Dict[str, List[Optional[Tensor]]]]],\n         log_probs: bool,\n         sample: Optional[Dict[str, Tensor]] = None,\n     ):\n         \"\"\"Scriptable helper function for get_normalized_probs in ~BaseFairseqModel\"\"\"\n         if hasattr(self, \"decoder\"):\n             return self.decoder.get_normalized_probs(net_output, log_probs, sample)\n         elif torch.is_tensor(net_output):\n             logits = net_output.float()\n             if log_probs:\n                 return F.log_softmax(logits, dim=-1)\n             else:\n                 return F.softmax(logits, dim=-1)\n         raise NotImplementedError\n It accepts net_output as tuple and later checks it to be a tensor. Is it okay?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "vadimkantorov", "commentT": "2020-09-03T11:06:36Z", "comment_text": "\n \t\tWhat error message are you experiencing? are you on the latest version of fairseq?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "vadimkantorov", "commentT": "2020-09-03T11:15:12Z", "comment_text": "\n \t\tIt was making the NotImplementedError. I'm no longer using this code path, so my problem is solved, so unfortunately cannot provide any more details. It was a recent master branch. But I thought this might be a bug (either with typing or with if check), so I reported it.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "vadimkantorov", "commentT": "2020-09-04T00:50:56Z", "comment_text": "\n \t\tYeah this looks off. Probably didn't get fully updated when we added types for torchscript.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "vadimkantorov", "commentT": "2020-10-29T11:53:17Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/vadimkantorov>@vadimkantorov</denchmark-link>\n   I am also facing the same problem.\n How did you solve this issue? Which code path did you use for inferencing ?\n Okay the new update from yesterday solved this issue.\n \t\t"}}}, "commit": {"commit_id": "c005362349075fb5952ece139481232cc49e2286", "commit_author": "Myle Ott", "commitT": "2020-10-13 08:10:58-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "fairseq\\distributed_utils.py", "file_new_name": "fairseq\\distributed_utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "387,389,390,391", "deleted_lines": "387,389", "method_info": {"method_name": "_all_reduce_dict", "method_params": "OrderedDict", "method_startline": "384", "method_endline": "391"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "fairseq\\models\\fairseq_model.py", "file_new_name": "fairseq\\models\\fairseq_model.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "72,73", "deleted_lines": null}}}}}}