{"BR": {"BR_id": "1736", "BR_author": "khttknoob", "BRopenT": "2020-07-05T05:17:30Z", "BRcloseT": "2020-07-05T21:35:51Z", "BR_text": {"BRsummary": "Truncation", "BRdescription": "\n Describe the bug\n Getting this warining\n Truncation was not explicitely activated but max_length is provided a specific value, please use truncation=True to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to truncation.\n To Reproduce\n I ran the transformers model a month ago didn't got anything but today getting this warning\n Environment (please complete the following information):\n \n OS [Using Google Colab]\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "khttknoob", "commentT": "2020-07-05T07:35:33Z", "comment_text": "\n \t\tDid you update to transformers 3.0 in the meantime?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "khttknoob", "commentT": "2020-07-05T07:53:32Z", "comment_text": "\n \t\tLooks like this error: <denchmark-link:https://github.com/huggingface/transformers/issues/5505>huggingface/transformers#5505</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "khttknoob", "commentT": "2020-07-06T08:46:26Z", "comment_text": "\n \t\tThis is now fixed in flair 0.5.1!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "khttknoob", "commentT": "2020-07-07T10:52:56Z", "comment_text": "\n \t\tI'm on flair 0.5.1 and transformers 3.0.2 and I still see this warning when using SentenceTransformerDocumentEmbeddings\n \t\t"}}}, "commit": {"commit_id": "93cb4113ae9c4ac70abd405b5b557baeac63871d", "commit_author": "alanakbik", "commitT": "2020-07-05 22:01:33+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "flair\\embeddings\\document.py", "file_new_name": "flair\\embeddings\\document.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "111,112,113", "deleted_lines": "111", "method_info": {"method_name": "_add_embeddings_to_sentences", "method_params": "self", "method_startline": "95", "method_endline": "156"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "flair\\embeddings\\token.py", "file_new_name": "flair\\embeddings\\token.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "960,961,962", "deleted_lines": "960", "method_info": {"method_name": "_add_embeddings_to_sentences", "method_params": "self", "method_startline": "913", "method_endline": "1074"}}}}}}}