{"BR": {"BR_id": "380", "BR_author": "Goofy-G", "BRopenT": "2019-03-11T06:54:49Z", "BRcloseT": "2019-03-11T11:34:57Z", "BR_text": {"BRsummary": "Error while serving nmtsmall model", "BRdescription": "\n Hi\n I trained nmtsmall model by using opennmt 1.21.3. Then I upgradeed to 1.21.4 for exporting model.\n When I used export model serving, I have met this error.\n Error\n Traceback (most recent call last):\n File \"D:\\GNMT\\venv\\lib\\site-packages\\grpc\\beta_client_adaptations.py\", line 95, in result\n return self._future.result(timeout=timeout)\n File \"D:\\GNMT\\venv\\lib\\site-packages\\grpc_channel.py\", line 276, in result\n raise self\n grpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with:\n status = StatusCode.INVALID_ARGUMENT\n details = \"Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\n [[Node: seq2seq/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _class=[\"loc:@seq2seq/cond/strided_slice/Switch\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](seq2seq/decoder_1/strided_slice_17, seq2seq/Reshape_1/shape)]]\n [[Node: seq2seq/decoder_1/while/concat_5/_225 = _Recv<denchmark-link:%5E_cloopseq2seq/decoder_1/while/decoder/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_39>client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1187_seq2seq/decoder_1/while/concat_5\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"</denchmark-link>\n ]]\"\n debug_error_string = \"{\"created\":\"@1552276258.713000000\",\"description\":\"Error received from peer\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1095,\"grpc_message\":\"Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\\n\\t [[Node: seq2seq/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _class=[\"loc:@seq2seq/cond/strided_slice/Switch\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](seq2seq/decoder_1/strided_slice_17, seq2seq/Reshape_1/shape)]]\\n\\t [[Node: seq2seq/decoder_1/while/concat_5/_225 = _Recv<denchmark-link:%5E_cloopseq2seq/decoder_1/while/decoder/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_39>client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1187_seq2seq/decoder_1/while/concat_5\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"</denchmark-link>\n ]]\",\"grpc_status\":3}\"\n \n \n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"C:\\Python35\\Lib\\unittest\\case.py\", line 59, in testPartExecutor\n yield\n File \"C:\\Python35\\Lib\\unittest\\case.py\", line 605, in run\n testMethod()\n File \"D:\\GNMT\\tests\\onmt_rpc_client_test.py\", line 78, in test_request_from_file\n address, result = client.request(line.strip(\"\\n\").split(\" \"))\n File \"D:\\GNMT\\address\\client\\onmt_rpc_client.py\", line 11, in request\n result = self._parse_translation_result(future.result())\n File \"D:\\GNMT\\venv\\lib\\site-packages\\grpc\\beta_client_adaptations.py\", line 97, in result\n raise _abortion_error(rpc_error_call)\n grpc.framework.interfaces.face.face.AbortionError: AbortionError(code=StatusCode.INVALID_ARGUMENT, details=\"Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\n [[Node: seq2seq/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _class=[\"loc:@seq2seq/cond/strided_slice/Switch\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](seq2seq/decoder_1/strided_slice_17, seq2seq/Reshape_1/shape)]]\n [[Node: seq2seq/decoder_1/while/concat_5/_225 = _Recv<denchmark-link:%5E_cloopseq2seq/decoder_1/while/decoder/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_39>client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1187_seq2seq/decoder_1/while/concat_5\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"</denchmark-link>\n ]]\")\n ===============================================================================\n [ERROR]\n Traceback (most recent call last):\n Failure: builtins.tuple: (<class 'grpc.framework.interfaces.face.face.AbortionError'>, AbortionError(), <traceback object at 0x000000001C31D748>)\n <denchmark-h:h2>onmt_rpc_client_test.TestOpenNMTPredictRPCClient.test_request_from_file</denchmark-h>\n \n Ran 1 tests in 45.879s\n FAILED (errors=1)\n Process finished with exit code 1\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Goofy-G", "commentT": "2019-03-11T10:11:59Z", "comment_text": "\n \t\tHi,\n Can you post the configuration file that was used when exporting the model?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Goofy-G", "commentT": "2019-03-11T10:16:44Z", "comment_text": "\n \t\tHi\n Configuration:\n params:\n optimizer: GradientDescentOptimizer\n learning_rate: 1.0\n param_init: 0.1\n clip_gradients: 5.0\n decat_type: exponential_decay\n decay_rate: 0.7\n decay_steps: 50000\n start_decay_steps: 500000\n beam_width: 5\n maximum_iterations: 250\n replace_unknown_target: true\n train:\n batch_size: 64\n bucket_width: 5\n save_checkpoints_steps: 10000\n save_summary_steps: 1000\n train_steps: 1000000\n maximum_features_length: 30\n maximum_labels_length: 30\n sample_buffer_size: -1\n eval:\n batch_size: 32\n num_threads: 4\n eval_delay: 36000\n save_eval_predictions: true\n external_evaluators: BLEU\n exporters: last\n infer:\n batch_size: 32\n num_threads: 1\n n_best: 1\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Goofy-G", "commentT": "2019-03-11T12:29:37Z", "comment_text": "\n \t\tThere was a possible error when the generated alignment vector was empty. You should try re-exporting the model with the latest version and try again.\n \t\t"}}}, "commit": {"commit_id": "760eaa66ddfecc196bf5a765a34eddda2e41c236", "commit_author": "Guillaume Klein", "commitT": "2019-03-11 12:34:56+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "21", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "opennmt\\models\\sequence_to_sequence.py", "file_new_name": "opennmt\\models\\sequence_to_sequence.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "280,281,282", "deleted_lines": "280", "method_info": {"method_name": "_call", "method_params": "self,features,labels,params,mode", "method_startline": "168", "method_endline": "299"}}}}}}}