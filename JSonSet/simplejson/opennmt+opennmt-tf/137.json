{"BR": {"BR_id": "137", "BR_author": "ppetrushkov", "BRopenT": "2018-05-25T14:44:40Z", "BRcloseT": "2018-05-28T07:22:17Z", "BR_text": {"BRsummary": "Synchronous multi-GPU seq2seq training crashes", "BRdescription": "\n I was trying to run a synchronous (with --num_gpus) multi GPU training using SequenceToSequence model, but encountered this error:\n <denchmark-code>InvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[4002,38991] labels_size=[4071,38991]\n          [[Node: seq2seq/parallel_1/seq2seq/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:1\"](seq2seq/parallel_1/seq2seq/Reshape, seq2seq/parallel_1/seq2seq/Reshape_1)]]\n          [[Node: optim/gradients/StackPopV2_1/_2077 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:1\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_4256_optim/gradients/StackPopV2_1\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](optim/gradients/StackPopV2_1/_2076)]]\n </denchmark-code>\n \n My setup is Python 2.6, Tensorflow 1.4, OpenNMT-tf 1.3.0.\n I think I figured out what causes this:\n When a mini-batch is sharded onto multiple devices, it is possible that in one of the shards, decoder sequence_length does not include the longest sentence, to which all other sentences in the mini-batch are padded. However tf.contrib.seq2seq.dynamic_decode truncates its output to the length of the longest sentence in a shard, which may be shorter than the longest sentence in a mini-batch. So the loss receives the sharded logits which are shorter than the corresponding labels, resulting in an error.\n When I pad the logits to the appropriate size the error goes away.\n Here is the full trace from a different run:\n <denchmark-code>Traceback (most recent call last):                                                        \n   File \"/root/tf-1.4/bin/onmt-main\", line 11, in <module>                                 \n     sys.exit(main())                                                                      \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/bin/main.py\", line 120, in main                                                                                       \n     runner.train_and_evaluate()                                                           \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/runner.py\", line 141, in train_and_evaluate                                                                           \n     tf.estimator.train_and_evaluate(self._estimator, train_spec, eval_spec)               \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 430, in train_and_evaluate                                                     \n     executor.run_local()                                                                  \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 609, in run_local                                                              \n     hooks=train_hooks)                                                                    \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train                                                                 \n     loss = self._train_model(input_fn, hooks, saving_listeners)                           \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 783, in _train_model                                                          \n     _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])                \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 521, in run                                                            \n     run_metadata=run_metadata)                                                            \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 892, in run                                                            \n     run_metadata=run_metadata)                                                            \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 967, in run                                                            \n     raise six.reraise(*original_exc_info)                                                 \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 952, in run                                                            \n     return self._sess.run(*args, **kwargs)                                                \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 1024, in run                                                           \n     run_metadata=run_metadata)                                                            \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in run                                                            \n     return self._sess.run(*args, **kwargs)                                                \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 889, in run                                                                        \n     run_metadata_ptr)                                                                     \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1120, in _run                                                                      \n     feed_dict_tensor, options, run_metadata)                                              \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run                                                                   \n     options, run_metadata)                                                                \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call                                                                  \n     raise type(e)(node_def, op, message)                                                  \n tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must be same size: logits_size=[196,101] labels_size=[203,101]                                       \n          [[Node: seq2seq/parallel_1/seq2seq/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](seq2seq/parallel_1/seq2seq/Reshape, seq2seq/parallel_1/seq2seq/Reshape_1)]]                                                                                                                 \n \n Caused by op u'seq2seq/parallel_1/seq2seq/SoftmaxCrossEntropyWithLogits', defined at:     \n   File \"/root/tf-1.4/bin/onmt-main\", line 11, in <module>                                 \n     sys.exit(main())                                                                      \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/bin/main.py\", line 120, in main                                                                                       \n     runner.train_and_evaluate()                                                           \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/runner.py\", line 141, in train_and_evaluate                                                                           \n     tf.estimator.train_and_evaluate(self._estimator, train_spec, eval_spec)               \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 430, in train_and_evaluate                                                     \n     executor.run_local()                                                                  \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/training.py\", line 609, in run_local                                                              \n     hooks=train_hooks)                                                                    \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 302, in train                                                                 \n     loss = self._train_model(input_fn, hooks, saving_listeners)                           \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 711, in _train_model                                                          \n     features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)                           \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py\", line 694, in _call_model_fn                                                        \n     model_fn_results = self._model_fn(features=features, **kwargs)                        \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/models/model.py\", line 88, in _model_fn                                                                               \n     _loss_op, features_shards, labels_shards, params, mode, config)                       \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/utils/parallel.py\", line 150, in __call__                                                                             \n     outputs.append(funs[i](*args[i], **kwargs[i]))                                        \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/models/model.py\", line 52, in _loss_op                                                                                \n     return self._compute_loss(features, labels, logits, params, mode)                     \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/models/sequence_to_sequence.py\", line 229, in _compute_loss                                                           \n     mode=mode)                                                                            \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/utils/losses.py\", line 51, in cross_entropy_sequence_loss                                                             \n     cross_entropy = _softmax_cross_entropy(logits, labels, label_smoothing, mode)         \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/opennmt/utils/losses.py\", line 24, in _softmax_cross_entropy                                                                  \n     logits=logits, labels=smoothed_labels)                                                \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1783, in softmax_cross_entropy_with_logits                                             \n     precise_logits, labels, name=name)                                                    \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4364, in _softmax_cross_entropy_with_logits                                        \n     name=name)                                                                            \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper                                                 \n     op_def=op_def)                                                                        \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op                                                                  \n     op_def=op_def)                                                                        \n   File \"/root/tf-1.4/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__                                                                   \n     self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access    \n \n InvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[196,101] labels_size=[203,101]                                                     \n          [[Node: seq2seq/parallel_1/seq2seq/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](seq2seq/parallel_1/seq2seq/Reshape, seq2seq/parallel_1/seq2seq/Reshape_1)]]\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ppetrushkov", "commentT": "2018-05-25T15:36:28Z", "comment_text": "\n \t\tThanks for the report! I did not know about this behavior of tf.contrib.seq2seq.dynamic_decode (and we mostly tested multi GPU training with Transformer models).\n As you already located the issue, do you mind sendind a PR with your workaround? Thanks.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ppetrushkov", "commentT": "2018-05-25T16:01:23Z", "comment_text": "\n \t\tWell, my workaround is concatenating a bunch of zeroes (which might get pretty large with a big vocabulary), so I doubt this is the best solution...\n On the other hand, I currently don't see a quick and better way to fix it. If you think that workaround is ok, I will write a test and create a PR.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ppetrushkov", "commentT": "2018-05-25T16:12:40Z", "comment_text": "\n \t\tYou could make use of this function on the decoder output to make sure that the time dimension is correct:\n <denchmark-link:http://opennmt.net/OpenNMT-tf/package/opennmt.layers.reducer.html#opennmt.layers.reducer.align_in_time>http://opennmt.net/OpenNMT-tf/package/opennmt.layers.reducer.html#opennmt.layers.reducer.align_in_time</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "9d8c55b23e6715f925abb482266a2bbca94322ec", "commit_author": "ppetrushkov", "commitT": "2018-05-28 09:21:43+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "opennmt\\decoders\\rnn_decoder.py", "file_new_name": "opennmt\\decoders\\rnn_decoder.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "11,136,137,138", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "opennmt\\tests\\decoder_test.py", "file_new_name": "opennmt\\tests\\decoder_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74", "deleted_lines": null, "method_info": {"method_name": "_testDecoderTraining", "method_params": "self,decoder", "method_startline": "47", "method_endline": "74"}}, "hunk_1": {"Ismethod": 1, "added_lines": "76,77,78", "deleted_lines": null, "method_info": {"method_name": "testRNNDecoderTraining", "method_params": "self", "method_startline": "76", "method_endline": "78"}}, "hunk_2": {"Ismethod": 1, "added_lines": "88,89,90", "deleted_lines": null, "method_info": {"method_name": "testSelfAttentionDecoderTraining", "method_params": "self", "method_startline": "88", "method_endline": "90"}}, "hunk_3": {"Ismethod": 1, "added_lines": "84,85,86", "deleted_lines": null, "method_info": {"method_name": "testMultiAttentionalRNNDecoderTraining", "method_params": "self", "method_startline": "84", "method_endline": "86"}}, "hunk_4": {"Ismethod": 1, "added_lines": "80,81,82", "deleted_lines": null, "method_info": {"method_name": "testAttentionalRNNDecoderTraining", "method_params": "self", "method_startline": "80", "method_endline": "82"}}}}}}}