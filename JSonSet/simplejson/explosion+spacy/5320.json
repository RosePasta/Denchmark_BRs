{"BR": {"BR_id": "5320", "BR_author": "bdewilde", "BRopenT": "2020-04-16T17:25:55Z", "BRcloseT": "2020-05-19T14:41:27Z", "BR_text": {"BRsummary": "`Vectors.most_similar()` raises ValueError when query vectors return different num matches", "BRdescription": "\n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n In the case that multiple queries passed in a given call to Vectors.most_similar() return different numbers of results \u2014 fewer than the specified n \u2014 the function fails with a cryptic numpy exception: ValueError: setting an array element with a sequence. Apparently this is raised when you try to create an array from lists of different lengths:\n <denchmark-code>>>> np.array([[1, 2], [1, 2, 3]], dtype=\"int64\")\n ValueError                                Traceback (most recent call last)\n <ipython-input-86-2d17c17be6b1> in <module>\n ----> 1 np.array([[1, 2], [1, 2, 3]], dtype=\"int64\")\n \n ValueError: setting an array element with a sequence.\n </denchmark-code>\n \n I think these lines are causing it \u2014 <denchmark-link:https://github.com/explosion/spaCy/blob/master/spacy/vectors.pyx#L361-L363>https://github.com/explosion/spaCy/blob/master/spacy/vectors.pyx#L361-L363</denchmark-link>\n  \u2014 but can't convince my debugger to dig into the cython. Here's some further evidence:\n <denchmark-code>(Pdb)  vocab.vectors.most_similar(np.asarray([query_vectors[0]]), n=10)[0].shape\n (1, 8)\n (Pdb)  vocab.vectors.most_similar(np.asarray([query_vectors[1]]), n=10)[0].shape\n (1, 10)\n (Pdb)  vocab.vectors.most_similar(np.asarray([query_vectors[2]]), n=10)[0].shape\n (1, 9)\n (Pdb)  vocab.vectors.most_similar(np.asarray([query_vectors[3]]), n=10)[0].shape\n (1, 10)\n (Pdb)  vocab.vectors.most_similar(query_vectors, n=10)\n *** ValueError: setting an array element with a sequence.\n </denchmark-code>\n \n It's possible that this is just a weird edge case, since I'm populating my vocab / vectors table from scratch using a relatively small corpus of (1k docs). But maybe this is a realistic issue for the pre-trained vocab/vectors when n is large.\n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n spaCy version: 2.2.4\n Platform: Darwin-19.3.0-x86_64-i386-64bit\n Python version: 3.7.4\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "bdewilde", "commentT": "2020-04-18T11:56:40Z", "comment_text": "\n \t\tThanks for the report and the detailed analysis!\n Looks like a bug to me, and something we should definitely investigate further.\n Any chance you have a small reproducible code snippet (with a mockup vocab maybe?) that triggers this error? That would help us dig into this faster :-)\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "bdewilde", "commentT": "2020-04-18T18:27:30Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/svlandeg>@svlandeg</denchmark-link>\n  , I came up with a (very haphazard) example that raises this error:\n import gensim\n import numpy as np\n import spacy\n \n lang = \"en\"\n embed_size = 100\n texts = [\n     \"Have you listened to the new Fiona Apple album yet?\",\n     \"I've had it on repeat since yesterday, and wow, it's so so great.\",\n     \"Almost makes the 8-year wait worth it!\",\n ]\n \n spacy_lang = spacy.blank(lang)\n docs = spacy_lang.pipe(texts)\n sents = [[tok.text for tok in doc] for doc in docs]\n # generating custom fasttext word embedding vectors\n ft = gensim.models.fasttext.FastText(\n     sentences=sents,\n     size=embed_size,\n     min_count=1,\n     window=5,\n     iter=5,\n )\n # reset vectors on vocab object w/ desired embedding size\n # see: https://spacy.io/usage/vectors-similarity#custom\n spacy_lang.vocab.reset_vectors(width=embed_size)\n for word in ft.wv.vocab:\n     spacy_lang.vocab.set_vector(word, ft.wv[word])\n     \n query_vectors = np.asarray([spacy_lang.vocab.get_vector(word) for word in [\"music\", \"album\", \"I\"]])\n keys, _, _ = spacy_lang.vocab.vectors.most_similar(query_vectors, n=5)\n Thanks for digging in!\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "bdewilde", "commentT": "2020-04-24T14:01:32Z", "comment_text": "\n \t\tAh, entertaining bugs. Here most_similar is also searching in the empty all-0 padding rows of the internal vectors table (it has some padding so it doesn't have to resize for each new vector, just when it gets full). For \"music\", which isn't assigned a vector in the model so it gets the default all-0 vector, it returns closest matches out of the all-0 padding rows. These individual matches get filtered out because it knows the rows aren't in use, but then you end up with fewer matches for some queries than others.\n \t\t"}}}, "commit": {"commit_id": "40e65d6f6349a55f20f109eb4fbae91489ec54b0", "commit_author": "adrianeboyd", "commitT": "2020-05-19 16:41:26+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\errors.py", "file_new_name": "spacy\\errors.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "567,568", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "spacy\\tests\\regression\\test_issue3001-3500.py", "file_new_name": "spacy\\tests\\regression\\test_issue3001-3500.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "298", "deleted_lines": "298", "method_info": {"method_name": "test_issue3412", "method_params": "", "method_startline": "296", "method_endline": "302"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "spacy\\tests\\vocab_vectors\\test_vectors.py", "file_new_name": "spacy\\tests\\vocab_vectors\\test_vectors.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "63,64", "deleted_lines": null, "method_info": {"method_name": "most_similar_vectors_keys", "method_params": "", "method_startline": "63", "method_endline": "64"}}, "hunk_1": {"Ismethod": 1, "added_lines": "342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367", "deleted_lines": "343", "method_info": {"method_name": "test_vectors_serialize", "method_params": "", "method_startline": "342", "method_endline": "367"}}, "hunk_2": {"Ismethod": 1, "added_lines": "378", "deleted_lines": null, "method_info": {"method_name": "test_vector_is_oov", "method_params": "", "method_startline": "369", "method_endline": "378"}}, "hunk_3": {"Ismethod": 1, "added_lines": null, "deleted_lines": "149,150", "method_info": {"method_name": "test_vectors_most_similar", "method_params": "most_similar_vectors_data", "method_startline": "149", "method_endline": "152"}}, "hunk_4": {"Ismethod": 1, "added_lines": "154,155,159,160", "deleted_lines": null, "method_info": {"method_name": "test_vectors_most_similar", "method_params": "most_similar_vectors_data,most_similar_vectors_keys", "method_startline": "154", "method_endline": "160"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\vectors.pyx", "file_new_name": "spacy\\vectors.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "215,312,313,332,333,334,337,339,361,362,425,468,470,471,472,473", "deleted_lines": "215,216,313,314,335,337,359"}}}}}}