{"BR": {"BR_id": "484", "BR_author": "briankosw", "BRopenT": "2020-12-26T01:34:37Z", "BRcloseT": "2021-01-18T10:24:26Z", "BR_text": {"BRsummary": "VOCDetectionDataModule fails to load", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n I tried to use VOCDetectionDataModule, and it seems that I fails to properly load the dataset because of the problems with multiprocessing. See the below minimal repro.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n >>> from pl_bolts.datamodules import VOCDetectionDataModule\n >>> datamodule = VOCDetectionDataModule(data_dir=data_dir, num_workers=2)\n >>> datamodule.prepare_data()\n >>> train_loader = datamodule.train_dataloader(batch_size=1)\n >>> next(iter(train_loader))\n ---------------------------------------------------------------------------\n AttributeError                            Traceback (most recent call last)\n <ipython-input-22-0fd2476fd2ff> in <module>\n ----> 1 next(iter(train_loader))\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/site-packages/torch/utils/data/dataloader.py in __iter__(self)\n     350             return self._iterator\n     351         else:\n --> 352             return self._get_iterator()\n     353\n     354     @property\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/site-packages/torch/utils/data/dataloader.py in _get_iterator(self)\n     292             return _SingleProcessDataLoaderIter(self)\n     293         else:\n --> 294             return _MultiProcessingDataLoaderIter(self)\n     295\n     296     @property\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/site-packages/torch/utils/data/dataloader.py in __init__(self, loader)\n     799             #     before it starts, and __del__ tries to join but will get:\n     800             #     AssertionError: can only join a started process.\n --> 801             w.start()\n     802             self._index_queues.append(index_queue)\n     803             self._workers.append(w)\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/multiprocessing/process.py in start(self)\n     119                'daemonic processes are not allowed to have children'\n     120         _cleanup()\n --> 121         self._popen = self._Popen(self)\n     122         self._sentinel = self._popen.sentinel\n     123         # Avoid a refcycle if the target function holds an indirect\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/multiprocessing/context.py in _Popen(process_obj)\n     222     @staticmethod\n     223     def _Popen(process_obj):\n --> 224         return _default_context.get_context().Process._Popen(process_obj)\n     225\n     226 class DefaultContext(BaseContext):\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/multiprocessing/context.py in _Popen(process_obj)\n     282         def _Popen(process_obj):\n     283             from .popen_spawn_posix import Popen\n --> 284             return Popen(process_obj)\n     285\n     286     class ForkServerProcess(process.BaseProcess):\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/multiprocessing/popen_spawn_posix.py in __init__(self, process_obj)\n      30     def __init__(self, process_obj):\n      31         self._fds = []\n ---> 32         super().__init__(process_obj)\n      33\n      34     def duplicate_for_child(self, fd):\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/multiprocessing/popen_fork.py in __init__(self, process_obj)\n      17         self.returncode = None\n      18         self.finalizer = None\n ---> 19         self._launch(process_obj)\n      20\n      21     def duplicate_for_child(self, fd):\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/multiprocessing/popen_spawn_posix.py in _launch(self, process_obj)\n      45         try:\n      46             reduction.dump(prep_data, fp)\n ---> 47             reduction.dump(process_obj, fp)\n      48         finally:\n      49             set_spawning_popen(None)\n \n ~/anaconda3/envs/lightning-bolts/lib/python3.8/multiprocessing/reduction.py in dump(obj, file, protocol)\n      58 def dump(obj, file, protocol=None):\n      59     '''Replacement for pickle.dump() using ForkingPickler.'''\n ---> 60     ForkingPickler(file, protocol).dump(obj)\n      61\n      62 #\n \n AttributeError: Can't pickle local object 'VOCDetectionDataModule._default_transforms.<locals>.<lambda>'\n If num_workers=0, then the above repro works perfectly fine. It's when num_workers>0 that the repro fails.\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n PyTorch Version (e.g., 1.0): 1.7\n OS (e.g., Linux): macOS\n How you installed PyTorch (conda, pip, source): pip\n Build command you used (if compiling from source):\n Python version: 3.8.6\n CUDA/cuDNN version: N/A\n GPU models and configuration: N/A\n Any other relevant information:\n PyTorch Lightning: 1.1.2\n PyTorch Lightning Bolts: 0.2.5\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "briankosw", "commentT": "2020-12-26T03:06:05Z", "comment_text": "\n \t\tIf we run in terminal like python -m train ... with num_workers>0, this will also be fine. But if we are working in Jupyter or IPython, it seems that we must set num_workers=0. Maybe this is not a bug?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "briankosw", "commentT": "2020-12-26T03:48:44Z", "comment_text": "\n \t\tI get the error when running in the terminal, so I'm not sure what's wrong. I manually reproduced this error by attempting to pickle the lambda function:\n import pickle\n import torchvision.transforms as transforms\n transform = lambda image, target: (transforms.ToTensor()(image), target)\n pickle.dumps(transform)\n I get the following error:\n <denchmark-code>---------------------------------------------------------------------------\n PicklingError                             Traceback (most recent call last)\n <ipython-input-4-a283fa50ceb5> in <module>\n ----> 1 pickle.dumps(transform)\n \n PicklingError: Can't pickle <function <lambda> at 0x7fe6b6b3f430>: attribute lookup <lambda> on __main__ failed\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "briankosw", "commentT": "2020-12-27T15:25:19Z", "comment_text": "\n \t\tAre torchvision transforms (especially lambda) pickleable ? I'm not sure.. They are JIT scriptable since 0.8.1 +. .\n Have a look at <denchmark-link:https://stackoverflow.com/questions/25348532/can-python-pickle-lambda-functions>this</denchmark-link>\n  thread.\n Posting a thread from the above link.\n <denchmark-code>what worked for me (windows 10, python 3.7) was to pass a function instead of a lambda function:\n \n def merge(x):\n     return Image.merge(\"RGB\", x.split()[::-1])\n \n transforms.Lambda(merge)\n \n instead of:\n \n transforms.Lambda(lambda x: Image.merge(\"RGB\", x.split()[::-1]))\n </denchmark-code>\n \n Also IIRC this bug occurs on Windows especially, we cannot pickle lambda objects. I really don't remember the thread but read somewhere in PyTorch discussions.\n Another <denchmark-link:https://stackoverflow.com/questions/64347217/error-pickle-picklingerror-cant-pickle-function-lambda-at-0x0000002f2175b>thread</denchmark-link>\n  that points this (Almost exactly what we are doing here).\n I think this is MacOS + Windows issue, I have tried to reproduce over linux as below.\n I ran the following on Linux, Ubuntu 20.04, torch 1.7.1, torchvision 0.8.2 and could not get any error.\n <denchmark-code>import pickle\n import torchvision.transforms as transforms\n import torch\n \n if __name__ == \"main\":\n     image = torch.randn(3, 224, 224)\n     target = torch.randn(1, 10)\n     transform = lambda image, target: (transforms.ToTensor()(image), target)\n     pickle.dumps(transform)\n \n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "briankosw", "commentT": "2020-12-27T15:55:20Z", "comment_text": "\n \t\tHm it does seem that you're absolutely on the money, since I ran your script on my computer (macOS) and I get the pickle error still. I'll try to narrow down the root cause of failure so that we can properly address this. I do think that the VOC detection data module implementation can avoid using  as well as be improved in general in certain ways. What do you think <denchmark-link:https://github.com/oke-aditya>@oke-aditya</denchmark-link>\n ?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "briankosw", "commentT": "2020-12-27T16:11:28Z", "comment_text": "\n \t\tLet's see, but I tihnk we can avoid lamda I think from <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning-bolts/blob/master/pl_bolts/datamodules/vocdetection_datamodule.py#L204>line</denchmark-link>\n \n Let's hear from <denchmark-link:https://github.com/Borda>@Borda</denchmark-link>\n  and <denchmark-link:https://github.com/akihironitta>@akihironitta</denchmark-link>\n  .\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "briankosw", "commentT": "2021-01-06T08:05:33Z", "comment_text": "\n \t\tI saw a similar issue yesterday in PL example with Windows, and strange that it was such for a very long time and suddenly appeared yesterday... see: <denchmark-link:https://stackoverflow.com/a/59680818/4521646>https://stackoverflow.com/a/59680818/4521646</denchmark-link>\n \n \n Let's see, but I tihnk we can avoid lamda I think from line\n \n yes, let's replace the lambda function :] <denchmark-link:https://github.com/briankosw>@briankosw</denchmark-link>\n  want to take it over?\n \t\t"}}}, "commit": {"commit_id": "67ebfe0ab6914187c013251fff490b30b24faa1a", "commit_author": "Brian Ko", "commitT": "2021-01-18 10:13:54+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 8, "file_old_name": "pl_bolts\\datamodules\\vocdetection_datamodule.py", "file_new_name": "pl_bolts\\datamodules\\vocdetection_datamodule.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "20,22", "deleted_lines": "20", "method_info": {"method_name": "__init__", "method_params": "self,transforms,image_transforms", "method_startline": "20", "method_endline": "22"}}, "hunk_1": {"Ismethod": 1, "added_lines": "152,160,161,162", "deleted_lines": "149,157,158,159,160,161,162", "method_info": {"method_name": "train_dataloader", "method_params": "self,batch_size,transforms", "method_startline": "149", "method_endline": "173"}}, "hunk_2": {"Ismethod": 1, "added_lines": "27,28", "deleted_lines": null, "method_info": {"method_name": "__call__", "method_params": "self,image,target", "method_startline": "24", "method_endline": "29"}}, "hunk_3": {"Ismethod": 1, "added_lines": "152,160,161,162", "deleted_lines": "157,158,159,160,161,162", "method_info": {"method_name": "train_dataloader", "method_params": "self,batch_size,image_transforms", "method_startline": "152", "method_endline": "173"}}, "hunk_4": {"Ismethod": 1, "added_lines": "200,201,202,203,204,205,206", "deleted_lines": "202,203,204,205,206", "method_info": {"method_name": "_default_transforms", "method_params": "self", "method_startline": "198", "method_endline": "206"}}, "hunk_5": {"Ismethod": 1, "added_lines": "20", "deleted_lines": "20", "method_info": {"method_name": "__init__", "method_params": "self,transforms", "method_startline": "20", "method_endline": "21"}}, "hunk_6": {"Ismethod": 1, "added_lines": "175,183,184,185", "deleted_lines": "175,183,184,185,186,187", "method_info": {"method_name": "val_dataloader", "method_params": "self,batch_size,transforms", "method_startline": "175", "method_endline": "198"}}, "hunk_7": {"Ismethod": 1, "added_lines": "175,183,184,185", "deleted_lines": "175,183,184,185,186,187", "method_info": {"method_name": "val_dataloader", "method_params": "self,batch_size,image_transforms", "method_startline": "175", "method_endline": "196"}}}}}}}