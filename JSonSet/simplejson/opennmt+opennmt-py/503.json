{"BR": {"BR_id": "503", "BR_author": "abaheti95", "BRopenT": "2018-01-08T18:46:05Z", "BRcloseT": "2018-09-05T09:45:43Z", "BR_text": {"BRsummary": "Warn users not to use special symbols.", "BRdescription": "\n Hi all,\n I have used the following format in my data\n <denchmark-code>BOS = '<s>'\n EOS = '</s>'\n UNK = '<unk>'\n </denchmark-code>\n \n All of my data is in the following format\n <s> w w w <unk> w <unk> </s>\n where w represents various words. But now when I try to translate the decoder prints  multiple times. For example\n <denchmark-code>PRED 15: <s> le </s> </s> </s> </s> T30\n PRED SCORE: -10.3222\n </denchmark-code>\n \n How do I explicitly specify these in the parameters? Or if I cannot specify them how should I organize my data in OpenNMT?\n \n \n \n OpenNMT-py/onmt/translate/Beam.py\n \n \n          Line 18\n       in\n       af24c9b\n \n \n \n \n \n \n  def __init__(self, size, pad, bos, eos, \n \n \n \n \n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "abaheti95", "commentT": "2018-01-08T23:44:49Z", "comment_text": "\n \t\tEos and bos are automatically added to data, you dont need to add them manually.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "abaheti95", "commentT": "2018-01-08T23:46:30Z", "comment_text": "\n \t\tSee onmt.io.TextDataset.get_fields and torchtext.data.fields.Fields for detail.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "abaheti95", "commentT": "2018-01-09T02:57:09Z", "comment_text": "\n \t\tSo why do some predictions have more than one eos symbol?? Is it because of the replace_unk flag??\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "abaheti95", "commentT": "2018-01-09T17:28:33Z", "comment_text": "\n \t\tIn perspective of human eyes, your symbols are identical to default special symbols used in OPENNMT.\n However,\n \n torchtext 0.3 adds preprocessing step which decodes all corpus tokens to UNICODE format.\n special symbols in OpenNMT are directly passed to field opjects, so they are NOT decoded into UNICODE format.\n that means, default symbols are not unicode, your special symbols in corpus are unicode. So the system recognize them as distinct symbols.\n for example, dictionary would looks like: {\"<unk>\": 0,  \"<blank>\" : 1, \"<s>\" : 2, \"</s>\": 3, ... ... u'</s>' : k ...}, so actually </s> in your corpus is u'</s>', which is not considered as stop symbol.\n \n Just remove them from corpus, and it will be solved.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "abaheti95", "commentT": "2018-01-09T17:36:16Z", "comment_text": "\n \t\tSo what should be the format of my data?\n No start and end symbol in the data?\n For example\n <s> Hi , I am <unk> </s> to Hi , I am <unk> in the data file?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "abaheti95", "commentT": "2018-01-09T17:38:32Z", "comment_text": "\n \t\tYou don't need to convert them to any format, tokenized plain text would be fine. Words with frequency rank lower than max_vocab_size will be automatically replaced with <unk>, you don't needed to convert them manually.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "abaheti95", "commentT": "2018-01-09T19:10:02Z", "comment_text": "\n \t\tBut what if I have preprocessed data from some other application? When I have  marked in my corpus already. How do I specify those  to OpenNMT?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "abaheti95", "commentT": "2018-01-09T19:21:02Z", "comment_text": "\n \t\tThey are declared in onmt/io/DatasetBase.py.\n You can change them to uncode format.\n But still, your translation result will contains start symbols.\n I suggest do pre-processing again.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "abaheti95", "commentT": "2018-01-09T19:27:30Z", "comment_text": "\n \t\tThe problem with that is that the data I have is collected by a totally different project so all I have is the preprocessed data. So do I have to change the preprocessing code to enforce OpenNMT to recognize the s?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "abaheti95", "commentT": "2018-01-09T19:33:34Z", "comment_text": "\n \t\tYou can remove start and end symbols from your file by additional pre-processing, and modify the default <unk> symbol to unicode format, that would be fine.\n I think that's quite simple to do.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "abaheti95", "commentT": "2018-01-10T03:32:17Z", "comment_text": "\n \t\tYeah, you should not use , ,  in your code.\n We should throw an error when we see them. I will add that to our preprocessing code.\n \t\t"}}}, "commit": {"commit_id": "7fb5e9256e0e9ddab8ec7854fdf11fcdb5717a45", "commit_author": "Paul Tardy", "commitT": "2018-09-05 11:45:43+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onmt\\inputters\\dataset_base.py", "file_new_name": "onmt\\inputters\\dataset_base.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83", "deleted_lines": "64,65,66,67,68,69,70,71,72,73,74", "method_info": {"method_name": "extract_text_features", "method_params": "tokens", "method_startline": "53", "method_endline": "83"}}}}}}}