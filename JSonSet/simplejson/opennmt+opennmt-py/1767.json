{"BR": {"BR_id": "1767", "BR_author": "ziyanyang", "BRopenT": "2020-04-01T03:51:18Z", "BRcloseT": "2020-04-03T07:53:21Z", "BR_text": {"BRsummary": "'Field' object has no attribute 'vocab'", "BRdescription": "\n Hi,\n I'm trying to do domain adaptation as described here(<denchmark-link:https://github.com/OpenNMT/OpenNMT-py/issues/768>#768</denchmark-link>\n ). I want to finetune a pre-trained model (from <denchmark-link:https://opennmt.net/Models-py/>https://opennmt.net/Models-py/</denchmark-link>\n ) using multi30k and follow the instructions to pre-process the data here(<denchmark-link:https://opennmt.net/OpenNMT-py/extended.html>https://opennmt.net/OpenNMT-py/extended.html</denchmark-link>\n ). However, when I retrain the model using:\n CUDA_VISIBLE_DEVICES=1,2 python train.py -world_size 2 -gpu_ranks 0 1 -batch_size 64 -encoder_type brnn -rnn_size 500 -save_model available_models/multi30k_finetune -data data/multi30k.atok.low -reset_optim keep_states -train_from available_models/iwslt-brnn2.s131_acc_62.71_ppl_7.74_e20.pt -learning_rate 0.1\n I get the error as:\n [2020-03-31 23:34:16,775 INFO] Loading dataset from data/multi30k.atok.low.train.0.pt\n [2020-03-31 23:34:17,091 INFO] number of examples: 29000\n [2020-03-31 23:34:17,474 INFO] Loading checkpoint from available_models/iwslt-brnn2.s131_acc_62.71_ppl_7.74_e20.pt\n [2020-03-31 23:34:17,771 INFO] Loading vocab from checkpoint at available_models/iwslt-brnn2.s131_acc_62.71_ppl_7.74_e20.pt.\n [2020-03-31 23:34:17,771 INFO]  * src vocab size = 35444\n [2020-03-31 23:34:17,771 INFO]  * tgt vocab size = 24725\n [2020-03-31 23:34:17,771 INFO] Building model...\n Process SpawnProcess-3:\n Traceback (most recent call last):\n File \"/zf18/zy3cx/ENTER/envs/rnn_language_model/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n self.run()\n File \"/zf18/zy3cx/ENTER/envs/rnn_language_model/lib/python3.7/multiprocessing/process.py\", line 99, in run\n self._target(*self._args, **self._kwargs)\n File \"/net/zf18/zy3cx/OpenNMT-py/onmt/bin/train.py\", line 115, in batch_producer\n b = next_batch(0)\n File \"/net/zf18/zy3cx/OpenNMT-py/onmt/bin/train.py\", line 111, in next_batch\n new_batch = next(generator_to_serve)\n File \"/net/zf18/zy3cx/OpenNMT-py/onmt/inputters/inputter.py\", line 822, in iter\n for batch in self._iter_dataset(path):\n File \"/net/zf18/zy3cx/OpenNMT-py/onmt/inputters/inputter.py\", line 804, in _iter_dataset\n for batch in cur_iter:\n File \"/net/zf18/zy3cx/OpenNMT-py/onmt/inputters/inputter.py\", line 695, in iter\n self.device)\n File \"/zf18/zy3cx/ENTER/envs/rnn_language_model/lib/python3.7/site-packages/torchtext/data/batch.py\", line 34, in init\n setattr(self, name, field.process(batch, device=device))\n File \"/zf18/zy3cx/ENTER/envs/rnn_language_model/lib/python3.7/site-packages/torchtext/data/field.py\", line 237, in process\n tensor = self.numericalize(padded, device=device)\n File \"/zf18/zy3cx/ENTER/envs/rnn_language_model/lib/python3.7/site-packages/torchtext/data/field.py\", line 338, in numericalize\n arr = [self.vocab.stoi[x] for x in arr]\n File \"/zf18/zy3cx/ENTER/envs/rnn_language_model/lib/python3.7/site-packages/torchtext/data/field.py\", line 338, in \n arr = [self.vocab.stoi[x] for x in arr]\n AttributeError: 'Field' object has no attribute 'vocab'\n Does anyone meet similar problem? The vocab in iwslt-brnn2.s131_acc_62.71_ppl_7.74_e20.pt is an 'old style vocab', and I'm not sure if it makes the error.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ziyanyang", "commentT": "2020-04-01T15:53:01Z", "comment_text": "\n \t\tHmm not sure if this is linked but you would need to preprocess with the same vocab as the one of the model if you want to -train_from it.\n You can retrieve it from the checkpoint:\n <denchmark-code>import torch\n checkpoint = torch.load(<checkpoint.pt>)\n torch.save(checkpoint['vocab'], \"vocab.pt\")\n </denchmark-code>\n \n And then preprocess using -src_vocab \"vocab.pt\".\n (Only -src_vocabis necessary here, as both src and tgt vocabs are stored in the .pt file.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ziyanyang", "commentT": "2020-04-01T20:00:24Z", "comment_text": "\n \t\t\n Hmm not sure if this is linked but you would need to preprocess with the same vocab as the one of the model if you want to -train_from it.\n You can retrieve it from the checkpoint:\n import torch\n checkpoint = torch.load(<checkpoint.pt>)\n torch.save(checkpoint['vocab'], \"vocab.pt\")\n \n And then preprocess using -src_vocab \"vocab.pt\".\n (Only -src_vocabis necessary here, as both src and tgt vocabs are stored in the .pt file.\n \n Thank you for the suggestion. I tried it, but the error still exists.\n I found the pre-trained model's vocab has only [('src', <torchtext.vocab.Vocab object at 0x7f2968601750>), ('tgt', <torchtext.vocab.Vocab object at 0x7f28f3d45d10>)] two parts. However, in onmt/inputters/inputter.py line 692: yield torchtext.data.Batch(minibatch, self.dataset, self.device), the self.dataset will have dict_keys(['src', 'tgt', 'indices', 'corpus_id']) four fields. The last field 'corpus_id' is not built in the pre-trained model's vocab. The error AttributeError: 'Field' object has no attribute 'vocab' indicates this problem.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ziyanyang", "commentT": "2020-04-01T20:53:39Z", "comment_text": "\n \t\tOh yes, this field was added in <denchmark-link:https://github.com/OpenNMT/OpenNMT-py/pull/1732>#1732</denchmark-link>\n .\n We probably need to add a patch for such a case.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "ziyanyang", "commentT": "2020-04-02T14:25:45Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/ziyanyang>@ziyanyang</denchmark-link>\n \n <denchmark-link:https://github.com/OpenNMT/OpenNMT-py/pull/1769>#1769</denchmark-link>\n  should fix this.\n Would you mind checking it's all good on your end before I merge?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "ziyanyang", "commentT": "2020-04-02T19:31:09Z", "comment_text": "\n \t\t\n Hey @ziyanyang\n #1769 should fix this.\n Would you mind checking it's all good on your end before I merge?\n \n Hi, in train.py the function patch_fields(opt, fields) will get the error as AttributeError: 'list' object has no attribute 'get'.\n This is because in function patch_fields: dvocab = torch.load(opt.data + '.vocab.pt') will try to load the vocab of the new data, but actually if I process the new data with old vocab, the new data's vocab will be the same as the old data's vocab. Therefore, this step will load the same vocab which is a list instead of a dictionary and still do not have 'corpus_id'.\n Is 'corpus_id' the same for most the text data? It includes {'': 0, '': 1, 'train': 2} in multi30k(using its own generated vocab). Is it only used to indicate the type of data?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "ziyanyang", "commentT": "2020-04-02T19:51:31Z", "comment_text": "\n \t\t\n Is 'corpus_id' the same for most the text data? It includes {'': 0, '': 1, 'train': 2} in multi30k(using its own generated vocab). Is it only used to indicate the type of data?\n \n It's for when we use multiple datasets (-data_ids / -train_ids). The corpus_id field was added in <denchmark-link:https://github.com/OpenNMT/OpenNMT-py/pull/1732>#1732</denchmark-link>\n  to track from which corpus each example orgiginate, and apply noise on only examples from some of those datasets. It will probably also be useful in the future to apply different treatment to different datasets.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "ziyanyang", "commentT": "2020-04-02T20:08:40Z", "comment_text": "\n \t\tOk, I just updated the PR. In preprocess, we will now add the corpus_id field to the existing vocab. And it will also update it to the 'new' dict format.\n Let me know if that works for you!\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "ziyanyang", "commentT": "2020-04-03T04:13:03Z", "comment_text": "\n \t\t\n Ok, I just updated the PR. In preprocess, we will now add the corpus_id field to the existing vocab. And it will also update it to the 'new' dict format.\n Let me know if that works for you!\n \n It works fine now. Thank you so much!\n \t\t"}}}, "commit": {"commit_id": "c20dbeac02688918607637f5f30ec73c0f17d817", "commit_author": "Fran\u00e7ois Hernandez", "commitT": "2020-04-03 09:53:21+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "onmt\\bin\\preprocess.py", "file_new_name": "onmt\\bin\\preprocess.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "18,19,20,212,213,214,215,216,217,218,220,223,224,225,226,227,228,229,230,231,232", "deleted_lines": "18,211,212,213,214,215,216,217"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onmt\\bin\\train.py", "file_new_name": "onmt\\bin\\train.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "45,46,47", "deleted_lines": null, "method_info": {"method_name": "train", "method_params": "opt", "method_startline": "20", "method_endline": "93"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onmt\\inputters\\inputter.py", "file_new_name": "onmt\\inputters\\inputter.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "192,193,194,195,196", "deleted_lines": null, "method_info": {"method_name": "patch_fields", "method_params": "opt,fields", "method_startline": "192", "method_endline": "196"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onmt\\train_single.py", "file_new_name": "onmt\\train_single.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "72,73,74", "deleted_lines": null, "method_info": {"method_name": "main", "method_params": "opt,device_id,batch_queue,semaphore", "method_startline": "42", "method_endline": "149"}}}}}}}