{"BR": {"BR_id": "45746", "BR_author": "kkoehncke", "BRopenT": "2020-10-02T17:04:15Z", "BRcloseT": "2020-12-03T19:54:54Z", "BR_text": {"BRsummary": "MKLDNN Segmentation Fault on backward pass on CPU with Conv1D layer", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n A segmentation fault and / or indefinite hanging occurs when using the Conv1D layer with varying kernel sizes. Based on my investigation, this occurs during the backward pass and is related to the MKLDNN back-end used for optimizing CPU operations.\n <denchmark-h:h2>To Reproduce</denchmark-h>\n \n The below code snippet shows this behavior:\n <denchmark-code>import torch\n import torch.nn as nn\n import torch.nn.functional as F\n \n class Model(nn.Module):\n     def __init__(self):\n         super(Model, self).__init__()\n         self.embedding_size = 16\n         self.filter_num = 512\n         self.padding_length = 25\n         self.convolutions = nn.ModuleList([nn.Conv1d(1, self.filter_num // 8, kernel_size=(K, self.embedding_size), stride=1) for K in range(1, 9)])\n \n     def forward(self):\n         X = torch.randn([300, 1, self.padding_length, self.embedding_size])\n         X = [torch.tanh(convolution(X).squeeze(3)) for convolution in self.convolutions]\n         X = [F.max_pool1d(x, x.size(2)).squeeze(2) for x in X]\n         X = torch.cat(X, dim=1)\n         return X\n \n if __name__ == \"__main__\":\n     model = Model()\n     output = model()\n     output.mean().backward()\n </denchmark-code>\n \n <denchmark-h:h2>Expected behavior</denchmark-h>\n \n I expect that this code would execute without error on CPU.\n <denchmark-h:h2>Environment</denchmark-h>\n \n Using a Intel\u00ae Core\u2122 i7-9800X CPU @ 3.80GHz\n <denchmark-code>PyTorch version: 1.6.0\n Is debug build: No\n CUDA used to build PyTorch: 10.2\n \n OS: Ubuntu 18.04.4 LTS\n GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n CMake version: Could not collect\n \n Python version: 3.7\n Is CUDA available: Yes\n CUDA runtime version: Could not collect\n GPU models and configuration: GPU 0: GeForce RTX 2080 Ti\n Nvidia driver version: 440.100\n cuDNN version: Could not collect\n \n Versions of relevant libraries:\n [pip3] numpy==1.19.1\n [pip3] numpydoc==1.1.0\n [pip3] pytorch-memlab==0.1.0\n [pip3] torch==1.6.0\n [pip3] torchvision==0.7.0\n [conda] blas                      1.0                         mkl  \n [conda] cudatoolkit               10.2.89              hfd86e86_1  \n [conda] mkl                       2020.2                      256  \n [conda] mkl-service               2.3.0            py37he904b0f_0  \n [conda] mkl_fft                   1.2.0            py37h23d657b_0  \n [conda] mkl_random                1.1.1            py37h0573a6f_0  \n [conda] numpy                     1.18.4                   pypi_0    pypi\n [conda] numpy-base                1.19.1           py37hfa32c7d_0  \n [conda] numpydoc                  1.1.0                      py_0  \n [conda] pytorch                   1.6.0           py3.7_cuda10.2.89_cudnn7.6.5_0    pytorch\n [conda] pytorch-memlab            0.1.0                    pypi_0    pypi\n [conda] torchvision               0.7.0                py37_cu102    pytorch\n </denchmark-code>\n \n <denchmark-h:h2>Additional context</denchmark-h>\n \n This problem does not occur when done on GPU.\n When turning off the MKLDNN backend via torch.backends.mkldnn.enabled = False, example executes without error.\n When self.embedding_size is >= 14, the example produces a seg-fault. Any lower integer value executes successfully.\n When running the above code snippet with MKLDNN_VERBOSE=1, the following stack trace is produced:\n <denchmark-code>dnnl_verbose,info,oneDNN v1.5.0 (commit e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n dnnl_verbose,info,cpu,runtime:OpenMP\n dnnl_verbose,info,cpu,isa:Intel AVX-512 with AVX512BW, AVX512VL, and AVX512DQ extensions\n dnnl_verbose,info,gpu,runtime:none\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb16a:f0,,,64x1x1x16,0.00195312\n dnnl_verbose,exec,cpu,convolution,jit:avx512_common,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb16a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd16b:f0,scratchpad_mode:user;,alg:convolution_direct,mb300_ic1oc64_ih25oh25kh1sh1dh0ph0_iw16ow1kw16sw1dw0pw0,0.908203\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd16b:f0 dst_f32::blocked:abcd:f0,,,300x64x25x1,0.529053\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb16a:f0,,,64x1x2x16,0.0151367\n dnnl_verbose,exec,cpu,convolution,jit:avx512_common,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb16a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd16b:f0,scratchpad_mode:user;,alg:convolution_direct,mb300_ic1oc64_ih25oh24kh2sh1dh0ph0_iw16ow1kw16sw1dw0pw0,0.844971\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd16b:f0 dst_f32::blocked:abcd:f0,,,300x64x24x1,0.456055\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb16a:f0,,,64x1x3x16,0.00610352\n dnnl_verbose,exec,cpu,convolution,jit:avx512_common,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb16a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd16b:f0,scratchpad_mode:user;,alg:convolution_direct,mb300_ic1oc64_ih25oh23kh3sh1dh0ph0_iw16ow1kw16sw1dw0pw0,0.763916\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd16b:f0 dst_f32::blocked:abcd:f0,,,300x64x23x1,0.393799\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb16a:f0,,,64x1x4x16,0.00585938\n dnnl_verbose,exec,cpu,convolution,jit:avx512_common,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb16a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd16b:f0,scratchpad_mode:user;,alg:convolution_direct,mb300_ic1oc64_ih25oh22kh4sh1dh0ph0_iw16ow1kw16sw1dw0pw0,1.00586\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd16b:f0 dst_f32::blocked:abcd:f0,,,300x64x22x1,0.0761719\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb16a:f0,,,64x1x5x16,0.00610352\n dnnl_verbose,exec,cpu,convolution,jit:avx512_common,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb16a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd16b:f0,scratchpad_mode:user;,alg:convolution_direct,mb300_ic1oc64_ih25oh21kh5sh1dh0ph0_iw16ow1kw16sw1dw0pw0,1.39478\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd16b:f0 dst_f32::blocked:abcd:f0,,,300x64x21x1,0.406982\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb16a:f0,,,64x1x6x16,0.00708008\n dnnl_verbose,exec,cpu,convolution,jit:avx512_common,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb16a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd16b:f0,scratchpad_mode:user;,alg:convolution_direct,mb300_ic1oc64_ih25oh20kh6sh1dh0ph0_iw16ow1kw16sw1dw0pw0,1.36694\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd16b:f0 dst_f32::blocked:abcd:f0,,,300x64x20x1,0.0708008\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb16a:f0,,,64x1x7x16,0.0090332\n dnnl_verbose,exec,cpu,convolution,jit:avx512_common,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb16a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd16b:f0,scratchpad_mode:user;,alg:convolution_direct,mb300_ic1oc64_ih25oh19kh7sh1dh0ph0_iw16ow1kw16sw1dw0pw0,1.31787\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd16b:f0 dst_f32::blocked:abcd:f0,,,300x64x19x1,0.0649414\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:Acdb16a:f0,,,64x1x8x16,0.00708008\n dnnl_verbose,exec,cpu,convolution,jit:avx512_common,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb16a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd16b:f0,scratchpad_mode:user;,alg:convolution_direct,mb300_ic1oc64_ih25oh18kh8sh1dh0ph0_iw16ow1kw16sw1dw0pw0,1.46704\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd16b:f0 dst_f32::blocked:abcd:f0,,,300x64x18x1,0.310059\n dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:abcd:f0 dst_f32::blocked:aBcd16b:f0,,,300x64x18x1,0.0441895\n Segmentation fault (core dumped)\n </denchmark-code>\n \n torch.config:\n <denchmark-code>PyTorch built with:\n   - GCC 7.3\n   - C++ Version: 201402\n   - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n   - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n   - OpenMP 201511 (a.k.a. OpenMP 4.5)\n   - NNPACK is enabled\n   - CPU capability usage: AVX2\n   - CUDA Runtime 10.2\n   - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n   - CuDNN 7.6.5\n   - Magma 2.5.2\n   - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n </denchmark-code>\n \n cc <denchmark-link:https://github.com/ezyang>@ezyang</denchmark-link>\n  <denchmark-link:https://github.com/gchanan>@gchanan</denchmark-link>\n  <denchmark-link:https://github.com/zou3519>@zou3519</denchmark-link>\n  <denchmark-link:https://github.com/bdhirsh>@bdhirsh</denchmark-link>\n  <denchmark-link:https://github.com/ejguan>@ejguan</denchmark-link>\n  <denchmark-link:https://github.com/gujinghui>@gujinghui</denchmark-link>\n  <denchmark-link:https://github.com/PenghuiCheng>@PenghuiCheng</denchmark-link>\n  <denchmark-link:https://github.com/XiaobingSuper>@XiaobingSuper</denchmark-link>\n  <denchmark-link:https://github.com/jianyuh>@jianyuh</denchmark-link>\n  <denchmark-link:https://github.com/VitalyFedyunin>@VitalyFedyunin</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "kkoehncke", "commentT": "2020-10-13T02:16:52Z", "comment_text": "\n \t\tCan't repro with mkldnn 1.6.0. Also, can you provide information about your cpu? Does is have avx512?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "kkoehncke", "commentT": "2020-10-13T04:07:12Z", "comment_text": "\n \t\tThere has a simple code can reproduce this issue\uff08test on a device having AVX512\uff09:\n <denchmark-code>conv1d = nn.Conv1d(1, 32, kernel_size=(8, 16), stride=1)\n x = torch.randn(300, 1, 25, 16)\n x.requires_grad_()\n y = conv1d(x).sum()\n y.backward()\n </denchmark-code>\n \n There will has a patch to solve it. Thanks!\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "kkoehncke", "commentT": "2020-10-13T05:24:14Z", "comment_text": "\n \t\tOk, must be avx512 thing\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "kkoehncke", "commentT": "2020-10-19T19:19:49Z", "comment_text": "\n \t\tAh okay great, thanks!\n \t\t"}}}, "commit": {"commit_id": "1eed54d17a8ae686c79ce716db35bc6ead97c4cd", "commit_author": "pinzhenx", "commitT": "2020-12-03 11:54:31-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": ".jenkins\\pytorch\\win-test-helpers\\installation-helpers\\install_mkl.bat", "file_new_name": ".jenkins\\pytorch\\win-test-helpers\\installation-helpers\\install_mkl.bat", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "10", "deleted_lines": "10"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "aten\\src\\ATen\\native\\CompositeRandomAccessorCommon.h", "file_new_name": "aten\\src\\ATen\\native\\CompositeRandomAccessorCommon.h", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "132", "deleted_lines": "132", "method_info": {"method_name": "at::native::CompositeRandomAccessor::operator *", "method_params": "", "method_startline": "132", "method_endline": "134"}}, "hunk_1": {"Ismethod": 1, "added_lines": "132", "deleted_lines": "132", "method_info": {"method_name": "at::native::CompositeRandomAccessor::operator *", "method_params": "", "method_startline": "132", "method_endline": "134"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "caffe2\\ideep\\ideep_utils.h", "file_new_name": "caffe2\\ideep\\ideep_utils.h", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "4", "deleted_lines": "4"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "third_party\\ideep", "file_new_name": "third_party\\ideep", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "1", "deleted_lines": "1"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "third_party\\mkl-dnn.BUILD", "file_new_name": "third_party\\mkl-dnn.BUILD", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "10,12,33,34,43,44", "deleted_lines": "10,12,41"}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "torch\\csrc\\python_headers.h", "file_new_name": "torch\\csrc\\python_headers.h", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2", "deleted_lines": "2"}}}}}}