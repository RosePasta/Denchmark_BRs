{"BR": {"BR_id": "465", "BR_author": "avitalsh", "BRopenT": "2019-05-06T11:39:29Z", "BRcloseT": "2019-06-14T18:55:40Z", "BR_text": {"BRsummary": "MaxPooling conversion", "BRdescription": "\n Hi,\n I tried converting the following model to PrivateModel using the secure_model method:\n <denchmark-code>input_img = tf.keras.Input(shape=(32, 32, 3))\n x = tf.keras.layers.Conv2D(16, (3,3), padding='same')(input_img)\n x = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x)\n x = tf.keras.layers.Flatten()(x)\n x = tf.keras.layers.Dense(10)(x)\n model = tf.keras.Model(inputs=input_img, outputs=x)\n </denchmark-code>\n \n And got the following error:\n File \"/cs/labs/peleg/avitalsh/tools/temp/tf-encrypted/tf_encrypted/private_model.py\", line 79, in secure_model\n y = c.convert(remove_training_nodes(graph_def), tfe.convert.registry(), 'input-provider', inputs)\n File \"/cs/labs/peleg/avitalsh/tools/temp/tf-encrypted/tf_encrypted/convert/convert.py\", line 92, in convert\n outs = op_handler(self, nodes, input_list)\n File \"/cs/labs/peleg/avitalsh/tools/temp/tf-encrypted/tf_encrypted/convert/register.py\", line 508, in flatten\n input = converter.outputs[inputs[0]]\n KeyError: 'max_pooling2d/MaxPool'\n When I remove the MaxPool layer, secure_model works fine.\n I am using tfe version 0.5.2. When using older version (0.4.0) it works fine (with the max pool layer).\n Is this a bug? or did the API change between the version and i'm not using it correctly?\n Thanks\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "avitalsh", "commentT": "2019-05-06T12:23:08Z", "comment_text": "\n \t\tIn the past, we have mainly stuck with using the tf.nn api when building models in plaintext. As such, the converter was originally built with these in mind, and so many tf.layers and tf.keras.layers wouldn't work by default.  By switching to using that api, you will find fewer bugs in the converter.\n To know what's supported and what's not, the registry in tf_encrypted/convert/register.py contains a full list.  If the op generates only one or a few standard ops, it's likely supported (e.g. tf.nn.conv2d generates Conv2D and BiasAdd, which are both supported).\n For layers that generate an entire subgraph, e.g. most tf.layers and tf.keras.layers, we usually require that they be registered, given reserved scopes, and converted as special ops.\n We are currently working on expanding our support for converting keras layers. Please see <denchmark-link:https://github.com/tf-encrypted/tf-encrypted/blob/master/tf_encrypted/convert/README.md>the converter guide</denchmark-link>\n  for more information on how to add ops, and to see what's already supported.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "avitalsh", "commentT": "2019-05-06T13:25:39Z", "comment_text": "\n \t\tI'm going to close this up if this takes care of your question, but feel free to reopen otherwise! :)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "avitalsh", "commentT": "2019-05-28T10:52:00Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/jvmancuso>@jvmancuso</denchmark-link>\n  , Sorry for the late response but I don't think the problem is with the keras api. I tried debugging the conversion of the following model -\n <denchmark-code>input_img = tf.keras.layers.Input(shape=(10,10,3))\n x = tf.keras.layers.Conv2D(16, (3,3))(input_img)\n x = tf.keras.layers.ReLU()(x)\n x = tf.keras.layers.AveragePooling2D((2, 2), (2,2))(x)\n x = tf.keras.layers.Flatten()(x)\n \n model = tf.keras.Model(inputs=input_img, outputs=x)\n \n s_model = tfe.private_model.secure_model(model)\n </denchmark-code>\n \n In the conversion function there is this for loop -\n \n \n \n tf-encrypted/tf_encrypted/convert/convert.py\n \n \n          Line 82\n       in\n       1233cdd\n \n \n \n \n \n \n  for node in node_list: \n \n \n \n \n \n That first works on the input node, which is fine, and then it moves on to the next layer which is conv.\n Since conv is considered as a special op, we don't go in here -\n \n \n \n tf-encrypted/tf_encrypted/convert/convert.py\n \n \n          Line 83\n       in\n       1233cdd\n \n \n \n \n \n \n  if node.name not in specop_outputs: \n \n \n \n \n \n and instead we move on the the else statement, where we enter this loop:\n \n \n \n tf-encrypted/tf_encrypted/convert/convert.py\n \n \n          Line 100\n       in\n       1233cdd\n \n \n \n \n \n \n  for s in specop_dict: \n \n \n \n \n \n In the first iteration s is conv - good. In the next iteration s is Flatten.\n The problem occurs when we reach this line -\n \n \n \n tf-encrypted/tf_encrypted/convert/convert.py\n \n \n          Line 110\n       in\n       1233cdd\n \n \n \n \n \n \n  outs = op_handler(self, nodes, input_list) \n \n \n \n \n \n We run the op_handler function, which in this case is -\n \n \n \n tf-encrypted/tf_encrypted/convert/register.py\n \n \n          Line 544\n       in\n       1233cdd\n \n \n \n \n \n \n  def _flatten(converter, node, inputs): \n \n \n \n \n \n Here we are looking for the input -\n \n \n \n tf-encrypted/tf_encrypted/convert/register.py\n \n \n          Line 545\n       in\n       1233cdd\n \n \n \n \n \n \n  x_in = converter.outputs[inputs[0]] \n \n \n \n \n \n which should be the output of the AvgPool layer but since we didn't reach it yet in the conver function, we don't have the output yet -\n <denchmark-link:https://user-images.githubusercontent.com/17612668/58472619-52057680-814f-11e9-9ad3-b5d3def983f2.png></denchmark-link>\n \n And then we crash.\n So I think the problem is with this for loop -\n \n \n \n tf-encrypted/tf_encrypted/convert/convert.py\n \n \n          Line 100\n       in\n       1233cdd\n \n \n \n \n \n \n  for s in specop_dict: \n \n \n \n \n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "avitalsh", "commentT": "2019-05-30T15:41:28Z", "comment_text": "\n \t\ttaking a look now!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "avitalsh", "commentT": "2019-06-13T07:16:15Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/jvmancuso>@jvmancuso</denchmark-link>\n , did you get a chance to look into this?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "avitalsh", "commentT": "2019-06-13T13:16:33Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/avitalsh>@avitalsh</denchmark-link>\n , I looked into it briefly before having to jump on something else.  I'll reinvestigate today and plan get back to you by tomorrow!\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "avitalsh", "commentT": "2019-06-14T16:42:42Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/avitalsh>@avitalsh</denchmark-link>\n , I've found two bugs related to this issue.\n The problem with the for-loop was that it was registering all special ops as soon as it reached the first one, which dependencies to later special ops may not have been registered yet.  I've solved this by filtering out special ops not associated with the current node/subgraph being converted.\n Another bug was in the function match_numbered_specop in convert.py.  The regex built to match numbered scopes for special ops was only recognizing unnumbered ones, i.e. model/conv2d/... would match on conv2d but model/conv2d_1/... would not match on conv2d_1, which again meant that certain ops/layers that were dependencies for other layers would go unregistered.  I fixed this by modifying the function to capture the right groups from the original regex.\n I'm adding these fixes in an upcoming PR, which also has some new functionality around inspecting Keras models that should be helpful when checking for convertibility.\n I also realized that depending on how you're calling secure_model, it could try to convert into Pond by default, in which case the pooling layer would throw an error. The script below is how I recreated and solved these issues, and they can also be used as an example for how to use the new tfe.convert functionality.\n import tensorflow as tf\n import tf_encrypted as tfe\n \n shape = (10, 10, 3)\n x = tf.keras.layers.Input(shape=shape)\n y = tf.keras.layers.Conv2D(16, (3, 3))(x)\n y = tf.keras.layers.MaxPooling2D((2, 2), (2, 2))(y)\n y = tf.keras.layers.Flatten()(y)\n y = tf.keras.layers.Dense(10)(y)\n \n model = tf.keras.Model(inputs=x, outputs=y)\n \n # Helper to inspect the incoming graph, to ensure that TFE has conversion\n # functions for everything you're requesting.\n sess = tf.keras.backend.get_session()\n tfe.convert.inspect_subgraph(model, shape, sess)\n \n # Idiomatic way of converting in a specific protocol\n with tfe.protocol.SecureNN():\n   s_model = tfe.private_model.secure_model(model)\n \n # This one should work as well\n prot = tfe.protocol.SecureNN()\n s_model = tfe.private_model.secure_model(model, protocol=prot)\n \t\t"}}}, "commit": {"commit_id": "96aad1ba765a25e45e49bb3f8721b0ead1857506", "commit_author": "jvmancuso", "commitT": "2019-06-14 14:55:39-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tf_encrypted\\convert\\convert.py", "file_new_name": "tf_encrypted\\convert\\convert.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137", "deleted_lines": "121,122,123,124,125", "method_info": {"method_name": "_register_specop", "method_params": "self,node,specop_scope_dict", "method_startline": "121", "method_endline": "137"}}, "hunk_1": {"Ismethod": 1, "added_lines": "277,278", "deleted_lines": null, "method_info": {"method_name": "match_numbered_scope", "method_params": "specop,search_string,return_group", "method_startline": "265", "method_endline": "280"}}, "hunk_2": {"Ismethod": 1, "added_lines": "95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118", "deleted_lines": "95,96,97,98,99,100,101,102,103,104,105,106,111,112,113,114,115,116,117,118", "method_info": {"method_name": "_register_op", "method_params": "self,node,inputs_iterable,input_player,pb_trimmed", "method_startline": "95", "method_endline": "118"}}}}}}}