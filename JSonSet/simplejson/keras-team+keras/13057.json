{"BR": {"BR_id": "13057", "BR_author": "rohit-gupta", "BRopenT": "2019-07-03T11:05:14Z", "BRcloseT": "2019-08-28T17:24:08Z", "BR_text": {"BRsummary": "multi_gpu_model not working w/ TensorFlow 1.14", "BRdescription": "\n System information\n \n Have I written custom code (as opposed to using example directory):  No/Yes (very slight change to an example)\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04\n TensorFlow backend (yes / no):  yes\n TensorFlow version:  1.14\n Keras version: Latest master from github\n Python version:  3.7 (through Anaconda)\n CUDA/cuDNN version:  10.0/7.4.2\n GPU model and memory:  2x Tesla K80 (11GB each)\n \n Describe the current behavior\n I am using the cifar-10 ResNet example from the Keras examples directory, with the addition of the following line at Line number 360 (just before compilation) in order to use multiple GPUs while training. However this doesn't work.\n Line Added:\n model = keras.utils.multi_gpu_model(model, gpus=2)\n Traceback Error log:\n <denchmark-code>Traceback (most recent call last):\n   File \"cifar10_resnet_multigpu.py\", line 360, in <module>\n     model = keras.utils.multi_gpu_model(model, gpus=2)\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/utils/multi_gpu_utils.py\", line 230, in multi_gpu_model\n     outputs = model(inputs)\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 451, in __call__\n     output = self.call(inputs, **kwargs)\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/network.py\", line 570, in call\n     output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/engine/network.py\", line 727, in run_internal_graph\n     layer.call(computed_tensor, **kwargs))\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/layers/normalization.py\", line 185, in call\n     epsilon=self.epsilon)\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 2053, in normalize_batch_in_training\n     if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 299, in _has_nchw_support\n     explicitly_on_cpu = _is_current_explicit_device('CPU')\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 272, in _is_current_explicit_device\n     device = _get_current_tf_device()\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 252, in _get_current_tf_device\n     g._apply_device_functions(op)\n   File \"/local/home/manasa/vpds2/conda/anaconda3/envs/tensorflow114/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 4581, in _apply_device_functions\n     op._set_device_from_string(device_string)\n AttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'\n \n </denchmark-code>\n \n Describe the expected behavior\n Previously, this typically worked fine and results in faster training due to parallelization across GPUs.\n Note: This works fine if the backend is Tensorflow 1.13, so this is a regression.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "rohit-gupta", "commentT": "2019-07-04T01:18:14Z", "comment_text": "\n \t\tThe same with you. The codes can run with tf==1.12.0, but cannot run with tf=1.14.0. I don't know the reason. The largest change is that I have transferred CUDA from 9.0 to 10.0, then nothing has been changed.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "rohit-gupta", "commentT": "2019-07-04T08:30:32Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/QtacierP>@QtacierP</denchmark-link>\n  It works with TF 1.13 and CUDA 10.0 for me, its just TF 1.14 that's a problem\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "rohit-gupta", "commentT": "2019-07-04T16:22:51Z", "comment_text": "\n \t\tI have the same problem now. Currently, is downgrade an only way to solve this problem?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "rohit-gupta", "commentT": "2019-07-04T17:16:41Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/derekhsu>@derekhsu</denchmark-link>\n  I can't really speak for Keras maintainers, but I don't know of any other solution. Bugs like this with critical features like Multi-GPU training are a big problem for Keras.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "rohit-gupta", "commentT": "2019-07-05T19:34:25Z", "comment_text": "\n \t\tSame here!!!! very disappointed solutions, please.....\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "rohit-gupta", "commentT": "2019-08-12T19:01:36Z", "comment_text": "\n \t\tI received the same error message as above when using tf1.14, but after downgrading to 1.12 as well as to 1.13 I am confronted with:\n <denchmark-code>Traceback (most recent call last):\n   File \"trainer_temp.py\", line 226, in <module>\n     main()\n   File \"trainer_temp.py\", line 137, in main\n     model = multi_gpu_model(build.models['vae'], gpus=gpus)\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/utils/multi_gpu_utils.py\", line 227, in multi_gpu_model\n     outputs = model(inputs)\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n     output = self.call(inputs, **kwargs)\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/engine/network.py\", line 564, in call\n     output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/engine/network.py\", line 721, in run_internal_graph\n     layer.call(computed_tensor, **kwargs))\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/engine/network.py\", line 564, in call\n     output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/engine/network.py\", line 721, in run_internal_graph\n     layer.call(computed_tensor, **kwargs))\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/layers/normalization.py\", line 185, in call\n     epsilon=self.epsilon)\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1858, in normalize_batch_in_training\n     if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 291, in _has_nchw_support\n     explicitly_on_cpu = _is_current_explicit_device('CPU')\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 266, in _is_current_explicit_device\n     device = _get_current_tf_device()\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 247, in _get_current_tf_device\n     g._apply_device_functions(op)\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4261, in _apply_device_functions\n     op._set_device(device_spec.function(op))\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 314, in _device_function\n     current_device = DeviceSpec.from_string(node_def.device or \"\")\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 232, in from_string\n     return DeviceSpec().parse_from_string(spec)\n   File \"/home/fh2-project-devel/pm7014/.virtualenvs/lala/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 150, in parse_from_string\n     splits = [x.split(\":\") for x in spec.split(\"/\")]\n AttributeError: 'DeviceSpec' object has no attribute 'split'\n </denchmark-code>\n \n Any suggestions whether this is caused by the same issue or if I might have another problem?\n System information\n \n OS:  Red Hat Enterprise Linux\n Python: 3.6.5\n Keras: 2.2.4\n Tensorflow: 1.12/1.13.1/1.14\n Cuda: 9/10\n GPU model:  NVIDIA GeForce GTX980 Ti\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "rohit-gupta", "commentT": "2019-08-20T13:12:36Z", "comment_text": "\n \t\tSame problem here. Log:\n <denchmark-code>Traceback (most recent call last):\n   File \"phase_retrieval_-108_gan.py\", line 39, in <module>\n     discriminator = multi_gpu_model( discriminator, gpus=2 )\n   File \"/usr/lib/python3.7/site-packages/keras/utils/multi_gpu_utils.py\", line 230, in multi_gpu_model\n     outputs = model(inputs)\n   File \"/usr/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 451, in __call__\n     output = self.call(inputs, **kwargs)\n   File \"/usr/lib/python3.7/site-packages/keras/engine/network.py\", line 570, in call\n     output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n   File \"/usr/lib/python3.7/site-packages/keras/engine/network.py\", line 727, in run_internal_graph\n     layer.call(computed_tensor, **kwargs))\n   File \"/usr/lib/python3.7/site-packages/keras/layers/normalization.py\", line 185, in call\n     epsilon=self.epsilon)\n   File \"/usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 2053, in normalize_batch_in_training\n     if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n   File \"/usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 299, in _has_nchw_support\n     explicitly_on_cpu = _is_current_explicit_device('CPU')\n   File \"/usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 272, in _is_current_explicit_device\n     device = _get_current_tf_device()\n   File \"/usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 252, in _get_current_tf_device\n     g._apply_device_functions(op)\n   File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 4581, in _apply_device_functions\n     op._set_device_from_string(device_string)\n AttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'\n \n </denchmark-code>\n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "rohit-gupta", "commentT": "2019-08-20T13:46:19Z", "comment_text": "\n \t\tI am trying to learn Pytorch.... little by little.... I dont kow when they will fix this.... it have been three months\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "rohit-gupta", "commentT": "2019-08-21T05:22:58Z", "comment_text": "\n \t\tsame problem here too...\n <denchmark-h:hr></denchmark-h>\n \n AttributeError                            Traceback (most recent call last)\n  in \n 10 opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt,loss_scale='dynamic')\n 11 #opt = tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite(opt,loss_scale='dynamic')\n ---> 12 parallel_model = multi_gpu_model(model, gpus=2)\n 13 #parallel_model.compile(loss='categorical_crossentropy',optimizer='rmsprop')\n 14 parallel_model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[dice_coef])\n /opt/conda/lib/python3.7/site-packages/keras/utils/multi_gpu_utils.py in multi_gpu_model(model, gpus, cpu_merge, cpu_relocation)\n 225                 # Apply model on slice\n 226                 # (creating a model replica on the target device).\n --> 227                 outputs = model(inputs)\n 228                 outputs = to_list(outputs)\n 229\n /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py in call(self, inputs, **kwargs)\n 455             # Actually call the layer,\n 456             # collecting output(s), mask(s), and shape(s).\n --> 457             output = self.call(inputs, **kwargs)\n 458             output_mask = self.compute_mask(inputs, previous_mask)\n 459\n /opt/conda/lib/python3.7/site-packages/keras/engine/network.py in call(self, inputs, mask)\n 562             return self._output_tensor_cache[cache_key]\n 563         else:\n --> 564             output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n 565             return output_tensors\n 566\n /opt/conda/lib/python3.7/site-packages/keras/engine/network.py in run_internal_graph(self, inputs, masks)\n 719                                     kwargs['mask'] = computed_mask\n 720                             output_tensors = to_list(\n --> 721                                 layer.call(computed_tensor, **kwargs))\n 722                             output_masks = layer.compute_mask(computed_tensor,\n 723                                                               computed_mask)\n /opt/conda/lib/python3.7/site-packages/keras/layers/normalization.py in call(self, inputs, training)\n 183         normed_training, mean, variance = K.normalize_batch_in_training(\n 184             inputs, self.gamma, self.beta, reduction_axes,\n --> 185             epsilon=self.epsilon)\n 186\n 187         if K.backend() != 'cntk':\n /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in normalize_batch_in_training(x, gamma, beta, reduction_axes, epsilon)\n 1856     \"\"\"\n 1857     if ndim(x) == 4 and list(reduction_axes) in [[0, 1, 2], [0, 2, 3]]:\n -> 1858         if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n 1859             return _broadcast_normalize_batch_in_training(x, gamma, beta,\n 1860                                                           reduction_axes,\n /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in _has_nchw_support()\n 289         bool: if the current scope device placement would support nchw\n 290     \"\"\"\n --> 291     explicitly_on_cpu = _is_current_explicit_device('CPU')\n 292     gpus_available = len(_get_available_gpus()) > 0\n 293     return (not explicitly_on_cpu and gpus_available)\n /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in _is_current_explicit_device(device_type)\n 264     if device_type not in ['CPU', 'GPU']:\n 265         raise ValueError('device_type should be either \"CPU\" or \"GPU\".')\n --> 266     device = _get_current_tf_device()\n 267     return (device is not None and device.device_type == device_type.upper())\n 268\n /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in _get_current_tf_device()\n 245     g = tf.get_default_graph()\n 246     op = _TfDeviceCaptureOp()\n --> 247     g._apply_device_functions(op)\n 248     return op.device\n 249\n /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in _apply_device_functions(self, op)\n 4579       # strings, since identity checks are faster than equality checks.\n 4580       if device_string is not prior_device_string:\n -> 4581         op._set_device_from_string(device_string)\n 4582         prior_device_string = device_string\n 4583     op._device_code_locations = self._snapshot_device_function_stack_metadata()\n AttributeError: '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string'\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "rohit-gupta", "commentT": "2019-08-23T10:56:48Z", "comment_text": "\n \t\tyes, TF 1.14 issue, see <denchmark-link:https://github.com/tensorflow/tensorflow/issues/30728>tensorflow/tensorflow#30728</denchmark-link>\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "rohit-gupta", "commentT": "2019-08-26T16:52:02Z", "comment_text": "\n \t\ti found a workaround (which worked at least for my configuration):\n since parse_from_string treated the DeviceSpec object it wanted to receive as an string, there was a simple solution, adding the following in\n site-packages/tensorflow/python/framework/device.py\", line 150, in parse_from_string:\n <denchmark-code>if isinstance(spec, DeviceSpec):\n         return spec\n </denchmark-code>\n \n might not be the optimal solution, but it finally allowed me to use all of my GPUs...\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "rohit-gupta", "commentT": "2019-08-26T21:27:12Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ju-he>@ju-he</denchmark-link>\n  thanks for the post, but I cant find that line of code, I dont have anything in line 150, just some comments....\n I have this\n if isinstance(spec, MergeDevice):\n return spec\n but never found\n parse_from_string in the file\n I don't understand what did you changed...\n Thanks.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "rohit-gupta", "commentT": "2019-08-26T21:52:10Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/TheStoneMX>@TheStoneMX</denchmark-link>\n  which tf version are you using? I downgraded from 1.14 to 1.12 and to 1.10, since some suggested this solution but I still had the issues as described above. Maybe it's due to my specific configuration. But do I understand you correctly, that the \"if isinstance-return spec\" part (that's the only thing I added) is already there in your version? Then apparently this bug has already been fixed, just not in the version I was using.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "rohit-gupta", "commentT": "2019-08-27T10:11:51Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ju-he>@ju-he</denchmark-link>\n  I am using 1.14 and still can't use multiple GPUs, I am thinking to learn Pytorch..... it has been too long and they are not fixing this bug\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "rohit-gupta", "commentT": "2019-08-27T10:19:11Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/TheStoneMX>@TheStoneMX</denchmark-link>\n  have you tried switching to tf 1.12 or even 1.10? This together with the Bugfix I posted above should work fine.\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "rohit-gupta", "commentT": "2019-08-27T10:46:24Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/ju-he>@ju-he</denchmark-link>\n \n Thanks for the email, but I havent  be able, I am using conda and everytim I install keras, it reinstall 1.4....\n Do you know how I can do it ?\n But I thought that 1.3 does not have this problem, because before everything was working.\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "rohit-gupta", "commentT": "2019-08-27T13:55:00Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/TheStoneMX>@TheStoneMX</denchmark-link>\n \n I stopped using conda a while ago, but I think you can choose the version of a specific package via \n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "rohit-gupta", "commentT": "2019-08-27T14:02:42Z", "comment_text": "\n \t\tI was not using conda for a while then I started to use it again, I am switching to see if I can make work, thanks bro.\n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "rohit-gupta", "commentT": "2019-08-27T14:57:24Z", "comment_text": "\n \t\tHi, same issue here when trying to use multi GPU with Keras.\n I had to fall back to tensorflow-gpu 1.13.2 to make it work :(\n Any news on this? Hope things get fixed soon \ud83d\udc4d\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "rohit-gupta", "commentT": "2019-08-27T16:50:59Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/ju-he>@ju-he</denchmark-link>\n   I got it working removing anaconda and using pip3 and installed TensorFlow-GPU 1.13.2\n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "rohit-gupta", "commentT": "2019-09-11T21:07:20Z", "comment_text": "\n \t\tI have the same problem when calling:\n with device('/gpu:0' if use_GPU else '/cpu:0'): portion of code\n Tensorflow-gpu 1.14 has disappointed me as well. I consider 1.13.2 a last reliable version.\n \n Just importing it causes incompatibilities:\n \n for example with numpy,\n with management of GPUs / CPUs.\n \n Many things have changed package path and there is no backwards compatibility, for example:\n \n package path to TocoConverter/TFLiteConverter\n package path to set_image_dim_ordering\n many other places get warning like for example \"tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead\"\n \n \n I believe 1.14 is currently more similar to TensorFlow 2 rather than to TensorFlow 1.\n Why would there be explicit necessity to change package path to \"v1\" otherwise.\n Please consider backwards compatibility for 1.x.x versions if the version still starts with 1.\n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "rohit-gupta", "commentT": "2019-12-26T09:17:01Z", "comment_text": "\n \t\tI, too, got it working by installing a pip3 environment separate from my Anaconda environment.\n \n pip3 for python 3.7.5\n tensorflow-gpu v. 1.14.0\n keras 2.3.1\n cuda 10.0 libraries only into /usr/local/cuda-10.0 in addition to cuda 10.1 + drivers that were previously installed\n \n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "rohit-gupta", "commentT": "2020-02-20T01:17:44Z", "comment_text": "\n \t\t\n I, too, got it working by installing a pip3 environment separate from my Anaconda environment.\n \n pip3 for python 3.7.5\n tensorflow-gpu v. 1.14.0\n keras 2.3.1\n cuda 10.0 libraries only into /usr/local/cuda-10.0 in addition to cuda 10.1 + drivers that were previously installed\n \n \n Just upgrade tf version to 1.15, works for me.\n \t\t"}, "comments_23": {"comment_id": 24, "comment_author": "rohit-gupta", "commentT": "2020-02-27T13:01:01Z", "comment_text": "\n \t\tError is triggered for me on Tensorflow-GPU 1.15 with Keras 2.2.4\n \t\t"}, "comments_24": {"comment_id": 25, "comment_author": "rohit-gupta", "commentT": "2020-03-04T05:40:41Z", "comment_text": "\n \t\t\n Error is triggered for me on Tensorflow-GPU 1.15 with Keras 2.2.4\n \n <denchmark-code>keras                     2.3.1                    pypi_0    pypi\n tensorboard               1.15.0                   pypi_0    pypi\n tensorflow-estimator      1.15.1                   pypi_0    pypi\n tensorflow-gpu            1.15.0                   pypi_0    pypi\n </denchmark-code>\n \n Tested on my computer.\n \n Ubuntu 19.10 , gtx1080ti sli, python3.7, cuda 10.1\n \n \t\t"}, "comments_25": {"comment_id": 26, "comment_author": "rohit-gupta", "commentT": "2020-09-29T09:52:42Z", "comment_text": "\n \t\tkeras 2.2.4\n tensorflow 1.13.1\n it works for me.\n \t\t"}}}, "commit": {"commit_id": "2bb96b6fa782abdc57c4ebe07b28cdfb98c49e50", "commit_author": "Taylor Robie", "commitT": "2019-08-28 10:24:07-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "keras\\backend\\tensorflow_backend.py", "file_new_name": "keras\\backend\\tensorflow_backend.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "248,249,250", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self", "method_startline": "247", "method_endline": "251"}}, "hunk_1": {"Ismethod": 1, "added_lines": "257,258", "deleted_lines": null, "method_info": {"method_name": "_set_device_from_string", "method_params": "self,device_str", "method_startline": "257", "method_endline": "258"}}}}}}}