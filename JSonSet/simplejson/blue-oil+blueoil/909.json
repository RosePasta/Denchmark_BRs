{"BR": {"BR_id": "909", "BR_author": "tk26eng", "BRopenT": "2020-03-10T13:05:04Z", "BRcloseT": "2020-04-16T01:27:35Z", "BR_text": {"BRsummary": "lm_fpga.elf sometimes fails with classification", "BRdescription": "\n An error occurs when we run lm_fpga.elf many times.\n The probability that the problem occurs is around 1/10000.\n In training, I almost followed the blueoil tutorial and modified some parameters.\n The actual config is below.\n <denchmark-code># -*- coding: utf-8 -*-\n # Copyright 2018 The Blueoil Authors. All Rights Reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n # you may not use this file except in compliance with the License.\n # You may obtain a copy of the License at\n #\n #     http://www.apache.org/licenses/LICENSE-2.0\n #\n # Unless required by applicable law or agreed to in writing, software\n # distributed under the License is distributed on an \"AS IS\" BASIS,\n # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # =============================================================================\n from easydict import EasyDict\n import tensorflow as tf\n \n from blueoil.common import Tasks\n from blueoil.networks.classification.lmnet_v1 import LmnetV1Quantize\n from blueoil.datasets.image_folder import ImageFolderBase\n \n from blueoil.data_processor import Sequence\n from blueoil.pre_processor import (\n     Resize,\n     DivideBy255,\n     PerImageStandardization\n )\n from blueoil.quantizations import (\n     binary_mean_scaling_quantizer,\n     linear_mid_tread_half_quantizer,\n )\n \n IS_DEBUG = False\n \n NETWORK_CLASS = LmnetV1Quantize\n \n # TODO(wakisaka): should be hidden. generate dataset class on the fly.\n DATASET_CLASS = type('DATASET_CLASS', (ImageFolderBase,), {'extend_dir': '/home/blueoil/cifar/train/', 'validation_extend_dir': '/home/blueoil/cifar/test/'})\n \n IMAGE_SIZE = [32, 32]\n BATCH_SIZE = 64\n DATA_FORMAT = \"NHWC\"\n TASK = Tasks.CLASSIFICATION\n CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n \n MAX_EPOCHS = 10\n SAVE_CHECKPOINT_STEPS = 1000\n KEEP_CHECKPOINT_MAX = 5\n TEST_STEPS = 1000\n SUMMARISE_STEPS = 100\n \n \n # pretrain\n IS_PRETRAIN = False\n PRETRAIN_VARS = []\n PRETRAIN_DIR = \"\"\n PRETRAIN_FILE = \"\"\n \n PRE_PROCESSOR = Sequence([\n     Resize(size=IMAGE_SIZE),\n     PerImageStandardization()\n ])\n POST_PROCESSOR = None\n \n NETWORK = EasyDict()\n \n NETWORK.OPTIMIZER_CLASS = tf.train.MomentumOptimizer\n NETWORK.OPTIMIZER_KWARGS = {'momentum': 0.9, 'learning_rate': 0.001}\n NETWORK.LEARNING_RATE_FUNC = None\n NETWORK.LEARNING_RATE_KWARGS = None\n \n NETWORK.IMAGE_SIZE = IMAGE_SIZE\n NETWORK.BATCH_SIZE = BATCH_SIZE\n NETWORK.DATA_FORMAT = DATA_FORMAT\n NETWORK.WEIGHT_DECAY_RATE = 0.0005\n \n # quantize\n NETWORK.ACTIVATION_QUANTIZER = linear_mid_tread_half_quantizer\n NETWORK.ACTIVATION_QUANTIZER_KWARGS = {\n     'bit': 2,\n     'max_value': 2\n }\n NETWORK.WEIGHT_QUANTIZER = binary_mean_scaling_quantizer\n NETWORK.WEIGHT_QUANTIZER_KWARGS = {}\n \n # dataset\n DATASET = EasyDict()\n DATASET.BATCH_SIZE = BATCH_SIZE\n DATASET.DATA_FORMAT = DATA_FORMAT\n DATASET.PRE_PROCESSOR = PRE_PROCESSOR\n DATASET.AUGMENTOR = Sequence([])\n DATASET.ENABLE_PREFETCH = True\n </denchmark-code>\n \n The probability of the problem was 19/100000.\n There're several patterns of error.\n I show the 1 succeeded and 3 failed patterns below.\n <denchmark-code>-------------------------------------------------------------\n Comparison: Default network test  succeeded!!!\n -------------------------------------------------------------\n TotalInitTime 8094,  sum:8.094ms\n TotalRunTime 7283,  sum:7.283ms\n ..Convolution 3750,72,  sum:3.822ms\n ....kn2row 3656,  sum:3.656ms\n ......kn2row-buf 6,  sum:0.006ms\n ......matrix_multiplication 464,429,423,417,  sum:1.733ms\n ........matrix_transpose (row_major) 26,25,21,18,  sum:0.09ms\n ......matrix_shift_add_f 580,434,425,420,  sum:1.859ms\n ....kn2row-1x1 63,  sum:0.063ms\n ......matrix_multiplication 50,  sum:0.05ms\n ..BatchNorm 367,17,  sum:0.384ms\n ..QTZ_linear_mid_tread_half 220,  sum:0.22ms\n ....pack_input 50,  sum:0.05ms\n ..QuantizedConv2D 552,922,319,389,124,  sum:2.306ms\n ....Convert Tensor 26,24,15,11,14,  sum:0.09ms\n ....Sync UDMABuf Input 100,77,43,29,28,  sum:0.277ms\n ....Conv2D TCA 337,768,215,300,42,  sum:1.662ms\n ....Sync UDMABuf Output 58,31,23,26,20,  sum:0.158ms\n ..Memcpy 76,24,18,17,  sum:0.135ms\n ..ExtractImagePatches 69,13,13,  sum:0.095ms\n ..QuantizedConv2D_ApplyScalingFactor 38,  sum:0.038ms\n ..ReLu 18,  sum:0.018ms\n ..Add 11,  sum:0.011ms\n ..AveragePool 23,  sum:0.023ms\n ..SoftMax 120,  sum:0.12ms\n </denchmark-code>\n \n <denchmark-code>-------------------------------------------------------------\n Comparison: Default network test  failed...\n Failed count: 5\n First failed report\n index: 2 / 10\n input: 0.00456843, expected: 0.00425674\n \n -------------------------------------------------------------\n TotalInitTime 8027,  sum:8.027ms\n TotalRunTime 7512,  sum:7.512ms\n ..Convolution 3978,72,  sum:4.05ms\n ....kn2row 3877,  sum:3.877ms\n ......kn2row-buf 6,  sum:0.006ms\n ......matrix_multiplication 462,431,428,424,  sum:1.745ms\n ........matrix_transpose (row_major) 24,27,26,24,  sum:0.101ms\n ......matrix_shift_add_f 627,484,487,468,  sum:2.066ms\n ....kn2row-1x1 63,  sum:0.063ms\n ......matrix_multiplication 50,  sum:0.05ms\n ..BatchNorm 354,17,  sum:0.371ms\n ..QTZ_linear_mid_tread_half 233,  sum:0.233ms\n ....pack_input 50,  sum:0.05ms\n ..QuantizedConv2D 635,922,320,331,119,  sum:2.327ms\n ....Convert Tensor 24,24,16,12,13,  sum:0.089ms\n ....Sync UDMABuf Input 194,77,44,29,24,  sum:0.368ms\n ....Conv2D TCA 331,768,215,254,41,  sum:1.609ms\n ....Sync UDMABuf Output 58,31,23,18,20,  sum:0.15ms\n ..Memcpy 67,24,18,12,  sum:0.121ms\n ..ExtractImagePatches 69,13,12,  sum:0.094ms\n ..QuantizedConv2D_ApplyScalingFactor 35,  sum:0.035ms\n ..ReLu 17,  sum:0.017ms\n ..Add 10,  sum:0.01ms\n ..AveragePool 22,  sum:0.022ms\n ..SoftMax 118,  sum:0.118ms\n </denchmark-code>\n \n <denchmark-code>-------------------------------------------------------------\n Comparison: Default network test  failed...\n Failed count: 6\n First failed report\n index: 1 / 10\n input: 8.70602e-05, expected: 7.18778e-05\n \n -------------------------------------------------------------\n TotalInitTime 8064,  sum:8.064ms\n TotalRunTime 7685,  sum:7.685ms\n ..Convolution 4225,71,  sum:4.296ms\n ....kn2row 4124,  sum:4.124ms\n ......kn2row-buf 6,  sum:0.006ms\n ......matrix_multiplication 464,430,547,423,  sum:1.864ms\n ........matrix_transpose (row_major) 25,26,21,20,  sum:0.092ms\n ......matrix_shift_add_f 645,514,549,486,  sum:2.194ms\n ....kn2row-1x1 62,  sum:0.062ms\n ......matrix_multiplication 49,  sum:0.049ms\n ..BatchNorm 382,17,  sum:0.399ms\n ..QTZ_linear_mid_tread_half 230,  sum:0.23ms\n ....pack_input 48,  sum:0.048ms\n ..QuantizedConv2D 538,921,319,331,118,  sum:2.227ms\n ....Convert Tensor 24,24,15,11,12,  sum:0.086ms\n ....Sync UDMABuf Input 98,75,43,28,24,  sum:0.268ms\n ....Conv2D TCA 330,769,215,254,41,  sum:1.609ms\n ....Sync UDMABuf Output 57,31,24,18,19,  sum:0.149ms\n ..Memcpy 73,25,18,12,  sum:0.128ms\n ..ExtractImagePatches 67,14,12,  sum:0.093ms\n ..QuantizedConv2D_ApplyScalingFactor 37,  sum:0.037ms\n ..ReLu 17,  sum:0.017ms\n ..Add 10,  sum:0.01ms\n ..AveragePool 22,  sum:0.022ms\n ..SoftMax 114,  sum:0.114ms\n </denchmark-code>\n \n <denchmark-code>-------------------------------------------------------------\n Comparison: Default network test  failed...\n Failed count: 6\n First failed report\n index: 0 / 10\n input: 5.93729e-05, expected: 4.80257e-05\n \n -------------------------------------------------------------\n TotalInitTime 8064,  sum:8.064ms\n TotalRunTime 7506,  sum:7.506ms\n ..Convolution 4082,72,  sum:4.154ms\n ....kn2row 3983,  sum:3.983ms\n ......kn2row-buf 6,  sum:0.006ms\n ......matrix_multiplication 463,428,422,593,  sum:1.906ms\n ........matrix_transpose (row_major) 25,24,19,19,  sum:0.087ms\n ......matrix_shift_add_f 612,457,441,498,  sum:2.008ms\n ....kn2row-1x1 63,  sum:0.063ms\n ......matrix_multiplication 50,  sum:0.05ms\n ..BatchNorm 384,17,  sum:0.401ms\n ..QTZ_linear_mid_tread_half 233,  sum:0.233ms\n ....pack_input 47,  sum:0.047ms\n ..QuantizedConv2D 539,922,317,330,117,  sum:2.225ms\n ....Convert Tensor 24,24,15,11,12,  sum:0.086ms\n ....Sync UDMABuf Input 99,77,43,29,24,  sum:0.272ms\n ....Conv2D TCA 330,768,215,254,41,  sum:1.608ms\n ....Sync UDMABuf Output 58,31,23,17,19,  sum:0.148ms\n ..Memcpy 70,24,18,12,  sum:0.124ms\n ..ExtractImagePatches 67,13,12,  sum:0.092ms\n ..QuantizedConv2D_ApplyScalingFactor 36,  sum:0.036ms\n ..ReLu 17,  sum:0.017ms\n ..Add 10,  sum:0.01ms\n ..AveragePool 22,  sum:0.022ms\n ..SoftMax 78,  sum:0.078ms\n </denchmark-code>\n \n Of course these results should be same because I just repeated lm_fpga.elf with same condition.\n What is the problem ?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "tk26eng", "commentT": "2020-03-10T13:17:12Z", "comment_text": "\n \t\tThis is the critical bug...\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "tk26eng", "commentT": "2020-03-13T10:18:02Z", "comment_text": "\n \t\tFurtuer infomation after some investigation\n I tried to run lm_fpga.elf or lm_arm.elf under several condtions and recorded the probabilities.\n \n \n lm_fpga.elf (without any modification)\n 19/100000\n \n \n lm_arm.elf (without any modification)\n 0/100000\n \n \n lm_fpga.elf (OMP_NUM_THREADS=1)\n 167/100000\n \n \n lm_fpga.elf (using /dev/mem and OMP_NUM_THREADS=1)\n 0/100000\n \n \n lm_fpga.elf (using O_SYNC and OMP_NUM_THREADS=1)\n 0/100000\n \n \n So this seems to be cache coherency problem.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "tk26eng", "commentT": "2020-03-16T00:05:02Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tk26eng>@tk26eng</denchmark-link>\n \n Thanks you for debugging!!\n It's good to find the way to avoid the bug.\n Which is prefer  or  ?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "tk26eng", "commentT": "2020-03-16T09:56:07Z", "comment_text": "\n \t\tIt may be a bug of synchronization around CSR operations.\n Can you check <denchmark-link:https://github.com/primenumber/blueoil/tree/insert-isb>https://github.com/primenumber/blueoil/tree/insert-isb</denchmark-link>\n  ?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "tk26eng", "commentT": "2020-03-17T23:41:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tk26eng>@tk26eng</denchmark-link>\n  Can you <denchmark-link:https://github.com/primenumber>@primenumber</denchmark-link>\n  suggestion?\n <denchmark-link:https://github.com/blue-oil/blueoil/issues/909#issuecomment-599443783>#909 (comment)</denchmark-link>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "tk26eng", "commentT": "2020-03-19T04:50:07Z", "comment_text": "\n \t\tA result of insert-isb is here.\n \n lm_fpga.elf (applying insert-isb and OMP_NUM_THREADS=1)\n 28/100000\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "tk26eng", "commentT": "2020-03-30T07:07:31Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tk26eng>@tk26eng</denchmark-link>\n  Can you tell me the status of this issue?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "tk26eng", "commentT": "2020-03-30T07:34:11Z", "comment_text": "\n \t\tThis problem came from bad cache operation and I made PR to fix this (just deleting one line).\n This was software problem and not the hardware problem.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "tk26eng", "commentT": "2020-03-30T08:59:35Z", "comment_text": "\n \t\tThank you!\n \t\t"}}}, "commit": {"commit_id": "8acb3c4564091e7cf7cf67afb43e0f300f0ea0b7", "commit_author": "tk26eng", "commitT": "2020-03-31 01:25:17+00:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "blueoil\\converter\\templates\\include\\dma_buffer.h", "file_new_name": "blueoil\\converter\\templates\\include\\dma_buffer.h", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "126,127", "method_info": {"method_name": "DMA_Buffer::init", "method_params": "device_name,elements,element_size,use_dma_cache,physical_address", "method_startline": "56", "method_endline": "129"}}}}}}}