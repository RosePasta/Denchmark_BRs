{"BR": {"BR_id": "687", "BR_author": "tbenthompson", "BRopenT": "2019-09-11T16:17:18Z", "BRcloseT": "2019-11-05T15:23:44Z", "BR_text": {"BRsummary": "Support min_gain_to_split and max_delta_step", "BRdescription": "\n These are two useful parameters in LightGBM that we are using in our non-spark models. max_delta_step controls the maximum output of a tree leaf. min_gain_to_split sets the minimal gain to perform split. Both can be useful for regularization purposes.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "tbenthompson", "commentT": "2019-09-11T16:20:02Z", "comment_text": "\n \t\tMore generally, is there some way to support the full range of LightGBM parameters in pyspark by just passing through a parameters dictionary? Many of these parameters don't affect (I think!) the sparkification and parallelization and I wonder if mmlspark can avoid replicating the full parameters API.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "tbenthompson", "commentT": "2019-09-16T21:54:07Z", "comment_text": "\n \t\thi <denchmark-link:https://github.com/tbenthompson>@tbenthompson</denchmark-link>\n   sorry about the issue you are having.  There is a hacky way to add parameters by putting them on any of the string fields (pass the original value, then a space, followed by param_name=param_value).  However, for now I would prefer to actually have users tell me what parameters should be on the learner since LightGBM in mmlspark is still relatively new.  I do agree it would be nice to add optional parameters through a parameter dictionary at some point, but I'm not sure if that point is now.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "tbenthompson", "commentT": "2019-09-17T00:17:38Z", "comment_text": "\n \t\tI just found max_bin_by_feature to be missing and it would be a useful parameter for me\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "tbenthompson", "commentT": "2019-11-05T15:39:44Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tbenthompson>@tbenthompson</denchmark-link>\n  <denchmark-link:https://github.com/chris-smith-zocdoc>@chris-smith-zocdoc</denchmark-link>\n  PR has been merged to add min_gain_to_split, max_delta_step and max_bin_by_feature, thank you for the feedback!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "tbenthompson", "commentT": "2019-11-05T16:11:28Z", "comment_text": "\n \t\tThanks so much!\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "tbenthompson", "commentT": "2020-11-05T23:01:02Z", "comment_text": "\n \t\tHi, all I want to know how I can set these parameters (max_bin_by_feature, min_gain_to_split) when using mmlspark LightGBM. Looking at the docs here: <denchmark-link:https://mmlspark.blob.core.windows.net/docs/0.18.1/pyspark/mmlspark.lightgbm.html>https://mmlspark.blob.core.windows.net/docs/0.18.1/pyspark/mmlspark.lightgbm.html</denchmark-link>\n , none of those parameters are listed.\n \t\t"}}}, "commit": {"commit_id": "2fdfe3e852f7010507a1af382ad483a0b977bac6", "commit_author": "Ilya Matiach", "commitT": "2019-11-05 10:23:43-05:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "notebooks\\samples\\Regression - Vowpal Wabbit vs. LightGBM vs. Linear Regressor.ipynb", "file_new_name": "notebooks\\samples\\Regression - Vowpal Wabbit vs. LightGBM vs. Linear Regressor.ipynb", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "292,293", "deleted_lines": "292"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\LightGBMClassifier.scala", "file_new_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\LightGBMClassifier.scala", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "52", "deleted_lines": "52", "method_info": {"method_name": "getTrainParams", "method_params": "Int", "method_startline": "41", "method_endline": "55"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 7, "file_old_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\LightGBMParams.scala", "file_new_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\LightGBMParams.scala", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "175", "method_info": {"method_name": "setLambdaL2", "method_params": "Double", "method_startline": "173", "method_endline": "175"}}, "hunk_1": {"Ismethod": 1, "added_lines": "235,236,237", "deleted_lines": null, "method_info": {"method_name": "setMaxDeltaStep", "method_params": "Double", "method_startline": "235", "method_endline": "237"}}, "hunk_2": {"Ismethod": 1, "added_lines": "228,229,230", "deleted_lines": null, "method_info": {"method_name": "setMinGainToSplit", "method_params": "Double", "method_startline": "228", "method_endline": "230"}}, "hunk_3": {"Ismethod": 1, "added_lines": "40,41", "deleted_lines": null, "method_info": {"method_name": "setUseBarrierExecutionMode", "method_params": "Boolean", "method_startline": "39", "method_endline": "41"}}, "hunk_4": {"Ismethod": 1, "added_lines": "222,223", "deleted_lines": null, "method_info": {"method_name": "setMetric", "method_params": "String", "method_startline": "221", "method_endline": "223"}}, "hunk_5": {"Ismethod": 1, "added_lines": "242", "deleted_lines": null, "method_info": {"method_name": "setMaxBinByFeature", "method_params": "", "method_startline": "242", "method_endline": "243"}}, "hunk_6": {"Ismethod": 1, "added_lines": "46", "deleted_lines": null, "method_info": {"method_name": "setNumBatches", "method_params": "Int", "method_startline": "46", "method_endline": "47"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\LightGBMRanker.scala", "file_new_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\LightGBMRanker.scala", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "57", "deleted_lines": "57", "method_info": {"method_name": "getTrainParams", "method_params": "Int", "method_startline": "51", "method_endline": "60"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\LightGBMRegressor.scala", "file_new_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\LightGBMRegressor.scala", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "65", "deleted_lines": "65", "method_info": {"method_name": "getTrainParams", "method_params": "Int", "method_startline": "59", "method_endline": "68"}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\TrainParams.scala", "file_new_name": "src\\main\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\TrainParams.scala", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "31,32,33,44,45,46,47,61,62,83,84,103,104", "deleted_lines": "41,42,56,77,96"}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "src\\test\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\split1\\VerifyLightGBMClassifier.scala", "file_new_name": "src\\test\\scala\\com\\microsoft\\ml\\spark\\lightgbm\\split1\\VerifyLightGBMClassifier.scala", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270", "deleted_lines": null}}}}}}