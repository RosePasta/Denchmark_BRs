{"BR": {"BR_id": "688", "BR_author": "redhairdragon", "BRopenT": "2020-04-07T10:07:47Z", "BRcloseT": "2020-04-17T21:39:24Z", "BR_text": {"BRsummary": "GRU Primitive Creation Error.", "BRdescription": "\n Hi, I am creating a really simple GRU function. It keeps showing\n \"terminate called after throwing an instance of 'dnnl::error'\n what():  could not create a descriptor for an LBR GRU forward propagation primitive\n Aborted (core dumped) \"\n Can anyone help me? I know this can be stupid. But I just cannot figure out why.\n <denchmark-code>#include <algorithm>\n #include <cmath>\n #include <cstring>\n #include <iostream>\n #include <numeric>\n #include <string>\n #include <vector>\n #include \"dnnl.hpp\"\n \n using namespace dnnl;\n using std::cout;\n using std::endl;\n \n using tag = memory::format_tag;\n using dt = memory::data_type;\n using dim_t = dnnl::memory::dim;\n \n const memory::dim N = CHUNK_SIZE,  // batch size\n     T = 1,                   // time steps\n     C = 600,                         // channels\n     G = 3,                         // gates (GRU has 6->3 U, 3 W)\n     L = 1,                 // layers\n     D = 1;                         // directions\n \n int main(int argc, char** argv) {\n     // Create execution dnnl::engine.\n     engine engine(engine::kind::cpu, 0);\n     // Create dnnl::stream.\n     stream engine_stream(engine);\n \n     memory::dims src_dims = {T, N, 2 * C};\n     memory::dims hx_dims = {L, D, N, C};\n     memory::dims w_dims = {L, D, 2 * C, G, C};\n     memory::dims u_dims = {L, D, C, G, C};\n     memory::dims dst_dims = {T, N, C};\n \n     auto src_layer_md = memory::desc(src_dims, dt::f32, tag::any);\n     auto src_iter_md = memory::desc();\n     // auto src_iter_md = memory::desc(hx_dims, dt::f32, tag::ldnc);\n     auto gru_weights_layer_md = memory::desc(w_dims, dt::f32, tag::any);\n     auto gru_weights_iter_md = memory::desc(u_dims, dt::f32, tag::any);\n     auto bias_md = memory::desc();\n     auto dst_layer_md = memory::desc(dst_dims, dt::f32, tag::any);\n     auto dst_iter_md = memory::desc();\n     // auto dst_iter_md = memory::desc(hx_dims, dt::f32, tag::any);\n \n \n     auto gru_desc = gru_forward::desc(\n         prop_kind::forward_training, \n         rnn_direction::unidirectional_left2right,\n         src_layer_md, \n         src_iter_md, \n         gru_weights_layer_md, \n         gru_weights_iter_md,\n         bias_md, \n         dst_layer_md, \n         dst_iter_md);\n \n     // Create primitive descriptor.\n     auto gru_pd = gru_forward::primitive_desc(gru_desc, engine);\n }\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "redhairdragon", "commentT": "2020-04-07T14:54:14Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/redhairdragon>@redhairdragon</denchmark-link>\n ,\n It seems we have a bug in the documentation: the bias is not expected to be zero. The fix is the following:\n -    auto bias_md = memory::desc();\n +    auto bias_md = memory::desc({L, D, G, C}, dt::f32, tag::ldgo);\n I tend to think this is a bug in the documentation and not in the implementation, as for training we assume that bias is a mandatory learnable parameter. However, from the usability perspective, I think nothing prevents us to make bias an optional parameter. <denchmark-link:https://github.com/redhairdragon>@redhairdragon</denchmark-link>\n , could you please comment on what is your use-case? In the final application do you need bias or as in the example here you want it to be zero? Is it inference or training?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "redhairdragon", "commentT": "2020-04-07T17:25:10Z", "comment_text": "\n \t\t\n Hi @redhairdragon,\n It seems we have a bug in the documentation: the bias is not expected to be zero. The fix is the following:\n -    auto bias_md = memory::desc();\n +    auto bias_md = memory::desc({L, D, G, C}, dt::f32, tag::ldgo);\n I tend to think this is a bug in the documentation and not in the implementation, as for training we assume that bias is a mandatory learnable parameter. However, from the usability perspective, I think nothing prevents us to make bias an optional parameter. @redhairdragon, could you please comment on what is your use-case? In the final application do you need bias or as in the example here you want it to be zero? Is it inference or training?\n \n Thank you very much. I was just experimenting with the API and I saw bias is optional so I just ignored it.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "redhairdragon", "commentT": "2020-04-07T17:33:51Z", "comment_text": "\n \t\tThanks for the update!\n I will keep this issue opened, as we have to at least fix the documentation.\n \t\t"}}}, "commit": {"commit_id": "1e3f73a86f26dc019cd8fc41a96aeaae2d83ecff", "commit_author": "Fomenko, Evarist M", "commitT": "2020-04-17 13:55:45-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "doc\\primitives\\rnn.md", "file_new_name": "doc\\primitives\\rnn.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "373,374,375,376,377,381,382,383", "deleted_lines": null}}}}}}