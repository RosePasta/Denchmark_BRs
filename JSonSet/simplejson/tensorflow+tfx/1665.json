{"BR": {"BR_id": "1665", "BR_author": "luischinchillagarcia", "BRopenT": "2020-04-22T19:08:46Z", "BRcloseT": "2020-10-19T18:09:03Z", "BR_text": {"BRsummary": "KeyError: 'user_module' in Transform", "BRdescription": "\n When running a TFX Pipeline, the Transform component returns an error in the form shown below. <denchmark-link:https://colab.research.google.com/drive/1qpd6tlRHWoVprj7LETBB0p07zF1JNAfu>This Colab</denchmark-link>\n  reproduces the error with the  from Transform, using a TFX Pipeline.\n RuntimeError: Traceback (most recent call last):\n   File \"/usr/local/lib/python3.6/dist-packages/apache_beam/runners/worker/sdk_worker.py\", line 312, in get\n     processor = self.cached_bundle_processors[bundle_descriptor_id].pop()\n IndexError: pop from empty list\n \n During handling of the above exception, another exception occurred:\n \n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.6/dist-packages/apache_beam/internal/pickler.py\", line 250, in dumps\n     s = dill.dumps(o)\n ...\n \n   File \"/usr/local/lib/python3.6/dist-packages/apache_beam/internal/pickler.py\", line 77, in _is_nested_class\n     and cls.__name__ not in sys.modules[cls.__module__].__dict__)\n KeyError: 'user_module'\n \n During handling of the above exception, another exception occurred:\n When using Interactive Context, issue is resolved by adding:\n import tensorflow_transform as tft\n import sys\n sys.modules['user_module'] = tft\n However, it had no such luck when using a pipeline.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "luischinchillagarcia", "commentT": "2020-04-23T21:56:33Z", "comment_text": "\n \t\tYou can't do it because it's a different process. You have the same context in an interactive context, but when you use Pipeline, you have a different context.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "luischinchillagarcia", "commentT": "2020-04-23T23:23:28Z", "comment_text": "\n \t\tIs there a possibility to solve this issue in any other way? (utilizing Pipeline) The end goal would be to use this in a Dataflow job for example.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "luischinchillagarcia", "commentT": "2020-04-24T10:39:30Z", "comment_text": "\n \t\tYou need create a file with preprocessing_fn and trainer_fn. You should add \"module_file\" to\n transform = Transform(\n examples=example_gen.outputs['examples'],\n schema=infer_schema.outputs['schema'],\n module_file=module_file)\n Variable module_file is path to file.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "luischinchillagarcia", "commentT": "2020-04-24T15:34:50Z", "comment_text": "\n \t\tThank you for the response. I am doing this step already though (it's under the %%writefile 'transform.py'). Here's the <denchmark-link:https://colab.research.google.com/drive/1qpd6tlRHWoVprj7LETBB0p07zF1JNAfu>Colab file I'm referencing</denchmark-link>\n , where the error occurs in the 'TF Transform (ERROR: KeyError)' tab.\n I should note: there's no Interactive Context here, this is purely a Pipeline where all the components are running. Transform fails with the error \"KeyError: 'user_module'\".\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "luischinchillagarcia", "commentT": "2020-04-28T23:58:21Z", "comment_text": "\n \t\t^ A follow-up on this issue, this error also appears in a Dataflow job.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "luischinchillagarcia", "commentT": "2020-06-30T17:11:29Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/charlesccychen>@charlesccychen</denchmark-link>\n  I think this could be related to your upcoming plan for dependency management and/or interactive context?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "luischinchillagarcia", "commentT": "2020-07-23T05:44:21Z", "comment_text": "\n \t\t^ Follow up to see if there's any hints that may lead to a solution.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "luischinchillagarcia", "commentT": "2020-10-19T18:09:04Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tfx/issues/1665>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tfx/issues/1665>No</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "758cc59bfbe1761af3a3920cec139fc90c7fc19b", "commit_author": "tfx-team", "commitT": "2020-10-19 11:08:53-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "tfx\\components\\transform\\executor.py", "file_new_name": "tfx\\components\\transform\\executor.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "968", "deleted_lines": null, "method_info": {"method_name": "_RunBeamImpl", "method_params": "self,Any,bool,DatasetMetadata,Text,int,Text,bool,int", "method_startline": "966", "method_endline": "975"}}, "hunk_1": {"Ismethod": 1, "added_lines": "674,675", "deleted_lines": "673", "method_info": {"method_name": "__init__", "method_params": "self,Text,Text,Text,Any,PTransform,bool", "method_startline": "668", "method_endline": "675"}}, "hunk_2": {"Ismethod": 1, "added_lines": "1251,1252,1253,1254", "deleted_lines": null, "method_info": {"method_name": "_RunInPlaceImpl", "method_params": "self,Any,bool,DatasetMetadata,Text,Text", "method_startline": "1251", "method_endline": "1254"}}, "hunk_3": {"Ismethod": 1, "added_lines": null, "deleted_lines": "1233,1234,1235,1236,1237", "method_info": {"method_name": "_RunInPlaceImpl", "method_params": "self,Any,DatasetMetadata,Text,Text", "method_startline": "1233", "method_endline": "1237"}}, "hunk_4": {"Ismethod": 1, "added_lines": null, "deleted_lines": "673", "method_info": {"method_name": "__init__", "method_params": "self,Text,Text,Text,Any,PTransform", "method_startline": "667", "method_endline": "673"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "tfx\\components\\transform\\executor_test.py", "file_new_name": "tfx\\components\\transform\\executor_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "67,68,69", "deleted_lines": null, "method_info": {"method_name": "Transform", "method_params": "self,inputs,outputs,status_file", "method_startline": "67", "method_endline": "69"}}, "hunk_1": {"Ismethod": 1, "added_lines": "63,64,65", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,force_tf_compat_v1", "method_startline": "63", "method_endline": "65"}}, "hunk_2": {"Ismethod": 1, "added_lines": "255,259", "deleted_lines": null, "method_info": {"method_name": "_run_pipeline_get_metrics", "method_params": "self", "method_startline": "246", "method_endline": "263"}}, "hunk_3": {"Ismethod": 1, "added_lines": "82,83", "deleted_lines": null, "method_info": {"method_name": "_use_force_tf_compat_v1", "method_params": "self", "method_startline": "82", "method_endline": "83"}}, "hunk_4": {"Ismethod": 1, "added_lines": "174,175", "deleted_lines": null, "method_info": {"method_name": "setUp", "method_params": "self", "method_startline": "159", "method_endline": "175"}}}}, "file_2": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tfx\\components\\transform\\executor_v2_test.py"}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tfx\\components\\transform\\labels.py", "file_new_name": "tfx\\components\\transform\\labels.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "33,34,35", "deleted_lines": null}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tfx\\utils\\import_utils.py", "file_new_name": "tfx\\utils\\import_utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "51,52,53,54,55,56,57,58,59,60", "deleted_lines": "53,54,55,56,57,58,59,60,61,62,63,64", "method_info": {"method_name": "import_func_from_source", "method_params": "Text,Text", "method_startline": "43", "method_endline": "64"}}}}}}}