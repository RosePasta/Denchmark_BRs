{"BR": {"BR_id": "94", "BR_author": "Codle", "BRopenT": "2019-07-08T08:12:20Z", "BRcloseT": "2019-07-09T15:53:00Z", "BR_text": {"BRsummary": "Not support Windows system\uff1f", "BRdescription": "\n When I run the code in Windows, I met the error\n RuntimeError: Expected tensor for argument <denchmark-link:https://github.com/asyml/texar-pytorch/pull/1>#1</denchmark-link>\n  'indices' to have scalar type Long; but got CUDAType instead\n and I run the same codes in Linux, all things were OK.\n I had checked the pytorch version were both 1.1.0.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Codle", "commentT": "2019-07-08T08:14:38Z", "comment_text": "\n \t\tthe codes I used were seq2seq_attn example, and the error was occured in embeding layer.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Codle", "commentT": "2019-07-08T14:41:21Z", "comment_text": "\n \t\tThank you for the feedback! I'm guessing the error is not related to Windows, it's probably due to some mistakes in tensor device placement.\n Could you share the hash of the commit you're working on, and the complete error message along with the stacktrace? This will help us locate the bug.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Codle", "commentT": "2019-07-08T14:57:54Z", "comment_text": "\n \t\t\n Thank you for the feedback! I'm guessing the error is not related to Windows, it's probably due to some mistakes in tensor device placement.\n Could you share the hash of the commit you're working on, and the complete error message along with the stacktrace? This will help us locate the bug.\n \n I remove my cuda code. Now the file was copied form example/seq2seq_attn/seq2seq_attn.py and the error was\n <denchmark-code>Traceback (most recent call last):\n   File \"seq2seq_attn.py\", line 186, in <module>\n     main()\n   File \"seq2seq_attn.py\", line 172, in main\n     _train_epoch()\n   File \"seq2seq_attn.py\", line 138, in _train_epoch\n     loss = model(batch, mode=\"train\")\n   File \"C:\\Users\\codle\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 493, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"seq2seq_attn.py\", line 81, in forward\n     inputs=self.source_embedder(batch['source_text_ids']),\n   File \"C:\\Users\\codle\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 493, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"c:\\projects\\texar-pytorch\\texar\\modules\\embedders\\embedders.py\", line 221, in forward\n     outputs = F.embedding(ids, embedding, **kwargs)\n   File \"C:\\Users\\codle\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 1506, in embedding\n     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got CPUType instead (while checking arguments for embedding)\n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Codle", "commentT": "2019-07-09T04:12:58Z", "comment_text": "\n \t\tThank you for the feedback! RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got CPUType instead (while checking arguments for embedding) My guess is that the type of batch['source_text_ids'] is wrong. batch['source_text_ids'] here should be LongTensor. We recently did some code refactor on data module and seq2seq_attn example. Could you try the lastest seq2seq_attn example to see if such error still exists?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Codle", "commentT": "2019-07-09T09:11:05Z", "comment_text": "\n \t\t\n Thank you for the feedback! RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got CPUType instead (while checking arguments for embedding) My guess is that the type of batch['source_text_ids'] is wrong. batch['source_text_ids'] here should be LongTensor. We recently did some code refactor on data module and seq2seq_attn example. Could you try the lastest seq2seq_attn example to see if such error still exists?\n \n It's useless. But I checked the batch['source_text_ids'], the dtype is dtype=torch.int32. So I think this is the problem.\n And I run the example successfully by add .long() in line 76, 89, 93\n <denchmark-code>76:inputs=self.source_embedder(batch['source_text_ids'].long()),\n 89:inputs=self.target_embedder(batch['target_text_ids'][:, :-1].long()),\n 93:labels=batch['target_text_ids'][:, 1:].long(),\n </denchmark-code>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Codle", "commentT": "2019-07-09T13:57:06Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Codle>@Codle</denchmark-link>\n  Could you confirm that you're using the latest version (commit <denchmark-link:https://github.com/asyml/texar-pytorch/commit/5e899bf359829dec1e08de90bb337d0dd239d3fc>5e899bf</denchmark-link>\n ) of Texar-PyTorch? I could not reproduce the problem in the latest version.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Codle", "commentT": "2019-07-09T14:05:37Z", "comment_text": "\n \t\t\n @Codle Could you confirm that you're using the latest version (commit 5e899bf) of Texar-PyTorch? I could not reproduce the problem in the latest version.\n \n <denchmark-code>(base) C:\\Users\\codle\\Documents>pip uninstall texar\n Uninstalling texar-0.0.1:\n   Would remove:\n     c:\\users\\codle\\anaconda3\\lib\\site-packages\\texar.egg-link\n Proceed (y/n)? y\n   Successfully uninstalled texar-0.0.1\n \n (base) C:\\Users\\codle\\Documents>git clone https://github.com/asyml/texar-pytorch.git\n Cloning into 'texar-pytorch'...\n remote: Enumerating objects: 42, done.\n remote: Counting objects: 100% (42/42), done.\n remote: Compressing objects: 100% (39/39), done.\n remote: Total 2899 (delta 1), reused 31 (delta 1), pack-reused 2857\n Receiving objects: 100% (2899/2899), 1.08 MiB | 473.00 KiB/s, done.\n Resolving deltas: 100% (2162/2162), done.\n \n (base) C:\\Users\\codle\\Documents>cd texar-pytorch\n \n (base) C:\\Users\\codle\\Documents\\texar-pytorch>pip install -e .\n Obtaining file:///C:/Users/codle/Documents/texar-pytorch\n Requirement already satisfied: numpy in c:\\users\\codle\\anaconda3\\lib\\site-packages (from texar==0.0.1) (1.16.2)\n Requirement already satisfied: pyyaml in c:\\users\\codle\\anaconda3\\lib\\site-packages (from texar==0.0.1) (5.1)\n Requirement already satisfied: requests in c:\\users\\codle\\anaconda3\\lib\\site-packages (from texar==0.0.1) (2.21.0)\n Requirement already satisfied: funcsigs in c:\\users\\codle\\anaconda3\\lib\\site-packages (from texar==0.0.1) (1.0.2)\n Requirement already satisfied: mypy_extensions in c:\\users\\codle\\anaconda3\\lib\\site-packages (from texar==0.0.1) (0.4.1)\n Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\codle\\anaconda3\\lib\\site-packages (from requests->texar==0.0.1) (1.24.1)\n Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\codle\\anaconda3\\lib\\site-packages (from requests->texar==0.0.1) (3.0.4)\n Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\codle\\anaconda3\\lib\\site-packages (from requests->texar==0.0.1) (2019.3.9)\n Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\codle\\anaconda3\\lib\\site-packages (from requests->texar==0.0.1) (2.8)\n Installing collected packages: texar\n   Running setup.py develop for texar\n Successfully installed texar\n \n (base) C:\\Users\\codle\\Documents\\texar-pytorch>cd examples\\seq2seq_attn\n (base) C:\\Users\\codle\\Documents\\texar-pytorch\\examples\\seq2seq_attn>python prepare_data.py --data toy_copy\n Successfully downloaded toy_copy.zip.\n \n (base) C:\\Users\\codle\\Documents\\texar-pytorch\\examples\\seq2seq_attn>python seq2seq_attn.py --config_model config_model --config_data config_toy_copy\n Traceback (most recent call last):\n   File \"seq2seq_attn.py\", line 184, in <module>\n     main()\n   File \"seq2seq_attn.py\", line 170, in main\n     _train_epoch()\n   File \"seq2seq_attn.py\", line 137, in _train_epoch\n     loss = model(batch, mode=\"train\")\n   File \"C:\\Users\\codle\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 493, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"seq2seq_attn.py\", line 76, in forward\n     inputs=self.source_embedder(batch['source_text_ids']),\n   File \"C:\\Users\\codle\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 493, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"c:\\users\\codle\\documents\\texar-pytorch\\texar\\modules\\embedders\\embedders.py\", line 221, in forward\n     outputs = F.embedding(ids, embedding, **kwargs)\n   File \"C:\\Users\\codle\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 1506, in embedding\n     return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got CUDAType instead (while checking arguments for embedding)\n \n \n </denchmark-code>\n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "Codle", "commentT": "2019-07-09T14:39:24Z", "comment_text": "\n \t\tI tried a experiment to reproduce the error:\n <denchmark-code>In [17]: a = torch.from_numpy(np.array([1, 2, 3]))\n In [18]: a\n Out[18]: tensor([1, 2, 3], dtype=torch.int32)\n In [19]: embed(a)\n </denchmark-code>\n \n then the error was showed.\n In the file data/data/paired_text_data.py , the line 409, 427 are used the function from_numpy and I add a parameter dtype=torch.long  in to(device=self.device). This example can also run, but I don't know add this parameter is right?\n It seems numpy's problem\n The C long in win64 is also int32....\n from <denchmark-link:https://stackoverflow.com/questions/36278590/numpy-array-dtype-is-coming-as-int32-by-default-in-a-windows-10-64-bit-machine>stackoverflow</denchmark-link>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "Codle", "commentT": "2019-07-09T15:30:21Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Codle>@Codle</denchmark-link>\n  Thank you for the details! I had no idea about  being platform-dependent.\n The root cause of the issue is in the padded_batch method in texar/data/data/dataset_utils.py, where a NumPy array with dtype np.long is created. Changing dtype to the platform-independent np.int64 should work.\n I am sorry for the inconvenience. We have not tested the code on Windows because we do not have Windows working environments. Thank you for your contribution!\n \t\t"}}}, "commit": {"commit_id": "908daa2650fad706f69d0c5b7bc07d5fad25d922", "commit_author": "Zecong Hu", "commitT": "2019-07-09 11:52:58-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "texar\\data\\data\\dataset_utils.py", "file_new_name": "texar\\data\\data\\dataset_utils.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "44", "deleted_lines": "44"}}}}}}