{"BR": {"BR_id": "254", "BR_author": "Hananel-Hazan", "BRopenT": "2019-05-23T19:04:45Z", "BRcloseT": "2019-05-31T18:08:13Z", "BR_text": {"BRsummary": "Encoder in environment.GymEnvironment", "BRdescription": "\n Trying to use environment.GymEnvironment in BindsNET without encoder lead to a error in loading.\n <denchmark-link:https://github.com/k-chaney>@k-chaney</denchmark-link>\n , I think encoder should be an option not mandatory.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Hananel-Hazan", "commentT": "2019-05-23T19:09:24Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/BindsNET/bindsnet/pull/255>#255</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Hananel-Hazan", "commentT": "2019-05-23T19:09:56Z", "comment_text": "\n \t\tYeah, is it possible to default to ? <denchmark-link:https://github.com/BindsNET/bindsnet/pull/255>#255</denchmark-link>\n  seems like it'd work, too. Any thoughts <denchmark-link:https://github.com/k-chaney>@k-chaney</denchmark-link>\n ?\n By the way, I think spike_encoders.py should be kept in the bindsnet/encoders/ folder, and I think it'd be best if you put all the Encoder classes in bindsnet/encoders/__init__.py.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Hananel-Hazan", "commentT": "2019-05-23T20:24:08Z", "comment_text": "\n \t\tI think that by default encoder,  image_encoder and label_encoder need to be set to NullEncoder\n That can solve the issue and my commit need to be cancel\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Hananel-Hazan", "commentT": "2019-05-27T19:39:21Z", "comment_text": "\n \t\tSorry about the delay, I've been diving into the other feature I'm working on. This seems like a reasonable change. I just pushed a branch chaney/gym_env_encoder_fix that deals with this as described.\n \n Do we want the encoders to be in their own module or should we leverage the encodings module that already exists?\n For the GymEnvironment the encoder default is NullEncoder.\n For the torchvision.dataset wrapping, we should probably keep them as mandatory positional arguments and just allow None to convert to NullEncoder in the constructor. This maintains the format of bindsnet arguments first and then the dataset specific arguments second and as keyword arguments.\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Hananel-Hazan", "commentT": "2019-05-28T00:01:34Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/k-chaney>@k-chaney</denchmark-link>\n .\n Yes, leveraging the encoder module is preferred. 2 and 3 look good.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Hananel-Hazan", "commentT": "2019-05-28T15:15:39Z", "comment_text": "\n \t\tYeah, I think should keep both the functional and class interfaces to the encodings in bindsnet/encoding/__init__.py.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Hananel-Hazan", "commentT": "2019-05-29T15:51:52Z", "comment_text": "\n \t\tJust pushed some changes to fix 1. I'll submit a pull request.\n \t\t"}}}, "commit": {"commit_id": "fc889c0c25cbd7cb4fcbf657d6230bbb349cb0b7", "commit_author": "k-chaney", "commitT": "2019-05-27 15:31:38-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "bindsnet\\datasets\\__init__.py", "file_new_name": "bindsnet\\datasets\\__init__.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "30", "deleted_lines": "30"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "bindsnet\\datasets\\spoken_mnist.py", "file_new_name": "bindsnet\\datasets\\spoken_mnist.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": "12,13"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "bindsnet\\datasets\\torchvision_wrapper.py", "file_new_name": "bindsnet\\datasets\\torchvision_wrapper.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "47,48,49,50,51,52,53,72,73", "deleted_lines": "65,66,67,68,69", "method_info": {"method_name": "torchvision_dataset_wrapper_creator", "method_params": "ds_type", "method_startline": "9", "method_endline": "80"}}, "hunk_1": {"Ismethod": 1, "added_lines": "72,73", "deleted_lines": "65,66,67,68,69", "method_info": {"method_name": "torchvision_dataset_wrapper_creator.__getitem__", "method_params": "self,int", "method_startline": "57", "method_endline": "75"}}}}, "file_3": {"file_change_type": "RENAME", "file_Nmethod": 0, "file_old_name": "bindsnet\\datasets\\spike_encoders.py", "file_new_name": "bindsnet\\encoders\\__init__.py"}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "bindsnet\\environment\\__init__.py", "file_new_name": "bindsnet\\environment\\__init__.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "67,92", "deleted_lines": "67", "method_info": {"method_name": "__init__", "method_params": "self,str,Encoder,kwargs", "method_startline": "67", "method_endline": "116"}}, "hunk_1": {"Ismethod": 1, "added_lines": "67,92", "deleted_lines": "67", "method_info": {"method_name": "__init__", "method_params": "self,str,Encoder", "method_startline": "67", "method_endline": "117"}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\datasets\\conv.py", "file_new_name": "examples\\datasets\\conv.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "11,15,57,70,82", "deleted_lines": "11,15,57,70,82"}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\datasets\\spoken_mnist.py", "file_new_name": "examples\\datasets\\spoken_mnist.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9", "deleted_lines": "9"}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\mnist\\conv_mnist.py", "file_new_name": "examples\\mnist\\conv_mnist.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "11", "deleted_lines": "11"}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\mnist\\minimal_mnist.py", "file_new_name": "examples\\mnist\\minimal_mnist.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2", "deleted_lines": "2"}}}, "file_9": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\mnist\\minimal_reservoir.py", "file_new_name": "examples\\mnist\\minimal_reservoir.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "8", "deleted_lines": "8"}}}, "file_10": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\space_invaders\\et_space_invaders.py", "file_new_name": "examples\\space_invaders\\et_space_invaders.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "6", "deleted_lines": "6"}}}, "file_11": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\space_invaders\\minimal_space_invaders.py", "file_new_name": "examples\\space_invaders\\minimal_space_invaders.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "6", "deleted_lines": "6"}}}, "file_12": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\space_invaders\\random_baseline.py", "file_new_name": "examples\\space_invaders\\random_baseline.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "19", "deleted_lines": "7,20"}}}}}}