{"BR": {"BR_id": "315", "BR_author": "Lamply", "BRopenT": "2018-03-29T07:45:09Z", "BRcloseT": "2018-03-29T12:19:15Z", "BR_text": {"BRsummary": "ConvolutionDepthWise doesn't seem to work when dilation is not equal 1", "BRdescription": "\n I got unexpected output when testing a network in 20180314 latest release version, which work well in 20180129 version.\n After debugging, I found the error occurred in 3x3 dilation 2 ConvolutionDepthWise layer. The result after dilation 2 ConvolutionDepthWise is same with the init result of top_blob.\n Here is a test example:\n #include <stdio.h>\n #include <iostream>\n #include <algorithm>\n #include <vector>\n #include \"net.h\"\n #include \"layer_type.h\"\n \n using namespace ncnn;\n \n // weights and bias\n float weight_data[3*3*4] = {0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111};\n float bias_data[4] = {1, 1, 1, 1};\n \n int main(int argc, char *argv[])\n {\n     // 1- set param\n     int inw = 5;\n     int inh = 5;\n     int outw = 5;\n     int outh = 5;\n     int num_input = 4;\n     int num_output = 4;\n     int kernel_w = 3;\n     int kernel_h = 3;\n     int dilation_w = 2;\n     int dilation_h = 2;\n     int stride_w = 1;\n     int stride_h = 1;\n     int pad_w = 2;\n     int pad_h = 2;\n     int bias_term = 1;\n     int weight_data_size = 36;\n     int group = 4;\n \n     // 2- set and display bottom blob\n     Mat bottom_blob(inw, inh, num_input);\n     if (bottom_blob.empty())\n         return -100;\n \n     std::cout << \"Produce all 1 to bottom_blob for init:\" << std::endl;\n     for (int n = 0; n < bottom_blob.c; ++n)\n     {\n         Mat bottom_blob_g = bottom_blob.channel(n);\n         for (int r = 0; r < bottom_blob_g.h; ++r)\n         {\n             float *ptr = bottom_blob_g.row(r);\n             for (int c = 0; c < bottom_blob_g.w; ++c)\n             {\n                 ptr[c] = 1.0f;\n                 std::cout << ptr[c] << ' ';\n             }\n             std::cout << std::endl;\n         }\n     }\n     std::cout << std::endl;\n \n     // 3- set and display top blob\n     Mat top_blob(outw, outh, num_output);\n     if (top_blob.empty())\n         return -100;\n \n     std::cout << \"Produce all 3.12 to top_blob for checking:\" << std::endl;\n     for (int n = 0; n < top_blob.c; ++n)\n     {\n         Mat top_blob_g = top_blob.channel(n);\n         for (int r = 0; r < top_blob_g.h; ++r)\n         {\n             float *ptr = top_blob_g.row(r);\n             for (int c = 0; c < top_blob_g.w; ++c)\n             {\n                 ptr[c] = 3.12f;\n                 std::cout << ptr[c] << ' ';\n             }\n             std::cout << std::endl;\n         }\n     }\n     std::cout << std::endl;\n \n     // 4- create ConvolutionDepthWise layer\n     Layer* op = ncnn::create_layer(ncnn::LayerType::ConvolutionDepthWise);\n \n     ncnn::ParamDict pd;\n     pd.set(0, num_output);// num_output\n     pd.set(1, kernel_w);\n     pd.set(11, kernel_h);\n     pd.set(2, dilation_w);\n     pd.set(12, dilation_h);\n     pd.set(3, stride_w);\n     pd.set(13, stride_h);\n     pd.set(4, pad_w);// pad_w\n     pd.set(14, pad_h);// pad_h\n     pd.set(5, bias_term);\n     pd.set(6, weight_data_size);// weight_data_size\n     pd.set(7, group);\n \n     op->load_param(pd);\n \n     Mat weight_data_g(3*3*10, (void*)weight_data);\n     Mat bias_data_g(10, (void*)bias_data);\n \n     ncnn::Mat weights[2];\n     weights[0] = weight_data_g;\n     weights[1] = bias_data_g;\n \n     op->load_model(ModelBinFromMatArray(weights));\n \n     op->forward(bottom_blob, top_blob);\n \n     // 5- display result\n     fprintf(stderr, \"After ConvolutionDepthWise input %d x %d  pad = %d %d  ksize=%d %d  dilation=%d %d  stride=%d %d:\\n\", bottom_blob.w, bottom_blob.h, pad_w, pad_h, kernel_w, kernel_h, dilation_w, dilation_h, stride_w, stride_h);\n     for (int n = 0; n < top_blob.c; ++n)\n     {\n         Mat top_blob_g = top_blob.channel(n);\n         for (int r = 0; r < top_blob_g.h; ++r)\n         {\n             float *ptr = top_blob_g.row(r);\n             for (int c = 0; c < top_blob_g.w; ++c)\n             {\n                 std::cout << ptr[c] << ' ';\n             }\n             std::cout << std::endl;\n         }\n     }\n \n     return 0;\n }\n and the result is:\n \n Produce all 1 to bottom_blob for init:\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n 1 1 1 1 1\n \n \n Produce all 3.12 to top_blob for checking:\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n \n \n After ConvolutionDepthWise input 5 x 5  pad = 2 2  ksize=3 3  dilation=2 2  stride=1 1:\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n 3.12 3.12 3.12 3.12 3.12\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Lamply", "commentT": "2018-03-29T11:31:23Z", "comment_text": "\n \t\tI find that the final result produce in here:\n \n \n \n ncnn/src/layer/x86/convolutiondepthwise_x86.cpp\n \n \n          Line 140\n       in\n       415bfbd\n \n \n \n \n \n \n  op->forward(bottom_blob_bordered_g, top_blob_g); \n \n \n \n \n \n is correct, but it doesn't effect the output top_blob. Then I manually element-wise assign the top_blob_g to top_blob, and problem disappear.\n Further more, It can simply solve by adding an top_blob empty check before here:\n \n \n \n ncnn/src/layer/convolution.cpp\n \n \n          Line 137\n       in\n       415bfbd\n \n \n \n \n \n \n  top_blob.create(outw, outh, num_output); \n \n \n \n \n \n \t\t"}}}, "commit": {"commit_id": "9ac305e1604ef9bc7735cdc140074020b06d1537", "commit_author": "nihuini", "commitT": "2018-03-29 20:17:21+08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\layer\\arm\\convolutiondepthwise_arm.cpp", "file_new_name": "src\\layer\\arm\\convolutiondepthwise_arm.cpp", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "106,107", "deleted_lines": "106,107", "method_info": {"method_name": "ncnn::ConvolutionDepthWise_arm::forward", "method_params": "bottom_blob,top_blob", "method_startline": "29", "method_endline": "196"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\layer\\arm\\deconvolutiondepthwise_arm.cpp", "file_new_name": "src\\layer\\arm\\deconvolutiondepthwise_arm.cpp", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "66,67,118", "deleted_lines": "66,67,117", "method_info": {"method_name": "ncnn::DeconvolutionDepthWise_arm::forward", "method_params": "bottom_blob,top_blob", "method_startline": "27", "method_endline": "171"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\layer\\x86\\convolutiondepthwise_x86.cpp", "file_new_name": "src\\layer\\x86\\convolutiondepthwise_x86.cpp", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "106,107", "deleted_lines": "106,107", "method_info": {"method_name": "ncnn::ConvolutionDepthWise_x86::forward", "method_params": "bottom_blob,top_blob", "method_startline": "29", "method_endline": "196"}}}}}}}