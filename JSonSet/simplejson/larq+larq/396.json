{"BR": {"BR_id": "396", "BR_author": "jneeven", "BRopenT": "2020-01-24T16:02:11Z", "BRcloseT": "2020-05-07T14:07:29Z", "BR_text": {"BRsummary": "`CaseOptimizer` broken on multi-GPU", "BRdescription": "\n <denchmark-h:h3>Describe the bug</denchmark-h>\n \n When training a model using the CaseOptimizer on multi-GPU (4 of them in my case, both p100 and v100 will break), I get the following error:\n <denchmark-code>WARNING:tensorflow:There is non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n distributed training:  False\n Train on 60000 samples\n 60000/60000 [==============================] - 4s 61us/sample - loss: 8.2390\n Successfully fitted model\n \n distributed training:  True\n Train on 60000 samples\n INFO:tensorflow:Error reported to Coordinator: list index out of range\n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/coordinator.py\", line 297, in stop_on_exception\n     yield\n   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 190, in _call_for_each_replica\n     **merge_kwargs)\n   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 446, in _distributed_apply\n     ds_reduce_util.ReduceOp.SUM, grads_and_vars)\n   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1481, in batch_reduce_to\n     return self._batch_reduce_to(reduce_op, value_destination_pairs)\n   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 707, in _batch_reduce_to\n     value_destination_pairs)\n   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 317, in batch_reduce\n     value_destination_pairs[0][0].values) == 1:\n IndexError: list index out of range\n    32/60000 [..............................] - ETA: 10:32Exception raised: \n  list index out of range\n </denchmark-code>\n \n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n import contextlib\n import numpy as np\n import tensorflow.keras as keras\n import larq as lq\n import tensorflow as tf\n \n \n def get_model():\n     model = keras.Sequential()\n     model.add(keras.layers.Flatten(input_shape=(28, 28)))\n     model.add(\n         lq.layers.QuantDense(\n             units=10,\n             input_quantizer=\"ste_sign\",\n             kernel_quantizer=\"ste_sign\",\n             kernel_constraint=\"weight_clip\",\n             name=\"layer_1\"\n         )\n     )\n     model.add(keras.layers.Dense(units=10, name=\"layer_2\"))\n     \n     \n     def is_layer_1(var: tf.Variable) -> bool:\n         layer_name = var.name.split(\"/\")[-2]\n         return layer_name == \"layer_1\"\n     \n     optimizer = lq.optimizers.CaseOptimizer(\n         (is_layer_1, keras.optimizers.Adam()),\n         default_optimizer=keras.optimizers.Adam(),\n     )\n \n #     optimizer = keras.optimizers.Adam()\n \n     model.compile(\n         optimizer=optimizer, loss=\"sparse_categorical_crossentropy\"\n     )\n     return model\n \n \n def attempt_fit(distributed_training=False):\n     fashion_mnist = keras.datasets.fashion_mnist\n     (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n     train_images = train_images / 255.0\n     test_images = test_images / 255.0\n \n     with strategy.scope() if distributed_training else contextlib.nullcontext():\n         model = get_model()\n         model.fit(train_images, train_labels, epochs=1)\n \n \n if __name__ == \"__main__\":\n     keras.backend.clear_session()\n     \n     strategy = tf.distribute.MirroredStrategy()\n     for distributed_training in [False, True]:\n         print(\"distributed training: \", distributed_training)\n         try:\n             attempt_fit(distributed_training)\n             print(\"Successfully fitted model\")\n         except Exception as e:\n             print(\"Exception raised: \\n\", e)\n         print()          \n For simplicity, you can change the predicate of the optimizer to lambda x: False; it makes no difference whether it actually selects any layers or not. Using keras.optimizers.Adam instead of the CaseOptimizer will work just fine.\n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n I expected it to train, as it does in the single-GPU case.\n <denchmark-h:h3>Environment</denchmark-h>\n \n TensorFlow version: 2.0.0\n Larq version: 0.8.3\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jneeven", "commentT": "2020-01-24T16:08:40Z", "comment_text": "\n \t\tIt's printing an interesting warning:\n \n WARNING:tensorflow:There is non-GPU devices in tf.distribute.Strategy, not using nccl allreduce.\n \n Anyway, if I submit this to Polyaxon using a more complex environment, I get a different error:\n <denchmark-code>2020-01-24 14:50:52 UTC -- Epoch 1/20\n \n 2020-01-24 14:50:55 UTC -- Traceback (most recent call last):\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py\", line 470, in _type_spec\n \n 2020-01-24 14:50:55 UTC --     value_specs = [type_spec.type_spec_from_value(v) for v in self._values]\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py\", line 470, in <listcomp>\n \n 2020-01-24 14:50:55 UTC --     value_specs = [type_spec.type_spec_from_value(v) for v in self._values]\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/type_spec.py\", line 492, in type_spec_from_value\n \n 2020-01-24 14:50:55 UTC --     (value, type(value).__name__))\n \n 2020-01-24 14:50:55 UTC -- TypeError: Could not build a TypeSpec for <tf.Operation 'train_with_group' type=NoOp> with type Operation\n \n 2020-01-24 14:50:55 UTC -- \n \n 2020-01-24 14:50:55 UTC -- The above exception was the direct cause of the following exception:\n \n 2020-01-24 14:50:55 UTC -- \n \n 2020-01-24 14:50:55 UTC -- Traceback (most recent call last):\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/bin/project\", line 11, in <module>\n \n 2020-01-24 14:50:55 UTC --     load_entry_point('research-project', 'console_scripts', 'project')()\n \n 2020-01-24 14:50:55 UTC --   File \"/code/main.py\", line 19, in cli\n \n 2020-01-24 14:50:55 UTC --     cli()\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 764, in __call__\n \n 2020-01-24 14:50:55 UTC --     return self.main(*args, **kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 717, in main\n \n 2020-01-24 14:50:55 UTC --     rv = self.invoke(ctx)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1137, in invoke\n \n 2020-01-24 14:50:55 UTC --     return _process_result(sub_ctx.command.invoke(sub_ctx))\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 956, in invoke\n \n 2020-01-24 14:50:55 UTC --     return ctx.invoke(self.callback, **ctx.params)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 555, in invoke\n \n 2020-01-24 14:50:55 UTC --     return callback(*args, **kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/zookeeper/core/task.py\", line 60, in command\n \n 2020-01-24 14:50:55 UTC --     task_instance.run()\n \n 2020-01-24 14:50:55 UTC --   File \"/code/core/polyaxon_experiment.py\", line 31, in wrapper\n \n 2020-01-24 14:50:55 UTC --     run_method(self)\n \n 2020-01-24 14:50:55 UTC --   File \"/code/project/experiments/project_experiment.py\", line 221, in run\n \n 2020-01-24 14:50:55 UTC --     callbacks=callbacks,\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\n \n 2020-01-24 14:50:55 UTC --     use_multiprocessing=use_multiprocessing)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 324, in fit\n \n 2020-01-24 14:50:55 UTC --     total_epochs=epochs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\n \n 2020-01-24 14:50:55 UTC --     batch_outs = execution_function(iterator)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\n \n 2020-01-24 14:50:55 UTC --     distributed_function(input_fn))\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\n \n 2020-01-24 14:50:55 UTC --     result = self._call(*args, **kwds)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\n \n 2020-01-24 14:50:55 UTC --     self._initialize(args, kwds, add_initializers_to=initializer_map)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\n \n 2020-01-24 14:50:55 UTC --     *args, **kwds))\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\n \n 2020-01-24 14:50:55 UTC --     graph_function, _, _ = self._maybe_define_function(args, kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\n \n 2020-01-24 14:50:55 UTC --     graph_function = self._create_graph_function(args, kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\n \n 2020-01-24 14:50:55 UTC --     capture_by_value=self._capture_by_value),\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\n \n 2020-01-24 14:50:55 UTC --     func_outputs = python_func(*func_args, **func_kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\n \n 2020-01-24 14:50:55 UTC --     return weak_wrapped_fn().__wrapped__(*args, **kwds)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 73, in distributed_function\n \n 2020-01-24 14:50:55 UTC --     per_replica_function, args=(model, x, y, sample_weights))\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 760, in experimental_run_v2\n \n 2020-01-24 14:50:55 UTC --     return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1787, in call_for_each_replica\n \n 2020-01-24 14:50:55 UTC --     return self._call_for_each_replica(fn, args, kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 661, in _call_for_each_replica\n \n 2020-01-24 14:50:55 UTC --     fn, args, kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 196, in _call_for_each_replica\n \n 2020-01-24 14:50:55 UTC --     coord.join(threads)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/coordinator.py\", line 389, in join\n \n 2020-01-24 14:50:55 UTC --     six.reraise(*self._exc_info_to_raise)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 703, in reraise\n \n 2020-01-24 14:50:55 UTC --     raise value\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/coordinator.py\", line 297, in stop_on_exception\n \n 2020-01-24 14:50:55 UTC --     yield\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 190, in _call_for_each_replica\n \n 2020-01-24 14:50:55 UTC --     **merge_kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/mixed_precision/experimental/loss_scale_optimizer.py\", line 241, in _apply_gradients_cross_replica\n \n 2020-01-24 14:50:55 UTC --     control_flow_ops.no_op)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/smart_cond.py\", line 59, in smart_cond\n \n 2020-01-24 14:50:55 UTC --     name=name)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n \n 2020-01-24 14:50:55 UTC --     return func(*args, **kwargs)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1174, in cond\n \n 2020-01-24 14:50:55 UTC --     return cond_v2.cond_v2(pred, true_fn, false_fn, name)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/cond_v2.py\", line 84, in cond_v2\n \n 2020-01-24 14:50:55 UTC --     op_return_value=pred)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 920, in func_graph_from_py_func\n \n 2020-01-24 14:50:55 UTC --     expand_composites=True)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/nest.py\", line 531, in map_structure\n \n 2020-01-24 14:50:55 UTC --     flat_structure = [flatten(s, expand_composites) for s in structure]\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/nest.py\", line 531, in <listcomp>\n \n 2020-01-24 14:50:55 UTC --     flat_structure = [flatten(s, expand_composites) for s in structure]\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/nest.py\", line 262, in flatten\n \n 2020-01-24 14:50:55 UTC --     return _pywrap_tensorflow.Flatten(structure, expand_composites)\n \n 2020-01-24 14:50:55 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 2651, in Flatten\n \n 2020-01-24 14:50:55 UTC --     return _pywrap_tensorflow_internal.Flatten(nested, expand_composites)\n \n 2020-01-24 14:50:55 UTC -- SystemError: <built-in function Flatten> returned a result with an error set\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jneeven", "commentT": "2020-01-24T16:13:59Z", "comment_text": "\n \t\tI think we had a similar issue with  in <denchmark-link:https://github.com/larq/larq/issues/286>#286</denchmark-link>\n  where distribution strategy will fail if no variables are available to be assigned too via an optimizer  : \n Could you double check that both optimizers actually receive variables to train?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jneeven", "commentT": "2020-01-24T16:15:49Z", "comment_text": "\n \t\t\n I think we had a similar issue with Bop in #286 where distribution strategy will fail if no variables are available to be assigned too via an optimizer : TypeError: Could not build a TypeSpec for <tf.Operation 'train_with_group' type=NoOp> with type Operation\n Could you double check that both optimizers actually receive variables to train?\n \n I have verified that is_layer_1 returns True for the first layer and False for the second layer (when called from the CaseOptimizer). Is there a more direct way to check which variables are assigned to which optimizer?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jneeven", "commentT": "2020-01-24T16:20:21Z", "comment_text": "\n \t\tI can reproduce the error above in this <denchmark-link:https://colab.research.google.com/drive/1vU9P20rzPNd-ioiQhZYbruGXAxEvL3Ip>notebook</denchmark-link>\n  with TensorFlow 2.0.0. TensorFlow 2.1.0 doesn't seem to show this error.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jneeven", "commentT": "2020-01-24T16:21:47Z", "comment_text": "\n \t\tI believe I also obtained this error with TF2.1.0, but will try again\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "jneeven", "commentT": "2020-01-24T16:28:18Z", "comment_text": "\n \t\t\n I believe I also obtained this error with TF2.1.0, but will try again\n \n I can reproduce this issue in TF 1.15.x as well, but can't with 2.1. Checkout <denchmark-link:https://colab.research.google.com/drive/1BTTQVOyY737GtB_pddF-VvAdBrPN14HK>this notebook</denchmark-link>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "jneeven", "commentT": "2020-01-27T10:18:44Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jneeven>@jneeven</denchmark-link>\n  is this fixed for you by running experiments on TF2.1?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "jneeven", "commentT": "2020-01-27T10:22:41Z", "comment_text": "\n \t\t\n @jneeven is this fixed for you by running experiments on TF2.1?\n \n Nope, I still get the same error with TF2.1 (actually using multiple GPUs). I could not test the fake multi-GPU case, because I ran into some XLA problems.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "jneeven", "commentT": "2020-02-14T10:42:55Z", "comment_text": "\n \t\tI found that the case optimizer breaks on multi-gpu when using TF 2.0 due to a distribution strategy related error, however works fine when using TF 2.1 with lq.optimizers.Bop.is_binary_variable as a predicate.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "jneeven", "commentT": "2020-03-16T13:44:46Z", "comment_text": "\n \t\tHi, I found the case optimizer works for both TF 2.0 and 2.1. The original script above can be fixed by calling  in between the single and multi gpu test (<denchmark-link:https://colab.research.google.com/drive/1j5p4NZmYBWfQYLisAIVlhaYRs-IqSpH2>notebook</denchmark-link>\n ). I did encounter the problem with , but only when running in reduced precision.\n Could someone double check if this solves the problems with the case optimizer? If so, we can close this issue.\n \t\t"}}}, "commit": {"commit_id": "56d7dca6d3e68d82d1b172251f3c97c71bc9fe9a", "commit_author": "Lukas Geiger", "commitT": "2020-05-07 15:07:28+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "larq\\optimizers.py", "file_new_name": "larq\\optimizers.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "142,143,144,145,146,147,148", "deleted_lines": "145", "method_info": {"method_name": "apply_gradients", "method_params": "self,grads_and_vars,None,kwargs", "method_startline": "123", "method_endline": "148"}}, "hunk_1": {"Ismethod": 1, "added_lines": "150,154,155,156", "deleted_lines": null, "method_info": {"method_name": "_apply_gradients", "method_params": "self,distribution,grad_var_lists,name,kwargs", "method_startline": "150", "method_endline": "162"}}}}}}}