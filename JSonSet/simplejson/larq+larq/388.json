{"BR": {"BR_id": "388", "BR_author": "MariaHeuss", "BRopenT": "2020-01-17T15:04:52Z", "BRcloseT": "2020-02-27T21:50:13Z", "BR_text": {"BRsummary": "Flip-ratio does not work on Multi GPU", "BRdescription": "\n <denchmark-h:h3>Describe the bug</denchmark-h>\n \n Trying to use the flip ratio metric on multi GPU gives me an error.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n import contextlib\n import numpy as np\n import tensorflow.keras as keras\n import larq as lq\n import tensorflow as tf\n \n \n def get_model():\n     model = keras.Sequential()\n     model.add(keras.layers.Flatten(input_shape=(28, 28)))\n     model.add(\n         lq.layers.QuantDense(\n             10,\n             input_quantizer=\"ste_sign\",\n             kernel_quantizer=\"ste_sign\",\n             kernel_constraint=\"weight_clip\",\n         )\n     )\n \n     model.compile(\n         optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\"\n     )\n     return model\n \n \n def attempt_fit_with_metric(metrics=[], distributed_training=False):\n     fashion_mnist = keras.datasets.fashion_mnist\n     (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n     train_images = train_images / 255.0\n     test_images = test_images / 255.0\n \n     with strategy.scope() if distributed_training else contextlib.nullcontext():\n         with lq.metrics.scope(metrics):\n             model = get_model()\n         model.fit(train_images, train_labels, epochs=1)\n \n \n if __name__ == \"__main__\":\n     strategy = tf.distribute.MirroredStrategy()\n     for distributed_training in [False, True]:\n         for metrics in [[], [\"flip_ratio\"]]:\n             print(\"distributed training: \", distributed_training)\n             print(\"metric:\", metrics)\n             try:\n                 attempt_fit_with_metric(metrics, distributed_training)\n                 print(\n                     \"Successfully fittet model with metric \",\n                     metrics,\n                     \", and distributed training = \",\n                     distributed_training,\n                 )\n             except Exception as e:\n                 print(\"Exception raised: \\n\", e)\n             print()\n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n I get the following error, while I would expect the flip ratio to work on both single and multi GPU.\n <denchmark-code>INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n distributed training:  False\n metric: []\n Train on 60000 samples\n 60000/60000 [==============================] - 3s 56us/sample - loss: 11.0572\n Successfully fittet model with metric  [] , and distributed training =  False\n \n distributed training:  False\n metric: ['flip_ratio']\n Train on 60000 samples\n 60000/60000 [==============================] - 4s 64us/sample - loss: 12.3813 - flip_ratio/quant_dense_1: 5.9605e-08\n Successfully fittet model with metric  ['flip_ratio'] , and distributed training =  False\n \n distributed training:  True\n metric: []\n Train on 60000 samples\n INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n INFO:tensorflow:batch_all_reduce: 2 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n 60000/60000 [==============================] - 9s 156us/sample - loss: 11.0572\n Successfully fittet model with metric  [] , and distributed training =  True\n \n distributed training:  True\n metric: ['flip_ratio']\n Train on 60000 samples\n WARNING:tensorflow:Gradients do not exist for variables ['quant_dense_3/kernel:0'] when minimizing the loss.\n INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n INFO:tensorflow:batch_all_reduce: 1 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n    32/60000 [..............................] - ETA: 1:44:14Exception raised: \n  An op outside of the function building code is being passed\n a \"Graph\" tensor. It is possible to have Graph tensors\n leak out of the function building context by including a\n tf.init_scope in your function building code.\n For example, the following function will fail:\n   @tf.function\n   def has_init_scope():\n     my_constant = tf.constant(1.)\n     with tf.init_scope():\n       added = my_constant * 2\n The graph tensor has name: replica_2/sequential_3/quant_dense_3/IdentityN_1:0\n </denchmark-code>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n TensorFlow version: 2.1.0\n Larq version: 0.8.2\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "MariaHeuss", "commentT": "2020-01-17T16:24:07Z", "comment_text": "\n \t\tI can reproduce it in <denchmark-link:https://colab.research.google.com/drive/168lbGqwZMYSTwHVlR1IjAlmb5yl8TFkx>this colab</denchmark-link>\n .\n I'll take a closer look at this next week.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "MariaHeuss", "commentT": "2020-01-17T17:30:32Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/MariaHeuss>@MariaHeuss</denchmark-link>\n  I just retested this and cannot reproduce this with larq installed from . For now I don't know a workaround other than installing larq from  (which unfortunately includes some breaking changes).\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "MariaHeuss", "commentT": "2020-02-13T16:46:20Z", "comment_text": "\n \t\tI can confirm that this is still broken on 0.8.4. When installing larq from master, I get some interesting warnings:\n <denchmark-code>2020-02-13 16:41:40 UTC -- WARNING:tensorflow:5 out of the last 5 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe23859d7d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:40 UTC -- WARNING:tensorflow:5 out of the last 5 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe23859d7d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:40 UTC -- WARNING:tensorflow:6 out of the last 6 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe23859d7d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:40 UTC -- WARNING:tensorflow:6 out of the last 6 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe23859d7d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:7 out of the last 7 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe23859d7d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:7 out of the last 7 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe23859d7d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:8 out of the last 8 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe23859d7d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:8 out of the last 8 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe23859d7d0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:5 out of the last 5 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2381adb50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:5 out of the last 5 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2381adb50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:6 out of the last 6 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2381adb50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:6 out of the last 6 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2381adb50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:7 out of the last 7 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2381adb50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:7 out of the last 7 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2381adb50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:8 out of the last 8 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2381adb50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:8 out of the last 8 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2381adb50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:5 out of the last 5 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2006fac50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:5 out of the last 5 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2006fac50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:6 out of the last 6 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2006fac50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:6 out of the last 6 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2006fac50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:7 out of the last 7 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2006fac50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:7 out of the last 7 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2006fac50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:8 out of the last 8 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2006fac50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n \n 2020-02-13 16:41:41 UTC -- WARNING:tensorflow:8 out of the last 8 calls to <bound method FlipRatio.update_state of <larq.metrics.FlipRatio object at 0x7fe2006fac50>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n </denchmark-code>\n \n Other than that, it does work \ud83d\udc4d\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "MariaHeuss", "commentT": "2020-02-13T17:02:13Z", "comment_text": "\n \t\tCan you see if it still happens on <denchmark-link:https://github.com/larq/larq/pull/402>#402</denchmark-link>\n ?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "MariaHeuss", "commentT": "2020-02-13T17:08:22Z", "comment_text": "\n \t\t\n Can you see if it still happens on #402?\n \n Yeah remind me tomorrow \ud83d\udc4d\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "MariaHeuss", "commentT": "2020-02-14T09:08:36Z", "comment_text": "\n \t\tRemind!\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "MariaHeuss", "commentT": "2020-02-14T11:39:56Z", "comment_text": "\n \t\t\n Remind!\n \n It works and the warnings are gone \ud83c\udf89\n \t\t"}}}, "commit": {"commit_id": "38867bb13d977e5d85a4fe7ad90e54bb71680b9d", "commit_author": "Leon Overweel", "commitT": "2020-02-27 21:50:11+00:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 7, "file_old_name": "larq\\layers.py", "file_new_name": "larq\\layers.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "542", "method_info": {"method_name": "__init__", "method_params": "self,kernel_size,strides,1", "method_startline": "524", "method_endline": "543"}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "319", "method_info": {"method_name": "__init__", "method_params": "self,filters,kernel_size,strides,1", "method_startline": "300", "method_endline": "320"}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "106", "method_info": {"method_name": "__init__", "method_params": "self,units,activation,use_bias,input_quantizer,kernel_quantizer,kernel_initializer,bias_initializer,kernel_regularizer,bias_regularizer,activity_regularizer,kernel_constraint,bias_constraint,metrics,kwargs", "method_startline": "92", "method_endline": "107"}}, "hunk_3": {"Ismethod": 1, "added_lines": null, "deleted_lines": "439", "method_info": {"method_name": "__init__", "method_params": "self,filters,kernel_size,strides,1,1", "method_startline": "420", "method_endline": "440"}}, "hunk_4": {"Ismethod": 1, "added_lines": null, "deleted_lines": "1171", "method_info": {"method_name": "__init__", "method_params": "self,filters,kernel_size,strides,padding,data_format,activation,use_bias,input_quantizer,kernel_quantizer,kernel_initializer,bias_initializer,kernel_regularizer,bias_regularizer,activity_regularizer,kernel_constraint,bias_constraint,metrics,implementation,kwargs", "method_startline": "1153", "method_endline": "1173"}}, "hunk_5": {"Ismethod": 1, "added_lines": null, "deleted_lines": "652", "method_info": {"method_name": "__init__", "method_params": "self,filters,kernel_size,strides,padding,data_format,dilation_rate,depth_multiplier,activation,use_bias,input_quantizer,depthwise_quantizer,pointwise_quantizer,depthwise_initializer,pointwise_initializer,bias_initializer,depthwise_regularizer,pointwise_regularizer,bias_regularizer,activity_regularizer,depthwise_constraint,pointwise_constraint,bias_constraint,metrics,kwargs", "method_startline": "628", "method_endline": "653"}}, "hunk_6": {"Ismethod": 1, "added_lines": null, "deleted_lines": "205", "method_info": {"method_name": "__init__", "method_params": "self,filters,kernel_size,strides,padding,data_format,dilation_rate,activation,use_bias,input_quantizer,kernel_quantizer,kernel_initializer,bias_initializer,kernel_regularizer,bias_regularizer,activity_regularizer,kernel_constraint,bias_constraint,metrics,kwargs", "method_startline": "186", "method_endline": "206"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 7, "file_old_name": "larq\\layers_base.py", "file_new_name": "larq\\layers_base.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "77,78,79", "method_info": {"method_name": "build", "method_params": "self,input_shape", "method_startline": "75", "method_endline": "79"}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "110", "method_info": {"method_name": "__init__", "method_params": "self,args,None,None,metrics,kwargs", "method_startline": "105", "method_endline": "111"}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "167", "method_info": {"method_name": "__init__", "method_params": "self,args,None,None,None,metrics,kwargs", "method_startline": "161", "method_endline": "168"}}, "hunk_3": {"Ismethod": 1, "added_lines": "45,47,49,50", "deleted_lines": "45,46,56,57", "method_info": {"method_name": "__init__", "method_params": "self,args,input_quantizer,kernel_quantizer,kwargs", "method_startline": "45", "method_endline": "57"}}, "hunk_4": {"Ismethod": 1, "added_lines": null, "deleted_lines": "85,86", "method_info": {"method_name": "call", "method_params": "self,inputs", "method_startline": "81", "method_endline": "87"}}, "hunk_5": {"Ismethod": 1, "added_lines": "45", "deleted_lines": "37,38,39,40,41,42,43,44,45", "method_info": {"method_name": "non_trainable_weights", "method_params": "self", "method_startline": "37", "method_endline": "45"}}, "hunk_6": {"Ismethod": 1, "added_lines": null, "deleted_lines": "56,57", "method_info": {"method_name": "__init__", "method_params": "self,args,input_quantizer,kernel_quantizer,metrics,kwargs", "method_startline": "56", "method_endline": "57"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "larq\\layers_test.py", "file_new_name": "larq\\layers_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "273", "method_info": {"method_name": "test_layer_kwargs", "method_params": "quant_layer,layer", "method_startline": "261", "method_endline": "282"}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244", "method_info": {"method_name": "test_metrics", "method_params": "", "method_startline": "219", "method_endline": "244"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "larq\\metrics.py", "file_new_name": "larq\\metrics.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "121,122,123,125,126,127,128,129,130", "deleted_lines": "123,124", "method_info": {"method_name": "update_state", "method_params": "self,values,sample_weight", "method_startline": "120", "method_endline": "136"}}, "hunk_1": {"Ismethod": 1, "added_lines": "23,35", "deleted_lines": "23,35", "method_info": {"method_name": "scope", "method_params": "metrics", "method_startline": "22", "method_endline": "47"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "larq\\metrics_test.py", "file_new_name": "larq\\metrics_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "58,59,60,61,62", "deleted_lines": null, "method_info": {"method_name": "test_metric_wrong_shape", "method_params": "eager_mode", "method_startline": "58", "method_endline": "62"}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "larq\\quantizers.py", "file_new_name": "larq\\quantizers.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "163,164", "deleted_lines": null, "method_info": {"method_name": "non_trainable_weights", "method_params": "self", "method_startline": "163", "method_endline": "164"}}, "hunk_1": {"Ismethod": 1, "added_lines": "149,150,151", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,args,metrics,kwargs", "method_startline": "149", "method_endline": "151"}}, "hunk_2": {"Ismethod": 1, "added_lines": "66,67", "deleted_lines": null, "method_info": {"method_name": "_clipped_gradient", "method_params": "x,dy,clip_value", "method_startline": "65", "method_endline": "73"}}, "hunk_3": {"Ismethod": 1, "added_lines": "153,154,155", "deleted_lines": null, "method_info": {"method_name": "build", "method_params": "self,input_shape", "method_startline": "153", "method_endline": "155"}}, "hunk_4": {"Ismethod": 1, "added_lines": "157,158,159,160", "deleted_lines": null, "method_info": {"method_name": "call", "method_params": "self,inputs", "method_startline": "157", "method_endline": "160"}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "larq\\quantizers_test.py", "file_new_name": "larq\\quantizers_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384", "deleted_lines": null, "method_info": {"method_name": "test_metrics", "method_params": "quantizer", "method_startline": "344", "method_endline": "384"}}}}}}}