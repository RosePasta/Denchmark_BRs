{"BR": {"BR_id": "286", "BR_author": "koenhelwegen", "BRopenT": "2019-10-11T14:04:21Z", "BRcloseT": "2019-10-14T17:55:36Z", "BR_text": {"BRsummary": "Bop not working with TF2 on MultiGPU", "BRdescription": "\n <denchmark-h:h3>Describe the bug</denchmark-h>\n \n In a multi-gpu environment, using Bop generates the following error:\n <denchmark-code>2019-10-11 13:45:47 UTC -- Epoch 1/150\n 2019-10-11 13:45:50 UTC -- Traceback (most recent call last):\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/bin/nf\", line 11, in <module>\n 2019-10-11 13:45:50 UTC --     load_entry_point('project-final', 'console_scripts', 'nf')()\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 764, in __call__\n 2019-10-11 13:45:50 UTC --     return self.main(*args, **kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 717, in main\n 2019-10-11 13:45:50 UTC --     rv = self.invoke(ctx)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1137, in invoke\n 2019-10-11 13:45:50 UTC --     return _process_result(sub_ctx.command.invoke(sub_ctx))\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 956, in invoke\n 2019-10-11 13:45:50 UTC --     return ctx.invoke(self.callback, **ctx.params)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 555, in invoke\n 2019-10-11 13:45:50 UTC --     return callback(*args, **kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/zookeeper/cli.py\", line 114, in train\n 2019-10-11 13:45:50 UTC --     function(build_model, dataset, hparams, output_dir, **kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/code/project_final/train.py\", line 110, in train\n 2019-10-11 13:45:50 UTC --     callbacks=callbacks,\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\n 2019-10-11 13:45:50 UTC --     use_multiprocessing=use_multiprocessing)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 324, in fit\n 2019-10-11 13:45:50 UTC --     total_epochs=epochs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\n 2019-10-11 13:45:50 UTC --     batch_outs = execution_function(iterator)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\n 2019-10-11 13:45:50 UTC --     distributed_function(input_fn))\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\n 2019-10-11 13:45:50 UTC --     result = self._call(*args, **kwds)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\n 2019-10-11 13:45:50 UTC --     self._initialize(args, kwds, add_initializers_to=initializer_map)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\n 2019-10-11 13:45:50 UTC --     *args, **kwds))\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\n 2019-10-11 13:45:50 UTC --     graph_function, _, _ = self._maybe_define_function(args, kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\n 2019-10-11 13:45:50 UTC --     graph_function = self._create_graph_function(args, kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\n 2019-10-11 13:45:50 UTC --     capture_by_value=self._capture_by_value),\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\n 2019-10-11 13:45:50 UTC --     func_outputs = python_func(*func_args, **func_kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\n 2019-10-11 13:45:50 UTC --     return weak_wrapped_fn().__wrapped__(*args, **kwds)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 73, in distributed_function\n 2019-10-11 13:45:50 UTC --     per_replica_function, args=(model, x, y, sample_weights))\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 760, in experimental_run_v2\n 2019-10-11 13:45:50 UTC --     return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1787, in call_for_each_replica\n 2019-10-11 13:45:50 UTC --     return self._call_for_each_replica(fn, args, kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 661, in _call_for_each_replica\n 2019-10-11 13:45:50 UTC --     fn, args, kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 196, in _call_for_each_replica\n 2019-10-11 13:45:50 UTC --     coord.join(threads)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/coordinator.py\", line 389, in join\n 2019-10-11 13:45:50 UTC --     six.reraise(*self._exc_info_to_raise)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 693, in reraise\n 2019-10-11 13:45:50 UTC --     raise value\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/coordinator.py\", line 297, in stop_on_exception\n 2019-10-11 13:45:50 UTC --     yield\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 190, in _call_for_each_replica\n 2019-10-11 13:45:50 UTC --     **merge_kwargs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 446, in _distributed_apply\n 2019-10-11 13:45:50 UTC --     ds_reduce_util.ReduceOp.SUM, grads_and_vars)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1481, in batch_reduce_to\n 2019-10-11 13:45:50 UTC --     return self._batch_reduce_to(reduce_op, value_destination_pairs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 707, in _batch_reduce_to\n 2019-10-11 13:45:50 UTC --     value_destination_pairs)\n 2019-10-11 13:45:50 UTC --   File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 317, in batch_reduce\n 2019-10-11 13:45:50 UTC --     value_destination_pairs[0][0].values) == 1:\n 2019-10-11 13:45:50 UTC -- IndexError: list index out of range\n </denchmark-code>\n \n The code runs fine if I use tf.keras.optimizers.Adam() instead of Bop, or if I run it on a single GPU.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n <denchmark-code>with tf.distribute.MirroredStrategy().scope():\n     model = build_model()\n     model.compile(\n         optimizer=lq.optimizers.Bop(tf.keras.optimizers.Adam()),\n         loss=\"categorical_crossentropy\",\n         metrics=[\"categorical_accuracy\", \"top_k_categorical_accuracy\"],\n         )\n model.fit(train_data)\n </denchmark-code>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n TensorFlow version: 2.0.0\n Larq version:  0.7.3\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "koenhelwegen", "commentT": "2019-10-14T14:53:30Z", "comment_text": "\n \t\tTurns out the problem is twofold:\n \n The direct cause for the error is that fp_grads_and_vars is empty, which apparently crashes in a distributed environments.\n However, fp_grads_and_vars shouldn't be empty (you have biases and bn vars); the problem is that the original grads_and_vars passed by the optimizer is a zip object which is empty after the first loop here.\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "koenhelwegen", "commentT": "2019-10-14T14:55:31Z", "comment_text": "\n \t\tThis should likely be solved together with <denchmark-link:https://github.com/larq/larq/issues/183>#183</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "koenhelwegen", "commentT": "2019-10-14T15:10:03Z", "comment_text": "\n \t\tI don't think we have a good solution for the API yet, while this a serious bug, so I would merge this fix asap. But yeah, I we should take on the API as well.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "koenhelwegen", "commentT": "2019-10-14T16:11:09Z", "comment_text": "\n \t\tChecked in TF1.14 and there the passed grads_and_vars is a list, so this worked as expected before TF2.0.\n \t\t"}}}, "commit": {"commit_id": "043e4e81404a6e6fd4ad51ece112b501e7e989fb", "commit_author": "Koen Helwegen", "commitT": "2019-10-14 18:55:35+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "larq\\optimizers_test.py", "file_new_name": "larq\\optimizers_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "26,27", "deleted_lines": "26", "method_info": {"method_name": "_test_optimizer", "method_params": "optimizer,target,test_kernels_are_binary,trainable_bn", "method_startline": "26", "method_endline": "27"}}, "hunk_1": {"Ismethod": 1, "added_lines": "26,27,28,35,36,37,39,40,41,44,45", "deleted_lines": "26,33", "method_info": {"method_name": "_test_optimizer", "method_params": "optimizer,target,test_kernels_are_binary", "method_startline": "26", "method_endline": "45"}}, "hunk_2": {"Ismethod": 1, "added_lines": "119,120,121,122,123,124,125", "deleted_lines": null, "method_info": {"method_name": "test_bop_accuracy", "method_params": "self", "method_startline": "114", "method_endline": "125"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "larq\\optimizers_v2.py", "file_new_name": "larq\\optimizers_v2.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "61,62,63,64,65,66,70", "deleted_lines": "61,62,65", "method_info": {"method_name": "apply_gradients", "method_params": "self,grads_and_vars,name", "method_startline": "60", "method_endline": "71"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "larq\\testing_utils.py", "file_new_name": "larq\\testing_utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "10,22", "deleted_lines": "10,22", "method_info": {"method_name": "get_small_bnn_model", "method_params": "input_dim,num_hidden,output_dim", "method_startline": "10", "method_endline": "33"}}, "hunk_1": {"Ismethod": 1, "added_lines": "10,22", "deleted_lines": "10,22", "method_info": {"method_name": "get_small_bnn_model", "method_params": "input_dim,num_hidden,output_dim,trainable_bn", "method_startline": "10", "method_endline": "33"}}}}}}}