{"BR": {"BR_id": "223", "BR_author": "capavrulus", "BRopenT": "2020-11-01T09:45:08Z", "BRcloseT": "2020-11-02T02:37:21Z", "BR_text": {"BRsummary": "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!", "BRdescription": "\n I made my own recipe but I got this error when I started training. I have no idea how this error occurred because theoretically it shouldn't depend on which recipe I use. I don't even know which variable is not on GPU.\n sc_loss, mag_loss = self.criterion[\"stft\"](y_.squeeze(1), y.squeeze(1)) both y_ and y are on GPU.\n sc_l, mag_l = f(x, y) both x and y are on GPU.\n x_stft = torch.stft(x, fft_size, hop_size, win_length, window) x is on GPU.\n \n [train]:   0%|          | 0/400000 [00:00<?, ?it/s]/home/train/.local/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n normalized, onesided, return_complex)\n Traceback (most recent call last):\n File \"/home/train/.local/bin/parallel-wavegan-train\", line 11, in \n load_entry_point('parallel-wavegan', 'console_scripts', 'parallel-wavegan-train')()\n File \"/home/train/ParallelWaveGAN/parallel_wavegan/bin/train.py\", line 921, in main\n trainer.run()\n File \"/home/train/ParallelWaveGAN/parallel_wavegan/bin/train.py\", line 91, in run\n self._train_epoch()\n File \"/home/train/ParallelWaveGAN/parallel_wavegan/bin/train.py\", line 291, in _train_epoch\n self._train_step(batch)\n File \"/home/train/ParallelWaveGAN/parallel_wavegan/bin/train.py\", line 175, in train_step\n sc_loss, mag_loss = self.criterion[\"stft\"](y.squeeze(1), y.squeeze(1))\n File \"/home/train/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n result = self.forward(*input, **kwargs)\n File \"/home/train/ParallelWaveGAN/parallel_wavegan/losses/stft_loss.py\", line 147, in forward\n sc_l, mag_l = f(x, y)\n File \"/home/train/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n result = self.forward(*input, **kwargs)\n File \"/home/train/ParallelWaveGAN/parallel_wavegan/losses/stft_loss.py\", line 101, in forward\n x_mag = stft(x, self.fft_size, self.shift_size, self.win_length, self.window)\n File \"/home/train/ParallelWaveGAN/parallel_wavegan/losses/stft_loss.py\", line 26, in stft\n x_stft = torch.stft(x, fft_size, hop_size, win_length, window)\n File \"/home/train/.local/lib/python3.7/site-packages/torch/functional.py\", line 516, in stft\n normalized, onesided, return_complex)\n RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "capavrulus", "commentT": "2020-11-01T09:26:55Z", "comment_text": "\n \t\tMaybe you use torch==1.7.\n Not yet tested.\n For quick fixing, please use torch<=1.6.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "capavrulus", "commentT": "2020-11-01T09:33:05Z", "comment_text": "\n \t\t\n Maybe you use torch==1.7.\n Not yet tested.\n For quick fixing, please use torch<=1.6.\n \n Resolved by using torch==1.6.0. Thank you!\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "capavrulus", "commentT": "2020-11-02T02:37:43Z", "comment_text": "\n \t\tFixed in <denchmark-link:https://github.com/kan-bayashi/ParallelWaveGAN/pull/225>#225</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "a4f8c0960d016ecba6b29522b518ee759373a9ca", "commit_author": "kan-bayashi", "commitT": "2020-11-02 11:22:36+09:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "parallel_wavegan\\losses\\stft_loss.py", "file_new_name": "parallel_wavegan\\losses\\stft_loss.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "30,31,32,33,34,35", "deleted_lines": "26", "method_info": {"method_name": "stft", "method_params": "x,fft_size,hop_size,win_length,window", "method_startline": "16", "method_endline": "40"}}, "hunk_1": {"Ismethod": 1, "added_lines": "88,89", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,fft_size,shift_size,win_length,window", "method_startline": "88", "method_endline": "89"}}, "hunk_2": {"Ismethod": 1, "added_lines": "124,125,126,127,128,129", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,fft_sizes,2048,hop_sizes,240,win_lengths,1200,window", "method_startline": "124", "method_endline": "129"}}, "hunk_3": {"Ismethod": 1, "added_lines": null, "deleted_lines": "79,85", "method_info": {"method_name": "__init__", "method_params": "self,fft_size,shift_size,win_length,window", "method_startline": "79", "method_endline": "87"}}, "hunk_4": {"Ismethod": 1, "added_lines": null, "deleted_lines": "112,113,114,115,116", "method_info": {"method_name": "__init__", "method_params": "self,fft_sizes,2048,hop_sizes,240,win_lengths,1200,window", "method_startline": "112", "method_endline": "116"}}}}}}}