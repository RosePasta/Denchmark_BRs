{"BR": {"BR_id": "4646", "BR_author": "tpanza", "BRopenT": "2020-09-17T17:38:06Z", "BRcloseT": "2020-10-15T01:48:51Z", "BR_text": {"BRsummary": "Cannot train NER model that uses bidirectional_lm_token_embedder: RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu", "BRdescription": "\n <denchmark-h:h2>Checklist</denchmark-h>\n \n \n  I have verified that the issue exists against the master branch of AllenNLP.\n  I have read the relevant section in the contribution guide on reporting bugs.\n  I have checked the issues list for similar or identical bug reports.\n  I have checked the pull requests list for existing proposed fixes.\n  I have checked the CHANGELOG and the commit log to find out if the bug was already fixed in the master branch.\n  I have included in the \"Description\" section below a traceback from any exceptions related to this bug.\n  I have included in the \"Related issues or possible duplicates\" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).\n  I have included in the \"Environment\" section below the name of the operating system and Python version that I was using when I discovered this bug.\n  I have included in the \"Environment\" section below the output of pip freeze.\n  I have included in the \"Steps to reproduce\" section below a minimally reproducible example.\n \n <denchmark-h:h2>Description</denchmark-h>\n \n \n Python traceback:\n \n 2020-09-16 17:06:02,589 - INFO - allennlp.training.trainer - Beginning training.\n 2020-09-16 17:06:02,589 - INFO - allennlp.training.trainer - Epoch 0/21\n 2020-09-16 17:06:02,589 - INFO - allennlp.training.trainer - Worker 0 memory usage MB: 3118.312\n 2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1314\n 2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 11\n 2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 2 memory usage MB: 11\n 2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 3 memory usage MB: 11\n 2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 4 memory usage MB: 11\n 2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 5 memory usage MB: 11\n 2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 6 memory usage MB: 11\n 2020-09-16 17:06:02,730 - INFO - allennlp.training.trainer - GPU 7 memory usage MB: 11\n 2020-09-16 17:06:02,732 - INFO - allennlp.training.trainer - Training\n   0%|          | 0/169 [00:00<?, ?it/s]\n 2020-09-16 17:06:02,784 - CRITICAL - root - Uncaught exception\n Traceback (most recent call last):\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/bin/allennlp\", line 8, in <module>\n     sys.exit(run())\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/__main__.py\", line 34, in run\n     main(prog=\"allennlp\")\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 92, in main\n     args.func(args)\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 118, in train_model_from_args\n     file_friendly_logging=args.file_friendly_logging,\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 177, in train_model_from_file\n     file_friendly_logging=file_friendly_logging,\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 238, in train_model\n     file_friendly_logging=file_friendly_logging,\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 443, in _train_worker\n     metrics = train_loop.run()\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/commands/train.py\", line 505, in run\n     return self.trainer.train()\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 867, in train\n     train_metrics = self._train_epoch(epoch)\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 589, in _train_epoch\n     batch_outputs = self.batch_outputs(batch, for_training=True)\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/training/trainer.py\", line 479, in batch_outputs\n     output_dict = self._pytorch_model(**batch)\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n     result = self.forward(*input, **kwargs)\n   File \"/localdata/tony/data-science/ner-refactor-pytorch/src/models/lstm.py\", line 46, in forward\n     embedded = self._embedder(tokens)\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n     result = self.forward(*input, **kwargs)\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/modules/text_field_embedders/basic_text_field_embedder.py\", line 84, in forward\n     token_vectors = embedder(list(tensors.values())[0], **forward_params_values)\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n     result = self.forward(*input, **kwargs)\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp_models/lm/modules/token_embedders/language_model.py\", line 187, in forward\n     tokens, mask, self._bos_indices, self._eos_indices\n   File \"/app/local/anaconda3/envs/torch1.6_allennlp1.1/lib/python3.7/site-packages/allennlp/nn/util.py\", line 1565, in add_sentence_boundary_token_ids\n     tensor_with_boundary_tokens[i, j + 1, :] = sentence_end_token\n RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n 2020-09-16 17:06:02,789 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpobwn4xyg\n \n \n \n <denchmark-h:h2>Related issues or possible duplicates</denchmark-h>\n \n \n #4336 (not positive about this one, but including it in case)\n #4554\n #4623\n #4632\n \n <denchmark-h:h2>Environment</denchmark-h>\n \n OS: Red Hat Enterprise Linux Server release 7.6 (Maipo), Linux 3.10.0-957.12.2.el7.x86_64 #1 SMP Fri Apr 19 21:09:07 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\n Python version: Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0] on linux\n Issue observed with 1.1.0 release of allennlp and allennlp-models, plus the following patches manually applied:\n \n #4632\n allenai/allennlp-models#129\n \n \n Output of pip freeze:\n \n alabaster==0.7.12\n alembic==1.4.2\n allennlp==1.1.0\n allennlp-models==1.1.0\n appdirs==1.4.3\n argon2-cffi @ file:///home/conda/feedstock_root/build_artifacts/argon2-cffi_1596629848788/work\n astroid @ file:///home/conda/feedstock_root/build_artifacts/astroid_1591645081755/work\n attrs @ file:///home/conda/feedstock_root/build_artifacts/attrs_1597959372343/work\n Babel==2.8.0\n backcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n backports.functools-lru-cache==1.6.1\n beautifulsoup4 @ file:///home/conda/feedstock_root/build_artifacts/beautifulsoup4_1597679909012/work\n black @ file:///home/conda/feedstock_root/build_artifacts/black-recipe_1596181673569/work\n bleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1588608214987/work\n blis==0.4.1\n boto==2.49.0\n boto3 @ file:///home/conda/feedstock_root/build_artifacts/boto3_1599083817494/work\n botocore @ file:///home/conda/feedstock_root/build_artifacts/botocore_1599079795233/work\n brotlipy==0.7.0\n bz2file==0.98\n cachetools @ file:///home/conda/feedstock_root/build_artifacts/cachetools_1593420445823/work\n catalogue==1.0.0\n certifi==2020.6.20\n cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1595805535531/work\n chardet==3.0.4\n click==7.1.2\n cliff @ file:///home/conda/feedstock_root/build_artifacts/cliff_1596473693634/work\n cmaes @ file:///home/conda/feedstock_root/build_artifacts/cmaes_1596014311252/work\n cmd2 @ file:///home/conda/feedstock_root/build_artifacts/cmd2_1591809284986/work\n colorama==0.4.3\n colorlog==4.2.1\n conllu==4.1\n cryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography_1598621005849/work\n css-html-js-minify @ file:///home/conda/feedstock_root/build_artifacts/css-html-js-minify_1589201803800/work\n cycler==0.10.0\n cymem==2.0.3\n Cython @ file:///home/conda/feedstock_root/build_artifacts/cython_1594253470382/work\n decorator==4.4.2\n defusedxml==0.6.0\n docutils==0.15.2\n en-core-web-sm @ file:///home/conda/feedstock_root/build_artifacts/spacy-model-en_core_web_1595437534769/work/sm\n entrypoints==0.3\n filelock==3.0.12\n flake8 @ file:///home/conda/feedstock_root/build_artifacts/flake8_1594584774608/work\n ftfy==5.8\n future==0.18.2\n gensim @ file:///home/conda/feedstock_root/build_artifacts/gensim_1589441213562/work\n google-api-core @ file:///home/conda/feedstock_root/build_artifacts/google-api-core-split_1597353416133/work\n google-auth @ file:///home/conda/feedstock_root/build_artifacts/google-auth_1598972371532/work\n google-cloud-core @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-core_1596721852962/work\n google-cloud-storage @ file:///home/conda/feedstock_root/build_artifacts/google-cloud-storage_1598557481535/work\n google-crc32c @ file:///home/conda/feedstock_root/build_artifacts/google-crc32c_1597069930917/work\n google-resumable-media @ file:///home/conda/feedstock_root/build_artifacts/google-resumable-media_1598452053521/work\n googleapis-common-protos==1.51.0\n grpcio @ file:///home/conda/feedstock_root/build_artifacts/grpcio_1596715635580/work\n h5py==2.10.0\n idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1593328102638/work\n imagesize==1.2.0\n importlib-metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1593211369179/work\n iniconfig==1.0.1\n ipykernel @ file:///home/conda/feedstock_root/build_artifacts/ipykernel_1595446871027/work/dist/ipykernel-5.3.4-py3-none-any.whl\n ipython @ file:///home/conda/feedstock_root/build_artifacts/ipython_1598749946943/work\n ipython-genutils==0.2.0\n isort @ file:///home/conda/feedstock_root/build_artifacts/isort_1599134253980/work\n jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1595018882455/work\n Jinja2==2.11.2\n jmespath @ file:///home/conda/feedstock_root/build_artifacts/jmespath_1589369830981/work\n joblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1593624380152/work\n json5 @ file:///home/conda/feedstock_root/build_artifacts/json5_1591810480056/work\n jsonnet==0.16.0\n jsonpickle==1.4.1\n jsonschema==3.2.0\n jupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1598486169312/work\n jupyter-core==4.6.3\n jupyterlab==2.2.6\n jupyterlab-server @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_server_1593951277307/work\n kiwisolver==1.2.0\n lazy-object-proxy==1.4.3\n livereload @ file:///home/conda/feedstock_root/build_artifacts/livereload_1598114753789/work\n lunr==0.5.8\n lxml @ file:///home/conda/feedstock_root/build_artifacts/lxml_1594322698782/work\n Mako @ file:///home/conda/feedstock_root/build_artifacts/mako_1595925083607/work\n Markdown @ file:///home/conda/feedstock_root/build_artifacts/markdown_1589366472132/work\n MarkupSafe==1.1.1\n matplotlib @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-base_1597952254444/work\n mccabe==0.6.1\n mistune==0.8.4\n mkdocs @ file:///home/conda/feedstock_root/build_artifacts/mkdocs_1591017186129/work\n mkdocs-material @ file:///home/conda/feedstock_root/build_artifacts/mkdocs-material_1598971568401/work\n more-itertools==8.5.0\n murmurhash==1.0.2\n mypy @ file:///home/conda/feedstock_root/build_artifacts/mypy_1592923020520/work\n mypy-extensions==0.4.3\n nbconvert==5.6.1\n nbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1594060262917/work\n networkx==2.5\n nltk==3.4.4\n notebook @ file:///home/conda/feedstock_root/build_artifacts/notebook_1597285190767/work\n numpy @ file:///home/conda/feedstock_root/build_artifacts/numpy_1597938346492/work\n olefile==0.46\n optuna @ file:///home/conda/feedstock_root/build_artifacts/optuna_1598323699360/work\n overrides==3.1.0\n packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1589925210001/work\n pandas @ file:///home/conda/feedstock_root/build_artifacts/pandas_1598294454723/work\n pandocfilters==1.4.2\n parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1595548966091/work\n pathspec==0.8.0\n patsy==0.5.1\n pbr @ file:///home/conda/feedstock_root/build_artifacts/pbr_1598996708473/work\n pexpect==4.8.0\n pickleshare==0.7.5\n Pillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1594213010297/work\n plac==1.1.3\n pluggy==0.13.1\n preshed==3.0.2\n prettytable==0.7.2\n prometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1590412252446/work\n prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1598885455507/work\n protobuf==3.13.0\n psutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1594826921622/work\n ptyprocess==0.6.0\n py==1.9.0\n py-rouge==1.1\n pyasn1==0.4.8\n pyasn1-modules==0.2.7\n pycodestyle @ file:///home/conda/feedstock_root/build_artifacts/pycodestyle_1589305246696/work\n pycorenlp==0.3.0\n pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1593275161868/work\n pyflakes==2.2.0\n Pygments==2.6.1\n pylint @ file:///home/conda/feedstock_root/build_artifacts/pylint_1598117058668/work\n pymdown-extensions @ file:///home/conda/feedstock_root/build_artifacts/pymdown-extensions_1597166028984/work\n Pyment==0.3.3\n pyneuroner==1.0.8\n pyOpenSSL==19.1.0\n pyparsing==2.4.7\n pyperclip @ file:///home/conda/feedstock_root/build_artifacts/pyperclip_1591810382257/work\n pyrsistent==0.16.0\n PySocks==1.7.1\n pytest==6.0.1\n python-dateutil==2.8.1\n python-editor==1.0.4\n python-magic==0.4.18\n python-slugify @ file:///home/conda/feedstock_root/build_artifacts/python-slugify_1593573453419/work\n pytz==2020.1\n PyYAML==5.3.1\n pyzmq==19.0.2\n regex @ file:///home/conda/feedstock_root/build_artifacts/regex_1594799371287/work\n requests @ file:///home/conda/feedstock_root/build_artifacts/requests_1592425495151/work\n rsa @ file:///home/conda/feedstock_root/build_artifacts/rsa_1591996208734/work\n s3cmd==2.1.0\n s3transfer==0.3.3\n sacremoses==0.0.43\n scikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1596546074663/work\n scipy @ file:///home/conda/feedstock_root/build_artifacts/scipy_1595583586868/work\n seaborn @ file:///home/conda/feedstock_root/build_artifacts/seaborn-base_1591878760859/work\n Send2Trash==1.5.0\n sentencepiece==0.1.91\n six @ file:///home/conda/feedstock_root/build_artifacts/six_1590081179328/work\n slugify==0.0.1\n smart-open @ file:///home/conda/feedstock_root/build_artifacts/smart_open_1598572939086/work\n snowballstemmer==2.0.0\n soupsieve @ file:///home/conda/feedstock_root/build_artifacts/soupsieve_1597680516047/work\n spacy==2.3.2\n Sphinx @ file:///home/conda/feedstock_root/build_artifacts/sphinx_1597405755328/work\n sphinx-material @ file:///home/conda/feedstock_root/build_artifacts/sphinx-material_1597663680729/work\n sphinxcontrib-applehelp==1.0.2\n sphinxcontrib-devhelp==1.0.2\n sphinxcontrib-htmlhelp==1.0.3\n sphinxcontrib-jsmath==1.0.1\n sphinxcontrib-qthelp==1.0.3\n sphinxcontrib-serializinghtml==1.1.4\n SQLAlchemy @ file:///home/conda/feedstock_root/build_artifacts/sqlalchemy_1597701920245/work\n srsly==1.0.2\n statsmodels @ file:///home/conda/feedstock_root/build_artifacts/statsmodels_1598551025620/work\n stevedore @ file:///home/conda/feedstock_root/build_artifacts/stevedore_1598982656343/work\n tensorboardX==2.1\n teradata==15.10.0.21\n terminado==0.8.3\n testpath==0.4.4\n text-unidecode==1.3\n thinc==7.4.1\n threadpoolctl @ file:///tmp/tmp79xdzxkt/threadpoolctl-2.1.0-py3-none-any.whl\n tokenizers==0.8.1rc1\n toml @ file:///home/conda/feedstock_root/build_artifacts/toml_1589469402899/work\n torch==1.6.0\n torchvision==0.7.0\n tornado==6.0.4\n tqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1596476591553/work\n traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1598976315411/work\n transformers==3.0.2\n typed-ast==1.4.1\n typing-extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1588470653596/work\n Unidecode==1.1.1\n urllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1595434816409/work\n wasabi==0.8.0\n wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1595859607677/work\n webencodings==0.5.1\n word2number==1.1\n wrapt==1.11.2\n XlsxWriter @ file:///home/conda/feedstock_root/build_artifacts/xlsxwriter_1597362230404/work\n zipp==3.1.0\n \n \n \n \n Output of conda list:\n \n # packages in environment at /app/local/anaconda3/envs/torch1.6_allennlp1.1:\n #\n # Name                    Version                   Build  Channel\n _libgcc_mutex             0.1                 conda_forge\n _openmp_mutex             4.5                      1_llvm\n alabaster                 0.7.12                     py_0\n alembic                   1.4.2              pyh9f0ad1d_0\n allennlp                  1.1.0                    pypi_0    pypi\n allennlp-models           1.1.0                    pypi_0    pypi\n appdirs                   1.4.3                      py_1\n argon2-cffi               20.1.0           py37h8f50634_1\n astroid                   2.4.2            py37hc8dfbb8_0\n attrs                     20.1.0             pyh9f0ad1d_0\n babel                     2.8.0                      py_0\n backcall                  0.2.0              pyh9f0ad1d_0\n backports                 1.0                        py_2\n backports.functools_lru_cache 1.6.1                      py_0\n beautifulsoup4            4.9.1                      py_1\n black                     19.10b0                    py_4\n blas                      2.16                        mkl\n bleach                    3.1.5              pyh9f0ad1d_0\n blis                      0.4.1                    pypi_0    pypi\n boto                      2.49.0                     py_0\n boto3                     1.14.54            pyh9f0ad1d_0\n botocore                  1.17.54            pyh9f0ad1d_0\n brotlipy                  0.7.0           py37h8f50634_1000\n bz2file                   0.98                       py_0\n c-ares                    1.16.1               h516909a_3\n ca-certificates           2020.6.20            hecda079_0\n cachetools                4.1.1                      py_0\n catalogue                 1.0.0                    pypi_0    pypi\n certifi                   2020.6.20        py37hc8dfbb8_0\n cffi                      1.14.1           py37h2b28604_0\n chardet                   3.0.4           py37hc8dfbb8_1006\n click                     7.1.2              pyh9f0ad1d_0\n cliff                     3.4.0                      py_0\n cmaes                     0.6.0              pyhbc3b93e_0\n cmd2                      0.9.22                   py37_0\n colorama                  0.4.3                      py_0\n colorlog                  4.2.1            py37hc8dfbb8_0\n conllu                    4.1                      pypi_0    pypi\n cryptography              3.1              py37hb09aad4_0\n css-html-js-minify        2.5.5            py37hc8dfbb8_1\n cudatoolkit               9.2                           0\n cycler                    0.10.0                     py_2\n cymem                     2.0.3                    pypi_0    pypi\n cython                    0.29.21          py37h3340039_0\n decorator                 4.4.2                      py_0\n defusedxml                0.6.0                      py_0\n docutils                  0.15.2                   py37_0\n entrypoints               0.3             py37hc8dfbb8_1001\n filelock                  3.0.12                   pypi_0    pypi\n flake8                    3.8.3                      py_1\n freetype                  2.10.2               he06d7ca_0\n ftfy                      5.8                      pypi_0    pypi\n future                    0.18.2           py37hc8dfbb8_1\n gensim                    3.8.3            py37h3340039_2\n google-api-core           1.22.1           py37hc8dfbb8_0\n google-auth               1.21.0                     py_0\n google-cloud-core         1.4.1              pyh9f0ad1d_0\n google-cloud-storage      1.31.0             pyh9f0ad1d_0\n google-crc32c             1.0.0            py37h193935f_0\n google-resumable-media    1.0.0              pyh9f0ad1d_0\n googleapis-common-protos  1.51.0           py37hc8dfbb8_2\n grpcio                    1.31.0           py37hb0870dc_0\n h5py                      2.10.0                   pypi_0    pypi\n icu                       67.1                 he1b5a44_0\n idna                      2.10               pyh9f0ad1d_0\n imagesize                 1.2.0                      py_0\n importlib-metadata        1.7.0            py37hc8dfbb8_0\n importlib_metadata        1.7.0                         0\n iniconfig                 1.0.1                    pypi_0    pypi\n ipykernel                 5.3.4            py37h43977f1_0\n ipython                   7.18.1           py37hc6149b9_0\n ipython_genutils          0.2.0                      py_1\n isort                     5.5.0            py37hc8dfbb8_0\n jedi                      0.17.2           py37hc8dfbb8_0\n jinja2                    2.11.2             pyh9f0ad1d_0\n jmespath                  0.10.0             pyh9f0ad1d_0\n joblib                    0.16.0                     py_0\n jpeg                      9d                   h516909a_0\n json5                     0.9.4              pyh9f0ad1d_0\n jsonnet                   0.16.0                   pypi_0    pypi\n jsonpickle                1.4.1                    pypi_0    pypi\n jsonschema                3.2.0            py37hc8dfbb8_1\n jupyter_client            6.1.7                      py_0\n jupyter_core              4.6.3            py37hc8dfbb8_1\n jupyterlab                2.2.6                      py_0\n jupyterlab_server         1.2.0                      py_0\n kiwisolver                1.2.0            py37h99015e2_0\n lazy-object-proxy         1.4.3            py37h8f50634_2\n lcms2                     2.11                 hbd6801e_0\n ld_impl_linux-64          2.34                 hc38a660_9\n libblas                   3.8.0                    16_mkl\n libcblas                  3.8.0                    16_mkl\n libcrc32c                 1.1.1                he1b5a44_2\n libffi                    3.2.1             he1b5a44_1007\n libgcc-ng                 9.3.0               h24d8f2e_16\n libgfortran-ng            7.5.0               hdf63c60_16\n libiconv                  1.16                 h516909a_0\n liblapack                 3.8.0                    16_mkl\n liblapacke                3.8.0                    16_mkl\n libpng                    1.6.37               hed695b0_2\n libprotobuf               3.13.0               h8b12597_0\n libsodium                 1.0.18               h516909a_0\n libstdcxx-ng              9.3.0               hdf63c60_16\n libtiff                   4.1.0                hc7e4089_6\n libuv                     1.39.0               h516909a_0\n libwebp-base              1.1.0                h516909a_3\n libxml2                   2.9.10               h68273f3_2\n libxslt                   1.1.33               h572872d_1\n livereload                2.6.3              pyh9f0ad1d_0\n llvm-openmp               10.0.1               hc9558a2_0\n lunr                      0.5.8            py37hc8dfbb8_0\n lxml                      4.5.2            py37he3881c9_0\n lz4-c                     1.9.2                he1b5a44_3\n mako                      1.1.3              pyh9f0ad1d_0\n markdown                  3.2.2                      py_0\n markupsafe                1.1.1            py37h8f50634_1\n matplotlib-base           3.3.1            py37hd478181_1\n mccabe                    0.6.1                      py_1\n mistune                   0.8.4           py37h8f50634_1001\n mkdocs                    1.1.2                      py_0\n mkdocs-material           5.5.12                     py_0\n mkl                       2020.2                      256\n more-itertools            8.5.0                    pypi_0    pypi\n murmurhash                1.0.2                    pypi_0    pypi\n mypy                      0.782                      py_0\n mypy_extensions           0.4.3            py37hc8dfbb8_1\n nbconvert                 5.6.1            py37hc8dfbb8_1\n nbformat                  5.0.7                      py_0\n ncurses                   6.2                  he1b5a44_1\n networkx                  2.5                      pypi_0    pypi\n ninja                     1.10.1               hc9558a2_1\n nltk                      3.4.4                      py_0\n nodejs                    14.9.0               h568c755_0\n notebook                  6.1.3            py37hc8dfbb8_0\n numpy                     1.19.1           py37h7ea13bd_2\n olefile                   0.46                       py_0\n openssl                   1.1.1g               h516909a_1\n optuna                    2.0.0                      py_1\n overrides                 3.1.0                    pypi_0    pypi\n packaging                 20.4               pyh9f0ad1d_0\n pandas                    1.1.1            py37h3340039_0\n pandoc                    2.10.1               h516909a_0\n pandocfilters             1.4.2                      py_1\n parso                     0.7.1              pyh9f0ad1d_0\n pathspec                  0.8.0              pyh9f0ad1d_0\n patsy                     0.5.1                      py_0\n pbr                       5.5.0              pyh9f0ad1d_0\n pexpect                   4.8.0            py37hc8dfbb8_1\n pickleshare               0.7.5           py37hc8dfbb8_1001\n pillow                    7.2.0            py37h718be6c_1\n pip                       20.2.2                     py_0\n plac                      1.1.3                    pypi_0    pypi\n pluggy                    0.13.1                   pypi_0    pypi\n preshed                   3.0.2                    pypi_0    pypi\n prettytable               0.7.2                      py_3\n prometheus_client         0.8.0              pyh9f0ad1d_0\n prompt-toolkit            3.0.7                      py_0\n protobuf                  3.13.0                   pypi_0    pypi\n psutil                    5.7.2            py37h8f50634_0\n ptyprocess                0.6.0                   py_1001\n py                        1.9.0                    pypi_0    pypi\n py-rouge                  1.1                      pypi_0    pypi\n pyasn1                    0.4.8                      py_0\n pyasn1-modules            0.2.7                      py_0\n pycodestyle               2.6.0              pyh9f0ad1d_0\n pycorenlp                 0.3.0                    pypi_0    pypi\n pycparser                 2.20               pyh9f0ad1d_2\n pyflakes                  2.2.0              pyh9f0ad1d_0\n pygments                  2.6.1                      py_0\n pylint                    2.6.0            py37hc8dfbb8_0\n pymdown-extensions        8.0                pyh9f0ad1d_0\n pyment                    0.3.3                    pypi_0    pypi\n pyneuroner                1.0.8                    pypi_0    pypi\n pyopenssl                 19.1.0                     py_1\n pyparsing                 2.4.7              pyh9f0ad1d_0\n pyperclip                 1.8.0              pyh9f0ad1d_0\n pyrsistent                0.16.0           py37h8f50634_0\n pysocks                   1.7.1            py37hc8dfbb8_1\n pytest                    6.0.1                    pypi_0    pypi\n python                    3.7.8           h6f2ec95_1_cpython\n python-dateutil           2.8.1                      py_0\n python-editor             1.0.4                      py_0\n python-magic              0.4.18                   pypi_0    pypi\n python-slugify            4.0.1              pyh9f0ad1d_0\n python_abi                3.7                     1_cp37m\n pytorch                   1.6.0           py3.7_cuda9.2.148_cudnn7.6.3_0\n pytz                      2020.1             pyh9f0ad1d_0\n pyyaml                    5.3.1            py37h8f50634_0\n pyzmq                     19.0.2           py37hac76be4_0\n readline                  8.0                  he28a2e2_2\n regex                     2020.7.14        py37h8f50634_0\n requests                  2.24.0             pyh9f0ad1d_0\n rsa                       4.6                pyh9f0ad1d_0\n s3cmd                     2.1.0                    pypi_0    pypi\n s3transfer                0.3.3            py37hc8dfbb8_1\n sacremoses                0.0.43                   pypi_0    pypi\n scikit-learn              0.23.2           py37h6785257_0\n scipy                     1.5.2            py37hb14ef9d_0\n seaborn                   0.10.1                        1\n seaborn-base              0.10.1                     py_1\n send2trash                1.5.0                      py_0\n sentencepiece             0.1.91                   pypi_0    pypi\n setuptools                49.6.0           py37hc8dfbb8_0\n six                       1.15.0             pyh9f0ad1d_0\n slugify                   0.0.1                      py_2\n smart_open                2.1.1              pyh9f0ad1d_0\n snowballstemmer           2.0.0                      py_0\n soupsieve                 2.0.1                      py_1\n spacy                     2.3.2                    pypi_0    pypi\n spacy-model-en_core_web_sm 2.3.1              pyh9f0ad1d_0\n sphinx                    3.2.1                      py_0\n sphinx-material           0.0.30                     py_1\n sphinxcontrib-applehelp   1.0.2                      py_0\n sphinxcontrib-devhelp     1.0.2                      py_0\n sphinxcontrib-htmlhelp    1.0.3                      py_0\n sphinxcontrib-jsmath      1.0.1                      py_0\n sphinxcontrib-qthelp      1.0.3                      py_0\n sphinxcontrib-serializinghtml 1.1.4                      py_0\n sqlalchemy                1.3.19           py37h8f50634_0\n sqlite                    3.33.0               h4cf870e_0\n srsly                     1.0.2                    pypi_0    pypi\n statsmodels               0.12.0           py37h8f50634_0\n stevedore                 3.2.1            py37hc8dfbb8_0\n tensorboardx              2.1                      pypi_0    pypi\n teradata                  15.10.0.21               py37_0\n terminado                 0.8.3            py37hc8dfbb8_1\n testpath                  0.4.4                      py_0\n text-unidecode            1.3                        py_0\n thinc                     7.4.1                    pypi_0    pypi\n threadpoolctl             2.1.0              pyh5ca1d4c_0\n tini                      0.18.0            h14c3975_1001\n tk                        8.6.10               hed695b0_0\n tokenizers                0.8.1rc1                 pypi_0    pypi\n toml                      0.10.1             pyh9f0ad1d_0\n torchvision               0.7.0                 py37_cu92\n tornado                   6.0.4            py37h8f50634_1\n tqdm                      4.48.2             pyh9f0ad1d_0\n traitlets                 5.0.0            py37hc8dfbb8_0\n transformers              3.0.2                    pypi_0    pypi\n typed-ast                 1.4.1            py37h516909a_0\n typing_extensions         3.7.4.2                    py_0\n unidecode                 1.1.1                      py_0\n urllib3                   1.25.10                    py_0\n wasabi                    0.8.0                    pypi_0    pypi\n wcwidth                   0.2.5              pyh9f0ad1d_1\n webencodings              0.5.1                      py_1\n wheel                     0.35.1             pyh9f0ad1d_0\n word2number               1.1                      pypi_0    pypi\n wrapt                     1.11.2           py37h8f50634_0\n xlsxwriter                1.3.3              pyh9f0ad1d_0\n xz                        5.2.5                h516909a_1\n yaml                      0.2.5                h516909a_0\n zeromq                    4.3.2                he1b5a44_3\n zipp                      3.1.0                      py_0\n zlib                      1.2.11            h516909a_1009\n zstd                      1.4.5                h6597ccf_2\n \n \n \n <denchmark-h:h2>Steps to reproduce</denchmark-h>\n \n \n Example source:\n \n # First, train the LM (this works):\n allennlp train --force --include-package src --serialization-dir tmp/elmo_lm_tran1 configs/bidirectional_language_model_part_notes.jsonnet\n \n # Second, train the NER model (this is what fails and produces the error):\n allennlp train --force --include-package src --serialization-dir tmp/ner_elmo_lm_tran1 configs/train_lstm_nobi_char_elmo1_v2.jsonnet\n \n \n \n \n Contents of Language Model config file bidirectional_language_model_part_notes.jsonnet\n {\n   dataset_reader: {\n     type: 'language_model_conll_reader',\n     //\"tokenizer\": {\n     //    \"type\": \"just_spaces\"\n     //},\n     token_indexers: {\n       tokens: {\n         type: 'single_id',\n       },\n       token_characters: {\n         type: 'elmo_characters',\n       },\n     },\n     //\"max_sequence_length\": 400,\n     //\"start_tokens\": [\"<S>\"],\n     //\"end_tokens\": [\"</S>\"]\n   },\n   train_data_path: 'data/processed/no_bi_tags/new_model1_train.txt',\n   model: {\n     type: 'language_model',\n     bidirectional: true,\n     //\"num_samples\": 8192,\n     sparse_embeddings: true,\n     text_field_embedder: {\n       //\"allow_unmatched_keys\": true,\n       token_embedders: {\n         //tokens: {\n         //          type: 'embedding',\n         //          pretrained_file: 'models/word2vec_newtoken1.txt',\n         //          embedding_dim: 50,\n         //          trainable: false\n         //      },\n         tokens: {\n           type: 'empty',\n         },\n         token_characters: {\n           type: 'character_encoding',\n           embedding: {\n             num_embeddings: 262,\n             embedding_dim: 16,\n           },\n           encoder: {\n             type: 'cnn-highway',\n             activation: 'relu',\n             embedding_dim: 16,\n             filters: [\n               [1, 32],\n               [2, 32],\n               [3, 64],\n               [4, 128],\n               [5, 256],\n               [6, 512],\n               [7, 1024],\n             ],\n             num_highway: 2,\n             projection_dim: 512,\n             projection_location: 'after_highway',\n             do_layer_norm: true,\n           },\n         },\n       },\n     },\n     dropout: 0.1,\n     contextualizer: {\n       type: 'bidirectional_language_model_transformer',\n       input_dim: 512,\n       hidden_dim: 2048,\n       num_layers: 6,\n       dropout: 0.1,\n       input_dropout: 0.1,\n     },\n   },\n   data_loader: {\n     batch_size: 64,\n   },\n   distributed: {\n     cuda_devices: std.range(0, 8 - 1),\n   },\n   trainer: {\n     num_epochs: 10,\n     optimizer: {\n       type: 'dense_sparse_adam',\n     },\n     // TODO(brendanr): Needed with transformer too?\n     // \"grad_norm\": 10.0,\n     learning_rate_scheduler: {\n       type: 'noam',\n       // See https://github.com/allenai/calypso/blob/master/calypso/train.py#L401\n       model_size: 512,\n       // See https://github.com/allenai/calypso/blob/master/bin/train_transformer_lm1b.py#L51.\n       // Adjusted based on our sample size relative to Calypso's.\n       warmup_steps: 6000,\n     },\n     //\"should_log_learning_rate\": true\n   },\n }\n \n \n \n \n \n Contents of NER model config file train_lstm_nobi_char_elmo1_v2.jsonnet:\n \n {\n   dataset_reader: {\n     type: 'conll_03_reader_elmo',\n     token_indexers: {\n       tokens: {\n         type: 'single_id',\n         namespace: 'tokens',\n       },\n       elmo: {\n         type: 'elmo_characters',\n         //namespace: 'token_characters'\n       },\n     },\n     lazy: false,\n   },\n   train_data_path: 'data/processed/no_bi_tags/new_model1_train.txt',\n   validation_data_path: 'data/processed/no_bi_tags/new_model1_val.txt',\n   model: {\n     //type: 'ner_lstm_crf',\n     type: 'NER_LSTM',  //without crf\n     embedder: {\n       token_embedders: {\n         tokens: {\n           type: 'embedding',\n           pretrained_file: 'models/word2vec_newtoken1.txt',\n           embedding_dim: 50,\n           trainable: false,\n         },\n         //elmo: {\n         //    type: 'elmo_token_embedder',\n         //    options_file: \"models/elmo_2x4096_512_2048cnn_2xhighway_options.json\",\n         //    weight_file: \"models/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\",\n         //    do_layer_norm: false,\n         //    dropout: 0.3\n         // }\n         elmo: {\n           type: 'bidirectional_lm_token_embedder',\n           archive_file: 'tmp/elmo_lm_tran1/model.tar.gz',\n           dropout: 0.2,\n           bos_eos_tokens: ['<S>', '</S>'],\n           remove_bos_eos: true,\n           requires_grad: false,\n         },\n       },\n     },\n     encoder: {\n       type: 'lstm',\n       input_size: 1024 + 50,\n       hidden_size: 25,\n       dropout: 0.3,\n       bidirectional: true,\n     },\n   },\n   data_loader: {\n     batch_size: 128,\n   },\n   trainer: {\n     num_epochs: 22,\n     patience: 10,\n     cuda_device: 0,\n     grad_clipping: 5.0,\n     validation_metric: '-loss',\n     optimizer: {\n       type: 'adam',\n       lr: 0.01,\n     },\n   },\n }\n \n \n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "tpanza", "commentT": "2020-09-21T20:23:06Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/dirkgr>@dirkgr</denchmark-link>\n  what can I do to help with this?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "tpanza", "commentT": "2020-09-24T18:42:08Z", "comment_text": "\n \t\tSorry for the radio silence. This is on my radar, but the machine I wanted to use has developed problems and now we're debugging GPUs instead of tensors.\n These wrong-device errors are usually easy. The problem is often that one of the tensors involved was created fresh without a device parameter, and so it defaults to CPU. I am a big fan of debuggers, so that's what I would use to find out where it came from, but there are other techniques, including \"staring at the code\".\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "tpanza", "commentT": "2020-10-09T16:28:05Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/dirkgr>@dirkgr</denchmark-link>\n  this is just a friendly ping to make sure you haven't forgotten about this issue \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "tpanza", "commentT": "2020-10-09T18:02:41Z", "comment_text": "\n \t\tThank you, <denchmark-link:https://github.com/github-actions>@github-actions</denchmark-link>\n . I have not.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "tpanza", "commentT": "2020-10-13T00:21:30Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/dirkgr>@dirkgr</denchmark-link>\n  please checkout <denchmark-link:https://github.com/allenai/allennlp/pull/4727>#4727</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "c14a056dfc2a3e4dbf7ad6798b1b50cd281170fc", "commit_author": "tpanza", "commitT": "2020-10-14 18:48:50-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "80", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "allennlp\\nn\\util.py", "file_new_name": "allennlp\\nn\\util.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "1554,1563,1564", "deleted_lines": "1554"}}}}}}