{"BR": {"BR_id": "851", "BR_author": "lokeshkvn", "BRopenT": "2020-06-22T17:46:12Z", "BRcloseT": "2020-07-06T04:09:19Z", "BR_text": {"BRsummary": "OneCycleLRWithWarmup does not starts with init_lr", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug Report</denchmark-h>\n \n OneCycleLRWithWarmup starts ahead of initial LR (does not start with init_lr)\n If the number of steps is 6 and warmup_fraction = 0.5 and init_lr = 1e-3 and lr_range=(2e-3,1e-3),\n The lr starts with 1.36-3 excutes two steps and starts cooling down from 2e-3\n <denchmark-h:h3>How To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n \n Go to https://colab.research.google.com/github/catalyst-team/catalyst/blob/master/examples/notebooks/segmentation-tutorial.ipynb#scrollTo=OG6_pgmkxk_b\n \n \n <denchmark-code>batch_size = 8\n loaders = get_loaders(\n     images=ALL_IMAGES[:200],\n     masks=ALL_MASKS[:200],\n     random_state=SEED,\n     train_transforms_fn=train_transforms,\n     valid_transforms_fn=valid_transforms,\n     batch_size=batch_size\n ) \n </denchmark-code>\n \n \n set epochs to 10\n replace scheduler with\n \n <denchmark-code>scheduler = OneCycleLRWithWarmup(optimizer, num_steps = 6,lr_range=(2e-3,1e-3), init_lr = 1e-3, warmup_fraction = 0.5)\n </denchmark-code>\n \n \n Run\n \n <denchmark-h:h4>Screenshots</denchmark-h>\n \n <denchmark-link:https://user-images.githubusercontent.com/16884938/85318756-20e2ab80-b4f3-11ea-8589-40039d7a056f.png></denchmark-link>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n OneCycleLRWithWarmup should start with lr = init_lr\n (Pardon me if I am wrong, please advise me if this is the correct behavior of OneCycleLRWithWarmup as I am new to DL)\n <denchmark-h:h3>Environment</denchmark-h>\n \n Google Colab\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "lokeshkvn", "commentT": "2020-06-22T17:46:48Z", "comment_text": "\n \t\tHi! Thank you for your contribution! Great first issue!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "lokeshkvn", "commentT": "2020-06-22T18:26:11Z", "comment_text": "\n \t\thi <denchmark-link:https://github.com/lokeshkvn>@lokeshkvn</denchmark-link>\n  , thanks for the issue!\n Due to a bunch of current tasks (we are working on huge codestyle and docs update),\n could you please help us and provide full-featured example for reproduce the issue?\n here is the template:\n import torch\n from torch.utils.data import DataLoader, TensorDataset\n from catalyst.dl import SupervisedRunner\n \n # data\n num_samples, num_features = int(1e4), int(1e1)\n X, y = torch.rand(num_samples, num_features), torch.rand(num_samples)\n dataset = TensorDataset(X, y)\n loader = DataLoader(dataset, batch_size=32, num_workers=1)\n loaders = {\"train\": loader, \"valid\": loader}\n \n # model, criterion, optimizer, scheduler\n model = torch.nn.Linear(num_features, 1)\n criterion = torch.nn.MSELoss()\n optimizer = torch.optim.Adam(model.parameters())\n scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [3, 6])\n \n # model training\n runner = SupervisedRunner()\n runner.train(\n     model=model,\n     criterion=criterion,\n     optimizer=optimizer,\n     scheduler=scheduler,\n     loaders=loaders,\n     logdir=\"./logdir\",\n     num_epochs=8,\n     verbose=True,\n )\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "lokeshkvn", "commentT": "2020-06-22T18:42:32Z", "comment_text": "\n \t\tSure <denchmark-link:https://github.com/Scitator>@Scitator</denchmark-link>\n  I will update you with the full-feature example.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "lokeshkvn", "commentT": "2020-06-22T18:57:53Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/Scitator>@Scitator</denchmark-link>\n \n Here is the code example to reproduce:\n import torch\n from torch.utils.data import DataLoader, TensorDataset\n from catalyst.dl import SupervisedRunner\n from catalyst.contrib.nn.schedulers.onecycle import OneCycleLRWithWarmup\n \n # data\n num_samples, num_features = int(1e4), int(1e1)\n X, y = torch.rand(num_samples, num_features), torch.rand(num_samples)\n dataset = TensorDataset(X, y)\n loader = DataLoader(dataset, batch_size=32, num_workers=1)\n loaders = {\"train\": loader, \"valid\": loader}\n \n # model, criterion, optimizer, scheduler\n model = torch.nn.Linear(num_features, 1)\n criterion = torch.nn.MSELoss()\n optimizer = torch.optim.Adam(model.parameters())\n scheduler = OneCycleLRWithWarmup(optimizer, num_steps = 6,lr_range=(2e-3,1e-3), init_lr = 1e-3, warmup_fraction = 0.5)\n \n # model training\n runner = SupervisedRunner()\n runner.train(\n     model=model,\n     criterion=criterion,\n     optimizer=optimizer,\n     scheduler=scheduler,\n     loaders=loaders,\n     logdir=\"./logdir\",\n     num_epochs=8,\n     verbose=True,\n )\n Then run tensorboard\n <denchmark-code>load_ext tensorboard \n tensorboard --logdir 'logdir/\n </denchmark-code>\n \n Below is the lr plot I get using tensorboard:\n <denchmark-link:https://user-images.githubusercontent.com/16884938/85324867-34930f80-b4fd-11ea-94fb-da62c801df94.png></denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "lokeshkvn", "commentT": "2020-06-23T20:34:13Z", "comment_text": "\n \t\tDear <denchmark-link:https://github.com/lokeshkvn>@lokeshkvn</denchmark-link>\n  ,\n looks like I found the solution,\n You need to change this line\n <denchmark-link:https://github.com/catalyst-team/catalyst/blob/master/catalyst/core/callbacks/scheduler.py#L121>https://github.com/catalyst-team/catalyst/blob/master/catalyst/core/callbacks/scheduler.py#L121</denchmark-link>\n \n to\n self._scheduler.recalculate(\n     loader_len=runner.loader_len, current_step=runner.epoch - 1\n )\n Would you like to make a PR with this fix?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "lokeshkvn", "commentT": "2020-06-24T02:58:24Z", "comment_text": "\n \t\tThanks I will make a PR soon with the above fix. \ud83d\ude03\n \t\t"}}}, "commit": {"commit_id": "135ed6f82c133dd0595e56c562fa75b3cd806078", "commit_author": "Sergey Kolesnikov", "commitT": "2020-07-05 22:24:55+03:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "44", "deleted_lines": "44"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "bin\\tests\\check_dl_cv.sh", "file_new_name": "bin\\tests\\check_dl_cv.sh", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "36,37,38,352,353,382,383,413,414,443,444", "deleted_lines": "36,37,351,380,381,411,440,441"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "catalyst\\core\\callbacks\\scheduler.py", "file_new_name": "catalyst\\core\\callbacks\\scheduler.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "122", "deleted_lines": "122", "method_info": {"method_name": "on_loader_start", "method_params": "self,IRunner", "method_startline": "110", "method_endline": "123"}}}}, "file_3": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tests\\_tests_scripts\\core_runner_onecyle_lr_scheduler.py"}}}}