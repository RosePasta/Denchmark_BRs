{"BR": {"BR_id": "5002", "BR_author": "tudorcebere", "BRopenT": "2021-01-10T18:19:39Z", "BRcloseT": "2021-01-18T10:13:55Z", "BR_text": {"BRsummary": "Model parameters not preserving .grad property", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n .grad property is not preserved on a model parameters when it's downloaded locally.\n <denchmark-h:h2>How to Reproduce</denchmark-h>\n \n <denchmark-code>import syft as sy\n import torch\n \n alice = sy.VirtualMachine(name=\"alice\")\n alice_client = alice.get_root_client()\n remote_torch = alice_client.torch\n \n class SyNet(sy.Module):\n     def __init__(self, torch_ref):\n         super(SyNet, self).__init__(torch_ref=torch_ref)\n         self.fc1 = self.torch_ref.nn.Linear(100, 10)\n \n     def forward(self, x):\n         return self.fc1(x)\n \n model = SyNet(torch)\n data = torch.randn(size=(1, 100))\n result = model(data)\n labels = torch.randn(size=(1, 10))\n loss_func = torch.nn.L1Loss()\n loss = loss_func(result, labels)\n loss.backward()\n \n print(model.parameters()[-1].grad) # exists\n \n \n model_ptr = model.send(alice_client)\n data_ptr = data.send(alice_client)\n labels_ptr = labels.send(alice_client)\n results_ptr = model_ptr(data_ptr)\n remote_loss_func = alice_client.torch.nn.L1Loss()\n remote_loss = remote_loss_func(results_ptr, labels_ptr)\n remote_loss.backward()\n \n print(model_ptr.parameters().get()[-1].grad) # exists\n print(model_ptr.get().parameters()[-1].grad) # does not exist anymore\n </denchmark-code>\n \n <denchmark-h:h2>Expected Behavior</denchmark-h>\n \n The .grad attribute should be present when we download the remote model.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "tudorcebere", "commentT": "2021-01-11T14:35:35Z", "comment_text": "\n \t\tI can work on this one. Please assign it to me.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "tudorcebere", "commentT": "2021-01-12T09:54:07Z", "comment_text": "\n \t\tPyTorch's load_state_dict breaks the computational graph, so on get(), there won't be any gradients to retrieve.\n The gradients will have to be retrieved via the model_ptr.parameters().get() call.\n \t\t"}}}, "commit": {"commit_id": "cd8e3058cd3b8f741ca7540708a4fe45608f597c", "commit_author": "Bogdan Cebere", "commitT": "2021-01-12 23:38:07+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 10, "file_old_name": "src\\syft\\lib\\torch\\module.py", "file_new_name": "src\\syft\\lib\\torch\\module.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "383,394", "deleted_lines": "382,383,384,387,388,389,390,391", "method_info": {"method_name": "debug_sum_layers", "method_params": "self", "method_startline": "382", "method_endline": "394"}}, "hunk_1": {"Ismethod": 1, "added_lines": "241,243,244,245", "deleted_lines": "239,240,241,242,244,245", "method_info": {"method_name": "save", "method_params": "self,str,bytes", "method_startline": "239", "method_endline": "245"}}, "hunk_2": {"Ismethod": 1, "added_lines": "249,251,252", "deleted_lines": "249,251,252", "method_info": {"method_name": "load", "method_params": "self,str", "method_startline": "247", "method_endline": "252"}}, "hunk_3": {"Ismethod": 1, "added_lines": "24,25,26", "deleted_lines": "24,25", "method_info": {"method_name": "debug", "method_params": "str", "method_startline": "24", "method_endline": "26"}}, "hunk_4": {"Ismethod": 1, "added_lines": "256,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,290,291,292", "deleted_lines": "257,259,260,264,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,289,290,291,292", "method_info": {"method_name": "send", "method_params": "self,Any", "method_startline": "254", "method_endline": "292"}}, "hunk_5": {"Ismethod": 1, "added_lines": "102,106", "deleted_lines": "96,97,98,102,103,104", "method_info": {"method_name": "setup", "method_params": "self,Any", "method_startline": "96", "method_endline": "111"}}, "hunk_6": {"Ismethod": 1, "added_lines": "183,185,186,187,188,189,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,218,220", "deleted_lines": "181,184,185,186,187,188,189,190,191,192,193,194,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221", "method_info": {"method_name": "load_state_dict", "method_params": "self,str,PathLike,str", "method_startline": "181", "method_endline": "221"}}, "hunk_7": {"Ismethod": 1, "added_lines": "29,30,31", "deleted_lines": null, "method_info": {"method_name": "critical", "method_params": "str", "method_startline": "29", "method_endline": "31"}}, "hunk_8": {"Ismethod": 1, "added_lines": "24,25", "deleted_lines": "24,25", "method_info": {"method_name": "full_name_with_qualname", "method_params": "type", "method_startline": "24", "method_endline": "25"}}, "hunk_9": {"Ismethod": 1, "added_lines": "225,228,229,230,231,232,233,234,235,236,237", "deleted_lines": "224,225,226,227,228,233,235,236,237", "method_info": {"method_name": "state_dict", "method_params": "self", "method_startline": "223", "method_endline": "237"}}}}, "file_1": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tests\\syft\\lib\\torch\\module_test.py"}}}}