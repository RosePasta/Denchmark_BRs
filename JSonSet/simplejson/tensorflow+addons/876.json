{"BR": {"BR_id": "876", "BR_author": "swghosh", "BRopenT": "2020-01-14T20:26:46Z", "BRcloseT": "2020-01-15T15:47:44Z", "BR_text": {"BRsummary": "SigmoidFocalCrossEntropy loss fails to compile model", "BRdescription": "\n System information\n \n OS Platform and Distribution: Deep Learning Linux VM (Debian Stretch) GCE Image\n TensorFlow version and how it was installed: Binary v2.1.0\n TensorFlow-Addons version and how it was installed: Binary v0.7.0\n Python version: Python 3.5.3\n Is GPU used? (yes/no): No\n \n Describe the bug\n model.compile tries to call some code with some test values for y_true and y_pred which causes a shape mismatch with tfa.losses.sigmoid_focal_crossentropy. The following line is causing the error to occur. It may also be a problem with the tf.keras models when used with custom losses altogether.\n \n \n \n addons/tensorflow_addons/losses/focal_loss.py\n \n \n         Lines 125 to 127\n       in\n       1bbe67f\n \n \n \n \n \n \n  if y_true.shape != y_pred.shape: \n \n \n \n  raise ValueError(\"Shape mismatch for y_true: {} and y_pred: {}\".format( \n \n \n \n  tf.shape(y_true), tf.shape(y_pred))) \n \n \n \n \n \n Also, it is notable to mention that the same model (with exact same code) is able to be compile when using tensorflow-addons v0.6.0 (even, training works perfectly fine)\n Code to reproduce the issue\n from tensorflow.keras.layers import Input, Dense\n from tensorflow.keras.models import Sequential\n from tensorflow.keras.optimizers import Adam\n from tensorflow.keras.losses import Reduction\n \n from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n \n def create_mlp(input_size, num_classes):\n     model = Sequential([\n         Dense(100, activation='relu', input_shape=(input_size,), name='hidden'),\n         Dense(num_classes, activation='softmax', name='output')\n     ], name='mlp')\n \n     loss = SigmoidFocalCrossEntropy(reduction=Reduction.SUM_OVER_BATCH_SIZE)\n     opt = Adam()\n \n     model.summary()\n     model.compile(opt, loss)\n \n     return model\n \n mlp = create_mlp(1000, 5)\n Other info / logs\n Model: \"mlp\"\n _________________________________________________________________\n Layer (type)                 Output Shape              Param #   \n =================================================================\n hidden (Dense)               (None, 100)               100100    \n _________________________________________________________________\n output (Dense)               (None, 5)                 505       \n =================================================================\n Total params: 100,605\n Trainable params: 100,605\n Non-trainable params: 0\n _________________________________________________________________\n ---------------------------------------------------------------------------\n ValueError                                Traceback (most recent call last)\n <ipython-input-10-2891a1b09888> in <module>()\n ----> 1 mlp = create_mlp_classifier(1000, 5)\n \n 14 frames\n <ipython-input-8-686d7bad7efc> in create_mlp_classifier(input_size, num_classes)\n      20 \n      21     model.summary()\n ---> 22     model.compile(opt, loss)\n      23 \n      24     return model\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\n     455     self._self_setattr_tracking = False  # pylint: disable=protected-access\n     456     try:\n --> 457       result = method(self, *args, **kwargs)\n     458     finally:\n     459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\n     444 \n     445       # Creates the model loss and weighted metrics sub-graphs.\n --> 446       self._compile_weights_loss_and_weighted_metrics()\n     447 \n     448       # Functions for train, test and predict will\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\n     455     self._self_setattr_tracking = False  # pylint: disable=protected-access\n     456     try:\n --> 457       result = method(self, *args, **kwargs)\n     458     finally:\n     459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py in _compile_weights_loss_and_weighted_metrics(self, sample_weights)\n    1590       #                   loss_weight_2 * output_2_loss_fn(...) +\n    1591       #                   layer losses.\n -> 1592       self.total_loss = self._prepare_total_loss(masks)\n    1593 \n    1594   def _prepare_skip_target_masks(self):\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py in _prepare_total_loss(self, masks)\n    1650 \n    1651           if hasattr(loss_fn, 'reduction'):\n -> 1652             per_sample_losses = loss_fn.call(y_true, y_pred)\n    1653             weighted_losses = losses_utils.compute_weighted_loss(\n    1654                 per_sample_losses,\n \n /usr/local/lib/python3.6/dist-packages/tensorflow_addons/losses/focal_loss.py in call(self, y_true, y_pred)\n      86             alpha=self.alpha,\n      87             gamma=self.gamma,\n ---> 88             from_logits=self.from_logits)\n      89 \n      90     def get_config(self):\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\n     566         xla_context.Exit()\n     567     else:\n --> 568       result = self._call(*args, **kwds)\n     569 \n     570     if tracing_count == self._get_tracing_count():\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\n     604       # In this case we have not created variables on the first call. So we can\n     605       # run the first trace but we should fail if variables are created.\n --> 606       results = self._stateful_fn(*args, **kwds)\n     607       if self._created_variables:\n     608         raise ValueError(\"Creating variables on a non-first call to a function\"\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\n    2360     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\n    2361     with self._lock:\n -> 2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n    2364 \n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\n    2701 \n    2702       self._function_cache.missed.add(call_context_key)\n -> 2703       graph_function = self._create_graph_function(args, kwargs)\n    2704       self._function_cache.primary[cache_key] = graph_function\n    2705       return graph_function, args, kwargs\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\n    2591             arg_names=arg_names,\n    2592             override_flat_arg_shapes=override_flat_arg_shapes,\n -> 2593             capture_by_value=self._capture_by_value),\n    2594         self._function_attributes,\n    2595         # Tell the ConcreteFunction to clean up its graph once it goes out of\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\n     976                                           converted_func)\n     977 \n --> 978       func_outputs = python_func(*func_args, **func_kwargs)\n     979 \n     980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\n     437         # __wrapped__ allows AutoGraph to swap in a converted function. We give\n     438         # the function a weak reference to itself to avoid a reference cycle.\n --> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)\n     440     weak_wrapped_fn = weakref.ref(wrapped_fn)\n     441 \n \n /tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)\n     966           except Exception as e:  # pylint:disable=broad-except\n     967             if hasattr(e, \"ag_error_metadata\"):\n --> 968               raise e.ag_error_metadata.to_exception(e)\n     969             else:\n     970               raise\n \n ValueError: in converted code:\n \n     /usr/local/lib/python3.6/dist-packages/tensorflow_addons/losses/focal_loss.py:126 sigmoid_focal_crossentropy  *\n         raise ValueError(\"Shape mismatch for y_true: {} and y_pred: {}\".format(\n \n     ValueError: Shape mismatch for y_true: Tensor(\"Shape:0\", shape=(2,), dtype=int32) and y_pred: Tensor(\"Shape_1:0\", shape=(2,),\n Thanks.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "swghosh", "commentT": "2020-01-15T06:22:02Z", "comment_text": "\n \t\tHi, thanks for the report! That check could be deleted actually. See <denchmark-link:https://github.com/tensorflow/addons/pull/298>#298</denchmark-link>\n  for more details. The hot fix is in <denchmark-link:https://github.com/tensorflow/addons/pull/890>#890</denchmark-link>\n . Thank you again for the information!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "swghosh", "commentT": "2020-06-03T12:29:39Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/WindQAQ>@WindQAQ</denchmark-link>\n  is this issue fixed? I am using the following version: <denchmark-link:https://github.com/tensorflow/addons#python-op-compatibility-matrix>Checked</denchmark-link>\n \n <denchmark-code>tf: 2.1\n tfa: 0.9.1\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "swghosh", "commentT": "2020-06-03T12:31:50Z", "comment_text": "\n \t\t\n @WindQAQ is this issue fixed? I am using the following version: Checked\n tf: 2.1\n tfa: 0.9.1\n \n \n Yes this has been fixed!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "swghosh", "commentT": "2020-06-03T12:40:31Z", "comment_text": "\n \t\tThnx. But I'm getting this error with this version. I'm running my code in kaggle kernel! Any catch?\n update:\n It's working anyway. Thank you.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "swghosh", "commentT": "2020-06-03T16:20:17Z", "comment_text": "\n \t\t\n Thnx. But I'm getting this error with this version. I'm running my code in kaggle kernel! Any catch?\n update:\n It's working anyway. Thank you.\n \n Will try out on a Kaggle environment and let you know soon.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "swghosh", "commentT": "2020-06-04T20:22:07Z", "comment_text": "\n \t\tIt will work on kaggle kernel.\n \t\t"}}}, "commit": {"commit_id": "7e4211100117b31d3a1a97488e4cc7df6008ff0e", "commit_author": "Tzu-Wei Sung", "commitT": "2020-01-15 10:47:36-05:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow_addons\\losses\\focal_loss.py", "file_new_name": "tensorflow_addons\\losses\\focal_loss.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": "120,121,122,123"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_addons\\losses\\focal_loss_test.py", "file_new_name": "tensorflow_addons\\losses\\focal_loss_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "109,110,111,112,113,114", "deleted_lines": null, "method_info": {"method_name": "test_keras_model_compile", "method_params": "self", "method_startline": "109", "method_endline": "114"}}}}}}}