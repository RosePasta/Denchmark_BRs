{"BR": {"BR_id": "2334", "BR_author": "vlawhern", "BRopenT": "2021-01-06T15:47:08Z", "BRcloseT": "2021-01-07T00:28:50Z", "BR_text": {"BRsummary": "TypeError 'Not JSON Serializable' when using FilterResponseNormalization", "BRdescription": "\n System information\n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\n TensorFlow version and how it was installed (source or binary): 2.3, compiled\n TensorFlow-Addons version and how it was installed (source or binary): 0.11.2, compiled\n Python version: 3.8\n Is GPU used? (yes/no): Yes\n \n Describe the bug\n When trying to use FilterResponseNormalization I get the following error when trying to save the weights\n TypeError: ('Not JSON Serializable:', <tf.Tensor: shape=(), dtype=float32, numpy=1e-06>)\n Here's a sample code (simple MNIST CNN) which reproduces the issue:\n import tensorflow\n import tensorflow.keras\n from tensorflow.keras.datasets import mnist\n from tensorflow.keras.models import Sequential\n from tensorflow.keras.layers import Dense, Dropout, Flatten\n from tensorflow.keras.layers import Conv2D, MaxPooling2D\n from tensorflow.keras import backend as K\n from tensorflow.keras.callbacks import ModelCheckpoint\n from tensorflow_addons.layers.normalizations import FilterResponseNormalization\n \n # def train_model(batch_size, epochs):\n num_classes = 10\n \n # input image dimensions\n img_rows, img_cols = 28, 28\n \n # the data, split between train and test sets\n (x_train, y_train), (x_test, y_test) = mnist.load_data()\n \n if K.image_data_format() == 'channels_first':\n     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n     input_shape = (1, img_rows, img_cols)\n else:\n     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n     input_shape = (img_rows, img_cols, 1)\n \n x_train = x_train.astype('float32')\n x_test = x_test.astype('float32')\n x_train /= 255\n x_test /= 255\n print('x_train shape:', x_train.shape)\n print(x_train.shape[0], 'train samples')\n print(x_test.shape[0], 'test samples')\n \n # convert class vectors to binary class matrices\n y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n \n model = Sequential()\n model.add(Conv2D(32, kernel_size=(3,3),\n                  activation='relu',\n                  input_shape=input_shape))\n model.add(FilterResponseNormalization())\n model.add(Conv2D(64, (3, 3), activation='relu'))\n model.add(MaxPooling2D(pool_size=(2, 2)))\n model.add(Dropout(0.25))\n model.add(Flatten())\n model.add(Dense(128, activation='relu'))\n model.add(Dropout(0.5))\n model.add(Dense(num_classes, activation='softmax'))\n \n checkpointer = ModelCheckpoint(filepath = '/tmp/check.hdf5', save_best_only = True,\n                                verbose = 1)\n model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n               optimizer=tensorflow.keras.optimizers.Adadelta(),\n               metrics=['accuracy'])\n model.summary()\n model.fit(x_train, y_train,\n           batch_size=128,\n           epochs=10,\n           verbose=2,\n           validation_data=(x_test, y_test),\n           callbacks = [checkpointer])\n score = model.evaluate(x_test, y_test, verbose=0)\n print('Test loss:', score[0])\n print('Test accuracy:', score[1])\n The sample code works as intended when you remove the FilterResponseNormalization layer.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "vlawhern", "commentT": "2021-01-06T21:47:05Z", "comment_text": "\n \t\tHi, <denchmark-link:https://github.com/vlawhern>@vlawhern</denchmark-link>\n . Thanks for the report! I've filed a PR to fix it!\n \t\t"}}}, "commit": {"commit_id": "e304f5c2a8b3763d33862be2db95216b1b85b8cf", "commit_author": "Tzu-Wei Sung", "commitT": "2021-01-06 16:28:50-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_addons\\layers\\normalizations.py", "file_new_name": "tensorflow_addons\\layers\\normalizations.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "443", "deleted_lines": "443", "method_info": {"method_name": "call", "method_params": "self,inputs", "method_startline": "442", "method_endline": "448"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_addons\\layers\\tests\\normalizations_test.py", "file_new_name": "tensorflow_addons\\layers\\tests\\normalizations_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "466,467,468,469,470,471,472,473", "deleted_lines": null, "method_info": {"method_name": "test_filter_response_normalization_save", "method_params": "tmpdir", "method_startline": "466", "method_endline": "473"}}}}}}}