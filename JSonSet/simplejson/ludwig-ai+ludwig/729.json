{"BR": {"BR_id": "729", "BR_author": "jmizgajski", "BRopenT": "2020-06-08T21:05:07Z", "BRcloseT": "2020-06-10T01:10:07Z", "BR_text": {"BRsummary": "Combining 2 input sequences with `sequence` Combiner", "BRdescription": "\n Is your feature request related to a problem? Please describe.\n I am trying to figure out how to combine 2 input sequences with sequence Combiner and I am not sure if this is possible. It would be great if it would ;) Right now I am getting\n <denchmark-code>ValueError: Decoder inputs rank is 2, but should be 3 [batch x sequence x hidden] when using a tagger sequential decoder. Consider setting reduce_output to null / None if a sequential encoder / combiner is used.\n </denchmark-code>\n \n if I try to put two sequences as inputs to sequence combiner.\n Describe the use case\n Consider following (simplified) features where tag is the ouput feature.\n <denchmark-code>text                                lexicon                                      tag\n I am a robot                   0 0 0 1                                      O O O X\n George killed Greg        1 0 1                                         X O X\n </denchmark-code>\n \n Describe the solution you'd like\n I would like to embed text and lexicon series and predict tag with tagger.\n So I would like to set up the combiner in a way that the first row that goes into the encoder of the sequence combiner would look like\n <denchmark-code>[ (emb(I) | emb(0)), (emb(am) | emb(0)), (emb(a) | emb(0)), (emb(robot) | emb(1)] \n </denchmark-code>\n \n like this:\n <denchmark-code>input_features:\n   - name: text\n     type: text\n     level: word\n     encoder: embed\n     reduce_output: null\n   - name: lexicon\n     type: sequence\n     encoder: embed\n     representation: sparse\n     reduce_output: null\n combiner:\n   type: sequence\n   main_sequence_feature: text\n   encoder: rnn\n   cell_type: lstm\n   bidirectional: true\n   num_layers: 2\n   reduce_output: null\n output_features:\n   - name: tag\n     type: sequence\n     decoder: tagger\n     reduce_inputs: null\n </denchmark-code>\n \n Describe alternatives you've considered\n I was hoping for this to work out of the box, but now I am not sure if this is supported.\n Additional context\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jmizgajski", "commentT": "2020-06-09T03:34:33Z", "comment_text": "\n \t\tYour task is exactly the reason why the sequence combiner exists :)\n It looks like you did everything correctly apart from reduce_inputs in the output feature, which should be reduce_input. With that, the tesnor the error is complaining about should have the correct sapes.\n Let me know if this fixes your issue. (this also suggests me to provide a mechanism to notify the user when wrong keys are used in the model definition, this would have avoided your error to happen if you got notified).\n I am really glad that people are starting to use those more advanced features in Ludwig!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jmizgajski", "commentT": "2020-06-09T10:53:10Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/w4nderlust>@w4nderlust</denchmark-link>\n  Thank you for your fast reply, the promise of an easy way to use those advanced features was what has drawn me to Ludwig in the first place (after seeing you present at Interspeech 2019).\n Unfortunately your recommendation does not solve the problem (same issue persists) - likely because reduce_input was set to None anyway as it is the default value for tagger.\n As to your other points:\n I think that ensuring correct user input is an essential addition, as there are few things more frustrating that chasing a configuration typo for half a day ;) You could use something like <denchmark-link:https://python-jsonschema.readthedocs.io/en/stable/>jsonschema</denchmark-link>\n  for it - it is pretty easy to write and convenient to use for validation. Alternatively <denchmark-link:https://www.python.org/dev/peps/pep-0557/>Data Classes in 3.7's PEP 557</denchmark-link>\n  could be of use, but maybe its too early for that.\n I guess there is also a bug in documentation, as this was a copy-paste from the <denchmark-link:https://ludwig-ai.github.io/ludwig-docs/user_guide/#tagger-decoder>tagger definition</denchmark-link>\n . Where it says  (with the  at the end), the same typo appears at least 13 times in the user guide.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jmizgajski", "commentT": "2020-06-09T15:50:12Z", "comment_text": "\n \t\tAlso it would be awesome to have a clear example for such a use-case in Examples :)\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jmizgajski", "commentT": "2020-06-09T20:24:12Z", "comment_text": "\n \t\t\n @w4nderlust Thank you for your fast reply, the promise of an easy way to use those advanced features was what has drawn me to Ludwig in the first place (after seeing you present at Interspeech 2019).\n \n Nice :)\n \n Unfortunately your recommendation does not solve the problem (same issue persists) - likely because reduce_input was set to None anyway as it is the default value for tagger.\n \n Let me try to fix it. Could you please provide a complete reproducible example with data, configuration and command? The data can be synthetic data generated using the script in data/dataset_synthesizer.py and can also be just a couple of lines, no need for the full dataset, as I believe the same problem will appear whith any amount of data.\n \n As to your other points:\n I think that ensuring correct user input is an essential addition, as there are few things more frustrating that chasing a configuration typo for half a day ;) You could use something like jsonschema for it - it is pretty easy to write and convenient to use for validation. Alternatively Data Classes in 3.7's PEP 557 could be of use, but maybe its too early for that.\n \n These are good suggestions, thank you. Although Ludwig's configuration file is highly dynamic, in the sense that it maps directly the parmeters you put in the configuration to parameters in the classes and functions it uses. For that reason, and for the fact that the classes themselves are often changing and new ones are added, so far I preferred not to have a static parsers for the configuration (it's a v0.x still so I know things will change quite a lot still). Moreover, if a use adds their own additional encoder for instance, they would have to modify the parser too, and I want to avoid that. What I plan to do instead is find a simple mechanism that notifies of all the unrecognized keyowrds passed to each function / object, that could be a temporary solution that preserves dynamicity and avoids failing silently like it happens right now.\n \n I guess there is also a bug in documentation, as this was a copy-paste from the tagger definition. Where it says reduce_inputs (with the s at the end), the same typo appears at least 13 times in the user guide.\n \n Fixed it. Although the default value for sequence features is sum not null.\n \n Also it would be awesome to have a clear example for such a use-case in Examples :)\n \n If you agree I can use yours as an example :)\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jmizgajski", "commentT": "2020-06-09T21:01:24Z", "comment_text": "\n \t\tthis will generate the data\n <denchmark-code>import pandas as pd\n \n \n tagged = {'Greg', 'Xavier', 'Smith', 'Piotr', 'robot', 'dad', 'George'}\n lex = {'Greg', 'Xavier', 'robot'}\n \n texts = [\n     \"I like Greg and Greg likes me more than George\",\n     \"Xavier Smith went to the gym with robot dad\",\n     \"robot dad was not the best dad cause he didn't have limbs just bits\",\n     \"Piotr Smith is a better name than Xavier Greg cause at least it is not both first names\",\n     \"the gut is called the second brain for good reasons listen to your gut\",\n     \"omg how many more examples I have to think of am I a robot or what\",\n     \"this is not going to be easy I should ask my dad for help\",\n     \"well he is busy so here is one more from the top of my head\",\n     \"this is a very nice libary btw i hope we manage to solve this issue so I can continue using it\",\n     \"i have great hopes for it\"\n ]\n \n df = pd.DataFrame(dict(\n     text=texts,\n     lexicon=[\" \".join('1' if w in lex else '0' for w in t.split()) for t in texts],\n     tag=[\" \".join('X' if w in tagged else 'O' for w in t.split()) for t in texts]  \n ))\n df.to_csv('combiner_test.csv')\n \n </denchmark-code>\n \n here is the example.yaml (ideally I would also set pretrained_embeddings: glove.txt on the text feature but this is not necessary for the example to reproduce the problem)\n <denchmark-code>input_features:\n   - name: text\n     type: text\n     level: word\n     embeddings_trainable: true\n     embedding_size: 300\n     encoder: embed\n     preprocessing:\n       word_format: space\n     reduce_output: null\n \n   - name: lexicon\n     type: sequence\n     encoder: embed\n     reduce_output: null\n \n \n combiner:\n   type: sequence\n   main_sequence_feature: text\n   encoder: rnn\n   cell_type: lstm\n   bidirectional: true\n   num_layers: 2\n   reduce_input: null\n   reduce_output: null\n \n output_features:\n   - name: tag\n     type: sequence\n     decoder: tagger\n     reduce_input: null\n \n </denchmark-code>\n \n and here is a command to reproduce\n <denchmark-code>ludwig train --data_csv combiner_test.csv --model_definition_file example.yaml \n \n </denchmark-code>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "jmizgajski", "commentT": "2020-06-10T01:12:14Z", "comment_text": "\n \t\tThank you, I found the bug and fixed it. Can you please confirm it now works for you?\n Please install from master with:\n pip uninstall ludwig & pip install git+http://github.com/uber/ludwig.git\n Also if you confirm your approval, I will add this to both examples and test.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "jmizgajski", "commentT": "2020-06-10T08:56:27Z", "comment_text": "\n \t\tI will do that first thing after the Wed meeting spree ;) Thank you <denchmark-link:https://github.com/w4nderlust>@w4nderlust</denchmark-link>\n  ! :)\n You have my approval to use the examples I provided in any way you like, as they are purely synthetic :)\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "jmizgajski", "commentT": "2020-06-10T14:36:29Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/w4nderlust>@w4nderlust</denchmark-link>\n  now I get the following error (both on the synthetic example and the real dataset).\n <denchmark-code> Traceback (most recent call last):\n   File \"/home/aci-user/venv36/bin/ludwig\", line 8, in <module>\n     sys.exit(main())\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/cli.py\", line 118, in main\n     CLI()\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/cli.py\", line 64, in __init__\n     getattr(self, args.command)()\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/cli.py\", line 74, in train\n     train.cli(sys.argv[2:])\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/train.py\", line 809, in cli\n     full_train(**vars(args))\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/train.py\", line 355, in full_train\n     debug=debug\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/train.py\", line 503, in train\n     debug=debug\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/models/model.py\", line 112, in __init__\n     **kwargs\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/models/model.py\", line 178, in __build\n     **kwargs\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/models/combiners.py\", line 294, in __call__\n     **kwargs\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/models/combiners.py\", line 250, in __call__\n     self.reduce_output\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/models/modules/reduction_modules.py\", line 85, in reduce_sequence\n     reduce_mode_registry\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/utils/misc.py\", line 132, in get_from_registry\n     key, registry.keys()\n ValueError: Key False not supported, available options: dict_keys(['last', 'sum', 'mean', 'avg', 'max', 'concat', 'attention', 'none', 'None', None])\n </denchmark-code>\n \n i also tried changing the reduce_input and reduce_output to none but it did not work either.\n It did work on the sample dataset when I edited \"ludwig/models/modules/reduction_modules.py\" locally to map False: dont_reduce, but likely you have a parsing/casting problem somewhere so this would be just a cover up.\n when I run it with this fix on the real dataset I get the following\n <denchmark-code>Traceback (most recent call last):\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n     return fn(*args)\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n     target_list, run_metadata)\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n     run_metadata)\n tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n   (0) Invalid argument: ConcatOp : Dimensions of inputs should match: shape[0] = [512,172,300] vs. shape[1] = [512,128,4]\n          [[{{node sequence_combiner/sequence_concat_combiner/concat}}]]\n          [[tag/measures_tag/rowwise_accuracy_tag/_169]]\n   (1) Invalid argument: ConcatOp : Dimensions of inputs should match: shape[0] = [512,172,300] vs. shape[1] = [512,128,4]\n          [[{{node sequence_combiner/sequence_concat_combiner/concat}}]]\n 0 successful operations.\n 0 derived errors ignored.\n \n During handling of the above exception, another exception occurred:\n \n Traceback (most recent call last):\n   File \"/home/aci-user/venv36/bin/ludwig\", line 8, in <module>\n     sys.exit(main())\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/cli.py\", line 118, in main\n     CLI()\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/cli.py\", line 64, in __init__\n     getattr(self, args.command)()\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/cli.py\", line 74, in train\n     train.cli(sys.argv[2:])\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/train.py\", line 809, in cli\n     full_train(**vars(args))\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/train.py\", line 355, in full_train\n     debug=debug\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/train.py\", line 523, in train\n     **model_definition[TRAINING]\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/ludwig/models/model.py\", line 597, in train\n     is_training=True\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\n     run_metadata_ptr)\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n     feed_dict_tensor, options, run_metadata)\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n     run_metadata)\n   File \"/home/aci-user/venv36/lib64/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n     raise type(e)(node_def, op, message)\n tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n   (0) Invalid argument: ConcatOp : Dimensions of inputs should match: shape[0] = [512,172,300] vs. shape[1] = [512,128,4]\n          [[node sequence_combiner/sequence_concat_combiner/concat (defined at /lib64/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n          [[tag/measures_tag/rowwise_accuracy_tag/_169]]\n   (1) Invalid argument: ConcatOp : Dimensions of inputs should match: shape[0] = [512,172,300] vs. shape[1] = [512,128,4]\n          [[node sequence_combiner/sequence_concat_combiner/concat (defined at /lib64/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n 0 successful operations.\n 0 derived errors ignored.\n \n Original stack trace for 'sequence_combiner/sequence_concat_combiner/concat':\n   File \"/bin/ludwig\", line 8, in <module>\n     sys.exit(main())\n   File \"/lib64/python3.6/site-packages/ludwig/cli.py\", line 118, in main\n     CLI()\n   File \"/lib64/python3.6/site-packages/ludwig/cli.py\", line 64, in __init__\n     getattr(self, args.command)()\n   File \"/lib64/python3.6/site-packages/ludwig/cli.py\", line 74, in train\n     train.cli(sys.argv[2:])\n   File \"/lib64/python3.6/site-packages/ludwig/train.py\", line 809, in cli\n     full_train(**vars(args))\n   File \"/lib64/python3.6/site-packages/ludwig/train.py\", line 355, in full_train\n     debug=debug\n   File \"/lib64/python3.6/site-packages/ludwig/train.py\", line 503, in train\n     debug=debug\n   File \"/lib64/python3.6/site-packages/ludwig/models/model.py\", line 112, in __init__\n     **kwargs\n   File \"/lib64/python3.6/site-packages/ludwig/models/model.py\", line 178, in __build\n     **kwargs\n   File \"/lib64/python3.6/site-packages/ludwig/models/combiners.py\", line 294, in __call__\n     **kwargs\n   File \"/lib64/python3.6/site-packages/ludwig/models/combiners.py\", line 234, in __call__\n     hidden = tf.concat(representations, 2)\n   File \"/lib64/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\n     return target(*args, **kwargs)\n   File \"/lib64/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\", line 1420, in concat\n     return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n   File \"/lib64/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 1257, in concat_v2\n     \"ConcatV2\", values=values, axis=axis, name=name)\n   File \"/lib64/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n     op_def=op_def)\n   File \"/lib64/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n     return func(*args, **kwargs)\n   File \"/lib64/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n     attrs, op_def, compute_device)\n   File \"/lib64/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n     op_def=op_def)\n   File \"/lib64/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n     self._traceback = tf_stack.extract_stack()\n </denchmark-code>\n \n which is the same problem I was running into when trying to use the sequence_concat combiner. I also checked my dataset and the features I dry run on are all sequences of equal length and all under 128 (no wonder, this is how I generated them), so I doubt this is a problem of the dataset. So it seems the rabbit hole goes deeper :( I would reopen this issue until at least the test is in place.\n I think it is unlikely that ludwig is applying some other tokenization on the text than spliting on spaces (which is what I want here) so could it be some other vector is wrongfully concatenated to the end of the text or tag feature?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "jmizgajski", "commentT": "2020-06-10T20:00:08Z", "comment_text": "\n \t\tPushed a new commit, it should fix The first issue, sorry about the additional step ;)\n As for the second issue, that may be data dependent. The logic is that vectors are concatenated along the the third (hidden) dimension, so they should have the first two that match: batch size and sequence length.\n What I suspect is happening is that there is a mismatch between the length of the text after tokenization and the length of the tag feature.\n The default text cokenizer is space_punct that splits on space and punctuation, so that \"Hello, world!\" becomes [\"Hello\", \",\", \"world\", \"!\"]. If you want to use just space as tokenizer, just add to the text feature:\n <denchmark-code>preprocessing:\n   word_tokenizer: space\n </denchmark-code>\n \n If even this does not fix the issue, i can try taking a look at it myself (but i would need at least a couple datapoints for which the problem is originated).\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "jmizgajski", "commentT": "2020-06-11T10:55:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/w4nderlust>@w4nderlust</denchmark-link>\n  I guess we found another <denchmark-link:https://ludwig-ai.github.io/ludwig-docs/examples/#named-entity-recognition-tagging>bug in the docs</denchmark-link>\n  then :) as it does say  in the tagger example. (or maybe I am looking at release docs and we changed to work with master throughout the development of this thread, not sure)\n also adding these lines under the text feature like in the example above did not help, I had to add it as a top level item in the yaml file, but now I am able to train. Thank you!\n I think this is something to underline in the documentation :)\n If any one has the same problem the following config could be of help:\n <denchmark-code>input_features:\n   - name: text\n     type: text\n     level: word\n     embeddings_trainable: true\n     embedding_size: 300\n     encoder: embed\n     reduce_output: null\n \n   - name: lexicon\n     type: sequence\n     encoder: embed\n     reduce_output: null\n \n combiner:\n   type: sequence\n   main_sequence_feature: text\n   encoder: rnn\n   cell_type: lstm\n   bidirectional: true\n   num_layers: 2\n   reduce_input: null\n   reduce_output: null\n \n output_features:\n   - name: tag\n     type: sequence\n     decoder: tagger\n     reduce_input: null\n \n preprocessing:\n   text:\n     word_tokenizer: space\n </denchmark-code>\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "jmizgajski", "commentT": "2020-06-11T19:33:57Z", "comment_text": "\n \t\tGood catch. yes word_format was an old name for word_tokenizer, I'm updating the docs right now. Regarding your model definition. You need only one word_tokenizer: space, either in the text feature or at the top level. The top level one applies to all text features, the one inside the feature applies only to that specific feature, but you have only one text feature so it makes no difference.\n Glad you were able to train the model!\n \t\t"}}}, "commit": {"commit_id": "ee086fb71d0f9e3c4eb8df9ff38b0420321cd66a", "commit_author": "w4nderlust", "commitT": "2020-06-09 18:09:39-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ludwig\\models\\combiners.py", "file_new_name": "ludwig\\models\\combiners.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "150,268,275", "deleted_lines": "32,151,269"}}}}}}