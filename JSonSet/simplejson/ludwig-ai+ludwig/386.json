{"BR": {"BR_id": "386", "BR_author": "priyaJagan90", "BRopenT": "2019-06-21T04:43:50Z", "BRcloseT": "2019-07-13T19:20:16Z", "BR_text": {"BRsummary": "Cannot feed value of shape for Tensor with --model_load_path for NER", "BRdescription": "\n Describe the bug\n I am trying to use  pretrained model weights for initialization for building NER models using --model_load_path (defines the path of my pretrained model). Pretrained model built with 7K  records. I was trying to build another NER model and uses pretrained model weights for initialization with 1.5 K records. But I am getting Cannot feed value of shape for Tensor error while building model with below command. I am using CONLL data for training\n Command:\n ludwig experiment --data_train_csv training/training_1.csv --data_validation_csv validation/validation_1.csv --data_test_csv testing/testing_1.csv --model_load_path results/experiment_run_0/model --model_definition_file model_definition/model_definition.yaml\n Error\n File \"D:\\Development_Avecto\\Anaconda3\\Scripts\\ludwig-script.py\", line 11, in \n load_entry_point('ludwig==0.1.2', 'console_scripts', 'ludwig')()\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\ludwig\\cli.py\", line 94, in main\n CLI()\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\ludwig\\cli.py\", line 60, in init\n getattr(self, args.command)()\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\ludwig\\cli.py\", line 65, in experiment\n experiment.cli(sys.argv[2:])\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\ludwig\\experiment.py\", line 472, in cli\n experiment(**vars(args))\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\ludwig\\experiment.py\", line 200, in experiment\n **kwargs\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\ludwig\\train.py\", line 301, in full_train\n debug=debug\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\ludwig\\train.py\", line 461, in train\n **model_definition['training']\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\ludwig\\models\\model.py\", line 523, in train\n is_training=True\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n run_metadata_ptr)\n File \"D:\\Development_Avecto\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run\n str(subfeed_t.get_shape())))\n ValueError: Cannot feed value of shape (128, 60) for Tensor 'Tagged_Entities/Tagged_Entities_placeholder:0', which has shape '(?, 113)'\n Expected behavior\n I wanted to create the NER model using prebuilt model wiegths as initialization\n Environment (please complete the following information):\n \n OS: Windows\n Version:  Windows10\n Python version : 3.6.5\n Ludwig version : 0.1.2\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "priyaJagan90", "commentT": "2019-06-21T06:11:34Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/priyaJagan90>@priyaJagan90</denchmark-link>\n  thank you for this report. My best guess so far is that the original dataset and the new one have different parameters for .\n Could you please help us replicate the error so that we can debug it?\n Ideally we would need:\n \n yaml definition of the original model\n original data (most likely a subsample, even obfuscated or with synthetic data may work, as long as it leads to the same error)\n command for the second training importing the previous model\n the second dataset (again subsampled, obfuscated or synthesized, as long as the error happens).\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "priyaJagan90", "commentT": "2019-07-02T11:02:48Z", "comment_text": "\n \t\tHi,\n Thanks for your response. I have attached the subsample for original dataset and dataset for second run.\n <denchmark-link:https://github.com/uber/ludwig/files/3349713/Data_subset.zip>Data_subset.zip</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "priyaJagan90", "commentT": "2019-07-07T00:55:36Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/priyaJagan90>@priyaJagan90</denchmark-link>\n  sorry for taking so long, but I was able to replicate your issue, identify the problem and solving it. Here you find a branch with the fixed code: <denchmark-link:https://github.com/uber/ludwig/tree/fix_model_load_path>https://github.com/uber/ludwig/tree/fix_model_load_path</denchmark-link>\n \n Could you please try it out and confirm that it solved your problem? In that case I will merge the branch in master and the solution will be available to everyone in the next release.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "priyaJagan90", "commentT": "2019-07-26T16:30:56Z", "comment_text": "\n \t\tHi\n sorry for the late reply. I couldn't access the link <denchmark-link:https://github.com/uber/ludwig/tree/fix_model_load_path>https://github.com/uber/ludwig/tree/fix_model_load_path</denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "priyaJagan90", "commentT": "2019-07-26T20:52:39Z", "comment_text": "\n \t\tYes in the mean time we merged into master. Please try using Ludwig 0.2 the\n issue should be solved.\n On Fri, 26 Jul 2019 at 09:30, priyaJagan90 ***@***.***> wrote:\n  Hi\n  sorry for the late reply. I couldn't access the link\n  <denchmark-link:https://github.com/uber/ludwig/tree/fix_model_load_path>https://github.com/uber/ludwig/tree/fix_model_load_path</denchmark-link>\n \n  <<denchmark-link:https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_uber_ludwig_tree_fix-5Fmodel-5Fload-5Fpath&d=DwMCaQ&c=r2dcLCtU9q6n0vrtnDw9vg&r=RrWxefUdVFeb7Dpg6EF4Ug&m=23i5BhKdATUS7oX_u6k5vF4VIyvNhU-hk3Tq7C4Vmrs&s=EE1fS-I-swgwjo1gFSgwVDFKnlwWJiAbFkCru-xgp6s&e=>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_uber_ludwig_tree_fix-5Fmodel-5Fload-5Fpath&d=DwMCaQ&c=r2dcLCtU9q6n0vrtnDw9vg&r=RrWxefUdVFeb7Dpg6EF4Ug&m=23i5BhKdATUS7oX_u6k5vF4VIyvNhU-hk3Tq7C4Vmrs&s=EE1fS-I-swgwjo1gFSgwVDFKnlwWJiAbFkCru-xgp6s&e=</denchmark-link>\n >\n \n  \u2014\n  You are receiving this because you modified the open/close state.\n \n \n  Reply to this email directly, view it on GitHub\n  <<denchmark-link:https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_uber_ludwig_issues_386-3Femail-5Fsource-3Dnotifications-26email-5Ftoken-3DAACVISFJSUFCVGRYQCOEKTLQBMREDA5CNFSM4H2KYZ22YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD25C7GQ-23issuecomment-2D515518362&d=DwMCaQ&c=r2dcLCtU9q6n0vrtnDw9vg&r=RrWxefUdVFeb7Dpg6EF4Ug&m=23i5BhKdATUS7oX_u6k5vF4VIyvNhU-hk3Tq7C4Vmrs&s=3tG0wI-GMXf67AUxTtuUUI-Ul61UBZnLDlTRxONtMOY&e=>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_uber_ludwig_issues_386-3Femail-5Fsource-3Dnotifications-26email-5Ftoken-3DAACVISFJSUFCVGRYQCOEKTLQBMREDA5CNFSM4H2KYZ22YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD25C7GQ-23issuecomment-2D515518362&d=DwMCaQ&c=r2dcLCtU9q6n0vrtnDw9vg&r=RrWxefUdVFeb7Dpg6EF4Ug&m=23i5BhKdATUS7oX_u6k5vF4VIyvNhU-hk3Tq7C4Vmrs&s=3tG0wI-GMXf67AUxTtuUUI-Ul61UBZnLDlTRxONtMOY&e=</denchmark-link>\n >,\n  or mute the thread\n  <<denchmark-link:https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AACVISDX4QGMS5OHFYU35DLQBMREDANCNFSM4H2KYZ2Q&d=DwMCaQ&c=r2dcLCtU9q6n0vrtnDw9vg&r=RrWxefUdVFeb7Dpg6EF4Ug&m=23i5BhKdATUS7oX_u6k5vF4VIyvNhU-hk3Tq7C4Vmrs&s=u-1sZCYG-HIDGbeJSYstHstzjFBtVNpMcHFxUOHGU98&e=>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AACVISDX4QGMS5OHFYU35DLQBMREDANCNFSM4H2KYZ2Q&d=DwMCaQ&c=r2dcLCtU9q6n0vrtnDw9vg&r=RrWxefUdVFeb7Dpg6EF4Ug&m=23i5BhKdATUS7oX_u6k5vF4VIyvNhU-hk3Tq7C4Vmrs&s=u-1sZCYG-HIDGbeJSYstHstzjFBtVNpMcHFxUOHGU98&e=</denchmark-link>\n >\n  .\n \n -- \n ----\n Piero Molino\n Sr Research Scientist\n UBER AI Labs\n \t\t"}}}, "commit": {"commit_id": "5f30f878d9f5009db398fb2072fb74dce0a76840", "commit_author": "Piero Molino", "commitT": "2019-07-13 12:20:13-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "ludwig\\data\\preprocessing.py", "file_new_name": "ludwig\\data\\preprocessing.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "500", "deleted_lines": null, "method_info": {"method_name": "_preprocess_csv_for_training", "method_params": "features,data_csv,data_train_csv,data_validation_csv,data_test_csv,train_set_metadata_json,skip_save_processed_input,preprocessing_params,random_seed", "method_startline": "494", "method_endline": "503"}}, "hunk_1": {"Ismethod": 1, "added_lines": "622", "deleted_lines": null, "method_info": {"method_name": "_preprocess_df_for_training", "method_params": "features,data_df,data_train_df,data_validation_df,data_test_df,train_set_metadata_json,preprocessing_params,random_seed", "method_startline": "616", "method_endline": "624"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ludwig\\models\\model.py", "file_new_name": "ludwig\\models\\model.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "415,416,417", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ludwig\\train.py", "file_new_name": "ludwig\\train.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "209,210,211,212,213,214,215", "deleted_lines": null}}}}}}