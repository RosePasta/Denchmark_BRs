{"BR": {"BR_id": "1588", "BR_author": "nathanbreitsch", "BRopenT": "2020-04-24T03:46:31Z", "BRcloseT": "2020-04-30T12:04:51Z", "BR_text": {"BRsummary": "Named converted to regular tuples when sent to the gpu.", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n Named tuples returned from Dataset get converted to regular tuples when sent to the gpu.\n This happens because isinstance(instance_of_a_named_tuple, tuple) evaluates to True in distrib_parts.py\n \n \n \n pytorch-lightning/pytorch_lightning/trainer/distrib_parts.py\n \n \n          Line 463\n       in\n       67d5f4d\n \n \n \n \n \n \n  if isinstance(batch, tuple): \n \n \n \n \n \n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n import pytorch_lightning as pl\n from collections import namedtuple\n import torch\n import numpy\n \n NamedTupleDemoInput = namedtuple('DemoInput', ['x1', 'x2', 'y'])\n \n class NamedTupleDemoDataset:\n     def __len__(self):\n         return 30000\n \n     def __getitem__(self, index):\n         x1 = numpy.random.uniform(0, 100)\n         x2 = numpy.random.uniform(0, 100)\n         y = 2*x1 + 3*x2 + numpy.random.normal(0, 0.05)\n         return NamedTupleDemoInput(x1, x2, y)\n \n class WeightedSum(torch.nn.Module):\n     def __init__(self):\n         super(WeightedSum, self).__init__()\n         self.a = torch.nn.Parameter(torch.zeros(1))\n         self.b = torch.nn.Parameter(torch.zeros(1))\n \n     def forward(self, x1, x2):\n         return self.a * x1 + self.b * x2\n \n class NamedTupleDemo(pl.LightningModule):\n \n     def __init__(self):\n         super(NamedTupleDemo, self).__init__()\n         self.model = WeightedSum()\n \n     def forward(self, x1, x2):\n         return self.model(x1, x2)\n \n     def train_dataloader(self):\n         return torch.utils.data.DataLoader(NamedTupleDemoDataset(), batch_size=128)\n \n     def training_step(self, batch, batch_index):\n         yhat = self.forward(batch.x1, batch.x2)\n         return {'loss': torch.nn.functional.mse_loss(batch.y, yhat)}\n \n     def configure_optimizers(self):\n         return torch.optim.Adam(self.parameters(), lr=1e-2)\n \n if __name__ == '__main__':\n     module = NamedTupleDemo()\n     pl.Trainer(max_epochs=20, gpus=1).fit(module)\n     print(f'a={float(module.model.a)} b={float(module.model.b)}')\n <denchmark-code>Traceback (most recent call last):\n   File \"demo.py\", line 48, in <module>\n     pl.Trainer(max_epochs=20, gpus=1).fit(module)\n   File \"/home/n/repos/pytorch-lightning/pytorch_lightning/trainer/trainer.py\", line 749, in fit\n     self.single_gpu_train(model)\n   File \"/home/n/repos/pytorch-lightning/pytorch_lightning/trainer/distrib_parts.py\", line 491, in single_gpu_train\n     self.run_pretrain_routine(model)\n   File \"/home/n/repos/pytorch-lightning/pytorch_lightning/trainer/trainer.py\", line 910, in run_pretrain_routine\n     self.train()\n   File \"/home/n/repos/pytorch-lightning/pytorch_lightning/trainer/training_loop.py\", line 384, in train\n     self.run_training_epoch()\n   File \"/home/n/repos/pytorch-lightning/pytorch_lightning/trainer/training_loop.py\", line 456, in run_training_epoch\n     _outputs = self.run_training_batch(batch, batch_idx)\n   File \"/home/n/repos/pytorch-lightning/pytorch_lightning/trainer/training_loop.py\", line 633, in run_training_batch\n     loss, batch_output = optimizer_closure()\n   File \"/home/n/repos/pytorch-lightning/pytorch_lightning/trainer/training_loop.py\", line 597, in optimizer_closure\n     output_dict = self.training_forward(split_batch, batch_idx, opt_idx, self.hiddens)\n   File \"/home/n/repos/pytorch-lightning/pytorch_lightning/trainer/training_loop.py\", line 770, in training_forward\n     output = self.model.training_step(*args)\n   File \"demo.py\", line 40, in training_step\n     yhat = self.forward(batch.x1, batch.x2)\n AttributeError: 'tuple' object has no attribute 'x1'\n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n Namedtuples returned from the dataset should be keep their original fields.\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n CUDA:\n - GPU:\n - GeForce RTX 2080 Ti\n - available:         True\n - version:           10.2\n Packages:\n - numpy:             1.18.3\n - pyTorch_debug:     False\n - pyTorch_version:   1.5.0\n - pytorch-lightning: 0.7.4rc5\n - tensorboard:       2.2.1\n - tqdm:              4.45.0\n System:\n - OS:                Linux\n - architecture:\n - 64bit\n - ELF\n - processor:\n - python:            3.8.2\n - version:           #1 SMP PREEMPT Sun, 05 Apr 2020 05:13:14 +0000\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "nathanbreitsch", "commentT": "2020-04-24T03:47:10Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}}}, "commit": {"commit_id": "3eac6cfd4fbbc4d13f4e93f6d90f8ee5302c421e", "commit_author": "Nathan Breitsch", "commitT": "2020-04-30 08:04:50-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\distrib_parts.py", "file_new_name": "pytorch_lightning\\trainer\\distrib_parts.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "464,465,466,467,468,469,470,471,472", "deleted_lines": "464,465,466,467", "method_info": {"method_name": "__transfer_data_to_device", "method_params": "self,batch,device,gpu_id", "method_startline": "442", "method_endline": "482"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\models\\test_cpu.py", "file_new_name": "tests\\models\\test_cpu.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "225,226,227,228,229,230", "deleted_lines": null, "method_info": {"method_name": "test_single_gpu_batch_parse", "method_params": "", "method_startline": "185", "method_endline": "230"}}}}}}}