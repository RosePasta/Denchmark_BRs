{"BR": {"BR_id": "2653", "BR_author": "s-rog", "BRopenT": "2020-07-21T01:30:04Z", "BRcloseT": "2020-09-02T13:36:45Z", "BR_text": {"BRsummary": "Checkpoints cannot be loaded in non-pl env", "BRdescription": "\n ## \ud83d\ude80 Feature\n Add an option to save only state_dict for ModelCheckpoint callbacks\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n PL checkpoints cannot be loaded in non-pl envs\n <denchmark-h:h3>Motivation</denchmark-h>\n \n To be able to move trained models and weights into pytorch only environments\n <denchmark-h:h3>Additional context</denchmark-h>\n \n Currently  when you do torch.load() on a pl generated checkpoint in an environment without pl, there is a pickling error. For my current use case I have to load the checkpoints in my training environment and save them again with only state_dict for the weights.\n See <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2653#issuecomment-681303007>reply below</denchmark-link>\n  for more info\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "s-rog", "commentT": "2020-07-21T18:04:55Z", "comment_text": "\n \t\tYou can use save_weights_only parameter in ModelCheckpoint to save weights only. Although it will save epoch, global_step and pl_version but that won't be a problem there, I guess. Also can you show the pickling error you are getting?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "s-rog", "commentT": "2020-07-22T00:23:59Z", "comment_text": "\n \t\tI am using save_weights_only  and that causes a pickling error with module lightning not found (don't have the extact error atm)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "s-rog", "commentT": "2020-07-22T04:46:34Z", "comment_text": "\n \t\tCan you check when you load that checkpoint manually in pl env, what keys does that file have?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "s-rog", "commentT": "2020-08-27T02:20:20Z", "comment_text": "\n \t\tError in non-pl env\n <denchmark-code>ModuleNotFoundError                       Traceback (most recent call last)\n <ipython-input-10-dbc5018f5317> in <module>\n ----> 1 pretrained_dict = torch.load('../input/weights/test.ckpt', map_location=torch.device('cpu'))\n \n /opt/conda/lib/python3.7/site-packages/torch/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)\n     591                     return torch.jit.load(f)\n     592                 return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n --> 593         return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n     594 \n     595 \n \n /opt/conda/lib/python3.7/site-packages/torch/serialization.py in _legacy_load(f, map_location, pickle_module, **pickle_load_args)\n     771     unpickler = pickle_module.Unpickler(f, **pickle_load_args)\n     772     unpickler.persistent_load = persistent_load\n --> 773     result = unpickler.load()\n     774 \n     775     deserialized_storage_keys = pickle_module.load(f, **pickle_load_args)\n \n ModuleNotFoundError: No module named 'pytorch_lightning'\n </denchmark-code>\n \n keys in pl env\n dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'hparams_name', 'hyper_parameters'])\n <denchmark-link:https://github.com/rohitgr7>@rohitgr7</denchmark-link>\n  sorry about the late reply, completely forgot about this issue\n Edit:\n found the issue, I'll look into a fix\n <denchmark-code>for k, v in pretrained_dict.items():\n     print(type(k), type(v))\n \n <class 'str'> <class 'int'>\n <class 'str'> <class 'int'>\n <class 'str'> <class 'str'>\n <class 'str'> <class 'collections.OrderedDict'>\n <class 'str'> <class 'str'>\n <class 'str'> pytorch_lightning.utilities.parsing.AttributeDict\n </denchmark-code>\n \n Edit 2:\n I'll submit a PR after refactor week!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "s-rog", "commentT": "2020-08-31T03:06:08Z", "comment_text": "\n \t\tI got around to testing and can load checkpoints now in non-pl envs. The only change needed was to cast hyper_parameters to dict in dump_checkpoint of  pytorch_lightning/trainer/training_io.py\n - checkpoint[LightningModule.CHECKPOINT_HYPER_PARAMS_KEY] = model.hparams\n + checkpoint[LightningModule.CHECKPOINT_HYPER_PARAMS_KEY] = dict(model.hparams)\n Thoughts?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "s-rog", "commentT": "2020-08-31T10:38:08Z", "comment_text": "\n \t\tYeah this looks good to avoid such error since AttributeDict is a PL thing.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "s-rog", "commentT": "2020-08-31T18:04:46Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/s-rog>@s-rog</denchmark-link>\n  , I tried on master with  and these are the dict keys I got. No hyperparams.\n dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict'])\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "s-rog", "commentT": "2020-09-01T00:37:25Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rohitgr7>@rohitgr7</denchmark-link>\n  Did the model have ?\n If you look at dump_checkpoint() the weights_only arg only controls:\n callbacks, optimizer_states, lr_schedulers, native_amp_scaling_state and amp_scaling_state\n hparams loggging is only controlled by if model.hparams:\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "s-rog", "commentT": "2020-09-01T16:56:16Z", "comment_text": "\n \t\tok, yeah my bad :)\n \t\t"}}}, "commit": {"commit_id": "65e6687c54937db0f9bdbdb089ac9d288457d6f8", "commit_author": "s-rog", "commitT": "2020-09-02 15:36:42+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\training_io.py", "file_new_name": "pytorch_lightning\\trainer\\training_io.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "374,377,378", "deleted_lines": "373", "method_info": {"method_name": "dump_checkpoint", "method_params": "self,bool", "method_startline": "325", "method_endline": "383"}}}}}}}