{"BR": {"BR_id": "9295", "BR_author": "marcoabreu", "BRopenT": "2018-01-04T01:11:03Z", "BRcloseT": "2018-03-09T17:14:19Z", "BR_text": {"BRsummary": "test_operator.test_laop_3 hangs", "BRdescription": "\n The execution of test_operator.test_laop_3 randomly hangs without a message on Python3: MKLML-CPU. See <denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/130/pipeline/329>http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/130/pipeline/329</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "marcoabreu", "commentT": "2018-01-04T01:11:26Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/piiswrong>@piiswrong</denchmark-link>\n  <denchmark-link:https://github.com/szha>@szha</denchmark-link>\n  Please assign the proper label.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "marcoabreu", "commentT": "2018-01-06T11:22:31Z", "comment_text": "\n \t\tHere's the ticket for the LA hangs with MKL <denchmark-link:https://github.com/mseeger>@mseeger</denchmark-link>\n  <denchmark-link:https://github.com/asmushetzel>@asmushetzel</denchmark-link>\n .\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "marcoabreu", "commentT": "2018-01-06T11:25:24Z", "comment_text": "\n \t\tThe next time someone runs into this one let's try and get a trace of all the threads.  I looked at this a little already with <denchmark-link:https://github.com/asmushetzel>@asmushetzel</denchmark-link>\n , and it certainly was a deadlock during initialization (i.e. not livelock, no activity on any thread), but I wasn't exactly clear on why one of the threads was blocked.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "marcoabreu", "commentT": "2018-01-06T14:59:07Z", "comment_text": "\n \t\tIf the test hangs using MKL, then I am afraid also a normal run of MXNet, using the linalg ops, will hang on MKL eventually.\n Do you also see these problems with the other laop tests? Because laop3 is only for a small subset of the ops. Is it clear which of them is the issue?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "marcoabreu", "commentT": "2018-01-06T15:07:53Z", "comment_text": "\n \t\tI have never seen this problem arise with any other test than laop3. Of course, it might be possible that the previous tests brought the process into a corrupted state. I haven't had the chance yet to dig into the problem and identify the failing line - we might consider adding more debug output to those tests, especially if one test-method consists of multiple tests.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "marcoabreu", "commentT": "2018-01-10T13:37:10Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/meissnereric>@meissnereric</denchmark-link>\n \n Eric, can you own this (I'm willing to help). The configuration that fails is\n python3, USE_MKL2017=1, USE_MKL2017_EXPERIMENTAL=1, USE_BLAS=openblas\n The hanging test executes seyvd, which according to the above settings,  will be the openblas-version of seyvd.\n Nobody currently knows what the issue is, there seems to be no change in test environment, neither have we modified any linalg-functions (at least to my knowledge, you may take a look at the git logs). Still this problem suddenly popped up (and worse only occasional, you have to run it repeatedly until it sometimes hangs).\n This is important, as we want to have all tests in MXNet working.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "marcoabreu", "commentT": "2018-01-10T13:43:24Z", "comment_text": "\n \t\tSure, I'll have a look at it today thanks for letting me know.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "marcoabreu", "commentT": "2018-01-10T20:33:22Z", "comment_text": "\n \t\tDid these test start failing around the end of December, when this change was merged?  <denchmark-link:https://github.com/apache/incubator-mxnet/commit/d0388d00d5959d96341129a40ab21264476dfda6>d0388d0</denchmark-link>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "marcoabreu", "commentT": "2018-01-10T20:39:48Z", "comment_text": "\n \t\tThat's the one! Yes, it started happening after Christmas. You're awesome\n Kellen, thanks for finding it!\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Wed, Jan 10, 2018 at 9:33 PM, Kellen Sunderland ***@***.*** > wrote:\n  Did these test start failing around the end of December, when this change\n  was merged? d0388d0#diff-6d85ccdfa8c4118c1722e64466901ef2\n  <d0388d0#diff-6d85ccdfa8c4118c1722e64466901ef2>\n \n  \u2014\n  You are receiving this because you authored the thread.\n  Reply to this email directly, view it on GitHub\n  <#9295 (comment)>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/ARxB6_W_yPcJadrVW-C7QTm9HyVs7jpCks5tJR6tgaJpZM4RSdR1>\n  .\n \n \n \n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "marcoabreu", "commentT": "2018-01-11T07:38:18Z", "comment_text": "\n \t\tEric Meissner in Cambridge now owning this one.\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Jan 10, 2018 9:33 PM, \"Kellen Sunderland\" ***@***.***> wrote:\n  Did these test start failing around the end of December, when this change\n  was merged? d0388d0#diff-6d85ccdfa8c4118c1722e64466901ef2\n  <d0388d0#diff-6d85ccdfa8c4118c1722e64466901ef2>\n \n  \u2014\n  You are receiving this because you were mentioned.\n  Reply to this email directly, view it on GitHub\n  <#9295 (comment)>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/AGNRoilFB-a47TSiN-5-KVXmwuyDkX5gks5tJR6tgaJpZM4RSdR1>\n  .\n \n \n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "marcoabreu", "commentT": "2018-01-11T13:44:06Z", "comment_text": "\n \t\tSo on a c5.2xlarge instance I built mxnet from source using USE_MKL2017=1, USE_MKL2017_EXPERIMENTAL=1, USE_BLAS=openblas flags this morning and ran\n PYTHONPATH=./python/ nosetests3 --verbose tests/python/unittest\n 3 separate times test_operator.test_laop_3 failed. It didn't hang for me at all. It's the only test to return a FAILURE as well. I'm not sure if we've seen failures like this before for the test, or only the hanging issue.\n Thoughts?\n <denchmark-h:h2>======================================================================\n FAIL: test_operator.test_laop_3</denchmark-h>\n \n Traceback (most recent call last):\n File \"/usr/lib/python3/dist-packages/nose/case.py\", line 198, in runTest\n self.test(*self.arg)\n File \"/home/ubuntu/src/incubator-mxnet/tests/python/unittest/test_operator.py\", line 4278, in test_laop_3\n check_fw(test_syevd2, [data_in1], [res_eye, res_a])\n File \"/home/ubuntu/src/incubator-mxnet/tests/python/unittest/test_operator.py\", line 4253, in \n atol=atol_fw, dtype=dtype)\n File \"/home/ubuntu/src/incubator-mxnet/python/mxnet/test_utils.py\", line 997, in check_symbolic_forward\n equal_nan=equal_nan)\n File \"/home/ubuntu/src/incubator-mxnet/python/mxnet/test_utils.py\", line 495, in assert_almost_equal\n raise AssertionError(msg)\n AssertionError:\n Items are not equal:\n Error 2142110.669088 exceeds tolerance rtol=0.000001, atol=0.000001.  Location of maximum error:(5, 7), a=3.772180, b=0.518782\n EXPECTED_Ut_L_U_output: array([[ -6.29539959,   3.14786301,  -7.76048236, ..., -14.55426068,\n 5.89200304,   2.89609144],\n [  3.14786301,  -2.20936719,  -5.00206088, ...,   2.18995202,...\n FORWARD_Ut_L_U_output: array([[ -5.86758909,   2.1861068 ,  -8.22037894, ..., -15.72788167,\n 7.86870499,   2.89609144],\n [  2.1861068 ,  -3.11242836,  -5.28864811, ...,   3.78613349,...\n <denchmark-h:hr></denchmark-h>\n \n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "marcoabreu", "commentT": "2018-01-12T06:55:23Z", "comment_text": "\n \t\tHello,\n \n This test compares A and identity to what you get computing expressions\n from U and Lambda.\n Please output everything, A, U, Lambda, and results of expressions. Do this\n directly in numpy format. Then compare to numpy. Use same style.\n These errors are too large to be due to low prec.\n Exactly what a test is for.\n \n If you find something wrong either with syevd, or worse, with gemm2, please\n isolate the case in non random test.\n \n \n On Jan 11, 2018 14:44, \"Eric R Meissner\" <notifications@github.com> wrote:\n \n Hmm, the plot thickens.\n \n So on a c5.2xlarge instance I built mxnet from source using USE_MKL2017=1,\n USE_MKL2017_EXPERIMENTAL=1, USE_BLAS=openblas flags this morning and ran\n PYTHONPATH=./python/ nosetests3 --verbose tests/python/unittest\n \n 3 separate times test_operator.test_laop_3 FAILED apparently due to some\n numerical issues. I haven't seen anyone mention this test failing yet, but\n it didn't hang for me at all. It's the only test to return a FAILURE as\n well.\n \n Thoughts?\n ======================================================================\n FAIL: test_operator.test_laop_3\n \n Traceback (most recent call last):\n File \"/usr/lib/python3/dist-packages/nose/case.py\", line 198, in runTest\n self.test(*self.arg)\n File \"/home/ubuntu/src/incubator-mxnet/tests/python/unittest/test_operator.py\",\n line 4278, in test_laop_3\n check_fw(test_syevd2, [data_in1], [res_eye, res_a])\n File \"/home/ubuntu/src/incubator-mxnet/tests/python/unittest/test_operator.py\",\n line 4253, in\n atol=atol_fw, dtype=dtype)\n File \"/home/ubuntu/src/incubator-mxnet/python/mxnet/test_utils.py\", line\n 997, in check_symbolic_forward\n equal_nan=equal_nan)\n File \"/home/ubuntu/src/incubator-mxnet/python/mxnet/test_utils.py\", line\n 495, in assert_almost_equal\n raise AssertionError(msg)\n AssertionError:\n Items are not equal:\n Error 2142110.669088 exceeds tolerance rtol=0.000001, atol=0.000001.\n Location of maximum error:(5, 7), a=3.772180, b=0.518782\n EXPECTED_Ut_L_U_output: array([[ -6.29539959, 3.14786301, -7.76048236, ...,\n -14.55426068,\n 5.89200304, 2.89609144],\n [ 3.14786301, -2.20936719, -5.00206088, ..., 2.18995202,...\n FORWARD_Ut_L_U_output: array([[ -5.86758909, 2.1861068 , -8.22037894, ...,\n -15.72788167,\n 7.86870499, 2.89609144],\n [ 2.1861068 , -3.11242836, -5.28864811, ..., 3.78613349,...\n ------------------------------\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <<denchmark-link:https://github.com/apache/incubator-mxnet/issues/9295#issuecomment-356937657>#9295 (comment)</denchmark-link>\n >,\n or mute the thread\n <<denchmark-link:https://github.com/notifications/unsubscribe-auth/AGNRomJq1Z8Zj7UzMcgka3TlUVjsijqKks5tJhBJgaJpZM4RSdR1>https://github.com/notifications/unsubscribe-auth/AGNRomJq1Z8Zj7UzMcgka3TlUVjsijqKks5tJhBJgaJpZM4RSdR1</denchmark-link>\n >\n .\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "marcoabreu", "commentT": "2018-01-12T07:20:20Z", "comment_text": "\n \t\tJust FYI, we updated MXNet to use MLKML v0.12 last night.\n \n Am 12.01.2018 7:55 vorm. schrieb \"mseeger\" <notifications@github.com>:\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n  Hello,\n \n  This test compares A and identity to what you get computing expressions\n  from U and Lambda.\n  Please output everything, A, U, Lambda, and results of expressions. Do this\n  directly in numpy format. Then compare to numpy. Use same style.\n  These errors are too large to be due to low prec.\n  Exactly what a test is for.\n \n  If you find something wrong either with syevd, or worse, with gemm2, please\n  isolate the case in non random test.\n \n \n  On Jan 11, 2018 14:44, \"Eric R Meissner\" ***@***.***> wrote:\n \n  Hmm, the plot thickens.\n \n  So on a c5.2xlarge instance I built mxnet from source using USE_MKL2017=1,\n  USE_MKL2017_EXPERIMENTAL=1, USE_BLAS=openblas flags this morning and ran\n  PYTHONPATH=./python/ nosetests3 --verbose tests/python/unittest\n \n  3 separate times test_operator.test_laop_3 FAILED apparently due to some\n  numerical issues. I haven't seen anyone mention this test failing yet, but\n  it didn't hang for me at all. It's the only test to return a FAILURE as\n  well.\n \n  Thoughts?\n  ======================================================================\n  FAIL: test_operator.test_laop_3\n \n  Traceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/nose/case.py\", line 198, in runTest\n  self.test(*self.arg)\n  File \"/home/ubuntu/src/incubator-mxnet/tests/python/unittest/\n  test_operator.py\",\n  line 4278, in test_laop_3\n  check_fw(test_syevd2, [data_in1], [res_eye, res_a])\n  File \"/home/ubuntu/src/incubator-mxnet/tests/python/unittest/\n  test_operator.py\",\n  line 4253, in\n  atol=atol_fw, dtype=dtype)\n  File \"/home/ubuntu/src/incubator-mxnet/python/mxnet/test_utils.py\", line\n  997, in check_symbolic_forward\n  equal_nan=equal_nan)\n  File \"/home/ubuntu/src/incubator-mxnet/python/mxnet/test_utils.py\", line\n  495, in assert_almost_equal\n  raise AssertionError(msg)\n  AssertionError:\n  Items are not equal:\n  Error 2142110.669088 exceeds tolerance rtol=0.000001, atol=0.000001.\n  Location of maximum error:(5, 7), a=3.772180, b=0.518782\n  EXPECTED_Ut_L_U_output: array([[ -6.29539959, 3.14786301, -7.76048236, ...,\n  -14.55426068,\n  5.89200304, 2.89609144],\n  [ 3.14786301, -2.20936719, -5.00206088, ..., 2.18995202,...\n  FORWARD_Ut_L_U_output: array([[ -5.86758909, 2.1861068 , -8.22037894, ...,\n  -15.72788167,\n  7.86870499, 2.89609144],\n  [ 2.1861068 , -3.11242836, -5.28864811, ..., 3.78613349,...\n  ------------------------------\n \n  \u2014\n  You are receiving this because you were mentioned.\n  Reply to this email directly, view it on GitHub\n  <#9295#\n  issuecomment-356937657>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/\n  AGNRomJq1Z8Zj7UzMcgka3TlUVjsijqKks5tJhBJgaJpZM4RSdR1>\n  .\n \n  \u2014\n  You are receiving this because you authored the thread.\n  Reply to this email directly, view it on GitHub\n  <#9295 (comment)>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/ARxB6wZxnozND1UhhRjSQp_7AEQVVnfzks5tJwHygaJpZM4RSdR1>\n  .\n \n \n \n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "marcoabreu", "commentT": "2018-01-12T15:21:42Z", "comment_text": "\n \t\tWith some help from Zhenwen in debugging the problem, I think we've figured out what the bug is that's causing this. Somewhere during syevd the signs of the eigenvectors are getting computed or flipped incorrectly.\n Haven't found where its introduced or how, but below is some simple example code to reproduce the issue. This was running the latest mxnet build as of this morning, with MKLML v0.12.\n import mxnet as mx\n import numpy as np\n \n np.random.seed(1896893920)\n n=10\n data_in1 = np.random.normal(0., 10., (n, n))\n data_in1 = 0.5 * (data_in1 + data_in1.T)\n \n np_eigval, np_eigvec = np.linalg.eig(data_in1)\n mx_eigvec, mx_eigval = mx.ndarray.linalg.syevd(mx.ndarray.array(data_in1, dtype=np.float64))\n \n np.allclose(np_eigval[idx], mx_eigval.asnumpy())\n #True, Eigenvalues are close to each other after sorting the unsorted numpy ones\n \n np.allclose(np_eigvec[idx], mx_eigvec.asnumpy())\n #False , but eigenvectors are not the same\n \n np_signs = np.sign(np_eigvec[:,idx].T)[:,0]\n mx_signs = np.sign(mx_eigvec.asnumpy())[:,0]\n \n sign_flips = np_signs * mx_signs\n print(sign_flips)\n #[ 1. -1.  1. -1. -1.  1. -1. -1.  1. -1.], I.E. numpy and mxnet signs not the same\n \n np.allclose(np_eigvec[:,idx].T * sign_flips[:,None], mx_eigvec.asnumpy())\n # If we flip the signs to match, now the eigenvectors are all the same.\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "marcoabreu", "commentT": "2018-01-12T21:03:57Z", "comment_text": "\n \t\tI noticed this issue with the signs as well, and I am in fact controlling\n the signs, see my code.\n \n The test however should be independent of signs of eigen vectors, it just\n depends on the definition of the decomposition, right?\n \n \n On Jan 12, 2018 4:22 PM, \"Eric R Meissner\" <notifications@github.com> wrote:\n \n With some help from Zhenwen in debugging the problem, I think we've figured\n out what the bug is that's causing this. Somewhere during syevd the signs\n of the eigenvectors are getting computed or flipped incorrectly.\n \n Haven't found where its introduced or how, but below is some simple example\n code to reproduce the issue. This was running the latest mxnet build as of\n this morning, with MKLML v0.12.\n \n import mxnet as mximport numpy as np\n \n np.random.seed(1896893920)\n n=10\n data_in1 = np.random.normal(0., 10., (n, n))\n data_in1 = 0.5 * (data_in1 + data_in1.T)\n \n np_eigval, np_eigvec = np.linalg.eig(data_in1)\n mx_eigvec, mx_eigval =\n mx.ndarray.linalg.syevd(mx.ndarray.array(data_in1, dtype=np.float64))\n \n np.allclose(np_eigval[idx], mx_eigval.asnumpy())#True, Eigenvalues are\n close to each other after sorting the unsorted numpy ones\n \n np.allclose(np_eigvec[idx], mx_eigvec.asnumpy())#False , but\n eigenvectors are not the same\n \n np_signs = np.sign(np_eigvec[:,idx].T)[:,0]\n mx_signs = np.sign(mx_eigvec.asnumpy())[:,0]\n \n sign_flips = np_signs * mx_signsprint(sign_flips)#[ 1. -1.  1. -1. -1.\n 1. -1. -1.  1. -1.], I.E. numpy and mxnet signs not the same\n \n np.allclose(np_eigvec[:,idx].T * sign_flips[:,None],\n mx_eigvec.asnumpy())# If we flip the signs to match, now the\n eigenvectors are all the same.\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <<denchmark-link:https://github.com/apache/incubator-mxnet/issues/9295#issuecomment-357266519>#9295 (comment)</denchmark-link>\n >,\n or mute the thread\n <<denchmark-link:https://github.com/notifications/unsubscribe-auth/AGNRog72dux8GZqdrJQp9YM6TIVxBQL_ks5tJ3i7gaJpZM4RSdR1>https://github.com/notifications/unsubscribe-auth/AGNRog72dux8GZqdrJQp9YM6TIVxBQL_ks5tJ3i7gaJpZM4RSdR1</denchmark-link>\n >\n .\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "marcoabreu", "commentT": "2018-01-12T21:04:57Z", "comment_text": "\n \t\tThe test does not compare eigen vectors. This cannot be the reason it fails.\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Jan 12, 2018 4:22 PM, \"Eric R Meissner\" ***@***.***> wrote:\n  With some help from Zhenwen in debugging the problem, I think we've\n  figured out what the bug is that's causing this. Somewhere during syevd the\n  signs of the eigenvectors are getting computed or flipped incorrectly.\n \n  Haven't found where its introduced or how, but below is some simple\n  example code to reproduce the issue. This was running the latest mxnet\n  build as of this morning, with MKLML v0.12.\n \n  import mxnet as mximport numpy as np\n \n  np.random.seed(1896893920)\n  n=10\n  data_in1 = np.random.normal(0., 10., (n, n))\n  data_in1 = 0.5 * (data_in1 + data_in1.T)\n \n  np_eigval, np_eigvec = np.linalg.eig(data_in1)\n  mx_eigvec, mx_eigval = mx.ndarray.linalg.syevd(mx.ndarray.array(data_in1, dtype=np.float64))\n \n  np.allclose(np_eigval[idx], mx_eigval.asnumpy())#True, Eigenvalues are close to each other after sorting the unsorted numpy ones\n \n  np.allclose(np_eigvec[idx], mx_eigvec.asnumpy())#False , but eigenvectors are not the same\n \n  np_signs = np.sign(np_eigvec[:,idx].T)[:,0]\n  mx_signs = np.sign(mx_eigvec.asnumpy())[:,0]\n \n  sign_flips = np_signs * mx_signsprint(sign_flips)#[ 1. -1.  1. -1. -1.  1. -1. -1.  1. -1.], I.E. numpy and mxnet signs not the same\n \n  np.allclose(np_eigvec[:,idx].T * sign_flips[:,None], mx_eigvec.asnumpy())# If we flip the signs to match, now the eigenvectors are all the same.\n \n  \u2014\n  You are receiving this because you were mentioned.\n  Reply to this email directly, view it on GitHub\n  <#9295 (comment)>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/AGNRog72dux8GZqdrJQp9YM6TIVxBQL_ks5tJ3i7gaJpZM4RSdR1>\n  .\n \n \n \n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "marcoabreu", "commentT": "2018-01-15T12:32:23Z", "comment_text": "\n \t\tWe\u2019ve been working on it this morning and have narrowed the issue down to a problem with syevd, only reproducible in the test environment.\n Running the following simplified code:\n def test_laop_TEST():\n     np.random.seed(1896893920)\n     n=10\n     data_in1 = np.random.normal(0., 10., (n, n))\n     data_in1 = 0.5 * (data_in1 + data_in1.T)\n     u, lam = mx.nd.linalg.syevd(mx.nd.array(data_in1, dtype=np.float64))\n     print(data_in1, u, lam)\n     assert(False)\n Inside the test environment (using \u201cPYTHONPATH=./python/ nosetests3 --verbose tests/python/unittest/test_operator.py:test_laop_TEST\u201d) returns the following results:\n A: [[-13.34414296  15.99829902  -5.9348693    0.33725903   7.08999108\n 3.48517748  -8.1782682    2.64821474 -11.71583022  -2.67093716]\n [ 15.99829902  -1.24079583  -5.15169143  -1.66193884   7.78811657\n -3.24022297   6.49511542  12.28121039   8.40569059  -2.6123374 ]\n [ -5.9348693   -5.15169143  18.40724804  -3.32434622  -8.2294941\n -12.05570085  -3.134901   -12.91228277  11.51627784  -3.26478123]\n [  0.33725903  -1.66193884  -3.32434622  13.99603538   5.64011818\n -5.48959896   4.85978757   4.35528089  -5.7480471  -11.40238071]\n [  7.08999108   7.78811657  -8.2294941    5.64011818  -5.28942777\n -3.71190675 -13.53220115   3.52255819   6.93703998   8.68193436]\n [  3.48517748  -3.24022297 -12.05570085  -5.48959896  -3.71190675\n -6.68378713   9.05448277   7.37555848   3.11379519   8.66276378]\n [ -8.1782682    6.49511542  -3.134901     4.85978757 -13.53220115\n 9.05448277  -1.94185915   0.70195063 -10.21748333   4.8669592 ]\n [  2.64821474  12.28121039 -12.91228277   4.35528089   3.52255819\n 7.37555848   0.70195063 -20.63472654   7.87549062   1.3931764 ]\n [-11.71583022   8.40569059  11.51627784  -5.7480471    6.93703998\n 3.11379519 -10.21748333   7.87549062   3.42171743   4.7941094 ]\n [ -2.67093716  -2.6123374   -3.26478123 -11.40238071   8.68193436\n 8.66276378   4.8669592    1.3931764    4.7941094   -5.61335189]]\n U: [[-0.40939395 -0.02004096  0.27457066 -0.25153737  0.66140858  0.28340247\n 0.14125274  0.22853749  0.18226673 -0.26486544]\n [ 0.4472236  -0.48209223  0.10682268 -0.08815147  0.06254703 -0.36772867\n 0.30321108  0.56092533  0.04835745 -0.01863414]\n [-0.39439743  0.09942506 -0.01934432 -0.06989485 -0.3580831   0.07148518\n -0.39629101  0.70887307 -0.11974635  0.14861161]\n [ 0.47108087 -0.15032447  0.34594981  0.19559081 -0.07895447  0.72793988\n -0.23360136  0.07264473 -0.01704545 -0.03578629]\n [-0.07231265  0.06808902  0.2476193   0.26860241  0.20379301 -0.02531744\n 0.10901297  0.01760572  0.27485097  0.85250383]\n [-0.16324278 -0.30664205 -0.10891006  0.40596886 -0.10056171 -0.10892519\n -0.28055657 -0.02900726  0.72918847 -0.26344591]\n [ 0.12151877  0.6399878   0.30715681  0.04750568 -0.33368478 -0.02954461\n 0.40925563  0.16125632  0.34502726 -0.23300369]\n [-0.34626999 -0.24576316 -0.15655482  0.51831127 -0.17288398  0.26124855\n 0.58672901  0.07084532 -0.27323606 -0.06688774]\n [ 0.24814453  0.40352612 -0.33373039  0.52155155  0.48083476 -0.10008073\n -0.17301593  0.27878979 -0.1649485  -0.12694282]\n [-0.16370208 -0.05674461  0.6998121   0.32548404  0.00940855 -0.39724873\n -0.21029293 -0.12432748 -0.34877216 -0.18731605]]\n <NDArray 10x10 <denchmark-link:https://github.com/cpu>@cpu</denchmark-link>\n (0)>\n Lambda: [-55.42942652 -36.08229736 -21.43322708 -13.37817004  -6.12139065\n 4.87496436   6.50358305  15.6977825   29.92340939  56.52168194]\n <NDArray 10 <denchmark-link:https://github.com/cpu>@cpu</denchmark-link>\n (0)>\n Whereas running the exact same code in an ipython notebook returns the following:\n A: [[-13.34414296  15.99829902  -5.9348693    0.33725903   7.08999108\n 3.48517748  -8.1782682    2.64821474 -11.71583022  -2.67093716]\n [ 15.99829902  -1.24079583  -5.15169143  -1.66193884   7.78811657\n -3.24022297   6.49511542  12.28121039   8.40569059  -2.6123374 ]\n [ -5.9348693   -5.15169143  18.40724804  -3.32434622  -8.2294941\n -12.05570085  -3.134901   -12.91228277  11.51627784  -3.26478123]\n [  0.33725903  -1.66193884  -3.32434622  13.99603538   5.64011818\n -5.48959896   4.85978757   4.35528089  -5.7480471  -11.40238071]\n [  7.08999108   7.78811657  -8.2294941    5.64011818  -5.28942777\n -3.71190675 -13.53220115   3.52255819   6.93703998   8.68193436]\n [  3.48517748  -3.24022297 -12.05570085  -5.48959896  -3.71190675\n -6.68378713   9.05448277   7.37555848   3.11379519   8.66276378]\n [ -8.1782682    6.49511542  -3.134901     4.85978757 -13.53220115\n 9.05448277  -1.94185915   0.70195063 -10.21748333   4.8669592 ]\n [  2.64821474  12.28121039 -12.91228277   4.35528089   3.52255819\n 7.37555848   0.70195063 -20.63472654   7.87549062   1.3931764 ]\n [-11.71583022   8.40569059  11.51627784  -5.7480471    6.93703998\n 3.11379519 -10.21748333   7.87549062   3.42171743   4.7941094 ]\n [ -2.67093716  -2.6123374   -3.26478123 -11.40238071   8.68193436\n 8.66276378   4.8669592    1.3931764    4.7941094   -5.61335189]]\n U: [[ 0.56896406 -0.49508446 -0.05515309 -0.09274153  0.05952866 -0.30276783\n 0.41076905  0.18170427  0.34030827 -0.08221328]\n [-0.24222508 -0.14435087  0.26295741 -0.18396091  0.30094882  0.01134089\n 0.04484504  0.75461613 -0.35400702 -0.17327796]\n [-0.13275656 -0.00823993  0.00394372 -0.16026696  0.57617405  0.29618633\n 0.3182481  -0.42766506  0.05309422 -0.4999056 ]\n [ 0.4795233  -0.15113111  0.35068639  0.19762309 -0.06883189  0.72410954\n -0.22482745  0.06161804 -0.02440456 -0.03418712]\n [ 0.1443947   0.08427882  0.32210052  0.15902208  0.42793043 -0.1065733\n 0.30022962 -0.18552473 -0.29677106  0.6602256 ]\n [ 0.4100674   0.61100202  0.24203264 -0.36583436 -0.26012926 -0.14006751\n 0.21300133 -0.01063569 -0.25163655 -0.26460707]\n [-0.26364054  0.32696231  0.18616994  0.38349845 -0.17037144  0.19078566\n 0.53068931  0.2664058   0.47268578  0.01995924]\n [ 0.19833204  0.25956163  0.15391535  0.52816029  0.37924181 -0.39832189\n -0.39632359  0.06842959  0.15922644 -0.31789337]\n [ 0.06100089  0.28041907  0.00365086 -0.52407767  0.32170882  0.11788932\n -0.29540979  0.16579616  0.55700809  0.31712067]\n [-0.2616713  -0.27894058  0.76428004 -0.18169327 -0.20501889 -0.23708203\n -0.12629573 -0.27049638  0.21217396 -0.06485779]]\n <NDArray 10x10 <denchmark-link:https://github.com/cpu>@cpu</denchmark-link>\n (0)>\n Lambda: [-39.53770898 -31.85235173 -27.55026183 -13.38111156  -6.97443774\n 5.59771442   7.56903358  22.57472579  27.01218163  37.619126  ]\n <NDArray 10 <denchmark-link:https://github.com/cpu>@cpu</denchmark-link>\n (0)>\n In both cases, A is the same but U and Lambda are different.\n Thoughts?\n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "marcoabreu", "commentT": "2018-01-15T19:20:43Z", "comment_text": "\n \t\tBut the test you said fails, it recomputes a and identity from u and lambda.\n While u is not unique (signs), the results must fulfill the definition, so\n must get a and identity.\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Jan 15, 2018 1:33 PM, \"Eric R Meissner\" ***@***.***> wrote:\n  We\u2019ve been working on it this morning and have narrowed the issue down to\n  a problem with syevd, only reproducible in the test environment.\n \n  Running the following simplified code:\n \n  def test_laop_TEST():\n      np.random.seed(1896893920)\n      n=10\n      data_in1 = np.random.normal(0., 10., (n, n))\n      data_in1 = 0.5 * (data_in1 + data_in1.T)\n      u, lam = mx.nd.linalg.syevd(mx.nd.array(data_in1, dtype=np.float64))\n      print(data_in1, u, lam)\n      assert(False)\n \n  Inside the test environment (using \u201cPYTHONPATH=./python/ nosetests3\n  --verbose tests/python/unittest/test_operator.py:test_laop_TEST\u201d) returns\n  the following results:\n  A: [[-13.34414296 15.99829902 -5.9348693 0.33725903 7.08999108\n  <089%2099108>\n  3.48517748 -8.1782682 2.64821474 -11.71583022 -2.67093716]\n  [ 15.99829902 -1.24079583 -5.15169143 -1.66193884 7.78811657\n  -3.24022297 6.49511542 12.28121039 8.40569059 -2.6123374 ]\n  [ -5.9348693 -5.15169143 18.40724804 -3.32434622 -8.2294941\n  -12.05570085 -3.134901 -12.91228277 11.51627784 -3.26478123]\n  [ 0.33725903 <03372%205903> -1.66193884 -3.32434622 13.99603538 5.64011818\n  -5.48959896 4.85978757 4.35528089 -5.7480471 -11.40238071]\n  [ 7.08999108 7.78811657 -8.2294941 5.64011818 -5.28942777\n  -3.71190675 -13.53220115 3.52255819 6.93703998 8.68193436]\n  [ 3.48517748 -3.24022297 -12.05570085 -5.48959896 -3.71190675\n  -6.68378713 9.05448277 7.37555848 3.11379519 8.66276378]\n  [ -8.1782682 6.49511542 -3.134901 4.85978757 -13.53220115\n  9.05448277 -1.94185915 0.70195063 -10.21748333 4.8669592 ]\n  [ 2.64821474 12.28121039 -12.91228277 4.35528089 3.52255819\n  7.37555848 0.70195063 -20.63472654 7.87549062 1.3931764 ]\n  [-11.71583022 8.40569059 11.51627784 -5.7480471 6.93703998\n  3.11379519 -10.21748333 7.87549062 3.42171743 4.7941094 ]\n  [ -2.67093716 -2.6123374 -3.26478123 -11.40238071 8.68193436\n  8.66276378 4.8669592 1.3931764 4.7941094 -5.61335189]]\n  U: [[-0.40939395 -0.02004096 0.27457066 -0.25153737 0.66140858 0.28340247\n  0.14125274 0.22853749 0.18226673 -0.26486544 <02648%206544>]\n  [ 0.4472236 <04472%20236> -0.48209223 <04820%209223> 0.10682268\n  -0.08815147 0.06254703 -0.36772867\n  0.30321108 <030%20321108> 0.56092533 0.04835745 -0.01863414]\n  [-0.39439743 0.09942506 -0.01934432 -0.06989485 -0.3580831 0.07148518\n  <07148%20518>\n  -0.39629101 <03962%209101> 0.70887307 <07088%207307> -0.11974635\n  0.14861161]\n  [ 0.47108087 <0471%2008087> -0.15032447 0.34594981 <0345%2094981>\n  0.19559081 -0.07895447 0.72793988\n  -0.23360136 0.07264473 -0.01704545 -0.03578629 <035786%2029>]\n  [-0.07231265 0.06808902 0.2476193 0.26860241 0.20379301 -0.02531744\n  <02531%20744>\n  0.10901297 0.01760572 0.27485097 <02748%205097> 0.85250383]\n  [-0.16324278 -0.30664205 <030%20664205> -0.10891006 0.40596886\n  -0.10056171 -0.10892519\n  -0.28055657 <02805%205657> -0.02900726 0.72918847 -0.26344591]\n  [ 0.12151877 0.6399878 0.30715681 0.04750568 -0.33368478 -0.02954461\n  <02954%20461>\n  0.40925563 0.16125632 0.34502726 -0.23300369 <02330%200369>]\n  [-0.34626999 <03462%206999> -0.24576316 -0.15655482 0.51831127\n  -0.17288398 0.26124855\n  0.58672901 0.07084532 -0.27323606 -0.06688774 <06688%20774>]\n  [ 0.24814453 <02481%204453> 0.40352612 -0.33373039 0.52155155 0.48083476\n  -0.10008073\n  -0.17301593 0.27878979 <02787%208979> -0.1649485 -0.12694282]\n  [-0.16370208 -0.05674461 0.6998121 0.32548404 0.00940855 -0.39724873\n  -0.21029293 <02102%209293> -0.12432748 -0.34877216 -0.18731605]]\n  <NDArray 10x10 @cpu <https://github.com/cpu>(0)>\n  Lambda: [-55.42942652 -36.08229736 -21.43322708 -13.37817004 -6.12139065\n  4.87496436 6.50358305 15.6977825 29.92340939 56.52168194]\n  <NDArray 10 @cpu <https://github.com/cpu>(0)>\n \n  Whereas running the exact same code in an ipython notebook returns the\n  following:\n \n  A: [[-13.34414296 15.99829902 -5.9348693 0.33725903 7.08999108\n  <089%2099108>\n  3.48517748 -8.1782682 2.64821474 -11.71583022 -2.67093716]\n  [ 15.99829902 -1.24079583 -5.15169143 -1.66193884 7.78811657\n  -3.24022297 6.49511542 12.28121039 8.40569059 -2.6123374 ]\n  [ -5.9348693 -5.15169143 18.40724804 -3.32434622 -8.2294941\n  -12.05570085 -3.134901 -12.91228277 11.51627784 -3.26478123]\n  [ 0.33725903 <03372%205903> -1.66193884 -3.32434622 13.99603538 5.64011818\n  -5.48959896 4.85978757 4.35528089 -5.7480471 -11.40238071]\n  [ 7.08999108 7.78811657 -8.2294941 5.64011818 -5.28942777\n  -3.71190675 -13.53220115 3.52255819 6.93703998 8.68193436]\n  [ 3.48517748 -3.24022297 -12.05570085 -5.48959896 -3.71190675\n  -6.68378713 9.05448277 7.37555848 3.11379519 8.66276378]\n  [ -8.1782682 6.49511542 -3.134901 4.85978757 -13.53220115\n  9.05448277 -1.94185915 0.70195063 -10.21748333 4.8669592 ]\n  [ 2.64821474 12.28121039 -12.91228277 4.35528089 3.52255819\n  7.37555848 0.70195063 -20.63472654 7.87549062 1.3931764 ]\n  [-11.71583022 8.40569059 11.51627784 -5.7480471 6.93703998\n  3.11379519 -10.21748333 7.87549062 3.42171743 4.7941094 ]\n  [ -2.67093716 -2.6123374 -3.26478123 -11.40238071 8.68193436\n  8.66276378 4.8669592 1.3931764 4.7941094 -5.61335189]]\n  U: [[ 0.56896406 <05689%206406> -0.49508446 -0.05515309 -0.09274153\n  0.05952866 -0.30276783\n  0.41076905 0.18170427 0.34030827 -0.08221328 <08221%20328>]\n  [-0.24222508 <02422%202508> -0.14435087 0.26295741 -0.18396091 0.30094882\n  0.01134089\n  0.04484504 0.75461613 <07546%201613> -0.35400702 -0.17327796]\n  [-0.13275656 -0.00823993 0.00394372 -0.16026696 0.57617405 0.29618633\n  0.3182481 -0.42766506 <04276%206506> 0.05309422 -0.4999056 ]\n  [ 0.4795233 <04795%20233> -0.15113111 0.35068639 0.19762309 -0.06883189\n  0.72410954\n  -0.22482745 0.06161804 -0.02440456 -0.03418712 <0341%208712>]\n  [ 0.1443947 0.08427882 0.32210052 0.15902208 0.42793043 -0.1065733\n  0.30022962 <030%20022962> -0.18552473 -0.29677106 0.6602256 ]\n  [ 0.4100674 <04100%20674> 0.61100202 0.24203264 -0.36583436 -0.26012926\n  -0.14006751\n  0.21300133 <02130%200133> -0.01063569 -0.25163655 -0.26460707]\n  [-0.26364054 <02636%204054> 0.32696231 0.18616994 0.38349845 -0.17037144\n  0.19078566\n  0.53068931 <05306%208931> 0.2664058 0.47268578 0.01995924]\n  [ 0.19833204 0.25956163 0.15391535 0.52816029 0.37924181 -0.39832189\n  <039832%20189>\n  -0.39632359 <03963%202359> 0.06842959 0.15922644 -0.31789337]\n  [ 0.06100089 0.28041907 0.00365086 -0.52407767 0.32170882 0.11788932\n  -0.29540979 <02954%200979> 0.16579616 0.55700809 0.31712067]\n  [-0.2616713 <0261%206713> -0.27894058 0.76428004 -0.18169327 -0.20501889\n  -0.23708203\n  -0.12629573 -0.27049638 0.21217396 -0.06485779 <06485%20779>]]\n  <NDArray 10x10 @cpu <https://github.com/cpu>(0)>\n  Lambda: [-39.53770898 -31.85235173 -27.55026183 -13.38111156 -6.97443774\n  5.59771442 7.56903358 22.57472579 27.01218163 37.619126 ]\n  <NDArray 10 @cpu <https://github.com/cpu>(0)>\n \n  In both cases, A is the same but U and Lambda are different.\n \n  Thoughts?\n \n  \u2014\n  You are receiving this because you were mentioned.\n  Reply to this email directly, view it on GitHub\n  <#9295 (comment)>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/AGNRovx0Jo7MFglaG289w3N-ClcjBdGSks5tK0WKgaJpZM4RSdR1>\n  .\n \n \n \n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "marcoabreu", "commentT": "2018-01-18T18:07:55Z", "comment_text": "\n \t\tOk new update to this story.\n I synced to the latest changes from master branch for each of them, and now I can't reproduce the bug at all. I then ran the build in 3 configurations:\n \n one with no MKL installed/configured (my mac)\n one with MKL2017+MKL2017_EXPERIMENTAL+USE_BLAS=openblas (ec2 host on DL AMI)\n one with MKL2017, MKL2017_EXPERIMENTAL, USE_BLAS=mkl and full MKL (ec2 host on DL AMI)\n \n Previously, we were seeing the bug in the second configuration. I haven't gone back to check if the bug is still reproducible at an earlier commit, but if it's fixed now it may or may not be worth figuring out what the issue was. What do you all think?\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "marcoabreu", "commentT": "2018-01-18T18:21:14Z", "comment_text": "\n \t\tAre we sure the test hangs due to the issue you saw?\n Well can watch for a while, see whether issues that Marco raised, are still\n present\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Jan 18, 2018 7:08 PM, \"Eric R Meissner\" ***@***.***> wrote:\n  Ok new update to this story.\n \n  I synced to the latest changes from master branch for each of them, and\n  now I can't reproduce the bug at all. I then ran the build in 3\n  configurations:\n \n     1. one with no MKL installed/configured (my mac)\n     2. one with MKL2017+MKL2017_EXPERIMENTAL+USE_BLAS=openblas (ec2 host\n     on DL AMI)\n     3. one with MKL2017, MKL2017_EXPERIMENTAL, USE_BLAS=mkl and full MKL\n     (ec2 host on DL AMI)\n \n  Previously, we were seeing the bug in the second configuration. I haven't\n  gone back to check if the bug is still reproducible at an earlier commit,\n  but if it's fixed now it may or may not be worth figuring out what the\n  issue was. What do you all think?\n \n  \u2014\n  You are receiving this because you were mentioned.\n  Reply to this email directly, view it on GitHub\n  <#9295 (comment)>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/AGNRomzwkNJ90J1rqqd4_ljw413mcyeIks5tL4iggaJpZM4RSdR1>\n  .\n \n \n \n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "marcoabreu", "commentT": "2018-01-18T18:59:42Z", "comment_text": "\n \t\tMKLML is a dependency of the MKL2017 option and was updated recently in <denchmark-link:https://github.com/apache/incubator-mxnet/pull/9218>#9218</denchmark-link>\n . Might be related. It would be easy to verify if you revert to the point before that PR.\n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "marcoabreu", "commentT": "2018-01-22T13:50:09Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/mseeger>@mseeger</denchmark-link>\n  No, I don't know for sure this issue caused the hanging tests as I never saw one hang. Both issues being in laop3 felt too specific for coincidence so I assumed they were the same underlying problem.\n <denchmark-link:https://github.com/szha>@szha</denchmark-link>\n  Could be. Since the issue seems to be resolved now, it would just be testing that it wasn't broken at that point.\n Anyone know if we're still seeing the hanging issue in CI builds?\n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "marcoabreu", "commentT": "2018-01-22T19:54:16Z", "comment_text": "\n \t\tIf all works fine now, we should close this issue. We have checked everything again, it should work as is, it does work as is, tests are in that ensure that we will notice if this ever happens again.\n Marco, ok with this?\n \t\t"}, "comments_23": {"comment_id": 24, "comment_author": "marcoabreu", "commentT": "2018-01-22T20:01:36Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/meissnereric>@meissnereric</denchmark-link>\n  <denchmark-link:https://github.com/asmushetzel>@asmushetzel</denchmark-link>\n , though not high priority, it would still be good if we rule out whether it's a bug in mxnet or not. This is why I suggested reverting to a version prior to PR9218, so that we know for sure.\n \t\t"}, "comments_24": {"comment_id": 25, "comment_author": "marcoabreu", "commentT": "2018-01-23T05:53:31Z", "comment_text": "\n \t\tSorry for the late response. I didn't see any hangs since the upgrade, but\n it would be good if we could figure out whether that specific version was\n the issue.\n \n Am 22.01.2018 9:02 nachm. schrieb \"Sheng Zha\" <notifications@github.com>:\n \n <denchmark-link:https://github.com/meissnereric>@meissnereric</denchmark-link>\n  <<denchmark-link:https://github.com/meissnereric>https://github.com/meissnereric</denchmark-link>\n > <denchmark-link:https://github.com/asmushetzel>@asmushetzel</denchmark-link>\n \n <<denchmark-link:https://github.com/asmushetzel>https://github.com/asmushetzel</denchmark-link>\n >, though not high priority, it would still\n be good if we rule out whether it's a bug in mxnet or not. This is why I\n suggested reverting to a version prior to PR9218, so that we know for sure.\n \n \u2014\n You are receiving this because you authored the thread.\n Reply to this email directly, view it on GitHub\n <<denchmark-link:https://github.com/apache/incubator-mxnet/issues/9295#issuecomment-359547025>#9295 (comment)</denchmark-link>\n >,\n or mute the thread\n <<denchmark-link:https://github.com/notifications/unsubscribe-auth/ARxB62jrelHBKmBEi071pTiCLkbyDDDkks5tNOk6gaJpZM4RSdR1>https://github.com/notifications/unsubscribe-auth/ARxB62jrelHBKmBEi071pTiCLkbyDDDkks5tNOk6gaJpZM4RSdR1</denchmark-link>\n >\n .\n \t\t"}, "comments_25": {"comment_id": 26, "comment_author": "marcoabreu", "commentT": "2018-03-09T17:14:19Z", "comment_text": "\n \t\tClosed due to MKLDNN replacement\n \t\t"}}}, "commit": {"commit_id": "3eae3bbb7a2b0a4314f732288df8f47cde7f00a6", "commit_author": "Marco de Abreu", "commitT": "2018-01-11 15:43:02-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "prepare_mkl.sh", "file_new_name": "prepare_mkl.sh", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "87", "deleted_lines": "87"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\ci_build\\Dockerfile.build_cuda", "file_new_name": "tests\\ci_build\\Dockerfile.build_cuda", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "23", "deleted_lines": "23"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\ci_build\\Dockerfile.cpu_mklml", "file_new_name": "tests\\ci_build\\Dockerfile.cpu_mklml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15", "deleted_lines": "15"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\ci_build\\Dockerfile.gpu_mklml", "file_new_name": "tests\\ci_build\\Dockerfile.gpu_mklml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15", "deleted_lines": "15"}}}}}}