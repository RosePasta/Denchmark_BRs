{"BR": {"BR_id": "1829", "BR_author": "StellaASchlotter", "BRopenT": "2020-07-01T12:41:00Z", "BRcloseT": "2020-07-23T19:10:06Z", "BR_text": {"BRsummary": "TFRecord file is missing the sha256 feature", "BRdescription": "\n <denchmark-h:h3>My actions before raising this issue</denchmark-h>\n \n \n  Read/searched the docs\n  Searched past issues\n \n I want to export a dataset as tfrecords format und use that to train a model with the TF Object Detection API. I encountered problems doing so because the exported records file does not contain a sha256 key.\n <denchmark-h:h3>Expected Behaviour</denchmark-h>\n \n I expected that the examples in the tfrecords file contain a feature like that:\n <denchmark-code>feature {\n     key: \"image/key/sha256\"\n     value {\n       bytes_list {\n         value: \"20bc63f9dc7604c9bb6d157669957325cf5c7d026c2222534a14d42f5fae1c6e\"\n       }\n     }\n   }\n </denchmark-code>\n \n <denchmark-h:h3>Current Behaviour</denchmark-h>\n \n Currently the key is missing resulting in the following error when starting training with the TF Object Detection API\n <denchmark-code>ValueError: in converted code:\n     relative to /home/benji/ObjectDetectionAPI/venv/lib/python3.6/site-packages/tensorflow_core/python:\n \n     data/ops/readers.py:336 __init__\n         filenames, compression_type, buffer_size, num_parallel_reads)\n     data/ops/readers.py:296 __init__\n         filenames = _create_or_validate_filenames_dataset(filenames)\n     data/ops/readers.py:56 _create_or_validate_filenames_dataset\n         filenames = ops.convert_to_tensor(filenames, dtype=dtypes.string)\n     framework/ops.py:1184 convert_to_tensor\n         return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n     framework/ops.py:1242 convert_to_tensor_v2\n         as_ref=False)\n     framework/ops.py:1273 internal_convert_to_tensor\n         (dtype.name, value.dtype.name, value))\n \n     ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor 'args_0:0' shape=() dtype=float32>\n </denchmark-code>\n \n I verified that this bug does not happen when I manually create the tfrecord file with the tools provided by the TF Object Detection API. The manually created tfrecords file only differs in the sha256  key.\n <denchmark-h:h3>Steps to Reproduce (for bugs)</denchmark-h>\n \n \n setup tf object detection api with branch r1.13.0. The recent branches don't support training yet\n setup training. I followed the guide at https://gilberttanner.com/blog/creating-your-own-objectdetector. Except for creating the tfrecords files.\n export a dataset as tfrecords\n start training\n \n <denchmark-h:h3>Your Environment</denchmark-h>\n \n \n Git hash commit (git log -1): d293876\n Docker version: 19.03.12, build 48a66213fe\n Are you using Docker Swarm or Kubernetes? no\n Operating System and version: Ubuntu 18.04\n \n \t"}, "comments": {}}, "commit": {"commit_id": "a3448a20ade0306c10b9d76c036b92f865161413", "commit_author": "zhiltsov-max", "commitT": "2020-07-23 22:10:05+03:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "datumaro\\datumaro\\plugins\\tf_detection_api_format\\converter.py", "file_new_name": "datumaro\\datumaro\\plugins\\tf_detection_api_format\\converter.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "184,185,190,195", "deleted_lines": "183", "method_info": {"method_name": "_make_tf_example", "method_params": "self,item", "method_startline": "162", "method_endline": "207"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "datumaro\\datumaro\\plugins\\tf_detection_api_format\\extractor.py", "file_new_name": "datumaro\\datumaro\\plugins\\tf_detection_api_format\\extractor.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "88,89,90,91", "deleted_lines": null, "method_info": {"method_name": "_parse_tfrecord_file", "method_params": "cls,filepath,subset,images_dir", "method_startline": "79", "method_endline": "195"}}}}}}}