{"BR": {"BR_id": "1332", "BR_author": "fsudrew07", "BRopenT": "2019-04-30T14:12:32Z", "BRcloseT": "2019-05-02T16:15:53Z", "BR_text": {"BRsummary": "Serving Predict Response Greater than 6 digits of precision gets rounded", "BRdescription": "\n <denchmark-h:hr></denchmark-h>\n \n <denchmark-h:h2>Bug Report</denchmark-h>\n \n If this is a bug report, please fill out the following form in full:\n <denchmark-h:h3>System information</denchmark-h>\n \n \n Using the latest Docker Hub version of tensorflow/serving 1.13.0 (this issue is also reproducible on nightly, 1.11.1, 1.10.1, 1.9.1 versions as well)\n \n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n Values in the predictions response appear to be rounded to 6 significant digits.\n When I run the example in the README for the tensorflow/serving GitHub repo for the \"half_plust_two\" model and change one of the input features to \"1111111.0\" I would expect to get back \"555557.5\" however what I get back is \"555558.0\".\n <denchmark-h:h3>Exact Steps to Reproduce</denchmark-h>\n \n `docker pull tensorflow/serving\n git clone <denchmark-link:https://github.com/tensorflow/serving>https://github.com/tensorflow/serving</denchmark-link>\n \n TESTDATA=\"$(pwd)/serving/tensorflow_serving/servables/tensorflow/testdata\"\n docker run -t --rm -p 8501:8501 \\\n -v \"$TESTDATA/saved_model_half_plus_two_cpu:/models/half_plus_two\" \\\n -e MODEL_NAME=half_plus_two \\\n tensorflow/serving &\n curl -d '{\"instances\": [1111111.0]}' -X POST <denchmark-link:http://localhost:8501/v1/models/half_plus_two:predict%60>http://localhost:8501/v1/models/half_plus_two:predict`</denchmark-link>\n \n I found this issue while running a different model of my own. While debugging this problem I am able to call the model and get the expected return to > 6 significant digits using the saved model CLI.\n This doesn't seem like expected behavior but if it is, could someone please let me know?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "fsudrew07", "commentT": "2019-04-30T18:22:59Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/fsudrew07>@fsudrew07</denchmark-link>\n  If you look at the output <denchmark-link:https://github.com/tensorflow/serving/blob/2f42c693b22c946bf38a4a5934e95a335379caac/tensorflow_serving/batching/test_util/matrix_half_plus_two_saved_model.py#L31>variable</denchmark-link>\n , its of type float32 i.e., if you're using the binary32 form which is commonly selected by C++ compilers for the float type, it holds just over 7 digits. Hence, the digits are limited to 7.Hope this helps!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "fsudrew07", "commentT": "2019-04-30T19:14:35Z", "comment_text": "\n \t\t@gowtham-kp Your answer is confusing. Are you suggesting that single-precision floats only have 7 digits of precision? I don't think that's accurate (e.g. <denchmark-link:https://en.wikipedia.org/wiki/Single-precision_floating-point_format>https://en.wikipedia.org/wiki/Single-precision_floating-point_format</denchmark-link>\n ). Regardless, the OP is saying that tensorflow/serving HTTP REST endpoints do not return the same results as if the model were called via the saved model cli. This seems like an error of some kind. Additionally, that example does not preserve 7 digits of precision, only 6.\n Here's what we might expect based on the float32 type:\n <denchmark-code>>>> import tensorflow as tf\n >>> tf.enable_eager_execution()\n >>> tf.constant(12345678, dtype=tf.float32).numpy()\n >>> 12345678.0  # preserves 8 digits of precision\n >>> tf.constant(123456789, dtype=tf.float32).numpy()\n >>> 123456790.0  # preserves 8 digits of precision\n >>> tf.constant(123456789, dtype=tf.float64).numpy()\n >>> 123456789.0\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "fsudrew07", "commentT": "2019-05-01T17:24:25Z", "comment_text": "\n \t\tthanks for reporting!\n yes this is a bug (and i suspect this has to do the way floating point numbers are printed (converted to string) in our json library, when composing the response. Many float->string routines format with 6 digits precision (%g format specifier in printf).\n \t\t"}}}, "commit": {"commit_id": "d7c3b3deacbabf763ed44fb6932535016852e90a", "commit_author": "Abhijit Karmarkar", "commitT": "2019-05-02 09:15:31-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow_serving\\util\\BUILD", "file_new_name": "tensorflow_serving\\util\\BUILD", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "351", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tensorflow_serving\\util\\json_tensor.cc", "file_new_name": "tensorflow_serving\\util\\json_tensor.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "130,131,132,133,134,135,136,137,138,139,140", "deleted_lines": null, "method_info": {"method_name": "tensorflow::serving::WriteDecimal", "method_params": "writer,val", "method_startline": "115", "method_endline": "160"}}, "hunk_1": {"Ismethod": 1, "added_lines": "105,106,107", "deleted_lines": null, "method_info": {"method_name": "tensorflow::serving::StringToDecimal", "method_params": "s,out", "method_startline": "105", "method_endline": "107"}}, "hunk_2": {"Ismethod": 1, "added_lines": "110,111,112", "deleted_lines": null, "method_info": {"method_name": "tensorflow::serving::StringToDecimal", "method_params": "s,out", "method_startline": "110", "method_endline": "112"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_serving\\util\\json_tensor_test.cc", "file_new_name": "tensorflow_serving\\util\\json_tensor_test.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "797,801,804,813,814", "deleted_lines": "797,811,812", "method_info": {"method_name": "tensorflow::serving::TEST", "method_params": "JsontensorTest,FromJsonSingleFloatTensorSixDigitPrecision", "method_startline": "791", "method_endline": "816"}}}}}}}