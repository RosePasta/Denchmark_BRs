{"BR": {"BR_id": "453", "BR_author": "Weilin37", "BRopenT": "2020-09-30T18:23:01Z", "BRcloseT": "2020-10-01T14:25:59Z", "BR_text": {"BRsummary": "Indexing of files is not currently supported", "BRdescription": "\n Describe the bug\n I am trying to follow the tutorial notebook for DPR and replace the GOT text files with my own text files. My text files is just a simple batch of 2k text files comprising of a title and abstract (paragraph or two long) separate by a newline.\n Error message\n in this section of the code:\n <denchmark-code># Convert files to dicts\n dicts = convert_files_to_dicts(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n </denchmark-code>\n \n I get an error message: Indexing of files is not currently supported:\n <denchmark-code>---------------------------------------------------------------------------\n Exception                                 Traceback (most recent call last)\n <ipython-input-3-fd0550140fb8> in <module>\n       5 \n       6 # Convert files to dicts\n ----> 7 dicts = convert_files_to_dicts(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n       8 \n       9 # Now, let's write the dicts containing documents to our DB.\n \n ~/Library/Python/3.8/lib/python/site-packages/haystack/preprocessor/utils.py in convert_files_to_dicts(dir_path, clean_func, split_paragraphs)\n     101             text = document[\"text\"]\n     102         else:\n --> 103             raise Exception(f\"Indexing of {path.suffix} files is not currently supported.\")\n     104 \n     105         if clean_func:\n \n Exception: Indexing of  files is not currently supported.\n </denchmark-code>\n \n Expected behavior\n I was expecting the code to simply convert the files to dicts in the same way it does for the GoT text\n \n <denchmark-link:https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial6_Better_Retrieval_via_DPR.ipynb>https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial6_Better_Retrieval_via_DPR.ipynb</denchmark-link>\n \n System:\n \n OS: MacOS\n GPU/CPU: CPU\n Haystack version (commit or version number): Latest pip install as of  today\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Weilin37", "commentT": "2020-09-30T23:38:51Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Weilin37>@Weilin37</denchmark-link>\n  You need to add  suffix with your file name. Currently files with  and  suffix are supported.\n But I think this should be properly documented.\n Ideally file type identification by checking file header should be used, but it require special  lib to be installed along with <denchmark-link:https://github.com/ahupp/python-magic>python-magic</denchmark-link>\n  lib.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Weilin37", "commentT": "2020-10-01T03:10:00Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n ,\n I checked my directory and indeed the \".txt\" suffix is present.\n Here is one of the file names: PMC7462872.txt\n Which contains the following title and abstract text from public scientific literature:\n <denchmark-code>Exacerbation of chronic inflammatory demyelinating polyneuropathy in concomitance with COVID-19\n \n \u2022 A worsening of CIDP may occur in concomitance with COVID-19. \u2022 Cytokine hyperactivation triggered by SARS-CoV-2 might be a possible mechanism. \u2022 The management of these patients is particularly challenging.\n </denchmark-code>\n \n I checked the other files which were auto generated in the same format and they all have \".txt\" suffix as well. I just tried only putting in one of the \"txt\" files to test if one file would work but it gave me the same error.\n Could it be possibly due to something that's inside the file?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Weilin37", "commentT": "2020-10-01T08:34:01Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Weilin37>@Weilin37</denchmark-link>\n  I am able to reproduce this issue, it happen when OS create few internal files with extension(s) not supported by converter.\n <denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n  <denchmark-link:https://github.com/tanaysoni>@tanaysoni</denchmark-link>\n   It would be better to skip not supported files, instead of throwing exception. I can create PR if this approach is okay for you?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Weilin37", "commentT": "2020-10-01T08:47:05Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n  A PR would be great. Thx!\n How about we skip unsupported files and log a warning ?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Weilin37", "commentT": "2020-10-01T13:11:40Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n \n Thanks! Just to be thorough - I generated the txt files in python and then manually moved them to a new folder. So I'm not entirely sure any hidden files are there but we'll have to see!\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Weilin37", "commentT": "2020-10-01T13:13:48Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Weilin37>@Weilin37</denchmark-link>\n  can you please try latest changes now. See if fix which merged for this is working in your case or you are getting some other issue.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Weilin37", "commentT": "2020-10-01T13:31:59Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n \n it works!\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "Weilin37", "commentT": "2020-10-01T14:25:59Z", "comment_text": "\n \t\tAwesome! Great to see the community helping each other :)\n Closing this as it's fixed by <denchmark-link:https://github.com/deepset-ai/haystack/pull/456>#456</denchmark-link>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "Weilin37", "commentT": "2020-11-05T14:43:11Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n  with 0.4.9 this problem appears again.\n When I upgrade from master (0.5.0), I get a different issues with the following code:\n <denchmark-code>from haystack.retriever.dense import DensePassageRetriever\n retriever = DensePassageRetriever(document_store=document_store,\n                                   query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n                                   passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n                                   use_gpu=True,\n                                   embed_title=True,\n                                   max_seq_len=256,\n                                   batch_size=16,\n                                   remove_sep_tok_from_untitled_passages=True)\n # Important: \n # Now that after we have the DPR initialized, we need to call update_embeddings() to iterate over all\n # previously indexed documents and update their embedding representation. \n # While this can be a time consuming operation (depending on corpus size), it only needs to be done once. \n # At query time, we only need to embed the query and compare it the existing doc embeddings which is very fast.\n document_store.update_embeddings(retriever)\n </denchmark-code>\n \n <denchmark-code>---------------------------------------------------------------------------\n TypeError                                 Traceback (most recent call last)\n <ipython-input-3-f8eb00f5564a> in <module>\n       1 from haystack.retriever.dense import DensePassageRetriever\n ----> 2 retriever = DensePassageRetriever(document_store=document_store,\n       3                                   query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n       4                                   passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n       5                                   use_gpu=True,\n \n TypeError: __init__() got an unexpected keyword argument 'max_seq_len'\n </denchmark-code>\n \n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "Weilin37", "commentT": "2020-11-05T16:11:51Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Weilin37>@Weilin37</denchmark-link>\n  DPR issue on 0.5.0 is because of changes in <denchmark-link:https://github.com/deepset-ai/haystack/pull/527>#527</denchmark-link>\n \n Can you please replace  with  in you script.\n Regarding your original issue I am not sure why you getting that as haystack already have <denchmark-link:https://github.com/deepset-ai/haystack/blob/master/test/test_utils.py>test</denchmark-link>\n  to catch it. Can you please try above suggested change on 0.5.0 and then share stacktrace or error.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "Weilin37", "commentT": "2020-11-05T16:17:18Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Weilin37>@Weilin37</denchmark-link>\n  I guess with 0.5.0 you refer to the FARM version? Please always make sure that your Haystack and FARM version are compatible. For example, with the latest Haystack, we expect FARM 0.5.0 (as specified in requirements.txt).\n As <denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n  already mentioned, the signature of DPR has changed in <denchmark-link:https://github.com/deepset-ai/haystack/pull/527>#527</denchmark-link>\n . You can also see an updated example reflecting the changes in our Tutorial 6\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "Weilin37", "commentT": "2020-11-05T17:56:09Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n   thanks the changing from max_seq_len to max_seq_len_passage worked!\n \t\t"}}}, "commit": {"commit_id": "9b58374b7cfaf31fadd79c6c78ea1214e994ac36", "commit_author": "Lalit Pagaria", "commitT": "2020-10-01 14:47:45+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "haystack\\preprocessor\\utils.py", "file_new_name": "haystack\\preprocessor\\utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "79,80,82,93,94,96,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,123,124,126,127,128,129,130,131,132", "deleted_lines": "89,90,91,92,94,96,97,98,99,100,102,103,105,106,108,109,110,111,112,113,114", "method_info": {"method_name": "convert_files_to_dicts", "method_params": "str,None,bool", "method_startline": "79", "method_endline": "134"}}, "hunk_1": {"Ismethod": 1, "added_lines": "62", "deleted_lines": "59,76", "method_info": {"method_name": "eval_data_from_file", "method_params": "str", "method_startline": "22", "method_endline": "76"}}, "hunk_2": {"Ismethod": 1, "added_lines": "256,257,258", "deleted_lines": "227", "method_info": {"method_name": "fetch_archive_from_http", "method_params": "str,str,None", "method_startline": "218", "method_endline": "260"}}}}, "file_1": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\test_utils.py"}}}}