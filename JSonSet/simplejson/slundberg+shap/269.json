{"BR": {"BR_id": "269", "BR_author": "skamkar", "BRopenT": "2018-09-23T16:38:37Z", "BRcloseT": "2018-10-02T17:33:32Z", "BR_text": {"BRsummary": "Linearexplainer interventional option", "BRdescription": "\n For the interventional option, from your docstring, \"assuming features are independent leads to interventional SHAP values which for a linear model are coef[i] * (x[i] - X.mean(0)[i]) for the ith feature\". I understand this to mean that regardless of any colinearity within the data, the feature importance computed will be a relative difference of the feature (relative to feature mean), scaled by the coefficient. Makes total sense.\n Now, here's a test case (adapted from your unit test) that offers a confounding result.\n <denchmark-code>np.random.seed(0)\n beta = np.array([1, 0, 0])\n mu = np.zeros(3)\n Sigma = np.array([[1, 1, 0],\n                   [1, 1, 0],\n                   [0, 0, 1]])\n \n X = np.ones((1,3))\n explainer = shap.LinearExplainer((beta, 0), (mu, Sigma), feature_dependence='interventional')\n explainer.shap_values(X)\n </denchmark-code>\n \n Which returns a result of array([[0.5, 0.5, 0. ]]). Since the first and second inputs are perfectly correlated, but the linear model only uses the first input, I'd expect a result of array([[1.0, 0., 0.]]). Any insight would be helpful. (I see that it's due to L81 - L85 of linear.py, but don't understand why this is necessary.)\n And, by the way, shap is a phenomenal repo; keep up the great work.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "skamkar", "commentT": "2018-10-02T17:28:30Z", "comment_text": "\n \t\tThanks for pointing this out! This is indeed a bug. The reason perfectly redundant variables are grouped together is to avoid singularity problems later on. But for \"interventional\" we don't need to invert the correlation matrix so this doesn't matter. This grouping should not be done when doing the interventional version.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "skamkar", "commentT": "2018-10-02T21:38:18Z", "comment_text": "\n \t\tExcellent. Thanks much!\n \t\t"}}}, "commit": {"commit_id": "e9c750a45fc027227c87dbfbe34ccc6143632aa1", "commit_author": "Scott Lundberg", "commitT": "2018-10-02 10:33:23-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "shap\\explainers\\linear.py", "file_new_name": "shap\\explainers\\linear.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "83,84,85,86,87,88,89,90,91,92,93,94", "deleted_lines": "81,82,83,84,85,86,87,88,89,90,91", "method_info": {"method_name": "__init__", "method_params": "self,model,data,nsamples,feature_dependence", "method_startline": "38", "method_endline": "102"}}, "hunk_1": {"Ismethod": 1, "added_lines": "195,197", "deleted_lines": "195,197", "method_info": {"method_name": "shap_values", "method_params": "self,X", "method_startline": "168", "method_endline": "201"}}}}}}}