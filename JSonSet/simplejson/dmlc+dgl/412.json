{"BR": {"BR_id": "412", "BR_author": "mufeili", "BRopenT": "2019-02-25T19:54:49Z", "BRcloseT": "2019-02-26T06:24:48Z", "BR_text": {"BRsummary": "Fixing random seeds does not yield deterministic results", "BRdescription": "\n \n Related discussion thread\n \n It has been observed by Erutan-pku, <denchmark-link:https://github.com/hbsun2113>@hbsun2113</denchmark-link>\n  , me and <denchmark-link:https://github.com/yzh119>@yzh119</denchmark-link>\n  that after fixing NumPy random seed, PyTorch random seed and  we still get different results across runs. There can be two possibilities:\n \n This is a bug.\n Some system optimization involves randomness, in which case we should provide APIs for users to fix results.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "mufeili", "commentT": "2019-02-25T22:46:37Z", "comment_text": "\n \t\tIn the case of SGC, the function python/dgl/data/citation_graph.py:_encode_onehot does not necessarily return the same output from the same input, since it is enumerating a set.\n Changing from classes = set(labels) to classes = list(sorted(set(labels))) solves the problem.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "mufeili", "commentT": "2019-02-26T01:41:35Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/BarclayII>@BarclayII</denchmark-link>\n  In that case we may want to add an option for our API to decide if a deterministic split is to be employed. Could you also please check GraphSAGE as mentioned by <denchmark-link:https://github.com/hbsun2113>@hbsun2113</denchmark-link>\n  ?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "mufeili", "commentT": "2019-02-26T03:09:13Z", "comment_text": "\n \t\tWorks for me.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "mufeili", "commentT": "2019-02-26T03:09:56Z", "comment_text": "\n \t\t\n @BarclayII In that case we may want to add an option for our API to decide if a deterministic split is to be employed. Could you also please check GraphSAGE as mentioned by @hbsun2113 ?\n \n Also it's not related to splitting the dataset, but encoding the labels into one-hot vectors.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "mufeili", "commentT": "2019-02-26T06:11:29Z", "comment_text": "\n \t\t\n Changing from classes = set(labels) to classes = list(sorted(set(labels))) solves the problem.\n \n <denchmark-link:/BarclayII>BarclayII</denchmark-link>\n  hi\uff01 I wonder why we need sort the ?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "mufeili", "commentT": "2019-02-26T06:21:53Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/hbsun2113>@hbsun2113</denchmark-link>\n  Sets are unordered and you can get different results across tries. To sort it can solve the issue.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "mufeili", "commentT": "2019-02-26T06:39:02Z", "comment_text": "\n \t\t\n Sets are unordered and you can get different results across tries. To sort it can solve the issue.\n \n <denchmark-link:https://github.com/mufeili>@mufeili</denchmark-link>\n   Encoding label to different onehot leads to different results?\n I think we only need call  once during training.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "mufeili", "commentT": "2019-02-26T08:00:53Z", "comment_text": "\n \t\t\n @mufeili Encoding label to different onehot leads to different results?\n I think we only need call _encode_onehot once during training.\n \n Yes to both.\n Think of a linear logistic regression.  If we swap the positive and negative labels, the optimal parameters would switch their signs as well.  This implies that, given everything the same (including initial parameters) except that we permute the labels, the trajectory of parameter updates would still be different.\n Now that we have a complicated non-convex model, we know that a lot of local minima exist.  Since the trajectory of parameter updates differ if we permute the labels, it is natural that the model performance would be (slightly) different between runs.  This also naturally extends to multi-class classification.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "mufeili", "commentT": "2019-05-15T03:10:48Z", "comment_text": "\n \t\tI just find an issue worth noting. When I fix all random seeds (torch, cuda, numpy, random,python), I can get same results (examples/gcn/train.py) using CPU but different results with GPU.\n Is there any function in DGL using GPU atomic function? This would introduce troubles in reproducity. Thanks.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "mufeili", "commentT": "2019-05-15T06:36:13Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/michaeljyt>@michaeljyt</denchmark-link>\n  Currently all operation in dgl are using framework operator, which you can find <denchmark-link:https://github.com/dmlc/dgl/blob/master/python/dgl/backend/pytorch/tensor.py>here</denchmark-link>\n . Using reduce function  will call  function and it might be non-deterministic. We will introduce new kernel in 0.3, using cuSparse kernel which is deterministic. (Correct me if I'm wrong <denchmark-link:https://github.com/jermainewang>@jermainewang</denchmark-link>\n  @ylfdq1118  )\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "mufeili", "commentT": "2019-05-15T10:23:29Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/VoVAllen>@VoVAllen</denchmark-link>\n  Thank very much for your reply. In my experiment, non-deterministic operation affects the performance seriously. CuSparse is a good choice. From the cuda document, the CUSPARSE_COOMM_ALG2 for cusparseSpMM is deterministic. Hope the new version would come out soon.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "mufeili", "commentT": "2019-05-17T08:17:16Z", "comment_text": "\n \t\t\n @michaeljyt Currently all operation in dgl are using framework operator, which you can find here. Using reduce function fn.sum will call spmm function and it might be non-deterministic. We will introduce new kernel in 0.3, using cuSparse kernel which is deterministic. (Correct me if I'm wrong @jermainewang @ylfdq1118 )\n \n Hi VoVAllen, I just tested torch.sparse function and find it quite slow (even worse than cpu). I am not familiar with CuSparse, so you may please test its speed first.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "mufeili", "commentT": "2019-05-17T08:33:49Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/michaeljyt>@michaeljyt</denchmark-link>\n  Another option is to use  to do the neighborhood sum at current stage, which is deterministic and had better performance.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "mufeili", "commentT": "2019-05-17T08:39:28Z", "comment_text": "\n \t\t\n @michaeljyt Another option is to use scatter_add to do the neighborhood sum at current stage, which is deterministic and had better performance.\n \n Unfortunately, scatter_add is not deterministic using gpu... The document of Pytorch has clarified it... Anyway, if dgl is used in supervised learning, this issue is not important. :D\n \t\t"}}}, "commit": {"commit_id": "c07ae34a990b05e9aeb9756977dcf7052c424a69", "commit_author": "Quan (Andy) Gan", "commitT": "2019-02-26 01:24:48-05:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\dgl\\data\\citation_graph.py", "file_new_name": "python\\dgl\\data\\citation_graph.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "392", "deleted_lines": "392", "method_info": {"method_name": "_encode_onehot", "method_params": "labels", "method_startline": "391", "method_endline": "397"}}}}}}}