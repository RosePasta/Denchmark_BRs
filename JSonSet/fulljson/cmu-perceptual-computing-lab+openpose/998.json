{"BR": {"BR_id": "998", "BR_author": "Glorialiujie", "BRopenT": "2018-12-31T14:36:04Z", "BRcloseT": "2019-01-03T21:05:13Z", "BR_text": {"BRsummary": "failed to run the examples in the tutorial_api_cpp form 4 to 9", "BRdescription": "\n <denchmark-h:h3>Issue Summary</denchmark-h>\n \n after I successfully run openpose.bin and the c++ API first 3 examples in the tutorial_api_cpp,I tried to run  rest examples such as 7_synchronous_custom_input, but it cannot work and shows that  (Segmentation fault).\n And when I run it in Clion ,it shows that:\n Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)\n after debugging\uff0cpointed at line46  in wPoseExtractor.hpp:  spPoseExtractor->initializationOnThread();\n <denchmark-h:h3>Type of Issue</denchmark-h>\n \n Execution error_\n <denchmark-h:h3>System Configuration</denchmark-h>\n \n ubuntu 18.04\n Caffe version:caffe -1.0\n CMake version:3.12\n opencv : opencv3.2.0\n cuda : 9.1\n GPU model: GTX 1060 6g\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Glorialiujie", "commentT": "2019-01-01T08:42:49Z", "comment_text": "\n \t\tI faced same problem.\n <denchmark-h:h2>7_synchronous_custom_input</denchmark-h>\n \n In the following statement, producerSharedPtr is empty and get functions fails.\n // Display\n const auto numberViews = (intRound(producerSharedPtr->get(ProducerProperty::NumberViews)));\n auto finalOutputSizeGui = finalOutputSize;\n if (numberViews > 1 && finalOutputSizeGui.x > 0)\n     finalOutputSizeGui.x *= numberViews;\n <denchmark-h:h3>Work Around</denchmark-h>\n \n Use WrapperStructInput and set ThreadManagerMode.AsynchronousIn to wrapper.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Glorialiujie", "commentT": "2019-01-01T13:52:37Z", "comment_text": "\n \t\t\n I faced same problem.\n 7_synchronous_custom_input\n In the following statement, producerSharedPtr is empty and get functions fails.\n // Display\n const auto numberViews = (intRound(producerSharedPtr->get(ProducerProperty::NumberViews)));\n auto finalOutputSizeGui = finalOutputSize;\n if (numberViews > 1 && finalOutputSizeGui.x > 0)\n     finalOutputSizeGui.x *= numberViews;\n Work Around\n Use WrapperStructInput and set ThreadManagerMode.AsynchronousIn to wrapper.\n \n \n I faced same problem.\n 7_synchronous_custom_input\n In the following statement, producerSharedPtr is empty and get functions fails.\n // Display\n const auto numberViews = (intRound(producerSharedPtr->get(ProducerProperty::NumberViews)));\n auto finalOutputSizeGui = finalOutputSize;\n if (numberViews > 1 && finalOutputSizeGui.x > 0)\n     finalOutputSizeGui.x *= numberViews;\n Work Around\n Use WrapperStructInput and set ThreadManagerMode.AsynchronousIn to wrapper.\n \n Hi,firstly thanks for your reply. I am a novice and could you please give more details about how to solve this\uff1fI just want to get some output in the console desk from video or camera . Besides, I have tried to run these examples in former releases that do not have the statement in  you mentioned and it also failed.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Glorialiujie", "commentT": "2019-01-01T14:52:26Z", "comment_text": "\n \t\tI tried windows 10. Not ubuntu. But I believe environmental does not matter.\n I changed code to. Please get diff if you want to know modification.\n // ------------------------- OpenPose C++ API Tutorial - Example 7 - XXXXXXXXXXXXX -------------------------\n // If the user wants to learn to use the OpenPose library, we highly recommend to start with the\n // examples in `examples/tutorial_api_cpp/`.\n // This example summarizes all the functionality of the OpenPose library:\n     // 1. Read folder of images / video / webcam  (`producer` module)\n     // 2. Extract and render body keypoint / heatmap / PAF of that image (`pose` module)\n     // 3. Extract and render face keypoint / heatmap / PAF of that image (`face` module)\n     // 4. Save the results on disk (`filestream` module)\n     // 5. Display the rendered pose (`gui` module)\n     // Everything in a multi-thread scenario (`thread` module)\n     // Points 2 to 5 are included in the `wrapper` module\n // In addition to the previous OpenPose modules, we also need to use:\n     // 1. `core` module:\n         // For the Array<float> class that the `pose` module needs\n         // For the Datum struct that the `thread` module sends between the queues\n     // 2. `utilities` module: for the error & logging functions, i.e., op::error & op::log respectively\n // This file should only be used for the user to take specific examples.\n \n // Command-line user intraface\n //#define OPENPOSE_FLAGS_DISABLE_PRODUCER\n #include <openpose/flags.hpp>\n // OpenPose dependencies\n #include <openpose/headers.hpp>\n \n // Custom OpenPose flags\n // Producer\n //DEFINE_string(image_dir, \"examples/media/\",\n //    \"Process a directory of images. Read all standard formats (jpg, png, bmp, etc.).\");\n \n // If the user needs his own variables, he can inherit the op::Datum struct and add them in there.\n // UserDatum can be directly used by the OpenPose wrapper because it inherits from op::Datum, just define\n // WrapperT<std::vector<UserDatum>> instead of Wrapper (or equivalently WrapperT<std::vector<UserDatum>>)\n struct UserDatum : public op::Datum\n {\n     bool boolThatUserNeedsForSomeReason;\n \n     UserDatum(const bool boolThatUserNeedsForSomeReason_ = false) :\n         boolThatUserNeedsForSomeReason{boolThatUserNeedsForSomeReason_}\n     {}\n };\n \n // The W-classes can be implemented either as a template or as simple classes given\n // that the user usually knows which kind of data he will move between the queues,\n // in this case we assume a std::shared_ptr of a std::vector of UserDatum\n \n // This worker will just read and return all the jpg files in a directory\n class WUserInput : public op::WorkerProducer<std::shared_ptr<std::vector<UserDatum>>>\n {\n public:\n     WUserInput(const std::string& directoryPath) :\n         mImageFiles{op::getFilesOnDirectory(directoryPath, \"jpg\")},\n         // If we want \"jpg\" + \"png\" images\n         // mImageFiles{op::getFilesOnDirectory(directoryPath, std::vector<std::string>{\"jpg\", \"png\"})},\n         mCounter{0}\n     {\n         if (mImageFiles.empty())\n             op::error(\"No images found on: \" + directoryPath, __LINE__, __FUNCTION__, __FILE__);\n     }\n \n     void initializationOnThread() {}\n \n     std::shared_ptr<std::vector<UserDatum>> workProducer()\n     {\n         try\n         {\n             // Close program when empty frame\n             if (mImageFiles.size() <= mCounter)\n             {\n                 op::log(\"Last frame read and added to queue. Closing program after it is processed.\",\n                         op::Priority::High);\n                 // This funtion stops this worker, which will eventually stop the whole thread system once all the\n                 // frames have been processed\n                 this->stop();\n                 return nullptr;\n             }\n             else\n             {\n                 // Create new datum\n                 auto datumsPtr = std::make_shared<std::vector<UserDatum>>();\n                 datumsPtr->emplace_back();\n                 auto& datum = datumsPtr->at(0);\n \n                 // Fill datum\n                 datum.cvInputData = cv::imread(mImageFiles.at(mCounter++));\n \n                 // If empty frame -> return nullptr\n                 if (datum.cvInputData.empty())\n                 {\n                     op::log(\"Empty frame detected on path: \" + mImageFiles.at(mCounter-1) + \". Closing program.\",\n                         op::Priority::High);\n                     this->stop();\n                     datumsPtr = nullptr;\n                 }\n \n                 return datumsPtr;\n             }\n         }\n         catch (const std::exception& e)\n         {\n             this->stop();\n             op::error(e.what(), __LINE__, __FUNCTION__, __FILE__);\n             return nullptr;\n         }\n     }\n \n private:\n     const std::vector<std::string> mImageFiles;\n     unsigned long long mCounter;\n };\n \n int tutorialApiCpp7()\n {\n     try\n     {\n \t\tFLAGS_image_dir = \"examples/media/\";\n         op::log(\"Starting OpenPose demo...\", op::Priority::High);\n         const auto timerBegin = std::chrono::high_resolution_clock::now();\n \n         // logging_level\n         op::check(0 <= FLAGS_logging_level && FLAGS_logging_level <= 255, \"Wrong logging_level value.\",\n                   __LINE__, __FUNCTION__, __FILE__);\n         op::ConfigureLog::setPriorityThreshold((op::Priority)FLAGS_logging_level);\n         op::Profiler::setDefaultX(FLAGS_profile_speed);\n         // // For debugging\n         // // Print all logging messages\n         // op::ConfigureLog::setPriorityThreshold(op::Priority::None);\n         // // Print out speed values faster\n         // op::Profiler::setDefaultX(100);\n \n         // Applying user defined configuration - GFlags to program variables\n         // cameraSize\n \t\tconst auto cameraSize = op::flagsToPoint(FLAGS_camera_resolution, \"-1x-1\");\n         // outputSize\n         const auto outputSize = op::flagsToPoint(FLAGS_output_resolution, \"-1x-1\");\n         // netInputSize\n         const auto netInputSize = op::flagsToPoint(FLAGS_net_resolution, \"-1x368\");\n         // faceNetInputSize\n         const auto faceNetInputSize = op::flagsToPoint(FLAGS_face_net_resolution, \"368x368 (multiples of 16)\");\n         // handNetInputSize\n         const auto handNetInputSize = op::flagsToPoint(FLAGS_hand_net_resolution, \"368x368 (multiples of 16)\");\n \t\t// producerType\n \t\top::ProducerType producerType;\n \t\tstd::string producerString;\n \t\tstd::tie(producerType, producerString) = op::flagsToProducer(\n \t\t\tFLAGS_image_dir, FLAGS_video, FLAGS_ip_camera, FLAGS_camera, FLAGS_flir_camera, FLAGS_flir_camera_index);\n         // poseModel\n         const auto poseModel = op::flagsToPoseModel(FLAGS_model_pose);\n         // JSON saving\n         if (!FLAGS_write_keypoint.empty())\n             op::log(\"Flag `write_keypoint` is deprecated and will eventually be removed.\"\n                     \" Please, use `write_json` instead.\", op::Priority::Max);\n         // keypointScale\n         const auto keypointScale = op::flagsToScaleMode(FLAGS_keypoint_scale);\n         // heatmaps to add\n         const auto heatMapTypes = op::flagsToHeatMaps(FLAGS_heatmaps_add_parts, FLAGS_heatmaps_add_bkg,\n                                                       FLAGS_heatmaps_add_PAFs);\n         const auto heatMapScale = op::flagsToHeatMapScaleMode(FLAGS_heatmaps_scale);\n         // >1 camera view?\n         // const auto multipleView = (FLAGS_3d || FLAGS_3d_views > 1 || FLAGS_flir_camera);\n         const auto multipleView = false;\n         // Enabling Google Logging\n         const bool enableGoogleLogging = true;\n \n         // OpenPose wrapper\n         op::log(\"Configuring OpenPose...\", op::Priority::High);\n         op::WrapperT<std::vector<UserDatum>> opWrapperT(op::ThreadManagerMode::AsynchronousIn);\n \n         // Initializing the user custom classes\n         // Frames producer (e.g., video, webcam, ...)\n         auto wUserInput = std::make_shared<WUserInput>(FLAGS_image_dir);\n         // Add custom processing\n         const auto workerInputOnNewThread = true;\n         opWrapperT.setWorker(op::WorkerType::Input, wUserInput, workerInputOnNewThread);\n \n         // Pose configuration (use WrapperStructPose{} for default and recommended configuration)\n         const op::WrapperStructPose wrapperStructPose{\n             !FLAGS_body_disable, netInputSize, outputSize, keypointScale, FLAGS_num_gpu, FLAGS_num_gpu_start,\n             FLAGS_scale_number, (float)FLAGS_scale_gap, op::flagsToRenderMode(FLAGS_render_pose, multipleView),\n             poseModel, !FLAGS_disable_blending, (float)FLAGS_alpha_pose, (float)FLAGS_alpha_heatmap,\n             FLAGS_part_to_show, FLAGS_model_folder, heatMapTypes, heatMapScale, FLAGS_part_candidates,\n             (float)FLAGS_render_threshold, FLAGS_number_people_max, FLAGS_maximize_positives, FLAGS_fps_max,\n             enableGoogleLogging};\n         opWrapperT.configure(wrapperStructPose);\n         // Face configuration (use op::WrapperStructFace{} to disable it)\n         const op::WrapperStructFace wrapperStructFace{\n             FLAGS_face, faceNetInputSize, op::flagsToRenderMode(FLAGS_face_render, multipleView, FLAGS_render_pose),\n             (float)FLAGS_face_alpha_pose, (float)FLAGS_face_alpha_heatmap, (float)FLAGS_face_render_threshold};\n         opWrapperT.configure(wrapperStructFace);\n         // Hand configuration (use op::WrapperStructHand{} to disable it)\n         const op::WrapperStructHand wrapperStructHand{\n             FLAGS_hand, handNetInputSize, FLAGS_hand_scale_number, (float)FLAGS_hand_scale_range, FLAGS_hand_tracking,\n             op::flagsToRenderMode(FLAGS_hand_render, multipleView, FLAGS_render_pose), (float)FLAGS_hand_alpha_pose,\n             (float)FLAGS_hand_alpha_heatmap, (float)FLAGS_hand_render_threshold};\n         opWrapperT.configure(wrapperStructHand);\n         // Extra functionality configuration (use op::WrapperStructExtra{} to disable it)\n         const op::WrapperStructExtra wrapperStructExtra{\n             FLAGS_3d, FLAGS_3d_min_views, FLAGS_identification, FLAGS_tracking, FLAGS_ik_threads};\n         opWrapperT.configure(wrapperStructExtra);\n \t\t// Producer (use default to disable any input)\n \t\tconst op::WrapperStructInput wrapperStructInput{\n \t\t\tproducerType, producerString, FLAGS_frame_first, FLAGS_frame_step, FLAGS_frame_last,\n \t\t\tFLAGS_process_real_time, FLAGS_frame_flip, FLAGS_frame_rotate, FLAGS_frames_repeat,\n \t\t\tcameraSize, FLAGS_camera_parameter_path, FLAGS_frame_undistort, FLAGS_3d_views };\n \t\topWrapperT.configure(wrapperStructInput);\n         // Output (comment or use default argument to disable any output)\n         const op::WrapperStructOutput wrapperStructOutput{\n             FLAGS_cli_verbose, FLAGS_write_keypoint, op::stringToDataFormat(FLAGS_write_keypoint_format),\n             FLAGS_write_json, FLAGS_write_coco_json, FLAGS_write_coco_foot_json, FLAGS_write_coco_json_variant,\n             FLAGS_write_images, FLAGS_write_images_format, FLAGS_write_video, FLAGS_write_video_fps,\n             FLAGS_write_heatmaps, FLAGS_write_heatmaps_format, FLAGS_write_video_3d, FLAGS_write_video_adam,\n             FLAGS_write_bvh, FLAGS_udp_host, FLAGS_udp_port};\n         opWrapperT.configure(wrapperStructOutput);\n         // GUI (comment or use default argument to disable any visual output)\n         const op::WrapperStructGui wrapperStructGui{\n             op::flagsToDisplayMode(FLAGS_display, FLAGS_3d), !FLAGS_no_gui_verbose, FLAGS_fullscreen};\n         opWrapperT.configure(wrapperStructGui);\n         // Set to single-thread (for sequential processing and/or debugging and/or reducing latency)\n         if (FLAGS_disable_multi_thread)\n             opWrapperT.disableMultiThreading();\n \n         // Start, run, and stop processing - exec() blocks this thread until OpenPose wrapper has finished\n         op::log(\"Starting thread(s)...\", op::Priority::High);\n         opWrapperT.exec();\n \n         // Measuring total time\n         const auto now = std::chrono::high_resolution_clock::now();\n         const auto totalTimeSec = (double)std::chrono::duration_cast<std::chrono::nanoseconds>(now-timerBegin).count()\n                                 * 1e-9;\n         const auto message = \"OpenPose demo successfully finished. Total time: \"\n                            + std::to_string(totalTimeSec) + \" seconds.\";\n         op::log(message, op::Priority::High);\n \n         // Return successful message\n         return 0;\n     }\n     catch (const std::exception& e)\n     {\n         return -1;\n     }\n }\n \n int main(int argc, char *argv[])\n {\n     // Parsing command line flags\n     gflags::ParseCommandLineFlags(&argc, &argv, true);\n \n     // Running tutorialApiCpp7\n     return tutorialApiCpp7();\n }\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Glorialiujie", "commentT": "2019-01-02T03:34:24Z", "comment_text": "\n \t\t\n I tried windows 10. Not ubuntu. But I believe environmental does not matter.\n I changed code to. Please get diff if you want to know modification.\n // ------------------------- OpenPose C++ API Tutorial - Example 7 - XXXXXXXXXXXXX -------------------------\n // If the user wants to learn to use the OpenPose library, we highly recommend to start with the\n // examples in `examples/tutorial_api_cpp/`.\n // This example summarizes all the functionality of the OpenPose library:\n     // 1. Read folder of images / video / webcam  (`producer` module)\n     // 2. Extract and render body keypoint / heatmap / PAF of that image (`pose` module)\n     // 3. Extract and render face keypoint / heatmap / PAF of that image (`face` module)\n     // 4. Save the results on disk (`filestream` module)\n     // 5. Display the rendered pose (`gui` module)\n     // Everything in a multi-thread scenario (`thread` module)\n     // Points 2 to 5 are included in the `wrapper` module\n // In addition to the previous OpenPose modules, we also need to use:\n     // 1. `core` module:\n         // For the Array<float> class that the `pose` module needs\n         // For the Datum struct that the `thread` module sends between the queues\n     // 2. `utilities` module: for the error & logging functions, i.e., op::error & op::log respectively\n // This file should only be used for the user to take specific examples.\n \n // Command-line user intraface\n //#define OPENPOSE_FLAGS_DISABLE_PRODUCER\n #include <openpose/flags.hpp>\n // OpenPose dependencies\n #include <openpose/headers.hpp>\n \n // Custom OpenPose flags\n // Producer\n //DEFINE_string(image_dir, \"examples/media/\",\n //    \"Process a directory of images. Read all standard formats (jpg, png, bmp, etc.).\");\n \n // If the user needs his own variables, he can inherit the op::Datum struct and add them in there.\n // UserDatum can be directly used by the OpenPose wrapper because it inherits from op::Datum, just define\n // WrapperT<std::vector<UserDatum>> instead of Wrapper (or equivalently WrapperT<std::vector<UserDatum>>)\n struct UserDatum : public op::Datum\n {\n     bool boolThatUserNeedsForSomeReason;\n \n     UserDatum(const bool boolThatUserNeedsForSomeReason_ = false) :\n         boolThatUserNeedsForSomeReason{boolThatUserNeedsForSomeReason_}\n     {}\n };\n \n // The W-classes can be implemented either as a template or as simple classes given\n // that the user usually knows which kind of data he will move between the queues,\n // in this case we assume a std::shared_ptr of a std::vector of UserDatum\n \n // This worker will just read and return all the jpg files in a directory\n class WUserInput : public op::WorkerProducer<std::shared_ptr<std::vector<UserDatum>>>\n {\n public:\n     WUserInput(const std::string& directoryPath) :\n         mImageFiles{op::getFilesOnDirectory(directoryPath, \"jpg\")},\n         // If we want \"jpg\" + \"png\" images\n         // mImageFiles{op::getFilesOnDirectory(directoryPath, std::vector<std::string>{\"jpg\", \"png\"})},\n         mCounter{0}\n     {\n         if (mImageFiles.empty())\n             op::error(\"No images found on: \" + directoryPath, __LINE__, __FUNCTION__, __FILE__);\n     }\n \n     void initializationOnThread() {}\n \n     std::shared_ptr<std::vector<UserDatum>> workProducer()\n     {\n         try\n         {\n             // Close program when empty frame\n             if (mImageFiles.size() <= mCounter)\n             {\n                 op::log(\"Last frame read and added to queue. Closing program after it is processed.\",\n                         op::Priority::High);\n                 // This funtion stops this worker, which will eventually stop the whole thread system once all the\n                 // frames have been processed\n                 this->stop();\n                 return nullptr;\n             }\n             else\n             {\n                 // Create new datum\n                 auto datumsPtr = std::make_shared<std::vector<UserDatum>>();\n                 datumsPtr->emplace_back();\n                 auto& datum = datumsPtr->at(0);\n \n                 // Fill datum\n                 datum.cvInputData = cv::imread(mImageFiles.at(mCounter++));\n \n                 // If empty frame -> return nullptr\n                 if (datum.cvInputData.empty())\n                 {\n                     op::log(\"Empty frame detected on path: \" + mImageFiles.at(mCounter-1) + \". Closing program.\",\n                         op::Priority::High);\n                     this->stop();\n                     datumsPtr = nullptr;\n                 }\n \n                 return datumsPtr;\n             }\n         }\n         catch (const std::exception& e)\n         {\n             this->stop();\n             op::error(e.what(), __LINE__, __FUNCTION__, __FILE__);\n             return nullptr;\n         }\n     }\n \n private:\n     const std::vector<std::string> mImageFiles;\n     unsigned long long mCounter;\n };\n \n int tutorialApiCpp7()\n {\n     try\n     {\n \t\tFLAGS_image_dir = \"examples/media/\";\n         op::log(\"Starting OpenPose demo...\", op::Priority::High);\n         const auto timerBegin = std::chrono::high_resolution_clock::now();\n \n         // logging_level\n         op::check(0 <= FLAGS_logging_level && FLAGS_logging_level <= 255, \"Wrong logging_level value.\",\n                   __LINE__, __FUNCTION__, __FILE__);\n         op::ConfigureLog::setPriorityThreshold((op::Priority)FLAGS_logging_level);\n         op::Profiler::setDefaultX(FLAGS_profile_speed);\n         // // For debugging\n         // // Print all logging messages\n         // op::ConfigureLog::setPriorityThreshold(op::Priority::None);\n         // // Print out speed values faster\n         // op::Profiler::setDefaultX(100);\n \n         // Applying user defined configuration - GFlags to program variables\n         // cameraSize\n \t\tconst auto cameraSize = op::flagsToPoint(FLAGS_camera_resolution, \"-1x-1\");\n         // outputSize\n         const auto outputSize = op::flagsToPoint(FLAGS_output_resolution, \"-1x-1\");\n         // netInputSize\n         const auto netInputSize = op::flagsToPoint(FLAGS_net_resolution, \"-1x368\");\n         // faceNetInputSize\n         const auto faceNetInputSize = op::flagsToPoint(FLAGS_face_net_resolution, \"368x368 (multiples of 16)\");\n         // handNetInputSize\n         const auto handNetInputSize = op::flagsToPoint(FLAGS_hand_net_resolution, \"368x368 (multiples of 16)\");\n \t\t// producerType\n \t\top::ProducerType producerType;\n \t\tstd::string producerString;\n \t\tstd::tie(producerType, producerString) = op::flagsToProducer(\n \t\t\tFLAGS_image_dir, FLAGS_video, FLAGS_ip_camera, FLAGS_camera, FLAGS_flir_camera, FLAGS_flir_camera_index);\n         // poseModel\n         const auto poseModel = op::flagsToPoseModel(FLAGS_model_pose);\n         // JSON saving\n         if (!FLAGS_write_keypoint.empty())\n             op::log(\"Flag `write_keypoint` is deprecated and will eventually be removed.\"\n                     \" Please, use `write_json` instead.\", op::Priority::Max);\n         // keypointScale\n         const auto keypointScale = op::flagsToScaleMode(FLAGS_keypoint_scale);\n         // heatmaps to add\n         const auto heatMapTypes = op::flagsToHeatMaps(FLAGS_heatmaps_add_parts, FLAGS_heatmaps_add_bkg,\n                                                       FLAGS_heatmaps_add_PAFs);\n         const auto heatMapScale = op::flagsToHeatMapScaleMode(FLAGS_heatmaps_scale);\n         // >1 camera view?\n         // const auto multipleView = (FLAGS_3d || FLAGS_3d_views > 1 || FLAGS_flir_camera);\n         const auto multipleView = false;\n         // Enabling Google Logging\n         const bool enableGoogleLogging = true;\n \n         // OpenPose wrapper\n         op::log(\"Configuring OpenPose...\", op::Priority::High);\n         op::WrapperT<std::vector<UserDatum>> opWrapperT(op::ThreadManagerMode::AsynchronousIn);\n \n         // Initializing the user custom classes\n         // Frames producer (e.g., video, webcam, ...)\n         auto wUserInput = std::make_shared<WUserInput>(FLAGS_image_dir);\n         // Add custom processing\n         const auto workerInputOnNewThread = true;\n         opWrapperT.setWorker(op::WorkerType::Input, wUserInput, workerInputOnNewThread);\n \n         // Pose configuration (use WrapperStructPose{} for default and recommended configuration)\n         const op::WrapperStructPose wrapperStructPose{\n             !FLAGS_body_disable, netInputSize, outputSize, keypointScale, FLAGS_num_gpu, FLAGS_num_gpu_start,\n             FLAGS_scale_number, (float)FLAGS_scale_gap, op::flagsToRenderMode(FLAGS_render_pose, multipleView),\n             poseModel, !FLAGS_disable_blending, (float)FLAGS_alpha_pose, (float)FLAGS_alpha_heatmap,\n             FLAGS_part_to_show, FLAGS_model_folder, heatMapTypes, heatMapScale, FLAGS_part_candidates,\n             (float)FLAGS_render_threshold, FLAGS_number_people_max, FLAGS_maximize_positives, FLAGS_fps_max,\n             enableGoogleLogging};\n         opWrapperT.configure(wrapperStructPose);\n         // Face configuration (use op::WrapperStructFace{} to disable it)\n         const op::WrapperStructFace wrapperStructFace{\n             FLAGS_face, faceNetInputSize, op::flagsToRenderMode(FLAGS_face_render, multipleView, FLAGS_render_pose),\n             (float)FLAGS_face_alpha_pose, (float)FLAGS_face_alpha_heatmap, (float)FLAGS_face_render_threshold};\n         opWrapperT.configure(wrapperStructFace);\n         // Hand configuration (use op::WrapperStructHand{} to disable it)\n         const op::WrapperStructHand wrapperStructHand{\n             FLAGS_hand, handNetInputSize, FLAGS_hand_scale_number, (float)FLAGS_hand_scale_range, FLAGS_hand_tracking,\n             op::flagsToRenderMode(FLAGS_hand_render, multipleView, FLAGS_render_pose), (float)FLAGS_hand_alpha_pose,\n             (float)FLAGS_hand_alpha_heatmap, (float)FLAGS_hand_render_threshold};\n         opWrapperT.configure(wrapperStructHand);\n         // Extra functionality configuration (use op::WrapperStructExtra{} to disable it)\n         const op::WrapperStructExtra wrapperStructExtra{\n             FLAGS_3d, FLAGS_3d_min_views, FLAGS_identification, FLAGS_tracking, FLAGS_ik_threads};\n         opWrapperT.configure(wrapperStructExtra);\n \t\t// Producer (use default to disable any input)\n \t\tconst op::WrapperStructInput wrapperStructInput{\n \t\t\tproducerType, producerString, FLAGS_frame_first, FLAGS_frame_step, FLAGS_frame_last,\n \t\t\tFLAGS_process_real_time, FLAGS_frame_flip, FLAGS_frame_rotate, FLAGS_frames_repeat,\n \t\t\tcameraSize, FLAGS_camera_parameter_path, FLAGS_frame_undistort, FLAGS_3d_views };\n \t\topWrapperT.configure(wrapperStructInput);\n         // Output (comment or use default argument to disable any output)\n         const op::WrapperStructOutput wrapperStructOutput{\n             FLAGS_cli_verbose, FLAGS_write_keypoint, op::stringToDataFormat(FLAGS_write_keypoint_format),\n             FLAGS_write_json, FLAGS_write_coco_json, FLAGS_write_coco_foot_json, FLAGS_write_coco_json_variant,\n             FLAGS_write_images, FLAGS_write_images_format, FLAGS_write_video, FLAGS_write_video_fps,\n             FLAGS_write_heatmaps, FLAGS_write_heatmaps_format, FLAGS_write_video_3d, FLAGS_write_video_adam,\n             FLAGS_write_bvh, FLAGS_udp_host, FLAGS_udp_port};\n         opWrapperT.configure(wrapperStructOutput);\n         // GUI (comment or use default argument to disable any visual output)\n         const op::WrapperStructGui wrapperStructGui{\n             op::flagsToDisplayMode(FLAGS_display, FLAGS_3d), !FLAGS_no_gui_verbose, FLAGS_fullscreen};\n         opWrapperT.configure(wrapperStructGui);\n         // Set to single-thread (for sequential processing and/or debugging and/or reducing latency)\n         if (FLAGS_disable_multi_thread)\n             opWrapperT.disableMultiThreading();\n \n         // Start, run, and stop processing - exec() blocks this thread until OpenPose wrapper has finished\n         op::log(\"Starting thread(s)...\", op::Priority::High);\n         opWrapperT.exec();\n \n         // Measuring total time\n         const auto now = std::chrono::high_resolution_clock::now();\n         const auto totalTimeSec = (double)std::chrono::duration_cast<std::chrono::nanoseconds>(now-timerBegin).count()\n                                 * 1e-9;\n         const auto message = \"OpenPose demo successfully finished. Total time: \"\n                            + std::to_string(totalTimeSec) + \" seconds.\";\n         op::log(message, op::Priority::High);\n \n         // Return successful message\n         return 0;\n     }\n     catch (const std::exception& e)\n     {\n         return -1;\n     }\n }\n \n int main(int argc, char *argv[])\n {\n     // Parsing command line flags\n     gflags::ParseCommandLineFlags(&argc, &argv, true);\n \n     // Running tutorialApiCpp7\n     return tutorialApiCpp7();\n }\n \n I have tried your code and it still failed. I found another error:\"Cannot create Cublas handle. Cublas won't be available.\". It always appears no matter it works(openppose.bin) or fail(7_synchronous_custom_input). Could it be the key of this problem?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Glorialiujie", "commentT": "2019-01-02T11:10:14Z", "comment_text": "\n \t\tI tried Ubuntu 1804 with 1080 on CUDA 9.2.\n It works fine without any modification.\n But latest openpose does not work. I refer <denchmark-link:https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/787#issuecomment-415476837>#787 (comment)</denchmark-link>\n  and it works. This commit has not larger modification about 7_synchronous_custom_input.cpp.\n It is weird.\n <denchmark-h:h3>NOTE</denchmark-h>\n \n It is a log of building openpose\n <denchmark-code>-- ******************* Caffe Configuration Summary *******************\n -- General:\n --   Version           :   1.0.0\n --   Git               :   1.0-118-gf019d0df\n --   System            :   Linux\n --   C++ compiler      :   /usr/bin/c++\n --   Release CXX flags :   -O3 -DNDEBUG -fPIC -Wall -Wno-sign-compare -Wno-uninitialized\n --   Debug CXX flags   :   -g -fPIC -Wall -Wno-sign-compare -Wno-uninitialized\n --   Build type        :   Release\n -- \n --   BUILD_SHARED_LIBS :   ON\n --   BUILD_python      :   OFF\n --   BUILD_matlab      :   OFF\n --   BUILD_docs        :   OFF\n --   CPU_ONLY          :   OFF\n --   USE_OPENCV        :   OFF\n --   USE_LEVELDB       :   OFF\n --   USE_LMDB          :   OFF\n --   USE_NCCL          :   OFF\n --   ALLOW_LMDB_NOLOCK :   OFF\n -- \n -- Dependencies:\n --   BLAS              :   Yes (Atlas)\n --   Boost             :   Yes (ver. 1.65)\n --   glog              :   Yes\n --   gflags            :   Yes\n --   protobuf          :   Yes (ver. 3.0.0)\n --   CUDA              :   Yes (ver. 9.2)\n -- \n -- NVIDIA CUDA:\n --   Target GPU(s)     :   Auto\n --   GPU arch(s)       :   sm_61\n --   cuDNN             :   Yes (ver. 7.4.1)\n -- \n -- Install:\n --   Install path      :   /media/hdd/work/OpenSource/OpenPoseDotNet/openpose/build/caffe\n </denchmark-code>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Glorialiujie", "commentT": "2019-01-03T21:05:13Z", "comment_text": "\n \t\tMy apologies. Fixed (it was only example 7, the rest were working on my machine). Let me know whether it works or not now (and if so, which example is failing).\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Glorialiujie", "commentT": "2019-01-03T22:57:10Z", "comment_text": "\n \t\tI confirmed it works fine. Thanks.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "Glorialiujie", "commentT": "2019-01-04T09:39:55Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/takuya-takeuchi>@takuya-takeuchi</denchmark-link>\n  I have reinstall almost everything in these two days and it seem to be the opencv that caused my problem.Now,it is fixed. Anyway, thanks for you help.\n \t\t"}}}, "commit": {"commit_id": "fdbe68d1dabe27489fa7047649b17f827599219d", "commit_author": "gineshidalgo99", "commitT": "2019-01-03 16:05:04-05:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": ".travis.yml", "file_new_name": ".travis.yml", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15,20,21,22,23,24,25,26,27,28,29,30,31,33,43,44,45,49,50,51,55,56,57,58,59,60,61,62", "deleted_lines": "20,30,31,32,39,40"}}}, "file_1": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "cmake\\travis\\defaults.sh", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "doc\\installation.md", "file_new_name": "doc\\installation.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "42", "deleted_lines": "42"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "include\\openpose\\wrapper\\wrapperAuxiliary.hpp", "file_new_name": "include\\openpose\\wrapper\\wrapperAuxiliary.hpp", "file_complexity": {"file_NLOC": "811", "file_CCN": "156", "file_NToken": "6380"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "345,350,388,393,426,430,431,436,437,442,481,486,525,531,542,556,561,577,587,597,605,610,616,621,626,635,640,644,648,659,670,674,679,684,696,700,709,714,720,725,730,739,743,749,758,759,767,787,808,824", "deleted_lines": "345,715", "method_info": {"method_name": "op::configureThreadManager", "method_params": "threadManager,multiThreadEnabledTemp,threadManagerMode,wrapperStructPoseTemp,wrapperStructFace,wrapperStructHand,wrapperStructExtra,wrapperStructInput,wrapperStructOutput,wrapperStructGui,userWs,userWsOnNewThread", "method_startline": "85", "method_endline": "1077", "method_complexity": {"method_NLOC": "765", "method_CCN": "156", "method_NToken": "6121", "method_nesting_level": "1"}}}}}}}}