{"BR": {"BR_id": "490", "BR_author": "PhilipMay", "BRopenT": "2019-09-09T21:54:09Z", "BRcloseT": "2019-11-05T02:20:34Z", "BR_text": {"BRsummary": "Bug in F1 and FBeta implementation and test", "BRdescription": "\n Describe the bug\n The tests for FBeta and F1 both use a softmax function with just one output.\n \n \n \n \n addons/tensorflow_addons/metrics/fbeta_test.py\n \n \n          Line 122\n       in\n       7624954\n \n \n \n \n \n \n  model.add(layers.Dense(1, activation='softmax')) \n \n \n \n \n \n \n \n \n addons/tensorflow_addons/metrics/f1_test.py\n \n \n          Line 116\n       in\n       7624954\n \n \n \n \n \n \n  model.add(layers.Dense(1, activation='softmax')) \n \n \n \n \n \n \n The effect is that the output (prediction) is always 1. The right activation function for a binary calssification (with just one output is sigmoid). But this is not the only problem. This bug in the test hides an even worse other bug.\n The other bug is that F1 and FBeta both can not handle values other then 1 (1.0) and 0 (0.0) as the predicted result. But the predictions of a binary classification (with simoid) and multi class classification with softmax is always somewhere between 1 and 0 (one hot encoded for multi class). The result of this bug is that this implementation of F1 and FBeta always return 0.0 when the predicted results are not exactly 0 (0.0) or 1 (1.0) - which is not realistic.\n Also all other tests of F1 and FBeta have values of 0 or 1 as the predicted results. This does not reflect reality.\n \n \n \n \n addons/tensorflow_addons/metrics/fbeta_test.py\n \n \n          Line 91\n       in\n       7624954\n \n \n \n \n \n \n  preds = tf.constant([[0, 0, 1], [1, 1, 0], [1, 1, 1]], dtype=tf.int32) \n \n \n \n \n \n \n \n \n addons/tensorflow_addons/metrics/f1_test.py\n \n \n          Line 88\n       in\n       7624954\n \n \n \n \n \n \n  preds = tf.constant([[0, 0, 1], [1, 1, 0], [1, 1, 1]], dtype=tf.int32) \n \n \n \n \n \n \n Code to reproduce the issue\n Just change softmax to sigmoid in the tests and change verbose=1 and see the results.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "PhilipMay", "commentT": "2019-09-09T22:20:31Z", "comment_text": "\n \t\tI guess something like this needs to be added:\n <denchmark-link:https://github.com/tensorflow/tensorflow/blob/2ff39d00faf8f7e433ddcae0aa278f6e573b0c55/tensorflow/python/keras/metrics.py#L2767>https://github.com/tensorflow/tensorflow/blob/2ff39d00faf8f7e433ddcae0aa278f6e573b0c55/tensorflow/python/keras/metrics.py#L2767</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "PhilipMay", "commentT": "2019-09-09T22:23:37Z", "comment_text": "\n \t\tThanks, <denchmark-link:https://github.com/PhilipMay>@PhilipMay</denchmark-link>\n . You are right that result will not be an exact number.\n The initial implementation we had do not indicate the probability.\n preds = tf.constant([[0, 0, 1], [1, 1, 0], [1, 1, 1]], dtype=tf.int32) \n In this [0, 0, 1] does not indicate probability. Think we have 3 classes and the predicted is class 3 which is encoded as [0,0,1]\n We may need to add argmax to change that in case if we are feeding directly.\n Will take up this one and post the updates\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "PhilipMay", "commentT": "2019-09-09T22:28:43Z", "comment_text": "\n \t\t\n We may need to add argmax to change that in case if we are feeding directly.\n \n Yes - if we want to be able to add the metric to keras at training time we need that. Mybe you could have a look at the metrics implementations in Tensorflow.\n Thanks you very much. :-)\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "PhilipMay", "commentT": "2019-09-09T22:30:04Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/seanpmorgan>@seanpmorgan</denchmark-link>\n  Can you please assign this issue to me?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "PhilipMay", "commentT": "2019-09-10T10:54:53Z", "comment_text": "\n \t\tThis here seems to work for me - not sure if it still has bugs in border cases or can be implemented more efficient:\n     def update_state(self, y_true, y_pred, sample_weight=None):\n         cond = tf.equal(y_pred, tf.reduce_max(y_pred))\n         y_pred = tf.where(cond, y_pred, tf.zeros_like(y_pred))\n         not_cond = tf.math.logical_not(cond)\n         y_pred = tf.where(not_cond, y_pred, tf.ones_like(y_pred))\n         \n         y_true = tf.cast(y_true, tf.int32)\n         y_pred = tf.cast(y_pred, tf.int32)\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "PhilipMay", "commentT": "2019-09-10T12:24:24Z", "comment_text": "\n \t\tFor further tests I would suggest that you can compare your results with those from sklearn:\n from sklearn.metrics import f1_score\n ytrue = np.argmax(y_test, axis=-1)\n ypred = np.argmax(y_hat_test, axis=-1)\n \n print(f1_score(ytrue, ypred, average='macro'))  \n print(f1_score(ytrue, ypred, average='micro'))  \n print(f1_score(ytrue, ypred, average='weighted'))\n print(f1_score(ytrue, ypred, average=None))\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "PhilipMay", "commentT": "2019-09-10T13:52:40Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/PhilipMay>@PhilipMay</denchmark-link>\n \n I have a working code ready now using threshold option. That will help in both multiclass and multilabel. Will create a PR today\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "PhilipMay", "commentT": "2019-09-10T15:05:46Z", "comment_text": "\n \t\t\n Thanks @PhilipMay\n I have a working code ready now using threshold option. That will help in both multiclass and multilabel. Will create a PR today\n \n That is great. Thanks. I need that fix for my project. :-)\n Maybe you can add a comparison with f1_score from sklearn to the tests.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "PhilipMay", "commentT": "2019-09-11T08:56:30Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/SSaishruthi>@SSaishruthi</denchmark-link>\n  I do not think that this implementation with threshold fixes the problem. Here is why:\n When you have a \"single-label categorial classification\" where one sample belongs to exactly one class of many possible classes you apply a softmax funcation. Let me give an example:\n You habe 3 classes: dog, cat and bike and do a one hot encoding.\n <denchmark-code>dog = [1, 0, 0]\n cat = [0, 1, 0]\n bike = [0, 0, 1]\n </denchmark-code>\n \n Now when you put a dog into the model you might get the following from the softmax function:\n \n This means: dog because 0.5 is the highest value. And this is the reason why a threshold is not valid. You should apply something like  or . Something like this: <denchmark-link:https://github.com/tensorflow/addons/issues/490#issuecomment-529882338>#490 (comment)</denchmark-link>\n \n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "PhilipMay", "commentT": "2019-09-11T13:39:07Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/PhilipMay>@PhilipMay</denchmark-link>\n \n I am taking binary accuracy as a reference here: <denchmark-link:https://github.com/tensorflow/tensorflow/blob/2ff39d00faf8f7e433ddcae0aa278f6e573b0c55/tensorflow/python/keras/metrics.py#L630>https://github.com/tensorflow/tensorflow/blob/2ff39d00faf8f7e433ddcae0aa278f6e573b0c55/tensorflow/python/keras/metrics.py#L630</denchmark-link>\n \n In order for this to work you need to provide the threshold value as 0.49 above. I can probably fix the threshold default to be 0.5. I think below 0.5, it may not be considered as a good prediction.\n I have this tested with scikit learn as (that's the usual procedure I follow)\n well.<denchmark-link:https://colab.research.google.com/drive/1qSq0SsYkPqjdKUgM1RM4kKM67X75ocFj>https://colab.research.google.com/drive/1qSq0SsYkPqjdKUgM1RM4kKM67X75ocFj</denchmark-link>\n \n Goal here is to make it compatible with both multi-class and multi-label\n \t\t"}}}, "commit": {"commit_id": "c3aba0818b6e74ac3a4341d00242c464584c8b50", "commit_author": "Dheeraj R Reddy", "commitT": "2019-11-04 21:20:33-05:00", "commit_complexity": {"commit_NLOC": "0.3508771929824561", "commit_CCN": "0.0", "commit_Nprams": "0.17543859649122806"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow_addons\\metrics\\BUILD", "file_new_name": "tensorflow_addons\\metrics\\BUILD", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "48,51,53", "deleted_lines": "48,51,53,54,55,56,57,58,59,60,61,62,63,64,65,66"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow_addons\\metrics\\README.md", "file_new_name": "tensorflow_addons\\metrics\\README.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15,16", "deleted_lines": "15"}}}, "file_2": {"file_change_type": "DELETE", "file_Nmethod": 0, "file_old_name": "tensorflow_addons\\metrics\\f1_test.py", "file_new_name": "None", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 9, "file_old_name": "tensorflow_addons\\metrics\\f_scores.py", "file_new_name": "tensorflow_addons\\metrics\\f_scores.py", "file_complexity": {"file_NLOC": "192", "file_CCN": "13", "file_NToken": "871"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "76", "deleted_lines": "72,73,74,75,76,77,78", "method_info": {"method_name": "__init__", "method_params": "self,num_classes,average,beta,threshold,name,dtype", "method_startline": "72", "method_endline": "78", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "31", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "136,137,138", "deleted_lines": "136,137,138", "method_info": {"method_name": "update_state._count_non_zero", "method_params": "val", "method_startline": "136", "method_endline": "138", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "32", "method_nesting_level": "2"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "230,231,232,233,234", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,num_classes,average,threshold,name,dtype", "method_startline": "230", "method_endline": "235", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "25", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "175,176,177,178", "deleted_lines": "167,168,169,170,171,172,173,174", "method_info": {"method_name": "get_config", "method_params": "self", "method_startline": "167", "method_endline": "180", "method_complexity": {"method_NLOC": "10", "method_CCN": "2", "method_NToken": "77", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "146,147,148,149,150,153,154,155,157,160,161,162,163", "deleted_lines": "145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165", "method_info": {"method_name": "result", "method_params": "self", "method_startline": "145", "method_endline": "165", "method_complexity": {"method_NLOC": "17", "method_CCN": "3", "method_NToken": "156", "method_nesting_level": "1"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "183,184,185,186", "deleted_lines": "184,185,186", "method_info": {"method_name": "reset_states", "method_params": "self", "method_startline": "182", "method_endline": "186", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "81", "method_nesting_level": "1"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "109,110,111,112", "deleted_lines": "109,110,111,112", "method_info": {"method_name": "_zero_wt_init", "method_params": "name", "method_startline": "109", "method_endline": "114", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "2"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "124,125,126,127,128,129,130,131,132,136,137,138,139,140,141,142,143", "deleted_lines": "123,124,125,126,127,128,129,130,134,135,136,137,138,139,140,141,142,143", "method_info": {"method_name": "update_state", "method_params": "self,y_true,y_pred,sample_weight", "method_startline": "123", "method_endline": "143", "method_complexity": {"method_NLOC": "14", "method_CCN": "2", "method_NToken": "151", "method_nesting_level": "1"}}}, "hunk_8": {"Ismethod": 1, "added_lines": null, "deleted_lines": "338", "method_info": {"method_name": "__init__", "method_params": "self,num_classes,average,name,dtype", "method_startline": "338", "method_endline": "339", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "19", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tensorflow_addons\\metrics\\f_test.py", "file_complexity": {"file_NLOC": "110", "file_CCN": "15", "file_NToken": "1525"}}, "file_5": {"file_change_type": "DELETE", "file_Nmethod": 0, "file_old_name": "tensorflow_addons\\metrics\\fbeta_test.py", "file_new_name": "None", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_addons\\metrics\\utils.py", "file_new_name": "tensorflow_addons\\metrics\\utils.py", "file_complexity": {"file_NLOC": "36", "file_CCN": "5", "file_NToken": "339"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "71,72,73,74,75,76,77,78,79,80,81,82,83", "deleted_lines": null, "method_info": {"method_name": "_get_model", "method_params": "metric,num_output", "method_startline": "71", "method_endline": "83", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "122", "method_nesting_level": "0"}}}}}}}}