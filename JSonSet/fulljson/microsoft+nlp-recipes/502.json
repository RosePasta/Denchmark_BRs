{"BR": {"BR_id": "502", "BR_author": "hlums", "BRopenT": "2019-11-27T23:20:38Z", "BRcloseT": "2020-01-12T20:18:25Z", "BR_text": {"BRsummary": "[BUG] Question Answering unit tests fail on gpu testing machine", "BRdescription": "\n <denchmark-h:h3>Description</denchmark-h>\n \n tests/unit/test_models_transformers_question_answering.py succeeds on DSVM, but fails on gpu testing machine.\n <denchmark-code>tests/unit/test_common_pytorch_utils.py ......                           [ 54%]\n tests/unit/test_models_transformers_question_answering.py .F..           [ 90%]\n tests/unit/test_transformers_sequence_classification.py .                [100%]\n \n =================================== FAILURES ===================================\n _____________________________ test_AnswerExtractor _____________________________\n \n qa_test_data = {'test_dataset': <utils_nlp.models.transformers.datasets.QADataset object at 0x7f1447bbe828>, 'test_features_bert': <t...ject at 0x7f1446a0c780>, 'test_features_xlnet': <torch.utils.data.dataloader.DataLoader object at 0x7f14469bfd30>, ...}\n tmp_module = '/tmp/pytest-of-nlpadmin/pytest-1011/tmpnzdwdt1d'\n \n     @pytest.mark.gpu\n     def test_AnswerExtractor(qa_test_data, tmp_module):\n         # test bert\n         qa_extractor_bert = AnswerExtractor(cache_dir=tmp_module)\n >       qa_extractor_bert.fit(qa_test_data[\"train_features_bert\"], cache_model=True)\n \n tests/unit/test_models_transformers_question_answering.py:197: \n _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n utils_nlp/models/transformers/question_answering.py:551: in fit\n     seed=seed,\n utils_nlp/models/transformers/common.py:174: in fine_tune\n     outputs = self.model(**inputs)\n /data/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/torch/nn/modules/module.py:547: in __call__\n     result = self.forward(*input, **kwargs)\n _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n \n self = DataParallel(\n   (module): BertForQuestionAnswering(\n     (bert): BertModel(\n       (embeddings): BertEmbeddings(\n        ...)\n         (activation): Tanh()\n       )\n     )\n     (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n   )\n )\n inputs = ()\n kwargs = {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, ... 0,\n              0,     0,     0,     0]], device='cuda:1'), 'start_positions': tensor([ 0, 17], device='cuda:1'), ...}\n t = Parameter containing:\n tensor([[-0.0005, -0.0416,  0.0131,  ..., -0.0039, -0.0335,  0.0150],\n         [ 0.0169, -0.0311,...18],\n         [ 0.0313, -0.0297, -0.0230,  ..., -0.0145, -0.0525,  0.0284]],\n        device='cuda:1', requires_grad=True)\n \n     def forward(self, *inputs, **kwargs):\n         if not self.device_ids:\n             return self.module(*inputs, **kwargs)\n     \n         for t in chain(self.module.parameters(), self.module.buffers()):\n             if t.device != self.src_device_obj:\n                 raise RuntimeError(\"module must have its parameters and buffers \"\n                                    \"on device {} (device_ids[0]) but found one of \"\n >                                  \"them on device: {}\".format(self.src_device_obj, t.device))\n E               RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:1\n </denchmark-code>\n \n <denchmark-h:h3>How do we replicate the bug?</denchmark-h>\n \n <denchmark-h:h3>Expected behavior (i.e. solution)</denchmark-h>\n \n <denchmark-h:h3>Other Comments</denchmark-h>\n \n \t"}, "comments": {}}, "commit": {"commit_id": "b0468ce2f209a2f965af1e33ab190f98f4bd7ad9", "commit_author": "Ke Huang", "commitT": "2019-12-05 15:30:27-05:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "utils_nlp\\models\\transformers\\common.py", "file_new_name": "utils_nlp\\models\\transformers\\common.py", "file_complexity": {"file_NLOC": "203", "file_CCN": "12", "file_NToken": "1249"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "14,15,16,17,18,19,20,21,144,145,146,147,148", "deleted_lines": "14,137"}}}}}}