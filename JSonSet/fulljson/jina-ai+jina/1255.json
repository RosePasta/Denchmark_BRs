{"BR": {"BR_id": "1255", "BR_author": "cristianmtr", "BRopenT": "2020-11-09T16:08:40Z", "BRcloseT": "2020-11-11T11:03:36Z", "BR_text": {"BRsummary": "clarify meaning of 'score'", "BRdescription": "\n Describe the bug\n From a discussion with <denchmark-link:https://github.com/JoanFM>@JoanFM</denchmark-link>\n  , it seems like there is a bit of confusion around the  field.\n \n In the context of chunk comparisons (at the Indexer level) it means distance. Thus, smaller is better\n In the context of documents (as parents of chunks) it means similarity. Or at least, in the context of MinRanker (https://github.com/jina-ai/jina-hub/blob/f92276c1c4a38ef9ac34a16c4065b5d360805600/rankers/MinRanker/__init__.py#L12), larger is better.\n \n Thus there is nothing wrong with the output of the below example (from multires lyrics example):\n <denchmark-link:https://user-images.githubusercontent.com/8330330/98240250-6a470b00-1f69-11eb-986c-fc09ade9074a.png></denchmark-link>\n \n However, this is confusing. The problem, to me, is a matter of documentation / conflicting definitions for the score field.\n As originally discussed in <denchmark-link:https://github.com/jina-ai/jina/issues/1224>#1224</denchmark-link>\n \n Describe how you solve it\n Possible solutions:\n \n documentation\n changing the name it by document / chunk. Document would be \"similarity\" (?), while chunk should be \"distance\". AFAIK, protobuf represents them with the same object, so that wouldn't work\n adding another field to the list of match and list of chunk that represents the method use to generate the score field.\n \n Something like\n  \"method\": \"MinRanker\"  # or \"Indexer\n in the output\n <denchmark-link:https://user-images.githubusercontent.com/8330330/98564389-9a194a00-22ac-11eb-8395-8e5d0bcb0dba.png></denchmark-link>\n \n Environment\n <denchmark-code>jina                          0.7.8\n jina-proto                    0.0.75\n jina-vcs-tag                  (unset)\n libzmq                        4.3.2\n pyzmq                         1.19.4\n protobuf                      3.13.0\n proto-backend                 cpp\n grpcio                        1.33.2\n ruamel.yaml                   0.16.12\n python                        3.8.5\n platform                      Linux\n platform-release              5.4.0-52-generic\n platform-version              #57-Ubuntu SMP Thu Oct 15 10:57:00 UTC 2020\n architecture                  x86_64\n processor                     x86_64\n jina-resources                /home/cristian/code/jina/jina/resources\n JINA_ARRAY_QUANT              (unset)\n JINA_BINARY_DELIMITER         (unset)\n JINA_CONTRIB_MODULE           (unset)\n JINA_CONTRIB_MODULE_IS_LOADING(unset)\n JINA_CONTROL_PORT             (unset)\n JINA_DB_COLLECTION            (unset)\n JINA_DB_HOSTNAME              (unset)\n JINA_DB_NAME                  (unset)\n JINA_DB_PASSWORD              (unset)\n JINA_DB_USERNAME              (unset)\n JINA_DEFAULT_HOST             (unset)\n JINA_DISABLE_UVLOOP           (unset)\n JINA_EXECUTOR_WORKDIR         (unset)\n JINA_FULL_CLI                 (unset)\n JINA_IPC_SOCK_TMP             (unset)\n JINA_LOG_CONFIG               (unset)\n JINA_LOG_NO_COLOR             (unset)\n JINA_POD_NAME                 (unset)\n JINA_PROFILING                (unset)\n JINA_RANDOM_PORTS             (unset)\n JINA_SOCKET_HWM               (unset)\n JINA_TEST_GPU                 (unset)\n JINA_TEST_PRETRAINED          (unset)\n JINA_VCS_VERSION              (unset)\n JINA_WARN_UNNAMED             (unset)\n </denchmark-code>\n \n Screenshots\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "cristianmtr", "commentT": "2020-11-09T16:31:03Z", "comment_text": "\n \t\tI think something similar to what you describe of the method used to calculate the score is currently in place. The op_name in the NamedScore\n <denchmark-code>message NamedScore {\n     float value = 1; // value\n     string op_name = 2; // the name of the operator/score function\n     string description = 3; // text description of the score\n     repeated NamedScore operands = 4; // the score can be nested\n     string ref_id = 5; // the score is computed between doc `id` and `ref_id`\n }\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "cristianmtr", "commentT": "2020-11-09T17:24:48Z", "comment_text": "\n \t\tyes, our protobuf already support it. Unfortunately, most of our rankers didn't leverage the rich semantic and only add value without description. The ranker creator should write that semantic into the description just like writing comment. It's a best practice thing when extending with Jina. I'd suggest enforcing this best practice from now.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "cristianmtr", "commentT": "2020-11-09T17:28:05Z", "comment_text": "\n \t\tI do think is already being added <denchmark-link:https://github.com/cristianmtr>@cristianmtr</denchmark-link>\n  , can you check if you see it inside the  object inside  at any level?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "cristianmtr", "commentT": "2020-11-09T17:35:35Z", "comment_text": "\n \t\tjust fyi, you can simply add r.score.description = exec.__doc__ in the RankDriver at jina/drivers/rank.py:178 to make it more descriptive.\n But then every score now carries a long description, could be less network-efficient. This is the tradeoff you anyway have to take. Or you don't make the decision and add an option and let the user decide.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "cristianmtr", "commentT": "2020-11-10T07:57:36Z", "comment_text": "\n \t\tCouldn't we maybe find a way to make them all fit one direction? Either all are lower is better or all are higher is better?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "cristianmtr", "commentT": "2020-11-10T08:47:42Z", "comment_text": "\n \t\tunfortunately, no. Not universally everywhere. Same goes with tf, pytorch, where score is always task-specific, you as the user say what is best, loss or distance is at low-level, it is smaller the better by definition.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "cristianmtr", "commentT": "2020-11-10T09:24:11Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/cristianmtr>@cristianmtr</denchmark-link>\n  maybe we can add some part in the documentation having a little discussion on .\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "cristianmtr", "commentT": "2020-11-10T09:25:12Z", "comment_text": "\n \t\tYeah, I guess we can do that. Is there a known list of rankers/sorters and whether they are lower or higher is better?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "cristianmtr", "commentT": "2020-11-10T09:26:05Z", "comment_text": "\n \t\t\n Yeah, I guess we can do that. Is there a known list of rankers/sorters and whether they are lower or higher is better?\n \n this list will evolve, so I would keep it conceptual\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "cristianmtr", "commentT": "2020-11-10T10:55:40Z", "comment_text": "\n \t\tI will try to write up something after reading through the code.\n Another possible approach: since all the classes that run any of the scoring / measure know their metric (right?), we could perhaps have them invert it so as to match one specific direction (lower or higher).\n E.g. NumpyIndexer knows it uses cosine dist. It measures distances between vectors. It gets the lowest nr as top result, right? We could then do 1 - score to map it so that higher is better.\n It might be problematic in the cases where we don't know the upper bound of a scoring/ranking function (not sure which examples might fit here)\n \t\t"}}}, "commit": {"commit_id": "6a84ca2f143e61e64d21978bc01671e97d551524", "commit_author": "cristian", "commitT": "2020-11-11 12:03:35+01:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "docs\\chapters\\flow\\index.md", "file_new_name": "docs\\chapters\\flow\\index.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556", "deleted_lines": "532"}}}}}}