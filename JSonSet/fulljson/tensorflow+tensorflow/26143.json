{"BR": {"BR_id": "26143", "BR_author": "lazysjb", "BRopenT": "2019-02-26T21:12:27Z", "BRcloseT": "2019-06-04T13:17:06Z", "BR_text": {"BRsummary": "[TF2.0] Error Logging for GradientTape", "BRdescription": "\n Hello everyone,\n I was wondering if there is an option for error logging / or could we have tf output error message for gradient calculation. In the example below, the below will output None values in the current setting but will output correct gradients when the tf.Variables are a float type. My question is, could we please add an error message stating something like gradient calculation supports only float types?\n Best Regards,\n Seung-jae Bang\n <denchmark-code>def forward(a, b):\n     \"\"\"f = a * b\"\"\"\n     return a * b\n \n params = [tf.Variable(1), tf.Variable(2)]\n \n with tf.GradientTape() as tape:\n     result = forward(*params)\n \n tape.gradient(result, params)\n </denchmark-code>\n \n System information\n \n Linux\n TensorFlow installed from pip install -U tf-nightly-2.0-preview - \"2.0.0-dev20190226\"\n Python version: 3.6\n \n ccing: <denchmark-link:https://github.com/random-forests>@random-forests</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "lazysjb", "commentT": "2019-03-04T17:12:49Z", "comment_text": "\n \t\tI'd love to approve a PR adding this test. Feel like giving it a shot?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "lazysjb", "commentT": "2019-03-05T01:55:20Z", "comment_text": "\n \t\tI would be happy to give it a shot - I haven't contributed to TF before, would you have any pointers?\n Also, would tensorflow/python/eager/backprop.py be the right place to make this change?\n cc: <denchmark-link:https://github.com/random-forests>@random-forests</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "lazysjb", "commentT": "2019-03-05T16:39:13Z", "comment_text": "\n \t\tYes, the change would be to add some logging to that particular file.\n \n If you need any more pointers, happy to help.\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Mon, Mar 4, 2019 at 5:58 PM lazysjb ***@***.***> wrote:\n  I would be happy to give it a shot - I haven't contributed to TF before,\n  would you have any pointers?\n  Also, would tensorflow/python/eager/backprop.py be the right place to make\n  this change?\n \n  cc: @random-forests <https://github.com/random-forests>\n \n  \u2014\n  You are receiving this because you were assigned.\n  Reply to this email directly, view it on GitHub\n  <#26143 (comment)>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/AAATxdlUmDjQehdKpLmQuotUBd4yku7iks5vTc9VgaJpZM4bTIcM>\n  .\n \n \n -- \n  - Alex\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "lazysjb", "commentT": "2019-03-08T14:20:08Z", "comment_text": "\n \t\ti would also like to contribute can you please help me where i can add logging in backprop.py\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "lazysjb", "commentT": "2019-03-08T16:51:54Z", "comment_text": "\n \t\tYou probably want to add the warning in tape.watch here \n \n \n tensorflow/tensorflow/python/eager/backprop.py\n \n \n          Line 804\n       in\n       d280d3d\n \n \n \n \n \n \n  def watch(self, tensor): \n \n \n \n \n  and tape.gradient here \n \n \n tensorflow/tensorflow/python/eager/backprop.py\n \n \n          Line 890\n       in\n       d280d3d\n \n \n \n \n \n \n  def gradient(self, \n \n \n \n \n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "lazysjb", "commentT": "2019-03-23T11:04:05Z", "comment_text": "\n \t\tHi,\n I wish to start contributing to TensorFlow and hence would like to know if someone is already working on this issue.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "lazysjb", "commentT": "2019-03-25T10:00:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/achalagarwal>@achalagarwal</denchmark-link>\n  I think <denchmark-link:https://github.com/shashvatshahi1998>@shashvatshahi1998</denchmark-link>\n  is already working on this. <denchmark-link:https://github.com/shashvatshahi1998>@shashvatshahi1998</denchmark-link>\n  can you confirm?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "lazysjb", "commentT": "2019-03-25T12:23:22Z", "comment_text": "\n \t\tYa I am working on that, but anyone else who is interested can start working.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "lazysjb", "commentT": "2019-06-04T07:21:25Z", "comment_text": "\n \t\tHey, This would be my first contribution to tf and i would like to know whether this issue is open and if anybody is contributing to this.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "lazysjb", "commentT": "2019-06-04T13:17:06Z", "comment_text": "\n \t\tClosing this out since I understand it to be resolved by the PR. I have checked the code which output warning as expected. Thanks!\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "lazysjb", "commentT": "2019-06-04T13:17:07Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26143>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26143>No</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "764fdc6fb1a9ac377440e1b537ff8a6b7e9f2063", "commit_author": "A. Unique TensorFlower", "commitT": "2019-04-01 14:35:59-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\eager\\backprop.py", "file_new_name": "tensorflow\\python\\eager\\backprop.py", "file_complexity": {"file_NLOC": "592", "file_CCN": "114", "file_NToken": "3311"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "815,816,817,818", "deleted_lines": null, "method_info": {"method_name": "watch", "method_params": "self,tensor", "method_startline": "808", "method_endline": "825", "method_complexity": {"method_NLOC": "10", "method_CCN": "4", "method_NToken": "71", "method_nesting_level": "1"}}}}}}}}