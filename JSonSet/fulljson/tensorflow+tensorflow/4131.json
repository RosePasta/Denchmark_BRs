{"BR": {"BR_id": "4131", "BR_author": "pronobis", "BRopenT": "2016-08-31T17:26:25Z", "BRcloseT": "2016-09-08T16:51:24Z", "BR_text": {"BRsummary": "reduce_max and maximum give different results for negative infinity", "BRdescription": "\n Using tf.maximum with negative inf inputs as follows:\n <denchmark-code>tf.maximum(-math.inf, -math.inf).eval()\n </denchmark-code>\n \n gives the expected result -inf\n However, tf.reduce_max, on the same inputs:\n <denchmark-code>tf.reduce_max([-math.inf, -math.inf]).eval()\n </denchmark-code>\n \n gives: -3.40282e+38 which is the min float32.\n For positive infinity inputs, both functions result in inf.\n <denchmark-h:h3>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</denchmark-h>\n \n I posted this as an SO question first:\n <denchmark-link:http://stackoverflow.com/questions/39211546/bug-in-tensorflow-reduce-max-for-negative-infinity>http://stackoverflow.com/questions/39211546/bug-in-tensorflow-reduce-max-for-negative-infinity</denchmark-link>\n \n <denchmark-h:h3>Environment info</denchmark-h>\n \n Operating System: Ubuntu 16.04\n Installed version of CUDA and cuDNN:\n <denchmark-code>-rw-r--r-- 1 root root   560184 May 25 17:48 /usr/local/cuda-8.0/lib64/libcudadevrt.a\n lrwxrwxrwx 1 root root       16 May 25 17:52 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0\n lrwxrwxrwx 1 root root       19 May 25 17:52 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n -rw-r--r-- 1 root root   394472 May 25 17:48 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27\n -rw-r--r-- 1 root root   737516 May 25 17:48 /usr/local/cuda-8.0/lib64/libcudart_static.a\n lrwxrwxrwx 1 root root       13 Jul  4 16:22 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5\n lrwxrwxrwx 1 root root       17 Jul  4 16:22 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5\n -rwxr-xr-x 1 root root 78065952 Jul  4 16:22 /usr/local/cuda-8.0/lib64/libcudnn.so.5.0.5\n -rw-r--r-- 1 root root 68709594 Jul  4 16:22 /usr/local/cuda-8.0/lib64/libcudnn_static.a\n \n </denchmark-code>\n \n Installed from source.\n Commit hash: <denchmark-link:https://github.com/tensorflow/tensorflow/commit/3cb39956e622b322e43547cf2b6e337020643f21>3cb3995</denchmark-link>\n \n Bazel:\n <denchmark-code>Build label: 0.3.0\n Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n Build time: Fri Jun 10 11:38:23 2016 (1465558703)\n Build timestamp: 1465558703\n Build timestamp as int: 1465558703\n \n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "pronobis", "commentT": "2016-08-31T23:51:56Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/pronobis>@pronobis</denchmark-link>\n  Thanks for the bug report. I have fixed the bug internally at Google and in the open source Eigen repository (<denchmark-link:https://bitbucket.org/eigen/eigen/commits/741b932c41cebff49c4419b7e0ef9910ef1b2907>https://bitbucket.org/eigen/eigen/commits/741b932c41cebff49c4419b7e0ef9910ef1b2907</denchmark-link>\n ). We will have to wait until a few unrelated issues are resolved in Eigen before pushing the fix to open source TensorFlow. Stay tuned! :-)\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "pronobis", "commentT": "2016-09-03T01:33:03Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/pronobis>@pronobis</denchmark-link>\n  Update: The issues in Eigen have been resolved and the fix for this issue will be pushed out on Monday.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "pronobis", "commentT": "2016-09-05T00:50:24Z", "comment_text": "\n \t\tGreat! Thanks!\n \t\t"}}}, "commit": {"commit_id": "fadc1f3c869c15b1890221bb6dfb0f7bd0f7c23d", "commit_author": "Benoit Steiner", "commitT": "2016-09-02 16:17:43-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tensorflow\\core\\kernels\\constant_op_gpu.cu.cc", "file_new_name": "tensorflow\\core\\kernels\\constant_op_gpu.cu.cc", "file_complexity": {"file_NLOC": "58", "file_CCN": "6", "file_NToken": "348"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "48", "method_info": {"method_name": "Eigen::internal::scalar_const_op::packetOp", "method_params": "Index,Index", "method_startline": "48", "method_endline": "50", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "23", "method_nesting_level": "3"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "45", "deleted_lines": "46,47", "method_info": {"method_name": "Eigen::internal::scalar_const_op::packetOp", "method_params": "", "method_startline": "45", "method_endline": "47", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "18", "method_nesting_level": "3"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "40", "deleted_lines": "40,41,42", "method_info": {"method_name": "Eigen::internal::scalar_const_op::operator ( )", "method_params": "", "method_startline": "40", "method_endline": "42", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "12", "method_nesting_level": "3"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "44", "deleted_lines": "41,42", "method_info": {"method_name": "Eigen::internal::scalar_const_op::operator ( )", "method_params": "Index,Index", "method_startline": "41", "method_endline": "44", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "17", "method_nesting_level": "3"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow\\workspace.bzl", "file_new_name": "tensorflow\\workspace.bzl", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15,16", "deleted_lines": "15,16"}}}}}}