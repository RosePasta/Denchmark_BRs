{"BR": {"BR_id": "44011", "BR_author": "dhruvin2910", "BRopenT": "2020-10-14T12:46:16Z", "BRcloseT": "2020-12-16T01:00:18Z", "BR_text": {"BRsummary": "ops defined inside tf.while_loop's cond/body or tf.cond's true_fn/false_fn functions ignore their enclosed tf.device if the tf.while_loop/tf.cond itself is inside a tf.device", "BRdescription": "\n Please make sure that this is a bug. As per our\n GitHub Policy,\n we only address code/doc bugs, performance issues, feature requests and\n build/installation issues on GitHub. tag:bug_template\n System information\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina\n Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\n TensorFlow installed from (source or binary): binary\n TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0\n Python version: Python 3.7.8\n Bazel version (if compiling from source):\n GCC/Compiler version (if compiling from source):\n CUDA/cuDNN version:\n GPU model and memory:\n \n You can collect some of this information using our environment capture\n <denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh>script</denchmark-link>\n \n You can also obtain the TensorFlow version with:\n \n TF 1.0: python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\n TF 2.0: python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\n \n Describe the current behavior\n tf.print doesn't print on specified device (using tf.device) if it is inside a for loop in graph mode.\n Initially I though it's an autograph issue. But if you trace the graph and inspect it in tensorboard (color by device), the graph does have that PrintV2 placed where it's supposed to.\n Now, I'm not sure why it's happening.\n I'm yet to verify if this happens across all the ops, or just the tf.print.\n Waiting for the team to let me know what to check next.\n Describe the expected behavior\n tf.print should print on specified device (using tf.device). Everything works fine if I'm using tf.while_loop instead.\n Can be seen from sample code.\n Standalone code to reproduce the issue\n Provide a reproducible test case that is the bare minimum necessary to generate\n the problem. If possible, please share a link to Colab/Jupyter/any notebook.\n THIS SNIPPET IS NOT CORRECT ANYMORE, PLEASE READ A COUPLE OF COMMENTS BELOW.\n import tensorflow as tf\n \n # assume there's a tf.distribute.Server running on rpi.local:2222\n tf.config.experimental_connect_to_cluster(\n     tf.train.ClusterSpec({'worker': ['dhruvins-macbook-air.local:2222', 'rpi.local:2222']}),\n     job_name='worker',\n     task_index=0\n )\n \n laptop = '/job:worker/task:0'\n rpi = '/job:worker/task:1'\n \n \n @tf.function\n def test_for():\n     with tf.device(rpi):\n         for i in tf.range(3):\n             tf.print('rpi', 'for', i)\n             with tf.device(laptop):\n                 tf.print('laptop', 'for', i)\n \n \n @tf.function\n def test_while():\n     def cond(i):\n         return i < 3\n \n     def body(i):\n         with tf.device(rpi):\n             tf.print('rpi', 'while', i)\n             with tf.device(laptop):\n                 tf.print('laptop', 'while', i)\n         return [i + 1]\n \n     tf.while_loop(cond, body, [0], parallel_iterations=1)\n \n \n test_for()\n test_while()\n Other info / logs Include any logs or source code that would be helpful to\n diagnose the problem. If including tracebacks, please include the full\n traceback. Large logs and files should be attached.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "dhruvin2910", "commentT": "2020-10-19T15:26:21Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jvishnuvardhan>@jvishnuvardhan</denchmark-link>\n \n I ran this code on nightly, the code keep running and does not produce any output, please find the <denchmark-link:https://colab.research.google.com/gist/Saduf2019/cdad7be80aca26f332c5e366cfbced34/untitled445.ipynb>gist here</denchmark-link>\n .\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "dhruvin2910", "commentT": "2020-10-19T17:52:37Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Saduf2019>@Saduf2019</denchmark-link>\n  One will need to modify their colab code a bit to point to existing (running) (s).\n The reason why it's stuck is because it's unable to connect to rpi.local:2222 while running inside colab's container.\n The sample code I provided requires at least two tensorflow servers. On same machine, or on different ones (i.e. my case).\n  Here's the <denchmark-link:https://colab.research.google.com/gist/dhruvin2910/d8b0765a28b8182303105b29dd57262c/untitled445.ipynb>reproducible version</denchmark-link>\n . Let me know if this suffices.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "dhruvin2910", "commentT": "2020-10-20T12:41:03Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/dhruvin2910>@dhruvin2910</denchmark-link>\n  there is a notable difference between the two snippets of code: In the autograph case, the  is places outside the loop. In the tf.while_loop case, the  is placed inside the loop. So to make them equivalent, you'd need to either write:\n <denchmark-code>for i in tf.range(3):\n     with tf.device(rpi):\n </denchmark-code>\n \n or\n <denchmark-code>with tf.device(rpi):\n     def cond(i):\n         ...\n     def body(i):\n         ...\n \n     tf.while_loop(...)\n </denchmark-code>\n \n And I believe that highlights the bug: if we place a tf.device outside a tf.while_loop, its body does not respect it. Things work as expected when the tf.device is placed inside the loop body. Could you verify that in your setup?\n At any rate, this looks like a placement bug in TensorFlow.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "dhruvin2910", "commentT": "2020-10-20T12:46:39Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/mdanatg>@mdanatg</denchmark-link>\n  You sure this is intended for me? Did you mean to tag dhruvin2910 and accidentally selected me in dropdown somehow? Because although I have contributed to tensorflow in past, I don't think I have touched this part of the code.\n Just realized I am logged into this from my work account (JayNakrani) and my personal account (dhananjay92) was tagged\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "dhruvin2910", "commentT": "2020-10-20T12:49:55Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JayNakrani>@JayNakrani</denchmark-link>\n  sorry about that. I meant to tag <denchmark-link:https://github.com/dhruvin2910>@dhruvin2910</denchmark-link>\n . Not sure how the autocomplete filled your tag.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "dhruvin2910", "commentT": "2020-10-20T14:00:18Z", "comment_text": "\n \t\t\n there is a notable difference between the two snippets of code: In the autograph case, the tf.device is places outside the loop. In the tf.while_loop case, the tf.device is placed inside the loop. So to make them equivalent, you'd need to either write: ...\n \n <denchmark-link:https://github.com/mdanatg>@mdanatg</denchmark-link>\n  Yes, I intended to provide what you just suggested. The problem originated from a bit involving code. Somehow, I missed wrapping the  with  instead, while I was simplifying it to reproduce this issue.\n \n And I believe that highlights the bug: if we place a tf.device outside a tf.while_loop, its body does not respect it. Things work as expected when the tf.device is placed inside the loop body. Could you verify that in your setup?\n \n Yes. <denchmark-link:https://colab.research.google.com/gist/dhruvin2910/d8b0765a28b8182303105b29dd57262c/untitled445.ipynb#scrollTo=vFcc6P_S_ebz>Updated Colab</denchmark-link>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "dhruvin2910", "commentT": "2020-10-21T03:23:47Z", "comment_text": "\n \t\tAs I mentioned earlier, the graph seems to have PrintV2 placed on expected device.\n I'm unable to upload the logs properly to tensorboard.dev, so here's a screenshot (blue ones are on rpi and green ones are on my macbook):\n <denchmark-link:https://user-images.githubusercontent.com/9679326/96669104-27d2db00-137a-11eb-8dc9-63eeaae26a48.png></denchmark-link>\n \n \n At any rate, this looks like a placement bug in TensorFlow.\n \n Yes, I think the problem lies in the execution of the graph.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "dhruvin2910", "commentT": "2020-10-21T06:49:10Z", "comment_text": "\n \t\tI tested if all ops are misplaced or not with this code.\n I don't really know a proper way to find it out. But here's an experiment (and assumptions) to test it:\n \n A very long while loop may be substituted for a long running task (with parallel iterations set to 1)\n \n \n With proper control_dependencies set, one can measure computation time of a set of ops.\n If two devices have different compute power, one can guess the device placement by the amount of time taken, faster task would mean it was placed on the device with better compute.\n \n \n \n \n Since both long running tasks are assigned to different devices, they should run concurrently.\n One can guess the device placement is wrong if they are run in sequence. Can be guessed from total time, or from print statements.\n \n \n \n def task(n):\n     with tf.name_scope('task'):\n         return tf.while_loop(lambda i: i < n, lambda i: i + 1, [0], parallel_iterations=1)[0]\n \n \n def timed(f, *args):\n     with tf.name_scope('timed'):\n         start = tf.timestamp(name='start')\n         with tf.control_dependencies([start]):\n             r = f(*args)\n         with tf.control_dependencies([r]):\n             end = tf.timestamp(name='end')\n         return tf.subtract(end, start, name='time'), r\n \n \n @tf.function\n def test_while():\n     with tf.device(rpi):\n         def cond(i):\n             return i < 1\n \n         def body(i):\n             t, n = timed(task, 100_000)\n             tf.print('rpi', 'while', t, n)\n             with tf.device(laptop):\n                 t, n = timed(task, 100_000)\n                 tf.print('laptop', 'while', t, n)\n             return [i + 1]\n \n         tf.while_loop(cond, body, [0], parallel_iterations=1)\n Observations:\n \n The tasks are running in sequence, so there's something more to this story.\n I have a rasppberry pi running at 700MHz and a MacBook Air running at 1.8GHz. The tasks take roughly the same time (6s), and the total time was around 12s. Again there's something missing.\n \n <denchmark-code>rpi while 6.2778100967407227 100000\n laptop while 6.16434907913208 100000\n </denchmark-code>\n \n Note:\n Since I may have made mistakes in my assumptions or the code, I don't think the experiment is conclusive.\n I think it may still help further investigation.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "dhruvin2910", "commentT": "2020-10-21T07:11:30Z", "comment_text": "\n \t\tJust discovered tf.debugging.set_log_device_placement(True), and I can confirm that the device placement is indeed incorrect.\n <denchmark-code>...\n while/body/_1/while/PrintV2: (PrintV2): /job:worker/replica:0/task:1/device:CPU:0\n ...\n while/body/_1/while/PrintV2_1: (PrintV2): /job:worker/replica:0/task:1/device:CPU:0\n ...\n </denchmark-code>\n \n Both of these are placed on task:1 (aka rpi).\n Also, not just the tf.print, but all the ops in the loop (edit: both cond and body) are are placed incorrectly. Tested with tf.random.uniform.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "dhruvin2910", "commentT": "2020-10-21T08:22:38Z", "comment_text": "\n \t\ttf.cond and if ...: else: ... (with autograph) both have same problem.\n @tf.function\n def test_cond():\n     with tf.device(rpi):\n         def true_fn():\n             tf.print('rpi')\n             with tf.device(laptop):\n                 tf.print('laptop')\n \n         def false_fn():\n             tf.print('rpi')\n             with tf.device(laptop):\n                 tf.print('laptop')\n \n         tf.cond(tf.greater_equal(tf.random.uniform(()), 0.5), true_fn, false_fn)\n \n \n @tf.function\n def test_if():\n     with tf.device(rpi):\n         if tf.greater_equal(tf.random.uniform(()), 0.5):\n             tf.print('rpi')\n             with tf.device(laptop):\n                 tf.print('laptop')\n         else:\n             tf.print('rpi')\n             with tf.device(laptop):\n                 tf.print('laptop')\n No tf.print (or any other op placed via tf.device) will be placed on laptop\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "dhruvin2910", "commentT": "2020-10-21T09:02:29Z", "comment_text": "\n \t\tAfter a lot of experiments, here's a concise example of what is working and what is not.\n import tensorflow as tf\n \n # assume there's a tf.distribute.Server running on rpi.local:2222\n tf.config.experimental_connect_to_cluster(\n     tf.train.ClusterSpec({'worker': ['dhruvins-macbook-air.local:2222', 'rpi.local:2222']}),\n     job_name='worker',\n     task_index=0\n )\n \n laptop = '/job:worker/task:0'\n rpi = '/job:worker/task:1'\n \n \n @tf.function\n def works():\n     def true_fn():\n         # this tf.device will be respected\n         with tf.device(laptop):\n             tf.print('expected on', 'laptop')\n \n     def false_fn():\n         # this tf.device will be respected\n         with tf.device(rpi):\n             tf.print('expected on', 'rpi')\n \n     tf.cond(tf.constant(True), true_fn, false_fn)\n \n \n @tf.function\n def does_not_work():\n     # we enclose everything inside a tf.device\n     with tf.device(rpi):\n         def true_fn():\n             # this tf.device will be ignored\n             with tf.device(laptop):\n                 tf.print('expected on', 'laptop')\n \n         def false_fn():\n             # this tf.device will be ignored\n             with tf.device(rpi):\n                 tf.print('expected on', 'rpi')\n \n         # tf.cond is in tf.device now\n         tf.cond(tf.constant(True), true_fn, false_fn)\n \n \n works()\n does_not_work()\n Both calls must print 'expected on laptop' on laptop.\n But the second call (aka does_not_work) prints on rpi instead.\n <denchmark-link:https://github.com/mdanatg>@mdanatg</denchmark-link>\n  can you verify this?\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "dhruvin2910", "commentT": "2020-10-21T12:21:01Z", "comment_text": "\n \t\tThanks for the detailed investigation. We're having a closer look at the cause.\n Just to double check, in the last snippet you meant tf.device(laptop), right (since the outer device is already rpi)?\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "dhruvin2910", "commentT": "2020-10-21T14:59:19Z", "comment_text": "\n \t\t\n Just to double check, in the last snippet you meant tf.device(laptop), right (since the outer device is already rpi)?\n \n works used to flip a coin and printed on a device at random, but to make the code deterministic, I set the condition as True. So in the example false_fn is never evaluated and any of rpi or laptop would work.\n I tried to demonstrate that if you take a correctly behaving tf.cond code (works in our example), and wrap it with a tf.device, the ops inside true_fn and false_fn don't get distributed the way they were originally.\n All the ops are placed where tf.cond is placed.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "dhruvin2910", "commentT": "2020-10-22T00:56:12Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tensorflow/tensorflow/commit/d3698cdfd94c858092ebbb9af7ab0815e9bc78c1>d3698cd</denchmark-link>\n  should fix the  scope inheritance issue. It also has a test that ops don't always follow cond placement (even if there's a device scope around the cond).\n Please give it a try and re-open if something's still broken.\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "dhruvin2910", "commentT": "2020-10-22T00:56:14Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44011>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44011>No</denchmark-link>\n \n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "dhruvin2910", "commentT": "2020-10-22T04:33:08Z", "comment_text": "\n \t\tThank you so much <denchmark-link:https://github.com/allenlavoie>@allenlavoie</denchmark-link>\n . I'll see if the issue is fixed in the nightly (when the commit gets in nightly) and let you know.\n For my future reference, <denchmark-link:https://colab.research.google.com/gist/dhruvin2910/d8b0765a28b8182303105b29dd57262c/untitled445.ipynb#scrollTo=vFcc6P_S_ebz>colab</denchmark-link>\n \n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "dhruvin2910", "commentT": "2020-10-25T03:36:56Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/allenlavoie>@allenlavoie</denchmark-link>\n  I think the commit you added must have arrived in nightly.\n I have been trying to see if the issue is still there or not for 3 days, and the problem persists.\n See the colab above.\n PS: I'm unable to reopen this issue. <denchmark-link:https://github.com/mdanatg>@mdanatg</denchmark-link>\n  can you still reproduce the issue?\n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "dhruvin2910", "commentT": "2020-10-27T15:00:09Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/dhruvin2910>@dhruvin2910</denchmark-link>\n  I'm not sure if the issue can be accurately reproduced in the colab setup. IIUC, the colab doesn't see the output from any of the two cluster workers. At the same time, I suspect w1_proc will capture outputs from both workers.\n Looking at the op placement: print(test_while.get_concrete_function().graph.as_graph_def()), if we search for op: \"PrintV2\", I can see that the two Print ops are placed one on worker/task:0 and worker/task:1, as expected.\n I don't know if it's possible to configure a cluster that includes the current colab process. <denchmark-link:https://github.com/guptapriya>@guptapriya</denchmark-link>\n  ?\n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "dhruvin2910", "commentT": "2020-10-27T17:34:45Z", "comment_text": "\n \t\t\n I'm not sure if the issue can be accurately reproduced in the colab setup. IIUC, the colab doesn't see the output from any of the two cluster workers. At the same time, I suspect w1_proc will capture outputs from both workers.\n \n <denchmark-link:https://github.com/mdanatg>@mdanatg</denchmark-link>\n  I tried a simple  code (example below) and the workers (in the same colab) had correct outputs.\n @tf.function\n def test():\n     with tf.device(w0):\n       tf.print(\"This is a test print. Should be done on w0\")\n     with tf.device(w1):\n       tf.print(\"This is a test print. Should be done on w1\")\n \n Looking at the op placement: print(test_while.get_concrete_function().graph.as_graph_def()), if we search for op: \"PrintV2\", I can see that the two Print ops are placed one on worker/task:0 and worker/task:1, as expected.\n \n I mentioned exactly this in my previous <denchmark-link:https://github.com/tensorflow/tensorflow/issues/44011#issuecomment-713271763>#44011 (comment)</denchmark-link>\n . Ops in the graph have proper device assigned, but the ops are placed incorrectly at runtime. See this <denchmark-link:https://github.com/tensorflow/tensorflow/issues/44011#issuecomment-713360321>#44011 (comment)</denchmark-link>\n .\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "dhruvin2910", "commentT": "2020-10-27T17:50:30Z", "comment_text": "\n \t\tThanks, and sorry I missed those bits. I concur, there is a bug still present in the placement logic. I suggest updating the test colab to make that clearer:\n <denchmark-code>@tf.function\n def test_while():\n     with tf.device(w0):\n       tf.print('w0', 'control test')\n     with tf.device(w1):\n       ...\n </denchmark-code>\n \n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "dhruvin2910", "commentT": "2020-12-16T00:58:06Z", "comment_text": "\n \t\tThe second issue looks like it was related to function inlining (when inlining, the function's placement partially overrode the body's placement; conds were inlined as two functions). I have a change that should go through soon for that.\n Thank you for the report.\n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "dhruvin2910", "commentT": "2020-12-16T01:00:19Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44011>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44011>No</denchmark-link>\n \n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "dhruvin2910", "commentT": "2020-12-19T11:01:08Z", "comment_text": "\n \t\tThe issue seems to be fixed in 2.4 . Thanks <denchmark-link:https://github.com/mdanatg>@mdanatg</denchmark-link>\n  and <denchmark-link:https://github.com/allenlavoie>@allenlavoie</denchmark-link>\n .\n \t\t"}}}, "commit": {"commit_id": "1ce28a3f8a7670eda543176c7fe3a78b5db11a1e", "commit_author": "Allen Lavoie", "commitT": "2020-12-15 16:59:01-08:00", "commit_complexity": {"commit_NLOC": "0.9428571428571428", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\core\\common_runtime\\function_test.cc", "file_new_name": "tensorflow\\core\\common_runtime\\function_test.cc", "file_complexity": {"file_NLOC": "1934", "file_CCN": "101", "file_NToken": "19427"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1292", "deleted_lines": "1292", "method_info": {"method_name": "tensorflow::tensorflow::TEST_F.TEST_F", "method_params": "FunctionLibraryRuntimeTest,ExpandInlineFunctionsAndPlaceInlinedNodes", "method_startline": "1190", "method_endline": "1306", "method_complexity": {"method_NLOC": "91", "method_CCN": "3", "method_NToken": "715", "method_nesting_level": "4"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "1292", "deleted_lines": "1292", "method_info": {"method_name": "tensorflow::TEST_F", "method_params": "FunctionTest,WXPlusB", "method_startline": "136", "method_endline": "2390", "method_complexity": {"method_NLOC": "75", "method_CCN": "1", "method_NToken": "243", "method_nesting_level": "2"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\core\\common_runtime\\inline_function_utils.cc", "file_new_name": "tensorflow\\core\\common_runtime\\inline_function_utils.cc", "file_complexity": {"file_NLOC": "582", "file_CCN": "131", "file_NToken": "4614"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "234,235,236,241,246", "deleted_lines": "234,239,244", "method_info": {"method_name": "tensorflow::MultiDeviceFunctionBodyPlacer::BodyNodeDevice", "method_params": "ndef", "method_startline": "221", "method_endline": "251", "method_complexity": {"method_NLOC": "20", "method_CCN": "10", "method_NToken": "162", "method_nesting_level": "3"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 22, "file_old_name": "tensorflow\\python\\kernel_tests\\cond_v2_test.py", "file_new_name": "tensorflow\\python\\kernel_tests\\cond_v2_test.py", "file_complexity": {"file_NLOC": "1320", "file_CCN": "224", "file_NToken": "11138"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1579,1580,1581", "deleted_lines": "1580,1581", "method_info": {"method_name": "testDeviceBeforeCond._cond_wrapper2", "method_params": "", "method_startline": "1579", "method_endline": "1581", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "2"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "956,957", "deleted_lines": "956,957", "method_info": {"method_name": "testGradientTapeOfCondWithResourceVariableInFunction.testGradientTapeOfCondWithResourceVariableInFunction.fn_with_cond.true_fn", "method_params": "", "method_startline": "956", "method_endline": "957", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "13", "method_nesting_level": "4"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "301,302", "deleted_lines": "302", "method_info": {"method_name": "testDefunInCond.testDefunInCond.true_fn.fn", "method_params": "", "method_startline": "301", "method_endline": "302", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "12", "method_nesting_level": "4"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "1628,1629,1630", "deleted_lines": null, "method_info": {"method_name": "testDeviceBeforeRemote._wrapper2", "method_params": "", "method_startline": "1628", "method_endline": "1630", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "17", "method_nesting_level": "2"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "949,951,952,953,954,956,957,959,960,962,963,965", "deleted_lines": "948,949,950,951,953,954,956,957,959,960,962", "method_info": {"method_name": "testGradientTapeOfCondWithResourceVariableInFunction", "method_params": "self", "method_startline": "948", "method_endline": "965", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "32", "method_nesting_level": "1"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "1563,1564,1565", "deleted_lines": "1563,1565", "method_info": {"method_name": "testDeviceBeforeCond._cond_wrapper", "method_params": "", "method_startline": "1563", "method_endline": "1565", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "2"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "306,307", "deleted_lines": "306,307", "method_info": {"method_name": "testDefunInCond.false_fn", "method_params": "", "method_startline": "306", "method_endline": "307", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "8", "method_nesting_level": "3"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "952,953,954,956,957,959,960,962,963", "deleted_lines": "953,954,956,957,959,960,962", "method_info": {"method_name": "testGradientTapeOfCondWithResourceVariableInFunction.fn_with_cond", "method_params": "", "method_startline": "952", "method_endline": "963", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "56", "method_nesting_level": "2"}}}, "hunk_8": {"Ismethod": 1, "added_lines": "1609,1610,1611", "deleted_lines": null, "method_info": {"method_name": "testDeviceBeforeRemote._wrapper", "method_params": "", "method_startline": "1609", "method_endline": "1611", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "17", "method_nesting_level": "2"}}}, "hunk_9": {"Ismethod": 1, "added_lines": "298,300,301,302,304", "deleted_lines": "298,300,302,303", "method_info": {"method_name": "testDefunInCond.true_fn", "method_params": "", "method_startline": "298", "method_endline": "304", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "14", "method_nesting_level": "3"}}}, "hunk_10": {"Ismethod": 1, "added_lines": "1599,1600,1601,1602,1603,1604,1605,1606,1608,1609,1610,1611,1613,1614,1615,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634", "deleted_lines": "1599,1600,1601,1602,1603,1604", "method_info": {"method_name": "testDeviceBeforeRemote", "method_params": "self,functional_op_to_test", "method_startline": "1599", "method_endline": "1634", "method_complexity": {"method_NLOC": "15", "method_CCN": "1", "method_NToken": "112", "method_nesting_level": "1"}}}, "hunk_11": {"Ismethod": 1, "added_lines": "1602,1603,1604,1605,1606", "deleted_lines": "1602,1603,1604", "method_info": {"method_name": "testDeviceBeforeRemote._fn", "method_params": "", "method_startline": "1602", "method_endline": "1606", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "30", "method_nesting_level": "2"}}}, "hunk_12": {"Ismethod": 1, "added_lines": "1554,1555,1556,1557,1558,1559,1560,1562,1563,1564,1565,1567,1568,1569,1570,1571,1573,1574,1575,1576,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588", "deleted_lines": "1552,1553,1554,1556,1557,1558,1559,1561,1562,1563,1565,1566,1567,1569,1570,1571,1572,1574,1575,1576,1577,1578,1580,1581,1583,1584,1585,1586,1587", "method_info": {"method_name": "testDeviceBeforeCond", "method_params": "self", "method_startline": "1552", "method_endline": "1588", "method_complexity": {"method_NLOC": "18", "method_CCN": "2", "method_NToken": "140", "method_nesting_level": "1"}}}, "hunk_13": {"Ismethod": 1, "added_lines": "1467,1475,1476", "deleted_lines": null, "method_info": {"method_name": "setUp", "method_params": "self", "method_startline": "1466", "method_endline": "1476", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "86", "method_nesting_level": "1"}}}, "hunk_14": {"Ismethod": 1, "added_lines": "1573,1574,1575,1576", "deleted_lines": "1574,1575,1576", "method_info": {"method_name": "testDeviceBeforeCond.fn2", "method_params": "", "method_startline": "1573", "method_endline": "1576", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "2"}}}, "hunk_15": {"Ismethod": 1, "added_lines": "1621,1622,1623,1624,1625", "deleted_lines": null, "method_info": {"method_name": "testDeviceBeforeRemote._fn2", "method_params": "", "method_startline": "1621", "method_endline": "1625", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "30", "method_nesting_level": "2"}}}, "hunk_16": {"Ismethod": 1, "added_lines": "294,295,296,298,300,301,302,304,306,307,309,310,311", "deleted_lines": "294,296,297,298,300,302,303,305,306,307", "method_info": {"method_name": "testDefunInCond", "method_params": "self", "method_startline": "293", "method_endline": "311", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "86", "method_nesting_level": "1"}}}, "hunk_17": {"Ismethod": 1, "added_lines": "1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659", "deleted_lines": null, "method_info": {"method_name": "testColocationBeforeCond", "method_params": "self", "method_startline": "1636", "method_endline": "1659", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "56", "method_nesting_level": "1"}}}, "hunk_18": {"Ismethod": 1, "added_lines": "1638,1639,1640,1641,1642", "deleted_lines": null, "method_info": {"method_name": "testColocationBeforeCond._fn", "method_params": "", "method_startline": "1638", "method_endline": "1642", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "34", "method_nesting_level": "2"}}}, "hunk_19": {"Ismethod": 1, "added_lines": "959,960", "deleted_lines": "959,960", "method_info": {"method_name": "testGradientTapeOfCondWithResourceVariableInFunction.testGradientTapeOfCondWithResourceVariableInFunction.fn_with_cond.false_fn", "method_params": "", "method_startline": "959", "method_endline": "960", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "6", "method_nesting_level": "4"}}}, "hunk_20": {"Ismethod": 1, "added_lines": "1554,1555,1556,1557,1558,1559,1560", "deleted_lines": "1554,1556,1557,1558,1559", "method_info": {"method_name": "testDeviceBeforeCond.fn", "method_params": "", "method_startline": "1554", "method_endline": "1560", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "50", "method_nesting_level": "2"}}}, "hunk_21": {"Ismethod": 1, "added_lines": "1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655", "deleted_lines": null, "method_info": {"method_name": "testColocationBeforeCond._cond_wrapper", "method_params": "", "method_startline": "1645", "method_endline": "1655", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "96", "method_nesting_level": "2"}}}}}}}}