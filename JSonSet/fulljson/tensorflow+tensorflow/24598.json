{"BR": {"BR_id": "24598", "BR_author": "ufukcbicici", "BRopenT": "2018-12-27T11:53:09Z", "BRcloseT": "2018-12-28T00:12:24Z", "BR_text": {"BRsummary": "Potential tf.boolean_mask bug when the mask array is empty", "BRdescription": "\n System information\n \n OS Platform and Distribution : Windows 10\n TensorFlow installed from (source or binary): Binary\n TensorFlow version (use command below): 1.11.0\n Python version: 3.6.6\n CUDA/cuDNN version: V8.0.60\n GPU model and memory: Geforce GTX 1070 8GB\n \n \n I have actually experiencing almost the similar problem like in thread:  <denchmark-link:https://github.com/tensorflow/tensorflow/issues/24585>#24585</denchmark-link>\n \n Again, I want to partition a minibatch into different parts, process them in parallel using different computation units and then stitch them back together. However this time I used  instead of  for the partition operation, since the latter runs into problems when one of the partitions is empty. This code is below (it is copy&paste reproducible):\n <denchmark-code>import tensorflow as tf\n import numpy as np\n \n \n def build_conv_layer(input, filter_size, num_of_input_channels, num_of_output_channels, name_suffix=\"\"):\n     # OK\n     conv_weights = tf.Variable(\n         tf.truncated_normal([filter_size, filter_size, num_of_input_channels, num_of_output_channels],\n                             stddev=0.1, dtype=tf.float32))\n     # OK\n     conv_biases = tf.Variable(\n         tf.constant(0.1, shape=[num_of_output_channels], dtype=tf.float32))\n     conv = tf.nn.conv2d(input, conv_weights, strides=[1, 1, 1, 1], padding='SAME')\n     relu = tf.nn.relu(tf.nn.bias_add(conv, conv_biases))\n     pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n     return pool\n \n \n batch_size = 250\n child_count = 3\n channel_count = 32\n \n dataTensor = tf.placeholder(tf.float32, shape=(None, 28, 28, 1), name=\"dataTensor\")\n indices_tensor = tf.placeholder(name=\"indices_tensor\", dtype=tf.int32)\n batch_size_tensor = tf.placeholder(name=\"batch_size_tensor\", dtype=tf.int32)\n \n condition_indices_list = []\n partition_list = []\n mask_list = []\n for child_index in range(child_count):\n     mask_indices = tf.reshape(indices_tensor[:, child_index], [-1])\n     condition_indices = tf.boolean_mask(tf.range(batch_size_tensor), mask_indices)\n     partition = tf.boolean_mask(dataTensor, mask_indices)\n     mask_list.append(mask_indices)\n     condition_indices_list.append(condition_indices)\n     partition_list.append(partition)\n \n transformed_list = [build_conv_layer(input=part, filter_size=5, num_of_input_channels=1, num_of_output_channels=32)\n                     for part in partition_list]\n squared_list = [tf.square(part) for part in partition_list]\n stitched_conv_transform = tf.dynamic_stitch(indices=condition_indices_list, data=transformed_list)\n stitched_square_transform = tf.dynamic_stitch(indices=condition_indices_list, data=squared_list)\n sum = tf.reduce_sum(stitched_square_transform)\n grads = tf.gradients(sum, dataTensor)\n \n sess = tf.Session()\n samples = np.random.uniform(size=(batch_size, 28, 28, 1))\n indices_arr = np.zeros(shape=(batch_size, child_count), dtype=np.int32)\n indices_arr[:, 0] = 1\n indices_arr[-2] = np.array([0, 1, 0])\n indices_arr[-1] = np.array([0, 1, 0])\n \n feed_dict = {dataTensor: samples,\n              batch_size_tensor: batch_size,\n              # indices_tensor: np.argmax(np.random.uniform(size=(GlobalConstants.EVAL_BATCH_SIZE, child_count)), axis=1)}\n              indices_tensor: indices_arr}\n outputs = []\n outputs.extend(mask_list)\n outputs.extend(transformed_list)\n outputs.extend(squared_list)\n outputs.append(stitched_conv_transform)\n outputs.append(stitched_square_transform)\n outputs.append(sum)\n outputs.append(grads)\n \n init = tf.global_variables_initializer()\n sess.run(init)\n for i in range(10000):\n     results = sess.run(outputs, feed_dict=feed_dict)\n     assert np.allclose(results[-1][0], 2.0*samples)\n     print(\"{0} runned.\".format(i))\n </denchmark-code>\n \n To my disappointment, tf.boolean_mask runs into a similar problem, when indices_arr  contains no references to at least one partition and it produces an empty array for that partition as the result. The for loop in the end runs correctly a few times but then the program crashes with the following error:\n \n InternalError (see above for traceback): WhereOp: Could not launch cub::DeviceReduce::Sum to count number of true / nonzero indices.  temp_storage_bytes: 1, status: invalid configuration argument\n [[{{node boolean_mask/Where}} = WhereT=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]]\n [[{{node DynamicStitch/_49}} = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_259_DynamicStitch\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]\n \n I think this is the same error underlying the problem in <denchmark-link:https://github.com/tensorflow/tensorflow/issues/24585>#24585</denchmark-link>\n  where it crashes when  receives an empty index array since they could be using the same mechanism in the cub library (or whatever cub is). The  error also occurs after a few succesfull iterations like this one. What could be the reason here?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ufukcbicici", "commentT": "2018-12-27T22:16:21Z", "comment_text": "\n \t\tI was able to run your code snippet successfully on cpu however interestingly it failed computing on gpu.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ufukcbicici", "commentT": "2018-12-27T23:39:30Z", "comment_text": "\n \t\tIndeed this is a bug, fixed by pinning Where to the CPU. I'm submitting a patch soon.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ufukcbicici", "commentT": "2018-12-28T06:12:11Z", "comment_text": "\n \t\tThank you <denchmark-link:https://github.com/alextp>@alextp</denchmark-link>\n  . How can I get the fix now?\n \t\t"}}}, "commit": {"commit_id": "961e9f4505dff0c5a91d12b1f4e476b3cf2d295d", "commit_author": "Alexandre Passos", "commitT": "2018-12-27 16:10:57-08:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\core\\kernels\\where_op.cc", "file_new_name": "tensorflow\\core\\kernels\\where_op.cc", "file_complexity": {"file_NLOC": "211", "file_CCN": "16", "file_NToken": "1442"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "140,141,142,143", "deleted_lines": "140,141", "method_info": {"method_name": "tensorflow::WhereCPUOp::Compute", "method_params": "context", "method_startline": "128", "method_endline": "189", "method_complexity": {"method_NLOC": "41", "method_CCN": "1", "method_NToken": "265", "method_nesting_level": "2"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow\\core\\kernels\\where_op.h", "file_new_name": "tensorflow\\core\\kernels\\where_op.h", "file_complexity": {"file_NLOC": "23", "file_CCN": "0", "file_NToken": "125"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": "30"}}}}}}