{"BR": {"BR_id": "27829", "BR_author": "ageron", "BRopenT": "2019-04-14T07:26:47Z", "BRcloseT": "2019-06-04T21:12:40Z", "BR_text": {"BRsummary": "Cannot create a stateful RNN with recurrent dropout", "BRdescription": "\n System information\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\n Yes\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n MacOSX 10.13.6\n Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\n N/A\n TensorFlow installed from (source or binary):\n binary\n TensorFlow version (use command below):\n tf.version.VERSION=2.0.0-dev20190413\n tf.version.GIT_VERSION=v1.12.0-12481-gc7ce6f4cd9\n Python version:\n 3.6.8\n Bazel version (if compiling from source):\n N/A\n GCC/Compiler version (if compiling from source):\n N/A\n CUDA/cuDNN version:\n N/A\n GPU model and memory:\n N/A\n \n Describe the current behavior\n I get an exception when trying to use recurrent_dropout in a stateful RNN:\n <denchmark-code>.../tensorflow/python/ops/resource_variable_ops.py in __imul__(self, unused_other)\n    1449\n    1450   def __imul__(self, unused_other):\n -> 1451     raise RuntimeError(\"Variable *= value not supported. Use \"\n    1452                        \"`var.assign(var * value)` to modify the variable or \"\n    1453                        \"`var = var * value` to get a new Tensor object.\")\n \n RuntimeError: Variable *= value not supported. Use `var.assign(var * value)` to modify the variable or `var = var * value` to get a new Tensor object.\n </denchmark-code>\n \n The full stacktrace is below.\n Describe the expected behavior\n No exception.\n Code to reproduce the issue\n from tensorflow import keras\n \n model = keras.models.Sequential([\n     keras.layers.GRU(128, return_sequences=True, stateful=True,\n                      batch_input_shape=[32, None, 5],\n                      recurrent_dropout=0.2)\n ])\n Other info / logs\n Complete stacktrace:\n <denchmark-code>---------------------------------------------------------------------------\n RuntimeError                              Traceback (most recent call last)\n <ipython-input-1-3e98e7412ec2> in <module>\n       4     keras.layers.GRU(128, return_sequences=True, stateful=True,\n       5                      batch_input_shape=[32, None, 5],\n ----> 6                      recurrent_dropout=0.2)\n       7 ])\n \n .../tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\n     456     self._self_setattr_tracking = False  # pylint: disable=protected-access\n     457     try:\n --> 458       result = method(self, *args, **kwargs)\n     459     finally:\n     460       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\n \n .../tensorflow/python/keras/engine/sequential.py in __init__(self, layers, name)\n     106     if layers:\n     107       for layer in layers:\n --> 108         self.add(layer)\n     109\n     110   @property\n \n .../tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\n     456     self._self_setattr_tracking = False  # pylint: disable=protected-access\n     457     try:\n --> 458       result = method(self, *args, **kwargs)\n     459     finally:\n     460       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access\n \n .../tensorflow/python/keras/engine/sequential.py in add(self, layer)\n     167           # and create the node connecting the current layer\n     168           # to the input layer we just created.\n --> 169           layer(x)\n     170           set_inputs = True\n     171\n \n .../tensorflow/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)\n     620\n     621     if initial_state is None and constants is None:\n --> 622       return super(RNN, self).__call__(inputs, **kwargs)\n     623\n     624     # If any of `initial_state` or `constants` are specified and are Keras\n \n .../tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\n     631                       base_layer_utils.AutoAddUpdates(self,\n     632                                                       inputs)) as auto_updater:\n --> 633                 outputs = call_fn(inputs, *args, **kwargs)\n     634                 auto_updater.set_outputs(outputs)\n     635\n \n .../tensorflow/python/keras/layers/recurrent_v2.py in call(self, inputs, mask, training, initial_state)\n     328           input_length=timesteps,\n     329           time_major=self.time_major,\n --> 330           zero_output_for_mask=self.zero_output_for_mask)\n     331       # This is a dummy tensor for testing purpose.\n     332       runtime = _runtime('unknown')\n \n .../tensorflow/python/keras/backend.py in rnn(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\n    3558     # the value is discarded.\n    3559     output_time_zero, _ = step_function(input_time_zero,\n -> 3560                                         initial_states + constants)\n    3561     output_ta = tuple(\n    3562         tensor_array_ops.TensorArray(\n \n .../tensorflow/python/keras/layers/recurrent_v2.py in step(cell_inputs, cell_states)\n     316\n     317       def step(cell_inputs, cell_states):\n --> 318         return self.cell.call(cell_inputs, cell_states, **kwargs)\n     319\n     320       last_output, outputs, states = K.rnn(\n \n .../tensorflow/python/keras/layers/recurrent.py in call(self, inputs, states, training)\n    1706\n    1707       if 0. < self.recurrent_dropout < 1.:\n -> 1708         h_tm1 *= rec_dp_mask[0]\n    1709\n    1710       if self.reset_after:\n \n .../tensorflow/python/ops/resource_variable_ops.py in __imul__(self, unused_other)\n    1449\n    1450   def __imul__(self, unused_other):\n -> 1451     raise RuntimeError(\"Variable *= value not supported. Use \"\n    1452                        \"`var.assign(var * value)` to modify the variable or \"\n    1453                        \"`var = var * value` to get a new Tensor object.\")\n \n RuntimeError: Variable *= value not supported. Use `var.assign(var * value)` to modify the variable or `var = var * value` to get a new Tensor object.\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ageron", "commentT": "2019-04-16T10:41:41Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ageron>@ageron</denchmark-link>\n  In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ageron", "commentT": "2019-04-16T12:52:33Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/muddham>@muddham</denchmark-link>\n  ,\n I did! It's in the section \"Code to reproduce the issue\". :)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ageron", "commentT": "2019-04-18T21:29:56Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ageron>@ageron</denchmark-link>\n  I tried to reproduce the bug in TF2.0.0-alpha0 but I don't get the runtime error. I see a warning and a deprecation message as follows. Just for your info, I ran your code in Google colab\n WARNING: Logging before flag parsing goes to stderr.\n W0418 17:16:01.808634 139806816728960 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4081: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n Instructions for updating:\n Please use rate instead of keep_prob. Rate should be set to rate = 1 - keep_prob.\n Please let me know what you think. Thanks!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "ageron", "commentT": "2019-04-19T05:06:08Z", "comment_text": "\n \t\tApparently the problem is now fixed, I don't get the error anymore.  Thanks <denchmark-link:https://github.com/jvishnuvardhan>@jvishnuvardhan</denchmark-link>\n  .\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "ageron", "commentT": "2019-04-19T05:06:09Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27829>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27829>No</denchmark-link>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "ageron", "commentT": "2019-05-24T20:58:00Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ageron>@ageron</denchmark-link>\n  does it still work for you? I tried using recurrent_dropout with a GRU (as you are) and it seems to break for me. The problem seems to be with recurrent_dropout, cos if you switch it out everything seems to work. This problem also exists with LSTMs, and not just GRUs.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "ageron", "commentT": "2019-05-25T01:29:56Z", "comment_text": "\n \t\tApparently the bug is back. Using VERSION='2.0.0-dev20190524' and GIT_VERSION='v1.12.1-2720-geafe861c2b'.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "ageron", "commentT": "2019-05-28T19:02:20Z", "comment_text": "\n \t\tI am also having a similar issue. Was wondering if there was an update or an older nightly where this is stable?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "ageron", "commentT": "2019-05-29T04:19:01Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jlanday>@jlanday</denchmark-link>\n  , it worked when I posted my comment on April 19th, so perhaps try a nightly from April 18th or 19th?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "ageron", "commentT": "2019-05-29T16:10:55Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ageron>@ageron</denchmark-link>\n  I tried to use the nightly version from both April 18th and 19th and it looks like it still doesn't work. Does version  work for you?\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "ageron", "commentT": "2019-05-29T17:40:35Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ageron>@ageron</denchmark-link>\n  I don't see any error with . Gist is <denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/4b32a507c8209a95d38335e8efc3e231/untitled203.ipynb>here</denchmark-link>\n .\n But I notice error is back with    pip install tf-nightly-gpu-2.0-preview==2.0.0-dev20190518 Thanks!\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "ageron", "commentT": "2019-06-04T17:12:17Z", "comment_text": "\n \t\tThanks for reporting the issue, will send a fix very soon.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "ageron", "commentT": "2019-06-04T21:12:37Z", "comment_text": "\n \t\tShould now be fixed by <denchmark-link:https://github.com/tensorflow/tensorflow/commit/6a6e8c2586dfd2aeeebe0d94d60dcca4604ab481>6a6e8c2</denchmark-link>\n .\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "ageron", "commentT": "2019-06-04T21:12:41Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27829>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27829>No</denchmark-link>\n \n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "ageron", "commentT": "2019-06-21T01:13:54Z", "comment_text": "\n \t\tdef build_cell(self):\n <denchmark-code>    char_input = self.tf.keras.layers.Input(shape=(1), batch_size=1, name=\"char_input\", dtype=self.tf.int32)\n     char_input_one_hot = self.tf.keras.backend.one_hot(char_input, self.vocab_size)\n     previous_hidden_state_input = self.tf.keras.layers.Input(shape=(self.num_units), batch_size=1, name=\"previous_hidden_state_input\")\n     previous_cell_state_input = self.tf.keras.layers.Input(shape=(self.num_units), batch_size=1, name=\"previous_cell_state_input\")`\n     \n     \n     hidden_input_stacked = self.tf.keras.layers.concatenate([self.tf.keras.backend.squeeze(char_input_one_hot, axis=1), previous_hidden_state_input], axis=1)\n     #Forget gate\n     forget_gate_f = self.tf.keras.layers.Dense(units=self.num_units, activation=\"sigmoid\")(hidden_input_stacked) #Helps us to take decisions about what must be removed from previous hidden state\n     #Input gate\n     input_gate_i = self.tf.keras.layers.Dense(units=self.num_units, activation=\"sigmoid\")(hidden_input_stacked) #Decides which values to update\n     input_gate_g = self.tf.keras.layers.Dense(units=self.num_units, activation=\"tanh\")(hidden_input_stacked)  #Creates a vector for new candidates to added to present cell state.\n     #Output_gate\n     output_state_o = self.tf.keras.layers.Dense(units=self.num_units, activation=\"sigmoid\")(hidden_input_stacked)\n     #Current cell state\n     current_cell_state = self.tf.keras.layers.add([self.tf.keras.layers.multiply([input_gate_g,input_gate_i]),self.tf.keras.layers.multiply([previous_cell_state_input,forget_gate_f])], name=\"current_cell_state\")\n     #output_hidden_state\n     output_hidden_state = self.tf.keras.layers.multiply([self.tf.keras.layers.Activation(\"tanh\")(current_cell_state), output_state_o], name=\"output_hidden_state\")\n     #output_char_probs\n     output_char_probs = self.tf.keras.layers.Dense(units=self.vocab_size, activation=\"softmax\", name=\"output_char_probs\")(output_hidden_state)\n     \n     cell = self.tf.keras.Model(inputs=[char_input, previous_hidden_state_input, previous_cell_state_input], outputs=[output_char_probs, output_hidden_state, current_cell_state])\n     return cell`\n </denchmark-code>\n \n This code will break tensorflow 2.0, I found the problem to be in tensorflow/tensorflow/python/keras/layers/merge.py  / with the add and multiply functions. Please fix\n The error I received trying to feed input in:\n \n raise RuntimeError(\"Variable *= value not supported. Use \"\n RuntimeError: Variable *= value not supported. Use `var.assign(var * value)` to modify the variable >     or `var = var * value` to get a new Tensor object.\n \n \n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "ageron", "commentT": "2019-12-31T01:34:46Z", "comment_text": "\n \t\tCan the line:\n \n \n \n tensorflow/tensorflow/python/keras/layers/merge.py\n \n \n          Line 245\n       in\n       3a094e6\n \n \n \n \n \n \n  output += inputs[i] \n \n \n \n \n \n be changed to\n output = output + inputs[i]\n to fix this?\n (and similar within Subtract etc.)\n It doesn't like the += notation when applied to a tf.Variable\n \t\t"}}}, "commit": {"commit_id": "6a6e8c2586dfd2aeeebe0d94d60dcca4604ab481", "commit_author": "Scott Zhu", "commitT": "2019-06-04 13:56:56-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\keras\\layers\\recurrent.py", "file_new_name": "tensorflow\\python\\keras\\layers\\recurrent.py", "file_complexity": {"file_NLOC": "2298", "file_CCN": "290", "file_NToken": "10911"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1213", "deleted_lines": "1213", "method_info": {"method_name": "call", "method_params": "self,inputs,states,training", "method_startline": "1199", "method_endline": "1218", "method_complexity": {"method_NLOC": "17", "method_CCN": "5", "method_NToken": "140", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\python\\keras\\layers\\recurrent_v2.py", "file_new_name": "tensorflow\\python\\keras\\layers\\recurrent_v2.py", "file_complexity": {"file_NLOC": "855", "file_CCN": "61", "file_NToken": "3753"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "847", "deleted_lines": "847", "method_info": {"method_name": "call", "method_params": "self,inputs,mask,training,initial_state", "method_startline": "807", "method_endline": "927", "method_complexity": {"method_NLOC": "88", "method_CCN": "17", "method_NToken": "543", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "370", "deleted_lines": "370", "method_info": {"method_name": "_defun_gru_call", "method_params": "self,inputs,initial_state,training,mask", "method_startline": "362", "method_endline": "425", "method_complexity": {"method_NLOC": "48", "method_CCN": "9", "method_NToken": "301", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\keras\\layers\\recurrent_v2_test.py", "file_new_name": "tensorflow\\python\\keras\\layers\\recurrent_v2_test.py", "file_complexity": {"file_NLOC": "70", "file_CCN": "7", "file_NToken": "529"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "93,94,95,96,97,98,99,100", "deleted_lines": null, "method_info": {"method_name": "test_recurrent_dropout_with_stateful_RNN", "method_params": "self,layer", "method_startline": "93", "method_endline": "100", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "50", "method_nesting_level": "1"}}}}}}}}