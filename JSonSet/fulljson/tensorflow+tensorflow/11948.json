{"BR": {"BR_id": "11948", "BR_author": "riklopfer", "BRopenT": "2017-08-01T18:52:55Z", "BRcloseT": "2018-02-03T01:35:39Z", "BR_text": {"BRsummary": "Memory leak in Java API when using GPU", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n Custom code: https://github.com/riklopfer/TensorflowJavaGpuMemoryTest\n OS: CentOS 7\n TensorFlow installed from (source or binary): binary\n TensorFlow version (use command below): n/a\n Python version: n/a\n Bazel version (if compiling from source): n/a\n CUDA/cuDNN version: 8.0\n GPU model and memory: GeForce GTX 1080\n Exact command to reproduce: see https://github.com/riklopfer/TensorflowJavaGpuMemoryTest\n \n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n Main memory on the machine is continuously consumed when running on the GPU. Memory consumption hovers around 600M when running on the CPU.\n <denchmark-h:h3>Source code / logs</denchmark-h>\n \n see: <denchmark-link:https://github.com/riklopfer/TensorflowJavaGpuMemoryTest>https://github.com/riklopfer/TensorflowJavaGpuMemoryTest</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "riklopfer", "commentT": "2017-08-02T18:00:17Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/asimshankar>@asimshankar</denchmark-link>\n  could you please take a look at this.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "riklopfer", "commentT": "2017-08-29T19:10:22Z", "comment_text": "\n \t\tSample log output fwiw,\n <denchmark-code>2017-08-29 14:30:27.963729: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-08-29 14:30:27.963779: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-08-29 14:30:27.963788: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n 2017-08-29 14:30:27.963795: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n 2017-08-29 14:30:27.963802: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n 2017-08-29 14:30:29.569904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \n name: GeForce GTX 1080\n major: 6 minor: 1 memoryClockRate (GHz) 1.7335\n pciBusID 0000:01:00.0\n Total memory: 7.92GiB\n Free memory: 7.81GiB\n 2017-08-29 14:30:29.569957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \n 2017-08-29 14:30:29.569965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \n 2017-08-29 14:30:29.569981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "riklopfer", "commentT": "2017-08-30T16:04:36Z", "comment_text": "\n \t\tI've added <denchmark-link:http://valgrind.org/info/tools.html#memcheck>valgrind</denchmark-link>\n  output to the test repository: <denchmark-link:https://github.com/riklopfer/TensorflowJavaGpuMemoryTest/blob/master/valgrind.out>https://github.com/riklopfer/TensorflowJavaGpuMemoryTest/blob/master/valgrind.out</denchmark-link>\n \n I'm not really familiar with this tool, but it seems like it would be useful. The summary makes me think that there definitely is a leak somewhere\n <denchmark-code>==28997== LEAK SUMMARY:\n ==28997==    definitely lost: 257,022 bytes in 1,028 blocks\n ==28997==    indirectly lost: 6,840 bytes in 15 blocks\n ==28997==      possibly lost: 61,716,234 bytes in 14,975 blocks\n ==28997==    still reachable: 397,427,506 bytes in 261,680 blocks\n ==28997==                       of which reachable via heuristic:\n ==28997==                         stdstring          : 2,034,837 bytes in 43,856 blocks\n ==28997==                         newarray           : 22,536 bytes in 1 blocks\n ==28997==         suppressed: 0 bytes in 0 blocks\n ==28997== Reachable blocks (those to which a pointer was found) are not shown.\n ==28997== To see them, rerun with: --leak-check=full --show-leak-kinds=all\n ==28997== \n ==28997== For counts of detected and suppressed errors, rerun with: -v\n ==28997== ERROR SUMMARY: 1011246 errors from 460 contexts (suppressed: 0 from 0)\n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "riklopfer", "commentT": "2017-08-30T16:45:52Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/riklopfer>@riklopfer</denchmark-link>\n  : Thanks very much for getting that information across. Unfortunately not a lot struck out to me.\n I did see 32 bytes of leaks from graph construction, which I will fix, but that happens once - not in a loop so won't explain the increasing usage over time.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "riklopfer", "commentT": "2017-08-30T23:12:20Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/asimshankar>@asimshankar</denchmark-link>\n  thanks for the fixes. Were you able to reproduce the issue of ever-increasing memory consumption? Any idea what the next steps might be?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "riklopfer", "commentT": "2017-08-31T19:01:20Z", "comment_text": "\n \t\tUpdating CUDA and Nvidia drivers seems to have greatly mitigated the problem for me. I added <denchmark-link:https://github.com/riklopfer/TensorflowJavaGpuMemoryTest/blob/master/updated-valgrind.out>updated valgrind output</denchmark-link>\n  to the test repo.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "riklopfer", "commentT": "2017-09-01T17:06:40Z", "comment_text": "\n \t\tThanks for the update <denchmark-link:https://github.com/riklopfer>@riklopfer</denchmark-link>\n \n Sampling the latest output, I'm not sure if there are false positives or actual leaks (e.g., many leaks are reported in , which IIUC has nothing to do with TensorFlow, it's just JVM initialization.\n When you say \"greatly mitigated\", are you still seeing a monotonic increase in memory usage over time, or does it stabilize?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "riklopfer", "commentT": "2017-09-06T15:01:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/asimshankar>@asimshankar</denchmark-link>\n  I no longer see monotonic increase in memory consumption when running my the small test  in the linked repo. However, when I run a longer, more complicated graph on the GPU, it is killed by the OOM killer. I wasn't able to get a valgrind dump for that process. When I have time, I will try increasing the complexity of the test graph until it shows the problem again (or not).\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "riklopfer", "commentT": "2017-12-20T01:17:05Z", "comment_text": "\n \t\tIt has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue? Please update the label and/or status accordingly.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "riklopfer", "commentT": "2017-12-20T15:55:08Z", "comment_text": "\n \t\tRunning with 1.4.0, I still see a slow, monotonic increase in memory consumption. I haven't had a chance to attempt to minimally reproduce the issue.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "riklopfer", "commentT": "2018-01-04T19:05:47Z", "comment_text": "\n \t\tIt has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue? Please update the label and/or status accordingly.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "riklopfer", "commentT": "2018-01-23T23:18:11Z", "comment_text": "\n \t\tThe original poster has replied to this issue after the stat:awaiting response label was applied.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "riklopfer", "commentT": "2018-02-03T01:35:39Z", "comment_text": "\n \t\tClosing since the original issue has been fixed. Please file another ticket with a repro if you can. Thanks!\n \t\t"}}}, "commit": {"commit_id": "03d310cc61a864600d24977f73138e643659986c", "commit_author": "Asim Shankar", "commitT": "2017-08-30 12:35:06-07:00", "commit_complexity": {"commit_NLOC": "0.5", "commit_CCN": "1.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tensorflow\\java\\src\\main\\native\\operation_builder_jni.cc", "file_new_name": "tensorflow\\java\\src\\main\\native\\operation_builder_jni.cc", "file_complexity": {"file_NLOC": "213", "file_CCN": "43", "file_NToken": "1791"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "78,81", "deleted_lines": null, "method_info": {"method_name": "Java_org_tensorflow_OperationBuilder_finish", "method_params": "env,clazz,handle", "method_startline": "71", "method_endline": "83", "method_complexity": {"method_NLOC": "13", "method_CCN": "3", "method_NToken": "86", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "240", "deleted_lines": null, "method_info": {"method_name": "Java_org_tensorflow_OperationBuilder_setAttrTensorList", "method_params": "env,clazz,handle,name,tensor_handles", "method_startline": "220", "method_endline": "242", "method_complexity": {"method_NLOC": "22", "method_CCN": "5", "method_NToken": "207", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "266,267,275,276,280,281", "deleted_lines": "270,271,275", "method_info": {"method_name": "Java_org_tensorflow_OperationBuilder_setAttrStringList", "method_params": "env,object,handle,name,values", "method_startline": "265", "method_endline": "292", "method_complexity": {"method_NLOC": "27", "method_CCN": "4", "method_NToken": "293", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "216", "deleted_lines": null, "method_info": {"method_name": "Java_org_tensorflow_OperationBuilder_setAttrTensor", "method_params": "env,clazz,handle,name,tensor_handle", "method_startline": "205", "method_endline": "218", "method_complexity": {"method_NLOC": "14", "method_CCN": "3", "method_NToken": "112", "method_nesting_level": "0"}}}}}}}}