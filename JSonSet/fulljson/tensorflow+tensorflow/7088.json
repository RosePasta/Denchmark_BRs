{"BR": {"BR_id": "7088", "BR_author": "bazinac", "BRopenT": "2017-01-26T10:34:02Z", "BRcloseT": "2017-01-28T08:48:20Z", "BR_text": {"BRsummary": "Running optimized graph with two output nodes on android gives \u201cSession was not created with a graph before Run()\u201d error.", "BRdescription": "\n Hi, please would you please be so kind and help me with one issue that prevents me from moving forward. I have graph with two output layers (final_result_orig \u2013 which is basically coming form retraining example,final_result_added \u2013 my custom layer) and I am unable to strip/optimize_on_inference it in order to run on android device (on pc it runs fine)\n When I run:\n bazel-bin/tensorflow/python/tools/optimize_for_inference \n \u2013input=/tmp/output.pb \n \u2013output=/tmp/optimized.pb \n \u2013input_names=Mul \n \u2013output_names=\u201dfinal_result_orig,final_result_added\u201d\n Then in my android application, I get \u201cSession was not created with a graph before Run()\u201d error, and both final_result_orig and final_result_added are not found.\n When I run:\n bazel-bin/tensorflow/python/tools/optimize_for_inference \n \u2013input=/tmp/output.pb \n \u2013output=/tmp/optimized.pb \n \u2013input_names=Mul \n \u2013output_names=\u201dfinal_result_orig\u201d\n It works fine, final_result_orig is available and works correctly, however final_result_added is obviously not found and not available for my app to use.\n And when I run:\n bazel-bin/tensorflow/python/tools/optimize_for_inference \n \u2013input=/tmp/output.pb \n \u2013output=/tmp/optimized.pb \n \u2013input_names=Mul \n \u2013output_names=\u201dfinal_result_added\u201d\n It does not work as well with \u201cSession was not created with a graph before Run()\u201d error, and both final_result_orig and final_result_added are not found.\n I do not understand what I am doing wrong \u2013 what could be wrong with \u201cfinal_result_added\u201d, as it works fine on PC and not android? Thank you very much.\n <denchmark-h:h2>What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?</denchmark-h>\n \n <denchmark-link:https://github.com/tensorflow/tensorflow/issues/5553>#5553</denchmark-link>\n \n <denchmark-h:h2>Environment info</denchmark-h>\n \n Ubuntu 16.04 + Android 6.0\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "bazinac", "commentT": "2017-01-26T16:39:20Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/bazinac>@bazinac</denchmark-link>\n  Are you using a recent version of TensorFlow? The loading code has been improved recently to give more descriptive errors when something goes wrong. I'd suggest syncing first and then seeing what it says.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "bazinac", "commentT": "2017-01-26T23:03:52Z", "comment_text": "\n \t\tUnfortunatelly, after installing latest Tensorflow, I am strangely unable to even build optimize_for_inference script with\n `Traceback (most recent call last):\n File \"/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/tools/optimize_for_inference.py\", line 65, in \n from tensorflow.python.framework import dtypes\n File \"/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/init.py\", line 72, in \n raise ImportError(msg)\n ImportError: Traceback (most recent call last):\n File \"/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/init.py\", line 61, in \n from tensorflow.python import pywrap_tensorflow\n File \"/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 28, in \n _pywrap_tensorflow = swig_import_helper()\n File \"/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 20, in swig_import_helper\n import _pywrap_tensorflow\n ImportError: No module named _pywrap_tensorflow\n Failed to load the native TensorFlow runtime.\n `\n Note that otherwise tensorflow works properly, (i can even run \"import tensorflow as tf\" in python shell, everywhere else than in /tensorflow-master dir). I fought this whole evening and now I gave up and will hope that you somehow will be able to help me.  Otherwise, thanks for very good job with this project. It is fantastic that you make tool like tensorflow available to us.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "bazinac", "commentT": "2017-01-26T23:15:27Z", "comment_text": "\n \t\tPerhaps <denchmark-link:https://github.com/tensorflow/tensorflow/issues/97>#97</denchmark-link>\n  or <denchmark-link:https://github.com/tensorflow/tensorflow/issues/1013>#1013</denchmark-link>\n  are relevant here? Have you run ./configure? What Python version are you using?\n My assumption is that you have a different version of tf installed that Python is finding when you import tf elsewhere, so that is probably misleading.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "bazinac", "commentT": "2017-01-26T23:30:29Z", "comment_text": "\n \t\tI am using Python 3.5. I have tried to build tf from source, but it has failed to build Python wheel. I therefore opted to install latest (12.1) release using pip.\n I then ran ./configure in downloaded copy od latest tensorflow-master and built optimize_for_inference (I am sorry to provide misleading info on my previous comment). Then this abovementioned error arises when I try to run built optimize_for_inference...\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "bazinac", "commentT": "2017-01-26T23:46:25Z", "comment_text": "\n \t\tIt sounds like <denchmark-link:https://github.com/andrewharp>@andrewharp</denchmark-link>\n  is right. There are two versions in your system. I'm guessing that the best at this point is to go back and  tensorflow, then work through the issues building from source.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "bazinac", "commentT": "2017-01-27T18:08:29Z", "comment_text": "\n \t\tI followed your hint and somehow managed to build from source. When I run it know, tensorflow is much more verbose and I can see that -\n <denchmark-code>E/native: tensorflow_inference_jni.cc:146 Could not create TensorFlow graph: Invalid argument: No OpKernel was registered to support Op 'Pow' with these attrs.\n \n [[Node: final_added_training_ops/final_result_added/pow = Pow[T=DT_FLOAT](final_added_training_ops/final_result_added/truediv, final_added_training_ops/final_result_added/pow/y)]]\n </denchmark-code>\n \n I google out somewhere that this can be surpassed by adding necessary OpKernel to Android operator sets in BUILD file. But I don't understand what OpKernel I should add to Android operator set in case of Op 'Pow' and how do to so. Could you please tell me.\n In addition to tf.sqrt I use also tf.reduce_mean, tf.truncated_normal...\n Sorry for being so annoying lately :D\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "bazinac", "commentT": "2017-01-27T18:39:27Z", "comment_text": "\n \t\tOn behalf of our users, thanks for helping us clarify things!\n You should be able to add ops from there:\n <denchmark-link:https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/BUILD#L3378>https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/BUILD#L3378</denchmark-link>\n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "bazinac", "commentT": "2017-01-27T20:01:11Z", "comment_text": "\n \t\tCould you try that and let us know?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "bazinac", "commentT": "2017-01-27T20:16:37Z", "comment_text": "\n \t\tIt looks like cwise_op_pow.cc needs to be added to android_extended_ops_group1.\n AFAIK there's no reason not to make this change -- we've just been adding ops as needed, so long as they actually compile for Android without adding undue size.\n I think it would also be informative to list registered ops in the case one isn't found; is there an easy way to do that?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "bazinac", "commentT": "2017-01-27T20:24:29Z", "comment_text": "\n \t\tIt's actually already included in the Makefile build, so not including it for Bazel seems to be an oversight. Sending a CL to fix.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "bazinac", "commentT": "2017-01-28T08:48:20Z", "comment_text": "\n \t\tYay after adding \"cwise_op_pow.cc\", it works. Thank you guys!\n \t\t"}}}, "commit": {"commit_id": "c3df5d40ef8240ede980ccb740d6af87837d8eef", "commit_author": "Andrew Harp", "commitT": "2017-01-27 15:12:31-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow\\core\\kernels\\BUILD", "file_new_name": "tensorflow\\core\\kernels\\BUILD", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "3607", "deleted_lines": null}}}}}}