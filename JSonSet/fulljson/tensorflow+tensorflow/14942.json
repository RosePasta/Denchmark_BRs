{"BR": {"BR_id": "14942", "BR_author": "WenmuZhou", "BRopenT": "2017-11-28T14:01:08Z", "BRcloseT": "2018-02-20T18:40:09Z", "BR_text": {"BRsummary": "tensorflow 1.4 is 8 times slower than tensorflow 1.3 when read data", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n TensorFlow installed from (source or binary): python wheel\n TensorFlow version (use command below): 1.4 and 1.3\n Python version: 3.6.1\n Bazel version (if compiling from source):\n GCC/Compiler version (if compiling from source):\n CUDA/cuDNN version: None\n GPU model and memory: None\n Exact command to reproduce:\n \n when I run tensorflow1.4 script using estimator, the script is 8 times slower than tensorflow 1.3\n <denchmark-h:h3>Source code / logs</denchmark-h>\n \n main script\n #!/usr/bin/env python\n __author__ = 'zj'\n \n import argparse\n import os\n import sys\n import numpy as np\n import time\n try:\n     import better_exceptions\n except ImportError:\n     pass\n import tensorflow as tf\n from src.model_ori import crnn_fn\n from src.data_handler import data_loader\n from src.config import Params, Alphabet\n from src.input_utils import input_fn\n \n \n def main(unused_argv):\n     models_path = FLAGS.input_model_dir\n     if not os.path.exists(models_path):\n         assert FileNotFoundError\n \n     models_list = [os.path.join(models_path, x[:-5]) for x in os.listdir(models_path) if x.endswith('.meta')]\n \n     if not os.path.exists(FLAGS.output_model_dir):\n         os.makedirs(FLAGS.output_model_dir)\n \n     parameters = Params(eval_batch_size=128,\n                         input_shape=(32, 304),\n                         digits_only=False,\n                         alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,\n                         alphabet_decoding='same',\n                         image_channels=1,\n                         csv_delimiter=' ',\n                         csv_files_eval=FLAGS.csv_files_eval,\n                         output_model_dir=FLAGS.output_model_dir,\n                         gpu=FLAGS.gpu\n                         )\n \n     model_params = {\n         'Params': parameters,\n     }\n \n     os.environ['CUDA_VISIBLE_DEVICES'] = parameters.gpu\n     config_sess = tf.ConfigProto()\n     config_sess.gpu_options.per_process_gpu_memory_fraction = 0.6\n \n     # Config estimator\n     est_config = tf.estimator.RunConfig()\n     est_config = est_config.replace(session_config=config_sess,\n                                     save_summary_steps=100,\n                                     model_dir=parameters.output_model_dir)\n \n     estimator = tf.estimator.Estimator(model_fn=crnn_fn,\n                                        params=model_params,\n                                        config=est_config,\n                                        model_dir=parameters.output_model_dir,\n                                        )\n     try:\n         with open(FLAGS.output_file, encoding='utf-8', mode='w') as save_file:\n             for model in models_list:\n                 start = time.time()\n                 \n                 eval_results = estimator.evaluate(input_fn=data_loader(csv_filename=parameters.csv_files_eval,\n                                                                        params=parameters,\n                                                                        batch_size=parameters.eval_batch_size,\n                                                                        num_epochs=1),\n                                                   steps=3,\n                                                   checkpoint_path=model)\n                 print('time:',time.time() - start)\n                 print('model: %s Evaluation results: %s' % (model, str(eval_results)))\n                 save_file.write(model + ' ' + str(eval_results) + '\\n')\n \n     except KeyboardInterrupt:\n         print('Interrupted')\n \n \n if __name__ == '__main__':\n     parser = argparse.ArgumentParser()\n     parser.add_argument('-fe', '--csv_files_eval', required=False, type=str, help='CSV filename for evaluation',\n                         nargs='*', default=['E:/val1.csv'])\n     parser.add_argument('-o', '--output_model_dir', required=False, type=str,\n                         help='Directory for output', default='models_vgg_100K_no_eval')\n     parser.add_argument('-m', '--input_model_dir', required=False, type=str,\n                         help='Directory for output', default='model_test')\n     parser.add_argument('-g', '--gpu', type=str, help=\"GPU 0,1 or '' \", default='0')\n     parser.add_argument('-of', '--output_file', required=False, type=str, default='123.txt', help=\"the log output file\")\n \n     tf.logging.set_verbosity(tf.logging.DEBUG)\n     FLAGS, unparsed = parser.parse_known_args()\n     tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n data_loader script\n #!/usr/bin/env python\n import tensorflow as tf\n import numpy as np\n from .config import Params, CONST\n from typing import Tuple\n \n \n def data_loader(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,\n                 num_epochs: int = None, image_summaries: bool = False):\n     def input_fn():\n         # Choose case one csv file or list of csv files\n         if not isinstance(csv_filename, list):\n             filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,\n                                                             name='filename_queue')\n         elif isinstance(csv_filename, list):\n             filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')\n \n         # Skip lines that have already been processed\n         reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)\n         key, value = reader.read(filename_queue, name='file_reading_op')\n \n         default_line = [['None'], ['None']]\n         path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,\n                                     name='csv_reading_op')\n \n         image, img_width = image_reading(path, resized_size=params.input_shape, params=params,\n                                          data_augmentation=data_augmentation, padding=True)\n \n         to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}\n         prepared_batch = tf.train.shuffle_batch(to_batch,\n                                                 batch_size=batch_size,\n                                                 min_after_dequeue=500,\n                                                 num_threads=15, capacity=4000,\n                                                 allow_smaller_final_batch=False,\n                                                 name='prepared_batch_queue')\n \n         if image_summaries:\n             tf.summary.image('input/image', prepared_batch.get('images'), max_outputs=1)\n         tf.summary.text('input/labels', prepared_batch.get('labels')[:10])\n         tf.summary.text('input/widths', tf.as_string(prepared_batch.get('images_widths')))\n \n         return prepared_batch, prepared_batch.get('labels')\n \n     return input_fn\n \n \n def image_reading(path: str, params: Params, resized_size: Tuple[int, int] = None, data_augmentation: bool = False,\n                   padding: bool = False) -> Tuple[tf.Tensor, tf.Tensor]:\n     # Read image\n     image_content = tf.read_file(path, name='image_reader')\n     image = tf.cond(tf.equal(tf.string_split([path], '.').values[1], tf.constant('jpg', dtype=tf.string)),\n                     true_fn=lambda: tf.image.decode_jpeg(image_content, channels=params.image_channels,\n                                                          try_recover_truncated=True),  # TODO channels = 3 ?\n                     false_fn=lambda: tf.image.decode_png(image_content, channels=params.image_channels),\n                     name='image_decoding')\n \n     # Data augmentation\n     if data_augmentation:\n         image = augment_data(image)\n \n     # Padding\n     if padding:\n         with tf.name_scope('padding'):\n             image, img_width = padding_inputs_width(image, resized_size, increment=CONST.DIMENSION_REDUCTION_W_POOLING)\n     # Resize\n     else:\n         image = tf.image.resize_images(image, size=resized_size)\n         img_width = tf.shape(image)[1]\n \n     with tf.control_dependencies([tf.assert_equal(image.shape[:2], resized_size)]):\n         return image, img_width\n \n \n def random_rotation(img: tf.Tensor, max_rotation: float = 0.1, crop: bool = True) -> tf.Tensor:  # from SeguinBe\n     with tf.name_scope('RandomRotation'):\n         rotation = tf.random_uniform([], -max_rotation, max_rotation)\n         rotated_image = tf.contrib.image.rotate(img, rotation, interpolation='BILINEAR')\n         if crop:\n             rotation = tf.abs(rotation)\n             original_shape = tf.shape(rotated_image)[:2]\n             h, w = original_shape[0], original_shape[1]\n             # see https://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders for formulae\n             old_l, old_s = tf.cond(h > w, lambda: [h, w], lambda: [w, h])\n             old_l, old_s = tf.cast(old_l, tf.float32), tf.cast(old_s, tf.float32)\n             new_l = (old_l * tf.cos(rotation) - old_s * tf.sin(rotation)) / tf.cos(2 * rotation)\n             new_s = (old_s - tf.sin(rotation) * new_l) / tf.cos(rotation)\n             new_h, new_w = tf.cond(h > w, lambda: [new_l, new_s], lambda: [new_s, new_l])\n             new_h, new_w = tf.cast(new_h, tf.int32), tf.cast(new_w, tf.int32)\n             bb_begin = tf.cast(tf.ceil((h - new_h) / 2), tf.int32), tf.cast(tf.ceil((w - new_w) / 2), tf.int32)\n             rotated_image_crop = rotated_image[bb_begin[0]:h - bb_begin[0], bb_begin[1]:w - bb_begin[1], :]\n \n             # If crop removes the entire image, keep the original image\n             rotated_image = tf.cond(tf.equal(tf.size(rotated_image_crop), 0),\n                                     true_fn=lambda: img,\n                                     false_fn=lambda: rotated_image_crop)\n \n         return rotated_image\n \n \n def random_padding(image: tf.Tensor, max_pad_w: int = 5, max_pad_h: int = 10) -> tf.Tensor:\n     w_pad = list(np.random.randint(0, max_pad_w, size=[2]))\n     h_pad = list(np.random.randint(0, max_pad_h, size=[2]))\n     paddings = [h_pad, w_pad, [0, 0]]\n \n     return tf.pad(image, paddings, mode='REFLECT', name='random_padding')\n \n \n def augment_data(image: tf.Tensor) -> tf.Tensor:\n     with tf.name_scope('DataAugmentation'):\n         # Random padding\n         image = random_padding(image)\n \n         image = tf.image.random_brightness(image, max_delta=0.1)\n         image = tf.image.random_contrast(image, 0.5, 1.5)\n         image = random_rotation(image, 0.05, crop=True)\n \n         if image.shape[-1] >= 3:\n             image = tf.image.random_hue(image, 0.2)\n             image = tf.image.random_saturation(image, 0.5, 1.5)\n \n         return image\n \n \n def padding_inputs_width(image: tf.Tensor, target_shape: Tuple[int, int], increment: int) -> Tuple[\n     tf.Tensor, tf.Tensor]:\n     target_ratio = target_shape[1] / target_shape[0]\n     # Compute ratio to keep the same ratio in new image and get the size of padding\n     # necessary to have the final desired shape\n     shape = tf.shape(image)\n     # \u8ba1\u7b97\u5bbd\u9ad8\u6bd4\n     ratio = tf.divide(shape[1], shape[0], name='ratio')\n \n     new_h = target_shape[0]\n     new_w = tf.cast(tf.round((ratio * new_h) / increment) * increment, tf.int32)\n     f1 = lambda: (new_w, ratio)\n     f2 = lambda: (new_h, tf.constant(1.0, dtype=tf.float64))\n     new_w, ratio = tf.case({tf.greater(new_w, 0): f1,\n                             tf.less_equal(new_w, 0): f2},\n                            default=f1, exclusive=True)\n     target_w = target_shape[1]\n \n     # Definitions for cases\n     def pad_fn():\n         with tf.name_scope('mirror_padding'):\n             pad = tf.subtract(target_w, new_w)\n \n             img_resized = tf.image.resize_images(image, [new_h, new_w])\n \n             # Padding to have the desired width\n             paddings = [[0, 0], [0, pad], [0, 0]]\n             pad_image = tf.pad(img_resized, paddings, mode='SYMMETRIC', name=None)\n \n             # Set manually the shape\n             pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])\n \n             return pad_image, (new_h, new_w)\n \n     def replicate_fn():\n         with tf.name_scope('replication_padding'):\n             img_resized = tf.image.resize_images(image, [new_h, new_w])\n \n             # If one symmetry is not enough to have a full width\n             # Count number of replications needed\n             n_replication = tf.cast(tf.ceil(target_shape[1] / new_w), tf.int32)\n             img_replicated = tf.tile(img_resized, tf.stack([1, n_replication, 1]))\n             pad_image = tf.image.crop_to_bounding_box(image=img_replicated, offset_height=0, offset_width=0,\n                                                       target_height=target_shape[0], target_width=target_shape[1])\n \n             # Set manually the shape\n             pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])\n \n             return pad_image, (new_h, new_w)\n \n     def simple_resize():\n         with tf.name_scope('simple_resize'):\n             img_resized = tf.image.resize_images(image, target_shape)\n \n             img_resized.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])\n \n             return img_resized, target_shape\n \n     # 3 cases\n     pad_image, (new_h, new_w) = tf.case(\n         {  # case 1 : new_w >= target_w\n             tf.logical_and(tf.greater_equal(ratio, target_ratio),\n                            tf.greater_equal(new_w, target_w)): simple_resize,\n             # case 2 : new_w >= target_w/2 & new_w < target_w & ratio < target_ratio\n             tf.logical_and(tf.less(ratio, target_ratio),\n                            tf.logical_and(tf.greater_equal(new_w, tf.cast(tf.divide(target_w, 2), tf.int32)),\n                                           tf.less(new_w, target_w))): pad_fn,\n             # case 3 : new_w < target_w/2 & new_w < target_w & ratio < target_ratio\n             tf.logical_and(tf.less(ratio, target_ratio),\n                            tf.logical_and(tf.less(new_w, target_w),\n                                           tf.less(new_w, tf.cast(tf.divide(target_w, 2), tf.int32)))): replicate_fn\n         },\n         default=simple_resize, exclusive=True)\n \n     return pad_image, new_w  # new_w = image width used for computing sequence lengths\n \n \n def preprocess_image_for_prediction(fixed_height: int = 32, min_width: int = 8):\n     \"\"\"\n     Input function to use when exporting the model for making predictions (see estimator.export_savedmodel)\n     :param fixed_height: height of the input image after resizing\n     :param min_width: minimum width of image after resizing\n     :return:\n     \"\"\"\n \n     def serving_input_fn():\n         # define placeholder for input image\n         image = tf.placeholder(dtype=tf.float32, shape=[None, None, 1])\n \n         shape = tf.shape(image)\n         # Assert shape is h x w x c with c = 1\n \n         ratio = tf.divide(shape[1], shape[0])\n         increment = CONST.DIMENSION_REDUCTION_W_POOLING\n         new_width = tf.cast(tf.round((ratio * fixed_height) / increment) * increment, tf.int32)\n \n         resized_image = tf.cond(new_width < tf.constant(min_width, dtype=tf.int32),\n                                 true_fn=lambda: tf.image.resize_images(image, size=(fixed_height, min_width)),\n                                 false_fn=lambda: tf.image.resize_images(image, size=(fixed_height, new_width))\n                                 )\n \n         # Features to serve\n         features = {'images': resized_image[None],  # cast to 1 x h x w x c\n                     'images_widths': new_width[None]  # cast to tensor\n                     }\n \n         # Inputs received\n         receiver_inputs = {'images': image}\n \n         return tf.estimator.export.ServingInputReceiver(features, receiver_inputs)\n \n     return serving_input_fn\n log\n tensorflow1.4\n INFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n   per_process_gpu_memory_fraction: 0.6\n }\n , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002BAAA7A6780>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n INFO:tensorflow:Starting evaluation at 2017-11-28-12:21:42\n INFO:tensorflow:Restoring parameters from model_test\\model.ckpt-54692\n 2017-11-28 20:22:04.720980: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.236689657]\n INFO:tensorflow:Evaluation [1/3]\n 2017-11-28 20:28:32.360331: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.238805175]\n INFO:tensorflow:Evaluation [2/3]\n 2017-11-28 20:35:41.020994: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.237995088]\n INFO:tensorflow:Evaluation [3/3]\n INFO:tensorflow:Finished evaluation at 2017-11-28-12:43:21\n INFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.0108218, eval/accuracy = 0.929688, global_step = 54692, loss = 0.23783\n time:1306.1133954524994\n model: model_test\\model.ckpt-54692 Evaluation results: {'eval/CER': 0.01082176, 'eval/accuracy': 0.9296875, 'loss': 0.23782997, 'global_step': 54692}\n tensorflow 1.3\n INFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': gpu_options {\n   per_process_gpu_memory_fraction: 0.6\n }\n , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n INFO:tensorflow:Starting evaluation at 2017-11-28-12:49:50\n INFO:tensorflow:Restoring parameters from model_test\\model.ckpt-54692\n 2017-11-28 20:50:12.841210: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.17519826]\n INFO:tensorflow:Evaluation [1/3]\n 2017-11-28 20:51:03.366275: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.2987892]\n INFO:tensorflow:Evaluation [2/3]\n 2017-11-28 20:51:49.843030: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.20660429]\n INFO:tensorflow:Evaluation [3/3]\n INFO:tensorflow:Finished evaluation at 2017-11-28-12:52:19\n INFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.01188, eval/accuracy = 0.924479, global_step = 54692, loss = 0.226864\n time:157.26274514198303\n model: model_test\\model.ckpt-54692 Evaluation results: {'eval/CER': 0.011879961, 'eval/accuracy': 0.92447919, 'loss': 0.22686392, 'global_step': 54692}\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "WenmuZhou", "commentT": "2017-11-28T18:19:56Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ispirmustafa>@ispirmustafa</denchmark-link>\n , any ideas what might be causing this?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "WenmuZhou", "commentT": "2017-11-28T18:58:52Z", "comment_text": "\n \t\tI'm not aware of any related change within estimator.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "WenmuZhou", "commentT": "2017-11-28T19:00:27Z", "comment_text": "\n \t\tMay be something related to data loader part? <denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n  do you mind to test time difference of input_fn between 1.3 and 1.4?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "WenmuZhou", "commentT": "2017-11-29T01:54:25Z", "comment_text": "\n \t\there is the time of input_fn between 1.3 and 1.4\n the script is\n # -*- coding: utf-8 -*-\n # @Time    : 2017/11/29 8:43\n # @Author  : zhoujun\n from src.data_handler import data_loader, input_fn\n from src.config import Params, Alphabet\n import tensorflow as tf\n import time\n \n if __name__ == '__main__':\n     parameters = Params(eval_batch_size=128,\n                         input_shape=(32, 304),\n                         digits_only=False,\n                         alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,\n                         alphabet_decoding='same',\n                         image_channels=1,\n                         csv_delimiter=' ',\n                         )\n \n     featureBatch, labelBatch = input_fn(csv_filename='E:/val1.csv', params=parameters,\n                                         batch_size=parameters.eval_batch_size,\n                                         num_epochs=1)\n \n     global_init = tf.global_variables_initializer()\n     loacl_init = tf.local_variables_initializer()\n     with tf.Session() as sess:\n         sess.run(global_init)\n         sess.run(loacl_init)\n         coord = tf.train.Coordinator()\n         threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n \n         start = time.time()\n         example, label = sess.run([featureBatch, labelBatch])\n         print('time: ',time.time()-start)\n         print(len(label))\n         coord.request_stop()\n         coord.join(threads)\n input_fn is extracted from data_loader function\n def input_fn(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,\n                 num_epochs: int = None):\n     # Choose case one csv file or list of csv files\n     if not isinstance(csv_filename, list):\n         filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,\n                                                         name='filename_queue')\n     elif isinstance(csv_filename, list):\n         filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')\n \n     # Skip lines that have already been processed\n     reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)\n     key, value = reader.read(filename_queue, name='file_reading_op')\n \n     default_line = [['None'], ['None']]\n     path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,\n                                 name='csv_reading_op')\n \n     image, img_width = image_reading(path, resized_size=params.input_shape, params=params,\n                                      data_augmentation=data_augmentation, padding=True)\n \n     to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}\n     prepared_batch = tf.train.shuffle_batch(to_batch,\n                                             batch_size=batch_size,\n                                             min_after_dequeue=500,\n                                             num_threads=15, capacity=4000,\n                                             allow_smaller_final_batch=False,\n                                             name='prepared_batch_queue')\n     return prepared_batch, prepared_batch.get('labels')\n tf 1.3 log\n time:  0.4531559944152832\n 128\n tf 1.4 log\n time:  0.5000338554382324\n 128\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "WenmuZhou", "commentT": "2017-11-29T08:30:26Z", "comment_text": "\n \t\tThere seems to be a tiny difference in the accuracies, are the runs exactly the same?\n The config for 1.4 seems to include a clusterspec, are you running the 1.4 run locally as well?\n Also are either or both of them using a GPU?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "WenmuZhou", "commentT": "2017-11-30T01:41:53Z", "comment_text": "\n \t\tboth of them ara run using 1080TI\uff0cand everything is the same except for the tensorflow version\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "WenmuZhou", "commentT": "2017-11-30T01:42:39Z", "comment_text": "\n \t\tthe tf1.4 log of input_fn is error and I have fixed it\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "WenmuZhou", "commentT": "2017-11-30T17:52:14Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n  thanks for helping us to investigate this issue.\n To understand the issue better could you please give us following information:\n print est_config.cluster_spec\n print os.environ['TF_CONFIG']\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "WenmuZhou", "commentT": "2017-11-30T18:13:43Z", "comment_text": "\n \t\tAnother useful information can be get by using ProfilerHook as follows:\n <denchmark-code>from tensorflow.contrib.hooks.python.training import profiler_hook\n import os\n os.mkdir('/tmp/estimator_debug')\n estimator.evaluate(input_fn=test_input_fn, hooks=[profiler_hook.ProfilerHook(save_steps=1, output_dir='/tmp/estimator_debug')])\n </denchmark-code>\n \n You can check the output by using catapult as follows:\n <denchmark-code>git clone https://github.com/catapult-project/catapult\n catapult/tracing/bin/trace2html /tmp/estimator_debug/FILENAME.json --output=/tmp/estimator_debug/FILENAME.html\n </denchmark-code>\n \n Could you please let us know the differences between 1.3 and 1.4 in profiler output?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "WenmuZhou", "commentT": "2017-12-02T02:34:00Z", "comment_text": "\n \t\tthe est_config.cluster_spec is None and there are a error when run\n print os.environ['TF_CONFIG']\n log is\n 1.3.0\n Traceback (most recent call last):\n   File \"Z:/zhoujun/tf-crnn/test_model.py\", line 110, in <module>\n     tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n   File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\n     _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n   File \"Z:/zhoujun/tf-crnn/test_model.py\", line 57, in main\n     print('os.environ[\\'TF_CONFIG\\']',os.environ['TF_CONFIG'])\n   File \"C:\\Anaconda3\\lib\\os.py\", line 669, in __getitem__\n     raise KeyError(key) from None\n KeyError: 'TF_CONFIG'\n est_config.cluster_spec None\n and when I import profile_hook, there are a error\n >>> from tensorflow.contrib.hooks.python.training import profiler_hook\n Traceback (most recent call last):\n   File \"<stdin>\", line 1, in <module>\n   File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\hooks\\__init__.py\", line 25, in <module>\n     from tensorflow.contrib.hooks.python.training import *\n ModuleNotFoundError: No module named 'tensorflow.contrib.hooks.python'\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "WenmuZhou", "commentT": "2017-12-02T09:21:10Z", "comment_text": "\n \t\tI've seen a similar issue:\n My code snippet to test on tf1.3:\n <denchmark-code>def parser(record, split_name, imagenet_mean):\n     assert (split_name == 'train' or split_name == 'train_dev')\n     keys_to_features = {\n         'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n         'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n         'image/class/class_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n         'image/product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n     }\n     parsed = tf.parse_single_example(record, keys_to_features)\n     image = tf.image.decode_jpeg(parsed['image/encoded'])\n     image.set_shape([180, 180, 3])\n     image = tf.cast(image, tf.float32)\n     image = tf.subtract(image, imagenet_mean)\n     image = tf.expand_dims(image, axis=0)\n     image = tf.image.resize_bicubic(image, [224, 224])\n     image = tf.squeeze(image)\n     if split_name == 'train':\n         image = tf.image.random_flip_left_right(image)\n     label = parsed['image/class/class_id']\n     product_id = parsed['image/product_id']\n     return image, label, product_id\n \n \n def get_dataset(file_patterns, split_name):\n     assert (split_name == 'train' or split_name == 'train_dev')\n     imagenet_mean = tf.constant([_R_MEAN, _G_MEAN, _B_MEAN])\n     d = tf.contrib.data.Dataset.list_files(file_patterns)\n     # We choose NUM_SHARDS as buffer_size to ensure that in each epoch we are seeing all the shard TFRecord files\n     # with no duplicate or missing ones.\n     d = d.shuffle(buffer_size=NUM_SHARDS)\n     # cycle_length is set as NUM_SHARDS so in each cycle we will be able to see images from different shards.\n     d = d.interleave(lambda x: tf.contrib.data.TFRecordDataset(filenames=x), cycle_length=NUM_SHARDS, block_length=1)\n     d = d.map(lambda x: parser(x, split_name, imagenet_mean), num_threads=8192, output_buffer_size=BATCH_SIZE * 20)\n     d = d.batch(BATCH_SIZE)\n     return d\n \n \n def main():\n     config = tf.ConfigProto()\n     config.gpu_options.visible_device_list = '0'\n     with tf.Graph().as_default() as g:\n         with tf.device('/cpu:0'):\n             train_set = get_dataset(TRAIN_ON_RAM, 'train')\n             train_iter = train_set.make_one_shot_iterator()\n             images, labels, product_ids = train_iter.get_next()\n     with tf.Session(graph=g, config=config) as sess:\n         for _ in tqdm(range(1000)):\n             sess.run(images)\n </denchmark-code>\n \n For tf1.4, I simply changed tf.contrib.data to tf.data, num_threads into num_parallel_calls and output_buffer_size to prefetch. Then I've seen a very significant performance drop:\n On TF 1.3 I get:\n <denchmark-code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [03:14<00:00,  5.14it/s]\n </denchmark-code>\n \n On TF 1.4 I get:\n <denchmark-code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [05:28<00:00,  3.05it/s]\n </denchmark-code>\n \n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "WenmuZhou", "commentT": "2017-12-02T15:06:46Z", "comment_text": "\n \t\tI did another test (using a trained models to predict the image) and also proved that tensorflow1.4 was slower than 1.3 <denchmark-link:https://github.com/tensorflow/tensorflow/issues/15057>#15057</denchmark-link>\n \n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "WenmuZhou", "commentT": "2017-12-02T20:45:17Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/mrry>@mrry</denchmark-link>\n  and <denchmark-link:https://github.com/jsimsa>@jsimsa</denchmark-link>\n  may have better ideas about the differences in tf.data performance.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "WenmuZhou", "commentT": "2017-12-02T21:05:08Z", "comment_text": "\n \t\tIt\u2019s not clear what caused the change in performance but num_threads=8192 (or num_parallel_calls=8192) is very unlikely to be optimal, because of the potential for contention from so many parallel work items. Try setting this to a much smaller value (e.g. the number of CPU cores in your test machine) to see if this speeds things up.\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "WenmuZhou", "commentT": "2017-12-03T21:28:44Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/mrry>@mrry</denchmark-link>\n . That code was a  benchmark script I was using when trying to tune the best parameter setting for input. Initially I was using something like 64 which is the number of cores, but I've increased the number of threads all the way from 64, 128, 256 to 8192 and the performance kept improving so that's why I was using 8192 in that script. I can change it back to smaller values and show more results.\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "WenmuZhou", "commentT": "2017-12-04T17:09:06Z", "comment_text": "\n \t\tThank you <denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n  for adding a test with Predict. That test doesn't use Dataset or Estimator. <denchmark-link:https://github.com/aselle>@aselle</denchmark-link>\n  who can help us here?\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "WenmuZhou", "commentT": "2017-12-04T21:11:28Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n  for your  experiment:\n \n \n Did you do the 64, 128, ..., 8192 scaling using TF 1.3 or TF 1.4? If TF 1.3, could you verify that you see a similar effect for TF 1.4?\n \n \n Could you also add timing information to the parser method to see how much time is spent in this method in TF 1.3 and TF 1.4? I am not aware of any tf.data changes between TF 1.3 and TF 1.4 to the transformations you are using that should result in a performance drop, so I am trying to see if perhaps the slowdown is due to a change in the image parsing logic.\n \n \n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "WenmuZhou", "commentT": "2017-12-05T00:22:35Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n  re:ProfilerHook, it is available as  in TF1.4. But for 1.3 sorry to here it's not working. Could you please run it only on 1.4? It may give us some info.\n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "WenmuZhou", "commentT": "2017-12-05T22:13:59Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jsimsa>@jsimsa</denchmark-link>\n  - I think that's actually my experiment but I'm happy to add more data. :)\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "WenmuZhou", "commentT": "2017-12-06T04:04:54Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ispirmustafa>@ispirmustafa</denchmark-link>\n   for tf 1.4 the ouput of\n print(est_config.cluster_spec)\n is\n <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000226E91666A0>\n but, the output of tf 1.3 is None\n and my python verison is python3 ,can not run\n catapult/tracing/bin/trace2html /tmp/estimator_debug/FILENAME.json --output=/tmp/estimator_debug/FILENAME.html\n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "WenmuZhou", "commentT": "2017-12-06T17:02:39Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n  please do print(est_config.cluster_spec.as_dict()) to get the content.\n re: catapult, did you clone it? I mean following: git clone https://github.com/catapult-project/catapult\n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "WenmuZhou", "commentT": "2017-12-07T01:53:15Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ispirmustafa>@ispirmustafa</denchmark-link>\n  the output is a None dict\n {}\n I have clone the catapult\n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "WenmuZhou", "commentT": "2017-12-22T07:34:19Z", "comment_text": "\n \t\tIt has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.\n \t\t"}, "comments_23": {"comment_id": 24, "comment_author": "WenmuZhou", "commentT": "2018-01-05T19:07:02Z", "comment_text": "\n \t\tNagging Awaiting TensorFlower: It has been 14 days with no activityand the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.\n \t\t"}, "comments_24": {"comment_id": 25, "comment_author": "WenmuZhou", "commentT": "2018-01-06T12:56:03Z", "comment_text": "\n \t\tthe code I used is in this <denchmark-link:https://github.com/solivr/tf-crnn>https://github.com/solivr/tf-crnn</denchmark-link>\n \n \t\t"}, "comments_25": {"comment_id": 26, "comment_author": "WenmuZhou", "commentT": "2018-01-06T17:43:14Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n \n <denchmark-link:https://github.com/ispirmustafa>@ispirmustafa</denchmark-link>\n  could you please look to reproduce this, and then pull in whoever else is needed.\n \t\t"}, "comments_26": {"comment_id": 27, "comment_author": "WenmuZhou", "commentT": "2018-01-08T17:58:33Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n \n Could you also point us an example data set in format expected by your program?\n \t\t"}, "comments_27": {"comment_id": 28, "comment_author": "WenmuZhou", "commentT": "2018-01-08T20:48:27Z", "comment_text": "\n \t\tI have a similar issue with v1.4.x. However, it goes away with v1.5rc0.\n \t\t"}, "comments_28": {"comment_id": 29, "comment_author": "WenmuZhou", "commentT": "2018-01-12T05:24:54Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/songgc>@songgc</denchmark-link>\n  v1.5rc0 is slower than 1.3 in my test\n \t\t"}, "comments_29": {"comment_id": 30, "comment_author": "WenmuZhou", "commentT": "2018-01-12T16:51:26Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n  ,\n It would be great to have an example data set in format expected by your program and creates this issue. Would you mind to point us to it?\n \t\t"}, "comments_30": {"comment_id": 31, "comment_author": "WenmuZhou", "commentT": "2018-01-20T01:35:42Z", "comment_text": "\n \t\tI have update the code to generate dataset\n <denchmark-link:https://github.com/tensorflow/tensorflow/files/1648413/hlp.zip>hlp.zip</denchmark-link>\n \n \t\t"}, "comments_31": {"comment_id": 32, "comment_author": "WenmuZhou", "commentT": "2018-01-23T22:59:51Z", "comment_text": "\n \t\tA member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.\n \t\t"}, "comments_32": {"comment_id": 33, "comment_author": "WenmuZhou", "commentT": "2018-01-25T21:04:55Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/WenmuZhou>@WenmuZhou</denchmark-link>\n \n We've created two environment with GPUS one with TF1.3 and one with TF1.4.\n We've run your data generation script (BTW, there is a small mismatch with between the generated data and what your model expects).\n We've run your model with following command as describe on your github:\n 'python train.py -g 1 -ft ../data/10.csv -fe ../data/10.csv -o ./export_model_dir'.\n At the end we couldn't reproduce the issue. Could you please provide us a single script which we can run and which reproduces the slowness.\n \t\t"}, "comments_33": {"comment_id": 34, "comment_author": "WenmuZhou", "commentT": "2018-01-29T14:20:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ispirmustafa>@ispirmustafa</denchmark-link>\n  I have update a latest <denchmark-link:https://github.com/WenmuZhou/Segmentation-Free_OCR>code</denchmark-link>\n , the python version I used is python3.5.2, and I have test once and reproduce the issue.\n the environment is\n \n python 3.5.2\n tensorflow 1.3 or 1.4\n \n Some Chinese comments cause the code to no longer run under python2 and if you need to test in python2 you need to comment out these Chinese comments\n \t\t"}, "comments_34": {"comment_id": 35, "comment_author": "WenmuZhou", "commentT": "2018-02-15T13:14:41Z", "comment_text": "\n \t\tNagging Awaiting TensorFlower: It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.\n \t\t"}, "comments_35": {"comment_id": 36, "comment_author": "WenmuZhou", "commentT": "2018-02-20T18:40:09Z", "comment_text": "\n \t\tI tried to reproduce your issue with the code you provided but I cannot see any slowdown switching from 1.3 to 1.4.\n The scripts you provided are very complex, many different issues inside and outside TensorFlow could contribute to a slowdown.\n Can you provide a small repro script that isolates the issue and which we can use for debugging?\n I will close this issue as not reproducible, but please reopen this with some more specific information.\n \t\t"}}}, "commit": {"commit_id": "2d4c29cd6a0627fdd71a752e6bd919204c7cb8bf", "commit_author": "Mustafa Ispir", "commitT": "2017-12-07 14:39:27-08:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\training\\server_lib.py", "file_new_name": "tensorflow\\python\\training\\server_lib.py", "file_complexity": {"file_NLOC": "220", "file_CCN": "47", "file_NToken": "1233"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "310,311,312,313,314", "deleted_lines": null, "method_info": {"method_name": "__str__", "method_params": "self", "method_startline": "310", "method_endline": "314", "method_complexity": {"method_NLOC": "5", "method_CCN": "2", "method_NToken": "48", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\training\\server_lib_test.py", "file_new_name": "tensorflow\\python\\training\\server_lib_test.py", "file_complexity": {"file_NLOC": "416", "file_CCN": "30", "file_NToken": "3408"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "424,425,426,427,428,429,430,431,432,433", "deleted_lines": null, "method_info": {"method_name": "testStringConversion", "method_params": "self", "method_startline": "424", "method_endline": "433", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "44", "method_nesting_level": "1"}}}}}}}}