{"BR": {"BR_id": "46128", "BR_author": "summa-code", "BRopenT": "2021-01-04T05:04:06Z", "BRcloseT": "2021-01-18T18:16:11Z", "BR_text": {"BRsummary": "This throws ERROR: features = tf.io.parse_example(..., features=make_parse_example_spec(columns))", "BRdescription": "\n Please make sure that this is a bug. As per our\n GitHub Policy,\n we only address code/doc bugs, performance issues, feature requests and\n build/installation issues on GitHub. tag:bug_template\n System information\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04\n Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\n TensorFlow installed from (source or binary): Source\n TensorFlow version (use command below): Latest from this week\n Python version: 3.8.x\n Bazel version (if compiling from source): 3.1.0\n GCC/Compiler version (if compiling from source):\n CUDA/cuDNN version: 11.2\n GPU model and memory:\n \n Describe the current behavior\n I was trying this code, but it throws exception\n https://www.tensorflow.org/api_docs/python/tf/keras/experimental/SequenceFeatures\n <denchmark-code>ValueError: Attempt to convert a value (Ellipsis) with an unsupported type (<class 'ellipsis'>) to a Tensor.```\n \n \n Here is the full code from that page,\n \n \n ```# Behavior of some cells or feature columns may depend on whether we are in\n # training or inference mode, e.g. applying dropout.\n training = True\n rating = sequence_numeric_column('rating')\n watches = sequence_categorical_column_with_identity(\n     'watches', num_buckets=1000)\n watches_embedding = embedding_column(watches, dimension=10)\n columns = [rating, watches_embedding]\n \n sequence_input_layer = SequenceFeatures(columns)\n features = tf.io.parse_example(...,\n                                features=make_parse_example_spec(columns))\n sequence_input, sequence_length = sequence_input_layer(\n    features, training=training)\n sequence_length_mask = tf.sequence_mask(sequence_length)\n \n rnn_cell = tf.keras.layers.SimpleRNNCell(hidden_size, training=training)\n rnn_layer = tf.keras.layers.RNN(rnn_cell, training=training)\n outputs, state = rnn_layer(sequence_input, mask=sequence_length_mask)\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "summa-code", "commentT": "2021-01-04T10:07:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/summa-code>@summa-code</denchmark-link>\n \n Please share colab link or simple standalone code with supporting files to reproduce the issue. It helps us in localizing the issue faster.I am seeing the error message(NameError: name 'sequence_numeric_column' is not defined) while trying to reproduce the issue. Thanks!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "summa-code", "commentT": "2021-01-04T15:53:02Z", "comment_text": "\n \t\tThat is what i have given in the description, and also is in this link !!!!!!!\n And Did you include the tensor packages ?\n <denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/experimental/SequenceFeatures>https://www.tensorflow.org/api_docs/python/tf/keras/experimental/SequenceFeatures</denchmark-link>\n \n <denchmark-code>import tensorflow as tf\n from tensorflow.keras import layers\n from tensorflow import feature_column\n \n training = True\n rating = feature_column.sequence_numeric_column('rating')\n watches = feature_column.sequence_categorical_column_with_identity(\n     'watches', num_buckets=1000)\n watches_embedding = feature_column.embedding_column(watches, dimension=10)\n columns = [rating, watches_embedding]\n \n sequence_input_layer = tf.keras.experimental.SequenceFeatures(columns)\n features = tf.io.parse_example(...,\n                                features=feature_column.make_parse_example_spec(columns))\n sequence_input, sequence_length = sequence_input_layer(\n    features, training=training)\n sequence_length_mask = tf.sequence_mask(sequence_length)\n \n rnn_cell = tf.keras.layers.SimpleRNNCell(hidden_size, training=training)\n rnn_layer = tf.keras.layers.RNN(rnn_cell, training=training)\n outputs, state = rnn_layer(sequence_input, mask=sequence_length_mask) \n \n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "summa-code", "commentT": "2021-01-05T05:08:46Z", "comment_text": "\n \t\tI have tried in colab with TF version <denchmark-link:https://colab.research.google.com/gist/ravikyram/445470fd54502d56b948ebc76743b505/untitled594.ipynb>2.4 gist</denchmark-link>\n  and Nightly version() <denchmark-link:https://colab.research.google.com/gist/ravikyram/9b2cc481b9c9390d2abdd3e516f43a84/untitled593.ipynb>gist</denchmark-link>\n  and was able to reproduce the issue. Thanks!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "summa-code", "commentT": "2021-01-08T22:52:57Z", "comment_text": "\n \t\t\n ValueError: Attempt to convert a value (Ellipsis) with an unsupported type (<class 'ellipsis'>) to a Tensor.\n \n Yeah, often people put ... in examples to say \"fill this in with the necessary code\". it's too bad that ... is also valid python.\n Anyway, this whole line: tf.io.parse_example(..., features=feature_column.make_parse_example_spec(columns)) is a distraction from the function being documented here. This thing doesn't need Examples or parser specifications. It needs a dictionary of SparseTensors.\n If you actually do want to parse some tensors using that construct, ... is where you's pass some SerializeToString serialized tf.Examples.\n Now, we encourage people to use doctest format >>> which we do test. But this doc is likely low enough traffic that we may never come back to fix this.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "summa-code", "commentT": "2021-01-10T17:53:38Z", "comment_text": "\n \t\tI am little bit confused. So the example given looks like self contained. We are trying to extract the inputs. In the example given above what do you think goes in ... ? There is one numeric and and one categorical feature.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "summa-code", "commentT": "2021-01-11T14:42:57Z", "comment_text": "\n \t\tThis line:\n <denchmark-code>features = tf.io.parse_example(...,\n                                features=feature_column.make_parse_example_spec(columns))\n </denchmark-code>\n \n Should be something like:\n <denchmark-code>features = {\n  'rating': tf.sparse.from_dense([[1.0,1.1, 0, 0, 0],[2.0,2.1,2.2, 2.3, 2.5]])\n  'watches': tf.sparse.from_dense([[2, 85, 61, 0, 0, 0],[33,92, 2, 73, 1]])\n }\n </denchmark-code>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "summa-code", "commentT": "2021-01-11T18:21:52Z", "comment_text": "\n \t\tSo this looks like feeding the actual sequence for building the model. And should there be a \",\" between ratings and watches ? There was a dimension issue in the watches array, Now it is throwing some other error.\n features = {\n 'rating': tf.sparse.from_dense([[1.0, 1.1, 0, 0, 0], [2.0, 2.1, 2.2, 2.3, 2.5]]),\n 'watches': tf.sparse.from_dense([[2, 85, 61, 0, 0, 0], [33, 92, 2, 73, 1, 3]])\n }\n sequence_input, sequence_length = sequence_input_layer(features, training=training)\n raise errors.InvalidArgumentError(\n tensorflow.python.framework.errors_impl.InvalidArgumentError: Condition x == y did not hold.\n Indices of first 2 different values:\n [[0]\n [1]]\n Corresponding x values:\n [2 5]\n Corresponding y values:\n [3 6]\n First 2 elements of x:\n [2 5]\n First 2 elements of y:\n [3 6]\n python-BaseException\n Process finished with exit code 1\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "summa-code", "commentT": "2021-01-11T18:26:44Z", "comment_text": "\n \t\tI am just looking for a simple usage example for SequenceFeatures with couple of different sequence columns.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "summa-code", "commentT": "2021-01-11T18:53:16Z", "comment_text": "\n \t\tAll sets of sequences need the same shapes. In my earlier post they didn't match.\n This works:\n <denchmark-code>training = True\n rating = feature_column.sequence_numeric_column('rating')\n watches = feature_column.sequence_categorical_column_with_identity(\n     'watches', num_buckets=1000)\n watches_embedding = feature_column.embedding_column(watches, dimension=10)\n columns = [rating, watches_embedding]\n \n features = {\n  'rating': tf.sparse.from_dense([[1.0,1.1, 0, 0, 0],[2.0,2.1,2.2, 2.3, 2.5]]),\n  'watches': tf.sparse.from_dense([[2, 85, 0, 0, 0],[33,78, 2, 73, 1]])\n }\n \n sequence_input_layer = tf.keras.experimental.SequenceFeatures(columns)\n sequence_input, sequence_length = sequence_input_layer(\n    features, training=training)\n    \n sequence_length_mask = tf.sequence_mask(sequence_length)\n </denchmark-code>\n \n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "summa-code", "commentT": "2021-01-11T22:31:23Z", "comment_text": "\n \t\tOops i missed that one. Ok, can we create \"features\" variable without using the real inputs ? something like this ?\n features['rating'] = tf.keras.Input(shape=(?,), name='rating', dtype=tf.float32)\n features['watches'] = tf.keras.Input(shape=(?,), name='watches', dtype=tf.float32)\n Is the shape here just one dimensional for the feature or should it have the windowed shape ?\n The timeseries example given does not do justice without using these \"Sequence\" functions. Since LSTM takes in 3 dimensional data, without knowing a working example, it is a bit hard.\n <denchmark-link:https://www.tensorflow.org/tutorials/structured_data/time_series>https://www.tensorflow.org/tutorials/structured_data/time_series</denchmark-link>\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "summa-code", "commentT": "2021-01-13T16:23:19Z", "comment_text": "\n \t\tI came across this one,\n <denchmark-link:https://github.com/tensorflow/tensorflow/issues/31240>#31240</denchmark-link>\n \n It is remarkable how durandg12 came back after almost a year after first he used it.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "summa-code", "commentT": "2021-01-15T00:02:06Z", "comment_text": "\n \t\tAnd how do i create an input to LSTMCell, because i want to use CuDNN with GPU,\n I am using \"tf.keras.preprocessing.timeseries_dataset_from_array\" to create dataset that has the shape(batch, time sequence, features) format ? I am having sliding window dataset. It is crazy that with the lack of documentation, there is much we could do with SequenceFeature API.\n What i wanted is a slidingwindow dataset with a categorical column that is fed into LSTM network. The examples is shown everything except this crucial part. Pytorch has nice way of doing this. Wish Tensorflow has something simple to implement categorical feature for timeseries.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "summa-code", "commentT": "2021-01-17T17:54:15Z", "comment_text": "\n \t\tAnd then i came across this one,\n <denchmark-link:https://github.com/tensorflow/community/blob/master/rfcs/20191212-keras-categorical-inputs.md>https://github.com/tensorflow/community/blob/master/rfcs/20191212-keras-categorical-inputs.md</denchmark-link>\n \n This all leads to One hot encoding, even the hashing Trick does not do the trick. I am just lost here.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "summa-code", "commentT": "2021-01-20T20:09:46Z", "comment_text": "\n \t\t???? Why was it closed ?\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "summa-code", "commentT": "2021-01-20T20:12:11Z", "comment_text": "\n \t\tThe linked commit updates that example:\n <denchmark-link:https://github.com/tensorflow/tensorflow/commit/2cc955f533a9ba70512cf4a07024aaf65708e103>2cc955f</denchmark-link>\n \n <denchmark-code> ```python\n import tensorflow as tf\n # Behavior of some cells or feature columns may depend on whether we are in\n # training or inference mode, e.g. applying dropout.\n training = True\n rating = tf.feature_column.sequence_numeric_column('rating')\n watches = tf.feature_column.sequence_categorical_column_with_identity(\n     'watches', num_buckets=1000)\n watches_embedding = tf.feature_column.embedding_column(watches,\n                                             dimension=10)\n columns = [rating, watches_embedding]\n features = {\n  'rating': tf.sparse.from_dense([[1.0,1.1, 0, 0, 0],\n                                              [2.0,2.1,2.2, 2.3, 2.5]]),\n  'watches': tf.sparse.from_dense([[2, 85, 0, 0, 0],[33,78, 2, 73, 1]])\n }\n sequence_input_layer = tf.keras.experimental.SequenceFeatures(columns)\n sequence_input, sequence_length = sequence_input_layer(\n    features, training=training)\n sequence_length_mask = tf.sequence_mask(sequence_length)\n hidden_size = 32\n rnn_cell = tf.keras.layers.SimpleRNNCell(hidden_size)\n rnn_layer = tf.keras.layers.RNN(rnn_cell)\n outputs, state = rnn_layer(sequence_input, mask=sequence_length_mask)\n ```\n </denchmark-code>\n \n \t\t"}}}, "commit": {"commit_id": "2cc955f533a9ba70512cf4a07024aaf65708e103", "commit_author": "A. Unique TensorFlower", "commitT": "2021-01-18 10:14:54-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow\\python\\keras\\feature_column\\sequence_feature_column.py", "file_new_name": "tensorflow\\python\\keras\\feature_column\\sequence_feature_column.py", "file_complexity": {"file_NLOC": "114", "file_CCN": "12", "file_NToken": "411"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "54,55,56,60,61,63,64,67,68,69,70,71,72,73,76,79,80,81,82", "deleted_lines": "57,58,60,63,64,65,70,71"}}}}}}