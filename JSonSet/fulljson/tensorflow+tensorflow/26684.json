{"BR": {"BR_id": "26684", "BR_author": "girving", "BRopenT": "2019-03-14T05:08:31Z", "BRcloseT": "2019-03-31T03:41:34Z", "BR_text": {"BRsummary": "Repeatedly allocating a graph and summary writer leaks memory", "BRdescription": "\n Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template\n System information\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I have\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.3\n Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\n TensorFlow installed from (source or binary): Source\n TensorFlow version (use command below): v1.12.0-10061-gf3954bf900 1.13.1\n Python version: 3.7.2\n Bazel version (if compiling from source): 0.23.1\n GCC/Compiler version (if compiling from source): Apple LLVM version 10.0.0 (clang-1000.11.45.5)\n CUDA/cuDNN version: N/A\n GPU model and memory: N/A\n \n Describe the current behavior\n Repeatedly allocating a graph and making a summary writer leaks memory.\n Describe the expected behavior\n Memory should be freed when the graph leaves scope.\n Code to reproduce the issue\n <denchmark-code>#!/usr/bin/env python3\n \n import resource\n import tensorflow as tf\n \n prev = 0\n while True:\n     peak = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n     print(f'peak memory = {peak:,} (+{peak-prev:,})')\n     prev = peak\n \n     with tf.Graph().as_default(), tf.init_scope():\n         tf.contrib.summary.create_file_writer('/tmp/tb')\n </denchmark-code>\n \n Other info / logs\n Here's what the output looks like:\n <denchmark-code>peak memory = 174,493,696 (+174,493,696)\n   \n WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n For more information, please see:\n   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n   * https://github.com/tensorflow/addons\n If you depend on functionality not listed there, please file an issue.\n \n peak memory = 202,215,424 (+27,721,728)\n peak memory = 202,264,576 (+49,152)\n peak memory = 202,309,632 (+45,056)\n peak memory = 202,358,784 (+49,152)\n peak memory = 202,432,512 (+73,728)\n peak memory = 202,473,472 (+40,960)\n peak memory = 202,522,624 (+49,152)\n peak memory = 202,567,680 (+45,056)\n peak memory = 202,604,544 (+36,864)\n peak memory = 202,641,408 (+36,864)\n peak memory = 202,694,656 (+53,248)\n peak memory = 202,739,712 (+45,056)\n peak memory = 202,784,768 (+45,056)\n peak memory = 202,829,824 (+45,056)\n peak memory = 202,878,976 (+49,152)\n peak memory = 202,919,936 (+40,960)\n peak memory = 202,981,376 (+61,440)\n peak memory = 203,026,432 (+45,056)\n peak memory = 203,067,392 (+40,960)\n ...\n peak memory = 999,665,664 (+49,152)\n peak memory = 999,718,912 (+53,248)\n peak memory = 999,768,064 (+49,152)\n peak memory = 999,817,216 (+49,152)\n peak memory = 999,866,368 (+49,152)\n peak memory = 999,915,520 (+49,152)\n peak memory = 999,964,672 (+49,152)\n peak memory = 1,000,009,728 (+45,056)\n peak memory = 1,000,058,880 (+49,152)\n peak memory = 1,000,108,032 (+49,152)\n peak memory = 1,000,161,280 (+53,248)\n peak memory = 1,000,202,240 (+40,960)\n peak memory = 1,000,255,488 (+53,248)\n ...\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "girving", "commentT": "2019-03-14T15:57:28Z", "comment_text": "\n \t\tForgot that I was using a slightly messy TensorFlow tree.  I've reconfirmed that the bug persists at <denchmark-link:https://github.com/tensorflow/tensorflow/pull/26705>#26705</denchmark-link>\n , which is <denchmark-link:https://github.com/tensorflow/tensorflow/commit/5b24fba0857394dab67359963726b3bcce071575>5b24fba</denchmark-link>\n  plus a one line header include addition to make it build on my machine.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "girving", "commentT": "2019-03-15T16:20:00Z", "comment_text": "\n \t\tNo more TF bugs, <denchmark-link:https://github.com/skye>@skye</denchmark-link>\n ? :)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "girving", "commentT": "2019-03-15T16:42:58Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/nfelt>@nfelt</denchmark-link>\n  are you familiar with summary writers?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "girving", "commentT": "2019-03-15T16:45:09Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/skye>@skye</denchmark-link>\n  To clarify what I wrote wasn't intended to ask you to do anything, was just expressing sympathy as a fellow ex-tensorflow person who occasionally gets added to bugs.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "girving", "commentT": "2019-03-15T17:15:57Z", "comment_text": "\n \t\tHaha no worries <denchmark-link:https://github.com/girving>@girving</denchmark-link>\n , I just switched teams this week, so still figuring out what to do with all my github issues :)\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "girving", "commentT": "2019-03-15T20:12:37Z", "comment_text": "\n \t\tThanks for the report.  I can reproduce this against last night's tf-nightly on both macOS and Linux (for anyone else reproducing, maxrss is in bytes on macOS but kb on linux, so the raw numbers are about 1000x smaller).\n I also could still reproduce this even with tf.init_scope() removed.\n cc <denchmark-link:https://github.com/alextp>@alextp</denchmark-link>\n  if you have any intuition about what might be causing this.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "girving", "commentT": "2019-03-15T20:21:13Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rohan100jain>@rohan100jain</denchmark-link>\n  I think the issue is that SUMMARY_WRITER_INIT_OP keeps a strong reference to the graph instead of a weak reference, so the graph can never be GC'd.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "girving", "commentT": "2019-03-20T19:54:16Z", "comment_text": "\n \t\tIt looks like there are two problems, one large and one small:\n  Every  has a strong reference to the graph it lives inside (<denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L1921>https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L1921</denchmark-link>\n ).  This should probably be a weak reference.  This is presumably the cause of the leak, since we store a long lived reference to the op in  at <denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/summary_ops_v2.py#L221>https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/summary_ops_v2.py#L221</denchmark-link>\n .\n   should be something like a <denchmark-link:https://docs.python.org/3/library/weakref.html#weakref.WeakKeyDictionary>https://docs.python.org/3/library/weakref.html#weakref.WeakKeyDictionary</denchmark-link>\n  with keys being the graphs, not keys being strings that live forever.  Even if we fix the large issue the small issue would remain, and thus pretty much any use of  is a bug.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "girving", "commentT": "2019-03-21T15:42:45Z", "comment_text": "\n \t\tUpdate: I made a brief attempt at removing that one reference, but it didn't work, so I think there are others.  Probably a more concerted push is required.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "girving", "commentT": "2019-03-25T17:51:41Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/alextp>@alextp</denchmark-link>\n  <denchmark-link:https://github.com/rohan100jain>@rohan100jain</denchmark-link>\n  Did you get a chance to look at this?  I want to make sure it isn't dropped, since it's blocking my upgrade of TensorFlow.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "girving", "commentT": "2019-03-25T17:58:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/nfelt>@nfelt</denchmark-link>\n  can you look?\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "girving", "commentT": "2019-03-29T17:37:52Z", "comment_text": "\n \t\tWhat's the likely ETA here?  I'm still blocked from upgrading due to this, so if no one is planning to fix I'd like to know for my own planning purposes.  In particular, if it's going to be weeks more I will have to fix it myself, but then you have to be happy with my weakref design decisions.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "girving", "commentT": "2019-03-29T17:49:28Z", "comment_text": "\n \t\tI will try to take a closer look today, but if _SUMMARY_WRITER_INIT_OP isn't the main issue then I don't have a good guess at what the leak might be so it may take some time to figure this out.\n Just so I understand, which upgrade path exactly are you blocked on?  Is this upgrading from tf.summary to tf.contrib.summary?  Or did you notice that this leak occurs across a TF version update?\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "girving", "commentT": "2019-03-29T17:52:22Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/nfelt>@nfelt</denchmark-link>\n  Thanks!  The leak appears going from TensorFlow 1.12 to 1.13, so it's blocking the 1.13 upgrade (and therefore also my Python 3.7 upgrade).\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "girving", "commentT": "2019-03-29T18:00:57Z", "comment_text": "\n \t\tNote that it's quite possibly I simply failed to fix the _SUMMARY_WRITER_INIT_OP reference, but as I mentioned it does seem like every use of _graph_key is a bug, and therefore it feels likely that there are other strong references.\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "girving", "commentT": "2019-03-29T20:41:14Z", "comment_text": "\n \t\tCan you check whether using gc frees the graph?\n I.e., is this a simple reference cycle problem, or is a reference to the graph kept hidden someplace?\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "girving", "commentT": "2019-03-29T20:41:49Z", "comment_text": "\n \t\tAh... Of course as long as the summary init op reference exists, that won't help.\n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "girving", "commentT": "2019-03-29T20:51:13Z", "comment_text": "\n \t\tNope, gc.collect has no effect.\n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "girving", "commentT": "2019-03-29T21:00:48Z", "comment_text": "\n \t\tPer discussion with <denchmark-link:https://github.com/alextp>@alextp</denchmark-link>\n  I think what's easiest here is to revert the part of <denchmark-link:https://github.com/tensorflow/tensorflow/commit/aa8f428a9310b3fd8371bddf612e480b27618b2e>aa8f428</denchmark-link>\n  that changed this from a graph collection to a python dict.  That seems very likely to be the root cause, and it was changed due to deprecation of global collections, but this is a 1.x-only usage anyway, and that seems like the easiest way to fix the regression.\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "girving", "commentT": "2019-03-29T21:04:38Z", "comment_text": "\n \t\tThat sounds good.  Arguably global variables with references to graphs should be even more deprecated. :)\n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "girving", "commentT": "2019-03-31T03:41:35Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26684>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26684>No</denchmark-link>\n \n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "girving", "commentT": "2019-04-01T21:14:46Z", "comment_text": "\n \t\tI've confirmed that this fixes both my minimized test case and my unminimized original code.  Thank you <denchmark-link:https://github.com/nfelt>@nfelt</denchmark-link>\n !\n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "girving", "commentT": "2019-04-01T22:05:24Z", "comment_text": "\n \t\tGlad to hear that :)\n \t\t"}}}, "commit": {"commit_id": "097fc1cdef5c56d4bb239a5a44bf950f0b1c4d37", "commit_author": "Nick Felt", "commitT": "2019-03-30 20:38:06-07:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tensorflow\\python\\kernel_tests\\summary_ops_test.py", "file_new_name": "tensorflow\\python\\kernel_tests\\summary_ops_test.py", "file_complexity": {"file_NLOC": "962", "file_CCN": "118", "file_NToken": "7824"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "733", "deleted_lines": null, "method_info": {"method_name": "testNoMemoryLeak_eagerMode", "method_params": "self", "method_startline": "733", "method_endline": "736", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "36", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "727,728,729,730", "deleted_lines": "727", "method_info": {"method_name": "testEagerMemory", "method_params": "self", "method_startline": "727", "method_endline": "730", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "36", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "727,728,729,730", "deleted_lines": "727", "method_info": {"method_name": "testNoMemoryLeak_graphMode", "method_params": "self", "method_startline": "727", "method_endline": "730", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "35", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\python\\ops\\summary_ops_v2.py", "file_new_name": "tensorflow\\python\\ops\\summary_ops_v2.py", "file_complexity": {"file_NLOC": "559", "file_CCN": "137", "file_NToken": "3806"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "220", "deleted_lines": "219,220", "method_info": {"method_name": "__init__", "method_params": "self,shared_name,init_op_fn,name,v2", "method_startline": "208", "method_endline": "220", "method_complexity": {"method_NLOC": "12", "method_CCN": "2", "method_NToken": "95", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "539", "deleted_lines": null, "method_info": {"method_name": "summary_writer_initializer_op", "method_params": "", "method_startline": "526", "method_endline": "539", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "25", "method_nesting_level": "0"}}}}}}}}