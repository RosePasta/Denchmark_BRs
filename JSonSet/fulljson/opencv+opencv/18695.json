{"BR": {"BR_id": "18695", "BR_author": "JulienMaille", "BRopenT": "2020-10-29T14:55:38Z", "BRcloseT": "2020-11-20T19:13:43Z", "BR_text": {"BRsummary": "onnx 12: Inconsistent shape for ConcatLayer in function 'cv::dnn::ConcatLayerImpl::getMemoryShapes'", "BRdescription": "\n I'm working on a Unet model and the upsampling layers will trigger an exception when infering on an image with a different size than the training dataset: \n When exporting to onnx opset 9, inference work for any input size. The upsampling layer is defined as \n <denchmark-link:https://user-images.githubusercontent.com/182520/97590329-c6a4aa80-19fe-11eb-9fb7-59f4b9339a4f.png></denchmark-link>\n \n When exporting to onnx opset >9, inference work on 256\u00b2 only. The upsampling layer is defined as \n <denchmark-link:https://user-images.githubusercontent.com/182520/97588931-43368980-19fd-11eb-9ba6-e72b687ce29a.png></denchmark-link>\n \n I can provide both onnx by email if needed\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "JulienMaille", "commentT": "2020-10-29T21:31:10Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/alalek>@alalek</denchmark-link>\n  wasn't that PR <denchmark-link:https://github.com/opencv/opencv/pull/16490>#16490</denchmark-link>\n  supposed to handle this? <denchmark-link:https://github.com/opencv/opencv/pull/16490/files>https://github.com/opencv/opencv/pull/16490/files</denchmark-link>\n \n Scales seems to be taken from zoom_factor_x & zoom_factor_y\n \n \n \n opencv/modules/dnn/src/layers/resize_layer.cpp\n \n \n         Lines 32 to 34\n       in\n       691c3d1\n \n \n \n \n \n \n  ResizeLayerImpl(const LayerParams& params) : zoomFactorWidth(params.get<float>(\"zoom_factor_x\", params.get<float>(\"zoom_factor\", 0))), \n \n \n \n  zoomFactorHeight(params.get<float>(\"zoom_factor_y\", params.get<float>(\"zoom_factor\", 0))), \n \n \n \n                                               scaleWidth(0), scaleHeight(0) \n \n \n \n \n \n Would it work to get them from scales[2] & scales[3]?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "JulienMaille", "commentT": "2020-10-30T09:12:06Z", "comment_text": "\n \t\tI confirm that editing my onnx and adding \"zoom_factor_x\", \"zoom_factor_y\" will make it work. So what we would need is to read from scales input instead\n EDIT: which seems to be done here:\n \n \n \n opencv/modules/dnn/src/onnx/onnx_importer.cpp\n \n \n         Lines 1689 to 1700\n       in\n       199687a\n \n \n \n \n \n \n  int height = shapes.at<int>(2); \n \n \n \n  int width  = shapes.at<int>(3); \n \n \n \n  if (node_proto.input_size() == 3) \n \n \n \n  { \n \n \n \n      IterShape_t shapeIt = outShapes.find(node_proto.input(0)); \n \n \n \n  CV_Assert(shapeIt != outShapes.end()); \n \n \n \n      MatShape scales = shapeIt->second; \n \n \n \n      height *= scales[2]; \n \n \n \n      width  *= scales[3]; \n \n \n \n  } \n \n \n \n  layerParams.set(\"width\", width); \n \n \n \n  layerParams.set(\"height\", height); \n \n \n \n \n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "JulienMaille", "commentT": "2020-10-30T13:28:39Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/alalek>@alalek</denchmark-link>\n  I'd be glad to help but I don't understand why the code quoted from onnx_importer doesn't already fix the bug?\n EDIT: I think that when scales are present, the w/h should not be set on import, it should be kept dynamic in case the input size is not the default one, so maybe something like this:\n  int height = shapes.at<int>(2); \n  int width  = shapes.at<int>(3); \n  if (node_proto.input_size() == 3) \n  { \n      IterShape_t shapeIt = outShapes.find(node_proto.input(0)); \n      CV_Assert(shapeIt != outShapes.end()); \n      MatShape scales = shapeIt->second; \n      height = width = 0; \n      layerParams.set(\"zoom_factor_y\", scales[2]);\n      layerParams.set(\"zoom_factor_x\", scales[3]);\n  } \n  layerParams.set(\"width\", width); \n  layerParams.set(\"height\", height);\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "JulienMaille", "commentT": "2020-10-31T20:32:24Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/l-bat>@l-bat</denchmark-link>\n  I do not want to break your code, but going step by step trough onnw_importer for the  layer I find strange things.\n As you can see above, the node has 3 inputs: the , a , the  (in that order)\n So when you retrieve the last input here, you get the scales, not the cv::Mat\n \n \n And later when you retrieve the first input, you get the cv::Mat shape, not the scales\n \n \n Am I wrong?\n I would suggest something like this instead\n         else if (layer_type == \"Resize\")\n         {\n             [...]\n             if (node_proto.input_size() == 3)\n             {\n                 Mat scales = getBlob(node_proto, 2);\n                 CV_Assert(scales.total() == 4);\n                 layerParams.set(\"zoom_factor_y\", scales.at<float>(2));\n                 layerParams.set(\"zoom_factor_x\", scales.at<float>(3));\n             }\n             else\n             {\n                 MatShape shapes = outShapes[node_proto.input(0)];\n                 CV_Assert(shapes.size() == 4);\n                 layerParams.set(\"width\", shapes[2]);\n                 layerParams.set(\"height\", shapes[3]);\n             }\n             [...]\n         }\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "JulienMaille", "commentT": "2020-11-04T19:09:13Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/alalek>@alalek</denchmark-link>\n  looking at the code, it seems it's more a bug than a feature request. I'm really willing to help fixing it. Can I go ahead with suggestion above?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "JulienMaille", "commentT": "2020-11-16T14:27:35Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JulienMaille>@JulienMaille</denchmark-link>\n  you are right. We don't consider that only one of 'scales' and 'sizes' can be specified. Could you please to add  block to your pull request?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "JulienMaille", "commentT": "2020-11-16T14:51:41Z", "comment_text": "\n \t\tHello, thank you <denchmark-link:https://github.com/l-bat>@l-bat</denchmark-link>\n  Just to make it clear, do you mean I should push this code to my PR?\n if (node_proto.input_size() == 3)\n {\n     Mat scales = getBlob(node_proto, 2);\n     CV_Assert(scales.total() == 4);\n     layerParams.set(\"zoom_factor_y\", scales.at<float>(2));\n     layerParams.set(\"zoom_factor_x\", scales.at<float>(3));\n }\n else\n {\n     MatShape shapes = outShapes[node_proto.input(0)];\n     CV_Assert(shapes.size() == 4);\n     layerParams.set(\"width\", shapes[2]);\n     layerParams.set(\"height\", shapes[3]);\n }\n In the mean time I found your test model: <denchmark-link:https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/onnx/models/dynamic_resize.onnx>https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/onnx/models/dynamic_resize.onnx</denchmark-link>\n \n it has 4 inputs, not 3, which means, \"scale\" should be selected by name, instead of assuming it is the last one\n <denchmark-link:https://user-images.githubusercontent.com/182520/99260068-36969b80-281b-11eb-93f4-f26fccb5f362.png></denchmark-link>\n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "JulienMaille", "commentT": "2020-11-16T14:54:17Z", "comment_text": "\n \t\tYes, I think it's easier to understand. But you need a change:\n layerParams.set(\"width\", shapes[3]);\n layerParams.set(\"height\", shapes[2]);\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "JulienMaille", "commentT": "2020-11-16T14:56:07Z", "comment_text": "\n \t\tSorry I edited in the mean time, with an additional question.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "JulienMaille", "commentT": "2020-11-16T14:57:10Z", "comment_text": "\n \t\tThis is strange because official ONNX docs <denchmark-link:https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Resize-13>https://github.com/onnx/onnx/blob/master/docs/Changelog.md#Resize-13</denchmark-link>\n  say that \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "JulienMaille", "commentT": "2020-11-16T14:58:17Z", "comment_text": "\n \t\tWell, this onnx comes from your commit, and was sent to netron.app to look at the inputs.\n Is there a way to getBlob()` by its name, not position?\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "JulienMaille", "commentT": "2020-11-16T15:10:13Z", "comment_text": "\n \t\tIf we have 3 inputs, then we need to determine the last input of the scale or sizes. I think we can determine this by the data type, integer for sizes and float for scales.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "JulienMaille", "commentT": "2020-11-16T15:15:27Z", "comment_text": "\n \t\tAccording to doc <denchmark-link:https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/onnx/models/dynamic_resize.onnx>our model</denchmark-link>\n  is incorrect ( we are generating them for a different opset), because   Could you please generate a new model for tests?\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "JulienMaille", "commentT": "2020-11-16T15:16:09Z", "comment_text": "\n \t\t\n If we have 3 inputs, then we need to determine the last input of the scale or sizes. I think we can determine this by the data type, integer for sizes and float for scales.\n \n Do you mean the input name (shown by netron) is not available in opencv onnx importer?\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "JulienMaille", "commentT": "2020-11-16T15:23:26Z", "comment_text": "\n \t\tYes, in opencv we extract all inputs to CV::Mat\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "JulienMaille", "commentT": "2020-11-16T16:01:35Z", "comment_text": "\n \t\t\n According to doc our model is incorrect  Could you please generate a new model for tests?\n \n Can you provide some guidance on how to do this? I tried to edit the current one using onnx.helper but failed.\n     original_model = onnx.load('dynamic_resize.onnx')\n \n     for node in original_model.graph.node:\n         if node.op_type == 'Resize':\n             del node.input[-1]\n \n     # save fixed ONNX\n     onnx.save(original_model, 'dynamic_resize_fix.onnx')\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "JulienMaille", "commentT": "2020-11-16T17:51:30Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JulienMaille>@JulienMaille</denchmark-link>\n  Please use this script used for generation of .onnx test files: <denchmark-link:https://github.com/opencv/opencv_extra/blob/4.5.0/testdata/dnn/onnx/generate_onnx_models.py>https://github.com/opencv/opencv_extra/blob/4.5.0/testdata/dnn/onnx/generate_onnx_models.py</denchmark-link>\n \n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "JulienMaille", "commentT": "2020-11-16T18:53:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/alalek>@alalek</denchmark-link>\n  it's weird the python file has missing includes and wrong indenting, is it in use?\n Anyway, without change, the script will pass the final size to Upsample, and generate a model with inputs [X, roi, scales, sizes] so an incorrect model according to <denchmark-link:https://github.com/l-bat>@l-bat</denchmark-link>\n \n I would suggest to add a model passing scales to Upsample like this:\n class DynamicResizeScale(nn.Module):\n     def __init__(self):\n         super(DynamicResizeScale, self).__init__()\n \n     def forward(self, x, y):\n         h = y.size(2)\n         w = y.size(3)\n         up = nn.Upsample(scale_factor=(0.5, 0.5), mode='bilinear')\n         return up(x) + y\n \n input_0 = Variable(torch.randn(1, 3, 8, 6))\n input_1 = Variable(torch.randn(1, 3, 4, 3))\n model = DynamicResizeScale()\n save_data_and_model_multy_inputs(\"dynamic_resize_scale\", model, input_0, input_1, version=11)\n <denchmark-link:https://user-images.githubusercontent.com/182520/99295127-4f1bab80-2845-11eb-8d9f-e30899749686.png></denchmark-link>\n \n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "JulienMaille", "commentT": "2020-11-16T19:04:28Z", "comment_text": "\n \t\t\n we are generating them for a different opset\n \n It is possible to generate testdata for different opset versions (see version=).\n Also it is possible to check <denchmark-link:https://github.com/opencv/opencv/blob/4.5.0/modules/dnn/src/onnx/onnx_importer.cpp#L386>ONNX version of the model</denchmark-link>\n  during loading process and adjust layers interpretation.\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "JulienMaille", "commentT": "2020-11-16T19:12:09Z", "comment_text": "\n \t\tWith an up-to-date onnx package (1.8.0) highest opset is 12 and when exporting in 12 I still have 4 inputs with both scales and sizes\n save_data_and_model_multy_inputs(\"dynamic_resize\", model, input_0, input_1, version=12)\n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "JulienMaille", "commentT": "2020-11-16T19:15:55Z", "comment_text": "\n \t\tIn opset 11 resize has 3 or 4 parameters according to the manual:\n X : T1\n \n N-D tensor\n \n roi : T2\n \n 1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is \"tf_crop_and_resize\"\n \n scales : tensor(float)\n \n The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. Only one of 'scales' and 'sizes' can be specified. If 'size' is needed, the user can use an empty string as the name of 'scales' in this operator's input list.\n \n sizes (optional) : tensor(int64)\n \n The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. Only one of 'scales' and 'sizes' can be specified.\n \n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "JulienMaille", "commentT": "2020-11-16T19:30:20Z", "comment_text": "\n \t\tOk so I exported both models with different opset, this is what I got\n <denchmark-code>when giving size & opset  9 -> Upsample [X, scales]\n when giving size & opset 10 -> Resize   [X, scales]\n when giving size & opset 11 -> Resize   [X, roi, scales, sizes]\n \n when giving scales & opset  9 -> Upsample [X, scales]\n when giving scales & opset 10 -> Resize   [X, scales]\n when giving scales & opset 11 -> Resize   [X, roi, scales]\n </denchmark-code>\n \n So I could change my PR to this:\n             int opset = model_proto.has_ir_version() ? (int)model_proto.ir_version() : -1;\n             Mat scales;\n             switch (opset)\n             {\n                 case 12:\n                 case 11: scales = getBlob(node_proto, 2); break;\n                 default: scales = getBlob(node_proto, 1); break;\n             }\n \t\t"}}}, "commit": {"commit_id": "ac24a72e669a7550516dc92304792e3800b6c85c", "commit_author": "Julien", "commitT": "2020-11-20 11:14:00+00:00", "commit_complexity": {"commit_NLOC": "0.5555555555555556", "commit_CCN": "0.5555555555555556", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "modules\\dnn\\src\\onnx\\onnx_importer.cpp", "file_new_name": "modules\\dnn\\src\\onnx\\onnx_importer.cpp", "file_complexity": {"file_NLOC": "1691", "file_CCN": "340", "file_NToken": "14451"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1827,1828,1829,1830,1831,1832,1833,1834", "deleted_lines": "1749,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1767,1768,1772,1773,1774,1775,1776,1777,1779,1780,1781,1782,1783,1784,1785,1825,1826,1827,1828", "method_info": {"method_name": "cv::dnn::ONNXImporter::handleNode", "method_params": "node_proto_", "method_startline": "451", "method_endline": "1886", "method_complexity": {"method_NLOC": "1290", "method_CCN": "259", "method_NToken": "11250", "method_nesting_level": "2"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "modules\\dnn\\test\\test_onnx_importer.cpp", "file_new_name": "modules\\dnn\\test\\test_onnx_importer.cpp", "file_complexity": {"file_NLOC": "867", "file_CCN": "300", "file_NToken": "5538"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "521,522,523,524,525,526", "deleted_lines": "521", "method_info": {"method_name": "opencv_test::TEST_P", "method_params": "Test_ONNX_layers,DynamicResize", "method_startline": "519", "method_endline": "527", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "110", "method_nesting_level": "2"}}}}}}}}