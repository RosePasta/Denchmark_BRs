{"BR": {"BR_id": "2000", "BR_author": "tgravescs", "BRopenT": "2020-05-29T20:35:30Z", "BRcloseT": "2020-06-02T17:21:09Z", "BR_text": {"BRsummary": "pyarrow 0.17 changed hdfs.connect api to remove driver parameter", "BRdescription": "\n Environment:\n \n Framework: (TensorFlow, Keras, PyTorch, MXNet) Keras Estimator example\n Framework version:\n Horovod version:  master branch\n MPI version:\n CUDA version:\n NCCL version:\n Python version:\n OS and version:\n GCC version:\n \n Checklist:\n \n Did you search issues to find if somebody asked this question before?\n If your question is about hang, did you read this doc?\n If your question is about docker, did you read this doc?\n Did you check if you question is answered in the troubleshooting guide?\n \n Bug report:\n Please describe errorneous behavior you're observing and steps to reproduce it.\n Trying to run with the latest horovod code with pyarrow 0.17.1 against HDFS for the working directory and it fails with:\n <denchmark-code>Traceback (most recent call last):\n   File \"keras_spark_rossmann_estimator.py\", line 408, in <module>\n     store = Store.create(args.work_dir)\n   File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 141, in create\n     return HDFSStore(prefix_path, *args, **kwargs)\n   File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 337, in __init__\n     self._hdfs = self._get_filesystem_fn()()\n   File \"/usr/local/lib/python3.8/dist-packages/horovod/spark/common/store.py\", line 416, in fn\n     return pa.hdfs.connect(**hdfs_kwargs)\n TypeError: connect() got an unexpected keyword argument 'driver'\n </denchmark-code>\n \n It looks like pyarrow removed that parameter with commit:\n <denchmark-link:https://github.com/apache/arrow/commit/4e53749097ba687afd5e000067925def2e2802c9#diff-72abd78694ddde2b1a059b194978b77b>apache/arrow@4e53749#diff-72abd78694ddde2b1a059b194978b77b</denchmark-link>\n \n Note I called it like:\n python keras_spark_rossmann_estimator.py --num-proc 2 --batch-size 1000 --epochs 2 --master spark://3ee9bf36f06b:7077 --work-dir hdfs:///rossmann\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "tgravescs", "commentT": "2020-05-29T20:37:50Z", "comment_text": "\n \t\tNote this is setup here: <denchmark-link:https://github.com/horovod/horovod/blob/master/horovod/spark/common/store.py#L335>https://github.com/horovod/horovod/blob/master/horovod/spark/common/store.py#L335</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "tgravescs", "commentT": "2020-06-01T18:05:03Z", "comment_text": "\n \t\tit looks like the older version of pyarrow may also only support Hadoop 2.x. Its failing with class mismatch exception when I run on hdfs 3.x.  I see they have a new api for filesystems, not sure if that supports both\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "tgravescs", "commentT": "2020-06-01T18:21:55Z", "comment_text": "\n \t\tThanks for the detailed report <denchmark-link:https://github.com/tgravescs>@tgravescs</denchmark-link>\n .  Can you try <denchmark-link:https://github.com/horovod/horovod/pull/2003>#2003</denchmark-link>\n  and verify whether it fixes the issue?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "tgravescs", "commentT": "2020-06-01T18:28:13Z", "comment_text": "\n \t\tso I tried a similar patch myself, but I think it failed with petastorm also using the parameter. I don't have the error around to show the trace.\n I tried using older version of  pyarrow which gets around this error but then fails to work with Hadoop 3.1.3, looks like Hadoop version mismatch.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "tgravescs", "commentT": "2020-06-01T18:36:15Z", "comment_text": "\n \t\tLet me see if I can get a fix in to Petastorm for this.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "tgravescs", "commentT": "2020-06-01T18:51:48Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tgravescs>@tgravescs</denchmark-link>\n  can you similarly try installing petastorm from <denchmark-link:https://github.com/uber/petastorm/pull/556>this</denchmark-link>\n  PR and see if it unblocks the issue?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "tgravescs", "commentT": "2020-06-01T20:05:02Z", "comment_text": "\n \t\tgiving it a try\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "tgravescs", "commentT": "2020-06-01T22:30:03Z", "comment_text": "\n \t\tso those 2 patches lets me use pyarrow 0.17.1 I can't access hdfs still. It looks like a version mismatch issue - either with protobuf or Hadoop versions. I'm not sure if its just an issue with my setup or something in the docker file build.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "tgravescs", "commentT": "2020-06-01T22:53:18Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tgravescs>@tgravescs</denchmark-link>\n  can you share the error message in a gist or pastebin?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "tgravescs", "commentT": "2020-06-01T22:57:45Z", "comment_text": "\n \t\t<denchmark-link:https://gist.github.com/tgravescs/1d825fc334b9c03bda540616e6718125>https://gist.github.com/tgravescs/1d825fc334b9c03bda540616e6718125</denchmark-link>\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "tgravescs", "commentT": "2020-06-01T23:11:56Z", "comment_text": "\n \t\tThanks, seems this is a classpath issue of some kind, according to sources online (<denchmark-link:https://stackoverflow.com/questions/49808271/java-lang-classcastexception-cannot-be-cast-to-com-google-protobuf-message>https://stackoverflow.com/questions/49808271/java-lang-classcastexception-cannot-be-cast-to-com-google-protobuf-message</denchmark-link>\n ).  Did you make any additional modifications to the Docker image for Spark 3?\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "tgravescs", "commentT": "2020-06-01T23:18:18Z", "comment_text": "\n \t\tthe only difference is the docker image uses the newest version of Spark built against Hadoop 3.1, then running on yarn 3.1 includes the Hadoop jars and such from Yarn.  Those are all 3.1 jars though.  It really looks like its a protobuf mismatch but I haven't been able to track it exactly.  I see tensor flow pulls a version of protobuf but not sure.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "tgravescs", "commentT": "2020-06-01T23:26:11Z", "comment_text": "\n \t\tYes, TensorFlow's imported version of protobuf is a frequent problem (<denchmark-link:https://github.com/horovod/horovod/issues/686>#686</denchmark-link>\n ).  Are you using TensorFlow 2.2?  They're using Protobuf 3.8 (<denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/workspace.bzl#L475>https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/workspace.bzl#L475</denchmark-link>\n ).\n There are some <denchmark-link:https://stackoverflow.com/questions/46235376/tensorflow-protobuf-version-mismatch>suggestions</denchmark-link>\n  here to deal with it.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "tgravescs", "commentT": "2020-06-01T23:43:25Z", "comment_text": "\n \t\tyes tensor flow 2.2.\n I was hoping tensor flow had fixed with <denchmark-link:https://github.com/tensorflow/ecosystem/pull/30/files>https://github.com/tensorflow/ecosystem/pull/30/files</denchmark-link>\n  but looks like that is only the tensorflow-hadoop package. looks like Hadoop 3.3 will update protobuf but that isn't out yet: <denchmark-link:https://issues.apache.org/jira/browse/HADOOP-16557>https://issues.apache.org/jira/browse/HADOOP-16557</denchmark-link>\n \n You must not run this on hdfs at this point because I assume it doesn't work with Hadoop 2.x either?\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "tgravescs", "commentT": "2020-06-02T00:12:02Z", "comment_text": "\n \t\tI'll try to write small test program to narrow it down and see if that is really the issue\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "tgravescs", "commentT": "2020-06-02T00:44:42Z", "comment_text": "\n \t\tok so I wrote a small program in a clean environment without horovod and tried different hdfs setups and it appears pyarrow connectivity works with Hadoop 2.x but gives the error above with 3.x\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "tgravescs", "commentT": "2020-06-02T17:01:29Z", "comment_text": "\n \t\tnote this works on the Hadoop 2.9 cluster so I think its good from that perspective. I filed an arrow jira to see if they support Hadoop 3.x <denchmark-link:https://issues.apache.org/jira/browse/ARROW-9019>https://issues.apache.org/jira/browse/ARROW-9019</denchmark-link>\n \n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "tgravescs", "commentT": "2020-06-02T17:12:14Z", "comment_text": "\n \t\tThanks for verifying, <denchmark-link:https://github.com/tgravescs>@tgravescs</denchmark-link>\n .  We'll go ahead and land the fix, then.\n \t\t"}}}, "commit": {"commit_id": "ffc2b4fb07e0a63b1df20179fd32f4bd37fe3511", "commit_author": "Travis Addair", "commitT": "2020-06-02 10:21:08-07:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "horovod\\spark\\common\\store.py", "file_new_name": "horovod\\spark\\common\\store.py", "file_complexity": {"file_NLOC": "304", "file_CCN": "93", "file_NToken": "1977"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "23,24,338,339", "deleted_lines": "335"}}}}}}