{"BR": {"BR_id": "1573", "BR_author": "pstjohn", "BRopenT": "2019-12-06T14:56:31Z", "BRcloseT": "2020-01-09T21:03:12Z", "BR_text": {"BRsummary": "tf.keras.optimizers.schedules not supported by distributed optimizer", "BRdescription": "\n Environment:\n \n Framework: (TensorFlow, Keras, PyTorch, MXNet)\n tensorflow\n Framework version:\n 2.0.0\n Horovod version:\n 0.18.2\n MPI version:\n openmpi/3.1.3\n CUDA version:\n cuda/10.0.130\n NCCL version:\n 2.4.8\n Python version:\n 3.7\n OS and version:\n centos 7\n GCC version:\n \n Checklist:\n \n Did you search issues to find if somebody asked this question before?\n If your question is about hang, did you read this doc?\n If your question is about docker, did you read this doc?\n Did you check if you question is answered in the troubleshooting guide?\n \n Bug report:\n Please describe errorneous behavior you're observing and steps to reproduce it.\n Using tensorflow's <denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay>LearningRateSchedules</denchmark-link>\n  doesn't appear to work with horovod's distributed optimizer. This might be an easier way of implementing warmup than horovod's keras callbacks.\n Modifying the example tensorflow_keras_mnist.py with the following lines gives this error message\n # Horovod: adjust learning rate based on number of GPUs.\n lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n     0.001 * hvd.size(),\n     decay_steps=100000,\n     decay_rate=0.96,\n     staircase=True)\n opt = tf.keras.optimizers.Adam(lr_schedule)\n \n # Horovod: add Horovod DistributedOptimizer.\n opt = hvd.DistributedOptimizer(opt)\n <denchmark-code>[1,0]<stderr>:Traceback (most recent call last):\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 541, in __getattribute__\n [1,0]<stderr>:    return super(OptimizerV2, self).__getattribute__(name)\n [1,0]<stderr>:AttributeError: 'Adam' object has no attribute 'lr'\n [1,0]<stderr>:\n [1,0]<stderr>:During handling of the above exception, another exception occurred:\n [1,0]<stderr>:\n [1,0]<stderr>:Traceback (most recent call last):\n [1,0]<stderr>:  File \"tensorflow_keras_mnist.py\", line 94, in <module>\n [1,0]<stderr>:    mnist_model.fit(dataset, steps_per_epoch=500 // hvd.size(), callbacks=callbacks, epochs=24, verbose=verbose)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\n [1,0]<stderr>:    use_multiprocessing=use_multiprocessing)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 693, in fit\n [1,0]<stderr>:    steps_name='steps_per_epoch')\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 196, in model_iteration\n [1,0]<stderr>:    callbacks._call_begin_hook(mode)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 249, in _call_begin_hook\n [1,0]<stderr>:    self.on_train_begin()\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 365, in on_train_begin\n [1,0]<stderr>:    callback.on_train_begin(logs)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/horovod/_keras/callbacks.py\", line 137, in on_train_begin\n [1,0]<stderr>:    self.initial_lr = self.backend.get_value(self.model.optimizer.lr)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 550, in __getattribute__\n [1,0]<stderr>:    return self._get_hyper(name)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 527, in _get_hyper\n [1,0]<stderr>:    self._create_hypers()\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 643, in _create_hypers\n [1,0]<stderr>:    aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 805, in add_weight\n [1,0]<stderr>:    aggregation=aggregation)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 744, in _add_variable_with_custom_getter\n [1,0]<stderr>:    **kwargs_for_getter)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 139, in make_variable\n [1,0]<stderr>:    shape=variable_shape if variable_shape else None)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n [1,0]<stderr>:    return cls._variable_v1_call(*args, **kwargs)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n [1,0]<stderr>:    shape=shape)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n [1,0]<stderr>:    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2507, in default_variable_creator\n [1,0]<stderr>:    shape=shape)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n [1,0]<stderr>:    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\n [1,0]<stderr>:    distribute_strategy=distribute_strategy)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resourc[1,0]<stderr>:e_variable_ops.py\", line 1538, in _init_from_args\n [1,0]<stderr>:    name=\"initial_value\", dtype=dtype)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1184, in convert_to_tensor\n [1,0]<stderr>:    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1242, in convert_to_tensor_v2\n [1,0]<stderr>:    as_ref=False)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1296, in internal_convert_to_tensor\n [1,0]<stderr>:    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 286, in _constant_tensor_conversion_function\n [1,0]<stderr>:    return constant(v, dtype=dtype, name=name)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 227, in constant\n [1,0]<stderr>:    allow_broadcast=True)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 235, in _constant_impl\n [1,0]<stderr>:    t = convert_to_eager_tensor(value, ctx, dtype)\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 96, in convert_to_eager_tensor\n [1,0]<stderr>:    return ops.EagerTensor(value, ctx.device_name, dtype)\n [1,0]<stderr>:ValueError: Attempt to convert a value ({'class_name': 'ExponentialDecay', 'config': {'initial_learning_rate': 0.001, 'decay_steps': 100000, 'decay_rate': 0.96, 'staircase': True, 'name': None}}) with an unsupported type (<class 'dict'>) to a Tensor.\n [1,0]<stderr>:Exception ignored in: <function _RandomSeedGeneratorDeleter.__del__ at 0x7f7dec944a70>\n [1,0]<stderr>:Traceback (most recent call last):\n [1,0]<stderr>:  File \"/home/pstjohn/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3009, in __del__\n [1,0]<stderr>:AttributeError: 'NoneType' object has no attribute 'device'\n --------------------------------------------------------------------------\n Primary job  terminated normally, but 1 process returned\n a non-zero exit code. Per user-direction, the job has been aborted.\n --------------------------------------------------------------------------\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "pstjohn", "commentT": "2019-12-16T04:25:48Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/pstjohn>@pstjohn</denchmark-link>\n , thanks for raising this issue.  And apologies for not getting back to you sooner.\n Looks like this is being caused by passing the optimizer config as keyword args without using .  This required a change on our end, since we are overriding this method as of <denchmark-link:https://github.com/horovod/horovod/pull/1444>#1444</denchmark-link>\n .  In TensorFlow's implementation, they handle the learning rate schedule specially, which was causing this error.  See: <denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L719>optimizer_v2.py</denchmark-link>\n .\n I put together <denchmark-link:https://github.com/horovod/horovod/pull/1588>#1588</denchmark-link>\n  to fix this.  Please try it out if you get a chance, and let me know if it solves your issue.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "pstjohn", "commentT": "2020-01-10T21:32:18Z", "comment_text": "\n \t\tThanks for this fix!! Sorry for not replying earlier, I hadn't previously been working off the horovod master, so I was looking into how to best build from source :)\n This is great though, I'm looking forward to using these lr schedules\n \t\t"}}}, "commit": {"commit_id": "438880e2a1744b309527b8b10d0bd88a77c6e565", "commit_author": "Travis Addair", "commitT": "2020-01-09 13:03:11-08:00", "commit_complexity": {"commit_NLOC": "0.5714285714285714", "commit_CCN": "1.0", "commit_Nprams": "0.875"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": ".buildkite\\gen-pipeline.sh", "file_new_name": ".buildkite\\gen-pipeline.sh", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "103,104,105,204,205,209", "deleted_lines": "103,202,206"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "horovod\\_keras\\__init__.py", "file_new_name": "horovod\\_keras\\__init__.py", "file_complexity": {"file_NLOC": "72", "file_CCN": "23", "file_NToken": "583"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "74,75", "method_info": {"method_name": "from_config", "method_params": "cls,cfg", "method_startline": "74", "method_endline": "75", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "22", "method_nesting_level": "2"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "64,65,66,67", "deleted_lines": "67,68", "method_info": {"method_name": "apply_gradients", "method_params": "self,args,kwargs", "method_startline": "62", "method_endline": "68", "method_complexity": {"method_NLOC": "7", "method_CCN": "2", "method_NToken": "43", "method_nesting_level": "2"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "23,24,30", "deleted_lines": "23,24,25,26,27", "method_info": {"method_name": "__init__", "method_params": "self,kwargs", "method_startline": "23", "method_endline": "30", "method_complexity": {"method_NLOC": "8", "method_CCN": "2", "method_NToken": "62", "method_nesting_level": "2"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "23,24", "deleted_lines": "23,24", "method_info": {"method_name": "__init__", "method_params": "self,name,device_dense,device_sparse,compression,sparse_as_dense,config", "method_startline": "23", "method_endline": "24", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "17", "method_nesting_level": "2"}}}}}, "file_2": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\test_tensorflow2_keras.py", "file_complexity": {"file_NLOC": "65", "file_CCN": "6", "file_NToken": "540"}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "test\\test_tensorflow_keras.py", "file_new_name": "test\\test_tensorflow_keras.py", "file_complexity": {"file_NLOC": "74", "file_CCN": "6", "file_NToken": "618"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "16,39", "deleted_lines": "16,39"}}}}}}