{"BR": {"BR_id": "14", "BR_author": "gshpychka", "BRopenT": "2018-09-26T18:35:53Z", "BRcloseT": "2018-11-22T07:50:33Z", "BR_text": {"BRsummary": "f1_score: nan", "BRdescription": "\n At some low threshold of precision and recall, f1_score becomes nan. I'm getting outputs like this:\n 2306/10000 [=====>........................] - ETA: 21:25 - loss: 0.7265 - precision: 0.5095 - recall: 0.4593 - f1_score: nan\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "gshpychka", "commentT": "2018-09-30T09:28:13Z", "comment_text": "\n \t\tI am not sure that it has to do with some low threshold.\n Training goes something like this:\n <denchmark-code>1/10000 [..............................] - ETA: 26:00 - loss: 0.4511 - precision: 0.3333 - recall: 0.3333 - f1_score: 0.3333\n \n 2/10000 [..............................] - ETA: 25:25 - loss: 0.4070 - precision: 0.4167 - recall: 0.3095 - f1_score: 0.3485\n \n 3/10000 [..............................] - ETA: 25:23 - loss: 0.4379 - precision: 0.2778 - recall: 0.2063 - f1_score: nan  \n \n 4/10000 [..............................] - ETA: 25:32 - loss: 0.4203 - precision: 0.2440 - recall: 0.4048 - f1_score: nan\n </denchmark-code>\n \n And then it's 'nan's all the way down. Even if precision and recall go up to relatively decent numbers.\n What kind of information would help you narrow this down?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "gshpychka", "commentT": "2018-09-30T19:25:55Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/gshpychka>@gshpychka</denchmark-link>\n , thank you a lot for posting the issue, this looks very strange. I wasn't being able to look into this issue last week, hopefully I'll figure out why is this happening on this one.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "gshpychka", "commentT": "2018-10-01T09:44:09Z", "comment_text": "\n \t\tHeres my two cents:\n 100/17172 [..............................] - ETA: 7:09 - loss: 0.0527 - acc: 0.9700 - precision: 0.8000 - recall: 0.8750 - f1_score: 0.8036\n 150/17172 [..............................] - ETA: 7:08 - loss: 0.0462 - acc: 0.9733 - precision: 0.8667 - recall: 0.8056 - f1_score: 0.8024\n 200/17172 [..............................] - ETA: 7:07 - loss: 0.0398 - acc: 0.9800 - precision: 0.9000 - recall: 0.8542 - f1_score: 0.8518\n 250/17172 [..............................] - ETA: 7:07 - loss: 0.0359 - acc: 0.9840 - precision: 0.9200 - recall: 0.8833 - f1_score: 0.8814\n 300/17172 [..............................] - ETA: 7:06 - loss: 0.0593 - acc: 0.9733 - precision: 0.8778 - recall: 0.8472 - f1_score: 0.8456\n 350/17172 [..............................] - ETA: 7:06 - loss: 0.0539 - acc: 0.9771 - precision: 0.8952 - recall: 0.8690 - f1_score: 0.8677\n 400/17172 [..............................] - ETA: 7:05 - loss: 0.0607 - acc: 0.9750 - precision: 0.9083 - recall: 0.8354 - f1_score: 0.8530\n 450/17172 [..............................] - ETA: 7:03 - loss: 0.0602 - acc: 0.9733 - precision: 0.9185 - recall: 0.8093 - f1_score: 0.8415\n 500/17172 [..............................] - ETA: 7:02 - loss: 0.0570 - acc: 0.9740 - precision: 0.8267 - recall: 0.7283 - f1_score: nan\n 550/17172 [..............................] - ETA: 7:00 - loss: 0.0579 - acc: 0.9727 - precision: 0.7970 - recall: 0.7076 - f1_score: nan\n 600/17172 [>.............................] - ETA: 6:59 - loss: 0.0565 - acc: 0.9750 - precision: 0.8139 - recall: 0.7319 - f1_score: nan\n 650/17172 [>.............................] - ETA: 6:58 - loss: 0.0531 - acc: 0.9769 - precision: 0.8282 - recall: 0.7526 - f1_score: nan\n 700/17172 [>.............................] - ETA: 6:56 - loss: 0.0535 - acc: 0.9771 - precision: 0.8405 - recall: 0.7583 - f1_score: nan\n 750/17172 [>.............................] - ETA: 6:55 - loss: 0.0510 - acc: 0.9787 - precision: 0.8511 - recall: 0.7744 - f1_score: nan\n 800/17172 [>.............................] - ETA: 6:54 - loss: 0.0503 - acc: 0.9800 - precision: 0.8604 - recall: 0.7885 - f1_score: nan\n 850/17172 [>.............................] - ETA: 6:53 - loss: 0.0505 - acc: 0.9800 - precision: 0.8569 - recall: 0.8010 - f1_score: nan\n Not sure if its connected to P/R values or epoch numer (i.e. it gets overwritten by something/nan) or something else.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "gshpychka", "commentT": "2018-10-01T09:46:21Z", "comment_text": "\n \t\tI don't actually think that it has to do with the values of P and R. Seems like it disappears after some number of iterations.\n See above - it displayed fine at much lower values of P and R, before disappearing.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "gshpychka", "commentT": "2018-10-01T09:47:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/gshpychka>@gshpychka</denchmark-link>\n  just updated my comment as in later batches, with P/R > 0.8, nan was calculated as f1 score.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "gshpychka", "commentT": "2018-10-24T16:36:16Z", "comment_text": "\n \t\t^ In fact, the code that keras used to use is much simpler. Might want to just copy that over.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "gshpychka", "commentT": "2018-10-25T17:49:38Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/gshpychka>@gshpychka</denchmark-link>\n , <denchmark-link:https://github.com/deakkon>@deakkon</denchmark-link>\n  could you, please, verify that the issue is gone in version ?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "gshpychka", "commentT": "2018-11-22T07:50:33Z", "comment_text": "\n \t\tClosing the issue, it is resolved in 0.0.5 version.\n \t\t"}}}, "commit": {"commit_id": "46bcce7d9e59d469ea60d5fc4ce5a4da1016d561", "commit_author": "Dan Grahn", "commitT": "2018-10-25 20:20:18+03:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "keras_metrics\\metrics.py", "file_new_name": "keras_metrics\\metrics.py", "file_complexity": {"file_NLOC": "157", "file_CCN": "28", "file_NToken": "1211"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "241", "deleted_lines": "241", "method_info": {"method_name": "__call__", "method_params": "self,y_true,y_pred", "method_startline": "237", "method_endline": "241", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "48", "method_nesting_level": "1"}}}}}}}}