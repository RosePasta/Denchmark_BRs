{"BR": {"BR_id": "273", "BR_author": "Eugene-1984", "BRopenT": "2019-04-02T10:01:05Z", "BRcloseT": "2019-04-10T18:46:23Z", "BR_text": {"BRsummary": "JSONDecodeError in `onnxmltools.utils.save_text` function", "BRdescription": "\n Hi! I am wondering about onnxmltools.utils.save_text function. The example on title page says:\n <denchmark-code># Save as text\n onnxmltools.utils.save_text(onnx_model, 'example.json')\n </denchmark-code>\n \n So I expected the output file to be a valid JSON but it is not. Here is the example code copied from the title page; MWE:\n <denchmark-code>import onnxmltools\n from keras.layers import Input, Dense, Add\n from keras.models import Model\n \n # N: batch size, C: sub-model input dimension, D: final model's input dimension\n N, C, D = 2, 3, 3\n \n # Define a sub-model, it will become a part of our final model\n sub_input1 = Input(shape=(C,))\n sub_mapped1 = Dense(D)(sub_input1)\n sub_model1 = Model(inputs=sub_input1, outputs=sub_mapped1)\n \n # Define another sub-model, it will become a part of our final model\n sub_input2 = Input(shape=(C,))\n sub_mapped2 = Dense(D)(sub_input2)\n sub_model2 = Model(inputs=sub_input2, outputs=sub_mapped2)\n \n # Define a model built upon the previous two sub-models\n input1 = Input(shape=(D,))\n input2 = Input(shape=(D,))\n mapped1_2 = sub_model1(input1)\n mapped2_2 = sub_model2(input2)\n sub_sum = Add()([mapped1_2, mapped2_2])\n keras_model = Model(inputs=[input1, input2], output=sub_sum)\n \n # Convert it! The target_opset parameter is optional.\n onnx_model = onnxmltools.convert_keras(keras_model, target_opset=7) \n \n onnxmltools.utils.save_text(onnx_model, 'example.json')\n \n import json\n with open('example.json') as f:\n     json.load(f)\n </denchmark-code>\n \n yields error: JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n So... can I somehow obtain a valid JSON out of converted ONNX model?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Eugene-1984", "commentT": "2019-04-04T20:17:49Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/Eugene-1984>@Eugene-1984</denchmark-link>\n ! Thanks for letting us know about your experience with the .save_text function.\n Your call to the save_text function looks correct. We're looking into this behavior and apologize for any inconvenience caused.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Eugene-1984", "commentT": "2019-04-08T22:54:36Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Eugene-1984>@Eugene-1984</denchmark-link>\n   is a protobuf object not a json, so json.load should not work. The function  is a legacy code, we need deprecate it, just use to save it into binary file. This library does not support the conversion to json.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Eugene-1984", "commentT": "2019-04-09T06:10:47Z", "comment_text": "\n \t\t@jiafatomm is there any way to obtain a json-like structure from a binary model? my final goal is to get the description of the network as it is in ONNX model and yet if I load a simple mode to, say, TensorFlow, it will add tons of additional nodes and complicate the graph. I hope that onnxmltools will help me in that.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Eugene-1984", "commentT": "2019-04-09T16:53:14Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Eugene-1984>@Eugene-1984</denchmark-link>\n  The binary model is actually a protobuf object, so when you load the model, you get the protobuf object. So your question is actually to convert protobuf to json. This is a general question and you can find various answers on Internet. Since this is not onnx specific, onnxmltools does not support it currently.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Eugene-1984", "commentT": "2019-04-09T20:22:07Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Eugene-1984>@Eugene-1984</denchmark-link>\n  The following script should help you get started! Remember to  and  in your environment.\n <denchmark-code>from google.protobuf.json_format import MessageToJson\n import onnx\n import json\n \n model = onnx.load('model.onnx')\n jsonObj = MessageToJson(model)\n \n with open('model.json', 'w') as outfile:\n     json.dump(jsonObj, outfile)\n \n with open('model.json') as infile:\n     j_model = json.load(infile)\n </denchmark-code>\n \n j_model is now a json string with the contents of model.json. If you would prefer the output as a dictionary, please include the following line: dict_model = json.loads(j_model)\n See the top voted answer here: <denchmark-link:https://stackoverflow.com/questions/19734617/protobuf-to-json-in-python>https://stackoverflow.com/questions/19734617/protobuf-to-json-in-python</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "903f5d81531f0d5f8b727aec822cd7ab29582973", "commit_author": "Vinitra Swamy", "commitT": "2019-04-10 11:46:21-07:00", "commit_complexity": {"commit_NLOC": "0.09090909090909091", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "README.md", "file_new_name": "README.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": "57,58,59"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "onnxmltools\\__init__.py", "file_new_name": "onnxmltools\\__init__.py", "file_complexity": {"file_NLOC": "18", "file_CCN": "0", "file_NToken": "54"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": "30"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "onnxmltools\\utils\\__init__.py", "file_new_name": "onnxmltools\\utils\\__init__.py", "file_complexity": {"file_NLOC": "12", "file_CCN": "0", "file_NToken": "69"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": "9"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxmltools\\utils\\main.py", "file_new_name": "onnxmltools\\utils\\main.py", "file_complexity": {"file_NLOC": "39", "file_CCN": "21", "file_NToken": "327"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74", "method_info": {"method_name": "save_text", "method_params": "model,file_path", "method_startline": "57", "method_endline": "74", "method_complexity": {"method_NLOC": "5", "method_CCN": "3", "method_NToken": "47", "method_nesting_level": "0"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\baseline\\test_convert_baseline.py", "file_new_name": "tests\\baseline\\test_convert_baseline.py", "file_complexity": {"file_NLOC": "43", "file_CCN": "8", "file_NToken": "319"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "26,27", "deleted_lines": "29", "method_info": {"method_name": "get_diff", "method_params": "self,input_file,ref_file", "method_startline": "17", "method_endline": "32", "method_complexity": {"method_NLOC": "16", "method_CCN": "2", "method_NToken": "158", "method_nesting_level": "1"}}}}}, "file_5": {"file_change_type": "DELETE", "file_Nmethod": 0, "file_old_name": "tests\\utils\\models\\coreml_OneHotEncoder_BikeSharing.json", "file_new_name": "None", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_6": {"file_change_type": "DELETE", "file_Nmethod": 0, "file_old_name": "tests\\utils\\models\\coreml_OneHotEncoder_BikeSharing_Op9.json", "file_new_name": "None", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\utils\\test_utils.py", "file_new_name": "tests\\utils\\test_utils.py", "file_complexity": {"file_NLOC": "90", "file_CCN": "10", "file_NToken": "987"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58", "method_info": {"method_name": "test_save_text", "method_params": "self", "method_startline": "40", "method_endline": "58", "method_complexity": {"method_NLOC": "18", "method_CCN": "3", "method_NToken": "135", "method_nesting_level": "1"}}}}}}}}