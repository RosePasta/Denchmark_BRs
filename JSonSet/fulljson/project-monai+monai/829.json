{"BR": {"BR_id": "829", "BR_author": "jillianlee", "BRopenT": "2020-07-30T04:02:53Z", "BRcloseT": "2020-08-06T15:09:11Z", "BR_text": {"BRsummary": "Error with tensor size using ArrayDataset, but not with CacheDataset?", "BRdescription": "\n Hello,\n I'm trying to use ArrayDataset to train a UNet with a single channeled image. I have my own data augmentation procedure that passes array data of size (160, 160) to ArrayDataset. I use the only the minimum transforms as follows:\n <denchmark-code>transforms = Compose([\n     AddChannel(),\n     ToTensor()\n     ])\n </denchmark-code>\n \n After running through the data loader, I get a tensor of size (1, 160, 160).\n I then try and use a UNet with configurations\n model = monai.networks.nets.UNet(dimensions=2, in_channels=1, out_channels=1, channels=(16, 32, 64), strides=(2, 2), num_res_units=2, norm=Norm.BATCH).to(device)\n This throws the following error:\n RuntimeError: Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 3-dimensional input of size [1, 160, 160] instead\n I had previously been able to train a UNet with these configurations with a CacheDataset structure, reading directly from the Nifti files and applying the following transforms:\n <denchmark-code>train_transforms = Compose([\n     LoadNiftid(keys=['image', 'label']),\n     AddChanneld(keys=['image', 'label']),\n     Spacingd(keys=['image', 'label'], pixdim=(1.5, 1.5, 2.), mode=('bilinear', 'nearest')),\n     Orientationd(keys=['image', 'label'], axcodes='RAS'),\n     Resized(keys=['image'], spatial_size = (160, 160, 72)),\n     Resized(keys=['label'], spatial_size = (160, 160, 72)),\n     RandSpatialCropSamplesd(keys=['image', 'label'], roi_size=[160, 160, 1], num_samples = 72, random_center = True, random_size = False),\n     SqueezeDimd(keys=['image', 'label'], dim=-1),\n     ToNumpyd(keys=['image', 'label'])\n ])\n </denchmark-code>\n \n The shape of the image tensor output from these transforms is (160, 160).\n Is the size of the output tensor the issue? Should I do an external squeeze or is there something else I'm doing wrong in setting up the ArrayDataset?\n Thanks,\n Jillian\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jillianlee", "commentT": "2020-07-30T14:58:21Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/jillianlee>@jillianlee</denchmark-link>\n  ,\n Thanks for your interest here and experiments.\n I think the expected shape of output data from DataLoader is [B, C, H, W], but seems your shape is [C, H, W].\n May I know what's your batch size?\n Thanks.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jillianlee", "commentT": "2020-07-30T16:12:43Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/Nic-Ma>@Nic-Ma</denchmark-link>\n \n The batch_size is set to 2 or 1 in both experiments for training and validation respectively.\n Thanks,\n Jillian\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jillianlee", "commentT": "2020-08-03T13:52:54Z", "comment_text": "\n \t\tOK, I can't guess the root cause now, could you please help paste your program here?\n I don't know why the data is not batched after DataLoader.\n Thanks.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jillianlee", "commentT": "2020-08-03T23:38:28Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/Nic-Ma>@Nic-Ma</denchmark-link>\n \n Here is my code below:\n <denchmark-code>def build_u_net_model(train, trainlab, val, vallab, test, testlab, hparams):\n     monai.config.print_config()\n     set_determinism(seed=0)\n     tempdir = tempfile.mkdtemp()\n     \n     batch_size = hparams.batch_size\n     num_epochs = hparams.num_epochs\n     lr = hparams.lr\n     \n     transforms = Compose([\n     AddChannel(),\n     ToTensor()\n     ])\n     \n     train_data = monai.data.ArrayDataset(img = train, img_transform = transforms, seg = trainlab, seg_transform = transforms)\n     train_loader = monai.data.DataLoader(train_data, batch_size=2, shuffle=True, num_workers=0, multiprocessing_context = None)\n     \n \n     val_data = monai.data.ArrayDataset(img = val, img_transform = transforms, seg = vallab, seg_transform = transforms)\n     val_loader = monai.data.DataLoader(val_data, batch_size=1, shuffle=True, num_workers=0, multiprocessing_context = None)\n \n     test_data = monai.data.ArrayDataset(img = test, img_transform = transforms, seg = testlab, seg_transform = transforms)\n     test_loader = monai.data.DataLoader(test_data, batch_size=1, shuffle=True, num_workers=0, multiprocessing_context = None)\n     \n     torch.cuda.set_device(0)    \n     device = torch.device('cuda:0')\n     model = monai.networks.nets.UNet(dimensions=2, in_channels=1, out_channels=1, channels=(16, 32, 64),\n                                       strides=(2, 2), num_res_units=2, norm=Norm.BATCH).to(device)\n     \n     loss_function = monai.losses.DiceLoss(to_onehot_y=True, sigmoid=True)\n     optimizer = torch.optim.Adam(model.parameters(), lr)\n     \n     # TRAINING\n     val_interval = 2\n     best_metric = -1\n     best_metric_epoch = -1\n     epoch_loss_values = list()\n     metric_values = list()\n \n     for epoch in range(num_epochs):\n         print(\"-\" * 10)\n         print(f\"epoch {epoch + 1}/{20}\")\n         model.train()\n         epoch_loss = 0\n         step = 0\n         for batch_data in train_loader:\n             step += 1\n             inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n             optimizer.zero_grad()\n             outputs = model(inputs)\n             loss = loss_function(outputs, labels)\n             loss.backward()\n             optimizer.step()\n             epoch_loss += loss.item()\n             epoch_len = len(train_data) // train_loader.batch_size\n             print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n         epoch_loss /= step\n         epoch_loss_values.append(epoch_loss)\n         print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n \n         if (epoch + 1) % val_interval == 0:\n             model.eval()\n             with torch.no_grad():\n                 metric_sum = 0.0\n                 metric_count = 0\n                 val_images = None\n                 val_labels = None\n                 val_outputs = None\n                 for val_data in val_loader:\n                     val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n                     roi_size = (96, 96, 96)\n                     sw_batch_size = 4\n                     val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n                     value = DiceMetric(y_pred=val_outputs, y=val_labels)\n                     metric_count += len(value)\n                     metric_sum += value.item() * len(value)\n                 metric = metric_sum / metric_count\n                 metric_values.append(metric)\n                 if metric > best_metric:\n                     best_metric = metric\n                     best_metric_epoch = epoch + 1\n                     torch.save(model.state_dict(), \"best_metric_model.pth\")\n                     print(\"saved new best metric model\")\n                 print(\n                     \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n                         epoch + 1, metric, best_metric, best_metric_epoch\n                     )\n                 )\n     shutil.rmtree(tempdir)\n     print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n     train_acc = best_metric\n </denchmark-code>\n \n I think I may be confused about the intended input for ArrayDataset. Your posted examples using array data first export the data to Nifti files and then read them back in using a NiftiDataset. In the snippets in your docs for ArrayDataset, the input images seems to be a filename list of array data.\n In my code here, I pass train which is a list of image arrays. All my input data is formatted in this way.\n <denchmark-code>len(train) = 3600\n train[i].shape = (160, 160)\n </denchmark-code>\n \n Here is the traceback:\n <denchmark-code>  File \"C:\\Users\\iBest\\Documents\\Jillian\\Documents\\BO-Aug-master\\BraTS\\select\\bo_train_brats.py\", line 125, in run_model\n     train_acc, val_acc, test_accuracy = build_u_net_model(train_images, train_labels, val_images, val_labels, test_images, test_labels, hparams)\n   File \"C:\\Users\\iBest\\Documents\\Jillian\\Documents\\BO-Aug-master\\BraTS\\select\\u_net.py\", line 119, in build_u_net_model\n     outputs = model(inputs)\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\n     result = self.forward(*input, **kwargs)\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\monai\\networks\\nets\\unet.py\", line 137, in forward\n     x = self.model(x)\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\n     result = self.forward(*input, **kwargs)\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 117, in forward\n     input = module(input)\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\n     result = self.forward(*input, **kwargs)\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\monai\\networks\\blocks\\convolutions.py\", line 209, in forward\n     res = self.residual(x)  # create the additive residual from x\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 722, in _call_impl\n     result = self.forward(*input, **kwargs)\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 419, in forward\n     return self._conv_forward(input, self.weight)\n   File \"C:\\Users\\iBest\\.conda\\envs\\data_aug\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 416, in _conv_forward\n     self.padding, self.dilation, self.groups)\n RuntimeError: Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 3], but got 3-dimensional input of size [1, 160, 160] instead\n </denchmark-code>\n \n Does ArrayDataset accept this kind of format?\n Thank you for your time and help,\n Jillian\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jillianlee", "commentT": "2020-08-04T00:40:48Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/jillianlee>@jillianlee</denchmark-link>\n  ,\n Could you please help check the data shape of batch_data[0] from for batch_data in train_loader?\n I think you need to add several print logs to find out why the output data of DataLoader is not [B, C, H, W].\n Thanks.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "jillianlee", "commentT": "2020-08-04T02:00:22Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/Nic-Ma>@Nic-Ma</denchmark-link>\n ,\n Both batch_data[0] and 'batch_data[1]` are size (1, 160, 160).\n Additionally train_loader.dataset[0][0] is also size (1, 160, 160).\n Best,\n Jillian\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "jillianlee", "commentT": "2020-08-06T11:27:54Z", "comment_text": "\n \t\tHi both, it is indeed an issue (at least a documentation issue) just checked that in the previous example, changing monai.data.Dataloader to torch.utils.data.DataLoader then everything works fine.\n I used these test cases:\n build_u_net_model(train=[np.zeros((160, 160))] * 3, trainlab=[np.zeros((160, 160))] * 3, ...)\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "jillianlee", "commentT": "2020-08-06T11:37:49Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Nic-Ma>@Nic-Ma</denchmark-link>\n  to reproduce the issue\n import torch\n import monai\n from monai.utils.misc import set_determinism\n from monai.transforms import AddChannel, Compose, ToTensor\n \n \n def build_u_net_model(train, trainlab):\n     monai.config.print_config()\n     set_determinism(seed=0)\n \n     batch_size = 2\n \n     transforms = Compose([AddChannel(), ToTensor()])\n \n     train_data = monai.data.ArrayDataset(img=train, img_transform=transforms, seg=trainlab, seg_transform=transforms)\n     train_loader = monai.data.DataLoader(\n         train_data, batch_size=2, shuffle=True, num_workers=0, multiprocessing_context=None\n     )\n     train_loader_1 = torch.utils.data.DataLoader(\n         train_data, batch_size=2, shuffle=True, num_workers=0, multiprocessing_context=None\n     )\n     for x in train_loader:\n         print(x[0].shape)\n     for x in train_loader_1:\n         print(x[0].shape)\n \n import numpy as np\n train = [np.zeros((160, 160))] * 3\n trainlab = [np.ones((160, 160))] * 3\n build_u_net_model(train, trainlab)\n output\n <denchmark-code>torch.Size([1, 160, 160])\n torch.Size([1, 160, 160])\n torch.Size([2, 1, 160, 160])\n torch.Size([1, 1, 160, 160])\n </denchmark-code>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "jillianlee", "commentT": "2020-08-06T12:25:38Z", "comment_text": "\n \t\tThanks for your help <denchmark-link:https://github.com/wyli>@wyli</denchmark-link>\n  !\n I will try to verify and fix soon.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "jillianlee", "commentT": "2020-08-06T14:40:47Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/jillianlee>@jillianlee</denchmark-link>\n  ,\n Sorry for the bug, I committed PR <denchmark-link:https://github.com/Project-MONAI/MONAI/pull/865>#865</denchmark-link>\n  to fix this issue.\n Thanks.\n \t\t"}}}, "commit": {"commit_id": "9d6002dc12c9092b2290726e0cdef656a080c973", "commit_author": "Nic Ma", "commitT": "2020-08-06 16:09:10+01:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "monai\\data\\dataset.py", "file_new_name": "monai\\data\\dataset.py", "file_complexity": {"file_NLOC": "364", "file_CCN": "50", "file_NToken": "1417"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "364,365", "deleted_lines": "364", "method_info": {"method_name": "__getitem__", "method_params": "self,int", "method_startline": "355", "method_endline": "365", "method_complexity": {"method_NLOC": "8", "method_CCN": "3", "method_NToken": "62", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "monai\\data\\nifti_reader.py", "file_new_name": "monai\\data\\nifti_reader.py", "file_complexity": {"file_NLOC": "93", "file_CCN": "16", "file_NToken": "526"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "119,120", "deleted_lines": "119", "method_info": {"method_name": "__getitem__", "method_params": "self,int", "method_startline": "81", "method_endline": "120", "method_complexity": {"method_NLOC": "35", "method_CCN": "13", "method_NToken": "263", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\test_arraydataset.py", "file_new_name": "tests\\test_arraydataset.py", "file_complexity": {"file_NLOC": "133", "file_CCN": "5", "file_NToken": "1484"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "119", "deleted_lines": "119", "method_info": {"method_name": "test_dataloading", "method_params": "self,img_transform,expected_shape", "method_startline": "119", "method_endline": "136", "method_complexity": {"method_NLOC": "17", "method_CCN": "1", "method_NToken": "195", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "119", "deleted_lines": "119", "method_info": {"method_name": "test_dataloading_img", "method_params": "self,img_transform,expected_shape", "method_startline": "119", "method_endline": "136", "method_complexity": {"method_NLOC": "17", "method_CCN": "1", "method_NToken": "195", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161", "deleted_lines": null, "method_info": {"method_name": "test_dataloading_img_label", "method_params": "self,img_transform,expected_shape", "method_startline": "139", "method_endline": "161", "method_complexity": {"method_NLOC": "22", "method_CCN": "1", "method_NToken": "255", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\test_zipdataset.py", "file_new_name": "tests\\test_zipdataset.py", "file_complexity": {"file_NLOC": "32", "file_CCN": "5", "file_NToken": "318"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "35,37,39,44", "deleted_lines": "35,37,39,44"}}}}}}