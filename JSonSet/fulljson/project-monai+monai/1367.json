{"BR": {"BR_id": "1367", "BR_author": "patriciacs1994", "BRopenT": "2020-12-15T15:45:43Z", "BRcloseT": "2020-12-16T18:53:36Z", "BR_text": {"BRsummary": "No Expected Model Output dimensions", "BRdescription": "\n Hello,\n I am using an autoencoder but the output channel dimension of the model does not correspond with the out-channel variable.\n Here is my code:\n <denchmark-code># create a training data loader\n     train_ds = ArrayDataset(img_train[0], train_imtrans, img_train[1], train_segtrans)\n     train_loader = DataLoader(train_ds, batch_size=16, num_workers=8, pin_memory=torch.cuda.is_available())\n     # create a validation data loader\n     val_ds = ArrayDataset(img_val[0], val_imtrans, img_val[1], val_segtrans)\n     val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n     \n     # create AE, MSELoss and Adam optimizer\n     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n     model = monai.networks.nets.AutoEncoder(\n         dimensions=2,\n         in_channels=1,\n         out_channels=4,\n         channels=(16, 32, 64, 128, 256),\n         strides=(2, 2, 2, 2),\n         num_res_units = 2\n     )\n     loss_function = torch.nn.MSELoss()\n     optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n     lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n     # start a typical PyTorch training\n     val_interval = 2\n     best_metric = -1\n     best_metric_epoch = -1\n     best_val_loss = 10000\n     best_val_loss_epoch = 10000\n     epoch_loss_values = list()\n     val_loss_values = list()\n \n     metric_values = list()\n     writer = SummaryWriter()\n     post_pred = AsDiscrete(argmax=True, to_onehot=True, n_classes=4)\n     post_label = AsDiscrete(to_onehot=True, n_classes=4)\n     \n     for epoch in range(200):\n         print(\"-\" * 10)\n         print('Epoch {}/{}'.format(epoch + 1, 200))\n         model.train()\n         epoch_loss = 0\n         step = 0\n         for batch_data in train_loader:\n             metric_sum = 0.0\n             metric_count = 0\n             metric_batch = 0 \n             step += 1\n             inputs, labels = batch_data[0], batch_data[1]\n             optimizer.zero_grad()\n             outputs = model(inputs)\n             loss = loss_function(outputs, labels)\n             loss.backward()\n             optimizer.step()\n             epoch_loss += loss.item()\n             epoch_len = len(train_ds) // train_loader.batch_size\n             outputs1 = post_pred(outputs)\n             labels1 = post_label(labels)\n             value_train = monai.metrics.compute_meandice(y_pred=outputs1, y=labels1, include_background=False)\n             \n             metric_count += value_train.shape[1]\n             metric_batch += value_train.shape[0]\n             metric_sum += value_train.sum().item()\n             \n             writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n             \n         metric1 = metric_sum / (metric_count * metric_batch)        \n         epoch_loss /= step\n         epoch_loss_values.append(epoch_loss)\n         print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f} mean dice: {metric1:.4f}\")\n </denchmark-code>\n \n I am getting this error:\n RuntimeError                              Traceback (most recent call last)\n  in \n 224\n 225 with tempfile.TemporaryDirectory() as tempdir:\n --> 226     outputs, labels, outputs1, labels1, inputs, labels = main(tempdir, img_train, img_val)\n  in main(tempdir, img_train, img_val)\n 121             epoch_loss += loss.item()\n 122             epoch_len = len(train_ds) // train_loader.batch_size\n --> 123             outputs1 = post_pred(outputs)\n 124             labels1 = post_label(labels)\n 125             value_train = monai.metrics.compute_meandice(y_pred=outputs1, y=labels1, include_background=False)\n ~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\monai\\transforms\\post\\array.py in call(self, img, argmax, to_onehot, n_classes, threshold_values, logit_thresh)\n 156             _nclasses = self.n_classes if n_classes is None else n_classes\n 157             assert isinstance(_nclasses, int), \"One of self.n_classes or n_classes must be an integer\"\n --> 158             img = one_hot(img, _nclasses)\n 159\n 160         if threshold_values or self.threshold_values:\n ~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\monai\\networks\\utils.py in one_hot(labels, num_classes, dtype, dim)\n 45\n 46     o = torch.zeros(size=sh, dtype=dtype, device=labels.device)\n ---> 47     labels = o.scatter_(dim=dim, index=labels.long(), value=1)\n 48\n 49     return labels\n RuntimeError: index 5 is out of bounds for dimension 1 with size 4\n I have checked the input and output shapes of the model and I got the next:\n inputs: torch.Size([16, 1, 256, 256])\n outputs: torch.Size([16, 16, 256, 256])\n Why if I set the out-channel to 4 I got a channel of 16 in the outputs?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "patriciacs1994", "commentT": "2020-12-16T14:09:45Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/rijobro>@rijobro</denchmark-link>\n  ,\n Could you please help check this issue as you are expert on the AutoEncoder?\n Thanks in advance.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "patriciacs1994", "commentT": "2020-12-16T15:11:14Z", "comment_text": "\n \t\tHi,\n I went able to fix it by changing the number of channels:\n <denchmark-code>    model = monai.networks.nets.AutoEncoder(\n         dimensions=2,\n         in_channels=1,\n         out_channels=4,\n         channels=(4,8,16, 32),\n         strides=(2, 2, 2, 2),\n         num_res_units = 2\n     )\n </denchmark-code>\n \n Thank you, anyway.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "patriciacs1994", "commentT": "2020-12-16T16:27:39Z", "comment_text": "\n \t\tLooks a little bit suspicious to me. I'll look at this, thanks for bringing it to our attention.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "patriciacs1994", "commentT": "2020-12-16T16:32:30Z", "comment_text": "\n \t\tAh I see the problem. The number of strides should match the number of channels for the autoencoder, which it doesn't in your first example.\n I'll add a check for this to avoid future confusion.\n \t\t"}}}, "commit": {"commit_id": "e213a89612344d57f898cc81a2cd29c68d04f14b", "commit_author": "Richard Brown", "commitT": "2020-12-16 18:53:35+00:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "monai\\networks\\nets\\autoencoder.py", "file_new_name": "monai\\networks\\nets\\autoencoder.py", "file_complexity": {"file_NLOC": "162", "file_CCN": "13", "file_NToken": "1159"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "56,57,58,59", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\test_autoencoder.py", "file_new_name": "tests\\test_autoencoder.py", "file_complexity": {"file_NLOC": "78", "file_CCN": "3", "file_NToken": "521"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "88,89,90", "deleted_lines": null, "method_info": {"method_name": "test_channel_stride_difference", "method_params": "self", "method_startline": "88", "method_endline": "90", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "20", "method_nesting_level": "1"}}}}}}}}