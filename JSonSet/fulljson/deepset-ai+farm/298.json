{"BR": {"BR_id": "298", "BR_author": "cregouby", "BRopenT": "2020-03-27T17:10:46Z", "BRcloseT": "2020-04-01T12:19:54Z", "BR_text": {"BRsummary": "[data_handler/utils.py] read_docs_from_txt() is not robust to sentence made of Out-of-vocabulary characters", "BRdescription": "\n Describe the bug\n When a text file with one sentence per line is read by read_docs_from_txt() with the sentence being made only on UTF-8  characters, pipeline end-up silently with a tokeniser exception. Such sentences may occur when text comes out of an automatic extraction workflow.\n Error message\n <denchmark-code>      .--.        _____                       _\n     .'_\\/_'.     / ____|                     | |\n     '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___\n       \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\\n        || /\\     ____) | (_| | | | | | | |_) | |  __/\n     /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n    (/\\||/                             |_|\n ______\\||/___________________________________________\n \n ID: train-2283-0\n Clear Text:\n         doc_id: 02789c9e-a975-3e0a-be08-bd6d8fa1f864\n         sent_id: 2\n         text: \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n Tokenized:\n         tokens: []\n         offsets: []\n         start_of_word: []\n Features:\n         None\n </denchmark-code>\n \n Expected behavior\n You could maybe add an explicit error message, and a fallback to [UNK] token\n To Reproduce\n Create a syntetic dataset with sentences made of utf-8 space characters\n System:\n \n OS: Linux\n GPU/CPU: GPU\n FARM version: 4ab81bd\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "cregouby", "commentT": "2020-04-01T09:52:26Z", "comment_text": "\n \t\tHi, this pull request (<denchmark-link:https://github.com/deepset-ai/FARM/pull/308>#308</denchmark-link>\n ) should fix the issue. Could you try it out and let us know if it solves it?\n \t\t"}}}, "commit": {"commit_id": "347ca82f9ad446bca3967e5e14421d0fe4c4f07a", "commit_author": "Branden Chan", "commitT": "2020-04-01 14:19:53+02:00", "commit_complexity": {"commit_NLOC": "0.15151515151515152", "commit_CCN": "0.0", "commit_Nprams": "0.09090909090909091"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "farm\\data_handler\\processor.py", "file_new_name": "farm\\data_handler\\processor.py", "file_complexity": {"file_NLOC": "808", "file_CCN": "126", "file_NToken": "4753"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "826,827,828,829,830,831,832,833,834,835,856,857", "deleted_lines": null, "method_info": {"method_name": "_dict_to_samples", "method_params": "self,dictionary,all_dicts", "method_startline": "804", "method_endline": "866", "method_complexity": {"method_NLOC": "54", "method_CCN": "8", "method_NToken": "362", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "280,281,282", "deleted_lines": null, "method_info": {"method_name": "_init_samples_in_baskets", "method_params": "self", "method_startline": "270", "method_endline": "282", "method_complexity": {"method_NLOC": "13", "method_CCN": "9", "method_NToken": "124", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "483,484,485,486,487", "deleted_lines": null, "method_info": {"method_name": "_dict_to_samples", "method_params": "self,dict,kwargs", "method_startline": "481", "method_endline": "492", "method_complexity": {"method_NLOC": "10", "method_CCN": "3", "method_NToken": "113", "method_nesting_level": "1"}}}}}}}}