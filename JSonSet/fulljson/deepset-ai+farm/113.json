{"BR": {"BR_id": "113", "BR_author": "tholor", "BRopenT": "2019-10-11T15:31:43Z", "BRcloseT": "2019-10-14T17:11:19Z", "BR_text": {"BRsummary": "Empty datasets due to random_split_ConcatDataset", "BRdescription": "\n Describe the bug\n DataSilo is Crashing during the attempt of splitting a dev set from a \"small\" train set.\n It seems that random_split_ConcatDataset() doesn't work if there's only a single chunk (= 1 dataset). idx_dataset is 0 in that case and thus creates an empty ConcatDataset for train\n Error message\n Error that was thrown (if available)\n <denchmark-code>10/11/2019 17:12:47 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n Traceback (most recent call last):\n   File \".../train.py\", line 436, in <module>\n     augmentation=True)\n   File \".../train.py\", line 348, in continue_finetuning\n     data_silo = DataSilo(processor=processor, batch_size=batch_size, multiprocessing_chunk_size=2000)\n   File \"/.../farm/data_handler/data_silo.py\", line 49, in __init__\n     self._load_data()\n   File \".../farm/data_handler/data_silo.py\", line 104, in _load_data\n     self._create_dev_from_train()\n   File \".../farm/data_handler/data_silo.py\", line 175, in _create_dev_from_train\n     train_dataset, dev_dataset = self.random_split_ConcatDataset(self.data[\"train\"], lengths=[n_train, n_dev])\n   File \".../farm/data_handler/data_silo.py\", line 200, in random_split_ConcatDataset\n     train = ConcatDataset(ds.datasets[:idx_dataset])\n   File \".../torch/utils/data/dataset.py\", line 68, in __init__\n     assert len(datasets) > 0, 'datasets should not be an empty iterable'\n AssertionError: datasets should not be an empty iterable\n </denchmark-code>\n \n Expected behavior\n A portion of the train set should be splitted apart into a dev set\n \n Related function:\n <denchmark-link:https://github.com/deepset-ai/FARM/blob/master/farm/data_handler/data_silo.py#L186>https://github.com/deepset-ai/FARM/blob/master/farm/data_handler/data_silo.py#L186</denchmark-link>\n \n <denchmark-code>    def random_split_ConcatDataset(self, ds, lengths):\n ...\n         if sum(lengths) != len(ds):\n             raise ValueError(\"Sum of input lengths does not equal the length of the input dataset!\")\n \n         idx_dataset = np.where(np.array(ds.cumulative_sizes) > lengths[0])[0][0]\n \n         train = ConcatDataset(ds.datasets[:idx_dataset])\n         test = ConcatDataset(ds.datasets[idx_dataset:])\n         return train, test\n </denchmark-code>\n \n To Reproduce\n \n Provide no dev_filename but instead set dev_split\n Have a trainfile that has less samples that multiprocessing_chunksize\n \n System:\n \n OS: Ubuntu 18.04\n GPU/CPU: CPU\n FARM version: 0.2.1\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "tholor", "commentT": "2019-10-14T17:11:19Z", "comment_text": "\n \t\tResolved by <denchmark-link:https://github.com/deepset-ai/FARM/pull/114>#114</denchmark-link>\n \n Closing this now\n \t\t"}}}, "commit": {"commit_id": "432ffb136a7c260b883e55c6c134a7e49ddaf53c", "commit_author": "Timo Moeller", "commitT": "2019-10-14 18:54:48+02:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "1.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "farm\\__init__.py", "file_new_name": "farm\\__init__.py", "file_complexity": {"file_NLOC": "12", "file_CCN": "0", "file_NToken": "76"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "18,19", "deleted_lines": "18"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "farm\\data_handler\\data_silo.py", "file_new_name": "farm\\data_handler\\data_silo.py", "file_complexity": {"file_NLOC": "204", "file_CCN": "33", "file_NToken": "1603"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "182", "deleted_lines": "173,174,180", "method_info": {"method_name": "_create_dev_from_train", "method_params": "self", "method_startline": "173", "method_endline": "186", "method_complexity": {"method_NLOC": "12", "method_CCN": "2", "method_NToken": "102", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "32", "deleted_lines": "32,47", "method_info": {"method_name": "__init__", "method_params": "self,processor,batch_size,distributed", "method_startline": "32", "method_endline": "48", "method_complexity": {"method_NLOC": "8", "method_CCN": "1", "method_NToken": "50", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "32", "deleted_lines": "32,47", "method_info": {"method_name": "__init__", "method_params": "self,processor,batch_size,distributed,multiprocessing_chunk_size", "method_startline": "32", "method_endline": "49", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "59", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "201,202", "deleted_lines": null, "method_info": {"method_name": "random_split_ConcatDataset", "method_params": "self,ds,lengths", "method_startline": "188", "method_endline": "206", "method_complexity": {"method_NLOC": "9", "method_CCN": "2", "method_NToken": "89", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "65,66,67,68,69,70,71,72,73,74,77,80,82,86,94", "deleted_lines": "66,67,70,73,75,79,87", "method_info": {"method_name": "_get_dataset", "method_params": "self,filename", "method_startline": "57", "method_endline": "97", "method_complexity": {"method_NLOC": "29", "method_CCN": "7", "method_NToken": "253", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "farm\\data_handler\\processor.py", "file_new_name": "farm\\data_handler\\processor.py", "file_complexity": {"file_NLOC": "599", "file_CCN": "81", "file_NToken": "3433"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "625", "deleted_lines": null, "method_info": {"method_name": "_dict_to_samples", "method_params": "self,dictionary,all_dicts", "method_startline": "624", "method_endline": "645", "method_complexity": {"method_NLOC": "22", "method_CCN": "2", "method_NToken": "132", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "farm\\eval.py", "file_new_name": "farm\\eval.py", "file_complexity": {"file_NLOC": "108", "file_CCN": "25", "file_NToken": "762"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "93,118,129", "deleted_lines": "117,118,119,120,121", "method_info": {"method_name": "eval", "method_params": "self,model", "method_startline": "46", "method_endline": "134", "method_complexity": {"method_NLOC": "57", "method_CCN": "15", "method_NToken": "448", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "farm\\infer.py", "file_new_name": "farm\\infer.py", "file_complexity": {"file_NLOC": "190", "file_CCN": "25", "file_NToken": "1186"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "52", "deleted_lines": "51,52", "method_info": {"method_name": "__init__", "method_params": "self,model,processor,batch_size,gpu,name,return_class_probs", "method_startline": "45", "method_endline": "52", "method_complexity": {"method_NLOC": "8", "method_CCN": "1", "method_NToken": "23", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "52", "deleted_lines": "51,52", "method_info": {"method_name": "__init__", "method_params": "self,model,processor,batch_size,gpu,name,return_class_probs,multiprocessing_chunk_size", "method_startline": "44", "method_endline": "52", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "104", "method_info": {"method_name": "load", "method_params": "cls,load_dir,batch_size,gpu,embedder_only,return_class_probs,multiprocessing_chunk_size", "method_startline": "97", "method_endline": "104", "method_complexity": {"method_NLOC": "8", "method_CCN": "1", "method_NToken": "26", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "162,163,164,165,166,167,168,169,170,171,174,177,179,183,191", "deleted_lines": "167,168,171,174,176,180,188", "method_info": {"method_name": "inference_from_dicts", "method_params": "self,dicts,rest_api_schema", "method_startline": "143", "method_endline": "193", "method_complexity": {"method_NLOC": "30", "method_CCN": "5", "method_NToken": "224", "method_nesting_level": "1"}}}}}}}}