{"BR": {"BR_id": "525", "BR_author": "PhilipMay", "BRopenT": "2020-09-07T07:25:21Z", "BRcloseT": "2020-09-07T10:40:25Z", "BR_text": {"BRsummary": "Warning message spam \"please use `truncation=True` to explicitely truncate examples to max length\"", "BRdescription": "\n Hi,\n since I use the code from master branch I am getting spammed with these messages:\n <denchmark-code>Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n </denchmark-code>\n \n I think this is related to <denchmark-link:https://github.com/deepset-ai/FARM/pull/482>#482</denchmark-link>\n  .\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "PhilipMay", "commentT": "2020-09-07T07:36:55Z", "comment_text": "\n \t\tHey,\n For which task do you get this? Are you using fast or slow tokenizers?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "PhilipMay", "commentT": "2020-09-07T07:48:27Z", "comment_text": "\n \t\tText classification. Since I did not specify to use fast I think I use slow.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "PhilipMay", "commentT": "2020-09-07T10:40:25Z", "comment_text": "\n \t\tFixed in <denchmark-link:https://github.com/deepset-ai/FARM/pull/528>#528</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "d6536bd3f3ebc591c7ca4f17e2de94627a53ada0", "commit_author": "Malte Pietsch", "commitT": "2020-09-07 12:40:07+02:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "farm\\data_handler\\input_features.py", "file_new_name": "farm\\data_handler\\input_features.py", "file_complexity": {"file_NLOC": "362", "file_CCN": "30", "file_NToken": "2512"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "46,47,164,165", "deleted_lines": "65"}}}}}}