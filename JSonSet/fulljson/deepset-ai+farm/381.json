{"BR": {"BR_id": "381", "BR_author": "PhilipMay", "BRopenT": "2020-05-29T16:13:05Z", "BRcloseT": "2020-06-04T06:34:32Z", "BR_text": {"BRsummary": "Zero-based counting in \"train epoch\" progress bar.", "BRdescription": "\n The train progress bar seems to work zero based. See below:\n <denchmark-code>Train epoch 0/20 (Cur. train loss: 0.5595):  13%|\u2588\u258e        | 368/2813 [10:44<48:51,  1.20s/it]\n </denchmark-code>\n \n IMO this is counterintuitive. It should count from 1 to 20 in this case (or from 0 to 19) since I said n_epochs=20 in initialize_optimizer.\n What do you think?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "PhilipMay", "commentT": "2020-05-31T14:34:03Z", "comment_text": "\n \t\tTotally agree. Please feel free to add a PR.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "PhilipMay", "commentT": "2020-06-02T10:48:59Z", "comment_text": "\n \t\tI remember that we had quite some discussion about this a while ago. The zero-based counting simplified some functionality around Checkpointing, StreamingDataSilo and LR schedules.\n I would vote for keeping it like it is at least until we merge <denchmark-link:https://github.com/deepset-ai/FARM/pull/305>#305</denchmark-link>\n  as there might be many unwanted side effects otherwise.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "PhilipMay", "commentT": "2020-06-02T12:53:03Z", "comment_text": "\n \t\tWell. IMO this is no big deal. I think we should plit 2 questions:\n \n How do we count epochs internaly?\n How do we show them to the user?\n \n I am not 100% sure and I did not try it but I think this could be a simple solution:\n Instead of:\n \n we could just say:  see here: <denchmark-link:https://github.com/deepset-ai/FARM/blob/master/farm/train.py#L249>https://github.com/deepset-ai/FARM/blob/master/farm/train.py#L249</denchmark-link>\n \n This way we change nothing internaly but just change the \"presentation logic\"...\n IMO this is the same as Keras is also doing. They show the epochs one based but internaly they count them zero based.\n What do you think?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "PhilipMay", "commentT": "2020-06-02T13:04:36Z", "comment_text": "\n \t\tI think this is a good solution and I do not see any problems in other parts of the code when changing this line.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "PhilipMay", "commentT": "2020-06-02T15:47:16Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n  What do you think about my suggestion? Does it interfere with <denchmark-link:https://github.com/deepset-ai/FARM/pull/305>#305</denchmark-link>\n  or is it independent?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "PhilipMay", "commentT": "2020-06-02T17:18:21Z", "comment_text": "\n \t\tHm... while I  see your point about a \"simple presentation logic\", I still have some doubts to be honest:\n \n If the epoch count is one-based the step count (within an epoch) should also be switched to one-based and there it might be more than a \"logged string\" that we need to change\n If we have a different counting logic for \"presentation\" and \"internal\", it might become ambiguous for some other parts of the pipeline. For example, how would we name saved checkpoint files - using \"internal\" or \"presentation\" logic? As this was a source of bugs in the past, I would be very cautious here (Disclaimer: I am probably biased because I once spent > 1 day tracing a bug where it turned out in the end that we were executing a training step twice after stopping & resuming training using checkpointing).\n \n I would propose to postpone this until <denchmark-link:https://github.com/deepset-ai/FARM/pull/305>#305</denchmark-link>\n  is finished & merged and evaluate then if we want to \"completely\" move to one-based counts.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "PhilipMay", "commentT": "2020-06-02T17:28:34Z", "comment_text": "\n \t\tWell - yes. There is pro and con for zero and one based counting. At the end of the day I do not care and can can live with both solutions. If you want to be zero based we should count from 0 to 19 if saying n_epochs=20.\n Then we could say progress_bar.set_description(f\"Train epoch {epoch}/{self.epochs-1} (Cur. train loss: {loss:.4f})\". The current implementation is just counterintuitive IMO.\n Maybe you can discuss this internally and make a decision on how to count. Personaly I would definitly count zero based internaly. External I do not care.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "PhilipMay", "commentT": "2020-06-03T08:26:43Z", "comment_text": "\n \t\tWe had a discussion in the team and everybody was in favor of zero-based counting (interal+external).\n We like your suggestion though to switch the progress bar to progress_bar.set_description(f\"Train epoch {epoch}/{self.epochs-1} (Cur. train loss: {loss:.4f})\".\n Hope this makes sense to you. We appreciate your initiative here and the open discussion.\n Do you want to create a quick PR for that?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "PhilipMay", "commentT": "2020-06-03T09:36:11Z", "comment_text": "\n \t\tYes - I can create a PR for this. :-)\n Hope the CI runs soon. :-)\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "PhilipMay", "commentT": "2020-06-03T20:31:07Z", "comment_text": "\n \t\tPR added: <denchmark-link:https://github.com/deepset-ai/FARM/pull/398>#398</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "f18c282c5ca040c13e0f1b011dbe1c60e311dcde", "commit_author": "Philip May", "commitT": "2020-06-04 08:34:20+02:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "farm\\train.py", "file_new_name": "farm\\train.py", "file_complexity": {"file_NLOC": "336", "file_CCN": "61", "file_NToken": "2122"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "221,222,223,224,225,226,254", "deleted_lines": "221,249", "method_info": {"method_name": "train", "method_params": "self", "method_startline": "220", "method_endline": "323", "method_complexity": {"method_NLOC": "68", "method_CCN": "24", "method_NToken": "585", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tutorials\\1_farm_building_blocks.ipynb", "file_new_name": "tutorials\\1_farm_building_blocks.ipynb", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "667,694,1225,1255,1285,1316,1363", "deleted_lines": "667,694,1225,1255,1285,1316,1363"}}}}}}