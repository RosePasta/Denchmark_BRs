{"BR": {"BR_id": "2945", "BR_author": "rsayn", "BRopenT": "2020-11-06T09:04:33Z", "BRcloseT": "2020-11-13T17:44:50Z", "BR_text": {"BRsummary": "[Model serialization] Exporting TabularLearner via learn.export() leads to huge file size", "BRdescription": "\n Please confirm you have the latest versions of fastai, fastcore, fastscript, and nbdev prior to reporting a bug (delete one): YES\n Describe the bug\n Exporting TabularLearner via learn.export() leads to huge Pickle file size (>80MB).\n To Reproduce\n Steps to reproduce the behavior:\n \n Create a TabularLearner\n Train it\n Export it to pickle file via learn.export(filepath)\n \n Expected behavior\n The Pickle file should be smaller in size.\n Error with full stack trace\n N/A\n Additional context\n By creating different learners with DataFrames of varying size, I noticed that the size of the pickled file increases with the dataset dimension, although after re-loading the serialized file learn.dls is empty as expected.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "rsayn", "commentT": "2020-11-06T16:11:09Z", "comment_text": "\n \t\tThere's a temporary solution here: <denchmark-link:https://walkwithfastai.com/tab.export#Exporting-our-TabularPandas>https://walkwithfastai.com/tab.export#Exporting-our-TabularPandas</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "rsayn", "commentT": "2020-11-06T22:25:16Z", "comment_text": "\n \t\tI've narrowed down the issue to the ReadTabBatch transform, we're always storing a copy of the dataframe into memory through this\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "rsayn", "commentT": "2020-11-07T18:57:32Z", "comment_text": "\n \t\tShould be fixed now.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "rsayn", "commentT": "2020-11-12T10:28:13Z", "comment_text": "\n \t\tHi, I upgraded Fastai to the lastest version (2.1.5) and I'm still experiencing the same issue.\n I created a notebook on Colab to reproduce the problem:\n <denchmark-link:https://colab.research.google.com/drive/1yvQwIrC9zfI0jq5xZq_h4JVkoXWszcHC?usp=sharing>https://colab.research.google.com/drive/1yvQwIrC9zfI0jq5xZq_h4JVkoXWszcHC?usp=sharing</denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "rsayn", "commentT": "2020-11-12T10:43:53Z", "comment_text": "\n \t\tI've done the same (after upgrading to 2.1.5) and I also experienced the same issue:\n Model trained with adult.csv, exported to a 161K file.\n Model trained with the same dataset, but containing 500K rows, exported to a 8Mb file.\n <denchmark-link:https://colab.research.google.com/drive/1zhSKeJCB5CvTiQKgYWubey9w1VzbNiG2?usp=sharing>https://colab.research.google.com/drive/1zhSKeJCB5CvTiQKgYWubey9w1VzbNiG2?usp=sharing</denchmark-link>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "rsayn", "commentT": "2020-11-12T14:02:29Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/claudiobottari>@claudiobottari</denchmark-link>\n  I've found the issue. It's after we  the model\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "rsayn", "commentT": "2020-11-12T15:34:13Z", "comment_text": "\n \t\tHere's a minimal reproducer showing that there is a duplicate validation dataframe being added after fit:\n <denchmark-link:https://gist.github.com/muellerzr/df3fc4a12b021be85639afddab3c5d32>https://gist.github.com/muellerzr/df3fc4a12b021be85639afddab3c5d32</denchmark-link>\n \n <denchmark-link:https://github.com/jph00>@jph00</denchmark-link>\n  we should reopen this issue\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "rsayn", "commentT": "2020-11-13T09:00:33Z", "comment_text": "\n \t\tThe problem is that  is not deleting its  attribute after the fit. I modified <denchmark-link:https://github.com/muellerzr>@muellerzr</denchmark-link>\n  gist showing how to solve the problem.\n <denchmark-link:https://gist.github.com/ababino/2a2c67ac264e2ed8c95144377b9be2b4>https://gist.github.com/ababino/2a2c67ac264e2ed8c95144377b9be2b4</denchmark-link>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "rsayn", "commentT": "2020-12-02T13:01:46Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/muellerz>@muellerz</denchmark-link>\n  can you provide a snippet on how to deserialize a bugged model and re-serialize it with the correct size?\n I have a lot of models affected by this issue that I can't retrain.\n Thanks in advance.\n \t\t"}}}, "commit": {"commit_id": "6dbbb9088b8354a1f26dc2927af6535ed39b08f7", "commit_author": "Zachary Mueller", "commitT": "2020-11-06 19:29:26-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "fastai\\tabular\\core.py", "file_new_name": "fastai\\tabular\\core.py", "file_complexity": {"file_NLOC": "291", "file_CCN": "107", "file_NToken": "3638"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "320", "deleted_lines": "320", "method_info": {"method_name": "_maybe_expand", "method_params": "o", "method_startline": "315", "method_endline": "336", "method_complexity": {"method_NLOC": "5", "method_CCN": "2", "method_NToken": "31", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "nbs\\40_tabular.core.ipynb", "file_new_name": "nbs\\40_tabular.core.ipynb", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "1631", "deleted_lines": "1631"}}}}}}