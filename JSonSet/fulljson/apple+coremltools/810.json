{"BR": {"BR_id": "810", "BR_author": "leovinus2001", "BRopenT": "2020-07-23T17:30:38Z", "BRcloseT": "2020-08-12T17:15:38Z", "BR_text": {"BRsummary": "PyTorch to CoreML LSTM model conversion v4 fails with ValueError: Layer with name \"_lstm_h0_reshaped_expanded\" has already been added. Please use a unique name.", "BRdescription": "\n Relevance:-----------------------------------------------------------\n While there other open issues in the coremltools v4 TOT repo regarding PyTorch trained LSTMs, such as <denchmark-link:https://github.com/apple/coremltools/issues/755>#755</denchmark-link>\n  (multi layer LSTM) and <denchmark-link:https://github.com/apple/coremltools/issues/776>#776</denchmark-link>\n  (handling of LSTM initials h0/c0), I was looking for workarounds on how to build multi-layer bidirectional LSTMs. Now I ran into a blocking bug with error:\n \n Layer with name \"_lstm_h0_reshaped_expanded\" has already been added. Please use a unique name.\n \n In other words, another blocker on the conversion of PyTorch multilayer LSTMs (potential GRU/RNN as well).\n On the good side, a little digging in the conversion code leads to potential fix as well (see code and potential solution below) but I need your please to help to assess whether this approach is best, whether the unidirectional LSTM and GRU also need fixes, etc.\n Reproducible:-----------------------------------------------------------\n Yes\n Testcase:-----------------------------------------------------------\n Attached. Run e.g. as\n python3 -O ../testLstmTwoLayer.py\n <denchmark-link:https://github.com/apple/coremltools/files/4967763/testLstmTwoLayer.txt>testLstmTwoLayer.txt</denchmark-link>\n \n Setup:-----------------------------------------------------------\n Torch version : 1.5.1\n CoreML tools version : TOT  <denchmark-link:https://github.com/apple/coremltools/commit/705244e2be26c3fb7881fd7a731d25a55f5e4765>705244e</denchmark-link>\n  July 23\n Log:-----------------------------------------------------------\n Torch version : 1.5.1\n CoreML tools version : 4.0b1\n small_model(\n (lstm1): LSTM(28, 16, batch_first=True, bidirectional=True)\n (lstm2): LSTM(32, 8, batch_first=True, bidirectional=True)\n (fc1): Linear(in_features=16, out_features=11, bias=True)\n )\n Converting Frontend ==> MIL Ops:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d     | 46/47 [00:00<00:00, 218.23 ops/s]\n Running MIL optimization passes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:00<00:00, 17.78 passes/s]\n Translating MIL ==> MLModel Ops:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                 | 22/32 [00:00<00:00, 14936.01 ops/s]\n Traceback (most recent call last):\n File \"../testLstmTwoLayer.py\", line 74, in \n inputs=[ ct.TensorType(name=\"input1\", shape=dummy_input.shape) ],\n File \"/Library/Python/3.7/lib/python/site-packages/coremltools/converters/_converters_entry.py\", line 299, in convert\n **kwargs\n File \"/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/converter.py\", line 122, in _convert\n out = backend_converter(prog, **kwargs)\n File \"/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/converter.py\", line 72, in call\n return load(*args, **kwargs)\n File \"/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/backend/nn/load.py\", line 239, in load\n prog.functions[\"main\"].outputs,\n File \"/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/backend/nn/op_mapping.py\", line 50, in convert_ops\n mapper(const_context, builder, op)\n File \"/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/backend/nn/op_mapping.py\", line 1399, in lstm\n _expand_dim(builder, initial_h + postfix, initial_h, [2, 3, 4])\n File \"/Library/Python/3.7/lib/python/site-packages/coremltools/converters/mil/backend/nn/op_mapping.py\", line 208, in _expand_dim\n name=node_name, input_name=input_name, output_name=node_name, axes=axes\n File \"/Library/Python/3.7/lib/python/site-packages/coremltools/models/neural_network/builder.py\", line 7056, in add_expand_dims\n spec_layer = self._add_generic_layer(name, [input_name], [output_name])\n File \"~/Library/Python/3.7/lib/python/site-packages/coremltools/models/neural_network/builder.py\", line 1029, in _add_generic_layer\n % name\n ValueError: Layer with name \"_lstm_h0_reshaped_expanded\" has already been added. Please use a unique name.\n Interpretation and potential fix: -----------------------------------------------------------\n This is observed with git coremltools, TOT <denchmark-link:https://github.com/apple/coremltools/commit/705244e2be26c3fb7881fd7a731d25a55f5e4765>705244e</denchmark-link>\n  July 23\n The error\n \n Layer with name \"_lstm_h0_reshaped_expanded\" has already been added. Please use a unique name.\n \n seems to indicate that the naming scheme in the converter is using a global name scheme.\n While the testcase runs fine with ONE layer (set flag twoLayerModelFlag to False) when you run with TWO layers (twoLayerModelFlag=True) ) (or more presumably) the error occurs.\n Originally, you have on TOT the use of fixed postfixes like \"_expanded\" (for h0) and \"_expanded2\" (for c0) which leads to the issue it seems. When you have 2 layers or more, it seems the same variable name is generated multiple times.\n The line 1399 in coremltools/converters/mil/backend/nn/op_mapping.py\n points to the code below (The line numbers might be a little off due to my logging lines).\n Original code:\n def lstm(const_context, builder, op):\n ...\n <denchmark-h:h1>Roughly Line 1375 et al</denchmark-h>\n \n <denchmark-h:h1></denchmark-h>\n \n <denchmark-code>elif direction == \"bidirectional\":\n     # Expand initial_h and initial_c\n     _expand_dim(builder, initial_h + \"_expanded\", initial_h, [2, 3, 4]) # <------------------\n      initial_h += \"_expanded\"\n     \n     # initial_h may have the same name as initial_c (e.g., same Var)\n     _expand_dim(builder, initial_c + \"_expanded2\", initial_c, [2, 3, 4])  # <------------------\n     initial_c += \"_expanded2\"\n </denchmark-code>\n \n Therefore, I tried a quick randomization fix along the lines below to generate UNIQUE names every time you handle a new BLSTM layer.\n Potential fix:\n def lstm(const_context, builder, op):\n ...\n <denchmark-h:h1>Roughly Line 1375 et al</denchmark-h>\n \n <denchmark-h:h1></denchmark-h>\n \n <denchmark-code>elif direction == \"bidirectional\":\n     # Expand initial_h and initial_c\n     if 1:\n         # New\n         import random\n         mymax = 10000000 # Better, use sys.maxint\n         n = random.randrange(1,mymax)\n         postfix = \"_expanded_\" + str(n)\n         \n         n2 = random.randrange(1,mymax)\n         postfix2 = \"_expanded2_\" + str(n2)\n \n         mynodename = initial_h + \"_expanded\"\n         print (\"nodename \" + str(mynodename))\n         print (\"postfix\" + str(postfix))\n         print (\"postfix2\" + str(postfix2))\n     else:\n \t\t#ORG\n         postfix  = \"_expanded\"\n         postfix2 = \"_expanded2\"\n         \n     _expand_dim(builder, initial_h + postfix, initial_h, [2, 3, 4])  # <------------------\n     initial_h += postfix\n     \n     # initial_h may have the same name as initial_c (e.g., same Var)\n     _expand_dim(builder, initial_c + postfix2, initial_c, [2, 3, 4])  # <------------------\n     initial_c += postfix2\n </denchmark-code>\n \n While the conversion now completes, I have not checked whether \"everything\" is fine. which is why I ask for your help for a proper fix please. Note we might need a fix for other uniLSTM, GRU or RNN in the same file as well.\n As the other issues  <denchmark-link:https://github.com/apple/coremltools/issues/755>#755</denchmark-link>\n  (multi layer LSTM) and <denchmark-link:https://github.com/apple/coremltools/issues/776>#776</denchmark-link>\n  (handling of initials h0/c0) are still blocking us, it would be an immense help if we could fix this new issue quickly such that I can properly stack multiple BLSTMs. Thanks.\n Here is the output WITH the fix above:\n python3 -O ../testLstmTwoLayer.py\n WARNING:root:Keras version 2.4.3 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n Torch version : 1.5.1\n CoreML tools version : 4.0b1\n small_model(\n (lstm1): LSTM(28, 16, batch_first=True, bidirectional=True)\n (lstm2): LSTM(32, 8, batch_first=True, bidirectional=True)\n (fc1): Linear(in_features=16, out_features=11, bias=True)\n )\n Converting Frontend ==> MIL Ops:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d     | 46/47 [00:00<00:00, 213.31 ops/s]\n Running MIL optimization passes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:00<00:00, 17.83 passes/s]\n Translating MIL ==> MLModel Ops:   0%|                                                                                                                                                                                                                                                                               | 0/32 [00:00<?, ? ops/s]\n nodename _lstm_h0_reshaped_expanded\n postfix_expanded_6035530\t\t\t# <------------------ randomized\n postfix2_expanded2_4582868\t\t\t# <------------------ randomized\n nodename _lstm_h0_reshaped_expanded\n postfix_expanded_3955283\n postfix2_expanded2_1781011\n Translating MIL ==> MLModel Ops: 100%\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "leovinus2001", "commentT": "2020-08-05T16:15:17Z", "comment_text": "\n \t\tUpdated testcase for PR <denchmark-link:https://github.com/apple/coremltools/pull/843>#843</denchmark-link>\n \n <denchmark-link:https://github.com/apple/coremltools/files/5029648/testLstmTwoLayer.txt>testLstmTwoLayer.txt</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "4b81a5e4954e39c78c351d3fe9d9b425549fc56e", "commit_author": "leovinus2001", "commitT": "2020-08-12 10:15:37-07:00", "commit_complexity": {"commit_NLOC": "0.75", "commit_CCN": "0.75", "commit_Nprams": "0.25"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "coremltools\\converters\\mil\\backend\\nn\\op_mapping.py", "file_new_name": "coremltools\\converters\\mil\\backend\\nn\\op_mapping.py", "file_complexity": {"file_NLOC": "2413", "file_CCN": "377", "file_NToken": "17415"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1378,1379,1380,1381,1382,1383,1384,1386,1387,1388,1389", "deleted_lines": "1378,1379,1380,1382,1383", "method_info": {"method_name": "lstm", "method_params": "const_context,builder,op", "method_startline": "1299", "method_endline": "1509", "method_complexity": {"method_NLOC": "145", "method_CCN": "12", "method_NToken": "1169", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "coremltools\\converters\\mil\\frontend\\torch\\test\\test_torch_ops.py", "file_new_name": "coremltools\\converters\\mil\\frontend\\torch\\test\\test_torch_ops.py", "file_complexity": {"file_NLOC": "532", "file_CCN": "55", "file_NToken": "3776"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "498,499,500", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,flagReturnTuple_", "method_startline": "498", "method_endline": "500", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "22", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "502,503,504,505", "deleted_lines": null, "method_info": {"method_name": "forward", "method_params": "self,x", "method_startline": "502", "method_endline": "505", "method_complexity": {"method_NLOC": "2", "method_CCN": "2", "method_NToken": "24", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "513,514,515,516,517,518,519,520,521,522", "deleted_lines": null, "method_info": {"method_name": "test_lstm", "method_params": "self,input_size,hidden_size,num_layers,bias,batch_first,dropout,bidirectional,backend", "method_startline": "513", "method_endline": "522", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "20", "method_nesting_level": "1"}}}}}}}}