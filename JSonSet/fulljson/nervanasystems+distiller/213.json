{"BR": {"BR_id": "213", "BR_author": "dabadee", "BRopenT": "2019-04-02T16:06:19Z", "BRcloseT": "2020-04-27T19:48:10Z", "BR_text": {"BRsummary": "Network Thinner Error", "BRdescription": "\n I am getting the following error when I use network thinner, how can I resolve it ?\n <denchmark-code>Traceback (most recent call last):\n   File \"compress_classifier.py\", line 754, in <module>\n     main()\n   File \"compress_classifier.py\", line 256, in main\n     loggers=[tflogger, pylogger], args=args)\n   File \"compress_classifier.py\", line 333, in train\n     output = model(inputs)\n   File \"/home/daba/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"/home/daba/anaconda3/lib/python3.7/site-packages/torchvision/models/alexnet.py\", line 44, in forward\n     x = x.view(x.size(0), 256 * 6 * 6)\n RuntimeError: shape '[32, 9216]' is invalid for input of size 266112\n </denchmark-code>\n \n I use the command\n <denchmark-code>python3 compress_classifier.py -a=alexnet --lr=0.000005 -p=50 /media/daba/0C5235005234F056/ImageNet/ -j 8 --epochs 1 --pretrained --compress=/home/daba/schedules/alexnetOneShot.yaml -b 32\n </denchmark-code>\n \n I am using the following schedule\n <denchmark-code>version: 1\n pruners:\n   fc1_pruner:\n     class: 'L1RankedStructureParameterPruner'\n     group_type: Rows\n     desired_sparsity: 0.33\n     weights: ['classifier.1.weight']\n \n   fc2_pruner:\n     class: 'L1RankedStructureParameterPruner'\n     group_type: Rows\n     desired_sparsity: 0.3\n     weights: ['classifier.4.weight']\n \n   fc3_pruner:\n     class: 'L1RankedStructureParameterPruner'\n     group_type: Rows\n     desired_sparsity: 0.2\n     weights: ['classifier.6.weight']\n \n   conv1_pruner:\n     class: 'L1RankedStructureParameterPruner'\n     group_type: Filters\n     desired_sparsity: 0.07\n     weights: ['features.module.0.weight']\n \n   conv2_pruner:\n     class: 'L1RankedStructureParameterPruner'\n     group_type: Filters\n     desired_sparsity: 0.1\n     weights: ['features.module.3.weight']\n \n   conv3_pruner:\n     class: 'L1RankedStructureParameterPruner'\n     group_type: Filters\n     desired_sparsity: 0.12\n     weights: ['features.module.6.weight']\n \n   conv4_pruner:\n     class: 'L1RankedStructureParameterPruner'\n     group_type: Filters\n     desired_sparsity: 0.1\n     weights: ['features.module.8.weight']\n \n   conv5_pruner:\n     class: 'L1RankedStructureParameterPruner'\n     group_type: Filters\n     desired_sparsity: 0.1\n     weights: ['features.module.10.weight']\n \n extensions:\n   net_thinner:\n       class: 'FilterRemover'\n       thinning_func_str: remove_filters\n       arch: 'alexnet'\n       dataset: 'imagenet'\n \n \n lr_schedulers:\n   # Learning rate decay scheduler\n    pruning_lr:\n      class: ExponentialLR\n      gamma: 0.9\n \n \n policies:\n \n   - pruner:\n       instance_name : 'conv1_pruner'\n     epochs : [0]\n \n   - pruner:\n       instance_name : 'conv2_pruner'\n     epochs : [0]\n \n   - pruner:\n       instance_name : 'conv3_pruner'\n     epochs : [0]\n \n   - pruner:\n       instance_name : 'conv4_pruner'\n     epochs : [0]\n \n   - pruner:\n       instance_name : 'conv5_pruner'\n     epochs : [0]\n \n   - pruner:\n       instance_name : 'fc1_pruner'\n     epochs : [0]\n \n   - pruner:\n       instance_name: 'fc2_pruner'\n     epochs : [0]\n \n   - pruner:\n       instance_name: 'fc3_pruner'\n     epochs : [0]\n \n   - extension:\n       instance_name: 'net_thinner'\n     epochs : [0]\n \n   - lr_scheduler:\n       instance_name: pruning_lr\n     starting_epoch: 24\n     ending_epoch: 200\n     frequency: 1\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "dabadee", "commentT": "2019-04-03T23:23:02Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/dabadee>@dabadee</denchmark-link>\n ,\n Thanks for the detailed description of the issue - it made it very easy to reproduce the problem.\n There are two problems here:\n \n The number of channels in the view created between the features and the classifier is hard-coded for no real reason:\n https://github.com/pytorch/vision/blob/f566fac80e3182a8b3c0219a88ae00ed1b81d7c7/torchvision/models/alexnet.py#L46\n \n In Alexnet change:\n \n to\n \n The thinning code could take care of this, but I don't think adding this now is very important.\n 2. The <denchmark-link:https://github.com/pytorch/vision/blob/f566fac80e3182a8b3c0219a88ae00ed1b81d7c7/torchvision/models/alexnet.py#L34>Dropout layers</denchmark-link>\n  remain when traversing the pytorch graph in evaluation mode and this is confusing .\n I will fix this.  Meanwhile you can disable .  Alternatively you can remark the problematic Dropout layer, but note that if you do that you won't be able to load the pretrained model from TorchVision.\n Cheers\n Neta\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "dabadee", "commentT": "2019-04-08T09:29:08Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/dabadee>@dabadee</denchmark-link>\n ,\n I merged the fix, but please note that there is another bug: pruning rows of a Linear layer following a convolutional layer that had its filters thinned throws a RuntimeError (wrong tensor sizes).\n I will file an issue.\n Cheers\n Neta\n \t\t"}}}, "commit": {"commit_id": "73b3b3cff33113c53e1aa396c09b041db7e79e90", "commit_author": "Neta Zmora", "commitT": "2019-04-08 11:38:20+03:00", "commit_complexity": {"commit_NLOC": "0.7777777777777778", "commit_CCN": "0.7777777777777778", "commit_Nprams": "0.7777777777777778"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "distiller\\summary_graph.py", "file_new_name": "distiller\\summary_graph.py", "file_complexity": {"file_NLOC": "275", "file_CCN": "106", "file_NToken": "2144"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "134,135,136,137,138,139", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,model,dummy_input", "method_startline": "95", "method_endline": "155", "method_complexity": {"method_NLOC": "37", "method_CCN": "10", "method_NToken": "392", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "52,53,54,55,56,57,58,59,60,61", "deleted_lines": null, "method_info": {"method_name": "increment_instance", "method_params": "node_name", "method_startline": "52", "method_endline": "61", "method_complexity": {"method_NLOC": "7", "method_CCN": "2", "method_NToken": "42", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tests\\test_summarygraph.py", "file_new_name": "tests\\test_summarygraph.py", "file_complexity": {"file_NLOC": "116", "file_CCN": "20", "file_NToken": "1038"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "62", "deleted_lines": "62", "method_info": {"method_name": "test_connectivity", "method_params": "", "method_startline": "57", "method_endline": "83", "method_complexity": {"method_NLOC": "20", "method_CCN": "3", "method_NToken": "204", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "176,179", "deleted_lines": "176,179", "method_info": {"method_name": "test_connectivity_summary", "method_params": "", "method_startline": "171", "method_endline": "179", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "43", "method_nesting_level": "0"}}}}}}}}