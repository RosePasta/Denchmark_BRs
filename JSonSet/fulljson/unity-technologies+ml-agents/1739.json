{"BR": {"BR_id": "1739", "BR_author": "Hamachan7", "BRopenT": "2019-02-21T13:47:00Z", "BRcloseT": "2019-02-22T03:18:42Z", "BR_text": {"BRsummary": "Sample project tennis learning is slowly training, need fixing script?", "BRdescription": "\n Hi.\n I try to run sample project \"tennis learning\" but agents seems to be trained slowly.\n The below result was obtained with the original hyper parameters.\n [terminal's output]\n <denchmark-code>INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 1000. Mean Reward: 0.009. Std of Reward: 0.038. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 10000. Mean Reward: 0.030. Std of Reward: 0.053. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 20000. Mean Reward: 0.048. Std of Reward: 0.057. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 25000. Mean Reward: 0.057. Std of Reward: 0.063. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 30000. Mean Reward: 0.085. Std of Reward: 0.112. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 40000. Mean Reward: 0.978. Std of Reward: 0.927. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 45000. Mean Reward: 1.332. Std of Reward: 1.000. Training.\n </denchmark-code>\n \n I noticed that both agentRb and ballRb refer to Agent's Rigidbody in  TennisAgent.cs.\n <denchmark-link:https://github.com/Unity-Technologies/ml-agents/blob/master/UnitySDK/Assets/ML-Agents/Examples/Tennis/Scripts/TennisAgent.cs>Here original script link</denchmark-link>\n \n <denchmark-code>Line 28   agentRb = GetComponent<Rigidbody>();\n Line 29   ballRb = GetComponent<Rigidbody>();\n Line 30   var canvas = GameObject.Find(CanvasName);\n </denchmark-code>\n \n Line 29,  \" ballRb = ball.GetComponent(); \" is correct ?\n According to the script context, agent needs ball's velocity to decide next action.\n Fixed script gave below results, maybe this is going well.\n <denchmark-code>INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 1000. Mean Reward: 0.006. Std of Reward: 0.034. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 10000. Mean Reward: 0.052. Std of Reward: 0.076. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 20000. Mean Reward: 0.153. Std of Reward: 0.148. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 25000. Mean Reward: 0.309. Std of Reward: 0.331. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 30000. Mean Reward: 0.833. Std of Reward: 0.728. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 40000. Mean Reward: 1.315. Std of Reward: 0.988. Training.\n INFO:mlagents.trainers: tennis-0: TennisLearning: Step: 45000. Mean Reward: 1.408. Std of Reward: 1.075. Training.\n </denchmark-code>\n \n Thank you.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Hamachan7", "commentT": "2019-02-21T21:49:02Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/Hamachan7>@Hamachan7</denchmark-link>\n \n You are correct. This is a bug, and we will be fixing it in v0.7. Thanks for pointing it out to us!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Hamachan7", "commentT": "2020-02-22T04:07:35Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "397b992f50eabc13a9d9b203b3ff6af8045aebe9", "commit_author": "Vincent-Pierre BERGES", "commitT": "2019-02-21 16:43:33-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "UnitySDK\\Assets\\ML-Agents\\Examples\\Tennis\\Scripts\\TennisAgent.cs", "file_new_name": "UnitySDK\\Assets\\ML-Agents\\Examples\\Tennis\\Scripts\\TennisAgent.cs", "file_complexity": {"file_NLOC": "71", "file_CCN": "12", "file_NToken": "583"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "29", "deleted_lines": "29", "method_info": {"method_name": "TennisAgent::InitializeAgent", "method_params": "", "method_startline": "26", "method_endline": "41", "method_complexity": {"method_NLOC": "16", "method_CCN": "2", "method_NToken": "84", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "UnitySDK\\Assets\\ML-Agents\\Examples\\Tennis\\TFModels\\TennisLearning.nn", "file_new_name": "UnitySDK\\Assets\\ML-Agents\\Examples\\Tennis\\TFModels\\TennisLearning.nn", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "UnitySDK\\Assets\\ML-Agents\\Examples\\Tennis\\TFModels\\TennisLearning.nn.meta", "file_new_name": "UnitySDK\\Assets\\ML-Agents\\Examples\\Tennis\\TFModels\\TennisLearning.nn.meta", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": null}}}}}}