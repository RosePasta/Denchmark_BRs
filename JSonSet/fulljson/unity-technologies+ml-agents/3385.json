{"BR": {"BR_id": "3385", "BR_author": "Dastyn", "BRopenT": "2020-02-07T15:47:47Z", "BRcloseT": "2020-03-09T20:31:57Z", "BR_text": {"BRsummary": "Pretraining: batch_size must fit number of experiences in demo file?", "BRdescription": "\n Hi!\n It seems that when training with pretraining, the batch_size in the yaml config file must be equal to the number of experiences recorded in the corresponding .demo file.\n If not equal, then an exception is raised:\n <denchmark-code>Setting up 2 worker threads for Enlighten.\n   Thread -> id: 7fb9e2ffd700 -> priority: 1 \n   Thread -> id: 7fb9e27fc700 -> priority: 1 \n ##utp:{\"type\":\"MemoryLeaks\",\"version\":2,\"phase\":\"Immediate\",\"time\":1581079838307,\"processId\":26838,\"allocatedMemory\":4079,\"memoryLabels\":[{\"Default\":40},{\"Permanent\":40},{\"NewDelete\":112},{\"Thread\":128},{\"Manager\":1680},{\"GfxDevice\":64},{\"Physics\":32},{\"Serialization\":40},{\"String\":311},{\"GI\":296},{\"VR\":1992},{\"Subsystems\":-656}]}\n INFO:mlagents_envs:Environment shut down with return code 0.\n Traceback (most recent call last):\n   File \"/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n     return fn(*args)\n   File \"/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\n     options, feed_dict, fetch_list, target_list, run_metadata)\n   File \"/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n     run_metadata)\n tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n   (0) Invalid argument: logits and labels must be broadcastable: logits_size=[579,2] labels_size=[573,2]\n \t [[{{node softmax_cross_entropy_with_logits_5}}]]\n \t [[Mean_3/_395]]\n   (1) Invalid argument: logits and labels must be broadcastable: logits_size=[579,2] labels_size=[573,2]\n \t [[{{node softmax_cross_entropy_with_logits_5}}]]\n 0 successful operations.\n 0 derived errors ignored.\n \n During handling of the above exception, another exception occurred:\n \n Traceback (most recent call last):\n   File \"/home/unity/.local/bin/mlagents-learn\", line 11, in <module>\n     sys.exit(main())\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/learn.py\", line 478, in main\n     run_training(0, run_seed, options, Queue())\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/learn.py\", line 316, in run_training\n     tc.start_learning(env_manager)\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/trainer_controller.py\", line 234, in start_learning\n     n_steps = self.advance(env_manager)\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents_envs/timers.py\", line 262, in wrapped\n     return func(*args, **kwargs)\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/trainer_controller.py\", line 321, in advance\n     trainer.update_policy()\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/ppo/trainer.py\", line 204, in update_policy\n     buffer.make_mini_batch(l, l + batch_size), n_sequences\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents_envs/timers.py\", line 262, in wrapped\n     return func(*args, **kwargs)\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/ppo/policy.py\", line 184, in update\n     update_vals = self._execute_model(feed_dict, self.update_dict)\n   File \"/home/unity/.local/lib/python3.6/site-packages/mlagents/trainers/tf_policy.py\", line 165, in _execute_model\n     network_out = self.sess.run(list(out_dict.values()), feed_dict=feed_dict)\n   File \"/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 950, in run\n     run_metadata_ptr)\n   File \"/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1173, in _run\n     feed_dict_tensor, options, run_metadata)\n   File \"/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\n     run_metadata)\n   File \"/home/unity/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_call\n     raise type(e)(node_def, op, message)\n tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n   (0) Invalid argument: logits and labels must be broadcastable: logits_size=[579,2] labels_size=[573,2]\n \t [[node softmax_cross_entropy_with_logits_5 (defined at /lib/python3.6/site-packages/mlagents/trainers/ppo/models.py:295) ]]\n \t [[Mean_3/_395]]\n   (1) Invalid argument: logits and labels must be broadcastable: logits_size=[579,2] labels_size=[573,2]\n \t [[node softmax_cross_entropy_with_logits_5 (defined at /lib/python3.6/site-packages/mlagents/trainers/ppo/models.py:295) ]]\n 0 successful operations.\n 0 derived errors ignored.\n \n Original stack trace for 'softmax_cross_entropy_with_logits_5':\n   File \"/bin/mlagents-learn\", line 11, in <module>\n     sys.exit(main())\n   File \"/lib/python3.6/site-packages/mlagents/trainers/learn.py\", line 478, in main\n     run_training(0, run_seed, options, Queue())\n   File \"/lib/python3.6/site-packages/mlagents/trainers/learn.py\", line 316, in run_training\n     tc.start_learning(env_manager)\n   File \"/lib/python3.6/site-packages/mlagents/trainers/trainer_controller.py\", line 213, in start_learning\n     env_manager.external_brains[name_behavior_id]\n   File \"/lib/python3.6/site-packages/mlagents/trainers/ppo/trainer.py\", line 239, in create_policy\n     self.load,\n   File \"/lib/python3.6/site-packages/mlagents/trainers/ppo/policy.py\", line 48, in __init__\n     brain, trainer_params, reward_signal_configs, is_training, load, seed\n   File \"/lib/python3.6/site-packages/mlagents/trainers/ppo/policy.py\", line 98, in create_model\n     trainer_params.get(\"vis_encode_type\", \"simple\")\n   File \"/lib/python3.6/site-packages/mlagents/trainers/ppo/models.py\", line 61, in __init__\n     self.create_dc_actor_critic(h_size, num_layers, vis_encode_type)\n   File \"/lib/python3.6/site-packages/mlagents/trainers/ppo/models.py\", line 295, in create_dc_actor_critic\n     for i in range(len(self.act_size))\n   File \"/lib/python3.6/site-packages/mlagents/trainers/ppo/models.py\", line 295, in <listcomp>\n     for i in range(len(self.act_size))\n   File \"/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n     return func(*args, **kwargs)\n   File \"/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 3151, in softmax_cross_entropy_with_logits_v2_helper\n     precise_logits, labels, name=name)\n   File \"/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 10970, in softmax_cross_entropy_with_logits\n     name=name)\n   File \"/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n     op_def=op_def)\n   File \"/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n     return func(*args, **kwargs)\n   File \"/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n     op_def=op_def)\n   File \"/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n     self._traceback = tf_stack.extract_stack()\n </denchmark-code>\n \n Typically, the demo file actually contained 573 experiences, but in the yaml config file, the batch_size = 579.\n \n OS: Linux Ubuntu 18.4\n ML-Agents version: v0.13.1\n TensorFlow version: 1.14\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Dastyn", "commentT": "2020-02-10T19:52:29Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/Dastyn>@Dastyn</denchmark-link>\n , thanks for reporting this, I've logged it with internal ID\n MLA-616.\n Basically there needs to be more than batch_size number of experiences in the demo file so that you could train at least one batch of demos. But the error message is pretty cryptic.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Dastyn", "commentT": "2020-03-09T20:31:57Z", "comment_text": "\n \t\tThis bug has been fixed in the latest master and will be released shortly. Closing this issue for now.\n \t\t"}}}, "commit": {"commit_id": "2b8630f5cb76fc6dd0cfd07e5828be43c87eb43a", "commit_author": "Ervin T", "commitT": "2020-03-09 12:57:55-07:00", "commit_complexity": {"commit_NLOC": "0.07142857142857142", "commit_CCN": "1.0", "commit_Nprams": "0.9285714285714286"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "com.unity.ml-agents\\CHANGELOG.md", "file_new_name": "com.unity.ml-agents\\CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "46", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "ml-agents\\mlagents\\trainers\\components\\reward_signals\\__init__.py", "file_new_name": "ml-agents\\mlagents\\trainers\\components\\reward_signals\\__init__.py", "file_complexity": {"file_NLOC": "64", "file_CCN": "4", "file_NToken": "330"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "43", "deleted_lines": "42", "method_info": {"method_name": "evaluate_batch", "method_params": "self,str", "method_startline": "42", "method_endline": "54", "method_complexity": {"method_NLOC": "13", "method_CCN": "1", "method_NToken": "69", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "57", "method_info": {"method_name": "prepare_update", "method_params": "self,TFPolicy,str,int", "method_startline": "56", "method_endline": "57", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "22", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "58", "deleted_lines": "57", "method_info": {"method_name": "prepare_update", "method_params": "self,TFPolicy,AgentBuffer,int", "method_startline": "57", "method_endline": "58", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "15", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "43", "deleted_lines": null, "method_info": {"method_name": "evaluate_batch", "method_params": "self,AgentBuffer", "method_startline": "43", "method_endline": "55", "method_complexity": {"method_NLOC": "13", "method_CCN": "1", "method_NToken": "62", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "ml-agents\\mlagents\\trainers\\components\\reward_signals\\curiosity\\signal.py", "file_new_name": "ml-agents\\mlagents\\trainers\\components\\reward_signals\\curiosity\\signal.py", "file_complexity": {"file_NLOC": "94", "file_CCN": "8", "file_NToken": "648"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "45", "deleted_lines": "44", "method_info": {"method_name": "evaluate_batch", "method_params": "self,str", "method_startline": "44", "method_endline": "69", "method_complexity": {"method_NLOC": "25", "method_CCN": "5", "method_NToken": "241", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "83", "method_info": {"method_name": "prepare_update", "method_params": "self,TFPolicy,str,int", "method_startline": "82", "method_endline": "83", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "22", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "84", "deleted_lines": "83", "method_info": {"method_name": "prepare_update", "method_params": "self,TFPolicy,AgentBuffer,int", "method_startline": "83", "method_endline": "84", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "15", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "45", "deleted_lines": null, "method_info": {"method_name": "evaluate_batch", "method_params": "self,AgentBuffer", "method_startline": "45", "method_endline": "70", "method_complexity": {"method_NLOC": "25", "method_CCN": "5", "method_NToken": "234", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "ml-agents\\mlagents\\trainers\\components\\reward_signals\\extrinsic\\signal.py", "file_new_name": "ml-agents\\mlagents\\trainers\\components\\reward_signals\\extrinsic\\signal.py", "file_complexity": {"file_NLOC": "18", "file_CCN": "2", "file_NToken": "124"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "20", "deleted_lines": "19", "method_info": {"method_name": "evaluate_batch", "method_params": "self,str", "method_startline": "19", "method_endline": "21", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "46", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "20", "deleted_lines": null, "method_info": {"method_name": "evaluate_batch", "method_params": "self,AgentBuffer", "method_startline": "20", "method_endline": "22", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "39", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "ml-agents\\mlagents\\trainers\\components\\reward_signals\\gail\\signal.py", "file_new_name": "ml-agents\\mlagents\\trainers\\components\\reward_signals\\gail\\signal.py", "file_complexity": {"file_NLOC": "113", "file_CCN": "9", "file_NToken": "823"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "65", "deleted_lines": "64", "method_info": {"method_name": "evaluate_batch", "method_params": "self,str", "method_startline": "64", "method_endline": "90", "method_complexity": {"method_NLOC": "25", "method_CCN": "6", "method_NToken": "239", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "104", "method_info": {"method_name": "prepare_update", "method_params": "self,TFPolicy,str,int", "method_startline": "103", "method_endline": "104", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "22", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "105", "deleted_lines": "104", "method_info": {"method_name": "prepare_update", "method_params": "self,TFPolicy,AgentBuffer,int", "method_startline": "104", "method_endline": "105", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "15", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "65", "deleted_lines": null, "method_info": {"method_name": "evaluate_batch", "method_params": "self,AgentBuffer", "method_startline": "65", "method_endline": "91", "method_complexity": {"method_NLOC": "25", "method_CCN": "6", "method_NToken": "232", "method_nesting_level": "1"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "ml-agents\\mlagents\\trainers\\sac\\optimizer.py", "file_new_name": "ml-agents\\mlagents\\trainers\\sac\\optimizer.py", "file_complexity": {"file_NLOC": "546", "file_CCN": "23", "file_NToken": "3412"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "570", "deleted_lines": "570", "method_info": {"method_name": "add_reward_signal_dicts", "method_params": "self,Tensor,str,str,str,int", "method_startline": "565", "method_endline": "571", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "48", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "540", "deleted_lines": "540", "method_info": {"method_name": "update_reward_signals", "method_params": "self,str,int", "method_startline": "539", "method_endline": "540", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "16", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "540", "deleted_lines": "540", "method_info": {"method_name": "update_reward_signals", "method_params": "self,str,int", "method_startline": "539", "method_endline": "540", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "16", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "570", "deleted_lines": "570", "method_info": {"method_name": "add_reward_signal_dicts", "method_params": "self,Tensor,str,str,str,int", "method_startline": "565", "method_endline": "571", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "48", "method_nesting_level": "1"}}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "ml-agents\\mlagents\\trainers\\tests\\test_ppo.py", "file_new_name": "ml-agents\\mlagents\\trainers\\tests\\test_ppo.py", "file_complexity": {"file_NLOC": "318", "file_CCN": "22", "file_NToken": "2018"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188", "deleted_lines": null, "method_info": {"method_name": "test_ppo_optimizer_update_gail", "method_params": "gail_dummy_config,dummy_config", "method_startline": "157", "method_endline": "188", "method_complexity": {"method_NLOC": "26", "method_CCN": "1", "method_NToken": "183", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "133,134", "deleted_lines": null, "method_info": {"method_name": "test_ppo_optimizer_update_curiosity", "method_params": "curiosity_dummy_config,dummy_config,rnn,visual,discrete", "method_startline": "133", "method_endline": "134", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "11", "method_nesting_level": "0"}}}}}}}}