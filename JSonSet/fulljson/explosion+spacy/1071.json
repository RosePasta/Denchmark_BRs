{"BR": {"BR_id": "1071", "BR_author": "sadovnychyi", "BRopenT": "2017-05-18T10:24:06Z", "BRcloseT": "2017-05-23T10:18:02Z", "BR_text": {"BRsummary": "doc.text doesn't match the original provided", "BRdescription": "\n import spacy\n nlp = spacy.load('en_core_web_sm')\n text = 'whereve'\n print(nlp('whereve').text)\n assert nlp('whereve').text == text\n <denchmark-code>where've\n Traceback (most recent call last):\n   File \"<stdin>\", line 1, in <module>\n AssertionError\n </denchmark-code>\n \n Seems to be a bug, since I'm expecting the documents to match exactly to retrieve the metadata for each of them after they are parsed.\n Happens with both en_core_web_sm@1.2.0 and en_core_web_md@1.2.1.\n <denchmark-h:h2>Info about spaCy</denchmark-h>\n \n \n spaCy version: 1.8.2\n Platform: Darwin-16.6.0-x86_64-i386-64bit\n Python version: 3.6.1\n Installed models: en_core_web_md, en_core_web_sm, en_depent_web_md\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "sadovnychyi", "commentT": "2017-05-19T15:32:44Z", "comment_text": "\n \t\tThanks!\n This will be a problem somewhere in the TOKENIZER_EXCEPTIONS. You can patch this at run-time to workaround the issue until we get it fixed in the next release.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "sadovnychyi", "commentT": "2017-05-23T10:18:50Z", "comment_text": "\n \t\tThanks \u2013 this was indeed a typo, damn. Just fixed it!\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "sadovnychyi", "commentT": "2018-05-08T21:38:17Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "7f6be41f212c2a6f65612beeccf170665e0ba106", "commit_author": "Ines Montani", "commitT": "2017-05-23 12:18:00+02:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\en\\tokenizer_exceptions.py", "file_new_name": "spacy\\en\\tokenizer_exceptions.py", "file_complexity": {"file_NLOC": "591", "file_CCN": "0", "file_NToken": "3923"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "181", "deleted_lines": "181"}}}}}}