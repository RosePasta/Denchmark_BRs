{"BR": {"BR_id": "4386", "BR_author": "ryszardtuora", "BRopenT": "2019-10-06T16:38:12Z", "BRcloseT": "2019-10-07T11:38:36Z", "BR_text": {"BRsummary": "An error while pruning vectors", "BRdescription": "\n I'm trying to retrain my models because of the 2.2 version update (btw the old ones seem to work alright, but I'm retraining them to be sure), and while trying to initialize a model using CLI i get an error inside the vector pruning function.\n The error is as follows\n \u2714 Successfully created model\n 2123132it [01:09, 30354.25it/s]i-forms-all-100-skipg-hs.txt\n \u2714 Loaded vectors from nkjp+wiki-forms-all-100-skipg-hs.txt\n Traceback (most recent call last):\n   File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n     \"__main__\", mod_spec)\n   File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n     exec(code, run_globals)\n   File \"/home/rtuora/.local/lib/python3.6/site-packages/spacy/__main__.py\", line 35, in <module>\n     plac.call(commands[command], sys.argv[1:])\n   File \"/home/rtuora/.local/lib/python3.6/site-packages/plac_core.py\", line 328, in call\n     cmd, result = parser.consume(arglist)\n   File \"/home/rtuora/.local/lib/python3.6/site-packages/plac_core.py\", line 207, in consume\n     return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n   File \"/home/rtuora/.local/lib/python3.6/site-packages/spacy/cli/init_model.py\", line 90, in init_model\n     add_vectors(nlp, vectors_loc, prune_vectors, vectors_name)\n   File \"/home/rtuora/.local/lib/python3.6/site-packages/spacy/cli/init_model.py\", line 201, in add_vectors\n     nlp.vocab.prune_vectors(prune_vectors)\n   File \"vocab.pyx\", line 324, in spacy.vocab.Vocab.prune_vectors\n   File \"vectors.pyx\", line 341, in spacy.vectors.Vectors.most_similar\n ValueError: could not broadcast input array from shape (1323132,1) into shape (1024,1)\n \n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n the exact commend I use is\n python3 -m spacy init-model pl output --vectors-loc nkjp+wiki-forms-all-100-skipg-hs.txt --prune-vectors 800000\n I've tried this with 2 different embeddings, and all seems to work well unless I enable the pruning option.\n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n spaCy version: 2.2.1\n Platform: Linux-4.15.0-58-generic-x86_64-with-Ubuntu-18.04-bionic\n Python version: 3.6.8\n \n BTW: I'm not sure if my reasoning on pruning vectors is correct. The loading times of my models are very long, and I suspect this might be because of it. If my initial embeddings have 3.5 m entries, and I prune them down to the first 800.000, is this a good practice for a general purpose model? Perhaps I should delete these entries altogether, as their effect on regular parsing task must be marginal (or maybe even need not be positive).\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ryszardtuora", "commentT": "2019-10-07T08:06:02Z", "comment_text": "\n \t\tThe most_similar() method was just updated and it looks like it's not taking the batch_size into account correctly. We'll look into it.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ryszardtuora", "commentT": "2019-11-06T11:54:33Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "d53a8d9313099b0c9724e28ca276603274749313", "commit_author": "adrianeboyd", "commitT": "2019-10-07 13:38:35+02:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\vectors.pyx", "file_new_name": "spacy\\vectors.pyx", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "340", "deleted_lines": "340"}}}}}}