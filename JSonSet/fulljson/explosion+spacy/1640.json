{"BR": {"BR_id": "1640", "BR_author": "cmckain", "BRopenT": "2017-11-26T04:47:12Z", "BRcloseT": "2018-01-14T14:02:24Z", "BR_text": {"BRsummary": "Debugger causes stack overflow because the property 'sent_start' is infinitely recursive", "BRdescription": "\n \"Unhandled exception at 0x00007FFC12181517 (token.cp36-win_amd64.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x0000000000000001, 0x0000000402603FF8).\"\n Iterating through a sentence causes a crash when PyCharm's debugger attempts to break after the first word (first word->second word->crash). Attached is the memory dump from Python after it crashed. If the dump with the heap would be useful, I can send it but it is over 2 GB.\n <denchmark-h:h2>Sample Code</denchmark-h>\n \n <denchmark-code>import spacy\n nlp = spacy.load('en_core_web_lg')\n sentence = \"Ashley graded Bob's term paper after he completed his assignment and she finished her group project with June.\"\n text = nlp(sentence)\n for token in text:\n     print(token.text, token.ent_id, token.lemma_, token.pos_, token.tag_, token.dep_) #break here\n </denchmark-code>\n \n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n spaCy version: 2.0.3\n Platform: Windows-10-10.0.17025-SP0\n Python version: 3.6.2\n python2.zip\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "cmckain", "commentT": "2017-11-29T22:15:37Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/cmckain>@cmckain</denchmark-link>\n  Do you have any insight about the likely implications of this?\n I don't regularly use debuggers, and I've never used PyCharm, so I'm not sure whether this points towards a deeper issue. If the crash is exposing a memory error in spaCy (e.g. a use after free or out-of-bounds access), obviously we're very interested in that! But if it's just that we hit some tight stack-size limit in this tool that we don't hit in regular execution, I don't think that's a problem we'd work on.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "cmckain", "commentT": "2017-11-29T23:05:23Z", "comment_text": "\n \t\tI have another problem with non-English models of Spacy 2.0 and PyCharm's debugger.\n With the English model, I run and debug my project as usual.\n With other models (I tried Portuguese and Spanish) I can run the project normally but when I try to use the debugger it halts on the line where I load the model:\n nlp = spacy.load('pt')\n or even:\n nlp = spacy.load('pt', disable=['parser', 'tagger', 'ner'])\n For some days I thought it was a PyCharm problem but after reinstall and even downgrade PyCharm I found that the source of the problem is the loading of the Spacy model. By chance, I left the debugger stopped in that line and discover that it restarts and follow to the next line after 10-15 minutes!!!\n Is there any difference in the load process of these models that can explain this incredible delay?\n It can't be a memory problem since the models' size is similar and I have enough memory (I run the project with the three models loaded without any problem).\n This is really puzzling me...\n Any tip would be welcome!\n <denchmark-h:h2>My Environment</denchmark-h>\n \n <denchmark-code>spaCy version      2.0.3\n Platform           Windows-10-10.0.17046-SP0\n Python version     3.6.3\n Models             en, es, pt\n \n TYPE        NAME                  MODEL                 VERSION\n package     pt-core-news-sm       pt_core_news_sm       2.0.0\n package     es-core-news-sm       es_core_news_sm       2.0.0\n package     en-core-web-sm        en_core_web_sm        2.0.0\n link        en                    en_core_web_sm        2.0.0\n link        es                    es_core_news_sm       2.0.0\n link        pt                    pt_core_news_sm       2.0.0\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "cmckain", "commentT": "2017-11-30T00:40:32Z", "comment_text": "\n \t\tAlthough I haven't stepped through the assembly line-by-line yet, I would infer that the debugger is somehow forcing the program into an unbreakable loop or, perhaps, some recursion which calls the same function over and over again. My first notice of this problem was when a depreciation warning kept printing until the program crashed. Oddly enough, the debugger works the first time you open a Spacy data structure but the second attempt (both on a child structure and something else) causes a crash. Perhaps the debugger is maintaining a lock on some of the data and the program just keeps failing to get it back and, as a result, just crashes?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "cmckain", "commentT": "2017-11-30T00:46:59Z", "comment_text": "\n \t\tI can confirm <denchmark-link:https://github.com/ruiEnca>@ruiEnca</denchmark-link>\n 's problem. Using the above code, here are my timed results with the debugger on and off:\n en_core_web_lg: 0:00:18.781000, 0:00:26.921000\n en_core_web_sm: 0:00:03.859000, 0:00:04.188000\n es_core_news_sm: 0:03:12.625000, 0:00:03.812000\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "cmckain", "commentT": "2017-12-03T03:54:09Z", "comment_text": "\n \t\tI think I figured it out, <denchmark-link:https://github.com/honnibal>@honnibal</denchmark-link>\n . In the file \"spaCy/spacy/tokens/token.pyx\", it sets up the 'get' and 'set' functions of the property \"sent_start\". If the word is literally the beginning of the sentence, it returns false but, if not, it returns the value of \"sent_start\" which calls the 'get' of \"sent_start\" which returns the value of \"sent_start\" and on and on. The stack overflow is because the function never stops calling itself after the first word. For most people, this isn't a problem because they don't need to call a depreciated function but the debugger does (since it lists all possible properties). My previous observation that it only occurred on the second listing was because I always tested the first word first and the second word second; when I removed the logic and had \"return self.sent_start\" always run, the program failed regardless of what word I chose to debug. My temporary solution was to change line 356 to \"return True\" although I'm not sure what it normally showed in the past. I would recommend that the removal of that property take place sooner rather than later. For <denchmark-link:https://github.com/ruiEnca>@ruiEnca</denchmark-link>\n 's issue, I would guess that the debugger is forcing some extra code to run that isn't normally run during startup as the debugger tries to load everything that it can.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "cmckain", "commentT": "2017-12-07T05:16:51Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/honnibal>@honnibal</denchmark-link>\n  <denchmark-link:https://github.com/cmckain>@cmckain</denchmark-link>\n  I found the place where the debugger stops for some minutes while loading a non-English model. It is in the  function of  in line 119:\n \n This function is called from  and  in \n With spacy.load('en') everything is ok. With other languages (I tried  and ) it halts.\n I can't spot the difference between loading the English model and the others.\n <denchmark-h:h2>My Environment</denchmark-h>\n \n <denchmark-code>spaCy version      2.0.4\n Location           C:\\Anaconda\\lib\\site-packages\\spacy-2.0.4-py3.6-win-amd64.egg\\spacy\n Platform           Windows-10-10.0.17046-SP0\n Python version     3.6.3\n Models             en, en_core_web_lg, en_core_web_md, es, pt\n \n TYPE        NAME                  MODEL                 VERSION\n package     pt-core-news-sm       pt_core_news_sm       2.0.0\n package     es-core-news-sm       es_core_news_sm       2.0.0\n package     en-core-web-sm        en_core_web_sm        2.0.0\n package     en-core-web-md        en_core_web_md        2.0.0\n package     en-core-web-lg        en_core_web_lg        2.0.0\n link        en                    en_core_web_sm        2.0.0\n link        en_core_web_lg        en_core_web_lg        2.0.0\n link        en_core_web_md        en_core_web_md        2.0.0\n link        es                    es_core_news_sm       2.0.0\n link        pt                    pt_core_news_sm       2.0.0\n </denchmark-code>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "cmckain", "commentT": "2018-01-14T14:03:11Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/cmckain>@cmckain</denchmark-link>\n  Thanks!! Was on holidays for most of December, so just getting back to this now. I've fixed the infinite loop -- I meant to write , but wrote ...\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "cmckain", "commentT": "2018-05-08T02:55:49Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "0cb090e52671eb05a31f5944df7dd8dc1cc209df", "commit_author": "Matthew Honnibal", "commitT": "2018-01-14 15:02:15+01:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\tokens\\token.pyx", "file_new_name": "spacy\\tokens\\token.pyx", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "357", "deleted_lines": "357"}}}}}}