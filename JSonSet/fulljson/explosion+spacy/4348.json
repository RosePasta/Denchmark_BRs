{"BR": {"BR_id": "4348", "BR_author": "AbhayGodbole", "BRopenT": "2019-10-01T06:28:31Z", "BRcloseT": "2019-10-02T02:04:11Z", "BR_text": {"BRsummary": "Getting IndexError: list index out of range", "BRdescription": "\n Hi\n I am trying to train the new NER model.  Getting following error while calling \" nlp.update(texts, annotations, sgd=optimizer, drop=0.35,\n losses=losses)\"\n <denchmark-code>INFO : Created blank 'en' model\n ERROR : Unable to process \n Error = list index out of range\n Traceback (most recent call last):\n   File \"..\\entityextractor\\model.py\", line 84, in trainModel\n     losses=losses)\n   File \"c:\\abhay\\ai\\ris-auditsupport\\virris-auditsupport\\lib\\site-packages\\spacy\\language.py\", line 475, in update\n     proc.update(docs, golds, sgd=get_grads, losses=losses, **kwargs)\n   File \"nn_parser.pyx\", line 418, in spacy.syntax.nn_parser.Parser.update\n   File \"_parser_model.pyx\", line 214, in spacy.syntax._parser_model.ParserModel.begin_update\n   File \"_parser_model.pyx\", line 262, in spacy.syntax._parser_model.ParserStepModel.__init__\n   File \"c:\\abhay\\ai\\ris-auditsupport\\virris-auditsupport\\lib\\site-packages\\thinc\\neural\\_classes\\feed_forward.py\", line 46, in begin_update\n     X, inc_layer_grad = layer.begin_update(X, drop=drop)\n   File \"c:\\abhay\\ai\\ris-auditsupport\\virris-auditsupport\\lib\\site-packages\\thinc\\api.py\", line 295, in begin_update\n     X, bp_layer = layer.begin_update(layer.ops.flatten(seqs_in, pad=pad), drop=drop)\n   File \"ops.pyx\", line 113, in thinc.neural.ops.Ops.flatten\n IndexError: list index out of range\n In [ ]:\n </denchmark-code>\n \n I am following a standard process, which worked for my earlier project.\n \n I have .tsv annotated fie, which currently have only one Entity annotated and rest is marked as \"O\"\n converting this tsv to json\n converting this json to spacy required format.\n passing this file to train the model.\n \n Looks like, there is some issue with the data, which I am not able to figure out, as if I provide my previous json, its working fine.\n Please help\n <denchmark-h:h2>Info about spaCy</denchmark-h>\n \n \n spaCy version: 2.1.8\n Platform: Windows-10-10.0.16299-SP0\n Python version: 3.7.1\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "AbhayGodbole", "commentT": "2019-10-01T06:53:43Z", "comment_text": "\n \t\tThanks for the report! We'll look into this. Just a quick question: are you training on GPU or CPU?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "AbhayGodbole", "commentT": "2019-10-01T07:24:05Z", "comment_text": "\n \t\tI am training on CPU\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "AbhayGodbole", "commentT": "2019-10-02T02:04:11Z", "comment_text": "\n \t\tHi\n It got solved. The issue was in Data. There were multiple full stops as part of the tokens like:\n .  O\n .  O\n .  O\n So it might be generating blank sentences while converting this to Json. When I removed this multiple occurrences, the error got fixed.\n In same use case I have one problem, which I will open another ticket for. This can be closed.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "AbhayGodbole", "commentT": "2019-10-02T10:59:57Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/AbhayGodbole>@AbhayGodbole</denchmark-link>\n  - happy to hear you got it solved. A recent patch to spaCy now should also prevent this error from happening (it will automatically ignore empty batches). Thanks again for the helpful report!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "AbhayGodbole", "commentT": "2019-10-02T12:47:20Z", "comment_text": "\n \t\tGreat!  Thanks for the update\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "AbhayGodbole", "commentT": "2019-11-01T12:54:28Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "9d3ce7cba237361fd9f442f3b02abfa464eac666", "commit_author": "Sofie Van Landeghem", "commitT": "2019-10-02 12:50:47+02:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\pipeline\\pipes.pyx", "file_new_name": "spacy\\pipeline\\pipes.pyx", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "457,458,459,460,474,475,476,978,979,980,991,992,993", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "spacy\\tests\\regression\\test_issue3001-3500.py", "file_new_name": "spacy\\tests\\regression\\test_issue3001-3500.py", "file_complexity": {"file_NLOC": "262", "file_CCN": "21", "file_NToken": "1992"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "321,322,323,324,325,326", "deleted_lines": null, "method_info": {"method_name": "test_issue3456", "method_params": "", "method_startline": "321", "method_endline": "326", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "38", "method_nesting_level": "0"}}}}}, "file_2": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "spacy\\tests\\regression\\test_issue4348.py", "file_complexity": {"file_NLOC": "15", "file_CCN": "3", "file_NToken": "142"}}}}}