{"BR": {"BR_id": "2385", "BR_author": "mpszumowski", "BRopenT": "2018-05-28T10:12:20Z", "BRcloseT": "2018-05-30T10:28:46Z", "BR_text": {"BRsummary": "iob_to_biluo converter does not handle multi-word entities", "BRdescription": "\n The spacy.gold.iob_to_biluo function mismatches NER tags for entities longer than one word. The problem seems to lie in _consume_ent function which increments length only for each I- tag and having encountered L- tag does not treat it as a part of entity. Thus it sets length = 1 where len(entity) == 1 token and length = len(entity) - 1 where len(entity) >= 2 tokens (in pseudocode, of course).\n Another problem I see is that the line: target = tags.pop(0).replace('B', 'I') corrupts all labels with a 'B' character, eg. it converts the following NER labels into the form:\n U-BRAWLERS -> U-IRAWLERS\n U-BAWLERS -> U-IAWLERS\n U-BASTARDS -> - U-IASTARDS\n In fact, this sets all labels with a 'B' to U- labels, because the formatted tag I-IAWLER will be compared to\n yet intact tag from the list I-BAWLER.\n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n You can reproduce the behavior sending to the read_iob (or any other converter from cli.converters) a list of line or lines in a iob (or appropriate) format.\n <denchmark-code>def read_iob(raw_sents):\n     sentences = []\n     for line in raw_sents:\n         if not line.strip():\n             continue\n         tokens = [t.split('|') for t in line.split()]\n         if len(tokens[0]) == 3:\n             words, pos, iob = zip(*tokens)\n         else:\n             words, iob = zip(*tokens)\n             pos = ['-'] * len(words)\n         biluo = iob_to_biluo(iob)\n         sentences.append([\n             {'orth': w, 'tag': p, 'ner': ent}\n             for (w, p, ent) in zip(words, pos, biluo)\n         ])\n     sentences = [{'tokens': sent} for sent in sentences]\n     paragraphs = [{'sentences': [sent]} for sent in sentences]\n     docs = [{'id': 0, 'paragraphs': [para]} for para in paragraphs]\n     return docs\n \n \n def iob_to_biluo(tags):\n     out = []\n     curr_label = None\n     tags = list(tags)\n     while tags:\n         out.extend(_consume_os(tags))\n         out.extend(_consume_ent(tags))\n     return out\n \n \n def _consume_os(tags):\n     while tags and tags[0] == 'O':\n         yield tags.pop(0)\n \n \n def _consume_ent(tags):\n     if not tags:\n         return []\n     target = tags.pop(0).replace('B', 'I')\n     length = 1\n     while tags and tags[0] == target:\n         length += 1\n         tags.pop(0)\n     label = target[2:]\n     if length == 1:\n         return ['U-' + label]\n     else:\n         start = 'B-' + label\n         end = 'L-' + label\n         middle = ['I-%s' % label for _ in range(1, length - 1)]\n         return [start] + middle + [end]\n \n \n text = ['participants|_|O :|_|O Angela|_|B-PERSON Merkel|_|L-PERSON and|_|O Virgil|_|B-PERSON van|_|I-PERSON Dijk|_|L-PERSON have|_|O convinced|_|O Polanski|_|U-BAWLER to|_|O make|_|O']\n read_iob(text)\n </denchmark-code>\n \n output:\n <class 'list'>: ['O', 'O', 'U-PERSON', 'U-PERSON', 'O', 'B-PERSON', 'L-PERSON', 'U-PERSON', 'O', 'O', 'U-IAWLER', 'O', 'O']\n should be:\n <class 'list'>: ['O', 'O', 'B-PERSON', L-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'L-PERSON', 'O', 'O', 'U-BAWLER', 'O', 'O']\n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n Operating System: Windows 10\n Python Version Used: 3.6.5\n spaCy Version Used: 2.0.11\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "mpszumowski", "commentT": "2018-05-28T10:38:47Z", "comment_text": "\n \t\tAlso, the lines:\n <denchmark-code>def _consume_ent(tags):\n     if not tags:\n         return []\n     target = tags.pop(0).replace('B', 'I')\n     length = 1\n     while tags and tags[0] == target:\n         length += 1\n         tags.pop(0)\n     label = target[2:]\n     if length == 1:\n         return ['U-' + label]\n </denchmark-code>\n \n are the place where it is possible to validate the input. If the tags are flawed (len(label) <= 2, hence  <= 2)  the converter will return \"U-\", which in turn will raise an error not until you pass the json to the train function. I have had problems with formatting the files correctly a couple of times, and from what I have seen here on Github, I am not the only one. But perhaps the general strategy with validation will depend on the implementation of a more complete converter <denchmark-link:https://github.com/explosion/spaCy/issues/1966#issuecomment-364732317>mentioned by Matthew some time ago</denchmark-link>\n .\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "mpszumowski", "commentT": "2018-05-28T15:01:49Z", "comment_text": "\n \t\tI have made a simple fix to the bug and will make a pull request shortly.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "mpszumowski", "commentT": "2018-06-29T11:11:41Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "c7d53348d7c0474852dc5ebe5794f2816ef7eb01", "commit_author": "Maciej", "commitT": "2018-05-30 12:28:44+02:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": ".github\\contributors\\mpszumowski.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\gold.pyx", "file_new_name": "spacy\\gold.pyx", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "356,357,358,360,363", "deleted_lines": "356,358,361"}}}, "file_2": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "spacy\\tests\\regression\\test_issue2385.py", "file_complexity": {"file_NLOC": "20", "file_CCN": "4", "file_NToken": "196"}}}}}