{"BR": {"BR_id": "5287", "BR_author": "peter-exos", "BRopenT": "2020-04-09T19:37:18Z", "BRcloseT": "2020-04-29T10:57:31Z", "BR_text": {"BRsummary": "Matcher with `\"SENT_START\": False` works differently with Sentencizer vs. dependency parser", "BRdescription": "\n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n Matcher with a token pattern containing \"SENT_START\": False gives the intended result with sentence boundaries set by the parser, but not if sentence boundaries are set by the Sentencizer.\n Say we want to identify (and merge) sequences of tokens in Title Case, but obviously we do not want to include the first token in a sentence. Then the following token pattern works with spaCy version >= 2.2.4\n <denchmark-code>import spacy\n from spacy.pipeline.pipes import Sentencizer\n from spacy.pipeline import EntityRuler\n \n prop_patterns = [\n     {   # Proper names come in title case\n         \"label\": \"ProperName\",\n         \"pattern\": [ \n             {\"IS_TITLE\": True, \"IS_SENT_START\": False},\n             {\"IS_TITLE\": True, \"OP\": \"+\"}]\n     }]\n \n nlp = spacy.load('en_core_web_sm', disable=['ner'])  # disabling NER here to see effect of Matcher\n nlp.add_pipe(EntityRuler(nlp, patterns=prop_patterns, validate=True))\n nlp.add_pipe(nlp.create_pipe('merge_entities'))\n \n text = \"In Europe, the European Central Bank is trying to calm the markets. But the crisis could last for months.\"\n doc = nlp(text)\n for sent in doc.sents:\n     print([tok.text for tok in sent])\n </denchmark-code>\n \n printing\n <denchmark-code>['In', 'Europe', ',', 'the', 'European Central Bank', 'is', 'trying', 'to', 'calm', 'the', 'markets', '.']\n ['But', 'the', 'crisis', 'could', 'last', 'for', 'months', '.']\n </denchmark-code>\n \n as expected.\n But when we disable the parser and instead use Sentencizer to assign sentence boundaries, we get\n <denchmark-code>['In', 'Europe', ',', 'the', 'European', 'Central', 'Bank', 'is', 'trying', 'to', 'calm', 'the', 'markets', '.']\n ['But', 'the', 'crisis', 'could', 'last', 'for', 'months', '.']\n </denchmark-code>\n \n where European Central Bank is not merged as an entity (full code is listed at the bottom).\n <denchmark-h:h2>Possible causes, solutions, and (currently impossible) workarounds</denchmark-h>\n \n When a token is not at the beginning of a sentence, the dependency parser does not actually set token.is_sent_start (leaving it as None), while Sentencizer sets it to False.\n (How exactly this leads to the difference in matching behavior is not 100% clear to me).\n <denchmark-h:h3>Trivalent sentence boundary marking and assigning is_sentenced</denchmark-h>\n \n The behavior of the dependency parser is probably the better option, because with its trivalent logic multiple sentence segmentation components could complement each other in a given pipeline.\n But just removing the following two lines\n <denchmark-code>                    else:\n                         doc.c[j].sent_start = -1\n </denchmark-code>\n \n from Sentencizer.set_annotations would cause problems with Docs consisting of a single sentence: given how it is currently implemented, Doc.is_sentenced would be False.\n <denchmark-h:h3>(Currently impossible?) workarounds</denchmark-h>\n \n Instead of specifying \"SENT_START\": False, we could try to write the pattern in terms of != True, which would include both False and None.\n Unfortunately, this does not seem possible right now.\n The following two approaches yield errors complaining that the complex right-hand side is not of type 'boolean'  [0 -> SENT_START]:\n <denchmark-code>{\"IS_TITLE\": True, \"SENT_START\": {\"NOT_IN\": [True]}}\n </denchmark-code>\n \n <denchmark-code>{\"IS_TITLE\": True, \"IS_SENT_START\": {\"!=\": True}}\n </denchmark-code>\n \n (The latter issue may be related to <denchmark-link:https://github.com/explosion/spaCy/issues/5281>#5281</denchmark-link>\n ).\n Finally, I tried writing the pattern like\n <denchmark-code>prop_patterns = [\n     {   # Proper names come in title case\n         \"label\": \"ProperName\",\n         \"pattern\": [ \n             {\"SENT_START\": True, \"OP\": \"!\"},\n             {\"IS_TITLE\": True, \"OP\": \"+\"}]\n     }]\n </denchmark-code>\n \n and the results were wild: in the above example it will (expectedly) yield the merged token the European Central Bank; but when a sentence starts with multiple tokens in Title Case, sentence boundaries get messed up (again expectedly: merging a match involving a sentence boundary invalidates the Spans marking sentences).\n <denchmark-h:h2></denchmark-h>\n \n The full code to reproduce the second output above (using IS_SENT_START instead of SENT_START yields the same pattern):\n <denchmark-code>nlq = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n nlq.add_pipe(Sentencizer())\n nlq.add_pipe(EntityRuler(nlq, patterns=prop_patterns, validate=True))\n nlq.add_pipe(nlq.create_pipe('merge_entities'))\n \n text = \"In Europe, the European Central Bank is trying to calm the markets. But the crisis could last for months.\"\n doc = nlq(text)\n for sent in doc.sents:\n     print([tok.text for tok in sent])\n for tok in doc:\n     print(tok.text, repr(tok.is_sent_start))\n </denchmark-code>\n \n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n spaCy version: 2.2.4\n Platform: Darwin-18.7.0-x86_64-i386-64bit\n Python version: 3.7.7\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "peter-exos", "commentT": "2020-04-10T08:01:37Z", "comment_text": "\n \t\tThis relates to <denchmark-link:https://github.com/explosion/spaCy/issues/4775>#4775</denchmark-link>\n . I agree that it's confusing that one component sets non-sentence boundaries as , and the other as . I think <denchmark-link:https://github.com/adrianeboyd>@adrianeboyd</denchmark-link>\n  is considering the options as this is a tricky issue when you want to combine different pipeline components that would set sentence boundaries in sequence.\n As a temporary workaround, have you tried pulling in branch <denchmark-link:https://github.com/explosion/spaCy/pull/5282>#5282</denchmark-link>\n  to check whether that would solve your issue, using  ? It would be a good test for that PR as well.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "peter-exos", "commentT": "2020-04-10T18:06:26Z", "comment_text": "\n \t\tIt doesn't look like <denchmark-link:https://github.com/explosion/spaCy/pull/5282>#5282</denchmark-link>\n  solves the issue.\n In fact, it looks like a completely different issue.\n After pulling <denchmark-link:https://github.com/explosion/spaCy/pull/5282>#5282</denchmark-link>\n  in I still get the same error message:\n <denchmark-code>spacy.errors.MatchPatternError: Invalid token patterns for matcher rule 'ProperName'\n \n Pattern 0:\n - {'!=': True} is not of type 'boolean' [0 -> SENT_START]\n </denchmark-code>\n \n This is the same error as I got when trying the workarounds mentioned above.\n The issue seems to be that any type of extended pattern syntax (like 'IN' or '!=') is not compatible with Boolean attributes, e.g. the following patterns all throw the same errors:\n <denchmark-code>{\"IS_TITLE\" : {\"!=\": False}}\n </denchmark-code>\n \n <denchmark-code>{\"IS_TITLE\" : {\"IN\": [True]}}\n </denchmark-code>\n \n This issue seems to be independent of <denchmark-link:https://github.com/explosion/spaCy/pull/5282>#5282</denchmark-link>\n .\n Just to confirm this, here is a self-contained code snippet, which breaks in the last line:\n <denchmark-code>import spacy\n from spacy.pipeline import EntityRuler\n from spacy.matcher import Matcher\n from spacy.tokens import Doc\n \n prop_patterns = [\n     {   # Proper names come in title case\n         \"label\": \"ProperName\",\n         \"pattern\": [ \n             {\"IS_TITLE\" : {\"==\": True}},\n             {\"IS_TITLE\": True, \"OP\": \"+\"}]\n     }]\n \n nlp = spacy.load('en_core_web_sm', disable=['ner'])\n \n matcher = Matcher(nlp.vocab)\n pattern = [{\"LENGTH\": {\"!=\": 2}}]\n matcher.add(\"LENGTH_COMPARE\", [pattern])\n doc = Doc(nlp.vocab, words=[\"a\", \"aa\", \"aaa\"])\n matches = matcher(doc)\n assert len(matches) == 2\n \n nlp.add_pipe(EntityRuler(nlp, patterns=prop_patterns, validate=True))\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "peter-exos", "commentT": "2020-04-24T08:31:58Z", "comment_text": "\n \t\tFor SENT_START, the Matcher is trying to compare boolean values in the pattern to -1/0/1 values underneath, which unsurprisingly does not really work that well for False == -1. This is only a problem for IS_SENT_START, since the other boolean attributes are actually boolean underneath.\n My proposed API is kind of clunky, but I think the easiest short-term solution is to normalize this value to True/False when the Matcher accesses it. I think we probably need to rethink how to store/show the sentence boundary values in the future.\n \t\t"}}}, "commit": {"commit_id": "3f43c73d37a5c175d0eabb35b9627a18aacd782a", "commit_author": "adrianeboyd", "commitT": "2020-04-29 12:57:30+02:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\matcher\\matcher.pyx", "file_new_name": "spacy\\matcher\\matcher.pyx", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "17,552,723,744,771", "deleted_lines": "17,552,723,744,771"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\tokens\\doc.pxd", "file_new_name": "spacy\\tokens\\doc.pxd", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "11", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\tokens\\doc.pyx", "file_new_name": "spacy\\tokens\\doc.pyx", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "82,83,84,85,86,87,88,89,90,91", "deleted_lines": null}}}}}}