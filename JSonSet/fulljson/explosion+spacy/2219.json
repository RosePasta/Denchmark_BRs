{"BR": {"BR_id": "2219", "BR_author": "hunan-rostomyan", "BRopenT": "2018-04-13T21:06:33Z", "BRcloseT": "2018-05-20T22:00:15Z", "BR_text": {"BRsummary": "Indexing issue during Token-Token similarity", "BRdescription": "\n Given these sentences:\n \n cat on the mat\n cat on a mat\n \n I want to look at the SpaCy <denchmark-link:https://spacy.io/api/token#similarity>similarity</denchmark-link>\n  scores between every pair of tokens in each of these sentences. The first one works, but I'm getting an error on the second one.\n <denchmark-h:h3>Code</denchmark-h>\n \n nlp = spacy.load('en')\n \n tokens = nlp('cat on a mat')\n \n for tok1 in tokens:\n     for tok2 in tokens:\n         print(tok1, tok2, tok1.similarity(tok2))\n <denchmark-h:h3>Error</denchmark-h>\n \n <denchmark-code>cat cat 1.0\n cat on -0.0020153373\n ---------------------------------------------------------------------------\n TypeError                                 Traceback (most recent call last)\n <ipython-input-133-e2870c8253a9> in <module>()\n       3 for tok1 in tokens:\n       4     for tok2 in tokens:\n ----> 5         print(tok1, tok2, tok1.similarity(tok2))\n       6 \n       7 heat = np.zeros(shape=(len(tokens), len(tokens)))\n \n token.pyx in spacy.tokens.token.Token.similarity()\n \n TypeError: 'spacy.tokens.token.Token' object does not support indexing\n </denchmark-code>\n \n I've had the same error on several other sentences, so I don't think it's specific to \"a\". Not sure how to make sense of this inconsistent behavior.\n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n Operating System: OS X 10.11.4 (15E65)\n Python Version Used: python 3.5+\n spaCy Version Used: 2.0.9\n Environment Information: Jupyter Notebook running a python3 kernel\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "hunan-rostomyan", "commentT": "2018-04-17T19:51:48Z", "comment_text": "\n \t\tI just encountered the same error, and agree that it looks like a bug. The problem is in lines 128\u2013129 of token.pyx, where if  other is length 1 there's an attempt to get the orth attribute of other[0]. I don't understand the full context, but it looks like this expects to unwrap a token from a single-item list, and instead it generates an error on a single-character string.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "hunan-rostomyan", "commentT": "2018-04-17T21:57:47Z", "comment_text": "\n \t\tGot the same error.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "hunan-rostomyan", "commentT": "2018-04-24T06:15:55Z", "comment_text": "\n \t\tGot the same error too.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "hunan-rostomyan", "commentT": "2018-04-25T04:24:45Z", "comment_text": "\n \t\tAlso got the same error.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "hunan-rostomyan", "commentT": "2018-04-28T04:15:10Z", "comment_text": "\n \t\tThis deserves a bug label, rather than feature labels. The test included with my pull request illustrates the problem.\n Briefly, token1.similarity(token2) will generate an error if token2 is a single-character word.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "hunan-rostomyan", "commentT": "2018-06-19T22:45:55Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "9b49a40f4e01dacb314007ab2b3f73ae93c654a8", "commit_author": "Douglas Knox", "commitT": "2018-05-03 18:40:46+02:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": ".github\\contributors\\knoxdw.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_1": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "spacy\\tests\\regression\\test_issue2219.py", "file_complexity": {"file_NLOC": "14", "file_CCN": "3", "file_NToken": "132"}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\tokens\\token.pyx", "file_new_name": "spacy\\tokens\\token.pyx", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "158", "deleted_lines": "158"}}}}}}