{"BR": {"BR_id": "4871", "BR_author": "danielvasic", "BRopenT": "2020-01-03T15:04:56Z", "BRcloseT": "2020-02-16T16:16:42Z", "BR_text": {"BRsummary": "AttributeError: 'FunctionLayer' object has no attribute 'W'", "BRdescription": "\n Hello, I have a problem using pretrained vectors with command line API. Steps to reproduce:\n <denchmark-code>python -m spacy pretrain fulltext.jsonl vectors/hr_vectors_web_md models/hr/language --use-vectors --use-char --dropout 0.3 --n-iter 60\n </denchmark-code>\n \n After that trying to train NER tagger with this command:\n <denchmark-code>python -m spacy train hr models/ner train-ner.json dev-ner.json -v vectors/hr_vectors_web_md --init-tok2vec models/hr/language/model59.bin -p ner\n </denchmark-code>\n \n Produces:\n \n Traceback (most recent call last):\n File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n \"main\", mod_spec)\n File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n exec(code, run_globals)\n File \"/usr/local/lib/python3.6/dist-packages/spacy/main.py\", line 33, in \n plac.call(commands[command], sys.argv[1:])\n File \"/usr/local/lib/python3.6/dist-packages/plac_core.py\", line 328, in call\n cmd, result = parser.consume(arglist)\n File \"/usr/local/lib/python3.6/dist-packages/plac_core.py\", line 207, in consume\n return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n File \"/usr/local/lib/python3.6/dist-packages/spacy/cli/train.py\", line 244, in train\n components = _load_pretrained_tok2vec(nlp, init_tok2vec)\n File \"/usr/local/lib/python3.6/dist-packages/spacy/cli/train.py\", line 551, in _load_pretrained_tok2vec\n component.tok2vec.from_bytes(weights_data)\n File \"/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\", line 375, in from_bytes\n dest = getattr(layer, name)\n AttributeError: 'FunctionLayer' object has no attribute 'W'\n \n I'm using Google Colaboratory enviroment.\n <denchmark-h:h2>Info about spaCy</denchmark-h>\n \n \n spaCy version: 2.2.3\n Platform: Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\n Python version: 3.6.9\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "danielvasic", "commentT": "2020-02-14T13:17:26Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/danielvasic>@danielvasic</denchmark-link>\n , thanks for the report!\n It looks like this is due to the  argument you used for , which should be replicated when you run the  command, but that option was not supported yet. PR <denchmark-link:https://github.com/explosion/spaCy/pull/5021>#5021</denchmark-link>\n  should hopefully fix that. See also my more extensive comment <denchmark-link:https://github.com/explosion/spaCy/issues/4819#issuecomment-586282668>here</denchmark-link>\n .\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "danielvasic", "commentT": "2020-02-14T13:40:50Z", "comment_text": "\n \t\tDear <denchmark-link:https://github.com/svlandeg>@svlandeg</denchmark-link>\n  , thanks for the response.\n Looking forward for the support of --use-char option in train command as it's very important for morphologically rich languages such as Croatian. I will try to train the model without this option for now.\n All the best,\n Daniel\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "danielvasic", "commentT": "2020-02-14T13:46:20Z", "comment_text": "\n \t\tAs a quick hack, you could also set the environment variable  to  (it needs to be the negation of ), then the parser will hopefully find it <denchmark-link:https://github.com/explosion/spaCy/blob/master/spacy/syntax/nn_parser.pyx#L57>here</denchmark-link>\n .\n All of this will be thoroughly refactored and much easier to work with, from spaCy v.3 onwards ;-)\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "danielvasic", "commentT": "2020-02-14T13:51:44Z", "comment_text": "\n \t\tActually, one more thought. If you want character embeddings, you should try running without vectors. Have a look at the code <denchmark-link:https://github.com/explosion/spaCy/blob/master/spacy/ml/_legacy_tok2vec.py#L63>here</denchmark-link>\n :  is only used when  and  is  !\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "danielvasic", "commentT": "2020-02-14T13:57:14Z", "comment_text": "\n \t\tI'm afraid I do not have enough annotated data not to use pre trained word vectors, I have already trained model using FastText word vectors, but  I will try this and compare the results maybe I'm wrong, many thanks for the support :-)\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "danielvasic", "commentT": "2020-02-14T13:57:34Z", "comment_text": "\n \t\tAnd yet another note: you can add a block for CharacterEmbed combined with a vector, but there's a bug in concatenate_lists on GPU so you can only use it on CPU. (Which is probably part of why CharacterEmbed isn't used in any spacy v2.2 models by default.)\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "danielvasic", "commentT": "2020-02-14T17:19:52Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/adrianeboyd>@adrianeboyd</denchmark-link>\n  thank you very much for the suggestion, will give it a try.\n All the best,\n Daniel\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "danielvasic", "commentT": "2020-03-17T16:37:19Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "257246017572433af7825d561de573dae73828f0", "commit_author": "Sofie Van Landeghem", "commitT": "2020-02-16 17:16:41+01:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "1.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "spacy\\cli\\pretrain.py", "file_new_name": "spacy\\cli\\pretrain.py", "file_complexity": {"file_NLOC": "319", "file_CCN": "25", "file_NToken": "2052"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "87", "deleted_lines": "87", "method_info": {"method_name": "pretrain", "method_params": "texts_loc,vectors_model,output_dir,width,depth,bilstm_depth,cnn_pieces,sa_depth,use_chars,cnn_window,embed_rows,loss_func,use_vectors,dropout,n_iter,batch_size,max_length,min_length,seed,n_save_every,init_tok2vec,epoch_start", "method_startline": "82", "method_endline": "104", "method_complexity": {"method_NLOC": "23", "method_CCN": "1", "method_NToken": "86", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "87", "deleted_lines": "87", "method_info": {"method_name": "pretrain", "method_params": "texts_loc,vectors_model,output_dir,width,conv_depth,bilstm_depth,cnn_pieces,sa_depth,use_chars,cnn_window,embed_rows,loss_func,use_vectors,dropout,n_iter,batch_size,max_length,min_length,seed,n_save_every,init_tok2vec,epoch_start", "method_startline": "82", "method_endline": "104", "method_complexity": {"method_NLOC": "23", "method_CCN": "1", "method_NToken": "86", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "spacy\\cli\\train.py", "file_new_name": "spacy\\cli\\train.py", "file_complexity": {"file_NLOC": "631", "file_CCN": "40", "file_NToken": "4184"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "74,75,76,77,78,79,80", "deleted_lines": null, "method_info": {"method_name": "train", "method_params": "lang,output_path,train_path,dev_path,raw_text,base_model,pipeline,replace_components,vectors,width,conv_depth,cnn_window,cnn_pieces,use_chars,bilstm_depth,embed_rows,n_iter,n_early_stopping,n_examples,use_gpu,version,meta_path,init_tok2vec,parser_multitasks,entity_multitasks,noise_level,orth_variant_level,eval_beam_widths,gold_preproc,learn_tokens,textcat_multilabel,textcat_arch,textcat_positive_label,verbose,debug", "method_startline": "64", "method_endline": "99", "method_complexity": {"method_NLOC": "36", "method_CCN": "1", "method_NToken": "139", "method_nesting_level": "0"}}}}}}}}