{"BR": {"BR_id": "6014", "BR_author": "chopeen", "BRopenT": "2020-09-02T11:11:34Z", "BRcloseT": "2020-09-02T13:15:46Z", "BR_text": {"BRsummary": "Off-by-one error when reporting best iteration of `spacy train`", "BRdescription": "\n I am running spacy train to train a NER model, the output is:\n <denchmark-code>Training pipeline: ['ner']\n Starting with base model 'en_core_web_lg'\n Replacing component from base model 'ner'\n Counting training words (limit=0)\n \n Itn  NER Loss   NER P   NER R   NER F   Token %  CPU WPS\n ---  ---------  ------  ------  ------  -------  -------\n   1  62234.469  62.796  41.864  50.237  100.000    23189                        \n   2  19664.287  65.930  51.817  58.027  100.000    27767                        \n   3  15704.214  63.482  53.002  57.770  100.000    29516                        \n   4  16203.358  65.178  56.477  60.516  100.000    27201                        \n   5  12726.774  65.704  59.321  62.350  100.000    29252                        \n   6  12014.974  66.430  59.084  62.542  100.000    27897                        \n   7  11054.259  66.725  60.190  63.289  100.000    28087                        \n   8  10016.129  65.371  58.452  61.718  100.000    26646                        \n Early stopping, best iteration is: 6\n Best score = 63.40121792913442; Final iteration score = 62.57056616419042\n </denchmark-code>\n \n The message says \"best iteration is: 6\" even though the F-score for iteration 7 is higher. Is it a bug or am I reading this output wrong?\n This issue appears consistently for different models I have been training today.\n <denchmark-h:h2>Info about spaCy</denchmark-h>\n \n \n spaCy version: 2.3.2\n Platform: Linux-4.15.0-112-generic-x86_64-with-glibc2.10\n Python version: 3.8.5\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "chopeen", "commentT": "2020-09-02T11:23:27Z", "comment_text": "\n \t\tThe calculation is implemented in <denchmark-link:https://github.com/explosion/spaCy/blob/597bcc629e173dfd87422188dc76a2f1053a9bba/spacy/cli/train.py#L559>train.py</denchmark-link>\n :\n <denchmark-code>if iter_since_best >= n_early_stopping:\n     msg.text(\n         \"Early stopping, best iteration \"\n         \"is: {}\".format(i - iter_since_best)\n     )\n </denchmark-code>\n \n i starts from zero and the iterations are numbered from 1 (column Itn), so I think the calculation should be (i + 1) - iter_since_best. If my reasoning I correct, I am happy to submit a PR.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "chopeen", "commentT": "2020-09-02T11:31:41Z", "comment_text": "\n \t\tSure, a PR would be welcome! I think we updated the console output to start counting the iterations from 1 at some point, but missed this section in the output. I'm pretty sure it's still correctly selecting/saving the best model in the saved output, right?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "chopeen", "commentT": "2020-09-02T12:12:09Z", "comment_text": "\n \t\tmodel-best == model6 and model directories are numbered from 0, so it is correct.\n \t\t"}}}, "commit": {"commit_id": "92d7832a86b9bb525cfc02f97378712ff4770cfb", "commit_author": "Marek Grzenkowicz", "commitT": "2020-09-02 15:15:45+02:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\cli\\train.py", "file_new_name": "spacy\\cli\\train.py", "file_complexity": {"file_NLOC": "689", "file_CCN": "43", "file_NToken": "4614"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "557,560", "deleted_lines": "559"}}}}}}