{"BR": {"BR_id": "4651", "BR_author": "GuiGel", "BRopenT": "2019-11-15T08:13:23Z", "BRcloseT": "2019-11-21T20:28:10Z", "BR_text": {"BRsummary": "EntityRuler from_disk method doesn't work when phrase_matcher_attr is specified", "BRdescription": "\n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n import spacy\n from spacy.lang.en import English\n from spacy.pipeline import EntityRuler\n nlp = English()\n ruler = EntityRuler(nlp, phrase_matcher_attr='LOWER')\n patterns = [{\"label\": \"PYTHON_LIB\", \"pattern\": \"spacy\", \"id\": \"spaCy\"}]\n ruler.add_patterns(patterns)\n nlp.add_pipe(ruler)\n nlp.to_disk('spacy2.2_model')\n text = \"Spacy is a python library for nlp\"\n doc = nlp(text)\n print('{}\\n{}'.format(text, '-'*100))\n print(\"original model\\n\")\n detection = [(ent.text, ent.label_, ent.ent_id_) for ent in doc.ents]\n print('ENT TEXT -> {}\\nENT LABEL > {}\\nENT ID ---> {}\\n'.format(*detection[0]))\n nlp_loaded = spacy.load('spacy2.2_model')\n print(\"{}\\nload model\\n\".format('-'*100))\n loaded_doc = nlp_loaded(\"Spacy is a python library for nlp.\")\n detection = [(ent.text, ent.label_, ent.ent_id_) for ent in loaded_doc.ents]\n print(detection)\n --> OUTPUT\n <denchmark-h:h2>Spacy is a python library for nlp</denchmark-h>\n \n original model\n ENT TEXT -> Spacy\n ENT LABEL > PYTHON_LIB\n ENT ID ---> spaCy\n <denchmark-h:hr></denchmark-h>\n \n load model\n []\n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n spaCy version: 2.2.2\n Platform: Linux-4.9.0-11-amd64-x86_64-with-debian-9.11\n Python version: 3.7.3\n \n Temporarily, I have modified the EntityRuler from_disk method in order to have my exemple working.\n I have split the deserializer in 2 parts. One in order to deserialize the cfg first and and other one in order to deserialize the patterns. By this way the phrase_matcher_attr attribute can be take into account when the add_patterns method is called by the line: from_disk(path, deserializers_patterns, {})\n <denchmark-h:h3>Info</denchmark-h>\n \n The code that I have used to solved the bug in order to continue working...\n def from_disk(self, path, **kwargs):\n \"\"\"Load the entity ruler from a file. Expects a file containing\n newline-delimited JSON (JSONL) with one entry per line.\n <denchmark-code>    path (unicode / Path): The JSONL file to load.\n     **kwargs: Other config paramters, mostly for consistency.\n     RETURNS (EntityRuler): The loaded entity ruler.\n \n     DOCS: https://spacy.io/api/entityruler#from_disk\n     \"\"\"\n     path = ensure_path(path)\n     depr_patterns_path = path.with_suffix(\".jsonl\")\n     if depr_patterns_path.is_file():\n         patterns = srsly.read_jsonl(depr_patterns_path)\n         self.add_patterns(patterns)\n     else:\n         cfg = {}\n </denchmark-code>\n \n '---------------------------------- MODIF ---------- SPLIT SERIALIZER -----------------------------'\n deserializers_patterns = {\n \"patterns\": lambda p: self.add_patterns(\n srsly.read_jsonl(p.with_suffix(\".jsonl\"))\n )}\n deserializers_cfg = {\n \"cfg\": lambda p: cfg.update(srsly.read_json(p))\n }\n from_disk(path, deserializers_cfg, {})\n '--------------------------------------------------------------------------------------------------------------'\n self.overwrite = cfg.get(\"overwrite\", False)\n self.phrase_matcher_attr = cfg.get(\"phrase_matcher_attr\")\n self.ent_id_sep = cfg.get(\"ent_id_sep\", DEFAULT_ENT_ID_SEP)\n <denchmark-code>        if self.phrase_matcher_attr is not None:\n             self.phrase_matcher = PhraseMatcher(\n                 self.nlp.vocab, attr=self.phrase_matcher_attr\n             )\n </denchmark-code>\n \n '---------------------------------- MODIF ---------- DESERIALIZE PATTERNS ----------------------'\n from_disk(path, deserializers_patterns, {})\n return self\n Can anyone reproduce the error?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "GuiGel", "commentT": "2019-11-15T08:43:06Z", "comment_text": "\n \t\tThanks for the report and the test case! That does look like a bug and that looks the right kind of solution, thanks! Would you like to submit a PR? (I can also do it, but if you'd like to, that would be great!)\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "GuiGel", "commentT": "2019-11-15T08:58:22Z", "comment_text": "\n \t\tYes I can try, It will be my first PR....\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "GuiGel", "commentT": "2019-11-21T20:28:10Z", "comment_text": "\n \t\tThanks again for the PR!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "GuiGel", "commentT": "2019-12-22T00:48:10Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "8f7ab70870cd4d2c8f33f878a8c4e6a4b5e5fa14", "commit_author": "GuiGel", "commitT": "2019-11-21 16:26:37+01:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "1.0", "commit_Nprams": "0.9473684210526315"}, "changed_files": {"file_0": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": ".github\\contributors\\GuiGel.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "spacy\\pipeline\\entityruler.py", "file_new_name": "spacy\\pipeline\\entityruler.py", "file_complexity": {"file_NLOC": "215", "file_CCN": "58", "file_NToken": "1576"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "295,298,299,300,302,311", "deleted_lines": "295,298,299,301", "method_info": {"method_name": "from_disk", "method_params": "self,path,kwargs", "method_startline": "278", "method_endline": "312", "method_complexity": {"method_NLOC": "25", "method_CCN": "3", "method_NToken": "177", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "spacy\\tests\\regression\\test_issue4651.py", "file_complexity": {"file_NLOC": "40", "file_CCN": "6", "file_NToken": "332"}}}}}