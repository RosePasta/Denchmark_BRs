{"BR": {"BR_id": "179", "BR_author": "appleleaves", "BRopenT": "2019-08-13T08:26:40Z", "BRcloseT": "2019-08-13T13:04:48Z", "BR_text": {"BRsummary": "model summery trainable params", "BRdescription": "\n If you set a keras.layers.Conv2D(...trainable=False), the lq.models.summery(model) report a wrong non-trainable number(and claim the non-trainable params trainable.)\n Using model.summery can get the right answer.\n I should be right, but please check it to confirm it again by yourself.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "appleleaves", "commentT": "2019-08-13T09:18:07Z", "comment_text": "\n \t\tThat's interesting, it looks like TensorFlow marks the weights as trainable even if they are listed as non trainable variables:\n In [19]: model = keras.Sequential([keras.layers.Conv2D(16, 3, input_shape=(32, 32, 3), trainable=False)])                                                   \n \n In [20]: model.layers[0].non_trainable_weights[0].trainable                                                                                                 \n Out[20]: True\n See also here: <denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/core.py#L1014-L1030>https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/core.py#L1014-L1030</denchmark-link>\n \n I'll take a look to see if there is a quick fix.\n \t\t"}}}, "commit": {"commit_id": "b32830b4cca4a69ac1daf1d176239971112620e4", "commit_author": "Lukas Geiger", "commitT": "2019-08-13 14:04:47+01:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "larq\\models.py", "file_new_name": "larq\\models.py", "file_complexity": {"file_NLOC": "297", "file_CCN": "100", "file_NToken": "1825"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "88,89", "method_info": {"method_name": "trainable", "method_params": "self", "method_startline": "88", "method_endline": "89", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "11", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "103,104,105,106,107", "deleted_lines": "106", "method_info": {"method_name": "__init__", "method_params": "self,layer", "method_startline": "100", "method_endline": "122", "method_complexity": {"method_NLOC": "21", "method_CCN": "5", "method_NToken": "113", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "71", "deleted_lines": "71", "method_info": {"method_name": "__init__", "method_params": "self,weight,bitwidth", "method_startline": "71", "method_endline": "73", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "21", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "71,74", "deleted_lines": "71", "method_info": {"method_name": "__init__", "method_params": "self,weight,bitwidth,trainable", "method_startline": "71", "method_endline": "74", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "30", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "larq\\models_test.py", "file_new_name": "larq\\models_test.py", "file_complexity": {"file_NLOC": "102", "file_CCN": "14", "file_NToken": "840"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "36", "deleted_lines": "36", "method_info": {"method_name": "get_profile_model", "method_params": "", "method_startline": "8", "method_endline": "38", "method_complexity": {"method_NLOC": "31", "method_CCN": "1", "method_NToken": "174", "method_nesting_level": "0"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "larq\\snapshots\\snap_models_test.py", "file_new_name": "larq\\snapshots\\snap_models_test.py", "file_complexity": {"file_NLOC": "28", "file_CCN": "0", "file_NToken": "19"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "10,25,26,34", "deleted_lines": "10,11,12,13,28,29,37"}}}}}}