{"BR": {"BR_id": "812", "BR_author": "dcferreira", "BRopenT": "2020-06-17T16:41:47Z", "BRcloseT": "2020-06-18T07:07:04Z", "BR_text": {"BRsummary": "--enable-microbatch breaks in text files with \",\" in it", "BRdescription": "\n Describe the bug\n When microbatch is enabled, a JSON input is (badly) converted to CSV, and a dataframe is generated from this CSV (I couldn't find any option to avoid this conversion, please let me know if such an option exists).\n Therefore, when a text field has the separator character (,) in it, it breaks. I suspect other characters might also break it (\", \\n).\n I'm not 100% sure I'm using this as intended from the client side, so please advise if that is the case.\n To Reproduce\n Steps to reproduce the behavior:\n \n Make a model, using the following code:\n \n import bentoml\n from bentoml.adapters import DataframeInput, DataframeOutput\n \n \n @bentoml.env(auto_pip_dependencies=True)\n class TestSizer(bentoml.BentoService):\n     @bentoml.api(input=DataframeInput(input_dtypes={\"text\": \"str\"}),\n                  output=DataframeOutput())\n     def size(self, df):\n         if 'text' not in df:\n             raise ValueError('The Dataframe needs a column named \"text\".')\n         return df.text.apply(len).to_frame()\n \n \n if __name__ == '__main__':\n     sizer = TestSizer()\n     sizer.save()\n \n \n Launch the server with bentoml serve TestSizer:latest --enable-microbatch.\n \n \n Use the following script to send some requests:\n \n \n import pandas as pd\n import requests\n \n \n class TextClient:\n     def __init__(self, server_url: str):\n         self.server_url = server_url\n \n     def size(self, df: pd.DataFrame) -> pd.DataFrame:\n         if 'text' not in df:\n             raise ValueError('The given Dataframe requires a column named \"html\".')\n         resp = requests.post(self.server_url, headers={'Content-Type': 'application/json'},\n                              data=df.to_json())\n         if resp.status_code != 200:\n             raise ValueError('Bad reply!')\n         return pd.DataFrame(data=resp.json(), index=df.index)\n \n \n if __name__ == '__main__':\n     client = TextClient('http://127.0.0.1:5000/size')\n     ex1 = pd.DataFrame({\"text\": [\"this is a text\", \"and another one\"]}, index=[\"one\", \"two\"])\n     ex2 = pd.DataFrame({\"text\": [\"this, is, a, text\", \"and yet another one\"]}, index=[\"one\", \"two\"])\n \n     print(client.size(ex1))\n     print(client.size(ex2))\n As described, ex1 is sent fine to the server, and a correct answer comes back; but for ex2 the server breaks with IndexError: list index out of range while trying to parse CSV into a DataFrame.\n If the server is running without --enable-microbatch, everything works fine.\n Full error message:\n <denchmark-code>[2020-06-17 18:29:02,374] ERROR - Exception on /size [POST]\n Traceback (most recent call last):\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/server/bento_api_server.py\", line 265, in api_func\n     response_body = api.handle_batch_request(request)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/service.py\", line 132, in handle_batch_request\n     responses = self.handler.handle_batch_request(requests, self.func)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/adapters/dataframe_input.py\", line 298, in handle_batch_request\n     datas, content_types\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/adapters/dataframe_input.py\", line 148, in read_dataframes_from_json_n_csv\n     df_merged = pd.read_csv(StringIO(df_str_csv), index_col=0)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 676, in parser_f\n     return _read(filepath_or_buffer, kwds)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 454, in _read\n     data = parser.read(nrows)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1133, in read\n     ret = self._engine.read(nrows)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/pandas/io/parsers.py\", line 2078, in read\n     values = data.pop(self.index_col[i])\n IndexError: list index out of range\n 127.0.0.1 - - [17/Jun/2020 18:29:02] \"POST /size HTTP/1.1\" 500 -\n [2020-06-17 18:29:02,377] ERROR - Traceback (most recent call last):\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/marshal/marshal.py\", line 207, in request_dispatcher\n     resp = await self.batch_handlers[api_name](req)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/marshal/dispatcher.py\", line 144, in _func\n     raise r\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/marshal/dispatcher.py\", line 204, in outbound_call\n     outputs = await self.callback(tuple(d for _, d, _ in inputs_info))\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/marshal/marshal.py\", line 110, in _batch_handler_template\n     return await func(requests, api_name)\n   File \"/home/dferreira/.miniconda3/envs/scam_env/lib/python3.7/site-packages/bentoml/marshal/marshal.py\", line 269, in _batch_handler_template\n     payload=SimpleResponse(resp.status, resp.headers, raw),\n bentoml.exceptions.RemoteException: Bad response status from model server:\n 500\n b'An error has occurred in BentoML user code when handling this request, find the error details in server logs'\n </denchmark-code>\n \n Environment:\n \n OS: Linux\n Python Version: 3.7\n BentoML Version: tried with 0.8.1 (stable) and also with current master branch\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "dcferreira", "commentT": "2020-06-17T20:08:56Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/bojiang>@bojiang</denchmark-link>\n  it probably makes more sense to separate batching JSON and CSV requests?\n I think it is ok to add a parameter to DataframeInput to specify the content type to only JSON or CSV if that makes more sense for micro batching implementation, e.g.:\n <denchmark-code>@api(input=DataframeInput(http_content_type='CSV'))\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "dcferreira", "commentT": "2020-06-18T08:43:28Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/dcferreira>@dcferreira</denchmark-link>\n  Thanks for your feedback!\n \n Fixed in PR #814\n More cases added to the test of DataframeInput https://github.com/bentoml/BentoML/blob/master/tests/handlers/test_dataframe_handler.py#L153\n As I mentioned in doc strings, the conversion before pandas.read_csv/read_json is necessary because it is N(batch size) times faster than an iteration of a batch of JSON inputs with pandas.read_csv. It helps a lot on throughput.\n \n \t\t"}}}, "commit": {"commit_id": "f893fc4e439b89ced0a8ae4b9be970af447fd966", "commit_author": "bojiang", "commitT": "2020-06-18 00:07:03-07:00", "commit_complexity": {"commit_NLOC": "0.7358490566037735", "commit_CCN": "0.2830188679245283", "commit_Nprams": "0.9622641509433962"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 14, "file_old_name": "bentoml\\utils\\dataframe_util.py", "file_new_name": "bentoml\\utils\\dataframe_util.py", "file_complexity": {"file_NLOC": "256", "file_CCN": "109", "file_NToken": "1699"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "99,110", "deleted_lines": "99,105", "method_info": {"method_name": "_from_json_split", "method_params": "DataFrameState,dict", "method_startline": "96", "method_endline": "110", "method_complexity": {"method_NLOC": "14", "method_CCN": "8", "method_NToken": "104", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "154,155,157,158,159,160,161,162,163,164,165,166,167,170,171,172,173", "deleted_lines": null, "method_info": {"method_name": "_from_csv_without_index", "method_params": "DataFrameState", "method_startline": "154", "method_endline": "173", "method_complexity": {"method_NLOC": "20", "method_CCN": "9", "method_NToken": "127", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "71,79", "deleted_lines": "71,77", "method_info": {"method_name": "_from_json_columns", "method_params": "DataFrameState,dict", "method_startline": "68", "method_endline": "79", "method_complexity": {"method_NLOC": "11", "method_CCN": "6", "method_NToken": "95", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "130,131,132,133,134,135,136,137,138", "deleted_lines": "130,132,133,134,135,138", "method_info": {"method_name": "_from_csv_without_index", "method_params": "DataFrameState", "method_startline": "130", "method_endline": "138", "method_complexity": {"method_NLOC": "9", "method_CCN": "4", "method_NToken": "66", "method_nesting_level": "0"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "51", "deleted_lines": "48,49,50,51", "method_info": {"method_name": "_to_str", "method_params": "v", "method_startline": "48", "method_endline": "51", "method_complexity": {"method_NLOC": "4", "method_CCN": "2", "method_NToken": "17", "method_nesting_level": "0"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "119,120,121,122,123,124,125,126,127", "deleted_lines": "119,120,121,122,123,124,125,126,127", "method_info": {"method_name": "_from_csv_with_index", "method_params": "DataFrameState", "method_startline": "119", "method_endline": "127", "method_complexity": {"method_NLOC": "9", "method_CCN": "4", "method_NToken": "68", "method_nesting_level": "0"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "85,93", "deleted_lines": "85,91", "method_info": {"method_name": "_from_json_index", "method_params": "DataFrameState,dict", "method_startline": "82", "method_endline": "93", "method_complexity": {"method_NLOC": "11", "method_CCN": "6", "method_NToken": "96", "method_nesting_level": "0"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "51,56", "deleted_lines": "48,49,50,51,52,53", "method_info": {"method_name": "_from_json_records", "method_params": "DataFrameState,list", "method_startline": "48", "method_endline": "56", "method_complexity": {"method_NLOC": "8", "method_CCN": "5", "method_NToken": "69", "method_nesting_level": "0"}}}, "hunk_8": {"Ismethod": 1, "added_lines": "61,65", "deleted_lines": "62", "method_info": {"method_name": "_from_json_values", "method_params": "DataFrameState,list", "method_startline": "59", "method_endline": "65", "method_complexity": {"method_NLOC": "6", "method_CCN": "3", "method_NToken": "40", "method_nesting_level": "0"}}}, "hunk_9": {"Ismethod": 1, "added_lines": "113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133", "deleted_lines": "116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,132,133", "method_info": {"method_name": "_csv_split", "method_params": "string,delimiter,maxsplit", "method_startline": "113", "method_endline": "133", "method_complexity": {"method_NLOC": "6", "method_CCN": "3", "method_NToken": "50", "method_nesting_level": "0"}}}, "hunk_10": {"Ismethod": 1, "added_lines": "240,278,279", "deleted_lines": "243,244,245,246,247,248", "method_info": {"method_name": "_dataframe_csv_from_input", "method_params": "tables,content_types,orients", "method_startline": "225", "method_endline": "279", "method_complexity": {"method_NLOC": "48", "method_CCN": "18", "method_NToken": "265", "method_nesting_level": "0"}}}, "hunk_11": {"Ismethod": 1, "added_lines": "136,137,138,139,140,141", "deleted_lines": "138", "method_info": {"method_name": "_csv_unquote", "method_params": "string", "method_startline": "136", "method_endline": "141", "method_complexity": {"method_NLOC": "6", "method_CCN": "3", "method_NToken": "49", "method_nesting_level": "0"}}}, "hunk_12": {"Ismethod": 1, "added_lines": "144,145,146,147,148,149,150,151", "deleted_lines": null, "method_info": {"method_name": "_csv_quote", "method_params": "td", "method_startline": "144", "method_endline": "151", "method_complexity": {"method_NLOC": "8", "method_CCN": "7", "method_NToken": "64", "method_nesting_level": "0"}}}, "hunk_13": {"Ismethod": 1, "added_lines": "117,118,119,120,121,122,123,124,125,126,127,128,129,130", "deleted_lines": "117,118,119,120,121,122,123,124,125,126,127,128,129,130", "method_info": {"method_name": "_csv_split._iter_line", "method_params": "line", "method_startline": "117", "method_endline": "130", "method_complexity": {"method_NLOC": "14", "method_CCN": "7", "method_NToken": "80", "method_nesting_level": "2"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tests\\handlers\\test_dataframe_handler.py", "file_new_name": "tests\\handlers\\test_dataframe_handler.py", "file_complexity": {"file_NLOC": "202", "file_CCN": "31", "file_NToken": "1543"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278", "deleted_lines": null, "method_info": {"method_name": "test_benchmark_load_dataframes", "method_params": "", "method_startline": "257", "method_endline": "278", "method_complexity": {"method_NLOC": "15", "method_CCN": "4", "method_NToken": "134", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "203,204,205,206,207,208,209,210", "deleted_lines": null, "method_info": {"method_name": "test_batch_read_dataframes_from_csv_other_CRLF", "method_params": "df", "method_startline": "203", "method_endline": "210", "method_complexity": {"method_NLOC": "8", "method_CCN": "2", "method_NToken": "76", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "190,191,192,193,194", "method_info": {"method_name": "test_batch_read_dataframes_from_mixed_json_n_csv", "method_params": "df", "method_startline": "172", "method_endline": "200", "method_complexity": {"method_NLOC": "20", "method_CCN": "4", "method_NToken": "174", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "251,252,253,254", "deleted_lines": null, "method_info": {"method_name": "test_guess_orient", "method_params": "df,orient", "method_startline": "251", "method_endline": "254", "method_complexity": {"method_NLOC": "4", "method_CCN": "2", "method_NToken": "36", "method_nesting_level": "0"}}}}}}}}