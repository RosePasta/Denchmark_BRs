{"BR": {"BR_id": "2705", "BR_author": "DoubleVII", "BRopenT": "2020-10-07T08:43:05Z", "BRcloseT": "2020-10-17T16:39:07Z", "BR_text": {"BRsummary": "The registries update forces the \"--remove-bpe\" option to require an argument", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n After the commit <denchmark-link:https://github.com/pytorch/fairseq/commit/5e82514d687289a73a6dec33b555217acd97cb0d>update registries</denchmark-link>\n , the option \"--remove-bpe\" needs an argument to declare the BPE decoder, which can be omitted according to the document. The <denchmark-link:https://github.com/pytorch/fairseq/tree/master/examples/translation>translation examples</denchmark-link>\n  also gives the omitted format.\n Further more, giving the argument 'subword_nmt', which is used to apply BPE at the preprocessing stage of the translation examples, the BLEU socre is still higher than the ture value. I have tried a couple of possible candidates, but they don't work.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n \n Run the given cmd of the translation examples\n \n <denchmark-code>fairseq-generate data-bin/iwslt14.tokenized.de-en \\\n     --path checkpoints/checkpoint_best.pt \\\n     --batch-size 128 --beam 5 --remove-bpe\n </denchmark-code>\n \n \n See error\n \n <denchmark-code>usage: fairseq-generate [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]\n                         [--log-format {json,none,simple,tqdm}]\n                         [--tensorboard-logdir TENSORBOARD_LOGDIR]\n                         [--seed SEED] [--cpu] [--tpu] [--bf16]\n                         [--memory-efficient-bf16] [--fp16]\n                         [--memory-efficient-fp16] [--fp16-no-flatten-grads]\n                         [--fp16-init-scale FP16_INIT_SCALE]\n                         [--fp16-scale-window FP16_SCALE_WINDOW]\n                         [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]\n                         [--min-loss-scale MIN_LOSS_SCALE]\n                         [--threshold-loss-scale THRESHOLD_LOSS_SCALE]\n                         [--user-dir USER_DIR]\n                         [--empty-cache-freq EMPTY_CACHE_FREQ]\n                         [--all-gather-list-size ALL_GATHER_LIST_SIZE]\n                         [--model-parallel-size MODEL_PARALLEL_SIZE]\n                         [--checkpoint-suffix CHECKPOINT_SUFFIX]\n                         [--quantization-config-path QUANTIZATION_CONFIG_PATH]\n                         [--profile]\n                         [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,example_criterion,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,legacy_masked_lm_loss,masked_lm,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]\n                         [--tokenizer {moses,nltk,space}]\n                         [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]\n                         [--optimizer {adadelta,adafactor,adagrad,adam,adamax,lamb,nag,sgd}]\n                         [--lr-scheduler {cosine,fixed,inverse_sqrt,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage}]\n                         [--scoring {sacrebleu,bleu,wer}] [--task TASK]\n                         [--num-workers NUM_WORKERS]\n                         [--skip-invalid-size-inputs-valid-test]\n                         [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]\n                         [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]\n                         [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]\n                         [--dataset-impl {raw,lazy,cached,mmap,fasta}]\n                         [--data-buffer-size DATA_BUFFER_SIZE]\n                         [--train-subset TRAIN_SUBSET]\n                         [--valid-subset VALID_SUBSET]\n                         [--validate-interval VALIDATE_INTERVAL]\n                         [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]\n                         [--validate-after-updates VALIDATE_AFTER_UPDATES]\n                         [--fixed-validation-seed FIXED_VALIDATION_SEED]\n                         [--disable-validation]\n                         [--max-tokens-valid MAX_TOKENS_VALID]\n                         [--batch-size-valid BATCH_SIZE_VALID]\n                         [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]\n                         [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]\n                         [--distributed-world-size DISTRIBUTED_WORLD_SIZE]\n                         [--distributed-rank DISTRIBUTED_RANK]\n                         [--distributed-backend DISTRIBUTED_BACKEND]\n                         [--distributed-init-method DISTRIBUTED_INIT_METHOD]\n                         [--distributed-port DISTRIBUTED_PORT]\n                         [--device-id DEVICE_ID] [--local-rank LOCAL_RANK]\n                         [--distributed-no-spawn]\n                         [--ddp-backend {c10d,no_c10d}]\n                         [--bucket-cap-mb BUCKET_CAP_MB]\n                         [--fix-batches-to-gpus] [--find-unused-parameters]\n                         [--fast-stat-sync] [--broadcast-buffers]\n                         [--distributed-wrapper {DDP,SlowMo}]\n                         [--slowmo-momentum SLOWMO_MOMENTUM]\n                         [--slowmo-algorithm SLOWMO_ALGORITHM]\n                         [--localsgd-frequency LOCALSGD_FREQUENCY]\n                         [--nprocs-per-node NPROCS_PER_NODE]\n                         [--pipeline-model-parallel]\n                         [--pipeline-balance PIPELINE_BALANCE]\n                         [--pipeline-devices PIPELINE_DEVICES]\n                         [--pipeline-chunks PIPELINE_CHUNKS]\n                         [--pipeline-checkpoint {always,never,except_last}]\n                         [--zero-sharding {none,os}] [--path PATH]\n                         [--remove-bpe REMOVE_BPE] [--quiet]\n                         [--model-overrides MODEL_OVERRIDES]\n                         [--results-path RESULTS_PATH] [--beam N] [--nbest N]\n                         [--max-len-a N] [--max-len-b N] [--min-len N]\n                         [--match-source-len] [--no-early-stop]\n                         [--unnormalized] [--no-beamable-mm] [--lenpen LENPEN]\n                         [--unkpen UNKPEN] [--replace-unk [REPLACE_UNK]]\n                         [--sacrebleu] [--score-reference] [--prefix-size PS]\n                         [--no-repeat-ngram-size N] [--sampling]\n                         [--sampling-topk PS] [--sampling-topp PS]\n                         [--constraints [{ordered,unordered}]]\n                         [--temperature N] [--diverse-beam-groups N]\n                         [--diverse-beam-strength N] [--diversity-rate N]\n                         [--print-alignment] [--print-step]\n                         [--iter-decode-eos-penalty N]\n                         [--iter-decode-max-iter N]\n                         [--iter-decode-force-max-iter]\n                         [--iter-decode-with-beam N]\n                         [--iter-decode-with-external-reranker]\n                         [--retain-iter-history] [--retain-dropout]\n                         [--retain-dropout-modules RETAIN_DROPOUT_MODULES [RETAIN_DROPOUT_MODULES ...]]\n                         [--decoding-format {unigram,ensemble,vote,dp,bs}]\n fairseq-generate: error: argument --remove-bpe: expected one argument\n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n No error when the argument is omitted, or correct BLEU socre when the argument is specified.\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n fairseq Version: master\n PyTorch Version: 1.6.0\n OS : Linux or Windows\n How you installed fairseq: source\n Build command you used (if compiling from source): pip install --editable ./\n Python version: 3.6.9\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "DoubleVII", "commentT": "2020-10-10T19:17:34Z", "comment_text": "\n \t\tplease provide \"@@ \" as argument. going forward it will not be possible to have implicit argument values. open to suggestions though. perhaps we can split this argument into \"--post-process\" (which enables \"removing bpe\" and other post processing options) and then \"--bpe-symbol\" for bpe removal, which we can default to \"@@ \"?\n \t\t"}}}, "commit": {"commit_id": "60442af216d551e4afc9d4fab1c056c1051725cc", "commit_author": "alexeib", "commitT": "2020-10-11 19:32:13-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "fairseq\\dataclass\\data_class.py", "file_new_name": "fairseq\\dataclass\\data_class.py", "file_complexity": {"file_NLOC": "672", "file_CCN": "20", "file_NToken": "3560"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "484,485", "deleted_lines": "484"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "fairseq\\dataclass\\utils.py", "file_new_name": "fairseq\\dataclass\\utils.py", "file_complexity": {"file_NLOC": "161", "file_CCN": "36", "file_NToken": "1158"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "96,97", "deleted_lines": null, "method_info": {"method_name": "_get_argparse_const", "method_params": "self,str", "method_startline": "96", "method_endline": "97", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "20", "method_nesting_level": "1"}}}}}}}}