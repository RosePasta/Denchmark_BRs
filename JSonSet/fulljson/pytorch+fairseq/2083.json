{"BR": {"BR_id": "2083", "BR_author": "eshaan-pathak", "BRopenT": "2020-04-30T20:33:44Z", "BRcloseT": "2020-05-11T19:43:25Z", "BR_text": {"BRsummary": "\"argument --distributed-world-size: conflicting option string: --distributed-world-size\" Error", "BRdescription": "\n <denchmark-h:h2>\u2753 Questions and Help</denchmark-h>\n \n <denchmark-h:h3>Before asking:</denchmark-h>\n \n \n search the issues.\n search the docs.\n \n <denchmark-h:h4>What is your question?</denchmark-h>\n \n After training my model, I would like to evaluate it; however, I run into an argument parse error, as seen below. I am using the command lines from <denchmark-link:https://github.com/pytorch/fairseq/blob/master/examples/language_model/README.md>here</denchmark-link>\n  and have slightly modified them where I am using a patience of 3, no-epoch-checkpoints, removed fp16, and distributed-world-size of 1 when training. I also changed the paths to reflect my own directory structure. These are the only changes I have made from the link, and I am sure that they are properly formatted. Any help is appreciated. :)\n <denchmark-h:h4>Code</denchmark-h>\n \n Traceback (most recent call last):\n File \"/home/e/miniconda3/envs/eshaan/bin/fairseq-eval-lm\", line 11, in \n load_entry_point('fairseq', 'console_scripts', 'fairseq-eval-lm')()\n File \"/srv/home/e/eshaan/fairseq/fairseq_cli/eval_lm.py\", line 251, in cli_main\n add_distributed_training_args(parser)\n File \"/srv/home/e/eshaan/fairseq/fairseq/options.py\", line 356, in add_distributed_training_args\n help='total number of GPUs across all nodes (default: all visible GPUs)')\n File \"/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py\", line 1352, in add_argument\n return self._add_action(action)\n File \"/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py\", line 1556, in _add_action\n action = super(_ArgumentGroup, self)._add_action(action)\n File \"/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py\", line 1366, in _add_action\n self._check_conflict(action)\n File \"/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py\", line 1505, in _check_conflict\n conflict_handler(action, confl_optionals)\n File \"/home/e/miniconda3/envs/eshaan/lib/python3.6/argparse.py\", line 1514, in _handle_conflict_error\n raise ArgumentError(action, message % conflict_string)\n argparse.ArgumentError: argument --distributed-world-size: conflicting option string: --distributed-world-size\n <denchmark-h:h4>What have you tried?</denchmark-h>\n \n I have tried retraining my model in case it was an issue with how my checkpoints were stored, despite how the output always said my distributed world size is 1. I have also looked at <denchmark-link:https://github.com/tensorflow/tensorflow/issues/8389>this similar error</denchmark-link>\n  to make sure that no other python processes are running.\n <denchmark-h:h4>What's your environment?</denchmark-h>\n \n \n fairseq Version (e.g., 1.0 or master): 0.9.0\n PyTorch Version (e.g., 1.0): 1.4.0\n OS (e.g., Linux): Ubuntu 16.04.6 LTS (Xenial Xerus)\n How you installed fairseq (pip, source): source\n Build command you used (if compiling from source): pip install -e fairseq/\n Python version: 3.6.10\n CUDA/cuDNN version: CUDA release 10.1, V10.1.243\n GPU models and configuration: NVIDIA GeForce GTX 1080 Ti\n Any other relevant information: Using a miniconda3 environment. There are 8 GPUs on the server that I am SSH'd into, but I am only connected to 1.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "eshaan-pathak", "commentT": "2020-05-02T05:09:33Z", "comment_text": "\n \t\tI encountered this bug as well. Seems like commenting out line 251 (add_distributed_training_args(parser)) in fairseq_cli/eval_lm.py fixes it.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "eshaan-pathak", "commentT": "2020-05-04T16:21:50Z", "comment_text": "\n \t\tFixed by <denchmark-link:https://github.com/pytorch/fairseq/commit/b2ee110c853c5effdd8d21f50a8437485bafb285>b2ee110</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "eshaan-pathak", "commentT": "2020-05-05T21:51:23Z", "comment_text": "\n \t\tHi Myle!\n I think there might still be an issue here. When I run eval_lm with the argument \"--distributed-world-size 1\" it fails:\n File \"eval_lm.py\", line 11, in \n cli_main()\n File \"fairseq_cli/eval_lm.py\", line 252, in cli_main\n distributed_utils.call_main(args, main)\n File \"fairseq/distributed_utils.py\", line 173, in call_main\n main(args, kwargs)\n TypeError: main() takes 1 positional argument but 2 were given\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "eshaan-pathak", "commentT": "2020-05-12T14:19:54Z", "comment_text": "\n \t\tThis should actually be fixed now :)\n \t\t"}}}, "commit": {"commit_id": "6209d7d6b2c41fccb01e00671261be80ba86029a", "commit_author": "Myle Ott", "commitT": "2020-05-11 12:43:14-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "1.0", "commit_Nprams": "0.875"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "fairseq\\data\\language_pair_dataset.py", "file_new_name": "fairseq\\data\\language_pair_dataset.py", "file_complexity": {"file_NLOC": "208", "file_CCN": "39", "file_NToken": "1566"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "168,169", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "fairseq\\distributed_utils.py", "file_new_name": "fairseq\\distributed_utils.py", "file_complexity": {"file_NLOC": "233", "file_CCN": "48", "file_NToken": "1521"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "173", "deleted_lines": "173", "method_info": {"method_name": "call_main", "method_params": "args,main,kwargs", "method_startline": "143", "method_endline": "173", "method_complexity": {"method_NLOC": "27", "method_CCN": "6", "method_NToken": "188", "method_nesting_level": "0"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "fairseq\\models\\transformer.py", "file_new_name": "fairseq\\models\\transformer.py", "file_complexity": {"file_NLOC": "742", "file_CCN": "100", "file_NToken": "4934"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "258", "method_info": {"method_name": "forward", "method_params": "self,src_tokens,src_lengths,prev_output_tokens,None,bool,bool,None,None", "method_startline": "253", "method_endline": "262", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "49", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "385", "method_info": {"method_name": "forward", "method_params": "self,src_tokens,src_lengths,None,bool", "method_startline": "381", "method_endline": "386", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "23", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "fairseq\\modules\\transformer_sentence_encoder.py", "file_new_name": "fairseq\\modules\\transformer_sentence_encoder.py", "file_complexity": {"file_NLOC": "191", "file_CCN": "11", "file_NToken": "1108"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "12,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,234,235,236", "deleted_lines": "146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,231,232,233,234,235,236"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "fairseq\\options.py", "file_new_name": "fairseq\\options.py", "file_complexity": {"file_NLOC": "491", "file_CCN": "30", "file_NToken": "3964"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "353,356,357,359", "deleted_lines": "353,357", "method_info": {"method_name": "add_distributed_training_args", "method_params": "parser", "method_startline": "353", "method_endline": "412", "method_complexity": {"method_NLOC": "51", "method_CCN": "1", "method_NToken": "396", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "353,356,357,359", "deleted_lines": "353,357", "method_info": {"method_name": "add_distributed_training_args", "method_params": "parser,default_world_size", "method_startline": "353", "method_endline": "414", "method_complexity": {"method_NLOC": "53", "method_CCN": "2", "method_NToken": "408", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "48", "deleted_lines": "48", "method_info": {"method_name": "get_eval_lm_parser", "method_params": "default_task", "method_startline": "45", "method_endline": "50", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "37", "method_nesting_level": "0"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "fairseq\\search.py", "file_new_name": "fairseq\\search.py", "file_complexity": {"file_NLOC": "219", "file_CCN": "33", "file_NToken": "1827"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "78,79,80,81", "deleted_lines": "78", "method_info": {"method_name": "step", "method_params": "self,int,lprobs", "method_startline": "55", "method_endline": "83", "method_complexity": {"method_NLOC": "22", "method_CCN": "3", "method_NToken": "175", "method_nesting_level": "1"}}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\test_binaries.py", "file_new_name": "tests\\test_binaries.py", "file_complexity": {"file_NLOC": "1052", "file_CCN": "93", "file_NToken": "5604"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "492,493,494,495,496", "deleted_lines": null, "method_info": {"method_name": "test_fconv_lm", "method_params": "self", "method_startline": "480", "method_endline": "496", "method_complexity": {"method_NLOC": "17", "method_CCN": "1", "method_NToken": "81", "method_nesting_level": "1"}}}}}}}}