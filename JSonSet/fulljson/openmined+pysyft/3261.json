{"BR": {"BR_id": "3261", "BR_author": "AlanAboudib", "BRopenT": "2020-03-27T13:48:18Z", "BRcloseT": "2020-03-31T19:44:14Z", "BR_text": {"BRsummary": "fix_precision() is inplace when applied to a pointer tensor.", "BRdescription": "\n Description of the bug\n The method fix_precision() applied on pointers is 'inplace'. This should not be the case\n In the following code:\n <denchmark-code>a = torch.Tensor([2., 3.]).send(bob)\n a.fix_precision()\n a = a.get()\n print(type(a))\n </denchmark-code>\n \n The variable  a after calling get() is a fixed precision tensor which is a bug, because the original variable a defined as torch.Tensor([2., 3.]) is not a fixed precision tensor.\n However, this bug is not existing in case when  a is not a pointer:\n <denchmark-code>a = torch.Tensor([2., 3.])\n a.fix_precision()\n print(type(a))\n </denchmark-code>\n \n a here is not a fixed precision tensor. which is the desired behavior.\n Desktop:\n \n OS: Archlinux\n Version 0.3.2\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "AlanAboudib", "commentT": "2020-03-27T14:05:30Z", "comment_text": "\n \t\tI can take this!!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "AlanAboudib", "commentT": "2020-03-28T06:50:10Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/AlanAboudib>@AlanAboudib</denchmark-link>\n  <denchmark-link:https://github.com/karlhigley>@karlhigley</denchmark-link>\n  <denchmark-link:https://github.com/LaRiffle>@LaRiffle</denchmark-link>\n  ,\n so if I understand this correctly,\n x = th.Tensor([1.,2.,3.]).send(bob)\n x_fx = x.fix_precision()\n x = x_fx.get()\n x_fx is a PointerTensor and expected behavior is to be a FixedPrecisionTensor with PointerTensor as child?\n Moreover when we .get() the x_fx, it returns FixedPrecisionTensor, which I think is a correct behavior, as we haven't called float_precision yet.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "AlanAboudib", "commentT": "2020-03-28T12:32:45Z", "comment_text": "\n \t\tnot exactly, fix_precision() should be applied anyway on the remote value when called on a pointer (and it works fine)\n the issue is that currently we have this for pointers:\n <denchmark-code>a = torch.Tensor([2., 3.]).send(bob)\n a_fp = a.fix_precision()\n # a_fp is a pointer to a fixed precision, but a is too!\n </denchmark-code>\n \n while for non pointers:\n <denchmark-code>a = torch.Tensor([2., 3.])\n a_fp = a.fix_precision()\n # a_fp is a wrapper onto a fixed precision, but a is not!\n </denchmark-code>\n \n So for pointers, fix_precision behaves as fix_precision_ while it shouldn't\n \t\t"}}}, "commit": {"commit_id": "10374f533f81c11fd2f5f23f63aeabd12849f67a", "commit_author": "Sukhad Joshi", "commitT": "2020-03-31 21:44:13+02:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "syft\\frameworks\\torch\\tensors\\interpreters\\native.py", "file_new_name": "syft\\frameworks\\torch\\tensors\\interpreters\\native.py", "file_complexity": {"file_NLOC": "641", "file_CCN": "142", "file_NToken": "3913"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "816,818,820", "deleted_lines": "816,818,820", "method_info": {"method_name": "fix_prec", "method_params": "self,args,storage,field_type,bool,kwargs", "method_startline": "800", "method_endline": "869", "method_complexity": {"method_NLOC": "49", "method_CCN": "10", "method_NToken": "309", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "test\\torch\\pointers\\test_pointer_tensor.py", "file_new_name": "test\\torch\\pointers\\test_pointer_tensor.py", "file_complexity": {"file_NLOC": "290", "file_CCN": "29", "file_NToken": "2862"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "404,411,412,414,415,416,417,420", "deleted_lines": "410,414", "method_info": {"method_name": "test_fix_prec_on_pointer_tensor", "method_params": "workers", "method_startline": "401", "method_endline": "420", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "93", "method_nesting_level": "0"}}}}}}}}