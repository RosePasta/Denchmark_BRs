{"BR": {"BR_id": "2631", "BR_author": "sanvenDev", "BRopenT": "2019-09-27T10:45:27Z", "BRcloseT": "2020-05-08T01:26:04Z", "BR_text": {"BRsummary": "MPC not working with more than or equal to 3 workers", "BRdescription": "\n I tried training a model using MPC, using 2 workers was successful. (A minor issue I noticed when using refresh() in computing loss, the loss values are good, otherwise it's computes big large values, which is not interpretable, any clue why this happens can be great to my research.)\n Anyways but when using 3 or more workers, I'm facing errors.\n First I got error:\n <denchmark-code>---------------------------------------------------------------------------\n TypeError                                 Traceback (most recent call last)\n <ipython-input-7-902fb9b77716> in <module>\n      12 x = th.tensor([1.1,2.0,3.2,4.0]).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)\n      13 m=th.nn.Linear(4, 1).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)\n ---> 14 o=m(x)\n \n /usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)\n     491             result = self._slow_forward(*input, **kwargs)\n     492         else:\n --> 493             result = self.forward(*input, **kwargs)\n     494         for hook in self._forward_hooks.values():\n     495             hook_result = hook(self, input, result)\n \n /usr/local/lib/python3.7/site-packages/torch/nn/modules/linear.py in forward(self, input)\n      90     @weak_script_method\n      91     def forward(self, input):\n ---> 92         return F.linear(input, self.weight, self.bias)\n      93 \n      94     def extra_repr(self):\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)\n     745                 handle_func_command = TorchTensor.handle_func_command\n     746 \n --> 747             response = handle_func_command(command)\n     748 \n     749             return response\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)\n     310             new_command = (cmd, None, new_args, new_kwargs)\n     311             # Send it to the appropriate class and get the response\n --> 312             response = new_type.handle_func_command(new_command)\n     313             # Put back the wrappers where needed\n     314             response = syft.frameworks.torch.hook_args.hook_response(\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in handle_func_command(cls, command)\n     236             # Try to get recursively the attributes in cmd = \"<attr1>.<attr2>.<attr3>...\"\n     237             cmd = cls.rgetattr(cls, cmd)\n --> 238             return cmd(*args, **kwargs)\n     239         except AttributeError:\n     240             pass\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in linear(*args)\n     201                     Un-hook the function to have its detailed behaviour\n     202                     \"\"\"\n --> 203                     return torch.nn.functional.native_linear(*args)\n     204 \n     205                 module.linear = linear\n \n /usr/local/lib/python3.7/site-packages/torch/nn/functional.py in linear(input, weight, bias)\n    1406         ret = torch.addmm(bias, input, weight.t())\n    1407     else:\n -> 1408         output = input.matmul(weight.t())\n    1409         if bias is not None:\n    1410             output += bias\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in method_with_grad(*args, **kwargs)\n     138                 )\n     139 \n --> 140                 result = getattr(new_self, name)(*new_args, **new_kwargs)\n     141 \n     142                 # Put back SyftTensor on the tensors found in the response\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py in matmul(self, *args, **kwargs)\n     414 \n     415         # Send it to the appropriate class and get the response\n --> 416         response = getattr(new_self, \"matmul\")(*new_args, **new_kwargs)\n     417 \n     418         # Put back SyftTensor on the tensors found in the response\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in matmul(self, other)\n     515             return self._public_mul(other, \"matmul\")\n     516 \n --> 517         return self._private_mul(other, \"matmul\")\n     518 \n     519     def mm(self, *args, **kwargs):\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in _private_mul(self, other, equation)\n     413             raise AttributeError(\"For multiplication a crypto_provider must be passed.\")\n     414 \n --> 415         shares = spdz.spdz_mul(cmd, self, other, self.crypto_provider, self.field)\n     416 \n     417         return shares\n \n /usr/local/lib/python3.7/site-packages/syft/frameworks/torch/crypto/spdz.py in spdz_mul(cmd, x_sh, y_sh, crypto_provider, field)\n      43         j = sy.MultiPointerTensor(children=[j1, j0])\n      44     else:\n ---> 45         j = sy.MultiPointerTensor(children=[j1] + j0.child.values())\n      46 \n      47     delta_b = cmd(delta, b)\n \n TypeError: can only concatenate list (not \"dict_values\") to list\n </denchmark-code>\n \n I tried cloning the repo, fixing this issue by passing  j0.child.values() to list constructor. Then I faced another error:\n <denchmark-code>\n Traceback (most recent call last):\n    <ipython-input-7-902fb9b77716> in <module>\n      o=m(x)\n    File \"/Users/sandeep/syft/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n      result = self.forward(*input, **kwargs)\n    File \"a3.py\", line 31, in forward\n      x=F.relu(self.fc1(x))\n    File \"/Users/sandeep/syft/PySyft/syft/generic/frameworks/hook/hook.py\", line 413, in overloaded_func\n      response = handle_func_command(command)\n    File \"/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\", line 297, in handle_func_command\n      response = new_type.handle_func_command(new_command)\n    File \"/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py\", line 237, in handle_func_command\n      return cmd(*args, **kwargs)\n   File \"/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py\", line 207, in relu\n      return tensor.relu()\n    File \"/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py\", line 141, in method_with_grad\n      result = getattr(new_self, name)(*new_args, **new_kwargs)\n    File \"/Users/sandeep/syft/PySyft/syft/generic/frameworks/hook/hook.py\", line 306, in overloaded_syft_method\n      response = getattr(new_self, attr)(*new_args, **new_kwargs)\n    File \"/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py\", line 793, in relu\n      return securenn.relu(self)\n    File \"/Users/sandeep/syft/PySyft/syft/frameworks/torch/crypto/securenn.py\", line 427, in relu\n      alice, bob = a_sh.locations\n ValueError: too many values to unpack (expected 2)\n </denchmark-code>\n \n To Reproduce\n Run this to reproduce:\n <denchmark-code>def connect_to_workers(n_workers):\n     return [\n         sy.VirtualWorker(hook, id=f\"worker{i+1}\")\n         for i in range(n_workers)\n     ]\n def connect_to_crypto_provider():\n     return sy.VirtualWorker(hook, id=\"crypto_provider\")\n \n workers = connect_to_workers(n_workers=3)\n sw = connect_to_crypto_provider()\n \n x = th.tensor([1.1,2.0,3.2,4.0]).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)\n m=th.nn.Linear(4, 1).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)\n o=m(x)\n </denchmark-code>\n \n Desktop (please complete the following information):\n \n OS: MacOS\n Version 10.14.6\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "sanvenDev", "commentT": "2019-12-04T16:37:23Z", "comment_text": "\n \t\tI'm having the same issue. I know this is a bit old but have you found a solution for this? (Not necessarily using PySyft, but on any Federated Learning solution)\n \t\t"}}}, "commit": {"commit_id": "6a0dc8e4fa9b2dcdb63458df1fdfa3a6f4aa6bbb", "commit_author": "knexator", "commitT": "2020-05-05 14:42:17+02:00", "commit_complexity": {"commit_NLOC": "0.5942028985507246", "commit_CCN": "0.9855072463768116", "commit_Nprams": "0.9855072463768116"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 10, "file_old_name": "syft\\frameworks\\torch\\mpc\\securenn.py", "file_new_name": "syft\\frameworks\\torch\\mpc\\securenn.py", "file_complexity": {"file_NLOC": "334", "file_CCN": "48", "file_NToken": "2880"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "530,535", "deleted_lines": "521,536,537", "method_info": {"method_name": "relu", "method_params": "a_sh", "method_startline": "515", "method_endline": "537", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "61", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "491,496,509", "deleted_lines": "476,497,502", "method_info": {"method_name": "relu_deriv", "method_params": "a_sh", "method_startline": "475", "method_endline": "512", "method_complexity": {"method_NLOC": "17", "method_CCN": "2", "method_NToken": "119", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "153,157", "deleted_lines": "151,155", "method_info": {"method_name": "select_share", "method_params": "alpha_sh,x_sh,y_sh", "method_startline": "136", "method_endline": "168", "method_complexity": {"method_NLOC": "13", "method_CCN": "1", "method_NToken": "83", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "617,625,626,631,646", "deleted_lines": "613,636,647,649", "method_info": {"method_name": "maxpool", "method_params": "x_sh", "method_startline": "600", "method_endline": "652", "method_complexity": {"method_NLOC": "26", "method_CCN": "3", "method_NToken": "216", "method_nesting_level": "0"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "403,404,405,406,407,408,460,461", "deleted_lines": "427,428,458,463", "method_info": {"method_name": "share_convert", "method_params": "a_sh", "method_startline": "368", "method_endline": "472", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "64", "method_nesting_level": "0"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "279,291,292,298,301,303,319,324", "deleted_lines": "277,289,290,296,299,301,317,322", "method_info": {"method_name": "msb", "method_params": "a_sh", "method_startline": "268", "method_endline": "340", "method_complexity": {"method_NLOC": "38", "method_CCN": "3", "method_NToken": "351", "method_nesting_level": "0"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "554,569,570,571", "deleted_lines": "584,592,593", "method_info": {"method_name": "division", "method_params": "x_sh,y_sh,bit_len_max", "method_startline": "542", "method_endline": "597", "method_complexity": {"method_NLOC": "31", "method_CCN": "5", "method_NToken": "242", "method_nesting_level": "0"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "669,677,681,683,690,699", "deleted_lines": "656,665", "method_info": {"method_name": "maxpool_deriv", "method_params": "x_sh", "method_startline": "655", "method_endline": "706", "method_complexity": {"method_NLOC": "29", "method_CCN": "2", "method_NToken": "230", "method_nesting_level": "0"}}}, "hunk_8": {"Ismethod": 1, "added_lines": "177,178,190,199,200,201,204,233", "deleted_lines": "175,176,188,197,198,199,202,231", "method_info": {"method_name": "private_compare", "method_params": "x_bit_sh,r,beta,L", "method_startline": "171", "method_endline": "265", "method_complexity": {"method_NLOC": "39", "method_CCN": "2", "method_NToken": "504", "method_nesting_level": "0"}}}, "hunk_9": {"Ismethod": 1, "added_lines": "757,758,759", "deleted_lines": "723", "method_info": {"method_name": "maxpool2d", "method_params": "a_sh,int,int,int", "method_startline": "709", "method_endline": "764", "method_complexity": {"method_NLOC": "35", "method_CCN": "6", "method_NToken": "380", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "test\\torch\\mpc\\test_multiparty_nn.py", "file_complexity": {"file_NLOC": "138", "file_CCN": "9", "file_NToken": "1170"}}}}}