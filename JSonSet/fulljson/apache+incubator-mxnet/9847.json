{"BR": {"BR_id": "9847", "BR_author": "asitstands", "BRopenT": "2018-02-21T11:54:08Z", "BRcloseT": "2018-02-27T20:06:35Z", "BR_text": {"BRsummary": "Imperative regression output layers are broken", "BRdescription": "\n I tried to implement a simple linear regression with ndarray in imperative style.\n import mxnet as mx\n from mxnet import nd\n \n num_inputs = 3\n num_outputs = 1\n num_examples = 1000\n \n def real_fn(X):\n     return 2 * X[:, 0] - 3.4 * X[:, 1] + 4.2\n \n train_data = nd.random_normal(shape=(num_examples, num_inputs))\n noise = 0.01 * nd.random_normal(shape=(num_examples,))\n train_label = real_fn(train_data) + noise\n \n batch_size = 4\n train_iter = mx.io.NDArrayIter(train_data, train_label, batch_size, shuffle=True, label_name='lin_reg_label')\n \n weight = nd.random_normal(0, 0.01, shape=(num_outputs, num_inputs))\n weight.attach_grad()\n bias = nd.random_normal(0, 0.01, shape=(num_outputs, ))\n bias.attach_grad()\n optimizer = mx.optimizer.SGD(learning_rate=0.1, momentum=0.9)\n optimizer_weight_st = optimizer.create_state(0, weight)\n optimizer_bias_st = optimizer.create_state(0, bias)\n \n for epoch in range(10):\n \ttrain_iter.reset()\n \tfor batch in train_iter: # `batch` is a `DataBatch`\n \t\twith mx.autograd.record():\n \t\t\tfc0 = nd.FullyConnected(data=batch.data[0], weight=weight, bias=bias, num_hidden=num_outputs)\n \t\t\tout = nd.LinearRegressionOutput(data=fc0, label=batch.label[0]) # RMS cost function\n \t\tout.backward()\n \t\toptimizer.update(0, weight, weight.grad, optimizer_weight_st)\n \t\toptimizer.update(0, bias, bias.grad, optimizer_bias_st)\n I got the following error message.\n <denchmark-code>/usr/lib/python3.6/site-packages/mxnet/optimizer.py:136: UserWarning: WARNING: New optimizer mxnet.optimizer.NAG is overriding existing optimizer mxnet.optimizer.NAG\n   Optimizer.opt_registry[name].__name__))\n Traceback (most recent call last):\n   File \"Tmp.py\", line 31, in <module>\n     out = nd.LinearRegressionOutput(data=fc0, label=batch.label[0]) # RMS cost function\n   File \"<string>\", line 52, in LinearRegressionOutput\n   File \"/usr/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\", line 92, in _imperative_invoke\n     ctypes.byref(out_stypes)))\n   File \"/usr/lib/python3.6/site-packages/mxnet/base.py\", line 148, in check_call\n     raise MXNetError(py_str(_LIB.MXGetLastError()))\n mxnet.base.MXNetError: [20:58:23] src/imperative/./imperative_utils.h:123: Check failed: infertype.count(attrs.op) Operator LinearRegressionOutput is missing FInferType attribute\n \n Stack trace returned 10 entries:\n [bt] (0) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x46) [0x7f380a187db6]\n [bt] (1) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x28) [0x7f380a185be8]\n [bt] (2) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::SetShapeType(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, mxnet::DispatchMode*)+0xc2e) [0x7f380b93416e]\n [bt] (3) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x25a) [0x7f380b921cea]\n [bt] (4) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(MXImperativeInvokeImpl(void*, int, void**, int*, void***, int, char const**, char const**)+0x1e4) [0x7f380bd24c44]\n [bt] (5) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x13c) [0x7f380bd2544c]\n [bt] (6) /usr/lib/libffi.so.6(ffi_call_unix64+0x4c) [0x7f3811e561c8]\n [bt] (7) /usr/lib/libffi.so.6(ffi_call+0x32a) [0x7f3811e55c2a]\n [bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f38120b654e]\n [bt] (9) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x11f85) [0x7f38120b6f85]\n </denchmark-code>\n \n I think the point of the error is \"src/imperative/./imperative_utils.h:123: Check failed: infertype.count(attrs.op) Operator LinearRegressionOutput is missing FInferType attribute\".\n I also got the similar errors with LogisticRegressionOutput and MAERegressionOutput. With SoftmaxOutput I get no errors while it is not the regression that I want. The imperative style regression outputs may not be used frequently but anyway they could be useful sometimes and listed in the API document anyway. Please fix them.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "asitstands", "commentT": "2018-02-21T13:31:26Z", "comment_text": "\n \t\tThanks for reporting this issue. I fix it in the PR above. Then your code is ok on my machine.\n By the way, I think mx.nd.waitall() should be in the last line otherwise the computation is not triggered.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "asitstands", "commentT": "2018-02-22T07:47:30Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ZiyueHuang>@ZiyueHuang</denchmark-link>\n  Thanks, the fix works. For the  call, why do we need explicit synchronization here? In my machine the code works without it.\n \t\t"}}}, "commit": {"commit_id": "34af930dcdc6f4b06ebffc07c903696d0092bacb", "commit_author": "Ziyue Huang", "commitT": "2018-02-27 12:06:34-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "src\\operator\\regression_output.cc", "file_new_name": "src\\operator\\regression_output.cc", "file_complexity": {"file_NLOC": "63", "file_CCN": "0", "file_NToken": "98"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "26,27,38,54", "deleted_lines": null}}}}}}