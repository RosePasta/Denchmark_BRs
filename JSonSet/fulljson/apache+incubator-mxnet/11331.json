{"BR": {"BR_id": "11331", "BR_author": "feevos", "BRopenT": "2018-06-19T02:50:10Z", "BRcloseT": "2018-07-19T22:07:56Z", "BR_text": {"BRsummary": "gluon bug: AttributeError: '_thread._local' object has no attribute 'value'", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n Dear all,\n I am trying to run mxnet in a distributed HPC environment for embarrassingly parallel (distributed) runs.\n The goal is to use this for bayesian hyperparameter optimization, therefore all communication between nodes is nothing mxnet/gpu specific (lists of hyperparams, like learning rate, batch size etc). For my distributed needs I chose <denchmark-link:http://ray.readthedocs.io/en/latest/>ray</denchmark-link>\n . Each node has 4 gpus and runs a completely independent run from other nodes. However, I cannot even define a simple gluon layer within\n a  function.\n When I am using 2 (or more) nodes with this trivial example, everything is working:\n import os\n import sys\n import ray\n import time\n \n # mxnet gpu examples \n import mxnet as mx\n from mxnet import nd\n import numpy as np\n \n \n @ray.remote(num_gpus = 4)\n def f():\n \n     gpus = [int(x) for x in os.environ[\"CUDA_VISIBLE_DEVICES\"].split(',')] # In case of multiple GPUs, comment out 2nd option. \n     tctx = [mx.gpu(i) for i in range(len(gpus))]\n     a = nd.random.uniform(shape=[3,4,16,16],ctx=tctx[0])\n \n \n     return a.asnumpy()\n \n if __name__ == '__main__':\n     ray.init( redis_address =  sys.argv[1])\n     result1 = ray.get(f.remote())\n     result2 = ray.get(f.remote())\n \n     print (result1,result2)\n However, when I try to use any gluon object that derives from HybridBlock, for example:\n @ray.remote(num_gpus=4)\n def f(x):\n     loss = gluon.loss.L2Loss()\n     return x\n I get an error. I've also tested ray with a simple pytorch nn (everything is working), so this is most probably a mxnet/gluon  problem.\n : The same problem and error message appears if I use <denchmark-link:http://distributed.readthedocs.io/en/latest/>dask.distributed</denchmark-link>\n  for launching/managing the cluster.\n <denchmark-h:h2>Environment info (Required)</denchmark-h>\n \n All nodes are identical, I've run diagnose.py command on an interactive node with 4 gpus allocated\n ----------Python Info----------\n Version      : 3.6.4\n Compiler     : GCC 7.2.0\n Build        : ('default', 'Jan 16 2018 18:10:19')\n Arch         : ('64bit', '')\n ------------Pip Info-----------\n Version      : 9.0.1\n Directory    : /home/dia021/Software/anaconda3/lib/python3.6/site-packages/pip\n ----------MXNet Info-----------\n /home/dia021/Software/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n   from ._conv import register_converters as _register_converters\n Version      : 1.3.0\n Directory    : /home/dia021/Software/mxnet\n Commit Hash   : 0910450110c37da9f052f3b29c40c6d051f46a6a\n ----------System Info----------\n Platform     : Linux-4.4.114-94.11-default-x86_64-with-SuSE-12-x86_64\n system       : Linux\n node         : b050\n release      : 4.4.114-94.11-default\n version      : #1 SMP Thu Feb 1 19:28:26 UTC 2018 (4309ff9)\n ----------Hardware Info----------\n machine      : x86_64\n processor    : x86_64\n Architecture:          x86_64\n CPU op-mode(s):        32-bit, 64-bit\n Byte Order:            Little Endian\n CPU(s):                56\n On-line CPU(s) list:   0-27\n Off-line CPU(s) list:  28-55\n Thread(s) per core:    1\n Core(s) per socket:    14\n Socket(s):             2\n NUMA node(s):          2\n Vendor ID:             GenuineIntel\n CPU family:            6\n Model:                 79\n Model name:            Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz\n Stepping:              1\n CPU MHz:               2599.787\n BogoMIPS:              5199.57\n Virtualization:        VT-x\n L1d cache:             32K\n L1i cache:             32K\n L2 cache:              256K\n L3 cache:              35840K\n NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,20,22,24,26\n NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,21,23,25,27\n Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch ida arat epb invpcid_single pln pts dtherm intel_pt spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx xsaveopt cqm_llc cqm_occup_llc\n ----------Network Test----------\n Setting timeout: 10\n Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0035 sec, LOAD: 1.1334 sec.\n Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0084 sec, LOAD: 0.9156 sec.\n Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.2081 sec, LOAD: 0.0405 sec.\n Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.2181 sec, LOAD: 0.2282 sec.\n Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0068 sec, LOAD: 0.5931 sec.\n Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0075 sec, LOAD: 0.0752 sec.\n nvidia-smi\n +-----------------------------------------------------------------------------+\n | NVIDIA-SMI 390.30                 Driver Version: 390.30                    |\n |-------------------------------+----------------------+----------------------+\n | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n |===============================+======================+======================|\n |   0  Tesla P100-SXM2...  Off  | 00000000:04:00.0 Off |                    0 |\n | N/A   31C    P0    32W / 300W |      0MiB / 16280MiB |      0%      Default |\n +-------------------------------+----------------------+----------------------+\n |   1  Tesla P100-SXM2...  Off  | 00000000:06:00.0 Off |                    0 |\n | N/A   29C    P0    32W / 300W |      0MiB / 16280MiB |      0%      Default |\n +-------------------------------+----------------------+----------------------+\n |   2  Tesla P100-SXM2...  Off  | 00000000:07:00.0 Off |                    0 |\n | N/A   30C    P0    31W / 300W |      0MiB / 16280MiB |      0%      Default |\n +-------------------------------+----------------------+----------------------+\n |   3  Tesla P100-SXM2...  Off  | 00000000:08:00.0 Off |                    0 |\n | N/A   32C    P0    29W / 300W |      0MiB / 16280MiB |      0%      Default |\n +-------------------------------+----------------------+----------------------+\n <denchmark-h:h2>Error Message:</denchmark-h>\n \n Traceback (most recent call last):\n   File \"test_ray.py\", line 75, in <module>\n     x1 = ray.get(feature1_id)\n   File \"/home/dia021/Software/anaconda3/lib/python3.6/site-packages/ray/worker.py\", line 2321, in get\n     raise RayGetError(object_ids, value)\n ray.worker.RayGetError: Could not get objectid ObjectID(250d79352e7800faddddf2c11ec6fd6ea65c20b8). It was created by remote function __main__.f which failed with:\n \n Remote function __main__.f failed with:\n \n Traceback (most recent call last):\n   File \"test_ray.py\", line 30, in f\n     loss = gluon.loss.L2Loss()\n   File \"/home/dia021/Software/mxnet/gluon/loss.py\", line 129, in __init__\n     super(L2Loss, self).__init__(weight, batch_axis, **kwargs)\n   File \"/home/dia021/Software/mxnet/gluon/loss.py\", line 77, in __init__\n     super(Loss, self).__init__(**kwargs)\n   File \"/home/dia021/Software/mxnet/gluon/block.py\", line 693, in __init__\n     super(HybridBlock, self).__init__(prefix=prefix, params=params)\n   File \"/home/dia021/Software/mxnet/gluon/block.py\", line 172, in __init__\n     self._prefix, self._params = _BlockScope.create(prefix, params, self._alias())\n   File \"/home/dia021/Software/mxnet/gluon/block.py\", line 53, in create\n     prefix = _name.NameManager._current.value.get(None, hint) + '_'\n AttributeError: '_thread._local' object has no attribute 'value'\n \n Remote function __main__.f failed with:\n \n Traceback (most recent call last):\n   File \"test_ray.py\", line 30, in f\n     loss = gluon.loss.L2Loss()\n   File \"/home/dia021/Software/mxnet/gluon/loss.py\", line 129, in __init__\n     super(L2Loss, self).__init__(weight, batch_axis, **kwargs)\n   File \"/home/dia021/Software/mxnet/gluon/loss.py\", line 77, in __init__\n     super(Loss, self).__init__(**kwargs)\n   File \"/home/dia021/Software/mxnet/gluon/block.py\", line 693, in __init__\n     super(HybridBlock, self).__init__(prefix=prefix, params=params)\n   File \"/home/dia021/Software/mxnet/gluon/block.py\", line 172, in __init__\n     self._prefix, self._params = _BlockScope.create(prefix, params, self._alias())\n   File \"/home/dia021/Software/mxnet/gluon/block.py\", line 53, in create\n     prefix = _name.NameManager._current.value.get(None, hint) + '_'\n AttributeError: '_thread._local' object has no attribute 'value'\n \n \n   You can inspect errors by running\n \n       ray.error_info()\n \n   If this driver is hanging, start a new one with\n \n       ray.init(redis_address=\"10.141.1.77:6379\")\n <denchmark-h:h2>Minimum reproducible example</denchmark-h>\n \n This is a python file. I needs to be executed after the ray cluster has initiated with (in SLURM environment) srun python name_of_file.py\n # Distributed stuff \n import ray\n \n #mxnet \n from mxnet import gluon\n \n # A trivial function to reproduce the example \n @ray.remote(num_gpus=4)\n def f(x):\n     loss = gluon.loss.L2Loss()\n     return x;\n \n \n if __name__ == '__main__':\n     # here sys.argv[1] is the redis_address after the initiation of the ray cluster \n     ray.init( redis_address =  sys.argv[1]  )\n \n     feature1_id = f.remote(0)\n     x1 = ray.get(feature1_id)\n \n     print (x1)\n If you could please provide any hack-around/advice, most appreciated. This is also linked to this <denchmark-link:https://github.com/dmlc/gluon-cv/issues/156>gluon-cv issue</denchmark-link>\n \n Thank you very much\n Foivos\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "feevos", "commentT": "2018-06-19T03:37:26Z", "comment_text": "\n \t\tDear all, <denchmark-link:https://github.com/ThomasDelteil>@ThomasDelteil</denchmark-link>\n   solved the problem <denchmark-link:https://discuss.mxnet.io/t/gluon-with-ray-and-dask-distributed-problem/1235/2>here</denchmark-link>\n   I am leaving this open until one of the developers decides to close it.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "feevos", "commentT": "2018-06-19T04:04:17Z", "comment_text": "\n \t\tThe problem persists if I use a more complex layer. When I test with a trivial network:\n @ray.remote(num_gpus=4)\n def f(x):\n \n \n \n     mynet = gluon.nn.HybridSequential(prefix = \"test\")\n     with mynet.name_scope():\n         mynet.add(gluon.nn.Conv2D(32,kernel_size=3),prefix=\"test\")\n     # \"\"\"\n     #loss = gluon.loss.L2Loss(prefix=\"test\")\n     return x;\n I get a very similar error:\n Remote function __main__.f failed with:\n \n Traceback (most recent call last):\n   File \"test_ray.py\", line 26, in f\n     mynet.add(gluon.nn.Conv2D(32,kernel_size=3),prefix=\"test\")\n   File \"/home/dia021/Software/mxnet/gluon/nn/conv_layers.py\", line 319, in __init__\n     in_channels, activation, use_bias, weight_initializer, bias_initializer, **kwargs)\n   File \"/home/dia021/Software/mxnet/gluon/nn/conv_layers.py\", line 115, in __init__\n     wshapes = _infer_weight_shape(op_name, dshape, self._kwargs)\n   File \"/home/dia021/Software/mxnet/gluon/nn/conv_layers.py\", line 37, in _infer_weight_shape\n     sym = op(symbol.var('data', shape=data_shape), **kwargs)\n   File \"/home/dia021/Software/mxnet/symbol/symbol.py\", line 2454, in var\n     attr = AttrScope._current.value.get(attr)\n AttributeError: '_thread._local' object has no attribute 'value'\n \n \n   You can inspect errors by running\n \n       ray.error_info()\n \n   If this driver is hanging, start a new one with\n \n       ray.init(redis_address=\"10.141.1.67:6379\")\n   \n Traceback (most recent call last):\n   File \"test_ray.py\", line 75, in <module>\n     x1 = ray.get(feature1_id)\n   File \"/home/dia021/Software/anaconda3/lib/python3.6/site-packages/ray/worker.py\", line 2321, in get\n     raise RayGetError(object_ids, value)\n ray.worker.RayGetError: Could not get objectid ObjectID(2a767168ffefb71fa84318c5f8e7e15918dcce35). It was created by remote function __main__.f which failed with:\n \n Remote function __main__.f failed with:\n \n Traceback (most recent call last):\n   File \"test_ray.py\", line 26, in f\n     mynet.add(gluon.nn.Conv2D(32,kernel_size=3),prefix=\"test\")\n   File \"/home/dia021/Software/mxnet/gluon/nn/conv_layers.py\", line 319, in __init__\n     in_channels, activation, use_bias, weight_initializer, bias_initializer, **kwargs)\n   File \"/home/dia021/Software/mxnet/gluon/nn/conv_layers.py\", line 115, in __init__\n     wshapes = _infer_weight_shape(op_name, dshape, self._kwargs)\n   File \"/home/dia021/Software/mxnet/gluon/nn/conv_layers.py\", line 37, in _infer_weight_shape\n     sym = op(symbol.var('data', shape=data_shape), **kwargs)\n   File \"/home/dia021/Software/mxnet/symbol/symbol.py\", line 2454, in var\n     attr = AttrScope._current.value.get(attr)\n AttributeError: '_thread._local' object has no attribute 'value'\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "feevos", "commentT": "2018-06-19T06:27:48Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/feevos>@feevos</denchmark-link>\n  it might be worth seeing if you can reproduce the issue without Ray. One thing to try would be pickling  (e.g., using ), then unpickling it (in a different Python interpreter), and then executing the unpickled version.\n EDIT: Oh, I see that it's already solved.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "feevos", "commentT": "2018-07-19T21:17:01Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/sandeep-krishnamurthy>@sandeep-krishnamurthy</denchmark-link>\n  This issue has been resolved. Please close it. Thanks\n \t\t"}}}, "commit": {"commit_id": "579e376edd461484a10bb93444e07e29df762208", "commit_author": "Thomas Delteil", "commitT": "2018-06-22 15:59:03-07:00", "commit_complexity": {"commit_NLOC": "0.7368421052631579", "commit_CCN": "0.7368421052631579", "commit_Nprams": "0.7368421052631579"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\mxnet\\gluon\\block.py", "file_new_name": "python\\mxnet\\gluon\\block.py", "file_complexity": {"file_NLOC": "741", "file_CCN": "192", "file_NToken": "4746"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "53,54", "deleted_lines": null, "method_info": {"method_name": "create", "method_params": "prefix,params,hint", "method_startline": "48", "method_endline": "71", "method_complexity": {"method_NLOC": "22", "method_CCN": "7", "method_NToken": "187", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\mxnet\\symbol\\register.py", "file_new_name": "python\\mxnet\\symbol\\register.py", "file_complexity": {"file_NLOC": "171", "file_CCN": "22", "file_NToken": "809"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "116,117,120,121,148,149,181,182", "deleted_lines": null, "method_info": {"method_name": "_generate_symbol_function_code", "method_params": "handle,name,func_name,signature_only", "method_startline": "34", "method_endline": "195", "method_complexity": {"method_NLOC": "150", "method_CCN": "21", "method_NToken": "682", "method_nesting_level": "0"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\mxnet\\symbol\\symbol.py", "file_new_name": "python\\mxnet\\symbol\\symbol.py", "file_complexity": {"file_NLOC": "1041", "file_CCN": "311", "file_NToken": "9202"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2454,2455", "deleted_lines": null}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tests\\python\\unittest\\test_thread_local.py", "file_new_name": "tests\\python\\unittest\\test_thread_local.py", "file_complexity": {"file_NLOC": "140", "file_CCN": "20", "file_NToken": "1010"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "139,140,141,142,143,144", "deleted_lines": null, "method_info": {"method_name": "test_createblock.f", "method_params": "", "method_startline": "139", "method_endline": "144", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "51", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "137,138,139,140,141,142,143,144,145,146,147,148,149", "deleted_lines": null, "method_info": {"method_name": "test_createblock", "method_params": "", "method_startline": "137", "method_endline": "149", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "38", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "153,154,155,156,157,158,159,160", "deleted_lines": null, "method_info": {"method_name": "test_symbol.f", "method_params": "", "method_startline": "153", "method_endline": "160", "method_complexity": {"method_NLOC": "8", "method_CCN": "1", "method_NToken": "91", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "151,152,153,154,155,156,157,158,159,160,161,162,163,164", "deleted_lines": null, "method_info": {"method_name": "test_symbol", "method_params": "", "method_startline": "151", "method_endline": "164", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "38", "method_nesting_level": "0"}}}}}}}}