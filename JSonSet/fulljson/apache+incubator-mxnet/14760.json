{"BR": {"BR_id": "14760", "BR_author": "nswamy", "BRopenT": "2019-04-22T07:01:30Z", "BRcloseT": "2019-05-22T18:54:21Z", "BR_text": {"BRsummary": "upcasting accumulation type in norm increases loss/Perplexity", "BRdescription": "\n While fixing an issue described <denchmark-link:https://github.com/apache/incubator-mxnet/issues/14722>here</denchmark-link>\n .\n I applied the changes from master and found that the change from <denchmark-link:https://github.com/apache/incubator-mxnet/pull/14616>#14616</denchmark-link>\n  follows the same pattern as the softmax change in <denchmark-link:https://github.com/apache/incubator-mxnet/pull/14098>#14098</denchmark-link>\n  and increases the loss and hence perpelity from 126.66 to 135, without this change and the fix to softmax <denchmark-link:https://github.com/apache/incubator-mxnet/pull/14759>#14759</denchmark-link>\n , validation perplexity comes back to 126.66\n Details on how to test are provided in <denchmark-link:https://github.com/apache/incubator-mxnet/issues/14722>#14722</denchmark-link>\n \n <denchmark-link:https://github.com/haojin2>@haojin2</denchmark-link>\n  <denchmark-link:https://github.com/eric-haibin-lin>@eric-haibin-lin</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "nswamy", "commentT": "2019-04-22T16:59:24Z", "comment_text": "\n \t\tBackward incompatibility is a concern. What about adding env var like MXNET_ENFORCE_SAFE_ACCUMULATION = 1 to trigger safe accumulation with higher precision on existing ops?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "nswamy", "commentT": "2019-04-22T17:15:23Z", "comment_text": "\n \t\tIf we have to do this for many operators it makes sense to control through a environment variable like you are suggesting. how many operators need this change?\n What i am puzzled about is why the loss goes up when the accumulation precision is increased.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "nswamy", "commentT": "2019-04-22T17:54:00Z", "comment_text": "\n \t\tWe need this for softmax, log_softmax, norm and layernorm (coming soon).\n <denchmark-link:https://github.com/szha>@szha</denchmark-link>\n  <denchmark-link:https://github.com/ptrendx>@ptrendx</denchmark-link>\n  what do you guys think is the best way to handle this?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "nswamy", "commentT": "2019-04-23T00:38:56Z", "comment_text": "\n \t\tCan we avoid adding another env variable ? We can accumulate only when dtype is set otherwise use the default behavior before this change was added. Also I understand FP16 inputs with accumulation in FP32 for softmax but does this also apply to FP32 inputs with accumulation in FP64. Will there be no accuracy loss ?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "nswamy", "commentT": "2019-05-22T18:54:21Z", "comment_text": "\n \t\tShould be fixed in <denchmark-link:https://github.com/apache/incubator-mxnet/pull/14830>#14830</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "5aa62d8ae2022646957dc9808deb650621125d5d", "commit_author": "Hao Jin", "commitT": "2019-05-17 13:48:19-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.5"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ci\\windows\\test_py2_cpu.ps1", "file_new_name": "ci\\windows\\test_py2_cpu.ps1", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "30,31,32,33", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ci\\windows\\test_py2_gpu.ps1", "file_new_name": "ci\\windows\\test_py2_gpu.ps1", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "34,35,36,37", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ci\\windows\\test_py3_cpu.ps1", "file_new_name": "ci\\windows\\test_py3_cpu.ps1", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "30,31,32,33", "deleted_lines": null}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ci\\windows\\test_py3_gpu.ps1", "file_new_name": "ci\\windows\\test_py3_gpu.ps1", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "34,35,36,37", "deleted_lines": null}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "docs\\faq\\env_var.md", "file_new_name": "docs\\faq\\env_var.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "283,284,285,286,287,288,289,290", "deleted_lines": null}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\operator\\tensor\\broadcast_reduce_op.h", "file_new_name": "src\\operator\\tensor\\broadcast_reduce_op.h", "file_complexity": {"file_NLOC": "1311", "file_CCN": "237", "file_NToken": "12125"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1186,1188,1189,1190,1191,1192,1194,1196,1197,1199,1200,1201,1202", "deleted_lines": "1187,1190", "method_info": {"method_name": "mxnet::op::LpNormCompute", "method_params": "attrs,ctx,inputs,req,outputs", "method_startline": "1171", "method_endline": "1204", "method_complexity": {"method_NLOC": "32", "method_CCN": "8", "method_NToken": "302", "method_nesting_level": "2"}}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\python\\unittest\\test_operator.py", "file_new_name": "tests\\python\\unittest\\test_operator.py", "file_complexity": {"file_NLOC": "6898", "file_CCN": "1146", "file_NToken": "85958"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "3485,3486,3488,3489,3490,3491,3492,3493,3494,3495,3496,3497,3498,3499,3500,3501,3502,3503,3504,3505,3506,3507,3508,3509,3511,3512,3513,3514,3515,3517,3518,3519,3524,3525,3526,3527,3528,3529,3530,3531,3532,3533,3534,3535,3536,3537,3538,3539", "deleted_lines": "3486,3487,3488,3489,3490,3491,3492,3493,3494,3495,3496,3497,3498,3499,3500,3501,3502,3503,3504,3505,3506,3507,3508,3509,3510,3511,3512,3513,3514,3515,3516,3518,3519,3520,3521,3522,3524,3525", "method_info": {"method_name": "test_norm", "method_params": "", "method_startline": "3462", "method_endline": "3539", "method_complexity": {"method_NLOC": "70", "method_CCN": "29", "method_NToken": "815", "method_nesting_level": "0"}}}}}}}}