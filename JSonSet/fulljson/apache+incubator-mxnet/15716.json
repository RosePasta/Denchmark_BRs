{"BR": {"BR_id": "15716", "BR_author": "fierceX", "BRopenT": "2019-08-01T02:26:42Z", "BRcloseT": "2019-08-15T04:56:45Z", "BR_text": {"BRsummary": "Increase amp support for Bi-lstm and Concat operators in gluon", "BRdescription": "\n Now amp does not support the bi-lstm and concat operators in gluon. I am getting the following error in converting a network with bi-lstm:\n <denchmark-code>Traceback (most recent call last):\n   File \"predict.py\", line 60, in <module>\n     net = amp.convert_hybrid_block(model)\n   File \"/home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/contrib/amp/amp.py\", line 636, in convert_hybrid_block\n     cast_optional_params=cast_optional_params)\n   File \"/home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/contrib/amp/amp.py\", line 505, in convert_symbol\n     keys))\n   File \"/home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/base.py\", line 253, in check_call\n     raise MXNetError(py_str(_LIB.MXGetLastError()))\n mxnet.base.MXNetError: Error in operator lstm0__rnn_param_concat0: [09:35:15] src/operator/nn/concat.cc:158: Not enough information to infer type in Concat.\n Stack trace:\n   [bt] (0) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4ee77b) [0x7f213625c77b]\n   [bt] (1) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x8ff5d0) [0x7f213666d5d0]\n   [bt] (2) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x297275e) [0x7f21386e075e]\n   [bt] (3) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x297bafe) [0x7f21386e9afe]\n   [bt] (4) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x297c54a) [0x7f21386ea54a]\n   [bt] (5) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/libmxnet.so(MXReducePrecisionSymbol+0x1610) [0x7f213864e600]\n   [bt] (6) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f21bc290ec0]\n   [bt] (7) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f21bc29087d]\n   [bt] (8) /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f21c3dfeede]\n </denchmark-code>\n \n Hardware and version information:\n <denchmark-code>Architecture:          x86_64\n CPU op-mode(s):        32-bit, 64-bit\n Byte Order:            Little Endian\n CPU(s):                32\n On-line CPU(s) list:   0-31\n Thread(s) per core:    2\n Core(s) per socket:    16\n Socket(s):             1\n NUMA node(s):          1\n Vendor ID:             GenuineIntel\n CPU family:            6\n Model:                 85\n Model name:            Intel(R) Xeon(R) Gold 6151 CPU @ 3.00GHz\n Stepping:              4\n CPU MHz:               3000.000\n BogoMIPS:              6000.00\n Hypervisor vendor:     KVM\n Virtualization type:   full\n L1d cache:             32K\n L1i cache:             32K\n L2 cache:              1024K\n L3 cache:              25344K\n NUMA node0 CPU(s):     0-31\n Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 arat spec_ctrl intel_stibp flush_l1d\n ----------Python Info----------\n Version      : 3.6.9\n Compiler     : GCC 7.3.0\n Build        : ('default', 'Jul 30 2019 19:07:31')\n Arch         : ('64bit', '')\n ------------Pip Info-----------\n Version      : 19.1.1\n Directory    : /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/pip\n ----------MXNet Info-----------\n Version      : 1.6.0\n Directory    : /home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet\n Commit Hash   : 0f28f5b827c718dcab7bbf2617e16a59ad3f601c\n Library      : ['/home/tiger/anaconda3/envs/mx1.6/lib/python3.6/site-packages/mxnet/libmxnet.so']\n Build features:\n \u2714 CUDA\n \u2714 CUDNN\n \u2714 NCCL\n \u2714 CUDA_RTC\n \u2716 TENSORRT\n \u2714 CPU_SSE\n \u2714 CPU_SSE2\n \u2714 CPU_SSE3\n \u2714 CPU_SSE4_1\n \u2714 CPU_SSE4_2\n \u2716 CPU_SSE4A\n \u2714 CPU_AVX\n \u2716 CPU_AVX2\n \u2714 OPENMP\n \u2716 SSE\n \u2714 F16C\n \u2716 JEMALLOC\n \u2714 BLAS_OPEN\n \u2716 BLAS_ATLAS\n \u2716 BLAS_MKL\n \u2716 BLAS_APPLE\n \u2714 LAPACK\n \u2716 MKLDNN\n \u2714 OPENCV\n \u2716 CAFFE\n \u2716 PROFILER\n \u2714 DIST_KVSTORE\n \u2716 CXX14\n \u2716 INT64_TENSOR_SIZE\n \u2714 SIGNAL_HANDLER\n \u2716 DEBUG\n \u2716 TVM_OP\n ----------System Info----------\n Platform     : Linux-3.10.0-862.14.4.el7.x86_64-x86_64-with-centos-7.5.1804-Core\n system       : Linux\n node         : dp-prod-dc3-gpu01\n release      : 3.10.0-862.14.4.el7.x86_64\n version      : #1 SMP Wed Sep 26 15:12:11 UTC 2018\n ----------Hardware Info----------\n machine      : x86_64\n processor    : x86_64\n ----------Network Test----------\n Setting timeout: 10\n Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0033 sec, LOAD: 0.9312 sec.\n Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0025 sec, LOAD: 1.1405 sec.\n Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 2.9024 sec, LOAD: 2.5129 sec.\n Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 1.4263 sec, LOAD: 5.9768 sec.\n Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.1766 sec, LOAD: 5.7293 sec.\n Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 1.0143 sec, LOAD: 0.8343 sec.\n </denchmark-code>\n \n The mxnet version is:mxnet-cu100==1.6.0b20190730\uff0cGPU is NVIDIA V100 16G.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "fierceX", "commentT": "2019-08-01T20:17:26Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/fierceX>@fierceX</denchmark-link>\n , do you have any small example that shows this problem? I will look into it.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "fierceX", "commentT": "2019-08-01T23:27:31Z", "comment_text": "\n \t\tThere seem to be 2 problems here. On 1 hand, the ConcatType function seems to be too strict in what it thinks it needs to be correct (and so that error should not be there in the first place as type could be inferred during later stage of InferType pass) - I will make a PR fixing that tomorrow. On the other hand, I don't quite see how you could end up with this situation by just adding AMP so again, a small example would be really nice.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "fierceX", "commentT": "2019-08-01T23:30:34Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/mxnet-label-bot>@mxnet-label-bot</denchmark-link>\n  add [Pending Requester Info]\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "fierceX", "commentT": "2019-08-02T02:17:44Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/ptrendx>@ptrendx</denchmark-link>\n  ,The following code should be able to reproduce this error.\n import mxnet as mx\n from mxnet import nd\n from mxnet.gluon import nn,rnn\n from mxnet.contrib import amp\n \n model = nn.HybridSequential()\n model.add(rnn.LSTM(hidden_size=10,num_layers=2,bidirectional=True))\n model.add(nn.Dense(2))\n \n model.initialize()\n model.hybridize()\n model(nd.ones((2,3,4)))\n \n new_model = amp.convert_hybrid_block(model)\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "fierceX", "commentT": "2019-08-02T15:45:24Z", "comment_text": "\n \t\tThanks! I will look into this.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "fierceX", "commentT": "2019-08-02T22:06:27Z", "comment_text": "\n \t\tthanks <denchmark-link:https://github.com/ptrendx>@ptrendx</denchmark-link>\n  for looking at this. let me know if I can help here.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "fierceX", "commentT": "2019-08-05T17:35:56Z", "comment_text": "\n \t\tOk, so after applying PR <denchmark-link:https://github.com/apache/incubator-mxnet/pull/15740>#15740</denchmark-link>\n  I can successfully run the example when using :\n <denchmark-code>import mxnet as mx\n from mxnet import nd\n from mxnet.gluon import nn,rnn\n from mxnet.contrib import amp\n \n amp.init()\n \n model = nn.HybridSequential()\n model.add(rnn.LSTM(hidden_size=10,num_layers=2,bidirectional=True))\n model.add(nn.Dense(2))\n \n model.initialize(ctx=mx.gpu(0))\n model.hybridize()\n model(nd.ones((2,3,4), ctx=mx.gpu(0)))\n \n # new_model = amp.convert_hybrid_block(model)\n </denchmark-code>\n \n while the  still fails with the same error in concat - <denchmark-link:https://github.com/anirudh2290>@anirudh2290</denchmark-link>\n , could you take a look at this?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "fierceX", "commentT": "2019-08-05T18:32:21Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ptrendx>@ptrendx</denchmark-link>\n  will take a look.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "fierceX", "commentT": "2019-08-09T19:35:36Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ptrendx>@ptrendx</denchmark-link>\n  <denchmark-link:https://github.com/fierceX>@fierceX</denchmark-link>\n  I have added a fix in <denchmark-link:https://github.com/apache/incubator-mxnet/pull/15829>#15829</denchmark-link>\n . Please help review.\n \t\t"}}}, "commit": {"commit_id": "40593c6f6c20baed98a914d14987db5438c0a5a5", "commit_author": "Anirudh Subramanian", "commitT": "2019-08-14 21:56:44-07:00", "commit_complexity": {"commit_NLOC": "0.5238095238095238", "commit_CCN": "0.5238095238095238", "commit_Nprams": "0.5238095238095238"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\operator\\nn\\concat.cc", "file_new_name": "src\\operator\\nn\\concat.cc", "file_complexity": {"file_NLOC": "314", "file_CCN": "75", "file_NToken": "2533"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "147,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180", "deleted_lines": "157,158,159,160,161,163,164,165,166,167", "method_info": {"method_name": "mxnet::op::ConcatType", "method_params": "attrs,in_type,out_type", "method_startline": "141", "method_endline": "182", "method_complexity": {"method_NLOC": "35", "method_CCN": "13", "method_NToken": "309", "method_nesting_level": "2"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\python\\gpu\\test_contrib_amp.py", "file_new_name": "tests\\python\\gpu\\test_contrib_amp.py", "file_complexity": {"file_NLOC": "342", "file_CCN": "28", "file_NToken": "3925"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "311,312,313,314,315,316,317,318,319,320,321", "deleted_lines": null, "method_info": {"method_name": "test_amp_conversion_rnn", "method_params": "", "method_startline": "311", "method_endline": "321", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "142", "method_nesting_level": "0"}}}}}}}}