{"BR": {"BR_id": "9094", "BR_author": "roaur", "BRopenT": "2017-12-15T21:14:27Z", "BRcloseT": "2019-07-17T19:59:45Z", "BR_text": {"BRsummary": "Cannot continue with MXNet Tutorial: Real-time Object Detection with MXNet On The Raspberry Pi", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n Cannot continue in MXNet Raspberry Pi tutorial (<denchmark-link:https://mxnet.incubator.apache.org/tutorials/embedded/wine_detector.html>https://mxnet.incubator.apache.org/tutorials/embedded/wine_detector.html</denchmark-link>\n ) after running  in Python interpreter. Error describes the following: \n <denchmark-h:h2>Environment info (Required)</denchmark-h>\n \n <denchmark-code>----------Python Info----------\n Version      : 3.5.3\n Compiler     : GCC 6.3.0 20170124\n Build        : ('default', 'Jan 19 2017 14:11:04')\n Arch         : ('32bit', 'ELF')\n ------------Pip Info-----------\n Version      : 9.0.1\n Directory    : /usr/lib/python3/dist-packages/pip\n ----------MXNet Info-----------\n Version      : 1.0.0\n Directory    : /home/pi/git/mxnet/python/mxnet\n Hashtag not found. Not installed from pre-built package.\n ----------System Info----------\n Platform     : Linux-4.9.59-v7+-armv7l-with-debian-9.1\n system       : Linux\n node         : raspberrypi\n release      : 4.9.59-v7+\n version      : #1047 SMP Sun Oct 29 12:19:23 GMT 2017\n ----------Hardware Info----------\n machine      : armv7l\n processor    :\n Architecture:          armv7l\n Byte Order:            Little Endian\n CPU(s):                4\n On-line CPU(s) list:   0-3\n Thread(s) per core:    1\n Core(s) per socket:    4\n Socket(s):             1\n Model:                 4\n Model name:            ARMv7 Processor rev 4 (v7l)\n CPU max MHz:           1200.0000\n CPU min MHz:           600.0000\n BogoMIPS:              76.80\n Flags:                 half thumb fastmult vfp edsp neon vfpv3 tls vfpv4 idiva idivt vfpd32 lpae evtstrm crc32\n ----------Network Test----------\n Setting timeout: 10\n Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0308 sec, LOAD: 0.1390 sec.\n Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0385 sec, LOAD: 0.2170 sec.\n Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0056 sec, LOAD: 5.4054 sec.\n Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0143 sec, LOAD: 0.6619 sec.\n Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0537 sec, LOAD: 0.2372 sec.\n Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0785 sec, LOAD: 0.1326 sec.\n </denchmark-code>\n \n Package used (Python/R/Scala/Julia):\n Python 2.7\n <denchmark-h:h2>Build info (Required if built from source)</denchmark-h>\n \n I used make? Instructions found at <denchmark-link:https://github.com/apache/incubator-mxnet/issues/7852>#7852</denchmark-link>\n \n MXNet commit hash:\n <denchmark-link:https://github.com/apache/incubator-mxnet/commit/41394a448a92efbe7704fe21c48a8504fd8d3edc>41394a4</denchmark-link>\n \n Build config:\n <denchmark-code>#-------------------------------------------------------------------------------\n #  Template configuration for compiling mxnet\n #\n #  If you want to change the configuration, please use the following\n #  steps. Assume you are on the root directory of mxnet. First copy the this\n #  file so that any local changes will be ignored by git\n #\n #  $ cp make/config.mk .\n #\n #  Next modify the according entries, and then compile by\n #\n #  $ make\n #\n #  or build in parallel with 8 threads\n #\n #  $ make -j8\n #-------------------------------------------------------------------------------\n \n #---------------------\n # choice of compiler\n #--------------------\n \n export CC = gcc\n export CXX = g++\n export NVCC = nvcc\n \n # whether compile with options for MXNet developer\n DEV = 0\n \n # whether compile with debug\n DEBUG = 0\n \n # whether compile with profiler\n USE_PROFILER =\n \n # whether to turn on segfault signal handler to log the stack trace\n USE_SIGNAL_HANDLER =\n \n # the additional link flags you want to add\n ADD_LDFLAGS =\n \n # the additional compile flags you want to add\n ADD_CFLAGS =\n \n #---------------------------------------------\n # matrix computation libraries for CPU/GPU\n #---------------------------------------------\n \n # whether use CUDA during compile\n USE_CUDA = 0\n \n # add the path to CUDA library to link and compile flag\n # if you have already add them to environment variable, leave it as NONE\n # USE_CUDA_PATH = /usr/local/cuda\n USE_CUDA_PATH = NONE\n \n # whether use CuDNN R3 library\n USE_CUDNN = 0\n \n #whether to use NCCL library\n USE_NCCL = 0\n #add the path to NCCL library\n USE_NCCL_PATH = NONE\n \n # whether use opencv during compilation\n # you can disable it, however, you will not able to use\n # imbin iterator\n USE_OPENCV = 1\n \n #whether use libjpeg-turbo for image decode without OpenCV wrapper\n USE_LIBJPEG_TURBO = 0\n #add the path to libjpeg-turbo library\n USE_LIBJPEG_TURBO_PATH = NONE\n \n # use openmp for parallelization\n USE_OPENMP = 1\n \n # MKL ML Library for Intel CPU/Xeon Phi\n # Please refer to MKL_README.md for details\n \n # MKL ML Library folder, need to be root for /usr/local\n # Change to User Home directory for standard user\n # For USE_BLAS!=mkl only\n MKLML_ROOT=/usr/local\n \n # whether use MKL2017 library\n USE_MKL2017 = 0\n \n # whether use MKL2017 experimental feature for high performance\n # Prerequisite USE_MKL2017=1\n USE_MKL2017_EXPERIMENTAL = 0\n \n # whether use NNPACK library\n USE_NNPACK = 0\n \n # choose the version of blas you want to use\n # can be: mkl, blas, atlas, openblas\n # in default use atlas for linux while apple for osx\n UNAME_S := $(shell uname -s)\n ifeq ($(UNAME_S), Darwin)\n USE_BLAS = apple\n else\n USE_BLAS = atlas\n endif\n \n # whether use lapack during compilation\n # only effective when compiled with blas versions openblas/apple/atlas/mkl\n USE_LAPACK = 1\n \n # path to lapack library in case of a non-standard installation\n USE_LAPACK_PATH =\n \n # by default, disable lapack when using MKL\n # switch on when there is a full installation of MKL available (not just MKL2017/MKL_ML)\n ifeq ($(USE_BLAS), mkl)\n USE_LAPACK = 0\n endif\n \n # add path to intel library, you may need it for MKL, if you did not add the path\n # to environment variable\n USE_INTEL_PATH = NONE\n \n # If use MKL only for BLAS, choose static link automatically to allow python wrapper\n ifeq ($(USE_MKL2017), 0)\n ifeq ($(USE_BLAS), mkl)\n USE_STATIC_MKL = 1\n endif\n else\n USE_STATIC_MKL = NONE\n endif\n \n #----------------------------\n # Settings for power and arm arch\n #----------------------------\n ARCH := $(shell uname -a)\n ifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))\n \tUSE_SSE=0\n else\n \tUSE_SSE=1\n endif\n \n #----------------------------\n # distributed computing\n #----------------------------\n \n # whether or not to enable multi-machine supporting\n USE_DIST_KVSTORE = 0\n \n # whether or not allow to read and write HDFS directly. If yes, then hadoop is\n # required\n USE_HDFS = 0\n \n # path to libjvm.so. required if USE_HDFS=1\n LIBJVM=$(JAVA_HOME)/jre/lib/amd64/server\n \n # whether or not allow to read and write AWS S3 directly. If yes, then\n # libcurl4-openssl-dev is required, it can be installed on Ubuntu by\n # sudo apt-get install -y libcurl4-openssl-dev\n USE_S3 = 0\n \n #----------------------------\n # performance settings\n #----------------------------\n # Use operator tuning\n USE_OPERATOR_TUNING = 1\n \n # Use gperftools if found\n USE_GPERFTOOLS = 1\n \n # Use JEMalloc if found, and not using gperftools\n USE_JEMALLOC = 1\n \n #----------------------------\n # additional operators\n #----------------------------\n \n # path to folders containing projects specific operators that you don't want to put in src/operators\n EXTRA_OPERATORS =\n \n #----------------------------\n # other features\n #----------------------------\n \n # Create C++ interface package\n USE_CPP_PACKAGE = 0\n \n #----------------------------\n # plugins\n #----------------------------\n \n # whether to use caffe integration. This requires installing caffe.\n # You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH\n # CAFFE_PATH = $(HOME)/caffe\n # MXNET_PLUGINS += plugin/caffe/caffe.mk\n \n # whether to use torch integration. This requires installing torch.\n # You also need to add TORCH_PATH/install/lib to your LD_LIBRARY_PATH\n # TORCH_PATH = $(HOME)/torch\n # MXNET_PLUGINS += plugin/torch/torch.mk\n \n # WARPCTC_PATH = $(HOME)/warp-ctc\n # MXNET_PLUGINS += plugin/warpctc/warpctc.mk\n \n # whether to use sframe integration. This requires build sframe\n # git@github.com:dato-code/SFrame.git\n # SFRAME_PATH = $(HOME)/SFrame\n # MXNET_PLUGINS += plugin/sframe/plugin.mk\n </denchmark-code>\n \n <denchmark-h:h2>Error Message:</denchmark-h>\n \n <denchmark-code>>>> import inception_predict\n [13:28:02] src/nnvm/legacy_json_util.cc:190: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\n Segmentation fault\n </denchmark-code>\n \n <denchmark-h:h2>Minimum reproducible example</denchmark-h>\n \n <denchmark-code>python\n >>> import inception_predict\n </denchmark-code>\n \n <denchmark-h:h2>Steps to reproduce</denchmark-h>\n \n \n Follow instructions from #7852 by @FrancisTse8\n Run\n \n <denchmark-code>python\n >>> import inception_predict\n </denchmark-code>\n \n <denchmark-h:h2>What have you tried to solve it?</denchmark-h>\n \n \n Renamed Inception_BN-000.params to Inception-BN-0000.params\n download squeezenetv1.1-0000.params from http://data.mxnet.io/models/imagenet/squeezenet/\n \n Should I try to build an older version of MXNet and try it again?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "roaur", "commentT": "2017-12-24T21:24:04Z", "comment_text": "\n \t\tI'm experiencing the same problem with a similar config (the  difference is I'm running MXNet in a virtual env).\n I have tried:\n \n Downloading the alternate version of the model http://data.mxnet.io/models/imagenet/inception-bn_old.tar.gz\n Building an older version of MXNet (v0.11.0 seems like the oldest stable branch)\n \n Neither fix the problem.\n The log message suggests that an attempt is being made to upgrade the symbol from v0.8.0 but fails for some reason.\n I'm new to MXNet and not sure what the differences might be in the symbol json file or API but I have also scoured the internet looking for way to manually edit the json file with no luck.\n Any suggestions would be appreciated.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "roaur", "commentT": "2018-01-05T19:36:13Z", "comment_text": "\n \t\tHi,\n To install mxnet use this address:  <denchmark-link:url>https://www.pyimagesearch.com/2017/11/13/how-to-install-mxnet-for-deep-learning/</denchmark-link>\n \n You have to change one line  \"git clone --recursive <denchmark-link:https://github.com/apache/incubator-mxnet.git>https://github.com/apache/incubator-mxnet.git</denchmark-link>\n  mxnet --branch 0.11.0\" with \"git clone --recursive <denchmark-link:https://github.com/apache/incubator-mxnet.git>https://github.com/apache/incubator-mxnet.git</denchmark-link>\n  mxnet --branch 1.0.0\"\n I have just installed it on virtual env. and I made a prediction with my own model.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "roaur", "commentT": "2018-01-12T15:48:54Z", "comment_text": "\n \t\tI have the same issue here. Using mxnet 1.0.1. Getting the actual error message. Do I have to reinstall mxnet using 0.8.0?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "roaur", "commentT": "2018-01-13T23:44:45Z", "comment_text": "\n \t\tHi yimingliu0216\n Just install version 1.0.0 from <denchmark-link:https://github.com/apache/incubator-mxnet/releases/tag/1.0.0>https://github.com/apache/incubator-mxnet/releases/tag/1.0.0</denchmark-link>\n \n It's working perfect.\n On reading lines (170, 171, 172, 173) from file: <denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/src/nnvm/legacy_json_util.cc>https://github.com/apache/incubator-mxnet/blob/master/src/nnvm/legacy_json_util.cc</denchmark-link>\n    you can see witch versions you can use:\n 170     {MXNET_MAKE_VERSION(), UpgradeJSON_Parse},\n 171     {MXNET_MAKE_VERSION(), UpgradeJSON_000800_000900},\n 172     {MXNET_MAKE_VERSION(), UpgradeJSON_000903_000904},\n 173     {MXNET_MAKE_VERSION(), UpgradeJSON_000904_000905},\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "roaur", "commentT": "2018-01-14T01:41:15Z", "comment_text": "\n \t\tThanks for the reply. I already downgrade to 1.0.0. It works fine now, but it wastes my date to reinstall the mxnet.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "roaur", "commentT": "2018-01-19T06:23:31Z", "comment_text": "\n \t\tCan you <denchmark-link:https://github.com/wildhunter-66>@wildhunter-66</denchmark-link>\n   tell me how to downgrade the mxnet version form 1.0.1 to v1.0.0 without having to reinstall from starting?\n I'm getting same error on v1.0.1\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "roaur", "commentT": "2018-01-19T07:31:08Z", "comment_text": "\n \t\t@yimingliu0216 Could you tell me how you downgraded version?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "roaur", "commentT": "2019-07-17T19:53:11Z", "comment_text": "\n \t\tIs this fixed with the wine detection tutorial improvements?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "roaur", "commentT": "2019-07-17T19:54:22Z", "comment_text": "\n \t\tIf you have further issues, feel free to reopen or create a new one. I think we should close this for now.\n \t\t"}}}, "commit": {"commit_id": "1af29e9c060a4c7d60eeaacba32afdb9a7775ba7", "commit_author": "Pedro Larroy", "commitT": "2019-04-29 15:47:13-07:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "docs\\tutorials\\embedded\\wine_detector.md", "file_new_name": "docs\\tutorials\\embedded\\wine_detector.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "94,104,105,111,134,140,141,161,169,170,173,174,175,176,177,178,179,180,181,182,183,184,185,186,212,216,227,266,269,272,290,385,388", "deleted_lines": "103,109,132,138,139,159,167,168,171,197,201,212,251,254,257,275,370,373"}}}}}}