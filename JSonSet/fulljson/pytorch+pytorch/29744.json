{"BR": {"BR_id": "29744", "BR_author": "colinfang", "BRopenT": "2019-11-13T20:00:25Z", "BRcloseT": "2020-01-31T00:58:37Z", "BR_text": {"BRsummary": "CuDNN batchnorm has batch size limit for eval with channel", "BRdescription": "\n <denchmark-code>torch.backends.cudnn.version()\n # 7603\n torch.version.cuda\n # 10.1.243\n # pytorch version 1.3\n </denchmark-code>\n \n x = torch.rand(70000, 1, 2).cuda()\n \n bn = nn.BatchNorm1d(1)\n bn.cuda()\n bn.eval()\n \n xbn = bn(x)\n xbn.size()\n \n # RuntimeError: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\n The above works if the batch size is 60000, or it is in training mode, or the input is 2d (no channel) instead of 3d.\n <denchmark-link:https://github.com/pytorch/pytorch/issues/2917>#2917</denchmark-link>\n  might be related\n cc <denchmark-link:https://github.com/ngimel>@ngimel</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "colinfang", "commentT": "2019-11-14T18:16:04Z", "comment_text": "\n \t\tHave you tried running your code with  as in <denchmark-link:https://github.com/pytorch/pytorch/issues/2917>#2917</denchmark-link>\n ? Have you tried running the same code as <denchmark-link:https://github.com/pytorch/pytorch/issues/2917>#2917</denchmark-link>\n ?\n <denchmark-code>import torch\n import torch.nn as nn\n from torch.autograd import Variable\n \n torch.backends.cudnn.enabled=True\n x = Variable(torch.rand(140000,1).contiguous()).cuda()\n \n print (torch.backends.cudnn.version())\n \n bn = nn.BatchNorm1d(1)\n bn.cuda()\n \n xbn = bn(x)\n xbn.size()\n </denchmark-code>\n \n For completeness, please copy and paste the output from our environment collection script:\n <denchmark-code>wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\n # For security purposes, please check the contents of collect_env.py before running it.\n python collect_env.py\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "colinfang", "commentT": "2019-11-14T19:23:13Z", "comment_text": "\n \t\tcc: <denchmark-link:https://github.com/csarofeen>@csarofeen</denchmark-link>\n  <denchmark-link:https://github.com/ptrblck>@ptrblck</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "colinfang", "commentT": "2019-11-25T12:49:48Z", "comment_text": "\n \t\tCode in <denchmark-link:https://github.com/pytorch/pytorch/issues/2917>#2917</denchmark-link>\n  runs well for me.\n Switching to x = torch.rand(70000, 1, 2).contiguous().cuda() still triggers the same error in my example.\n <denchmark-code>python collect_env.py\n \n Collecting environment information...\n PyTorch version: 1.3.0\n Is debug build: No\n CUDA used to build PyTorch: 10.1.243\n \n OS: Ubuntu 18.04.2 LTS\n GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\n CMake version: version 3.10.2\n \n Python version: 3.7\n Is CUDA available: Yes\n CUDA runtime version: Could not collect\n GPU models and configuration: \n GPU 0: TITAN X (Pascal)\n GPU 1: TITAN Xp\n GPU 2: TITAN X (Pascal)\n GPU 3: TITAN Xp\n \n Nvidia driver version: 418.67\n cuDNN version: /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudnn.so.7.1.3\n \n Versions of relevant libraries:\n [pip] numpy==1.17.3\n [pip] torch==1.3.0\n [pip] torchvision==0.4.1a0+d94043a\n [conda] mkl                       2019.4                      243  \n [conda] pytorch                   1.3.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n [conda] torchvision               0.4.1                py37_cu101    pytorch\n </denchmark-code>\n \n I also have conda installed cudatoolkit with version   10.1.243\n BTW the cuDNN version is wrong above, I think pytorch binary comes with statically linked cudnn.\n <denchmark-code>torch.backends.cudnn.version()\n # 7603\n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "colinfang", "commentT": "2019-11-26T16:11:49Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/csarofeen>@csarofeen</denchmark-link>\n , <denchmark-link:https://github.com/ptrblck>@ptrblck</denchmark-link>\n  can you please look up conditions under which cudnn can be used (in training/activation, in spatial/per_activation modes) and change the conditions in the pytorch code accordingly, so that it transparently falls to native implementation where cudnn can't be used?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "colinfang", "commentT": "2019-11-28T04:39:16Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ngimel>@ngimel</denchmark-link>\n  I've pushed an initial commit with updated size limitations and tested it with cudnn 7.6.5.32.\n Based on the minimal CUDA version of 9.0, I assume the minimal cudnn version would be 7.1.4?\n If that's the case, we might also update the cudnn version check in <denchmark-link:https://github.com/ptrblck/pytorch/commit/4c5f048e7ad6242171512294a110bfc33abe2a77#diff-334eb235b4eb8d228fe544dbe506e3c7R472>line 472</denchmark-link>\n  and I'll retest it with older versions.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "colinfang", "commentT": "2019-11-29T20:22:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ptrblck>@ptrblck</denchmark-link>\n   How did you come up with such magic numbers for the limits? Are they listed in cudnn manual or something?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "colinfang", "commentT": "2019-12-02T16:55:29Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ptrblck>@ptrblck</denchmark-link>\n  That's ok, binaries are built with cudnn 7.6, there's no need to specifically test older versions.\n \t\t"}}}, "commit": {"commit_id": "0f0972051a7eaf3da645b2f18cc77be188d59b8d", "commit_author": "root", "commitT": "2020-01-30 16:57:15-08:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "aten\\src\\ATen\\native\\Normalization.cpp", "file_new_name": "aten\\src\\ATen\\native\\Normalization.cpp", "file_complexity": {"file_NLOC": "496", "file_CCN": "140", "file_NToken": "4833"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "467,468,469,470", "deleted_lines": "467", "method_info": {"method_name": "at::native::_batch_norm_impl_index", "method_params": "input,weight,bias,running_mean,running_var,training,momentum,eps,cudnn_enabled", "method_startline": "438", "method_endline": "513", "method_complexity": {"method_NLOC": "70", "method_CCN": "49", "method_NToken": "709", "method_nesting_level": "2"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "test\\test_nn.py", "file_new_name": "test\\test_nn.py", "file_complexity": {"file_NLOC": "8484", "file_CCN": "1307", "file_NToken": "95666"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "6265,6266", "deleted_lines": "6265,6266", "method_info": {"method_name": "test_batchnorm_large_batch", "method_params": "self,dtype", "method_startline": "6264", "method_endline": "6267", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "62", "method_nesting_level": "1"}}}}}}}}