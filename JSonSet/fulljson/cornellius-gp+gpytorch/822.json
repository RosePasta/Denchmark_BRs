{"BR": {"BR_id": "822", "BR_author": "Balandat", "BRopenT": "2019-08-01T20:39:09Z", "BRcloseT": "2019-08-02T18:25:19Z", "BR_text": {"BRsummary": "[Bug] Upstream changes to tensor comparisons breaks things", "BRdescription": "\n <denchmark-h:h1>\ud83d\udc1b Bug</denchmark-h>\n \n After <denchmark-link:https://github.com/pytorch/pytorch/pull/21113>pytorch/pytorch#21113</denchmark-link>\n  a bunch of tests are failing b/c of the change in tensor comparison behavior (return type from uint8 to bool). Creating this issue to track the fix.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Balandat", "commentT": "2019-08-01T20:48:27Z", "comment_text": "\n \t\tIt appears most of this happens in batch_symeig where we do 1 - mask - will put up a fix shortly.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Balandat", "commentT": "2019-08-01T21:07:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Balandat>@Balandat</denchmark-link>\n , we have introduced '~' operator for masks to fix this issue. You should be able to just replace '1-mask' with '~mask'\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Balandat", "commentT": "2019-08-01T21:13:46Z", "comment_text": "\n \t\tSure that works. There are a few other places in the code where this causes failures, but they should be easy enough to fix.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Balandat", "commentT": "2019-08-01T22:04:57Z", "comment_text": "\n \t\tFixed by <denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/823>#823</denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Balandat", "commentT": "2019-08-01T22:47:19Z", "comment_text": "\n \t\tOk of course there are now a bunch more warnings emitted when using uint8 on pytorch master, so all the tests that count the warnings fail there ...\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Balandat", "commentT": "2019-08-02T00:30:50Z", "comment_text": "\n \t\tIt's worse than that, the change actually breaks the jit script code for _jit_linear_cg_updates. So the correct thing is to use bool everywhere, and fix the tests that count the warnings...\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Balandat", "commentT": "2019-08-02T00:38:09Z", "comment_text": "\n \t\tWon't be able to fix all this properly right now, deferring to the above issue.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "Balandat", "commentT": "2019-08-02T00:42:49Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Balandat>@Balandat</denchmark-link>\n  I'll take a look once the nightly build comes out and I can repro the errors without having to build pytorch from source.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "Balandat", "commentT": "2019-08-02T01:02:20Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jacobrgardner>@jacobrgardner</denchmark-link>\n  sounds good, if you base this on <denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/825>#825</denchmark-link>\n  at least you won't have to deal with the warnings.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "Balandat", "commentT": "2019-08-02T01:29:27Z", "comment_text": "\n \t\tFwiw, here's a notebook that shows the failure (commented out the jit decorators locally).\n It only happens when broadcasting. <denchmark-link:https://github.com/izdeby>@izdeby</denchmark-link>\n , maybe broadcasting semantics for bool tensors are different?\n <denchmark-link:https://github.com/cornellius-gp/gpytorch/files/3459249/test_broadcasting_issues.ipynb.txt>test_broadcasting_issues.ipynb.txt</denchmark-link>\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "Balandat", "commentT": "2019-08-02T16:51:09Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Balandat>@Balandat</denchmark-link>\n , what exactly failed in broadcasting for you? there shouldn't be any difference in broadcasting semantics for bool tensors\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "Balandat", "commentT": "2019-08-02T17:10:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/izdeby>@izdeby</denchmark-link>\n  looks like this is a different issue related to changing sizes in , see <denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/827>#827</denchmark-link>\n \n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "Balandat", "commentT": "2019-08-02T17:20:02Z", "comment_text": "\n \t\tFor now do we think we could define like a gpytorch.bool type to be torch.bool if that will work (i.e. we are on master), and torch.uint8 otherwise?\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "Balandat", "commentT": "2019-08-02T17:21:00Z", "comment_text": "\n \t\tWe could similarly define gpytorch.not to do ~ and 1 - ... respectively\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "Balandat", "commentT": "2019-08-02T17:29:07Z", "comment_text": "\n \t\tSo ~ will work even with uint8, so there is no need for that. But we can do the gpytorch.bool thing to avoid the mass of warnings\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "Balandat", "commentT": "2019-08-02T17:46:59Z", "comment_text": "\n \t\tmade this change in the latest update to <denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/827>#827</denchmark-link>\n \n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "Balandat", "commentT": "2019-08-02T18:25:19Z", "comment_text": "\n \t\tReasonably fixed for now via <denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/827>#827</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "b5ca4235cef1eff64bb063945a422c1ebf178a1b", "commit_author": "Max Balandat", "commitT": "2019-08-01 15:00:45-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "gpytorch\\functions\\_log_normal_cdf.py", "file_new_name": "gpytorch\\functions\\_log_normal_cdf.py", "file_complexity": {"file_NLOC": "88", "file_CCN": "8", "file_NToken": "694"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "105", "deleted_lines": "105", "method_info": {"method_name": "backward", "method_params": "ctx,grad_output", "method_startline": "100", "method_endline": "114", "method_complexity": {"method_NLOC": "10", "method_CCN": "2", "method_NToken": "147", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "63", "deleted_lines": "63", "method_info": {"method_name": "forward", "method_params": "ctx,z", "method_startline": "11", "method_endline": "97", "method_complexity": {"method_NLOC": "71", "method_CCN": "6", "method_NToken": "519", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "gpytorch\\kernels\\grid_interpolation_kernel.py", "file_new_name": "gpytorch\\kernels\\grid_interpolation_kernel.py", "file_complexity": {"file_NLOC": "160", "file_CCN": "29", "file_NToken": "1016"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "97", "deleted_lines": "97", "method_info": {"method_name": "__init__", "method_params": "self,base_kernel,grid_size,num_dims,grid_bounds,active_dims", "method_startline": "65", "method_endline": "97", "method_complexity": {"method_NLOC": "27", "method_CCN": "6", "method_NToken": "180", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "gpytorch\\lazy\\cat_lazy_tensor.py", "file_new_name": "gpytorch\\lazy\\cat_lazy_tensor.py", "file_complexity": {"file_NLOC": "294", "file_CCN": "99", "file_NToken": "2817"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "193", "deleted_lines": null, "method_info": {"method_name": "_getitem", "method_params": "self,row_index,col_index,batch_indices", "method_startline": "171", "method_endline": "231", "method_complexity": {"method_NLOC": "45", "method_CCN": "14", "method_NToken": "504", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "140", "deleted_lines": null, "method_info": {"method_name": "_get_indices", "method_params": "self,row_index,col_index,batch_indices", "method_startline": "132", "method_endline": "169", "method_complexity": {"method_NLOC": "27", "method_CCN": "10", "method_NToken": "358", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "gpytorch\\utils\\eig.py", "file_new_name": "gpytorch\\utils\\eig.py", "file_complexity": {"file_NLOC": "19", "file_CCN": "3", "file_NToken": "237"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "26", "deleted_lines": "26", "method_info": {"method_name": "batch_symeig", "method_params": "mat", "method_startline": "6", "method_endline": "30", "method_complexity": {"method_NLOC": "18", "method_CCN": "3", "method_NToken": "234", "method_nesting_level": "0"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "gpytorch\\utils\\linear_cg.py", "file_new_name": "gpytorch\\utils\\linear_cg.py", "file_complexity": {"file_NLOC": "189", "file_CCN": "4", "file_NToken": "1434"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "182,190", "deleted_lines": null}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "gpytorch\\utils\\sparse.py", "file_new_name": "gpytorch\\utils\\sparse.py", "file_complexity": {"file_NLOC": "175", "file_CCN": "38", "file_NToken": "1906"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "157,158,159,160,180,181,182", "deleted_lines": "157,158,178,179,180", "method_info": {"method_name": "sparse_getitem", "method_params": "sparse,idxs", "method_startline": "137", "method_endline": "195", "method_complexity": {"method_NLOC": "49", "method_CCN": "15", "method_NToken": "507", "method_nesting_level": "0"}}}}}}}}