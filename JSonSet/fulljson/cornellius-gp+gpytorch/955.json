{"BR": {"BR_id": "955", "BR_author": "jeffwillette", "BRopenT": "2019-11-19T01:36:38Z", "BRcloseT": "2019-11-29T16:56:01Z", "BR_text": {"BRsummary": "[Bug] Invalid index in gather during call to mll in training loop", "BRdescription": "\n <denchmark-h:h1>\ud83d\udc1b Bug</denchmark-h>\n \n I followed the docs related to DKL exactly and got the following error during the training loop when calculating the loss with the marginal likelihood function\n ** Stack trace/error message **\n <denchmark-code>Traceback (most recent call last):\n   File \"gp.py\", line 24, in <module>\n     exact.train()\n   File \"/st2/jeff/real_estate/models/gaussian_processes/exact.py\", line 102, in train\n     loss = -mll(output, train_y).sum()\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/module.py\", line 22, in __call__\n     outputs = self.forward(*inputs, **kwargs)\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\", line 27, in forward\n     res = output.log_prob(target)\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/distributions/multivariate_normal.py\", line 128, in log_prob\n     inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/lazy/batch_repeat_lazy_tensor.py\", line 242, in inv_quad_logdet\n     inv_quad_rhs, logdet, reduce_inv_quad=False\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py\", line 1052, in inv_quad_logdet\n     *args,\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/functions/_inv_quad_log_det.py\", line 63, in forward\n     preconditioner, precond_lt, logdet_correction = lazy_tsr._preconditioner()\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\", line 59, in _preconditioner\n     self._piv_chol_self = pivoted_cholesky.pivoted_cholesky(self._lazy_tensor, max_iter)\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/utils/pivoted_cholesky.py\", line 19, in pivoted_cholesky\n     matrix_diag = matrix._approx_diag()\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/lazy/interpolated_lazy_tensor.py\", line 90, in _approx_diag\n     left_res = left_interp(self.left_interp_indices, self.left_interp_values, base_diag_root.unsqueeze(-1))\n   File \"/st2/jeff/anaconda3/envs/jeff/lib/python3.7/site-packages/gpytorch/utils/interpolation.py\", line 187, in left_interp\n     res = rhs_expanded.gather(-3, interp_indices_expanded).mul(interp_values_expanded)\n RuntimeError: Invalid index in gather at /tmp/pip-req-build-58y_cjjl/aten/src/TH/generic/THTensorEvenMoreMath.cpp:472\n loss: 57158.71 med: 0.30, minmax: 0.30 0.30 noise: 0.56: : 0it [00:08, ?it/s]\n </denchmark-code>\n \n <denchmark-h:h2>Expected Behavior</denchmark-h>\n \n I am left unsure of what is causing the error and how to go about fixing it because it is initially successful in iterating and calculating the loss and then it crashes. The sizing of tensors must be correct, but there is must be some numerical instability and I am unsure about where to look for it.\n <denchmark-h:h2>System information</denchmark-h>\n \n Please complete the following information:\n gpytorch version: 0.3.6\n torch version: `1.2.0\n Ubuntu 18.04\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jeffwillette", "commentT": "2019-11-20T00:39:08Z", "comment_text": "\n \t\t@deltaskelta can you provide a more complete example? I don't know how to reproduce.\n Can you also try on the latest version of gpytorch (off of the master branch on Github) and PyTorch 1.3.1?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jeffwillette", "commentT": "2019-11-20T12:55:28Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/gpleiss>@gpleiss</denchmark-link>\n  thanks for your response. I installed the most recent pytorch and gpytorch from the master branch and I still had the issue. I had time to create a small reproduction repo (<denchmark-link:https://github.com/deltaskelta/gpytorch-955>https://github.com/deltaskelta/gpytorch-955</denchmark-link>\n ) with a minimal dataset. You can run it by doing...\n <denchmark-code>python dkl.py\n </denchmark-code>\n \n I printed the input tensor to make sure no weird values were showing up. If you let it run for a minute or so it should fail with the above error very quickly\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jeffwillette", "commentT": "2019-11-25T17:13:30Z", "comment_text": "\n \t\tThanks so much for the repo! I've reproduced the error - and will look into it.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jeffwillette", "commentT": "2019-11-25T17:27:45Z", "comment_text": "\n \t\t@deltaskelta - it looks like these NaNs came from a divide-by-zero error that <denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/971>#971</denchmark-link>\n  addresses. However, this error is mostly stemming from the neural network outputs collapsing to a single point, which will cause lots of other learning issues for the GP.\n To solve that larger issue, I would either\n \n Pre-train the neural network without a GP for a few iterations. This is especially useful for large NNs, like the one in your example.\n Use batch normalization\n Make sure that the outputs are scaled to be zero mean + unit variance.\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jeffwillette", "commentT": "2019-12-26T02:10:17Z", "comment_text": "\n \t\tHi,\n I also received the same error in a GP for multiclass classification like the one in <denchmark-link:https://github.com/cornellius-gp/gpytorch/issues/1003>#1003</denchmark-link>\n  . I am using  and .\n Fortunately it went away after normalizing the inputs properly.\n \t\t"}}}, "commit": {"commit_id": "c19b1cf823ec3d4f3a8835139dc4f965ecb447e1", "commit_author": "Geoff Pleiss", "commitT": "2019-11-25 12:22:32-05:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": ".isort.cfg", "file_new_name": ".isort.cfg", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2", "deleted_lines": "2"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "gpytorch\\utils\\interpolation.py", "file_new_name": "gpytorch\\utils\\interpolation.py", "file_complexity": {"file_NLOC": "163", "file_CCN": "20", "file_NToken": "1841"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "42,102", "deleted_lines": "42,102", "method_info": {"method_name": "interpolate", "method_params": "self,Tensor,interp_points,2", "method_startline": "42", "method_endline": "165", "method_complexity": {"method_NLOC": "96", "method_CCN": "13", "method_NToken": "1050", "method_nesting_level": "1"}}}}}}}}