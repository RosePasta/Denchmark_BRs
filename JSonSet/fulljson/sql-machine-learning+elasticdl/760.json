{"BR": {"BR_id": "760", "BR_author": "yuyicg", "BRopenT": "2019-06-24T11:42:43Z", "BRcloseT": "2019-06-25T07:17:18Z", "BR_text": {"BRsummary": "Local PySpark Job Error", "BRdescription": "\n Error raised when run the local pyspark job according to doc <denchmark-link:https://github.com/wangkuiyi/elasticdl/blob/develop/elasticdl/python/data/recordio_gen/recordio_data_preparation_tutorial.md#local-pyspark-job>RecordIO Data Preparation Tutorial</denchmark-link>\n , full error stack is below:\n 19/06/24 11:31:04 ERROR Executor: Exception in task 1.0 in stage 0.0 (TID 1)\n org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n   File \"/usr/local/lib/python3.5/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n     process()\n   File \"/usr/local/lib/python3.5/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n     serializer.dump_stream(func(split_index, iterator), outfile)\n   File \"/usr/local/lib/python3.5/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/rdd.py\", line 352, in func\n   File \"/elasticdl/python/data/recordio_gen/sample_pyspark_recordio_gen/spark_gen_recordio.py\", line 48, in _process_data\n     codec_module.codec.init(feature_label_columns)\n   File \"elasticdl/python/data/codec/tf_example_codec.py\", line 10, in init\n     feature_columns\n   File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 799, in make_parse_example_spec\n     'Given: {}'.format(column))\n ValueError: All feature_columns must be _FeatureColumn instances. Given: NumericColumn(key='image', shape=(28, 28), default_value=None, dtype=tf.float32, normalizer_fn=None)\n \n \tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n \tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n \tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:571)\n \tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n \tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n \tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n \tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n \tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n \tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n \tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n \tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n \tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n \tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n \tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n \tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n \tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n \tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n \tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945)\n \tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n \tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n \tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n \tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n \tat java.lang.Thread.run(Thread.java:748)\n \n \t"}, "comments": {}}, "commit": {"commit_id": "f20e3ea845a6aad33f6387f535ffd41406d4f414", "commit_author": "zhujl1991", "commitT": "2019-06-25 00:17:17-07:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "elasticdl\\python\\data\\codec\\tf_example_codec.py", "file_new_name": "elasticdl\\python\\data\\codec\\tf_example_codec.py", "file_complexity": {"file_NLOC": "27", "file_CCN": "6", "file_NToken": "207"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "5", "deleted_lines": "5,6", "method_info": {"method_name": "__init__", "method_params": "self", "method_startline": "5", "method_endline": "6", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "10", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "29,30", "deleted_lines": null, "method_info": {"method_name": "decode", "method_params": "self,raw,example_spec", "method_startline": "29", "method_endline": "30", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "20", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "47,48,49", "method_info": {"method_name": "decode", "method_params": "self,raw", "method_startline": "47", "method_endline": "49", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "26", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "5,8", "deleted_lines": "5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26", "method_info": {"method_name": "encode", "method_params": "self,example,feature_name_to_type", "method_startline": "5", "method_endline": "27", "method_complexity": {"method_NLOC": "22", "method_CCN": "5", "method_NToken": "170", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "29,30", "deleted_lines": "17,18,19,20,21,22,23,26", "method_info": {"method_name": "encode", "method_params": "self,example", "method_startline": "17", "method_endline": "45", "method_complexity": {"method_NLOC": "28", "method_CCN": "6", "method_NToken": "212", "method_nesting_level": "1"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "8", "deleted_lines": "8,9,10,11,12,13,14,15", "method_info": {"method_name": "init", "method_params": "self,feature_columns", "method_startline": "8", "method_endline": "15", "method_complexity": {"method_NLOC": "8", "method_CCN": "2", "method_NToken": "41", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "elasticdl\\python\\data\\recordio_gen\\convert_numpy_to_recordio.py", "file_new_name": "elasticdl\\python\\data\\recordio_gen\\convert_numpy_to_recordio.py", "file_complexity": {"file_NLOC": "45", "file_CCN": "1", "file_NToken": "219"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "30,31,32,33,47,48,49,50,51,52,53", "deleted_lines": "43,44,45,46,47,48,49,50"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "elasticdl\\python\\data\\recordio_gen\\sample_pyspark_recordio_gen\\spark_gen_recordio.py", "file_new_name": "elasticdl\\python\\data\\recordio_gen\\sample_pyspark_recordio_gen\\spark_gen_recordio.py", "file_complexity": {"file_NLOC": "108", "file_CCN": "11", "file_NToken": "519"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "48", "method_info": {"method_name": "_process_data", "method_params": "filename_list", "method_startline": "22", "method_endline": "60", "method_complexity": {"method_NLOC": "34", "method_CCN": "5", "method_NToken": "179", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "elasticdl\\python\\elasticdl\\worker\\worker.py", "file_new_name": "elasticdl\\python\\elasticdl\\worker\\worker.py", "file_complexity": {"file_NLOC": "174", "file_CCN": "36", "file_NToken": "1152"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "136,142", "deleted_lines": "141", "method_info": {"method_name": "_get_batch", "method_params": "self,reader,batch_size,decode", "method_startline": "136", "method_endline": "143", "method_complexity": {"method_NLOC": "8", "method_CCN": "3", "method_NToken": "51", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "136,142", "deleted_lines": "135,141", "method_info": {"method_name": "_get_batch", "method_params": "reader,batch_size,decode", "method_startline": "135", "method_endline": "142", "method_complexity": {"method_NLOC": "8", "method_CCN": "3", "method_NToken": "45", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "elasticdl\\python\\tests\\checkpoint_test.py", "file_new_name": "elasticdl\\python\\tests\\checkpoint_test.py", "file_complexity": {"file_NLOC": "170", "file_CCN": "8", "file_NToken": "1035"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "38", "deleted_lines": "36", "method_info": {"method_name": "create_recordio_file", "method_params": "size", "method_startline": "30", "method_endline": "39", "method_complexity": {"method_NLOC": "9", "method_CCN": "2", "method_NToken": "92", "method_nesting_level": "0"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "elasticdl\\python\\tests\\example_test.py", "file_new_name": "elasticdl\\python\\tests\\example_test.py", "file_complexity": {"file_NLOC": "118", "file_CCN": "14", "file_NToken": "718"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "32,33,34,47,48,49,50", "deleted_lines": "32,45", "method_info": {"method_name": "create_recordio_file", "method_params": "size,shape,columns", "method_startline": "30", "method_endline": "51", "method_complexity": {"method_NLOC": "21", "method_CCN": "4", "method_NToken": "155", "method_nesting_level": "0"}}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "elasticdl\\python\\tests\\tf_example_codec_test.py", "file_new_name": "elasticdl\\python\\tests\\tf_example_codec_test.py", "file_complexity": {"file_NLOC": "37", "file_CCN": "4", "file_NToken": "298"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "21,22,23,24,25,26,27,28,38,42", "deleted_lines": "28,31,35", "method_info": {"method_name": "test_encode_and_decode", "method_params": "self", "method_startline": "11", "method_endline": "47", "method_complexity": {"method_NLOC": "28", "method_CCN": "4", "method_NToken": "258", "method_nesting_level": "1"}}}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "elasticdl\\python\\tests\\worker_test.py", "file_new_name": "elasticdl\\python\\tests\\worker_test.py", "file_complexity": {"file_NLOC": "83", "file_CCN": "12", "file_NToken": "568"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "29,30,31,38", "deleted_lines": "29,36", "method_info": {"method_name": "create_recordio_file", "method_params": "size", "method_startline": "27", "method_endline": "39", "method_complexity": {"method_NLOC": "12", "method_CCN": "3", "method_NToken": "109", "method_nesting_level": "0"}}}}}}}}