{"BR": {"BR_id": "11670", "BR_author": "andrewredd", "BRopenT": "2020-10-28T13:10:45Z", "BRcloseT": "2020-11-15T05:41:12Z", "BR_text": {"BRsummary": "[tune] Schedulers should automatically handle nans/inf values", "BRdescription": "\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n I get the following when I run the following code\n <denchmark-code>  def tune_asha(num_samples=400, num_epochs=25, gpus_per_trial=0.1):\n         config = {\n             \"logger_config\": {\"mlflow_experiment_id\": experiment_id},\n             \"batch_size\": 1024,\n             \"learning_rate\": tune.uniform(1e-5, 1e-3),\n             \"layer1_2_size\": tune.uniform(128, 512),\n             \"layer3\": tune.uniform(64, 256),\n             \"layer4\": tune.uniform(32, 128),\n             \"layer5\": tune.uniform(16, 64),\n             \"layer1_2_d\": tune.uniform(0.01, 0.2),\n             \"layer3_4_5_d\": tune.uniform(0.01, 0.05),\n             \"emb_dropout\": tune.uniform(0.01, 0.1),\n             \"emb_max\": tune.uniform(64, 256),\n             \"gradient_clipping\": tune.uniform(5, 500),\n             \"accul_batches\": 10,\n             \"optimizer_weight_decay\": tune.uniform(0, 0.001),\n             \"lr_scheduler_patience\": tune.uniform(1, 5),\n             \"lr_scheduler_reduction_factor\": tune.uniform(0.1, 0.25),\n         }\n \n         scheduler = ASHAScheduler(\n             metric=\"loss\",\n             mode=\"min\",\n             max_t=num_epochs,\n             grace_period=7,\n             reduction_factor=2,\n         )\n \n         reporter = CLIReporter(\n             parameter_columns=[\n                 \"layer1_2_size\",\n                 \"layer3\",\n                 \"layer4\",\n                 \"layer5\",\n                 \"learning_rate\",\n                 \"batch_size\",\n             ],\n             metric_columns=[\"loss\", \"training_iteration\"],\n         )\n \n         algo = BayesOptSearch(\n             metric=\"loss\",\n             mode=\"min\",\n             utility_kwargs={\"kind\": \"ucb\", \"kappa\": 2.5, \"xi\": 0.0},\n             random_search_steps=30,\n         )\n         algo = ConcurrencyLimiter(algo, max_concurrent=10)\n \n         return tune.run(\n             partial(train_tune, num_epochs=num_epochs, num_gpus=gpus_per_trial),\n             name=experiment_name,\n             resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n             config=config,\n             local_dir=\".\",\n             search_alg=algo,\n             scheduler=scheduler,\n             num_samples=num_samples,\n             progress_reporter=reporter,\n             loggers=DEFAULT_LOGGERS + (MLFLowLogger,),\n         )\n </denchmark-code>\n \n When it's seeding the space there are no issues but as soon as it is on trial 30, I get the following error\n <denchmark-code>  File \"tune_r_learner_bo.py\", line 116, in <module>\n     main()\n   File \"tune_r_learner_bo.py\", line 110, in main\n     expr_obj = tune_asha()\n   File \"tune_r_learner_bo.py\", line 107, in tune_asha\n     loggers=DEFAULT_LOGGERS + (MLFLowLogger,),\n   File \"/opt/conda/lib/python3.7/site-packages/ray/tune/tune.py\", line 411, in run\n     runner.step()\n   File \"/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 561, in step\n     next_trial = self._get_next_trial()  # blocking\n   File \"/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 658, in _get_next_trial\n     self._update_trial_queue(blocking=wait_for_trial)\n   File \"/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 1011, in _update_trial_queue\n     trial = self._search_alg.next_trial()\n   File \"/opt/conda/lib/python3.7/site-packages/ray/tune/suggest/search_generator.py\", line 114, in next_trial\n     self._experiment.dir_name)\n   File \"/opt/conda/lib/python3.7/site-packages/ray/tune/suggest/search_generator.py\", line 121, in create_trial_if_possible\n     suggested_config = self.searcher.suggest(trial_id)\n   File \"/opt/conda/lib/python3.7/site-packages/ray/tune/suggest/suggestion.py\", line 346, in suggest\n     suggestion = self.searcher.suggest(trial_id)\n   File \"/opt/conda/lib/python3.7/site-packages/ray/tune/suggest/bayesopt.py\", line 257, in suggest\n     config = self.optimizer.suggest(self.utility)\n   File \"/opt/conda/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\", line 128, in suggest\n     self._gp.fit(self._space.params, self._space.target)\n   File \"/opt/conda/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py\", line 190, in fit\n     ensure_2d=True, dtype=\"numeric\")\n   File \"/opt/conda/lib/python3.7/site-packages/sklearn/base.py\", line 432, in _validate_data\n     X, y = check_X_y(X, y, **check_params)\n   File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n     return f(**kwargs)\n   File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 805, in check_X_y\n     ensure_2d=False, dtype=None)\n   File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n     return f(**kwargs)\n   File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 645, in check_array\n     allow_nan=force_all_finite == 'allow-nan')\n   File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 99, in _assert_all_finite\n     msg_dtype if msg_dtype is not None else X.dtype)\n ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n </denchmark-code>\n \n My neural network is capable of inf and Nan losses but will not always generate these values. Further I would expect there to be a workaround if it does produce a Nan I just haven't been able to find it.\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):\n I'm in a docker container that is based off the latest pytorch image.\n I'm building Ray from the latest wheel (or the latest from Monday)\n <denchmark-link:https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-1.1.0.dev0-cp37-cp37m-manylinux1_x86_64.whl>https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-1.1.0.dev0-cp37-cp37m-manylinux1_x86_64.whl</denchmark-link>\n \n ray==1.1.0.dev0\n Python 3.7.7\n bayesian-optimization==1.2.0\n If we cannot run your script, we cannot fix your issue.\n \n  I have verified my script runs in a clean environment and reproduces the issue.\n  I have verified the issue also occurs with the latest wheels.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "andrewredd", "commentT": "2020-10-28T18:07:30Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/andrewredd>@andrewredd</denchmark-link>\n  thanks a bunch for raising this issue! We'll be sure to get to this in our 1.0.2 release.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "andrewredd", "commentT": "2020-10-29T00:28:01Z", "comment_text": "\n \t\tThanks Richard, do you know what the rough timeline for 1.0.2 would be?\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Wed, Oct 28, 2020 at 2:07 PM Richard Liaw ***@***.***> wrote:\n  @andrewredd <https://github.com/andrewredd> thanks a bunch for raising\n  this issue! We'll be sure to get to this in our 1.0.2 release.\n \n  \u2014\n  You are receiving this because you were mentioned.\n  Reply to this email directly, view it on GitHub\n  <#11670 (comment)>,\n  or unsubscribe\n  <https://github.com/notifications/unsubscribe-auth/ALQO4BW5G66ZC6Q5YTCHSIDSNBMXDANCNFSM4TCJVTDQ>\n  .\n \n \n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "andrewredd", "commentT": "2020-10-29T00:40:45Z", "comment_text": "\n \t\tIn a month. However, <denchmark-link:https://github.com/andrewredd>@andrewredd</denchmark-link>\n  can you you filter out inf/nan values for now? i.e., if a value is nan or inf, just set it to a very high or very low number?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "andrewredd", "commentT": "2020-10-29T21:28:54Z", "comment_text": "\n \t\tthanks <denchmark-link:https://github.com/richardliaw>@richardliaw</denchmark-link>\n  that resolved my question\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "andrewredd", "commentT": "2020-10-29T23:16:41Z", "comment_text": "\n \t\tlet's keep this open so we can track a fix for improving the error message :)\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "andrewredd", "commentT": "2020-10-29T23:36:22Z", "comment_text": "\n \t\t\ud83d\udc4d\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Thu, Oct 29, 2020 at 7:16 PM Richard Liaw ***@***.***> wrote:\n  let's keep this open so we can track a fix for improving the error message\n  :)\n \n  \u2014\n  You are receiving this because you modified the open/close state.\n  Reply to this email directly, view it on GitHub\n  <#11670 (comment)>,\n  or unsubscribe\n  <https://github.com/notifications/unsubscribe-auth/ALQO4BTBH56JHMYKTLVI4X3SNHZWPANCNFSM4TCJVTDQ>\n  .\n \n \n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "andrewredd", "commentT": "2020-11-09T19:19:47Z", "comment_text": "\n \t\t(opening to address Schedulers)\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "andrewredd", "commentT": "2020-11-09T21:44:52Z", "comment_text": "\n \t\tI tested <denchmark-link:https://github.com/ray-project/ray/pull/11835>#11835</denchmark-link>\n  with schedulers and it seems to work fine. Added unit tests for this as well: <denchmark-link:https://github.com/ray-project/ray/pull/11835/files#diff-3883e3ca074a1c1aa4339e6a35f1baeff54eac485cacf65522b650a5df16c063>https://github.com/ray-project/ray/pull/11835/files#diff-3883e3ca074a1c1aa4339e6a35f1baeff54eac485cacf65522b650a5df16c063</denchmark-link>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "andrewredd", "commentT": "2020-11-09T22:36:04Z", "comment_text": "\n \t\tI think the schedulers will run, but I'm not sure if the behavior is expected (i.e., everything becomes a nan?)\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "andrewredd", "commentT": "2020-11-15T05:41:12Z", "comment_text": "\n \t\tWell, I'll close this for now.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "andrewredd", "commentT": "2020-11-16T13:47:59Z", "comment_text": "\n \t\tHm right, schedulers should filter out NaNs for quantile calculation etc. Let's discuss intended behavior here - if a trial reports NaN e.g. to Hyperband, should it continue to run (assuming it might recover) or stop (assuming it is broken)? It's straightforward for searchers to just ignore results, but schedulers have to make a decision.\n Some possibilities:\n \n Stop trial immediately\n Assign a large negative (for mode=max) or position (for mode=min) value, so the trial might be filtered next time (e.g. in Hyperband) and won't be exploited (in PBT)\n Do nothing (like right now) - might lead to weird results if inf is reported. Here we would put the burden on the user to only report valid values.\n \n It seems low priority since this is a user output validation issue, but I'd opt for option 2 with the possibility to disable this through an ENV variable. It should also log_once if this occurs.\n \t\t"}}}, "commit": {"commit_id": "88be1ea20b0a9b45120e664d4f714f49b8b307a3", "commit_author": "Kai Fricke", "commitT": "2020-11-09 11:18:31-08:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "0.9415204678362573", "commit_Nprams": "0.9064327485380117"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\ray\\tune\\BUILD", "file_new_name": "python\\ray\\tune\\BUILD", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "166,167,168,169,170,171,172,173", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\tune\\analysis\\experiment_analysis.py", "file_new_name": "python\\ray\\tune\\analysis\\experiment_analysis.py", "file_complexity": {"file_NLOC": "586", "file_CCN": "68", "file_NToken": "2314"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "498", "method_info": {"method_name": "get_best_trial", "method_params": "self,None,None,str", "method_startline": "495", "method_endline": "498", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "34", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "499,500", "deleted_lines": "498", "method_info": {"method_name": "get_best_trial", "method_params": "self,None,None,str,bool", "method_startline": "496", "method_endline": "500", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "40", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\ray\\tune\\schedulers\\hyperband.py", "file_new_name": "python\\ray\\tune\\schedulers\\hyperband.py", "file_complexity": {"file_NLOC": "363", "file_CCN": "44", "file_NToken": "2096"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "247,248,253,254", "deleted_lines": "247,252"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\tune\\suggest\\bayesopt.py", "file_new_name": "python\\ray\\tune\\suggest\\bayesopt.py", "file_complexity": {"file_NLOC": "284", "file_CCN": "34", "file_NToken": "1410"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "358,359", "deleted_lines": null, "method_info": {"method_name": "_register_result", "method_params": "self,Dict", "method_startline": "356", "method_endline": "360", "method_complexity": {"method_NLOC": "4", "method_CCN": "2", "method_NToken": "48", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "python\\ray\\tune\\suggest\\dragonfly.py", "file_new_name": "python\\ray\\tune\\suggest\\dragonfly.py", "file_complexity": {"file_NLOC": "324", "file_CCN": "38", "file_NToken": "1323"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "137", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,str,None,None,Dict,None,None,None,None,None,kwargs", "method_startline": "136", "method_endline": "144", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "87", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "360", "method_info": {"method_name": "convert_search_space", "method_params": "Dict", "method_startline": "323", "method_endline": "361", "method_complexity": {"method_NLOC": "13", "method_CCN": "3", "method_NToken": "66", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "137", "deleted_lines": "134", "method_info": {"method_name": "__init__", "method_params": "self,None,None,Dict,None,None,None,None,None,kwargs", "method_startline": "133", "method_endline": "141", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "82", "method_nesting_level": "1"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\tune\\suggest\\skopt.py", "file_new_name": "python\\ray\\tune\\suggest\\skopt.py", "file_complexity": {"file_NLOC": "283", "file_CCN": "35", "file_NToken": "1367"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "274,275,276", "deleted_lines": "272", "method_info": {"method_name": "_process_result", "method_params": "self,str,Dict", "method_startline": "272", "method_endline": "276", "method_complexity": {"method_NLOC": "5", "method_CCN": "3", "method_NToken": "54", "method_nesting_level": "1"}}}}}, "file_6": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "python\\ray\\tune\\tests\\test_searchers.py", "file_complexity": {"file_NLOC": "135", "file_CCN": "18", "file_NToken": "884"}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "python\\ray\\tune\\tests\\test_trial_scheduler.py", "file_new_name": "python\\ray\\tune\\tests\\test_trial_scheduler.py", "file_complexity": {"file_NLOC": "1657", "file_CCN": "252", "file_NToken": "13898"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1939,1940,1941,1942,1943,1944,1945,1946", "deleted_lines": null, "method_info": {"method_name": "testMedianStoppingNanInf", "method_params": "self", "method_startline": "1939", "method_endline": "1946", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "82", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852", "deleted_lines": null, "method_info": {"method_name": "nanInfSetup", "method_params": "self,scheduler,runner", "method_startline": "1839", "method_endline": "1852", "method_complexity": {"method_NLOC": "14", "method_CCN": "4", "method_NToken": "136", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "1948,1949,1950,1951,1952,1953,1954", "deleted_lines": null, "method_info": {"method_name": "testHyperbandNanInf", "method_params": "self", "method_startline": "1948", "method_endline": "1954", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "82", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "1966,1967,1968,1969,1970,1971,1972", "deleted_lines": null, "method_info": {"method_name": "testPBTNanInf", "method_params": "self", "method_startline": "1966", "method_endline": "1972", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "82", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "1956,1957,1958,1959,1960,1961,1962,1963", "deleted_lines": null, "method_info": {"method_name": "testBOHBNanInf", "method_params": "self", "method_startline": "1956", "method_endline": "1963", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "53", "method_nesting_level": "1"}}}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\tune\\utils\\util.py", "file_new_name": "python\\ray\\tune\\utils\\util.py", "file_complexity": {"file_NLOC": "376", "file_CCN": "97", "file_NToken": "2299"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "164,165", "deleted_lines": null, "method_info": {"method_name": "is_nan_or_inf", "method_params": "value", "method_startline": "164", "method_endline": "165", "method_complexity": {"method_NLOC": "2", "method_CCN": "2", "method_NToken": "19", "method_nesting_level": "0"}}}}}}}}