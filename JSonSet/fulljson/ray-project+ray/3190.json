{"BR": {"BR_id": "3190", "BR_author": "robertnishihara", "BRopenT": "2018-11-01T22:08:13Z", "BRcloseT": "2019-10-24T20:13:42Z", "BR_text": {"BRsummary": "[autoscaler] Nodes other than the head node are not starting up.", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Launching from MacOS, but starting Ubuntu 16 (with deep learning AMI)\n Ray installed from (source or binary): source\n Ray version: current master\n Python version: 3.6\n \n My autoscaler config is\n <denchmark-code># An unique identifier for the head node and workers of this cluster.\n cluster_name: default\n \n min_workers: 200\n \n max_workers: 200\n \n docker:\n     image: \"\" # e.g., tensorflow/tensorflow:1.5.0-py3\n     container_name: \"\" # e.g. ray_docker\n \n target_utilization_fraction: 0.8\n \n idle_timeout_minutes: 5\n \n provider:\n     type: aws\n     region: us-west-2\n     availability_zone: us-west-2a,us-west-2b\n \n auth:\n     ssh_user: ubuntu\n \n head_node:\n     InstanceType: m5.2xlarge\n     ImageId: ami-3b6bce43  # Amazon Deep Learning AMI (Ubuntu)\n \n     BlockDeviceMappings:\n         - DeviceName: /dev/sda1\n           Ebs:\n               VolumeSize: 50\n \n worker_nodes:\n     InstanceType: m5.large\n     ImageId: ami-3b6bce43  # Amazon Deep Learning AMI (Ubuntu)\n \n     InstanceMarketOptions:\n         MarketType: spot\n \n file_mounts: {}\n \n setup_commands:\n     - echo 'export PATH=\"$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH\"' >> ~/.bashrc\n     - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.5.3-cp36-cp36m-manylinux1_x86_64.whl\n \n head_setup_commands:\n     - pip install boto3==1.4.8  # 1.4.8 adds InstanceMarketOptions\n \n worker_setup_commands: []\n \n head_start_ray_commands:\n     - ray stop\n     - ulimit -n 65536; ray start --head --redis-port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml\n \n worker_start_ray_commands:\n     - ray stop\n     - ulimit -n 65536; ray start --redis-address=$RAY_HEAD_IP:6379 --object-manager-port=8076\n </denchmark-code>\n \n The head node starts up fine. When I ssh to it and print the monitor logs, I see the following.\n No nodes other than the head node start up.\n <denchmark-code>ubuntu@ip-172-31-22-20:/tmp/ray/session_2018-11-01_22-01-45_16654/logs$ cat monitor.err\n StandardAutoscaler: {'cluster_name': 'mastertest', 'min_workers': 200, 'max_workers': 200, 'docker': {'image': '', 'container_name': ''}, 'target_utilization_fraction': 0.8, 'idle_timeout_minutes': 5, 'provider': {'type': 'aws', 'region': 'us-west-2', 'availability_zone': 'us-west-2a,us-west-2b'}, 'auth': {'ssh_user': 'ubuntu', 'ssh_private_key': '~/ray_bootstrap_key.pem'}, 'head_node': {'InstanceType': 'm5.2xlarge', 'ImageId': 'ami-3b6bce43', 'BlockDeviceMappings': [{'DeviceName': '/dev/sda1', 'Ebs': {'VolumeSize': 50}}], 'IamInstanceProfile': {'Arn': 'arn:aws:iam::339530224232:instance-profile/ray-autoscaler-v1'}, 'KeyName': 'ray-autoscaler_us-west-2', 'SubnetIds': ['subnet-2154c944', 'subnet-4645f631'], 'SecurityGroupIds': ['sg-030b1764c1812e998']}, 'worker_nodes': {'InstanceType': 'm5.large', 'ImageId': 'ami-3b6bce43', 'InstanceMarketOptions': {'MarketType': 'spot'}, 'IamInstanceProfile': {'Arn': 'arn:aws:iam::339530224232:instance-profile/ray-autoscaler-v1'}, 'KeyName': 'ray-autoscaler_us-west-2', 'SubnetIds': ['subnet-2154c944', 'subnet-4645f631'], 'SecurityGroupIds': ['sg-030b1764c1812e998']}, 'file_mounts': {}, 'setup_commands': ['echo \\'export PATH=\"$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH\"\\' >> ~/.bashrc'], 'head_setup_commands': ['pip install boto3==1.4.8'], 'worker_setup_commands': [], 'head_start_ray_commands': ['ray stop', 'ulimit -n 65536; ray start --head --redis-port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml'], 'worker_start_ray_commands': ['ray stop', 'ulimit -n 65536; ray start --redis-address=$RAY_HEAD_IP:6379 --object-manager-port=8076'], 'no_restart': False}\n StandardAutoscaler [2018-11-01 22:01:46.799401]: 0/200 target nodes (0 pending)\n  - NodeIdleSeconds: Min=-1 Mean=-1 Max=-1\n  - NumNodesConnected: 0\n  - NumNodesUsed: 0.0\n  - ResourceUsage: \n  - TimeSinceLastHeartbeat: Min=-1 Mean=-1 Max=-1\n StandardAutoscaler: Launching 5 new nodes\n StandardAutoscaler [2018-11-01 22:01:46.830794]: 0/200 target nodes (5 pending)\n  - NodeIdleSeconds: Min=-1 Mean=-1 Max=-1\n  - NumNodesConnected: 0\n  - NumNodesUsed: 0.0\n  - ResourceUsage: \n  - TimeSinceLastHeartbeat: Min=-1 Mean=-1 Max=-1\n Exception in thread Thread-1:\n Traceback (most recent call last):\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n     self.run()\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/autoscaler.py\", line 251, in run\n     self._launch_node(config, count)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/autoscaler.py\", line 242, in _launch_node\n     }, count)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/aws/node_provider.py\", line 163, in create_node\n     self.ec2.create_instances(**conf)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/boto3/resources/factory.py\", line 520, in do_action\n     response = action(self, *args, **kwargs)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/boto3/resources/action.py\", line 83, in __call__\n     response = getattr(parent.meta.client, operation_name)(**params)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n     return self._make_api_call(operation_name, kwargs)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n     raise error_class(parsed_response, operation_name)\n botocore.exceptions.ClientError: An error occurred (UnauthorizedOperation) when calling the RunInstances operation: You are not authorized to perform this operation. Encoded authorization failure message: JUmMphVKvdVLB83WorEP2n5lOkl7LJT5E1K6lCJAxAjpvkJzdk--3vcnRXFh0Yj6Ez-XjrAda9hU472FJ_o2JIzby0EqMD2WD_qg7SqlgmahgDWBSwxOu4uCn_Py-OV1Cwj6XqFy6xJ9QcqsIfttWB9DstSHNQR_8y6SZ0-KYgUzzP51lLcYbTm2CK-D5mghExYd30aoyIV1YQpZ_8JyudvA8JhOFGVNrAIsYK_fT0iqsJOalAeTJAu-TUQNFxzUW6NENFT6xfN3bov6MPB2z0UvnFkMzH9fyerYzUXblO0qzdoEgyfxhcvhnq-7Dd6OJIBlycL5QF2XnR8czqmiSE3aQ09USKgKj1Oaru04EonLCRr64oVKMqpR80jTIGET7TTKDy-qqra-_uS2oQajd0T21V_y__GB7197KlSMi6JPSFHni7H6pZxOp3YTOneNBCydPrHCEmf6OFrbBtD7US-xIo_mW-LWMfHygRINgdAlPTQxBNfCWNpd7Mo9TK_02i0uNQaxR2Eb4sHQgPjWRRyN1gtsEA\n \n StandardAutoscaler [2018-11-01 22:01:51.687415]: 0/200 target nodes (0 pending)\n  - NodeIdleSeconds: Min=4 Mean=4 Max=4\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 5 new nodes\n StandardAutoscaler [2018-11-01 22:01:51.703377]: 0/200 target nodes (5 pending)\n  - NodeIdleSeconds: Min=4 Mean=4 Max=4\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n Exception in thread Thread-2:\n Traceback (most recent call last):\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n     self.run()\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/autoscaler.py\", line 251, in run\n     self._launch_node(config, count)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/autoscaler.py\", line 242, in _launch_node\n     }, count)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/aws/node_provider.py\", line 163, in create_node\n     self.ec2.create_instances(**conf)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/boto3/resources/factory.py\", line 520, in do_action\n     response = action(self, *args, **kwargs)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/boto3/resources/action.py\", line 83, in __call__\n     response = getattr(parent.meta.client, operation_name)(**params)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\", line 314, in _api_call\n     return self._make_api_call(operation_name, kwargs)\n   File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\", line 612, in _make_api_call\n     raise error_class(parsed_response, operation_name)\n botocore.exceptions.ClientError: An error occurred (UnauthorizedOperation) when calling the RunInstances operation: You are not authorized to perform this operation. Encoded authorization failure message: QOnTis6VbTYrt-07yg40sRrg8_SPtfkGI7lGq8R4bvzaISfzl48BMA5e6PeMiilTnDI40xDfLhJCVrCBIvvPoKljhdk-fssOX9yc174zfGLQRWZZGra1F8P3_bAEaAZn-KlWMZKbfh2XPeMw6U83Lbln2wuEWNaTxydbXyO4ADjz9PUsyXDijXopkp7VylGRBNcQy20718--eGZ5kIZlc5BJ40YTFU9JfaiMGLWTAV_hNcUrB5DOAtklZI4de4tYjxt88imIpp-slkiTbtJXcP4--bU1keOqIgbIP5vZMTrECvo95av4Tyq2BsydvK4PVviQSpqnZ9FlFUJi232jrxNYoH7-meIqGRsU9Xl715WOos2Yorgfqp5KyJn_aaxwWzwdPReN_aaIetpmQHJJtUj6c5R5jiJxtl9LxJNicT47JHvmPyJYb4iYNFHdAUMcrJryQCvZ6aNvz9IiG5ZVXyueSabABGskplcTZkpQ9wEib0kGbMyBncGR9kyAkmHrqOcauAjx1qpGawbrz16JXUED1FZJfQ\n \n StandardAutoscaler [2018-11-01 22:01:56.744077]: 0/200 target nodes (0 pending)\n  - NodeIdleSeconds: Min=9 Mean=9 Max=9\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 5 new nodes\n StandardAutoscaler [2018-11-01 22:01:56.767962]: 0/200 target nodes (5 pending)\n  - NodeIdleSeconds: Min=9 Mean=9 Max=9\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler [2018-11-01 22:02:01.814536]: 0/200 target nodes (5 pending)\n  - NodeIdleSeconds: Min=14 Mean=14 Max=14\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 5 new nodes\n StandardAutoscaler [2018-11-01 22:02:01.841278]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=14 Mean=14 Max=14\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler [2018-11-01 22:02:06.875743]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=19 Mean=19 Max=19\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 0 new nodes\n StandardAutoscaler [2018-11-01 22:02:06.893544]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=19 Mean=19 Max=19\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler [2018-11-01 22:02:11.929128]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=24 Mean=24 Max=24\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 0 new nodes\n StandardAutoscaler [2018-11-01 22:02:11.945196]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=25 Mean=25 Max=25\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler [2018-11-01 22:02:16.983206]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=30 Mean=30 Max=30\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 0 new nodes\n StandardAutoscaler [2018-11-01 22:02:16.997781]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=30 Mean=30 Max=30\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler [2018-11-01 22:02:22.051389]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=35 Mean=35 Max=35\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 0 new nodes\n StandardAutoscaler [2018-11-01 22:02:22.067704]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=35 Mean=35 Max=35\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler [2018-11-01 22:02:27.109345]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=40 Mean=40 Max=40\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 0 new nodes\n StandardAutoscaler [2018-11-01 22:02:27.125878]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=40 Mean=40 Max=40\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler [2018-11-01 22:02:32.157747]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=45 Mean=45 Max=45\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n StandardAutoscaler: Launching 0 new nodes\n StandardAutoscaler [2018-11-01 22:02:32.172933]: 0/200 target nodes (10 pending)\n  - NodeIdleSeconds: Min=45 Mean=45 Max=45\n  - NumNodesConnected: 1\n  - NumNodesUsed: 0.0\n  - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'\n  - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0\n </denchmark-code>\n \n For some reason, the non-head nodes are not starting up. Any ideas about this?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "robertnishihara", "commentT": "2018-11-01T22:09:23Z", "comment_text": "\n \t\tcc <denchmark-link:https://github.com/ericl>@ericl</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "robertnishihara", "commentT": "2018-11-01T22:41:23Z", "comment_text": "\n \t\tThe error says Unauthorized... Can you check if this works in 0.5.3? I wonder if it's a Ray change or an AWS issue.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "robertnishihara", "commentT": "2018-11-01T23:38:24Z", "comment_text": "\n \t\tIt seems to work for 0.5.3.\n EDIT: It also works when you call ray up using the current master, but pip install 0.5.3 on the cluster.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "robertnishihara", "commentT": "2018-11-01T23:53:07Z", "comment_text": "\n \t\tOk it might be <denchmark-link:https://github.com/ray-project/ray/pull/3118>#3118</denchmark-link>\n \n But I don't know why that would be the case.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "robertnishihara", "commentT": "2018-11-01T23:53:46Z", "comment_text": "\n \t\tOh, maybe the head doesn't have permission to grant the workers its own profile. We can probably just revert that PR then.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "robertnishihara", "commentT": "2019-05-10T01:46:44Z", "comment_text": "\n \t\tHello,\n I seem to be hitting this problem. The cluster starts with two workers but doesn't start more even though the two workers are near-100% utilisation.\n I'm using ray 0.7.0.dev2 and Python 3.6 on Ubuntu.\n My yaml file:\n <denchmark-code># An unique identifier for the head node and workers of this cluster.\n cluster_name: default\n \n # The minimum number of workers nodes to launch in addition to the head\n # node. This number should be >= 0.\n min_workers: 0\n \n # The maximum number of workers nodes to launch in addition to the head\n # node. This takes precedence over min_workers.\n max_workers: 10\n \n # The initial number of worker nodes to launch in addition to the head\n # node. When the cluster is first brought up (or when it is refreshed with a\n # subsequent `ray up`) this number of nodes will be started.\n initial_workers: 2\n \n # Whether or not to autoscale aggressively. If this is enabled, if at any point\n #   we would start more workers, we start at least enough to bring us to\n #   initial_workers.\n # autoscaling_mode: default\n \n # This executes all commands on all nodes in the docker container,\n # and opens all the necessary ports to support the Ray cluster.\n # Empty string means disabled.\n docker:\n     image: \"\" # e.g., tensorflow/tensorflow:1.5.0-py3\n     container_name: \"\" # e.g. ray_docker\n     run_options: []  # Extra options to pass into \"docker run\"\n \n     # Example of running a GPU head with CPU workers\n     # head_image: \"tensorflow/tensorflow:1.13.1-py3\"\n     # head_run_options:\n     #     - --runtime=nvidia\n \n     # worker_image: \"ubuntu:18.04\"\n     # worker_run_options: []\n \n # The autoscaler will scale up the cluster to this target fraction of resource\n # usage. For example, if a cluster of 10 nodes is 100% busy and\n # target_utilization is 0.8, it would resize the cluster to 13. This fraction\n # can be decreased to increase the aggressiveness of upscaling.\n # This value must be less than 1.0 for scaling to happen.\n target_utilization_fraction: 0.8\n \n # If a node is idle for this many minutes, it will be removed.\n idle_timeout_minutes: 5\n \n # Cloud-provider specific configuration.\n provider:\n     type: aws\n     region: us-west-2\n     # Availability zone(s), comma-separated, that nodes may be launched in.\n     # Nodes are currently spread between zones by a round-robin approach,\n     # however this implementation detail should not be relied upon.\n     availability_zone: us-west-2a,us-west-2b\n \n # How Ray will authenticate with newly launched nodes.\n auth:\n     ssh_user: ubuntu\n # By default Ray creates a new private keypair, but you can also use your own.\n # If you do so, make sure to also set \"KeyName\" in the head and worker node\n # configurations below.\n #    ssh_private_key: /path/to/your/key.pem\n \n # Provider-specific config for the head node, e.g. instance type. By default\n # Ray will auto-configure unspecified fields such as SubnetId and KeyName.\n # For more documentation on available fields, see:\n # http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances\n head_node:\n     InstanceType: m5.2xlarge\n     ImageId: ami-0b5a1e5a79033f015  # ray-cluster-template in us-west-2\n \n     # You can provision additional disk space with a conf as follows\n     # BlockDeviceMappings:\n     #     - DeviceName: /dev/sda1\n     #       Ebs:\n     #           VolumeSize: 100\n \n     # Additional options in the boto docs.\n \n # Provider-specific config for worker nodes, e.g. instance type. By default\n # Ray will auto-configure unspecified fields such as SubnetId and KeyName.\n # For more documentation on available fields, see:\n # http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances\n worker_nodes:\n     InstanceType: m5.2xlarge\n     ImageId: ami-0b5a1e5a79033f015  # ray-cluster-template in us-west-2\n \n     # Run workers on spot by default. Comment this out to use on-demand.\n     InstanceMarketOptions:\n         MarketType: spot\n         # Additional options can be found in the boto docs, e.g.\n         #   SpotOptions:\n         #       MaxPrice: MAX_HOURLY_PRICE\n \n     # Additional options in the boto docs.\n \n # Files or directories to copy to the head and worker nodes. The format is a\n # dictionary from REMOTE_PATH: LOCAL_PATH, e.g.\n file_mounts: {\n    \"/home/ubuntu/HeLa_20KInt-rt-4340-4580-denoised/HeLa_20KInt.sqlite\": \"/Users/darylwilding-mcbride/Downloads/HeLa_20KInt-rt-4340-4580-denoised/HeLa_20KInt.sqlite\",\n    \"/home/ubuntu/denoised-HeLa_20KInt_2KIT_Slot1-46_01_1179.d/analysis.tdf\": \"/Users/darylwilding-mcbride/Downloads/denoised-HeLa_20KInt_2KIT_Slot1-46_01_1179.d/analysis.tdf\",\n    \"/home/ubuntu/feature-extraction-from-PASEF-isolation-windows.py\": \"/Users/darylwilding-mcbride/Documents/otf-peak-detect/experiments/feature-extraction-from-PASEF-isolation-windows.py\"\n }\n \n # List of commands that will be run before `setup_commands`. If docker is\n # enabled, these commands will run outside the container and before docker\n # is setup.\n initialization_commands: []\n \n # List of shell commands to run to set up nodes.\n setup_commands:\n     # Note: if you're developing Ray, you probably want to create an AMI that\n     # has your Ray repo pre-cloned. Then, you can replace the pip installs\n     # below with a git checkout <your_sha> (and possibly a recompile).\n     - echo 'hello'\n     # - echo 'export PATH=\"$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH\"' >> ~/.bashrc\n     # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.7.0.dev2-cp27-cp27mu-manylinux1_x86_64.whl\n     # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.7.0.dev2-cp35-cp35m-manylinux1_x86_64.whl\n     # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.7.0.dev2-cp36-cp36m-manylinux1_x86_64.whl\n     # Consider uncommenting these if you also want to run apt-get commands during setup\n     # - sudo pkill -9 apt-get || true\n     # - sudo pkill -9 dpkg || true\n     # - sudo dpkg --configure -a\n \n # Custom commands that will be run on the head node after common setup.\n head_setup_commands:\n     - pip install boto3==1.4.8  # 1.4.8 adds InstanceMarketOptions\n \n # Custom commands that will be run on worker nodes after common setup.\n worker_setup_commands: []\n \n # Command to start ray on the head node. You don't need to change this.\n head_start_ray_commands:\n     - ray stop\n     - ulimit -n 65536; ray start --head --redis-port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml\n \n # Command to start ray on worker nodes. You don't need to change this.\n worker_start_ray_commands:\n     - ray stop\n     - ulimit -n 65536; ray start --redis-address=$RAY_HEAD_IP:6379 --object-manager-port=8076\n \n </denchmark-code>\n \n A monitor log fragment:\n <denchmark-code>2019-05-10 01:27:12,573\tINFO autoscaler.py:630 -- StandardAutoscaler: 2/0 target nodes (0 pending)\n 2019-05-10 01:27:12,573\tINFO autoscaler.py:631 -- LoadMetrics: MostDelayedHeartbeats={'172.31.41.98': 0.17139339447021484, '172.31.40.64': 0.17134618759155273, '172.31.36.240': 0.17130565643310547}, NodeIdleSeconds=Min=14 Mean=151 Max=419, NumNodesConnected=3, NumNodesUsed=0.0, ResourceUsage=, TimeSinceLastHeartbeat=Min=0 Mean=0 Max=0\n 2019-05-10 01:27:12,574\tINFO autoscaler.py:456 -- Ending bringup phase\n 2019-05-10 01:27:17,578\tINFO autoscaler.py:630 -- StandardAutoscaler: 2/0 target nodes (0 pending)\n 2019-05-10 01:27:17,579\tINFO autoscaler.py:631 -- LoadMetrics: MostDelayedHeartbeats={'172.31.41.98': 0.17473340034484863, '172.31.40.64': 0.17469072341918945, '172.31.36.240': 0.174652099609375}, NodeIdleSeconds=Min=19 Mean=156 Max=424, NumNodesConnected=3, NumNodesUsed=0.0, ResourceUsage=, TimeSinceLastHeartbeat=Min=0 Mean=0 Max=0\n 2019-05-10 01:27:17,579\tINFO autoscaler.py:456 -- Ending bringup phase\n 2019-05-10 01:27:22,688\tINFO autoscaler.py:630 -- StandardAutoscaler: 2/0 target nodes (0 pending)\n 2019-05-10 01:27:22,688\tINFO autoscaler.py:631 -- LoadMetrics: MostDelayedHeartbeats={'172.31.41.98': 0.20582270622253418, '172.31.40.64': 0.2057802677154541, '172.31.36.240': 0.20574188232421875}, NodeIdleSeconds=Min=0 Mean=153 Max=429, NumNodesConnected=3, NumNodesUsed=0.0, ResourceUsage=, TimeSinceLastHeartbeat=Min=0 Mean=0 Max=0\n 2019-05-10 01:27:22,688\tINFO autoscaler.py:456 -- Ending bringup phase\n \n </denchmark-code>\n \n The worker node utilisation:\n <denchmark-link:https://user-images.githubusercontent.com/1016303/57496960-ef237b00-7318-11e9-90d8-d50c1a143654.png></denchmark-link>\n \n NumNodesUsed and ResourceUsage don't seem right when worker utilisation is well above 0.8 average.\n \t\t"}}}, "commit": {"commit_id": "2bef9844bf99e4cfe6f4dd041ec4774ede9d4af4", "commit_author": "Eric Liang", "commitT": "2018-11-01 23:23:06-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\autoscaler\\aws\\config.py", "file_new_name": "python\\ray\\autoscaler\\aws\\config.py", "file_complexity": {"file_NLOC": "233", "file_CCN": "49", "file_NToken": "1453"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "104", "method_info": {"method_name": "_configure_iam_role", "method_params": "config", "method_startline": "57", "method_endline": "106", "method_complexity": {"method_NLOC": "44", "method_CCN": "5", "method_NToken": "248", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\autoscaler\\gcp\\config.py", "file_new_name": "python\\ray\\autoscaler\\gcp\\config.py", "file_complexity": {"file_NLOC": "265", "file_CCN": "54", "file_NToken": "1798"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "173,174,175,176", "deleted_lines": "171,172,173,174,177,178,179,180", "method_info": {"method_name": "_configure_iam_role", "method_params": "config", "method_startline": "145", "method_endline": "180", "method_complexity": {"method_NLOC": "17", "method_CCN": "2", "method_NToken": "99", "method_nesting_level": "0"}}}}}}}}