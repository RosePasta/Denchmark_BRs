{"BR": {"BR_id": "11296", "BR_author": "bcahlit", "BRopenT": "2020-10-09T04:57:02Z", "BRcloseT": "2020-11-02T11:22:34Z", "BR_text": {"BRsummary": "[rllib] EpsilonGreedy with nested_action_spaces ERROR: Substructure \"type=tuple str=(Discrete(3), Box(1,), Box(1,), Box(1,))\" is a sequence, while substructure \"type=int64 str=1\" is not Entire first structure:", "BRdescription": "\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n EpsilonGreedy Does not work with nested_action_spaces\n Ray version and other system information (Python version, TensorFlow version, OS):\n Ray : 1.0.0\n python: 3.8.5\n pytorch: 1.6.0\n OS: Linux 5.8.11\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):\n just add EpsilonGreedy in nested_action_spaces.py\n import argparse\n from gym.spaces import Dict, Tuple, Box, Discrete\n \n import ray\n import numpy as np\n import ray.tune as tune\n from ray.tune.registry import register_env\n from ray.rllib.examples.env.nested_space_repeat_after_me_env import \\\n     NestedSpaceRepeatAfterMeEnv\n from ray.rllib.utils.test_utils import check_learning_achieved\n \n parser = argparse.ArgumentParser()\n parser.add_argument(\"--run\", type=str, default=\"PPO\")\n parser.add_argument(\"--torch\", action=\"store_true\")\n parser.add_argument(\"--as-test\", action=\"store_true\")\n parser.add_argument(\"--stop-reward\", type=float, default=0.0)\n parser.add_argument(\"--stop-iters\", type=int, default=100)\n parser.add_argument(\"--stop-timesteps\", type=int, default=100000)\n parser.add_argument(\"--num-cpus\", type=int, default=0)\n \n if __name__ == \"__main__\":\n     args = parser.parse_args()\n     ray.init(num_cpus=args.num_cpus or None)\n     register_env(\"NestedSpaceRepeatAfterMeEnv\",\n                  lambda c: NestedSpaceRepeatAfterMeEnv(c))\n \n     low = np.array([-180], dtype=np.float32)\n     high = np.array([180], dtype=np.float32)\n     config = {\n         \"env\": \"NestedSpaceRepeatAfterMeEnv\",\n         \"env_config\": {\n             \"space\": Tuple((Discrete(3), Box(low=low, high=high, dtype=np.float32),\n                            Box(low=low, high=high, dtype=np.float32),\n                            Box(low=low, high=high, dtype=np.float32)))\n         },\n         \"exploration_config\": {\n            \"type\": \"EpsilonGreedy\",\n            \"initial_epsilon\": 1.0,\n            \"final_epsilon\": 0.02,\n            \"epsilon_timesteps\": 10000,  # Timesteps over which to anneal epsilon.\n         },\n         \"entropy_coeff\": 0.00005,  # We don't want high entropy in this Env.\n         \"gamma\": 0.0,  # No history in Env (bandit problem).\n         \"lr\": 0.0005,\n         \"num_envs_per_worker\": 20,\n         \"num_sgd_iter\": 4,\n         \"num_workers\": 0,\n         \"vf_loss_coeff\": 0.01,\n         \"framework\": \"torch\" if args.torch else \"tf\",\n     }\n \n     stop = {\n         \"training_iteration\": args.stop_iters,\n         \"episode_reward_mean\": args.stop_reward,\n         \"timesteps_total\": args.stop_timesteps,\n     }\n \n     results = tune.run(args.run, config=config, stop=stop)\n \n     if args.as_test:\n         check_learning_achieved(results, args.stop_reward)\n \n     ray.shutdown()\n error.txt:\n Failure # 1 (occurred at 2020-10-09_12-10-54)\n Traceback (most recent call last):\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n     result = self.trial_executor.fetch_result(trial)\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n     result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n     raise value.as_instanceof_cause()\n ray.exceptions.RayTaskError(ValueError): ray::PPO.train() (pid=150173, ip=192.168.123.147)\n ValueError: The two structures don't have the same nested structure.\n \n First structure: type=int64 str=1\n \n Second structure: type=tuple str=(Discrete(3), Box(1,), Box(1,), Box(1,))\n \n More specifically: Substructure \"type=tuple str=(Discrete(3), Box(1,), Box(1,), Box(1,))\" is a sequence, while substructure \"type=int64 str=1\" is not\n \n During handling of the above exception, another exception occurred:\n \n ray::PPO.train() (pid=150173, ip=192.168.123.147)\n   File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 519, in train\n     raise e\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n     result = Trainable.train(self)\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n     result = self.step()\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n     res = next(self.train_exec_impl)\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n     return next(self.built_iterator)\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n     for item in it:\n   [Previous line repeated 1 more time]\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n     item = next(it)\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n     for item in it:\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/execution/rollout_ops.py\", line 70, in sampler\n     yield workers.local_worker().sample()\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n     batches = [self.input_reader.next()]\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n     batches = [self.get_data()]\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n     item = next(self.rollout_provider)\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 632, in _env_runner\n     _process_policy_eval_results(\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 1411, in _process_policy_eval_results\n     clipped_action = clip_action(action,\n   File \"/home/bcahlit/anaconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/policy/policy.py\", line 532, in clip_action\n     return tree.map_structure(map_, action, action_space)\n   File \"/home/bcahlit/.local/lib/python3.8/site-packages/tree/__init__.py\", line 513, in map_structure\n     assert_same_structure(structures[0], other, check_types=check_types)\n   File \"/home/bcahlit/.local/lib/python3.8/site-packages/tree/__init__.py\", line 369, in assert_same_structure\n     raise type(e)(\"%s\\n\"\n ValueError: The two structures don't have the same nested structure.\n \n First structure: type=int64 str=1\n \n Second structure: type=tuple str=(Discrete(3), Box(1,), Box(1,), Box(1,))\n \n More specifically: Substructure \"type=tuple str=(Discrete(3), Box(1,), Box(1,), Box(1,))\" is a sequence, while substructure \"type=int64 str=1\" is not\n Entire first structure:\n .\n Entire second structure:\n (., ., ., .)\n \n print(action, action_space) in <denchmark-link:https://github.com/ray-project/ray/rllib/policy/policy.py#L555>https://github.com/ray-project/ray/rllib/policy/policy.py#L555</denchmark-link>\n \n show: 1 (Discrete(3), Box(1,), Box(1,), Box(1,))\n I think it should be a matter of exploration strategy. Can you help me fix this problem? Thanks\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "bcahlit", "commentT": "2020-10-09T14:26:27Z", "comment_text": "\n \t\tThe DiagGaussian fluctuation is too small to meet the exploration needs of my environment. So I want to use EpsilonGreedy. My needs can only customize the action distribution class, right?\n \t\t"}}}, "commit": {"commit_id": "26176ec5706cc7b3c153676554e6f51f071bf545", "commit_author": "bcahlit", "commitT": "2020-11-02 12:22:33+01:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "rllib\\utils\\exploration\\epsilon_greedy.py", "file_new_name": "rllib\\utils\\exploration\\epsilon_greedy.py", "file_complexity": {"file_NLOC": "144", "file_CCN": "6", "file_NToken": "971"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "128,129,130", "method_info": {"method_name": "_get_torch_exploration_action", "method_params": "self,TensorType,bool,int", "method_startline": "128", "method_endline": "130", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "22", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "82,83", "deleted_lines": "82", "method_info": {"method_name": "_get_tf_exploration_action_op", "method_params": "self,TensorType,bool,int", "method_startline": "82", "method_endline": "84", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "27", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "136,137,138", "deleted_lines": null, "method_info": {"method_name": "_get_torch_exploration_action", "method_params": "self,ActionDistribution,bool,int", "method_startline": "136", "method_endline": "138", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "22", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "85,86", "deleted_lines": "88", "method_info": {"method_name": "_get_tf_exploration_action_op", "method_params": "self,ActionDistribution,bool,int", "method_startline": "85", "method_endline": "88", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "27", "method_nesting_level": "1"}}}}}}}}