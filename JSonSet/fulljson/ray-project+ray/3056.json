{"BR": {"BR_id": "3056", "BR_author": "pcmoritz", "BRopenT": "2018-10-14T02:18:29Z", "BRcloseT": "2018-10-18T01:01:04Z", "BR_text": {"BRsummary": "Potential problem with actor handles", "BRdescription": "\n The following crashes XRay and makes legacy ray hang:\n import ray\n \n ray.init(use_raylet=True)\n \n @ray.remote\n class Actor(object):\n     def f(self):\n         return 1\n \n @ray.remote\n class Bctor(object):\n     def __init__(self, constructor):\n         self.actor = constructor()\n \n     def step(self):\n         ray.get(self.actor.f.remote())\n \n a = Actor.remote()\n \n b = Bctor.remote(lambda: a)\n \n ray.get(b.step.remote())\n ray.get(b.step.remote())\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "pcmoritz", "commentT": "2018-10-14T19:55:50Z", "comment_text": "\n \t\tCan you explain what the issue is? This looks like it should work.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "pcmoritz", "commentT": "2018-10-14T20:02:51Z", "comment_text": "\n \t\tThe symptom is this:\n <denchmark-code>F1014 12:59:52.206046 2571563904 node_manager.cc:72]  Check failed: spec.ActorCounter() == expected_task_counter Expected actor counter: 0, got: 1\n *** Check failure stack trace: ***\n     @        0x10a4cc82d  google::LogMessage::Fail()\n     @        0x10a4ca64e  google::LogMessage::SendToLog()\n     @        0x10a4cb4cf  google::LogMessage::Flush()\n     @        0x10a4cb309  google::LogMessage::~LogMessage()\n     @        0x10a4cb5c5  google::LogMessage::~LogMessage()\n     @        0x10a42c3dd  ray::RayLog::~RayLog()\n     @        0x10a47b417  ray::raylet::NodeManager::AssignTask()\n     @        0x10a47ab08  ray::raylet::NodeManager::DispatchTasks()\n     @        0x10a4828b1  ray::raylet::NodeManager::EnqueuePlaceableTask()\n     @        0x10a479abc  ray::raylet::NodeManager::SubmitTask()\n     @        0x10a47eaef  ray::raylet::NodeManager::ProcessSubmitTaskMessage()\n     @        0x10a47cbd9  ray::raylet::NodeManager::ProcessClientMessage()\n     @        0x10a3de63c  std::__1::__function::__func<>::operator()()\n     @        0x10a42d853  ray::ClientConnection<>::ProcessMessage()\n     @        0x10a430db8  boost::asio::detail::reactive_socket_recv_op<>::do_complete()\n     @        0x10a3d05b8  boost::asio::detail::task_io_service::do_run_one()\n     @        0x10a3d0121  boost::asio::detail::task_io_service::run()\n     @        0x10a3cb7de  main\n </denchmark-code>\n \n New actor handle IDs are being created that are not registered in the backend. One possibility is that every time we call compute_actor_handle_id_non_forked, the actor counter needs to be reset too. But not sure if that's the right fix.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "pcmoritz", "commentT": "2018-10-14T20:24:43Z", "comment_text": "\n \t\tThis  be the same as <denchmark-link:https://github.com/ray-project/ray/issues/2115>#2115</denchmark-link>\n .\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "pcmoritz", "commentT": "2018-10-15T06:06:54Z", "comment_text": "\n \t\tHmm, I'm not really sure why this is happening since it looks like the actor counter should get reset <denchmark-link:https://github.com/ray-project/ray/blob/master/python/ray/actor.py#L662>here</denchmark-link>\n . Can you check to make sure that that line is getting hit?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "pcmoritz", "commentT": "2018-10-15T06:18:03Z", "comment_text": "\n \t\tIt does get reset, but only when the actor handle is unpickled. However every time a method on the unpickled actor handle is called, a new actor handle is created by compute_actor_handle_id_non_forked and for that, the counter is not reset. See here: <denchmark-link:https://github.com/ray-project/ray/blob/master/python/ray/actor.py#L558>https://github.com/ray-project/ray/blob/master/python/ray/actor.py#L558</denchmark-link>\n \n It seems to me very dangerous to create a new actor handle id every time we call an actor handle. This can easily lead to blowup of datastructures in the raylet.\n Maybe actor_handle_id was supposed to be assigned to self._ray_actor_handle_id in the line above?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "pcmoritz", "commentT": "2018-10-15T17:15:36Z", "comment_text": "\n \t\tThat seems like a bug; the actor handle should only get created once, when the handle is first unpickled. I believe that we should be setting  earlier, somewhere around <denchmark-link:https://github.com/ray-project/ray/blob/master/python/ray/actor.py#L697>here</denchmark-link>\n . I don't really understand the use of  in that code, though.\n <denchmark-link:https://github.com/robertnishihara>@robertnishihara</denchmark-link>\n , it looks like you wrote that commit. Can you explain what happens when  and why it is necessary?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "pcmoritz", "commentT": "2018-10-15T18:47:32Z", "comment_text": "\n \t\tCreating a new actor handle was intentional. There are a couple cases:\n \n \n We pass an actor handle into a task/actor. This is the forking=True case. It creates a new actor handle for the task/actor. In this case we generate the new actor handle ID deterministically.\n \n \n A remote function or actor class includes an actor handle in its closure (but the actor handle is not passed in). When the remote function or actor class is unpickled, we create an \"uninitialized\" actor handle. Then when a task actually tries to use the actor handle, we generate a new actor handle ID for it (deterministically based on the actor task ID). Note that we can't generate the actor handle ID deterministically when the actor handle is unpickled because it can be unpickled on multiple workers.\n \n \n If we want to generate actor handle IDs deterministically, then we need a separate one per task (or per actor) that uses the actor handle (we currently also do one per actor method to simplify the code, so we could reduce the redundancy a bit in the actor case).\n \n There's a third case where someone just pickles an actor handle and then unpickles it somewhere else (e.g., a different driver). This is the same code path as case 2.\n \n <denchmark-link:https://github.com/pcmoritz>@pcmoritz</denchmark-link>\n  is right that there is a performance issue here with the explosion of actor handles. I may be overlooking some simple solution. Ideally we'd just find a way to make actor handles super lightweight.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "pcmoritz", "commentT": "2018-10-15T19:02:18Z", "comment_text": "\n \t\tOne possibility might be to have pickled actor handles essentially not have any dependencies with other actor handles, they only maintain a local count of methods that have been invoked and the count is reset every time a new task starts.\n Also, one thing I wasn't sure how to handle (and which currently breaks) is what to do when an actor handle is unpickled multiple times in the same task.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "pcmoritz", "commentT": "2018-10-18T01:01:04Z", "comment_text": "\n \t\tFixed by <denchmark-link:https://github.com/ray-project/ray/pull/3074>#3074</denchmark-link>\n .\n \t\t"}}}, "commit": {"commit_id": "2c52d9dfa043a168a00d0fe2083c73cef4b82228", "commit_author": "Philipp Moritz", "commitT": "2018-10-17 18:00:52-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\ray\\actor.py", "file_new_name": "python\\ray\\actor.py", "file_complexity": {"file_NLOC": "494", "file_CCN": "55", "file_NToken": "2492"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "504,558,559,560,561,562,567,568,569,570,571,572,573", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "test\\actor_test.py", "file_new_name": "test\\actor_test.py", "file_complexity": {"file_NLOC": "1450", "file_CCN": "347", "file_NToken": "11383"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990", "deleted_lines": null, "method_info": {"method_name": "test_pickled_actor_handle_call_in_method_twice", "method_params": "ray_start_regular", "method_startline": "1971", "method_endline": "1990", "method_complexity": {"method_NLOC": "12", "method_CCN": "1", "method_NToken": "72", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "1982,1983", "deleted_lines": null, "method_info": {"method_name": "test_pickled_actor_handle_call_in_method_twice.step", "method_params": "self", "method_startline": "1982", "method_endline": "1983", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "19", "method_nesting_level": "2"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "1979,1980", "deleted_lines": null, "method_info": {"method_name": "test_pickled_actor_handle_call_in_method_twice.__init__", "method_params": "self,constructor", "method_startline": "1979", "method_endline": "1980", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "14", "method_nesting_level": "2"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "1974,1975", "deleted_lines": null, "method_info": {"method_name": "test_pickled_actor_handle_call_in_method_twice.f", "method_params": "self", "method_startline": "1974", "method_endline": "1975", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "7", "method_nesting_level": "2"}}}}}}}}