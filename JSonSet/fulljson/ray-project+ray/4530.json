{"BR": {"BR_id": "4530", "BR_author": "jacooba", "BRopenT": "2019-04-01T14:14:14Z", "BRcloseT": "2019-04-07T19:11:31Z", "BR_text": {"BRsummary": "[rllib] Value Error with long RNN seq in Single Env", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\n Ray installed from (source or binary): source\n Ray version: 0.6.2\n Python version: 3.5.5\n Exact command to reproduce: (running on custom env)\n \n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n When running with a single environment, load_data() in multi_gpu_impl.py throws an error, since self._loaded_max_seq_len is larger than self.max_per_device_batch_size. self._loaded_max_seq_len is 496 (but varies) and self.max_per_device_batch_size is 201, which is set by sgd_minibatch_size in yaml file. However, I believe self._loaded_max_seq_len should be truncated to 200, since sample_batch_size is 200 in the yaml. When I increase the number of environments per worker to 2 or 4, self._loaded_max_seq_len is always truncated to 200. For 1 env, why are my sequences (length 496) longer than 200?\n <denchmark-h:h3>Source code / logs</denchmark-h>\n \n self.max_per_device_batch_size: 201\n self._loaded_max_seq_len 496\n seq_batch_size: 0\n len(self.devices): 1\n 2019-04-01 14:53:10,232\tERROR trial_runner.py:412 -- Error processing event.\n Traceback (most recent call last):\n File \"/home/jake/ray/python/ray/tune/trial_runner.py\", line 378, in _process_events\n result = self.trial_executor.fetch_result(trial)\n File \"/home/jake/ray/python/ray/tune/ray_trial_executor.py\", line 228, in fetch_result\n result = ray.get(trial_future[0])\n File \"/home/jake/ray/python/ray/worker.py\", line 2210, in get\n raise value\n ray.worker.RayTaskError: ray_worker (pid=131044, host=jake-Virtual-Machine)\n File \"/home/jake/ray/python/ray/rllib/agents/agent.py\", line 274, in train\n result = Trainable.train(self)\n File \"/home/jake/ray/python/ray/tune/trainable.py\", line 151, in train\n result = self._train()\n File \"/home/jake/ray/python/ray/rllib/agents/ppo/ppo.py\", line 101, in _train\n fetches = self.optimizer.step()\n File \"/home/jake/ray/python/ray/rllib/optimizers/multi_gpu_optimizer.py\", line 177, in step\n [tuples[k] for k in state_keys]))\n File \"/home/jake/ray/python/ray/rllib/optimizers/multi_gpu_impl.py\", line 169, in load_data\n \"Must load at least 1 tuple sequence per device. Try \"\n ValueError: Must load at least 1 tuple sequence per device. Try increasing sgd_minibatch_size or reducing max_seq_len to ensure that at least one sequence fits per device.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jacooba", "commentT": "2019-04-01T18:19:10Z", "comment_text": "\n \t\tCould you provide a reproduction script on a gym env here?\n I think you could also try reducing the max seq len of your LSTM model?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jacooba", "commentT": "2019-04-02T08:54:45Z", "comment_text": "\n \t\tHey! Thanks for getting back so quickly.\n I believe reducing the max seq len of your LSTM model will fix the issue, but I am more concerned about whether there is either an underlying issue that might cause problems or a misunderstanding of how the parameters are supposed to operate. It seems like this might be unintended/inconsitent behaviour.\n Here is a way to reproduce on cartpole. I've created and uploaded a zip containing two configs where the only difference is the number of envs.\n This command should have a problem:\n python3 train.py -f cartpole-dqn-lstm-bug.yaml\n Whereas, this one should not:\n python3 train.py -f cartpole-dqn-lstm-NO-bug.yaml\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jacooba", "commentT": "2019-04-02T08:57:46Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ray-project/ray/files/3033078/cartpole-dqn-lstm-bug.-.Copy.zip>cartpole-dqn-lstm-bug - Copy.zip</denchmark-link>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jacooba", "commentT": "2019-04-04T06:14:15Z", "comment_text": "\n \t\tThis turns out to be a bug in the check. We previously assumed the seq len would always be smaller than a minibatch.\n <denchmark-link:https://github.com/ray-project/ray/pull/4557/files>https://github.com/ray-project/ray/pull/4557/files</denchmark-link>\n  changes the behaviour to automatically increase the minibatch size to fit at least one sequence.\n As for why it worked when num_envs > 1: this is a separate bug where sometimes RNN sequences got concatenated together across sample batches. This could be unsafe, so in <denchmark-link:https://github.com/ray-project/ray/pull/4557>#4557</denchmark-link>\n  this is also disallowed.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jacooba", "commentT": "2019-04-04T08:43:01Z", "comment_text": "\n \t\tThanks for following up on this! The concatenation could certainly be unsafe. However, with multiple envs, and in general, the downside to automatic SGD minibatch resizing is that the user may not realize and it could cause training issues. Perhaps this is better than the alternative though. A Boolean could be introduced for dynamic minibatch resizing, but this may be overkill.\n \t\t"}}}, "commit": {"commit_id": "f9b8e77e3b701f0b2de96062f8f6f9087bf3aa6c", "commit_author": "Eric Liang", "commitT": "2019-04-07 12:11:30-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.6538461538461539", "commit_Nprams": "0.6538461538461539"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\agents\\qmix\\qmix_policy_graph.py", "file_new_name": "python\\ray\\rllib\\agents\\qmix\\qmix_policy_graph.py", "file_complexity": {"file_NLOC": "322", "file_CCN": "50", "file_NToken": "2766"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "248", "deleted_lines": null, "method_info": {"method_name": "learn_on_batch", "method_params": "self,samples", "method_startline": "239", "method_endline": "302", "method_complexity": {"method_NLOC": "49", "method_CCN": "3", "method_NToken": "536", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\ray\\rllib\\evaluation\\sample_batch.py", "file_new_name": "python\\ray\\rllib\\evaluation\\sample_batch.py", "file_complexity": {"file_NLOC": "200", "file_CCN": "65", "file_NToken": "1367"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "109,110,111,112,113", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\rllib\\evaluation\\sample_batch_builder.py", "file_new_name": "python\\ray\\rllib\\evaluation\\sample_batch_builder.py", "file_complexity": {"file_NLOC": "131", "file_CCN": "32", "file_NToken": "845"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "60,61,64", "deleted_lines": null, "method_info": {"method_name": "build_and_reset", "method_params": "self", "method_startline": "54", "method_endline": "65", "method_complexity": {"method_NLOC": "10", "method_CCN": "2", "method_NToken": "71", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "35", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self", "method_startline": "32", "method_endline": "35", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "25", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\evaluation\\tf_policy_graph.py", "file_new_name": "python\\ray\\rllib\\evaluation\\tf_policy_graph.py", "file_complexity": {"file_NLOC": "387", "file_CCN": "60", "file_NToken": "2507"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "467", "deleted_lines": null, "method_info": {"method_name": "_get_loss_inputs_dict", "method_params": "self,batch", "method_startline": "437", "method_endline": "486", "method_complexity": {"method_NLOC": "44", "method_CCN": "14", "method_NToken": "290", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\models\\lstm.py", "file_new_name": "python\\ray\\rllib\\models\\lstm.py", "file_complexity": {"file_NLOC": "135", "file_CCN": "5", "file_NToken": "765"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "124", "deleted_lines": null, "method_info": {"method_name": "chop_into_sequences", "method_params": "episode_ids,unroll_ids,agent_indices,feature_columns,state_columns,max_seq_len,dynamic_max,_extra_padding", "method_startline": "123", "method_endline": "130", "method_complexity": {"method_NLOC": "8", "method_CCN": "1", "method_NToken": "23", "method_nesting_level": "0"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\optimizers\\multi_gpu_impl.py", "file_new_name": "python\\ray\\rllib\\optimizers\\multi_gpu_impl.py", "file_complexity": {"file_NLOC": "233", "file_CCN": "31", "file_NToken": "1410"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "167,168,169,170,171,172,173,174,175,176,177,178,179,181,183,184,185,186,187,188,189,190,191,196,197,200,202,203,208,209,215", "deleted_lines": "167,168,169,171,173,178,179,182,184,189,195", "method_info": {"method_name": "load_data", "method_params": "self,sess,inputs,state_inputs", "method_startline": "118", "method_endline": "225", "method_complexity": {"method_NLOC": "69", "method_CCN": "13", "method_NToken": "458", "method_nesting_level": "1"}}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "python\\ray\\rllib\\tests\\test_lstm.py", "file_new_name": "python\\ray\\rllib\\tests\\test_lstm.py", "file_complexity": {"file_NLOC": "247", "file_CCN": "19", "file_NToken": "2628"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "57,58,59,60,61,62,63", "deleted_lines": "55,56", "method_info": {"method_name": "testMultiAgent", "method_params": "self", "method_startline": "50", "method_endline": "66", "method_complexity": {"method_NLOC": "17", "method_CCN": "1", "method_NToken": "198", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "73,74,75", "deleted_lines": null, "method_info": {"method_name": "testDynamicMaxLen", "method_params": "self", "method_startline": "68", "method_endline": "78", "method_complexity": {"method_NLOC": "11", "method_CCN": "3", "method_NToken": "138", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "28,29,30", "deleted_lines": "28,29", "method_info": {"method_name": "testBasic", "method_params": "self", "method_startline": "22", "method_endline": "37", "method_complexity": {"method_NLOC": "16", "method_CCN": "3", "method_NToken": "283", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "39,40,41,42,43,44,45,46,47,48", "deleted_lines": "45", "method_info": {"method_name": "testBatchId", "method_params": "self", "method_startline": "39", "method_endline": "48", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "180", "method_nesting_level": "1"}}}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\tests\\test_policy_evaluator.py", "file_new_name": "python\\ray\\rllib\\tests\\test_policy_evaluator.py", "file_complexity": {"file_NLOC": "398", "file_CCN": "55", "file_NToken": "3143"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "158,159,160,161,162,163,164,165,166,167", "deleted_lines": null, "method_info": {"method_name": "testBatchIds", "method_params": "self", "method_startline": "158", "method_endline": "167", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "97", "method_nesting_level": "1"}}}}}}}}