{"BR": {"BR_id": "6452", "BR_author": "zplizzi", "BRopenT": "2019-12-12T08:05:59Z", "BRcloseT": "2019-12-12T18:24:18Z", "BR_text": {"BRsummary": "[rllib] APEX DQN performance regression?", "BRdescription": "\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n It says in the <denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/pong-apex.yaml>pong_apex.yaml</denchmark-link>\n  tuned config:\n <denchmark-code># This can be expected to reach 20.8 reward within an hour when using a V100 GPU\n # (e.g. p3.2xl instance on AWS, and m4.4xl workers). It also can reach ~21 reward\n # within an hour with fewer workers (e.g. 4-8) but less reliably.\n </denchmark-code>\n \n I trained this example on an AWS p3.2xlarge instance (4 workers, 8 vec_env per worker) but could not replicate that statement. It took 4.5 hours of training and 10M timesteps sampled and trained on to reach a mean performance of 19.\n But maybe this is just the expected behavior for having less rollout workers? I don't quite know what the expected # of samples to convergence here is.\n For some comparison, training <denchmark-link:https://google.github.io/dopamine/baselines/plots.html>curves</denchmark-link>\n  for Rainbow in Dopamine show good performance in 10*250k=2.5M timesteps, although certainly the algorithm and hyperparameters aren't terribly comparable.\n Here's a full record of the run: <denchmark-link:https://app.wandb.ai/zplizzi/test/runs/2dthszrq?workspace=user-zplizzi>https://app.wandb.ai/zplizzi/test/runs/2dthszrq?workspace=user-zplizzi</denchmark-link>\n \n <denchmark-link:https://user-images.githubusercontent.com/5598968/70693629-af3bc200-1c72-11ea-8959-4f34e06fd03e.png></denchmark-link>\n \n Ray version and other system information (Python version, TensorFlow version, OS):\n \n Ray nightly wheels as of earlier today\n Tensorflow 1.14.0\n Ubuntu 16.04\n \n <denchmark-h:h3>Reproduction</denchmark-h>\n \n Here's the exact script used for training. All parameters are directly from the tuned example:\n <denchmark-code>from ray.rllib.agents.dqn import ApexTrainer\n from ray.rllib.agents import dqn\n \n config = dqn.apex.APEX_DEFAULT_CONFIG.copy()\n \n config[\"env\"] = \"PongNoFrameskip-v4\"\n config[\"monitor\"] = True\n config[\"env_config\"][\"wandb\"] = {\"project\": \"test\", \"monitor_gym\": True}\n \n config[\"target_network_update_freq\"] = 50000\n config[\"num_workers\"] = 4\n config[\"num_envs_per_worker\"] = 8\n config[\"gamma\"] = 0.99\n config[\"lr\"] = .0001\n \n from ray import tune\n from wandb.ray import WandbLogger\n tune.run(ApexTrainer,\n             loggers=[WandbLogger],\n             config=config,\n             )\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "zplizzi", "commentT": "2019-12-12T08:50:58Z", "comment_text": "\n \t\tNote that p3.2x is very wimpy in terms of CPU, you almost certainly want a p3.8xl or above if not using a distributed cluster.\n Btw you can see this file for the APEX runs we run regularly for regression testing: <denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/compact-regression-test.yaml>https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/compact-regression-test.yaml</denchmark-link>\n \n It seems to clock in at ~4.5m timesteps/hr with 10 workers.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "zplizzi", "commentT": "2019-12-12T17:12:21Z", "comment_text": "\n \t\tYeah, I agree this was a pretty CPU-limited run. I was more curious if it was expected to take 10M timesteps. As another comparison, the <denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/tuned_examples/pong-dqn.yaml>tuned DQN pong example</denchmark-link>\n  says\n <denchmark-code># You can expect ~20 reward within 1.1m timesteps / 2.1 hours on a K80 GPU\n </denchmark-code>\n \n Is this Apex config expected to be 10x less sample efficient than the DQN config?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "zplizzi", "commentT": "2019-12-12T17:33:23Z", "comment_text": "\n \t\tAlso, is there a mechanism that throttles the trainer to match the sample rate of the sampler? In the graphs above I noticed that the trainer initially was much faster than the sampler, but seems to have been throttled back over the course of the run in two distinct steps (bottom left graph). But perhaps this is some thermal throttling of CPU/GPU.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "zplizzi", "commentT": "2019-12-12T18:18:06Z", "comment_text": "\n \t\tYes, Ape-X samples as fast as it can go and usually ends up much less sample efficient, but more real time efficient. In earlier versions of RLlib we used to throttle the sampler with the trainer, but now it is decoupled.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "zplizzi", "commentT": "2019-12-12T18:24:18Z", "comment_text": "\n \t\tGot it, thanks!\n For what it's worth, I re-ran that test with these modified hyperparams (all else the same):\n <denchmark-code>config[\"target_network_update_freq\"] = 20000\n config[\"lr\"] = .00005\n config[\"train_batch_size\"] = 64\n </denchmark-code>\n \n and it's performing much better (almost done at 5M training steps/1.5M env steps/40 mins on the same machine). But I could imagine that the original hyperparams are better wall-clock for the 32-worker case that it's designed for.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "zplizzi", "commentT": "2019-12-12T18:26:54Z", "comment_text": "\n \t\tThat's quite a good result, consider updating the tuned example file if you'd like!\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "zplizzi", "commentT": "2019-12-12T18:29:47Z", "comment_text": "\n \t\tSure, here's a link to the run: <denchmark-link:https://app.wandb.ai/zplizzi/test/runs/ayuuhixr?workspace=user-zplizzi>https://app.wandb.ai/zplizzi/test/runs/ayuuhixr?workspace=user-zplizzi</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "9e9c5248238629a00fb8eeeffcd10fc5e54cf76d", "commit_author": "Zack Polizzi", "commitT": "2019-12-12 10:57:55-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\tuned_examples\\pong-apex.yaml", "file_new_name": "rllib\\tuned_examples\\pong-apex.yaml", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "1,2,3,4,9,10,11,12,13", "deleted_lines": "1,2,3,8,9,10,11,12"}}}}}}