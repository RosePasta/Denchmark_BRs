{"BR": {"BR_id": "9631", "BR_author": "andrew-rosenfeld-ts", "BRopenT": "2020-07-22T08:49:19Z", "BRcloseT": "2020-07-25T09:46:17Z", "BR_text": {"BRsummary": "[rllib] tensorflow 1.14 doesn't work with GPUs any longer", "BRdescription": "\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n Using a recent nightly build of Ray/RLlib, you can't train using GPUs with TensorFlow 1.14 due to an API mismatch.\n rollout_worker.py assumes that tensorflow has a function list_physical_devices but in 1.14, it's only experimental_list_devices, so you get\n AttributeError: module 'tensorflow._api.v1.config' has no attribute 'list_physical_devices'\n Here's the code in question in rollout_worker.py:\n if (ray.is_initialized() and\n                 ray.worker._mode() != ray.worker.LOCAL_MODE):\n             # Check available number of GPUs\n             if not ray.get_gpu_ids():\n                 logger.debug(\n                     \"Creating policy evaluation worker {}\".format(\n                         worker_index) +\n                     \" on CPU (please ignore any CUDA init errors)\")\n             elif (policy_config[\"framework\"] in [\"tf2\", \"tf\", \"tfe\"] and\n                   not tf.config.list_physical_devices(\"GPU\")) or \\\n                     (policy_config[\"framework\"] == \"torch\" and\n                      not torch.cuda.is_available()):\n                 raise RuntimeError(\n                     \"GPUs were assigned to this worker by Ray, but \"\n                     \"your DL framework ({}) reports GPU acceleration is \"\n                     \"disabled. This could be due to a bad CUDA- or {} \"\n                     \"installation.\".format(\n                         policy_config[\"framework\"],\n                         policy_config[\"framework\"]))\n vs the API in tensorflow/_api/v1/config/__init__.py:\n from tensorflow.python.eager.context import list_devices as experimental_list_devices\n and here's the full stacktrace:\n <denchmark-code>Traceback (most recent call last):\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 471, in _process_trial\n     result = self.trial_executor.fetch_result(trial)\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 430, in fetch_result\n     result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/worker.py\", line 1532, in get\n     raise value.as_instanceof_cause()\n ray.exceptions.RayTaskError(AttributeError): ray::PPO.train() (pid=7711, ip=10.128.0.4)\n   File \"python/ray/_raylet.pyx\", line 433, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 468, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 472, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 473, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 426, in ray._raylet.execute_task.function_executor\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 88, in __init__\n     Trainer.__init__(self, config, env, logger_creator)\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 475, in __init__\n     super().__init__(config, logger_creator)\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in __init__\n     self.setup(copy.deepcopy(self.config))\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 639, in setup\n     self._init(self.config, self.env_creator)\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 102, in _init\n     env_creator, self._policy, config, self.config[\"num_workers\"])\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 709, in _make_workers\n     logdir=self.logdir)\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 67, in __init__\n     RolloutWorker, env_creator, policy, 0, self._local_config)\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 296, in _make_worker\n     extra_python_environs=extra_python_environs)\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 415, in __init__\n     not tf.config.list_physical_devices(\"GPU\")) or \\\n   File \"/home/andrew/miniconda3/envs/ray_nightly_tf14/lib/python3.7/site-packages/tensorflow/python/util/deprecation_wrapper.py\", line 106, in __getattr__\n     attr = getattr(self._dw_wrapped_module, name)\n AttributeError: module 'tensorflow._api.v1.config' has no attribute 'list_physical_devices'\n </denchmark-code>\n \n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n Ray: latest nightly wheel as of 2020-07-22\n TensorFlow: 1.14\n Python: 3.7\n OS: Ubuntu 20.04\n from ray import tune\n from ray.rllib.agents.ppo import PPOTrainer\n tune.run(PPOTrainer,\n          config={\n              \"env\": \"CartPole-v0\",\n              \"num_workers\": 4,\n              \"num_envs_per_worker\": 2,\n              \"num_gpus\": 0.5,\n              \"num_gpus_per_worker\": 0.1,\n          })\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "andrew-rosenfeld-ts", "commentT": "2020-07-22T14:00:20Z", "comment_text": "\n \t\tMaybe the correct fix is to use ?\n (as noted on <denchmark-link:https://www.tensorflow.org/guide/gpu>https://www.tensorflow.org/guide/gpu</denchmark-link>\n  )\n That exists in both TF 1.4 and 2.2.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "andrew-rosenfeld-ts", "commentT": "2020-07-23T10:37:23Z", "comment_text": "\n \t\tI guess I could submit a patch for this if that's easiest.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "andrew-rosenfeld-ts", "commentT": "2020-07-24T09:53:46Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/andrew-rosenfeld-ts>@andrew-rosenfeld-ts</denchmark-link>\n  for filing this! Taking a look right now ...\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "andrew-rosenfeld-ts", "commentT": "2020-07-24T09:54:39Z", "comment_text": "\n \t\tYeah, it's really just that one line. No worries, will PR right now ... (probably merged later today).\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "andrew-rosenfeld-ts", "commentT": "2020-07-24T10:00:30Z", "comment_text": "\n \t\tThis PR fixes the issue:\n <denchmark-link:https://github.com/ray-project/ray/pull/9681>#9681</denchmark-link>\n \n Leaving this open until merged.\n <denchmark-link:https://github.com/andrew-rosenfeld-ts>@andrew-rosenfeld-ts</denchmark-link>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "andrew-rosenfeld-ts", "commentT": "2020-07-24T10:03:43Z", "comment_text": "\n \t\tBtw, we are very close to setting up daily automatic GPU + \"heavy\" regression tests (Atari, MuJoCo) to catch these things much earlier than we do right now. Hopefully, this will eliminate issues like the GPU one here altogether.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "andrew-rosenfeld-ts", "commentT": "2020-07-25T09:46:17Z", "comment_text": "\n \t\tClosing this now. Feel free to re-open if there are still problems on your end.\n \t\t"}}}, "commit": {"commit_id": "e4c5d3526f6eefe352892ef1293d062f7aecb09b", "commit_author": "Sven Mika", "commitT": "2020-07-24 21:48:58+02:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\evaluation\\rollout_worker.py", "file_new_name": "rllib\\evaluation\\rollout_worker.py", "file_complexity": {"file_NLOC": "964", "file_CCN": "94", "file_NToken": "4961"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "415", "deleted_lines": "415"}}}}}}