{"BR": {"BR_id": "10228", "BR_author": "ThomasLecat", "BRopenT": "2020-08-20T18:44:40Z", "BRcloseT": "2020-09-10T22:03:03Z", "BR_text": {"BRsummary": "[rllib] _get_torch_exploration_action doesn't support tuple action dist", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.15.4\n Ray installed from (source or binary): binary (via pip)\n Ray version: 0.8.6., but nothing seems to have changed on master\n Python version: 3.7\n \n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n When using tuple action distributions (as advised in <denchmark-link:https://github.com/ray-project/ray/issues/6372>#6372</denchmark-link>\n ) and exploration is disabled, the line:\n \n \n \n ray/rllib/utils/exploration/stochastic_sampling.py\n \n \n          Line 75\n       in\n       a462ae2\n \n \n \n \n \n \n  logp = torch.zeros((action.size()[0], ), dtype=torch.float32) \n \n \n \n \n \n from _get_torch_exploration_action raises the following exception:\n <denchmark-code>AttributeError: 'tuple' object has no attribute 'size'\n </denchmark-code>\n \n A simple fix that supports any type of distribution would be:\n logp = torch.zeros_like(action_dist.sampled_action_logp())\n I can submit a PR if it helps.\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n Exact command to reproduce: python rllib_cartpole.py for the following file\n import gym.envs.classic_control\n from gym.spaces import Tuple, Discrete\n \n import ray\n from ray import tune\n \n \n class CustomCartpole(gym.envs.classic_control.CartPoleEnv):\n     \"\"\"Add a dimension to the cartpole action space that is ignored.\"\"\"\n \n     def __init__(self, env_config):\n         super().__init__()\n         # if override_actions is false this is just the Cartpole environment\n         self.override_actions = env_config['override_actions']\n         if self.override_actions:\n             # 2 is the environment's normal action space\n             # 4 is just a dummy number to give it an extra dimension\n             self.original_action_space = self.action_space\n             self.action_space = Tuple([Discrete(2), Discrete(4)])\n             self.tuple_action_space = self.action_space\n \n     def step(self, action):\n         # call the cartpole environment with the original action\n         if self.override_actions:\n             self.action_space = self.original_action_space\n             return super().step(action[0])\n         else:\n             return super().step(action)\n \n \n def main():\n     ray.init()\n     tune.run(\n         \"PPO\",\n         stop={\"episode_reward_mean\": 50},\n         config={\n             \"env\": CustomCartpole,\n             \"env_config\": {'override_actions': True},\n             \"num_gpus\": 0,\n             \"num_workers\": 1,\n             \"eager\": False,\n             \"evaluation_interval\": 1,\n             \"evaluation_config\": {\n                 \"explore\": False,\n             },\n             \"framework\": \"torch\",\n         },\n     )\n \n \n if __name__ == '__main__':\n     main()\n \n  I have verified my script runs in a clean environment and reproduces the issue.\n  I have verified the issue also occurs with the latest wheels.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ThomasLecat", "commentT": "2020-08-20T20:46:34Z", "comment_text": "\n \t\tThe proposed fix makes sense to me. We could alternatively try to get the batch dimension of the tuple, but I don't see an existing helper method for that, so your proposal is probably simpler.\n And yeah, a PR would be great!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ThomasLecat", "commentT": "2020-08-31T11:45:46Z", "comment_text": "\n \t\tThanks for your answer!\n Just got back from holidays, I opened a PR <denchmark-link:https://github.com/ray-project/ray/pull/10443>#10443</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "504da45e699cae4f8e62c6fa39ab7d504706d356", "commit_author": "Thomas Lecat", "commitT": "2020-09-10 15:03:02-07:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\utils\\exploration\\stochastic_sampling.py", "file_new_name": "rllib\\utils\\exploration\\stochastic_sampling.py", "file_complexity": {"file_NLOC": "59", "file_CCN": "8", "file_NToken": "383"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "75", "deleted_lines": "75", "method_info": {"method_name": "_get_torch_exploration_action", "method_params": "action_dist,explore", "method_startline": "69", "method_endline": "76", "method_complexity": {"method_NLOC": "8", "method_CCN": "2", "method_NToken": "49", "method_nesting_level": "1"}}}}}}}}