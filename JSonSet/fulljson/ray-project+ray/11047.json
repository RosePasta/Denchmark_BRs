{"BR": {"BR_id": "11047", "BR_author": "Karol-G", "BRopenT": "2020-09-26T15:12:07Z", "BRcloseT": "2020-10-20T23:03:24Z", "BR_text": {"BRsummary": "[tune] TypeError: __init__() got multiple values for argument 'arch' when using 'with_parameters'", "BRdescription": "\n Hi,\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n I compiled ray from source from the commit <denchmark-link:https://github.com/ray-project/ray/commit/552ebdbedae7327b2e6f084c989bae6c1010f58d>552ebdb</denchmark-link>\n  to be able to use the new  function <denchmark-link:https://github.com/ray-project/ray/pull/10679>#10679</denchmark-link>\n  to pass constant variables to my trainable class. However, I get the following error when calling :\n <denchmark-code>Failure # 1 (occurred at 2020-09-26_16-50-01)\n Traceback (most recent call last):\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/trial_runner.py\", line 518, in _process_trial\n     result = self.trial_executor.fetch_result(trial)\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n     result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n   File \"/home/karol/PycharmProjects/ray/python/ray/worker.py\", line 1438, in get\n     raise value.as_instanceof_cause()\n ray.exceptions.RayTaskError(TuneError): \ufffd[36mray::ImplicitFunc.train()\ufffd[39m (pid=25150, ip=141.12.239.114)\n   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/trainable.py\", line 336, in train\n     result = self.step()\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/function_runner.py\", line 346, in step\n     self._report_thread_runner_error(block=True)\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/function_runner.py\", line 464, in _report_thread_runner_error\n     raise TuneError((\"Trial raised an exception. Traceback:\\n{}\"\n ray.tune.error.TuneError: Trial raised an exception. Traceback:\n \ufffd[36mray::ImplicitFunc.train()\ufffd[39m (pid=25150, ip=141.12.239.114)\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/function_runner.py\", line 233, in run\n     self._entrypoint()\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/function_runner.py\", line 295, in entrypoint\n     return self._trainable_func(self.config, self._status_reporter,\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/function_runner.py\", line 527, in _trainable_func\n     output = fn()\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/function_runner.py\", line 595, in _inner\n     inner(config, checkpoint_dir=None)\n   File \"/home/karol/PycharmProjects/ray/python/ray/tune/function_runner.py\", line 589, in inner\n     fn(config, **fn_kwargs)\n TypeError: __init__() got multiple values for argument 'arch'\n </denchmark-code>\n \n I am using Ubuntu 18.04.4 LTS (GNU/Linux 5.4.0-42-generic x86_64) with python 3.8.3 and pytorch 1.5.0\n <denchmark-h:h3>Reproduction</denchmark-h>\n \n from ray import tune\n from ray.tune.schedulers import PopulationBasedTraining\n from ray.tune.function_runner import with_parameters\n \n ray.init(num_cpus=3, num_gpus=3, _memory=7516192768, object_store_memory=7516192768)\n pbt = PopulationBasedTraining(\n             time_attr=\"training_iteration\",\n             metric=\"val_dice\",\n             mode=\"max\",\n             perturbation_interval=2,\n             hyperparam_mutations={\n                 \"lr\": lambda: np.random.uniform(0.001, 0.0001)\n             })\n analysis = tune.run(with_parameters(MyTrainable,\n                                             arch=\"FPN\",\n                                             encoder=encoder,\n                                             train_loader=train_loader,\n                                             val_loader=val_loader,\n                                             optimizer=\"adam\",\n                                             device=device),\n                     scheduler=pbt,\n                     reuse_actors=True,\n                     keep_checkpoints_num=3,\n                     verbose=1,\n                     config={\"lr\": tune.uniform(0.001, 0.0001)},\n                     num_samples=2,\n                     resources_per_trial={\"gpu\": 1, \"cpu\": 1})\n \n class MyTrainable(tune.Trainable):\n     def __init__(self, arch, encoder, train_loader, val_loader, optimizer=\"adam\", device=\"cuda\"):\n         super().__init__()\n         self.train_loader = train_loader\n         self.val_loader = val_loader\n         self.device = device\n         self.model = NoiseSegModel(arch=arch, encoder=encoder)\n         if str(self.device) != \"cpu\":\n             self.model = self.model.cuda()\n         self.optimizer = optimizer\n \n     def _setup(self, config):\n         if self.optimizer == \"adam\":\n             self.optimizer = torch.optim.Adam(self.model.parameters(), lr=config.get(\"lr\"))\n         elif self.optimizer == \"RMSprop\":\n             self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr=config.get(\"lr\"), weight_decay=1e-8, momentum=0.9)\n         else:\n             raise NotImplementedError\n \n         self.criterion = nn.BCEWithLogitsLoss()\n         self.best_val_score = 0\n         self.best_global_step = 0\n         self.start_epoch = 0\n \n    # Other methods from MyTrainable\n \n  I have verified my script runs in a clean environment and reproduces the issue.\n [Not possible] I have verified the issue also occurs with the latest wheels.\n \n Best\n Karol\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Karol-G", "commentT": "2020-10-19T19:08:28Z", "comment_text": "\n \t\tI think what we should do is just raise a better error here; <denchmark-link:https://github.com/krfricke>@krfricke</denchmark-link>\n  will take care of this.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Karol-G", "commentT": "2020-10-20T16:10:19Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/Karol-G>@Karol-G</denchmark-link>\n , thanks for raising the issue.\n  only works with the <denchmark-link:https://docs.ray.io/en/master/tune/api_docs/trainable.html#function-api>function API</denchmark-link>\n . I would suggest to take a look if you could convert your trainable to a function trainable. Please note that we recommend the function API over the older class API.\n Let me know if you need any help with that.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Karol-G", "commentT": "2020-10-21T10:20:45Z", "comment_text": "\n \t\t\n Hi @Karol-G, thanks for raising the issue.\n tune.with_parameters() only works with the function API. I would suggest to take a look if you could convert your trainable to a function trainable. Please note that we recommend the function API over the older class API.\n Let me know if you need any help with that.\n \n Thanks for the reply. I managed to convert the trainable class to a trainable function. It works fine now \ud83d\udc4d\n \t\t"}}}, "commit": {"commit_id": "6d11fb8bc6a7eaed92e9e3247ed244c6a9b218f3", "commit_author": "Kai Fricke", "commitT": "2020-10-20 16:03:24-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\tune\\function_runner.py", "file_new_name": "python\\ray\\tune\\function_runner.py", "file_complexity": {"file_NLOC": "427", "file_CCN": "94", "file_NToken": "2272"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "619,620,621,622,623,624", "deleted_lines": null, "method_info": {"method_name": "with_parameters", "method_params": "fn,kwargs", "method_startline": "587", "method_endline": "653", "method_complexity": {"method_NLOC": "15", "method_CCN": "4", "method_NToken": "66", "method_nesting_level": "0"}}}}}}}}