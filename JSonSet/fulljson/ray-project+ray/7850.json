{"BR": {"BR_id": "7850", "BR_author": "devinbarry", "BRopenT": "2020-04-01T09:25:38Z", "BRcloseT": "2020-04-02T01:03:15Z", "BR_text": {"BRsummary": "[rllib] ModuleNotFoundError: No module named 'tensorflow.contrib'", "BRdescription": "\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n <denchmark-code>File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 93, in __init__\n     Trainer.__init__(self, config, env, logger_creator)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 455, in __init__\n     super().__init__(config, logger_creator)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n     self._setup(copy.deepcopy(self.config))\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 596, in _setup\n     self._init(self.config, self.env_creator)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 117, in _init\n     config)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/dqn/apex.py\", line 48, in defer_make_workers\n     return trainer._make_workers(env_creator, policy, config, 0)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 666, in _make_workers\n     logdir=self.logdir)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 61, in __init__\n     RolloutWorker, env_creator, policy, 0, self._local_config)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 271, in _make_worker\n     _fake_sampler=config.get(\"_fake_sampler\", False))\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 360, in __init__\n     self._build_policy_map(policy_dict, policy_config)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 836, in _build_policy_map\n     policy_map[name] = cls(obs_space, act_space, merged_conf)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/ddpg/ddpg_policy.py\", line 110, in __init__\n     self.cur_observations, observation_space, action_space)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/ddpg/ddpg_policy.py\", line 410, in _build_policy_network\n     import tensorflow.contrib.layers as layers\n ModuleNotFoundError: No module named 'tensorflow.contrib'\n </denchmark-code>\n \n Ray version and other system information (Python version, TensorFlow version, OS):\n Python 3.7.7\n I am running Ray 0.8.3 but this bug is currently still in the master branch\n tensorflow==2.1.0\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n Setting any DDPG algorithm to  forces this import to run\n <denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/agents/ddpg/ddpg_policy.py#L417>https://github.com/ray-project/ray/blob/master/rllib/agents/ddpg/ddpg_policy.py#L417</denchmark-link>\n \n Tensorflow 2 does not have a contrib module\n \n  I have verified my script runs in a clean environment and reproduces the issue.\n  I have verified the issue also occurs with the latest wheels.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "devinbarry", "commentT": "2020-04-01T09:41:28Z", "comment_text": "\n \t\tYeah, we should switch to keras here. I'm taking a look.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "devinbarry", "commentT": "2020-04-01T09:47:29Z", "comment_text": "\n \t\tFor now, could you replace the code (~ line 416) in rllib/agents/ddpg/ddpg_policy.py with the following? That should eliminate the dependency on the deprecated tf.contrib.\n <denchmark-code>        activation = getattr(tf.nn, self.config[\"actor_hidden_activation\"])\n         for hidden in self.config[\"actor_hiddens\"]:\n             if self.config[\"parameter_noise\"]:\n                 action_out = tf.keras.layers.Dense(\n                     units=hidden,\n                     activation=activation)(action_out)\n                 action_out = tf.keras.layers.LayerNormalization()(action_out)\n             else:\n                 action_out = tf.keras.layers.Dense(\n                     units=hidden, activation=activation)(action_out)\n         action_out = tf.keras.layers.Dense(\n             units=action_space.shape[0], activation=None)(action_out)\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "devinbarry", "commentT": "2020-04-01T09:48:23Z", "comment_text": "\n \t\tCool. I will give this a try!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "devinbarry", "commentT": "2020-04-01T09:49:07Z", "comment_text": "\n \t\tPreliminary tests look ok. Please let me know, if this doesn't help.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "devinbarry", "commentT": "2020-04-01T11:25:39Z", "comment_text": "\n \t\tSorry it takes me ages to compile the entire of Ray when I make a change like this.\n This is the error I get with the new code changed\n <denchmark-code>2020-04-01 11:22:49,761\tERROR trial_runner.py:521 -- Trial APEX_DDPG_LunarLanderContinuous-v2_00005: Error processing event.\n Traceback (most recent call last):\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n     result = self.trial_executor.fetch_result(trial)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 381, in fetch_result\n     result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/worker.py\", line 1513, in get\n     raise value.as_instanceof_cause()\n ray.exceptions.RayTaskError(ValueError): ray::APEX_DDPG.__init__() (pid=97720, ip=10.30.30.100)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1619, in _create_c_op\n     c_op = c_api.TF_FinishOperation(op_desc)\n tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 400 and 300 for 'default_policy/add_14' (op: 'AddV2') with input shapes: [400], [300].\n \n During handling of the above exception, another exception occurred:\n \n ray::APEX_DDPG.__init__() (pid=97720, ip=10.30.30.100)\n   File \"python/ray/_raylet.pyx\", line 414, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 450, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 90, in __init__\n     Trainer.__init__(self, config, env, logger_creator)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 455, in __init__\n     super().__init__(config, logger_creator)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/tune/trainable.py\", line 174, in __init__\n     self._setup(copy.deepcopy(self.config))\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 596, in _setup\n     self._init(self.config, self.env_creator)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 113, in _init\n     config)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/dqn/apex.py\", line 48, in defer_make_workers\n     return trainer._make_workers(env_creator, policy, config, 0)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 667, in _make_workers\n     logdir=self.logdir)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 62, in __init__\n     RolloutWorker, env_creator, policy, 0, self._local_config)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 272, in _make_worker\n     _fake_sampler=config.get(\"_fake_sampler\", False))\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 360, in __init__\n     self._build_policy_map(policy_dict, policy_config)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 842, in _build_policy_map\n     policy_map[name] = cls(obs_space, act_space, merged_conf)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/ddpg/ddpg_policy.py\", line 262, in __init__\n     (1.0 - self.tau) * var_target))\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\", line 902, in binary_op_wrapper\n     return func(x, y, name=name)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\", line 1194, in _add_dispatch\n     return gen_math_ops.add_v2(x, y, name=name)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 483, in add_v2\n     \"AddV2\", x=x, y=y, name=name)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n     attrs=attr_protos, op_def=op_def)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n     op_def=op_def)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1786, in __init__\n     control_input_ops)\n   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1622, in _create_c_op\n     raise ValueError(str(e))\n ValueError: Dimensions must be equal, but are 400 and 300 for 'default_policy/add_14' (op: 'AddV2') with input shapes: [400], [300].\n </denchmark-code>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "devinbarry", "commentT": "2020-04-01T11:41:48Z", "comment_text": "\n \t\tOK I think that error is actually caused by a problem in my code. I am compiling now from your branch in the PR you made <denchmark-link:https://github.com/sven1977>@sven1977</denchmark-link>\n . Will report back\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "devinbarry", "commentT": "2020-04-01T11:57:44Z", "comment_text": "\n \t\tOk I compiled from https://github.com/sven1977/ray/tree/issue_7850_ddpg_tf_contrib_error\n And now I get a new error\n <denchmark-code>ray::RolloutWorker.sample_with_count() (pid=101749, ip=10.30.30.100)\n (pid=101732)   File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task\n (pid=101732)   File \"python/ray/_raylet.pyx\", line 450, in ray._raylet.execute_task\n (pid=101732)   File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n (pid=101732)   File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 539, in sample_with_count\n (pid=101732)     batch = self.sample()\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 492, in sample\n (pid=101732)     batches = [self.input_reader.next()]\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 53, in next\n (pid=101732)     batches = [self.get_data()]\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 96, in get_data\n (pid=101732)     item = next(self.rollout_provider)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 346, in _env_runner\n (pid=101732)     callbacks, soft_horizon, no_done_at_end)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py\", line 495, in _process_observations\n (pid=101732)     outputs.append(episode.batch_builder.build_and_reset(episode))\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/sample_batch_builder.py\", line 202, in build_and_reset\n (pid=101732)     self.postprocess_batch_so_far(episode)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/evaluation/sample_batch_builder.py\", line 153, in postprocess_batch_so_far\n (pid=101732)     pre_batch, other_batches, episode)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/ddpg/ddpg_policy.py\", line 56, in postprocess_trajectory\n (pid=101732)     self._is_exploring: False,\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 960, in run\n (pid=101732)     run_metadata_ptr)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1183, in _run\n (pid=101732)     feed_dict_tensor, options, run_metadata)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1361, in _do_run\n (pid=101732)     run_metadata)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1386, in _do_call\n (pid=101732)     raise type(e)(node_def, op, message)\n (pid=101732) tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'default_policy/timestep' with dtype int32\n (pid=101732) \t [[node default_policy/timestep (defined at /ray/rllib/agents/ddpg/ddpg_policy.py:96) ]]\n (pid=101732)\n (pid=101732) Original stack trace for 'default_policy/timestep':\n (pid=101732)   File \"/ray/workers/default_worker.py\", line 113, in <module>\n (pid=101732)     ray.worker.global_worker.main_loop()\n (pid=101732)   File \"/ray/rllib/evaluation/rollout_worker.py\", line 360, in __init__\n (pid=101732)     self._build_policy_map(policy_dict, policy_config)\n (pid=101732)   File \"/ray/rllib/evaluation/rollout_worker.py\", line 842, in _build_policy_map\n (pid=101732)     policy_map[name] = cls(obs_space, act_space, merged_conf)\n (pid=101732)   File \"/ray/rllib/agents/ddpg/ddpg_policy.py\", line 96, in __init__\n (pid=101732)     timestep = tf.placeholder(tf.int32, (), name=\"timestep\")\n (pid=101732)   File \"/tensorflow_core/python/ops/array_ops.py\", line 2718, in placeholder\n (pid=101732)     return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n (pid=101732)   File \"/tensorflow_core/python/ops/gen_array_ops.py\", line 6032, in placeholder\n (pid=101732)     \"Placeholder\", dtype=dtype, shape=shape, name=name)\n (pid=101732)   File \"/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\n (pid=101732)     attrs=attr_protos, op_def=op_def)\n (pid=101732)   File \"/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\n (pid=101732)     op_def=op_def)\n (pid=101732)   File \"/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\n (pid=101732)     self._traceback = tf_stack.extract_stack()\n (pid=101732)\n (pid=101732) During handling of the above exception, another exception occurred:\n (pid=101732)\n (pid=101732) Traceback (most recent call last):\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 491, in train\n (pid=101732)     result = Trainable.train(self)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/tune/trainable.py\", line 261, in train\n (pid=101732)     result = self._train()\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 150, in _train\n (pid=101732)     fetches = self.optimizer.step()\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/optimizers/async_replay_optimizer.py\", line 143, in step\n (pid=101732)     sample_timesteps, train_timesteps = self._step()\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/optimizers/async_replay_optimizer.py\", line 265, in _step\n (pid=101732)     raise ray_error\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/optimizers/async_replay_optimizer.py\", line 229, in _step\n (pid=101732)     counts[i] = ray_get_and_free(c[1][1])\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/rllib/utils/memory.py\", line 29, in ray_get_and_free\n (pid=101732)     result = ray.get(object_ids)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/ray/worker.py\", line 1513, in get\n (pid=101732)     raise value.as_instanceof_cause()\n (pid=101732) ray.exceptions.RayTaskError(InvalidArgumentError): ray::RolloutWorker.sample_with_count() (pid=101749, ip=10.30.30.100)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1352, in _run_fn\n (pid=101732)     target_list, run_metadata)\n (pid=101732)   File \"/home/axion/anaconda3/envs/training/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1445, in _call_tf_sessionrun\n (pid=101732)     run_metadata)\n (pid=101732) tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'default_policy/timestep' with dtype int32\n (pid=101732) \t [[{{node default_policy/timestep}}]]\n </denchmark-code>\n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "devinbarry", "commentT": "2020-04-01T14:57:31Z", "comment_text": "\n \t\tTaking another look ...\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "devinbarry", "commentT": "2020-04-01T15:24:57Z", "comment_text": "\n \t\tGot it ...\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "devinbarry", "commentT": "2020-04-01T15:28:39Z", "comment_text": "\n \t\tSorry about the trouble:\n Could you try the same PR (I just updated, you just have to git pull)? Or just add this line to ddpg_policy.py:\n <denchmark-code>            clean_actions, cur_noise_scale = self.sess.run(\n                 [self.output_actions,\n                  self.exploration.get_info()],\n                 feed_dict={\n                     self.cur_observations: states,\n                     self._is_exploring: False,\n                     self._timestep: self.global_timestep,  # <- new line here\n                 })\n </denchmark-code>\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "devinbarry", "commentT": "2020-04-01T15:30:47Z", "comment_text": "\n \t\tTo explain the situation: We are just cleaning up all of the existing ParameterNoise code and are still finding bugs in it here and there. We have started moving this into the new Exploration API (and are adding tests and tuned examples), but it's not fully merged yet for neither DQN, nor DDPG. This will probably happen next week and then, param-noise will also be available for other algos.\n \t\t"}}}, "commit": {"commit_id": "7b08db9f8cd85d185879e5bef778e8855f2a06cf", "commit_author": "Sven Mika", "commitT": "2020-04-01 18:03:14-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "0.0", "commit_Nprams": "0.75"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\agents\\ddpg\\ddpg_policy.py", "file_new_name": "rllib\\agents\\ddpg\\ddpg_policy.py", "file_complexity": {"file_NLOC": "443", "file_CCN": "57", "file_NToken": "3499"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "418,419,421", "deleted_lines": "418,419,420,421,422,423,424,425,426", "method_info": {"method_name": "_build_policy_network", "method_params": "self,obs,obs_space,action_space", "method_startline": "405", "method_endline": "435", "method_complexity": {"method_NLOC": "23", "method_CCN": "4", "method_NToken": "199", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\agents\\dqn\\distributional_q_model.py", "file_new_name": "rllib\\agents\\dqn\\distributional_q_model.py", "file_complexity": {"file_NLOC": "208", "file_CCN": "23", "file_NToken": "1260"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "131,132,133", "deleted_lines": "128,129,130,131,132", "method_info": {"method_name": "build_state_score", "method_params": "model_out", "method_startline": "121", "method_endline": "144", "method_complexity": {"method_NLOC": "24", "method_CCN": "5", "method_NToken": "134", "method_nesting_level": "2"}}}}}}}}