{"BR": {"BR_id": "7438", "BR_author": "soundway", "BRopenT": "2020-03-04T03:08:17Z", "BRcloseT": "2020-03-04T09:48:08Z", "BR_text": {"BRsummary": "[rllib] Evaluation doesn\u2019t work properly for PyTorch.", "BRdescription": "\n This is not a contribution.\n Ray version: 0.8.1\n Python version: 3.6.8\n Pytorch version: 1.4\n OS: Ubuntu 18.04 Docker\n Training with Pytorch with evaluation enabled doesn\u2019t work properly as it ends up calling tensorflow code. Here's a script that reproduces the problem:\n import gym\n from gym.spaces import Box\n from ray import tune\n \n class DummyEnv(gym.Env):\n     def __init__(self, config):\n         self.action_space = Box(0.0, 1.0, shape=(1,))\n         self.observation_space = Box(0.0, 1.0, shape=(1, ))\n \n     def reset(self):\n         self.num_steps = 0\n         return [0.0]\n \n     def step(self, action):\n         self.num_steps += 1\n         return [0.0], 1.0, True if self.num_steps == 30 else False, {}\n \n tune.run(\n     \"PPO\",\n     config={\n         \"env\": DummyEnv,\n         \"use_pytorch\": True,\n         \"num_workers\": 1,\n         \"evaluation_interval\": 1,\n         \"evaluation_config\": {\"seed\": 1},\n     }\n )\n This will result in the following exception:\n <denchmark-code>ray.exceptions.RayTaskError(AssertionError): ray::PPO.train() (pid=33990)\n   File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n   File \"python/ray/_raylet.pyx\", line 430, in ray._raylet.execute_task.function_executor\n   File \"/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/trainer.py\", line 513, in train\n     evaluation_metrics = self._evaluate()\n   File \"/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/trainer.py\", line 685, in _evaluate\n     lambda w: w.restore(ray.get(weights)))\n   File \"/usr/local/lib/python3.6/dist-packages/ray/rllib/evaluation/worker_set.py\", line 110, in foreach_worker\n     local_result = [func(self.local_worker())]\n   File \"/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/trainer.py\", line 685, in <lambda>\n     lambda w: w.restore(ray.get(weights)))\n   File \"/usr/local/lib/python3.6/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 764, in restore\n     self.policy_map[pid].set_state(state)\n   File \"/usr/local/lib/python3.6/dist-packages/ray/rllib/policy/policy.py\", line 320, in set_state\n     self.set_weights(state)\n   File \"/usr/local/lib/python3.6/dist-packages/ray/rllib/policy/tf_policy.py\", line 290, in set_weights\n     return self._variables.set_weights(weights)\n   File \"/usr/local/lib/python3.6/dist-packages/ray/experimental/tf_utils.py\", line 185, in set_weights\n     assert assign_list, (\"No variables in the input matched those in the \"\n AssertionError: No variables in the input matched those in the network. Possible cause: Two networks were defined in the same TensorFlow graph. To fix this, place each network definition in its own tf.Graph.\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "soundway", "commentT": "2020-03-04T09:34:54Z", "comment_text": "\n \t\tThis is a bug (seems to have been there for a while). Fixing this now ...\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "soundway", "commentT": "2020-03-04T09:48:08Z", "comment_text": "\n \t\tThanks for filing this! Please use this PR here for a fix (will be merged into master in the next days):\n <denchmark-link:https://github.com/ray-project/ray/pull/7443>#7443</denchmark-link>\n \n The problem was that the default policy (always TF) would be used for evaluation workers, no matter the setting in config[use_pytorch].\n \t\t"}}}, "commit": {"commit_id": "c38224d8e53cefad62481d911f0efe90d2d74775", "commit_author": "Eric Liang", "commitT": "2020-03-04 12:53:04-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\agents\\trainer_template.py", "file_new_name": "rllib\\agents\\trainer_template.py", "file_complexity": {"file_NLOC": "123", "file_CCN": "32", "file_NToken": "728"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "98,103,104,105,106,107,110,111,113,114,116,117", "deleted_lines": "99,100,101,102,106,108", "method_info": {"method_name": "_init", "method_params": "self,config,env_creator", "method_startline": "95", "method_endline": "135", "method_complexity": {"method_NLOC": "34", "method_CCN": "11", "method_NToken": "202", "method_nesting_level": "2"}}}}}}}}