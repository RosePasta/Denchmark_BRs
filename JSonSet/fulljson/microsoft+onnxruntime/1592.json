{"BR": {"BR_id": "1592", "BR_author": "GuanLuo", "BRopenT": "2019-08-08T18:34:48Z", "BRcloseT": "2019-09-16T18:59:28Z", "BR_text": {"BRsummary": "multi-GPU \"alloc failed\" error arises after updating to rel-0.5.0", "BRdescription": "\n \n On a multi-GPU system, if a model session is created on GPUs other than GPU0 (i.e. GPU1), then \"alloc failed\" error will be thrown when running the model. The issue arise on <denchmark-link:https://gallery.azure.ai/Model/DenseNet-121-1-2-2>densenet</denchmark-link>\n  and <denchmark-link:https://gallery.azure.ai/Model/Inception-v1-1-2-3>inception</denchmark-link>\n , I scoped it down to a simple model that only have \"concat\" op. So the implementation of \"concat\" seems to be what causes the issue, but there might be more causes.\n Urgency\n none\n System information\n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\n ONNX Runtime installed from (source or binary): source\n ONNX Runtime version: rel-0.5.0\n Python version: 2.7\n Visual Studio version (if applicable):\n GCC/Compiler version (if compiling from source):\n CUDA/cuDNN version: gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\n GPU model and memory: Tesla P100 / 16280MiB\n \n To Reproduce\n Describe steps/code to reproduce the behavior:\n \n Compile the following code snippet gcc -std=c++11 c_api_sample.cc -o ort_c_api -lonnxruntime -lstdc++ -lpthread\n copy the simple_concat model to pwd with name \"model.onnx\". Or you can use the densenet / inception model mentioned above\n ./ort_c_api\n \n c_api_sample.cc\n #include <assert.h>\n #include <onnxruntime/cuda_provider_factory.h>\n #include <onnxruntime/onnxruntime_c_api.h>\n #include <stdio.h>\n #include <stdlib.h>\n #include <iostream>\n #include <vector>\n #include <thread>\n #include <future>\n \n //*****************************************************************************\n // helper function to check for status\n #define CHECK_STATUS(expr)                               \\\n   {                                                      \\\n     OrtStatus* onnx_status = (expr);                     \\\n     if (onnx_status != NULL) {                           \\\n       const char* msg = OrtGetErrorMessage(onnx_status); \\\n       fprintf(stderr, \"%s\\n\", msg);                      \\\n       OrtReleaseStatus(onnx_status);                     \\\n       exit(1);                                           \\\n     }                                                    \\\n   }\n \n std::string DimsToString(const std::vector<int64_t>& dims)\n {\n   std::string res = \"[\";\n   for (const auto& dim : dims) {\n     res += std::to_string(dim);\n     res += \",\";\n   }\n   res.back() = ']';\n   return res;\n }\n \n struct TensorInfo {\n   TensorInfo(\n       const char* name, const ONNXTensorElementDataType& type,\n       const std::vector<int64_t>& dims)\n    : name_(name), type_(type), dims_(dims)\n   {\n   }\n \n   const char* name_;\n   ONNXTensorElementDataType type_;\n   std::vector<int64_t> dims_;\n };\n \n void CreateSession(\n   const char* model_path, const int device_id, OrtEnv* env,\n   OrtSessionOptions* session_options, OrtSession** session)\n {\n   // To deploy on different device, need to set provider on cloned option\n   // as you can remove a execution provider once it is appended\n   OrtSessionOptions* context_options;\n   CHECK_STATUS(OrtCloneSessionOptions(session_options, &context_options));\n   std::unique_ptr<OrtSessionOptions, decltype(&OrtReleaseSessionOptions)>\n       options_wrapper(context_options, OrtReleaseSessionOptions);\n \n   // Use CUDA, device 0. CPU if -1\n   if (device_id >= 0) {\n     CHECK_STATUS(OrtSessionOptionsAppendExecutionProvider_CUDA(context_options, device_id));\n     std::cout << \"deploy on GPU \" << device_id << std::endl;\n   } else {\n     std::cout << \"deploy on CPU\" << std::endl;\n   }\n   \n   CHECK_STATUS(OrtCreateSession(env, model_path, context_options, session));\n }\n \n std::vector<TensorInfo> GetIOTensors(OrtSession* session, bool is_input, bool print_info = true)\n {\n   std::vector<TensorInfo> res;\n \n   OrtAllocator* allocator;\n   CHECK_STATUS(OrtCreateDefaultAllocator(&allocator));\n   std::unique_ptr<OrtAllocator, decltype(&OrtReleaseAllocator)>\n       allocator_wrapper(allocator, OrtReleaseAllocator);\n \n   // print number of model input nodes\n   size_t num_nodes;\n   if (is_input) {\n     CHECK_STATUS(OrtSessionGetInputCount(session, &num_nodes));\n   } else {\n     CHECK_STATUS(OrtSessionGetOutputCount(session, &num_nodes));\n   }\n \n   // iterate over all input nodes\n   for (size_t i = 0; i < num_nodes; i++) {\n     OrtTypeInfo* typeinfo;\n     if (is_input) {\n       CHECK_STATUS(OrtSessionGetInputTypeInfo(session, i, &typeinfo));\n     } else {\n       CHECK_STATUS(OrtSessionGetOutputTypeInfo(session, i, &typeinfo));\n     }\n     std::unique_ptr<OrtTypeInfo, decltype(&OrtReleaseTypeInfo)>\n       type_info_wrapper(typeinfo, OrtReleaseTypeInfo);\n       \n     const OrtTensorTypeAndShapeInfo* tensor_info;\n \n     // node names\n     char* tensor_name;\n     if (is_input) {\n       CHECK_STATUS(OrtSessionGetInputName(session, i, allocator, &tensor_name));\n     } else {\n       CHECK_STATUS(OrtSessionGetOutputName(session, i, allocator, &tensor_name));\n     }\n     \n     // node types\n     ONNXTensorElementDataType type;\n     CHECK_STATUS(OrtCastTypeInfoToTensorInfo(typeinfo, &tensor_info));\n     CHECK_STATUS(OrtGetTensorElementType(tensor_info, &type));\n \n     // shapes/dims\n     size_t num_dims;\n     CHECK_STATUS(OrtGetDimensionsCount(tensor_info, &num_dims));\n     std::vector<int64_t> dims(num_dims);\n     CHECK_STATUS(OrtGetDimensions(tensor_info, (int64_t*)dims.data(), num_dims));\n \n     res.emplace_back(tensor_name, type, dims);\n   }\n \n   if (print_info) {\n     std::cout << \"Number of tensors = \" << num_nodes << std::endl;\n     for (size_t idx = 0; idx < res.size(); idx++) {\n       std::cout << \"Tensor \" << idx << \":\" << std::endl\n                 << \"    name: \" << res[idx].name_ << std::endl\n                 << \"    type: \" << res[idx].type_ << std::endl\n                 << \"    dims: \" << DimsToString(res[idx].dims_)\n                 << std::endl;\n     }\n   }\n   return res;\n }\n \n OrtValue*\n CreateTensor(const TensorInfo& info)\n {\n   OrtAllocator* allocator;\n   CHECK_STATUS(OrtCreateDefaultAllocator(&allocator));\n   std::unique_ptr<OrtAllocator, decltype(&OrtReleaseAllocator)>\n       allocator_wrapper(allocator, OrtReleaseAllocator);\n \n   OrtValue* res = nullptr;\n   CHECK_STATUS(OrtCreateTensorAsOrtValue(\n     allocator, info.dims_.data(), info.dims_.size(), info.type_, &res));\n   return res;\n }\n \n int\n main(int argc, char* argv[])\n {\n   //===================== Factory Scope ======================\n   // initialize  enviroment...one enviroment per process\n   // enviroment maintains thread pools and other state info\n   \n   // [TODO] look into OrtCreateEnvWithCustomLogger()\n   OrtEnv* env;\n   CHECK_STATUS(OrtCreateEnv(ORT_LOGGING_LEVEL_WARNING, \"test\", &env));\n   std::unique_ptr<OrtEnv, decltype(&OrtReleaseEnv)>\n         env_wrapper(env, OrtReleaseEnv);\n \n   //===================== Backend Scope ======================\n   // session option is backend-wise as it also specified GPU device\n   // but other session option can be set \"globally\", like const variables\n   // defined in factory object and use it to set corresponding options\n   // initialize session options if needed\n   OrtSessionOptions* session_options;\n   CHECK_STATUS(OrtCreateSessionOptions(&session_options));\n   std::unique_ptr<OrtSessionOptions, decltype(&OrtReleaseSessionOptions)>\n         options_wrapper(session_options, OrtReleaseSessionOptions);\n   CHECK_STATUS(OrtSetSessionThreadPoolSize(session_options, 1));\n \n   // disable graph optimization\n   CHECK_STATUS(OrtSetSessionGraphOptimizationLevel(session_options, 0));\n \n   //===================== Context Scope ======================\n   // create multiple sessions and load models into memory\n   std::vector<std::pair<const char*, int>> model_spec;\n   {\n     // deploy model on all devices\n     // [TODO] argument option\n     model_spec.emplace_back(\"model.onnx\", -1);\n     model_spec.emplace_back(\"model.onnx\", 0);\n     model_spec.emplace_back(\"model.onnx\", 1);\n   }\n \n   std::vector<std::unique_ptr<OrtSession, decltype(&OrtReleaseSession)>> sessions;\n   for (const auto path_device : model_spec) {\n     OrtSession* session;\n     CreateSession(\n         path_device.first, path_device.second, env, session_options, &session);\n     sessions.emplace_back(session, OrtReleaseSession);\n   }\n \n   //===================== Infer Scope ======================\n   for (auto& session_wrapper : sessions) {\n     auto session = session_wrapper.get();\n     \n     // print model input/output layer (node names, types, shape etc.)\n     std::cout << \"Input infos:\" << std::endl;\n     auto input_infos = GetIOTensors(session, true);\n \n     std::cout << \"Output infos:\" << std::endl;\n     auto output_infos = GetIOTensors(session, false);\n \n     // Fill input tensors\n     std::vector<const char*> input_names;\n     std::vector<OrtValue*> input_tensors;\n     for (auto input_info : input_infos) {\n       if (input_info.type_ != ONNX_TENSOR_ELEMENT_DATA_TYPE_STRING) {\n         input_names.emplace_back(input_info.name_);\n         // [TODO] generate meaningful input so that output can be validated\n         input_tensors.emplace_back(CreateTensor(input_info));\n       } else {\n         std::cout << \"Inference with STRING input hasn't been implemented\" << std::endl;\n         exit(1);\n       }\n     }\n \n     // Set output tensors to be retrieved\n     std::vector<const char*> output_names;\n     std::vector<OrtValue*> output_tensors;\n     for (auto output_info : output_infos) {\n       output_names.emplace_back(output_info.name_);\n       output_tensors.emplace_back(nullptr);\n     }\n \n     // Run...\n     CHECK_STATUS(OrtRun(\n         session, NULL /* run options */, input_names.data(),\n         (const OrtValue* const*)input_tensors.data(), input_tensors.size(),\n         output_names.data(), output_names.size(), output_tensors.data()));\n   }\n \n   // Factory-wise\n   \n   return 0;\n }\n \n Expected behavior\n The sample code can run all model sessions on all devices without throwing errors.\n \n The commit version I used before was <denchmark-link:https://github.com/microsoft/onnxruntime/commit/2f698bd54b713bb87dbd0bbb913e94bcf7fd480c>2f698bd</denchmark-link>\n \n Compare with rel-0.5.0:\n <denchmark-link:https://github.com/microsoft/onnxruntime/compare/2f698bd54b713bb87dbd0bbb913e94bcf7fd480c...rel-0.5.0>2f698bd...rel-0.5.0</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "GuanLuo", "commentT": "2019-08-17T09:06:43Z", "comment_text": "\n \t\tI have same problem.  Are there any solution to solve it?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "GuanLuo", "commentT": "2019-08-19T01:07:53Z", "comment_text": "\n \t\tThank you for sending the great feedback! ORT is not supporting using multiple GPUs well in inference right now. We'll add the support later and update this issue once it's well supported.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "GuanLuo", "commentT": "2019-08-19T22:57:51Z", "comment_text": "\n \t\tIs there an ETA for fixing this particular operator? This is breaking the models that were okay with multi-GPU previously...\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "GuanLuo", "commentT": "2019-09-12T23:05:42Z", "comment_text": "\n \t\tI've merged my pull request to master. With this change you can run a model on a device other than device 0. But it's still not possible to run multiple model in same thread but on different device, because the cudaSetDevice works with thread scope. more details refer to this link:\n <denchmark-link:https://devblogs.nvidia.com/cuda-pro-tip-always-set-current-device-avoid-multithreading-bugs/>https://devblogs.nvidia.com/cuda-pro-tip-always-set-current-device-avoid-multithreading-bugs/</denchmark-link>\n \n so, from your sample code, there's a session using device 0, then another session using device 1. When the program runs, it will use device 1 for these 2 sessions finally. To make it able to run on different device within same thread, there are more work to be done. e.g. need to re-call cudaSetDevice before every cuda kernel and cuda allocator.\n For now, you can create and run different session in different threads, that is no problem.\n Let us know if you still have some concerns on this.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "GuanLuo", "commentT": "2019-09-12T23:19:04Z", "comment_text": "\n \t\tThanks for the fix, I will try it out later and close the issue.\n And regarding the multiple devices issue you pointed out, does this <denchmark-link:https://github.com/microsoft/onnxruntime/issues/1034#issuecomment-497184636>workaround</denchmark-link>\n  work the same as \"create and run different session in different threads\"? In this workaround, I will create the sessions in different threads, but I will only use one thread to distribute requests to different sessions.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "GuanLuo", "commentT": "2019-09-12T23:30:10Z", "comment_text": "\n \t\tYes, that should work fine.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "GuanLuo", "commentT": "2019-09-16T18:59:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/HectorSVC>@HectorSVC</denchmark-link>\n  Thanks, I have verified that the issue is fixed, closing the issue now. By the way, it seems like multi-GPU work without using the workaround: I created sessions for the same model on different GPUs and send requests to them, the GPU memory usage and utilization increases roughly the same amount on both GPUs\n \t\t"}}}, "commit": {"commit_id": "a0ba25f98f210fa506300bb5040695e2b7a636a8", "commit_author": "Hector Li", "commitT": "2019-09-12 15:31:59-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "0.3333333333333333", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "onnxruntime\\contrib_ops\\cuda\\activation\\activations.cc", "file_new_name": "onnxruntime\\contrib_ops\\cuda\\activation\\activations.cc", "file_complexity": {"file_NLOC": "15", "file_CCN": "0", "file_NToken": "67"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "30", "deleted_lines": "30"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "onnxruntime\\core\\providers\\cuda\\activation\\activations.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\activation\\activations.cc", "file_complexity": {"file_NLOC": "15", "file_CCN": "0", "file_NToken": "80"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "26", "deleted_lines": "26"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 10, "file_old_name": "onnxruntime\\core\\providers\\cuda\\cuda_common.h", "file_new_name": "onnxruntime\\core\\providers\\cuda\\cuda_common.h", "file_complexity": {"file_NLOC": "136", "file_CCN": "31", "file_NToken": "915"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "87,88", "deleted_lines": "87,88", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::AllocCpuPtr", "method_params": "id,count", "method_startline": "87", "method_endline": "92", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "42", "method_nesting_level": "4"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "75,76", "deleted_lines": "75,76", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CudaAsyncBuffer", "method_params": "op_kernel,device_id,value,count", "method_startline": "75", "method_endline": "81", "method_complexity": {"method_NLOC": "7", "method_CCN": "2", "method_NToken": "59", "method_nesting_level": "4"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "83", "deleted_lines": "83", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CudaAsyncBuffer", "method_params": "op_kernel,device_id,vec", "method_startline": "83", "method_endline": "85", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "59", "method_nesting_level": "4"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "48,49", "deleted_lines": "48,49", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::AllocateBufferOnCPUPinned", "method_params": "count_or_bytes", "method_startline": "48", "method_endline": "53", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "41", "method_nesting_level": "3"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "87,88", "deleted_lines": "87,88", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::AllocCpuPtr", "method_params": "count", "method_startline": "87", "method_endline": "92", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "37", "method_nesting_level": "4"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "83", "deleted_lines": "83", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CudaAsyncBuffer", "method_params": "op_kernel,vec", "method_startline": "83", "method_endline": "85", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "54", "method_nesting_level": "4"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "75,76", "deleted_lines": "75,76", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CudaAsyncBuffer", "method_params": "op_kernel,value,count", "method_startline": "75", "method_endline": "81", "method_complexity": {"method_NLOC": "7", "method_CCN": "2", "method_NToken": "54", "method_nesting_level": "4"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "71,72", "deleted_lines": "71,72", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CudaAsyncBuffer", "method_params": "op_kernel,count", "method_startline": "71", "method_endline": "73", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "22", "method_nesting_level": "4"}}}, "hunk_8": {"Ismethod": 1, "added_lines": "71,72", "deleted_lines": "71,72", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CudaAsyncBuffer", "method_params": "op_kernel,device_id,count", "method_startline": "71", "method_endline": "73", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "27", "method_nesting_level": "4"}}}, "hunk_9": {"Ismethod": 1, "added_lines": "48,49", "deleted_lines": "48,49", "method_info": {"method_name": "onnxruntime::cuda::CudaKernel::AllocateBufferOnCPUPinned", "method_params": "id,count_or_bytes", "method_startline": "48", "method_endline": "53", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "44", "method_nesting_level": "3"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "onnxruntime\\core\\providers\\cuda\\cuda_execution_provider.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\cuda_execution_provider.cc", "file_complexity": {"file_NLOC": "1007", "file_CCN": "88", "file_NToken": "12798"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "87", "deleted_lines": null, "method_info": {"method_name": "onnxruntime::CUDAExecutionProvider::~CUDAExecutionProvider", "method_params": "", "method_startline": "86", "method_endline": "102", "method_complexity": {"method_NLOC": "17", "method_CCN": "4", "method_NToken": "118", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "70,74,75,79,80,81,82,83", "deleted_lines": "70,74,75,79,80,84", "method_info": {"method_name": "onnxruntime::CUDAExecutionProvider::CUDAExecutionProvider", "method_params": "info", "method_startline": "65", "method_endline": "84", "method_complexity": {"method_NLOC": "15", "method_CCN": "1", "method_NToken": "204", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\cuda_execution_provider.h", "file_new_name": "onnxruntime\\core\\providers\\cuda\\cuda_execution_provider.h", "file_complexity": {"file_NLOC": "106", "file_CCN": "17", "file_NToken": "661"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "57", "deleted_lines": "55", "method_info": {"method_name": "onnxruntime::CUDAExecutionProvider::GetScratchBuffer", "method_params": "count_or_bytes", "method_startline": "53", "method_endline": "58", "method_complexity": {"method_NLOC": "5", "method_CCN": "2", "method_NToken": "35", "method_nesting_level": "2"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 12, "file_old_name": "onnxruntime\\core\\providers\\cuda\\math\\binary_elementwise_ops.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\math\\binary_elementwise_ops.cc", "file_complexity": {"file_NLOC": "339", "file_CCN": "30", "file_NToken": "3526"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "311,324", "deleted_lines": "311,324", "method_info": {"method_name": "onnxruntime::cuda::Max<T>::ComputeInternal", "method_params": "context", "method_startline": "286", "method_endline": "339", "method_complexity": {"method_NLOC": "50", "method_CCN": "4", "method_NToken": "571", "method_nesting_level": "2"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "50,64", "deleted_lines": "50,64", "method_info": {"method_name": "onnxruntime::cuda::BinaryElementwiseBroadcastPrepare", "method_params": "lhs_tensor,rhs_tensor,output_tensor,p,override_lhs_shape,override_rhs_shape", "method_startline": "49", "method_endline": "67", "method_complexity": {"method_NLOC": "16", "method_CCN": "3", "method_NToken": "118", "method_nesting_level": "2"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "70,80", "deleted_lines": "70,80", "method_info": {"method_name": "onnxruntime::cuda::BinaryElementwise<ShouldBroadcast>::Prepare", "method_params": "context,device_id,p", "method_startline": "70", "method_endline": "83", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "127", "method_nesting_level": "2"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "449", "deleted_lines": "449", "method_info": {"method_name": "onnxruntime::cuda::Equal<T>::ComputeInternal", "method_params": "context", "method_startline": "436", "method_endline": "469", "method_complexity": {"method_NLOC": "30", "method_CCN": "1", "method_NToken": "316", "method_nesting_level": "2"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "487", "deleted_lines": "487", "method_info": {"method_name": "onnxruntime::cuda::Less<T>::ComputeInternal", "method_params": "context", "method_startline": "474", "method_endline": "507", "method_complexity": {"method_NLOC": "30", "method_CCN": "1", "method_NToken": "316", "method_nesting_level": "2"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "13", "deleted_lines": "13", "method_info": {"method_name": "onnxruntime::cuda::BinaryElementwise<ShouldNotBroadcast>::Prepare", "method_params": "context,p", "method_startline": "13", "method_endline": "21", "method_complexity": {"method_NLOC": "9", "method_CCN": "2", "method_NToken": "151", "method_nesting_level": "2"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "251,267", "deleted_lines": "251,267", "method_info": {"method_name": "onnxruntime::cuda::Sum<T>::ComputeInternal", "method_params": "context", "method_startline": "227", "method_endline": "283", "method_complexity": {"method_NLOC": "53", "method_CCN": "5", "method_NToken": "584", "method_nesting_level": "2"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "13", "deleted_lines": "13", "method_info": {"method_name": "onnxruntime::cuda::BinaryElementwise<ShouldNotBroadcast>::Prepare", "method_params": "context,int,p", "method_startline": "13", "method_endline": "21", "method_complexity": {"method_NLOC": "9", "method_CCN": "2", "method_NToken": "153", "method_nesting_level": "2"}}}, "hunk_8": {"Ismethod": 1, "added_lines": "50,64", "deleted_lines": "50,64", "method_info": {"method_name": "onnxruntime::cuda::BinaryElementwiseBroadcastPrepare", "method_params": "device_id,lhs_tensor,rhs_tensor,output_tensor,p,override_lhs_shape,override_rhs_shape", "method_startline": "49", "method_endline": "67", "method_complexity": {"method_NLOC": "16", "method_CCN": "3", "method_NToken": "123", "method_nesting_level": "2"}}}, "hunk_9": {"Ismethod": 1, "added_lines": "70,80", "deleted_lines": "70,80", "method_info": {"method_name": "onnxruntime::cuda::BinaryElementwise<ShouldBroadcast>::Prepare", "method_params": "context,p", "method_startline": "70", "method_endline": "83", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "122", "method_nesting_level": "2"}}}, "hunk_10": {"Ismethod": 1, "added_lines": "413", "deleted_lines": "413", "method_info": {"method_name": "onnxruntime::cuda::Greater<T>::ComputeInternal", "method_params": "context", "method_startline": "400", "method_endline": "433", "method_complexity": {"method_NLOC": "30", "method_CCN": "1", "method_NToken": "316", "method_nesting_level": "2"}}}, "hunk_11": {"Ismethod": 1, "added_lines": "367,380", "deleted_lines": "367,380", "method_info": {"method_name": "onnxruntime::cuda::Min<T>::ComputeInternal", "method_params": "context", "method_startline": "342", "method_endline": "395", "method_complexity": {"method_NLOC": "50", "method_CCN": "4", "method_NToken": "571", "method_nesting_level": "2"}}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "onnxruntime\\core\\providers\\cuda\\math\\binary_elementwise_ops.h", "file_new_name": "onnxruntime\\core\\providers\\cuda\\math\\binary_elementwise_ops.h", "file_complexity": {"file_NLOC": "185", "file_CCN": "35", "file_NToken": "1371"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "37,85,92,98", "deleted_lines": "37,85,92,98", "method_info": {"method_name": "onnxruntime::cuda::BinaryElementwisePreparation::BinaryElementwiseBroadcastPrepareHelper", "method_params": "device_id,lhs_shape,rhs_shape,output_shape", "method_startline": "37", "method_endline": "101", "method_complexity": {"method_NLOC": "50", "method_CCN": "16", "method_NToken": "536", "method_nesting_level": "3"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "37,85,92,98", "deleted_lines": "37,85,92,98", "method_info": {"method_name": "onnxruntime::cuda::BinaryElementwisePreparation::BinaryElementwiseBroadcastPrepareHelper", "method_params": "lhs_shape,rhs_shape,output_shape", "method_startline": "37", "method_endline": "101", "method_complexity": {"method_NLOC": "50", "method_CCN": "16", "method_NToken": "527", "method_nesting_level": "3"}}}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\math\\matmul.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\math\\matmul.cc", "file_complexity": {"file_NLOC": "67", "file_CCN": "2", "file_NToken": "676"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "70,71,72", "deleted_lines": "70,71,72,73", "method_info": {"method_name": "onnxruntime::cuda::MatMul<T>::ComputeInternal", "method_params": "ctx", "method_startline": "37", "method_endline": "100", "method_complexity": {"method_NLOC": "55", "method_CCN": "2", "method_NToken": "636", "method_nesting_level": "2"}}}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\reduction\\reduction_ops.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\reduction\\reduction_ops.cc", "file_complexity": {"file_NLOC": "206", "file_CCN": "24", "file_NToken": "1814"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "162", "deleted_lines": "162", "method_info": {"method_name": "onnxruntime::cuda::ReduceKernel<allow_multi_axes>::ComputeImpl", "method_params": "ctx,cudnnReduceOp", "method_startline": "60", "method_endline": "242", "method_complexity": {"method_NLOC": "154", "method_CCN": "18", "method_NToken": "1616", "method_nesting_level": "2"}}}}}, "file_9": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "onnxruntime\\core\\providers\\cuda\\rnn\\cudnn_rnn_base.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\rnn\\cudnn_rnn_base.cc", "file_complexity": {"file_NLOC": "316", "file_CCN": "50", "file_NToken": "2780"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "351", "deleted_lines": "351", "method_info": {"method_name": "onnxruntime::cuda::CudnnRnnBase<T>::ComputeInternal", "method_params": "ctx", "method_startline": "136", "method_endline": "365", "method_complexity": {"method_NLOC": "188", "method_CCN": "35", "method_NToken": "1668", "method_nesting_level": "2"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "374", "deleted_lines": "374", "method_info": {"method_name": "onnxruntime::cuda::CudnnRnnBase<T>::SetZeroSequences", "method_params": "zero_seq_index_cache_size,zero_seq_index_cache,y_data,y_h_data,y_c_data", "method_startline": "368", "method_endline": "383", "method_complexity": {"method_NLOC": "16", "method_CCN": "1", "method_NToken": "138", "method_nesting_level": "2"}}}}}, "file_10": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\concat.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\concat.cc", "file_complexity": {"file_NLOC": "59", "file_CCN": "5", "file_NToken": "469"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "30,47,48,49", "deleted_lines": "28,31,48,49,50", "method_info": {"method_name": "onnxruntime::cuda::Concat::ComputeInternal", "method_params": "ctx", "method_startline": "18", "method_endline": "68", "method_complexity": {"method_NLOC": "45", "method_CCN": "5", "method_NToken": "428", "method_nesting_level": "2"}}}}}, "file_11": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\expand.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\expand.cc", "file_complexity": {"file_NLOC": "62", "file_CCN": "4", "file_NToken": "498"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "36,37,38", "deleted_lines": "14,37,38,39", "method_info": {"method_name": "onnxruntime::cuda::Expand::ComputeInternal", "method_params": "ctx", "method_startline": "11", "method_endline": "69", "method_complexity": {"method_NLOC": "46", "method_CCN": "4", "method_NToken": "446", "method_nesting_level": "2"}}}}}, "file_12": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\gather.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\gather.cc", "file_complexity": {"file_NLOC": "49", "file_CCN": "1", "file_NToken": "325"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "65", "deleted_lines": "65", "method_info": {"method_name": "onnxruntime::cuda::Gather::ComputeInternal", "method_params": "context", "method_startline": "51", "method_endline": "88", "method_complexity": {"method_NLOC": "30", "method_CCN": "1", "method_NToken": "249", "method_nesting_level": "2"}}}}}, "file_13": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\pad.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\pad.cc", "file_complexity": {"file_NLOC": "52", "file_CCN": "2", "file_NToken": "460"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "27,28,29,30,31", "deleted_lines": "27,28,29,30,31,32", "method_info": {"method_name": "onnxruntime::cuda::Pad<T>::ComputeInternal", "method_params": "ctx", "method_startline": "23", "method_endline": "69", "method_complexity": {"method_NLOC": "41", "method_CCN": "2", "method_NToken": "427", "method_nesting_level": "2"}}}}}, "file_14": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\slice.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\slice.cc", "file_complexity": {"file_NLOC": "69", "file_CCN": "6", "file_NToken": "551"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "71,78,85,91", "deleted_lines": "71,72,79,86,92", "method_info": {"method_name": "onnxruntime::cuda::Slice<Tind,dynamic>::ComputeInternal", "method_params": "ctx", "method_startline": "43", "method_endline": "111", "method_complexity": {"method_NLOC": "57", "method_CCN": "6", "method_NToken": "504", "method_nesting_level": "2"}}}}}, "file_15": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\split.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\split.cc", "file_complexity": {"file_NLOC": "74", "file_CCN": "4", "file_NToken": "484"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "44,62,69,72", "deleted_lines": "44,45,63,70,73", "method_info": {"method_name": "onnxruntime::cuda::Split::ComputeInternal", "method_params": "ctx", "method_startline": "20", "method_endline": "88", "method_complexity": {"method_NLOC": "58", "method_CCN": "4", "method_NToken": "439", "method_nesting_level": "2"}}}}}, "file_16": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\tile.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\tile.cc", "file_complexity": {"file_NLOC": "50", "file_CCN": "5", "file_NToken": "469"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "46,47,48", "deleted_lines": "46,47,48,49", "method_info": {"method_name": "onnxruntime::cuda::Tile<T>::ComputeInternal", "method_params": "ctx", "method_startline": "25", "method_endline": "71", "method_complexity": {"method_NLOC": "38", "method_CCN": "5", "method_NToken": "431", "method_nesting_level": "2"}}}}}, "file_17": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\transpose.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\transpose.cc", "file_complexity": {"file_NLOC": "91", "file_CCN": "19", "file_NToken": "822"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "95,96,97", "deleted_lines": "95,96,97,98", "method_info": {"method_name": "onnxruntime::cuda::Transpose<T>::ComputeInternal", "method_params": "ctx", "method_startline": "50", "method_endline": "115", "method_complexity": {"method_NLOC": "59", "method_CCN": "5", "method_NToken": "524", "method_nesting_level": "2"}}}}}, "file_18": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "onnxruntime\\core\\providers\\cuda\\tensor\\upsample.cc", "file_new_name": "onnxruntime\\core\\providers\\cuda\\tensor\\upsample.cc", "file_complexity": {"file_NLOC": "96", "file_CCN": "20", "file_NToken": "816"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "66,70,83,95", "deleted_lines": "65,67,71,84,96", "method_info": {"method_name": "onnxruntime::cuda::Upsample<T>::BaseCompute", "method_params": "context,scales", "method_startline": "34", "method_endline": "115", "method_complexity": {"method_NLOC": "69", "method_CCN": "17", "method_NToken": "651", "method_nesting_level": "2"}}}}}}}}