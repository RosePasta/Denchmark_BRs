{"BR": {"BR_id": "3391", "BR_author": "TianzhongSong", "BRopenT": "2020-04-01T10:14:26Z", "BRcloseT": "2020-04-30T21:17:10Z", "BR_text": {"BRsummary": "GPU topk may get different results with same input", "BRdescription": "\n System information\n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu18.04\n ONNX Runtime installed from (source or binary): source (latest commit:a61400d)\n ONNX Runtime version: 1.2.0\n Python version: 3.6\n Visual Studio version (if applicable):\n GCC/Compiler version (if compiling from source): 7.5.0\n CUDA/cuDNN version: CUDA10.2, cuDNN7.6\n GPU model and memory: RTX2080Ti, 11G\n \n To Reproduce\n <denchmark-h:h2>Pytorch demo</denchmark-h>\n \n <denchmark-code>import torch\n import torch.nn as nn\n \n \n class Model(nn.Module):\n \n     def forward(self, x):\n         x, y = x.topk(5, dim=-1)\n         return x, y\n \n \n if __name__ == \"__main__\":\n     model = Model()\n     model.eval()\n \n     input_tensor = torch.randn(5, 7175)\n \n     print('Export to onnx..')\n     torch.onnx.export(model, input_tensor, \"topk.onnx\",\n                       opset_version=11,\n                       verbose=False,\n                       input_names=['data'],\n                       dynamic_axes={'data': {0: 'dim1'}})\n \n </denchmark-code>\n \n <denchmark-h:h2>onnxruntime demo</denchmark-h>\n \n <denchmark-code>import onnxruntime as ort\n import numpy as np\n \n sess = ort.InferenceSession(\"topk.onnx\")\n \n data = np.load(\"feature1.npy\")\n \n inputs = {\"data\": data}\n \n values1, indexs1 = sess.run(None, inputs)\n \n for i in range(10):\n     values, indexs = sess.run(None, inputs)\n     print(\"iters: {}\".format(i))\n     print(\"sum of value diff: {}\".format(np.sum(np.abs(values1 - values))))\n     print(\"sum of index diff: {}\".format(np.sum(np.abs(indexs1 - indexs))))\n \n </denchmark-code>\n \n Expected behavior\n onnxruntime can not always get same results each iteration.\n Some outputs:\n <denchmark-code>iters: 0\n sum of value diff: 0.0\n sum of index diff: 0\n iters: 1\n sum of value diff: 1.0\n sum of index diff: 10941\n iters: 2\n sum of value diff: 0.0\n sum of index diff: 0\n iters: 3\n sum of value diff: 0.0\n sum of index diff: 0\n iters: 4\n sum of value diff: 0.0\n sum of index diff: 0\n iters: 5\n sum of value diff: 0.0\n sum of index diff: 0\n iters: 6\n sum of value diff: 0.0\n sum of index diff: 0\n iters: 7\n sum of value diff: 0.0\n sum of index diff: 0\n iters: 8\n sum of value diff: 0.0\n sum of index diff: 0\n iters: 9\n sum of value diff: 0.0\n sum of index diff: 0\n </denchmark-code>\n \n test data, unzip it and load it in ort demo\n <denchmark-link:https://github.com/microsoft/onnxruntime/files/4414364/feature1.zip>feature1.zip</denchmark-link>\n \n Thank you.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "TianzhongSong", "commentT": "2020-04-28T04:30:33Z", "comment_text": "\n \t\tThe bitonic-topk we implemented for topk cuda compares value of floats in multi-threading env, sometime two equal floats are placed in reversed order between rounds of test. Will delve deeper for a solution.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "TianzhongSong", "commentT": "2020-04-30T03:47:11Z", "comment_text": "\n \t\tIt turns out to be a sync issue, cub functions are not doing that for caller, we are on our own.\n \t\t"}}}, "commit": {"commit_id": "86eaa71ec69fe8961dd58a364052d61831dae5ed", "commit_author": "RandySheriffH", "commitT": "2020-04-30 14:16:46-07:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "onnxruntime\\core\\providers\\cuda\\math\\topk_impl.cu", "file_new_name": "onnxruntime\\core\\providers\\cuda\\math\\topk_impl.cu", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "151,152,153,154,156,157,158,159,160,161,232,299", "deleted_lines": "152"}}}}}}