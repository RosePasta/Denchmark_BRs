{"BR": {"BR_id": "1157", "BR_author": "kaijennissen", "BRopenT": "2020-11-19T09:18:33Z", "BRcloseT": "2020-11-20T11:01:07Z", "BR_text": {"BRsummary": "Multiprocessing hangs when num_workers &gt; len(dataset)", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n I'm trying to serialize a predictor trained on multiple cores. When calling the serialize method nothing happens.\n Running the same code, but without specifying num_workers, it works as expected.\n <denchmark-h:h2>To Reproduce</denchmark-h>\n \n from pathlib import Path\n from typing import Optional\n \n from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n from gluonts.dataset.common import TrainDatasets\n from gluonts.model.gpvar import GPVAREstimator\n from gluonts.dataset.repository.datasets import get_dataset\n from gluonts.mx.trainer import Trainer\n \n \n def load_multivariate_dataset(dataset_name: str, target_dim: Optional[int] = None):\n     ds = get_dataset(dataset_name)\n \n     if target_dim is None:\n         target_dim = len(ds.train)\n \n     grouper = MultivariateGrouper(max_target_dim=target_dim)\n \n     meta = ds.metadata\n     meta.feat_static_cat[0].cardinality = target_dim\n \n     return (TrainDatasets(\n         metadata=meta,\n         train=grouper(ds.train),\n         test=grouper(ds.test)\n     ), target_dim)\n \n \n ds, target_dim = load_multivariate_dataset(\"exchange_rate\")\n metadata = ds.metadata\n \n estimator = GPVAREstimator(\n     prediction_length=metadata.prediction_length,\n     freq=metadata.freq,\n     target_dim=target_dim,\n     trainer=Trainer(\n         epochs=2,\n         num_batches_per_epoch=10,\n         batch_size=8,\n     ),\n )\n \n predictor = estimator.train(training_data=ds.train, num_workers=2)\n \n predictor.serialize(Path(\"/tmp\"))\n <denchmark-h:h2>Error message or code output</denchmark-h>\n \n Nothing happens.\n <denchmark-h:h2>Environment</denchmark-h>\n \n \n Operating system: Mac OSX 10.15.7\n Python version: 3.6.12\n GluonTS version: 0.6.0\n MXNet version: 1.7.0post1\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "kaijennissen", "commentT": "2020-11-19T10:29:15Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/kaijennissen>@kaijennissen</denchmark-link>\n  I'm not able to reproduce this: the following snippet, adapted from yours, doesn't raise an error\n (I modified the path where the model is serialized, and added a test in the end to check if the reconstructed model is the same)\n Edit: I'm using master with mxnet==1.7.0post1\n from pathlib import Path\n from typing import Optional\n import tempfile\n \n from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n from gluonts.dataset.common import TrainDatasets\n from gluonts.model.predictor import Predictor\n from gluonts.model.gpvar import GPVAREstimator\n from gluonts.dataset.repository.datasets import get_dataset\n from gluonts.mx.trainer import Trainer\n \n \n def load_multivariate_dataset(dataset_name: str, target_dim: Optional[int] = None):\n     ds = get_dataset(dataset_name)\n \n     if target_dim is None:\n         target_dim = len(ds.train)\n \n     grouper = MultivariateGrouper(max_target_dim=target_dim)\n \n     meta = ds.metadata\n     meta.feat_static_cat[0].cardinality = target_dim\n \n     return (TrainDatasets(\n         metadata=meta,\n         train=grouper(ds.train),\n         test=grouper(ds.test)\n     ), target_dim)\n \n \n ds, target_dim = load_multivariate_dataset(\"exchange_rate\")\n metadata = ds.metadata\n \n estimator = GPVAREstimator(\n     prediction_length=metadata.prediction_length,\n     freq=metadata.freq,\n     target_dim=target_dim,\n     trainer=Trainer(\n         epochs=2,\n         num_batches_per_epoch=10,\n         batch_size=8,\n     ),\n )\n \n predictor = estimator.train(training_data=ds.train, num_workers=2)\n \n with tempfile.TemporaryDirectory() as path_str:\n     print(f\"saving model in {path_str}\")\n     predictor.serialize(Path(path_str))\n     predictor_copy = Predictor.deserialize(Path(path_str))\n \n assert predictor == predictor_copy\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "kaijennissen", "commentT": "2020-11-19T10:45:46Z", "comment_text": "\n \t\tI just tried it on gpu with\n import multiprocessing\n multiprocessing.set_start_method(\"spawn\", force=True)\n at the beginning of the script. The training takes approx. 4 minutes to start.\n On CPU it works, but the CPU usage of Python goes up to 99% after the code finishes until I restart the kernel. I think there are some processes which do not get terminated. I think this is related to <denchmark-link:https://github.com/awslabs/gluon-ts/issues/941>#941</denchmark-link>\n .\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "kaijennissen", "commentT": "2020-11-19T13:11:54Z", "comment_text": "\n \t\t\n On CPU it works, but the CPU usage of Python goes up to 99% after the code finishes until I restart the kernel. I think there are some processes which do not get terminated. I think this is related to #941.\n \n You' re right.\n I've modified the last part and it appears that the problem is not the serialization but that some processes are not terminated.\n It also occurs inside a docker container, with Gitpod (using master) and on a EC2 DLAMI instance (using the mxnet_latest_p37 conda env and pip install gluonts==0.6).\n print(\"Finished serialization!\")\n assert predictor == predictor_copy\n <denchmark-code>learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:25<00:00,  2.52s/it, epoch=1/2, avg_epoch_loss=1.31]\n 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:18<00:00,  1.90s/it, epoch=2/2, avg_epoch_loss=-.802]\n saving model in /tmp/tmpz684afay\n WARNING:root:Serializing RepresentableBlockPredictor instances does not save the prediction network structure in a backwards-compatible manner. Be careful not to use this method in production.\n Finished serialization!\n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "kaijennissen", "commentT": "2020-11-19T15:26:10Z", "comment_text": "\n \t\tLooks like the MultivariateGrouper doesn't play well with multiprocessing: the following example works fine with use_grouper = False (where we construct a multivariate dataset manually), but hangs with use_grouper = True (where we group an originally univariate dataset to get a multivariate one).\n import pandas as pd\n import numpy as np\n \n from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n from gluonts.model.gpvar import GPVAREstimator\n from gluonts.mx.trainer import Trainer\n \n use_grouper = False\n \n if use_grouper:\n     dataset = [\n         {\"start\": pd.Timestamp(\"2020-01-01 00:00:00\", freq=\"1H\"), \"target\": np.array([1.0]*1000)}\n         for _ in range(8)\n     ]\n     grouper = MultivariateGrouper(max_target_dim=8)\n     multivariate_dataset = grouper(dataset)\n else:\n     multivariate_dataset = [\n         {\"start\": pd.Timestamp(\"2020-01-01 00:00:00\", freq=\"1H\"), \"target\": np.array([[1.0]*1000] * 8)}\n     ]\n \n estimator = GPVAREstimator(\n     prediction_length=24,\n     freq=\"1H\",\n     target_dim=8,\n     trainer=Trainer(\n         epochs=2,\n         num_batches_per_epoch=10,\n         batch_size=8,\n     ),\n )\n \n predictor = estimator.train(training_data=multivariate_dataset, num_workers=2)\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "kaijennissen", "commentT": "2020-11-19T15:47:59Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/kaijennissen>@kaijennissen</denchmark-link>\n  <denchmark-link:https://github.com/PascalIversen>@PascalIversen</denchmark-link>\n  the problem appears to be , I reduced the issue to the following minimal example (univariate with DeepAR, but I also checked multivariate with GPVAR):\n from gluonts.dataset.common import ListDataset\n from gluonts.model.deepar import DeepAREstimator\n from gluonts.mx.trainer import Trainer\n \n univariate_dataset = ListDataset(\n     data_iter=[\n         {\"start\": \"2020-01-01 00:00:00\", \"target\": [1.0] * 1000}\n     ],\n     freq=\"1H\",\n )\n \n estimator = DeepAREstimator(\n     prediction_length=24,\n     freq=\"1H\",\n     trainer=Trainer(\n         epochs=2,\n         num_batches_per_epoch=10,\n         batch_size=8,\n     ),\n )\n \n predictor = estimator.train(training_data=univariate_dataset, num_workers=2)\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "kaijennissen", "commentT": "2020-11-19T16:23:04Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/lostella>@lostella</denchmark-link>\n  Okay. To summarize this.\n For a univariate datasets with multiple entries, one can speed up training by setting .\n The only way to reduce training time in case of a multivariate dataset (which will be of length 1) is to use a .\n Correct?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "kaijennissen", "commentT": "2020-11-19T16:31:28Z", "comment_text": "\n \t\tThis works :\n from gluonts.model.deepar import DeepAREstimator\n from gluonts.mx.trainer import Trainer\n import pandas as pd\n data_iter=[\n     {\"start\": pd.Timestamp(\"1990-01-01 00:00:00\", freq=\"1H\"), \"target\": [1.0] * 1000}\n ]\n estimator = DeepAREstimator(\n     prediction_length=24,\n     freq=\"1H\",\n     trainer=Trainer(\n         epochs=2,\n         num_batches_per_epoch=10,\n         batch_size=8,\n     ),\n )\n \n predictor = estimator.train(training_data=data_iter, num_workers=2)\n Maybe the problem is the ListDataset?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "kaijennissen", "commentT": "2020-11-19T16:49:33Z", "comment_text": "\n \t\tThis works for as-well (only difference is the list() in the last line)\n from pathlib import Path\n from typing import Optional\n \n from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n from gluonts.dataset.common import TrainDatasets\n from gluonts.model.gpvar import GPVAREstimator\n from gluonts.dataset.repository.datasets import get_dataset\n from gluonts.mx.trainer import Trainer\n \n \n def load_multivariate_dataset(dataset_name: str, target_dim: Optional[int] = None):\n     ds = get_dataset(dataset_name)\n \n     if target_dim is None:\n         target_dim = len(ds.train)\n \n     grouper = MultivariateGrouper(max_target_dim=target_dim)\n \n     meta = ds.metadata\n     meta.feat_static_cat[0].cardinality = target_dim\n \n     return (TrainDatasets(\n         metadata=meta,\n         train=grouper(ds.train),\n         test=grouper(ds.test)\n     ), target_dim)\n \n \n ds, target_dim = load_multivariate_dataset(\"exchange_rate\")\n metadata = ds.metadata\n \n estimator = GPVAREstimator(\n     prediction_length=metadata.prediction_length,\n     freq=metadata.freq,\n     target_dim=target_dim,\n     trainer=Trainer(\n         epochs=2,\n         num_batches_per_epoch=10,\n         batch_size=8,\n     ),\n )\n \n predictor = estimator.train(training_data=list(ds.train), num_workers=2)\n However the speedup on CPU compared to num_workers=None is negligible. My intuition is that data-loading is not really the bottleneck on CPU.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "kaijennissen", "commentT": "2020-11-19T16:50:40Z", "comment_text": "\n \t\t\n For a univariate datasets with multiple entries, one can speed up training by setting num_workers>1.\n \n That's correct. Whether you will observe any speedup depends on what the bottleneck is: if data loading is the bottleneck (because the lazy transformations involved there) then multiple workers will help.\n There might be other ways of speeding things up in that case, like caching some of the transformations (instead of doing them again and again) but that's not exposed yet as an option.\n \n The only way to reduce training time in case of a multivariate dataset (which will be of length 1) is to use a GPU.\n \n That's definitely one thing to try, but it may not help with all models. CNN-based models will benefit from it, and also dense layers should operate faster on GPU, but with RNN-based models one may not observe significant speedup. I'm not sure what's the case for GPVAR.\n All of this said, we should keep this issue open and fix the way data loader workers terminate in this (not so) edge case. Thanks for opening this <denchmark-link:https://github.com/kaijennissen>@kaijennissen</denchmark-link>\n !!\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "kaijennissen", "commentT": "2020-11-19T20:07:03Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/PascalIversen>@PascalIversen</denchmark-link>\n  yes, the issue is in the  (and might be in  too) and concerns what happens if some worker doesn't get assigned any slice of the dataset, which is the case when num_workers > 1 and len(dataset) == 1\n I'm not sure what happens with multiple workers when a list is used directly, but I suspect that all workers just iterate the entire list, so you can have as many workers as you like and they won't be bothered. Edit: of course this is also not the intended behavior, but outside of the scope here.\n \t\t"}}}, "commit": {"commit_id": "86f12318efdd7b41ee744a52a9d3cac1f3fb68ea", "commit_author": "Lorenzo Stella", "commitT": "2020-11-20 12:01:05+01:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "0.5555555555555556"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\gluonts\\itertools.py", "file_new_name": "src\\gluonts\\itertools.py", "file_complexity": {"file_NLOC": "55", "file_CCN": "14", "file_NToken": "249"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "24,26,27,28,29,30", "deleted_lines": "25", "method_info": {"method_name": "cyclic", "method_params": "it", "method_startline": "21", "method_endline": "30", "method_complexity": {"method_NLOC": "8", "method_CCN": "4", "method_NToken": "27", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "test\\test_itertools.py", "file_new_name": "test\\test_itertools.py", "file_complexity": {"file_NLOC": "19", "file_CCN": "3", "file_NToken": "196"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "26,27,28,29", "deleted_lines": null, "method_info": {"method_name": "test_cyclic", "method_params": "Iterable,int,List", "method_startline": "26", "method_endline": "29", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "40", "method_nesting_level": "0"}}}}}}}}