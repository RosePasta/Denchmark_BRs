{"BR": {"BR_id": "161", "BR_author": "cyrusmvahid", "BRopenT": "2019-07-01T11:34:32Z", "BRcloseT": "2019-08-23T18:24:19Z", "BR_text": {"BRsummary": "canonical estimator results in shape error", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n I am trying to run the twit example on other estimators. In this case canonical rnn.\n Here is the code:\n <denchmark-code>canonical_estimator = CanonicalRNNEstimator(freq=\"5min\", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))\n canonical_predictor = canonical_estimator.train(training_data=training_data)\n </denchmark-code>\n \n I receive shape error.\n <denchmark-code>MXNetError: Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]\n </denchmark-code>\n \n my context length is 10. It seems as the ndarray has been squeezed somewhere.\n <denchmark-h:h2>To Reproduce</denchmark-h>\n \n <denchmark-code>canonical_estimator = CanonicalRNNEstimator(freq=\"5min\", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))\n canonical_predictor = canonical_estimator.train(training_data=training_data)\n </denchmark-code>\n \n <denchmark-h:h2>Error Message</denchmark-h>\n \n I am trying to run the twit example on other estimators. In this case canonical rnn.\n Here is the code:\n <denchmark-code>canonical_estimator = CanonicalRNNEstimator(freq=\"5min\", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))\n canonical_predictor = canonical_estimator.train(training_data=training_data)\n </denchmark-code>\n \n I receive shape error.\n <denchmark-code>MXNetError: Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]\n </denchmark-code>\n \n my context length is 10. It seems as the ndarray has been squeezed somewhere.\n <denchmark-h:h2>Environment</denchmark-h>\n \n \n Operating system:\n Python version:\n GluonTS version:\n \n (Add as much information about your environment as possible, e.g. dependencies versions.)\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "cyrusmvahid", "commentT": "2019-07-01T11:38:06Z", "comment_text": "\n \t\tI am trying to run the twit example on other estimators. In this case canonical rnn.\n Here is the code:\n <denchmark-code>canonical_estimator = CanonicalRNNEstimator(freq=\"5min\", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))\n canonical_predictor = canonical_estimator.train(training_data=training_data)\n </denchmark-code>\n \n I receive shape error.\n <denchmark-code>MXNetError: Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]\n </denchmark-code>\n \n my context length is 10. It seems as the ndarray has been squeezed somewhere.\n Full error:\n <denchmark-code>infer_shape error. Arguments:\n   data0: (32, 1)\n   data1: (32, 10, 5)\n   data2: (32, 10)\n ---------------------------------------------------------------------------\n DeferredInitializationError               Traceback (most recent call last)\n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _call_cached_op(self, *args)\n     802             cargs = [args[i] if is_arg else i.data()\n --> 803                      for is_arg, i in self._cached_op_args]\n     804         except DeferredInitializationError:\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in <listcomp>(.0)\n     802             cargs = [args[i] if is_arg else i.data()\n --> 803                      for is_arg, i in self._cached_op_args]\n     804         except DeferredInitializationError:\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/parameter.py in data(self, ctx)\n     493                                \"instead.\" % (self.name, str(ctx), self._stype))\n --> 494         return self._check_and_get(self._data, ctx)\n     495 \n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/parameter.py in _check_and_get(self, arr_list, ctx)\n     207                 \"You can also avoid deferred initialization by specifying in_units, \" \\\n --> 208                 \"num_features, etc., for network layers.\"%(self.name))\n     209         raise RuntimeError(\n \n DeferredInitializationError: Parameter 'rnn8_lstm0_l0_i2h_weight' has not been initialized yet because initialization was deferred. Actual initialization happens during the first forward pass. Please pass one batch of data through the network before accessing Parameters. You can also avoid deferred initialization by specifying in_units, num_features, etc., for network layers.\n \n During handling of the above exception, another exception occurred:\n \n MXNetError                                Traceback (most recent call last)\n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _deferred_infer_shape(self, *args)\n     788         try:\n --> 789             self.infer_shape(*args)\n     790         except Exception as e:\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in infer_shape(self, *args)\n     861         \"\"\"Infers shape of Parameters from inputs.\"\"\"\n --> 862         self._infer_attrs('infer_shape', 'shape', *args)\n     863 \n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _infer_attrs(self, infer_fn, attr, *args)\n     850             arg_attrs, _, aux_attrs = getattr(out, infer_fn)(\n --> 851                 **{i.name: getattr(j, attr) for i, j in zip(inputs, args)})\n     852             if arg_attrs is None:\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/symbol/symbol.py in infer_shape(self, *args, **kwargs)\n     995         try:\n --> 996             res = self._infer_shape_impl(False, *args, **kwargs)\n     997             if res[1] is None:\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/symbol/symbol.py in _infer_shape_impl(self, partial, *args, **kwargs)\n    1125             ctypes.byref(aux_shape_data),\n -> 1126             ctypes.byref(complete)))\n    1127         if complete.value != 0:\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/base.py in check_call(ret)\n     251     if ret != 0:\n --> 252         raise MXNetError(py_str(_LIB.MXGetLastError()))\n     253 \n \n MXNetError: Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]\n \n Stack trace returned 10 entries:\n [bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f935a) [0x7f928cf2a35a]\n [bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f9981) [0x7f928cf2a981]\n [bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x73e45d) [0x7f928d26f45d]\n [bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x7a25b6) [0x7f928d2d35b6]\n [bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x9c33d8) [0x7f928d4f43d8]\n [bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e0e10a) [0x7f928f93f10a]\n [bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e10a84) [0x7f928f941a84]\n [bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(MXSymbolInferShape+0x15ba) [0x7f928f8a79aa]\n [bt] (8) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f92fc62dec0]\n [bt] (9) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f92fc62d87d]\n \n \n \n During handling of the above exception, another exception occurred:\n \n ValueError                                Traceback (most recent call last)\n <ipython-input-143-b6d286edd137> in <module>()\n       1 canonical_estimator = CanonicalRNNEstimator(freq=\"5min\", context_length=10, prediction_length=12, trainer=Trainer(epochs=EPOCHS))\n ----> 2 canonical_predictor = canonical_estimator.train(training_data=training_data)\n       3 \n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py in train(self, training_data)\n     187     def train(self, training_data: Dataset) -> Predictor:\n     188 \n --> 189         training_transformation, trained_net = self.train_model(training_data)\n     190 \n     191         # ensure that the prediction network is created within the same MXNet\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/model/estimator.py in train_model(self, training_data)\n     180             net=trained_net,\n     181             input_names=get_hybrid_forward_input_names(trained_net),\n --> 182             train_iter=training_data_loader,\n     183         )\n     184 \n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluonts/trainer/_base.py in __call__(self, net, input_names, train_iter)\n     256 \n     257                             with mx.autograd.record():\n --> 258                                 output = net(*inputs)\n     259 \n     260                                 # network can returns several outputs, the first being always the loss\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in __call__(self, *args)\n     538             hook(self, args)\n     539 \n --> 540         out = self.forward(*args)\n     541 \n     542         for hook in self._forward_hooks.values():\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in forward(self, x, *args)\n     905             with x.context as ctx:\n     906                 if self._active:\n --> 907                     return self._call_cached_op(x, *args)\n     908 \n     909                 try:\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _call_cached_op(self, *args)\n     803                      for is_arg, i in self._cached_op_args]\n     804         except DeferredInitializationError:\n --> 805             self._deferred_infer_shape(*args)\n     806             cargs = []\n     807             for is_arg, i in self._cached_op_args:\n \n ~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/gluon/block.py in _deferred_infer_shape(self, *args)\n     791             error_msg = \"Deferred initialization failed because shape\"\\\n     792                         \" cannot be inferred. {}\".format(e)\n --> 793             raise ValueError(error_msg)\n     794 \n     795     def _call_cached_op(self, *args):\n \n ValueError: Deferred initialization failed because shape cannot be inferred. Error in operator canonicaltrainingnetwork5__minus0: [11:35:55] /work/mxnet/3rdparty/mshadow/../../src/operator/tensor/../elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)) Incompatible attr in node canonicaltrainingnetwork5__minus0 at 1-th input: expected [32,10,1], got [32,10]\n \n Stack trace returned 10 entries:\n [bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f935a) [0x7f928cf2a35a]\n [bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x3f9981) [0x7f928cf2a981]\n [bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x73e45d) [0x7f928d26f45d]\n [bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x7a25b6) [0x7f928d2d35b6]\n [bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x9c33d8) [0x7f928d4f43d8]\n [bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e0e10a) [0x7f928f93f10a]\n [bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2e10a84) [0x7f928f941a84]\n [bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(MXSymbolInferShape+0x15ba) [0x7f928f8a79aa]\n [bt] (8) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f92fc62dec0]\n [bt] (9) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f92fc62d87d]\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "cyrusmvahid", "commentT": "2019-07-01T11:40:42Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/cyrusmvahid>@cyrusmvahid</denchmark-link>\n  thanks for submitting this -- could you enclose snippets and error traces in triple ticks (`) to have it formatted nicely?\n <denchmark-code>like this\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "cyrusmvahid", "commentT": "2019-07-01T11:44:10Z", "comment_text": "\n \t\tdone\n sorry\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "cyrusmvahid", "commentT": "2019-07-01T11:47:27Z", "comment_text": "\n \t\t\n done\n sorry\n \n Thank you, but remember to put triple ticks (```) one line before and one line after snippets and error traces. Sorry for being so pedantic, but nicely formatted issues are more likely to be looked into.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "cyrusmvahid", "commentT": "2019-07-01T11:48:16Z", "comment_text": "\n \t\tsure\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n On Mon, Jul 1, 2019 at 1:47 PM Lorenzo Stella ***@***.***> wrote:\n  done\n  sorry\n \n  Thank you, but remember to put *triple* ticks (```) one line before and\n  one line after snippets and error traces. Sorry for being so pedantic, but\n  nicely formatted issues are more likely to be looked into.\n \n  \u2014\n  You are receiving this because you were mentioned.\n  Reply to this email directly, view it on GitHub\n  <#161?email_source=notifications&email_token=ABLOVGPRZVJO6ZER4WFTLVLP5HVFDA5CNFSM4H4ROYDKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODY53ZPY#issuecomment-507231423>,\n  or mute the thread\n  <https://github.com/notifications/unsubscribe-auth/ABLOVGKEB7UEZ5UDHGYVEXDP5HVFDANCNFSM4H4ROYDA>\n  .\n \n \n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "cyrusmvahid", "commentT": "2019-08-23T18:24:19Z", "comment_text": "\n \t\tFixed in <denchmark-link:https://github.com/awslabs/gluon-ts/pull/254>#254</denchmark-link>\n , closing\n \t\t"}}}, "commit": {"commit_id": "4740da09eaec4f819c39eb4c1577188586519515", "commit_author": "Lorenzo Stella", "commitT": "2019-08-23 20:00:50+02:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "src\\gluonts\\model\\canonical\\_network.py", "file_new_name": "src\\gluonts\\model\\canonical\\_network.py", "file_complexity": {"file_NLOC": "137", "file_CCN": "6", "file_NToken": "544"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "44,110,178", "deleted_lines": "44,110,111,179,180"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "test\\model\\test_models.py", "file_new_name": "test\\model\\test_models.py", "file_complexity": {"file_NLOC": "228", "file_CCN": "15", "file_NToken": "1212"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "267,268,269,270,271", "method_info": {"method_name": "test_hybridize", "method_params": "Estimator,hyperparameters", "method_startline": "267", "method_endline": "271", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "34", "method_nesting_level": "0"}}}}}}}}