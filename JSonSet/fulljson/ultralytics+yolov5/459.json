{"BR": {"BR_id": "459", "BR_author": "AlexWang1900", "BRopenT": "2020-07-21T02:39:48Z", "BRcloseT": "2020-07-23T02:24:17Z", "BR_text": {"BRsummary": "custom anchors get flushed when loading pretrain weights", "BRdescription": "\n Before submitting a bug report, please be aware that your issue must be reproducible with all of the following, otherwise it is non-actionable, and we can not help you:\n \n Current repo: run git fetch && git status -uno to check and git pull to update repo\n Common dataset: coco.yaml or coco128.yaml\n Common environment: Colab, Google Cloud, or Docker image. See https://github.com/ultralytics/yolov5#reproduce-our-environment\n \n If this is a custom dataset/training question you must include your train*.jpg, test*.jpg and results.png figures, or we can not help you. You can generate these with utils.plot_results().\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n in train.py  , the anchors set by user in yaml file are flushed by pretrain weights.\n <denchmark-code>\n     if weights.endswith('.pt'):  # pytorch format\n         ckpt = torch.load(weights, map_location=device)  # load checkpoint\n \n         # load model\n         try:\n             ckpt['model'] = {k: v for k, v in ckpt['model'].float().state_dict().items()\n                              if model.state_dict()[k].shape == v.shape}  # to FP32, filter\n             #print(ckpt['model'].keys())\n             **#ckpt['model'].pop('model.27.anchors')  \n             #ckpt['model'].pop('model.27.anchor_grid')**\n             \n             model.load_state_dict(ckpt['model'], strict=False)\n         except KeyError as e:\n             s = \"%s is not compatible with %s. This may be due to model differences or %s may be out of date. \" \\\n                 \"Please delete or update %s and try again, or use --weights '' to train from scratch.\" \\\n                 % (opt.weights, opt.cfg, opt.weights, opt.weights)\n             raise KeyError(s) from e\n \n </denchmark-code>\n \n <denchmark-h:h2>To Reproduce (REQUIRED)</denchmark-h>\n \n Input:\n in ./model/yolov5x.yaml\n change anchors' shape to any other than default.\n Output:\n the anchors set in yaml file didn't activated .\n <denchmark-h:h2>Expected behavior</denchmark-h>\n \n A clear and concise description of what you expected to happen.\n <denchmark-h:h2>Environment</denchmark-h>\n \n If applicable, add screenshots to help explain your problem.\n \n OS: [Ubuntu]\n GPU [2080 Ti]\n \n <denchmark-h:h2>Additional context</denchmark-h>\n \n if the anchors set by user in yaml file, is more than 9 anchors, the bug didn't get triggered because it did not match the pretrain weight's anchors' shape.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "AlexWang1900", "commentT": "2020-07-21T02:40:27Z", "comment_text": "\n \t\tHello <denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n , thank you for your interest in our work! Please visit our <denchmark-link:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data>Custom Training Tutorial</denchmark-link>\n  to get started, and see our <denchmark-link:https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb>Jupyter Notebook</denchmark-link>\n  <denchmark-link:https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb></denchmark-link>\n , <denchmark-link:https://hub.docker.com/r/ultralytics/yolov5>Docker Image</denchmark-link>\n , and <denchmark-link:https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart>Google Cloud Quickstart Guide</denchmark-link>\n  for example environments.\n If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.\n If this is a custom model or data training question, please note that Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:\n \n Cloud-based AI systems operating on hundreds of HD video streams in realtime.\n Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.\n Custom data training, hyperparameter evolution, and model exportation to any destination.\n \n For more information please visit <denchmark-link:https://www.ultralytics.com>https://www.ultralytics.com</denchmark-link>\n .\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "AlexWang1900", "commentT": "2020-07-21T03:13:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  thanks for looking into this. AutoAnchor will run always after this region of code, but you are saying that prior to AutoAnchor running a model.yaml's anchors may be replaced by the pretrained weight's anchors?\n The anchors are attributes of the Detect() layer, they are buffers rather than parameters, so they are not assigned a gradient but they are still transferred across devices which is useful for loss computations and inference etc. I will try to reproduce your experiment to see if the yaml anchors are being overwritten.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "AlexWang1900", "commentT": "2020-07-21T03:27:10Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  yes, I am able to reproduce your bug! Ok, so it seems that buffers are being transferred from pretrained weight as well as parameters. I suppose we can simply reject any transfer with 'anchor' in the key. This raises a bigger question though, if I look at the entire list of info transferred I also see a lot of batchnorm info, such as batches tracked:\n This is the total list of modules transferred from pretrained weights to the randomly initialized weights. 364 of 370 parameters transferred if the number of classes is different. The 3 output layer .weight and .bias are omitted.\n model.0.conv.conv.weight\n model.0.conv.bn.weight\n model.0.conv.bn.bias\n model.0.conv.bn.running_mean\n model.0.conv.bn.running_var\n model.0.conv.bn.num_batches_tracked\n model.1.conv.weight\n model.1.bn.weight\n model.1.bn.bias\n model.1.bn.running_mean\n model.1.bn.running_var\n model.1.bn.num_batches_tracked\n model.2.cv1.conv.weight\n model.2.cv1.bn.weight\n model.2.cv1.bn.bias\n model.2.cv1.bn.running_mean\n model.2.cv1.bn.running_var\n model.2.cv1.bn.num_batches_tracked\n model.2.cv2.weight\n model.2.cv3.weight\n model.2.cv4.conv.weight\n model.2.cv4.bn.weight\n model.2.cv4.bn.bias\n model.2.cv4.bn.running_mean\n model.2.cv4.bn.running_var\n model.2.cv4.bn.num_batches_tracked\n model.2.bn.weight\n model.2.bn.bias\n model.2.bn.running_mean\n model.2.bn.running_var\n model.2.bn.num_batches_tracked\n model.2.m.0.cv1.conv.weight\n model.2.m.0.cv1.bn.weight\n model.2.m.0.cv1.bn.bias\n model.2.m.0.cv1.bn.running_mean\n model.2.m.0.cv1.bn.running_var\n model.2.m.0.cv1.bn.num_batches_tracked\n model.2.m.0.cv2.conv.weight\n model.2.m.0.cv2.bn.weight\n model.2.m.0.cv2.bn.bias\n model.2.m.0.cv2.bn.running_mean\n model.2.m.0.cv2.bn.running_var\n model.2.m.0.cv2.bn.num_batches_tracked\n model.3.conv.weight\n model.3.bn.weight\n model.3.bn.bias\n model.3.bn.running_mean\n model.3.bn.running_var\n model.3.bn.num_batches_tracked\n model.4.cv1.conv.weight\n model.4.cv1.bn.weight\n model.4.cv1.bn.bias\n model.4.cv1.bn.running_mean\n model.4.cv1.bn.running_var\n model.4.cv1.bn.num_batches_tracked\n model.4.cv2.weight\n model.4.cv3.weight\n model.4.cv4.conv.weight\n model.4.cv4.bn.weight\n model.4.cv4.bn.bias\n model.4.cv4.bn.running_mean\n model.4.cv4.bn.running_var\n model.4.cv4.bn.num_batches_tracked\n model.4.bn.weight\n model.4.bn.bias\n model.4.bn.running_mean\n model.4.bn.running_var\n model.4.bn.num_batches_tracked\n model.4.m.0.cv1.conv.weight\n model.4.m.0.cv1.bn.weight\n model.4.m.0.cv1.bn.bias\n model.4.m.0.cv1.bn.running_mean\n model.4.m.0.cv1.bn.running_var\n model.4.m.0.cv1.bn.num_batches_tracked\n model.4.m.0.cv2.conv.weight\n model.4.m.0.cv2.bn.weight\n model.4.m.0.cv2.bn.bias\n model.4.m.0.cv2.bn.running_mean\n model.4.m.0.cv2.bn.running_var\n model.4.m.0.cv2.bn.num_batches_tracked\n model.4.m.1.cv1.conv.weight\n model.4.m.1.cv1.bn.weight\n model.4.m.1.cv1.bn.bias\n model.4.m.1.cv1.bn.running_mean\n model.4.m.1.cv1.bn.running_var\n model.4.m.1.cv1.bn.num_batches_tracked\n model.4.m.1.cv2.conv.weight\n model.4.m.1.cv2.bn.weight\n model.4.m.1.cv2.bn.bias\n model.4.m.1.cv2.bn.running_mean\n model.4.m.1.cv2.bn.running_var\n model.4.m.1.cv2.bn.num_batches_tracked\n model.4.m.2.cv1.conv.weight\n model.4.m.2.cv1.bn.weight\n model.4.m.2.cv1.bn.bias\n model.4.m.2.cv1.bn.running_mean\n model.4.m.2.cv1.bn.running_var\n model.4.m.2.cv1.bn.num_batches_tracked\n model.4.m.2.cv2.conv.weight\n model.4.m.2.cv2.bn.weight\n model.4.m.2.cv2.bn.bias\n model.4.m.2.cv2.bn.running_mean\n model.4.m.2.cv2.bn.running_var\n model.4.m.2.cv2.bn.num_batches_tracked\n model.5.conv.weight\n model.5.bn.weight\n model.5.bn.bias\n model.5.bn.running_mean\n model.5.bn.running_var\n model.5.bn.num_batches_tracked\n model.6.cv1.conv.weight\n model.6.cv1.bn.weight\n model.6.cv1.bn.bias\n model.6.cv1.bn.running_mean\n model.6.cv1.bn.running_var\n model.6.cv1.bn.num_batches_tracked\n model.6.cv2.weight\n model.6.cv3.weight\n model.6.cv4.conv.weight\n model.6.cv4.bn.weight\n model.6.cv4.bn.bias\n model.6.cv4.bn.running_mean\n model.6.cv4.bn.running_var\n model.6.cv4.bn.num_batches_tracked\n model.6.bn.weight\n model.6.bn.bias\n model.6.bn.running_mean\n model.6.bn.running_var\n model.6.bn.num_batches_tracked\n model.6.m.0.cv1.conv.weight\n model.6.m.0.cv1.bn.weight\n model.6.m.0.cv1.bn.bias\n model.6.m.0.cv1.bn.running_mean\n model.6.m.0.cv1.bn.running_var\n model.6.m.0.cv1.bn.num_batches_tracked\n model.6.m.0.cv2.conv.weight\n model.6.m.0.cv2.bn.weight\n model.6.m.0.cv2.bn.bias\n model.6.m.0.cv2.bn.running_mean\n model.6.m.0.cv2.bn.running_var\n model.6.m.0.cv2.bn.num_batches_tracked\n model.6.m.1.cv1.conv.weight\n model.6.m.1.cv1.bn.weight\n model.6.m.1.cv1.bn.bias\n model.6.m.1.cv1.bn.running_mean\n model.6.m.1.cv1.bn.running_var\n model.6.m.1.cv1.bn.num_batches_tracked\n model.6.m.1.cv2.conv.weight\n model.6.m.1.cv2.bn.weight\n model.6.m.1.cv2.bn.bias\n model.6.m.1.cv2.bn.running_mean\n model.6.m.1.cv2.bn.running_var\n model.6.m.1.cv2.bn.num_batches_tracked\n model.6.m.2.cv1.conv.weight\n model.6.m.2.cv1.bn.weight\n model.6.m.2.cv1.bn.bias\n model.6.m.2.cv1.bn.running_mean\n model.6.m.2.cv1.bn.running_var\n model.6.m.2.cv1.bn.num_batches_tracked\n model.6.m.2.cv2.conv.weight\n model.6.m.2.cv2.bn.weight\n model.6.m.2.cv2.bn.bias\n model.6.m.2.cv2.bn.running_mean\n model.6.m.2.cv2.bn.running_var\n model.6.m.2.cv2.bn.num_batches_tracked\n model.7.conv.weight\n model.7.bn.weight\n model.7.bn.bias\n model.7.bn.running_mean\n model.7.bn.running_var\n model.7.bn.num_batches_tracked\n model.8.cv1.conv.weight\n model.8.cv1.bn.weight\n model.8.cv1.bn.bias\n model.8.cv1.bn.running_mean\n model.8.cv1.bn.running_var\n model.8.cv1.bn.num_batches_tracked\n model.8.cv2.conv.weight\n model.8.cv2.bn.weight\n model.8.cv2.bn.bias\n model.8.cv2.bn.running_mean\n model.8.cv2.bn.running_var\n model.8.cv2.bn.num_batches_tracked\n model.9.cv1.conv.weight\n model.9.cv1.bn.weight\n model.9.cv1.bn.bias\n model.9.cv1.bn.running_mean\n model.9.cv1.bn.running_var\n model.9.cv1.bn.num_batches_tracked\n model.9.cv2.weight\n model.9.cv3.weight\n model.9.cv4.conv.weight\n model.9.cv4.bn.weight\n model.9.cv4.bn.bias\n model.9.cv4.bn.running_mean\n model.9.cv4.bn.running_var\n model.9.cv4.bn.num_batches_tracked\n model.9.bn.weight\n model.9.bn.bias\n model.9.bn.running_mean\n model.9.bn.running_var\n model.9.bn.num_batches_tracked\n model.9.m.0.cv1.conv.weight\n model.9.m.0.cv1.bn.weight\n model.9.m.0.cv1.bn.bias\n model.9.m.0.cv1.bn.running_mean\n model.9.m.0.cv1.bn.running_var\n model.9.m.0.cv1.bn.num_batches_tracked\n model.9.m.0.cv2.conv.weight\n model.9.m.0.cv2.bn.weight\n model.9.m.0.cv2.bn.bias\n model.9.m.0.cv2.bn.running_mean\n model.9.m.0.cv2.bn.running_var\n model.9.m.0.cv2.bn.num_batches_tracked\n model.10.conv.weight\n model.10.bn.weight\n model.10.bn.bias\n model.10.bn.running_mean\n model.10.bn.running_var\n model.10.bn.num_batches_tracked\n model.13.cv1.conv.weight\n model.13.cv1.bn.weight\n model.13.cv1.bn.bias\n model.13.cv1.bn.running_mean\n model.13.cv1.bn.running_var\n model.13.cv1.bn.num_batches_tracked\n model.13.cv2.weight\n model.13.cv3.weight\n model.13.cv4.conv.weight\n model.13.cv4.bn.weight\n model.13.cv4.bn.bias\n model.13.cv4.bn.running_mean\n model.13.cv4.bn.running_var\n model.13.cv4.bn.num_batches_tracked\n model.13.bn.weight\n model.13.bn.bias\n model.13.bn.running_mean\n model.13.bn.running_var\n model.13.bn.num_batches_tracked\n model.13.m.0.cv1.conv.weight\n model.13.m.0.cv1.bn.weight\n model.13.m.0.cv1.bn.bias\n model.13.m.0.cv1.bn.running_mean\n model.13.m.0.cv1.bn.running_var\n model.13.m.0.cv1.bn.num_batches_tracked\n model.13.m.0.cv2.conv.weight\n model.13.m.0.cv2.bn.weight\n model.13.m.0.cv2.bn.bias\n model.13.m.0.cv2.bn.running_mean\n model.13.m.0.cv2.bn.running_var\n model.13.m.0.cv2.bn.num_batches_tracked\n model.14.conv.weight\n model.14.bn.weight\n model.14.bn.bias\n model.14.bn.running_mean\n model.14.bn.running_var\n model.14.bn.num_batches_tracked\n model.17.cv1.conv.weight\n model.17.cv1.bn.weight\n model.17.cv1.bn.bias\n model.17.cv1.bn.running_mean\n model.17.cv1.bn.running_var\n model.17.cv1.bn.num_batches_tracked\n model.17.cv2.weight\n model.17.cv3.weight\n model.17.cv4.conv.weight\n model.17.cv4.bn.weight\n model.17.cv4.bn.bias\n model.17.cv4.bn.running_mean\n model.17.cv4.bn.running_var\n model.17.cv4.bn.num_batches_tracked\n model.17.bn.weight\n model.17.bn.bias\n model.17.bn.running_mean\n model.17.bn.running_var\n model.17.bn.num_batches_tracked\n model.17.m.0.cv1.conv.weight\n model.17.m.0.cv1.bn.weight\n model.17.m.0.cv1.bn.bias\n model.17.m.0.cv1.bn.running_mean\n model.17.m.0.cv1.bn.running_var\n model.17.m.0.cv1.bn.num_batches_tracked\n model.17.m.0.cv2.conv.weight\n model.17.m.0.cv2.bn.weight\n model.17.m.0.cv2.bn.bias\n model.17.m.0.cv2.bn.running_mean\n model.17.m.0.cv2.bn.running_var\n model.17.m.0.cv2.bn.num_batches_tracked\n model.19.conv.weight\n model.19.bn.weight\n model.19.bn.bias\n model.19.bn.running_mean\n model.19.bn.running_var\n model.19.bn.num_batches_tracked\n model.21.cv1.conv.weight\n model.21.cv1.bn.weight\n model.21.cv1.bn.bias\n model.21.cv1.bn.running_mean\n model.21.cv1.bn.running_var\n model.21.cv1.bn.num_batches_tracked\n model.21.cv2.weight\n model.21.cv3.weight\n model.21.cv4.conv.weight\n model.21.cv4.bn.weight\n model.21.cv4.bn.bias\n model.21.cv4.bn.running_mean\n model.21.cv4.bn.running_var\n model.21.cv4.bn.num_batches_tracked\n model.21.bn.weight\n model.21.bn.bias\n model.21.bn.running_mean\n model.21.bn.running_var\n model.21.bn.num_batches_tracked\n model.21.m.0.cv1.conv.weight\n model.21.m.0.cv1.bn.weight\n model.21.m.0.cv1.bn.bias\n model.21.m.0.cv1.bn.running_mean\n model.21.m.0.cv1.bn.running_var\n model.21.m.0.cv1.bn.num_batches_tracked\n model.21.m.0.cv2.conv.weight\n model.21.m.0.cv2.bn.weight\n model.21.m.0.cv2.bn.bias\n model.21.m.0.cv2.bn.running_mean\n model.21.m.0.cv2.bn.running_var\n model.21.m.0.cv2.bn.num_batches_tracked\n model.23.conv.weight\n model.23.bn.weight\n model.23.bn.bias\n model.23.bn.running_mean\n model.23.bn.running_var\n model.23.bn.num_batches_tracked\n model.25.cv1.conv.weight\n model.25.cv1.bn.weight\n model.25.cv1.bn.bias\n model.25.cv1.bn.running_mean\n model.25.cv1.bn.running_var\n model.25.cv1.bn.num_batches_tracked\n model.25.cv2.weight\n model.25.cv3.weight\n model.25.cv4.conv.weight\n model.25.cv4.bn.weight\n model.25.cv4.bn.bias\n model.25.cv4.bn.running_mean\n model.25.cv4.bn.running_var\n model.25.cv4.bn.num_batches_tracked\n model.25.bn.weight\n model.25.bn.bias\n model.25.bn.running_mean\n model.25.bn.running_var\n model.25.bn.num_batches_tracked\n model.25.m.0.cv1.conv.weight\n model.25.m.0.cv1.bn.weight\n model.25.m.0.cv1.bn.bias\n model.25.m.0.cv1.bn.running_mean\n model.25.m.0.cv1.bn.running_var\n model.25.m.0.cv1.bn.num_batches_tracked\n model.25.m.0.cv2.conv.weight\n model.25.m.0.cv2.bn.weight\n model.25.m.0.cv2.bn.bias\n model.25.m.0.cv2.bn.running_mean\n model.25.m.0.cv2.bn.running_var\n model.25.m.0.cv2.bn.num_batches_tracked\n model.27.anchors\n model.27.anchor_grid\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "AlexWang1900", "commentT": "2020-07-21T03:42:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n   you suggests to omit bn weights? I have to test it on custom datasets.\n I will test it on Kaggle global Wheat detection , to see if it is worthy to omit pretrained bn weights.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "AlexWang1900", "commentT": "2020-07-21T03:48:58Z", "comment_text": "\n \t\tCurrent implementation:\n \n \n \n yolov5/train.py\n \n \n         Lines 131 to 135\n       in\n       1e95337\n \n \n \n \n \n \n  # load model \n \n \n \n  try: \n \n \n \n  ckpt['model'] = {k: v for k, v in ckpt['model'].float().state_dict().items() \n \n \n \n  if k in model.state_dict() and model.state_dict()[k].shape == v.shape} \n \n \n \n  model.load_state_dict(ckpt['model'], strict=False) \n \n \n \n \n \n Proposed fix:\n         # load model\n         try:\n             exclude = ['anchor', 'tracked']  # exclude list\n             ckpt['model'] = {k: v for k, v in ckpt['model'].float().state_dict().items()\n                              if k in model.state_dict() and not any(x in k for x in exclude)\n                              and model.state_dict()[k].shape == v.shape}\n \n             model.load_state_dict(ckpt['model'], strict=False)\n             print('Transferred %g/%g items from %s' % (len(ckpt['model']), len(model.state_dict()), weights))\n Using current master: Transferred 364/370 items from yolov5s.pt\n Adding 'anchor' to exclude list: Transferred 362/370 items from yolov5s.pt\n Adding 'anchors' and 'tracked' to exclude list: Transferred 303/370 items from yolov5s.pt\n Ok so this fix appears to be solid. Philosophically speaking though, you might want to be careful modifying anchors significantly on pretrained weights. AutoAnchor threshold for action is 0.99 best possible recall (BPR), anything above this and it leaves the anchors alone. If the modified anchors are significantly different than the pretrained weights anchors, the new model may take significant training time to adjust all of the regression-related neurons to fully compensate (i.e. hundreds of epochs for smaller datasets).\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "AlexWang1900", "commentT": "2020-07-21T03:51:34Z", "comment_text": "\n \t\tAlso, lastly, we need some empirical (experimental) results to guide us on whether to exclude all of the num_batches_tracked values from being transferred. I think the other 4 are beneficial to transfer:\n model.25.m.0.cv1.bn.weight\n model.25.m.0.cv1.bn.bias\n model.25.m.0.cv1.bn.running_mean\n model.25.m.0.cv1.bn.running_var\n model.25.m.0.cv1.bn.num_batches_tracked  # should we start this from zero ??\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "AlexWang1900", "commentT": "2020-07-21T03:54:00Z", "comment_text": "\n \t\t\n Also, lastly, we need some empirical (experimental) results to guide us on whether to exclude all of the num_batches_tracked values from being transferred. I think the other 4 are beneficial to transfer:\n model.25.m.0.cv1.bn.weight\n model.25.m.0.cv1.bn.bias\n model.25.m.0.cv1.bn.running_mean\n model.25.m.0.cv1.bn.running_var\n model.25.m.0.cv1.bn.num_batches_tracked  # should we start this from zero ??\n \n Okay!!! I will start testing from there!! I will test it on Kaggle global Wheat detection dataset\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "AlexWang1900", "commentT": "2020-07-21T04:02:35Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  ok sounds good. BTW, when you train on wheat detection what's the BPR you get initially (is it above 0.99?). I opened up a PR <denchmark-link:https://github.com/ultralytics/yolov5/pull/462>#462</denchmark-link>\n  with the proposed fix. Not sure if I should add 'tracked' to the list, I'll wait for your experiment results.\n I think if the batchnorm tracking starts from 0 it will be more noisy initially, but also more quickly adapt to the new dataset (possibly converge faster, and/or possibly overfit faster). But I really have no idea. Suggest maybe train with exclude=['anchor'] and exclude=['anchor', 'tracked'] and plot both results together to try to spot any differences.\n You can overlay multiple training results togethor by copying both to your main yolov5/ directory and then running:\n from utils.utils import *; plot_results(), it will plot any results*.txt files it finds in the main directory.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "AlexWang1900", "commentT": "2020-07-21T04:21:16Z", "comment_text": "\n \t\t\n @AlexWang1900 ok sounds good. BTW, when you train on wheat detection what's the BPR you get initially (is it above 0.99?). I opened up a PR #462 with the proposed fix. Not sure if I should add 'tracked' to the list, I'll wait for your experiment results.\n I think if the batchnorm tracking starts from 0 it will be more noisy initially, but also more quickly adapt to the new dataset (possibly converge faster, and/or possibly overfit faster). But I really have no idea. Suggest maybe train with exclude=['anchor'] and exclude=['anchor', 'tracked'] and plot both results together to try to spot any differences.\n You can overlay multiple training results togethor by copying both to your main yolov5/ directory and then running:\n from utils.utils import *; plot_results(), it will plot any results*.txt files it finds in the main directory.\n \n for the BPR, it is above 0.99 if the default anchor_t =4.0.  if I set anchor_t = 2.0 ,BPR falls to 0.9847~ then it starts using k-means to caculate new anchors.\n new anchors get lower result for map 0.5 and map 0.5-0.75. drops 3%,2%  on validation set. I think it is because new anchors are much smaller and  anchor_t = 2.0 makes much fewer proposal for positive targets.\n it seems the kmeans for anchor caculation has some issue, : the k * standard makes anchors smaller\n <denchmark-code>    # Kmeans calculation\n     from scipy.cluster.vq import kmeans\n     print('Running kmeans for %g anchors on %g points...' % (n, len(wh)))\n     s = wh.std(0)  # sigmas for whitening\n     natural_k,dist = kmeans(wh,5,iter=300)\n     print(\"natural:\",natural_k)\n     k, dist = kmeans(wh, n, iter=30)#kmeans(wh / s, n, iter=30)  # points, mean distance\n     #k *= s\n     wh = torch.tensor(wh, dtype=torch.float32)  # filtered\n     wh0 = torch.tensor(wh0, dtype=torch.float32)  # unflitered\n     k = print_results(k)\n </denchmark-code>\n \n it is better without standard on validataion set, but I forgot the exact numbers.\n So finnally I caculated 9 anchors and add them aside original anchors totally 18 anchors. and set anchor_t =4.0, 3.0, 2.0 , all have 0.1%-%0.2 rising on validation score map 0.5-0.75.\n but unfortunelly they lower the score on kaggel test set 1%, because, maybe ,according to the dataset paper the dataset was labelled using yolov3 with default settings and obj_score >=0.5 , then hand crafted for mistakes.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "AlexWang1900", "commentT": "2020-07-22T07:01:38Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n \n Hi~~ here is the astonishing result of the tests:\n <denchmark-link:https://user-images.githubusercontent.com/60679873/88142036-5d571380-cc27-11ea-9c4a-c1d996a9eea0.png></denchmark-link>\n \n test_1: original baseline without tricks, best map0.5-0.75: 0.7981 at epoch 23\n test_2: omit  'tracked' , best :0.798  at epoch 20\n test_3: omit  'tracked', 'running_mean''running_var',\n best: 0.0.7995 at epoch 22\n test_4:omit 'bn'              best: 0.8 at epoch 35\n from the pytorch code:\n <denchmark-code>\n                if self.momentum is None:  # use cumulative moving average\n                     exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n                 else:  # use exponential moving average\n                     exponential_average_factor = self.momentum\n \n </denchmark-code>\n \n with 'tracked batches', it is dominate for the pretrained mean and var when calculating moving average ,  take an example tracked = 1000,  then (1-1/1000)^100 = 0.905, after 100 batches , (1\u22121/1000)^1000 = 0.365 after 1000 batches, old bn mean and var still have roughly 0.36 left.\n omitting 'tracked ' , exponential_average_factor = momentum = 0.1 by default, it takes 40 batches to wipe out old bn means and var.\n but it is higher if whole bn removed , I can't quite understand that, I was predicting test_3 maybe the best because bn weights are randomly initialized in test_4\n and the confidence level here is high, for I have ran 50+ times with different tricks or hyperparameters ,the 0.8 is the highest score above all.\n I suggest from a user's perspective:\n \n user want to incrementally transfer learning, like user have some pictures at night, want to increase the night performance, while  keeping the yolo performance with original scene.\n it is better to keep the whole bn.\n user want to transfer learning for another domain, and doesn't care about the performance on general scene, just like Wheat detection,\n it is better to omit whole bn.\n when I am training, the system reboot, then I have to load last.pt then continue to run\n it has to keep bn\n \n at the end of day , it's up to you ~~~\n need more tests ,welcome to say~~~\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "AlexWang1900", "commentT": "2020-07-22T19:28:52Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  wow, thanks for running the tests! Surprisingly removing the tracked stats has almost no effect, though if you remove bn completely there is some noticeably higher instability in the early epochs. I think the highest mAPs are all essentially identical. This is wheat detection?\n I'll go ahead and push the PR with just 'anchor' in the exclude list.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "AlexWang1900", "commentT": "2020-07-23T01:23:05Z", "comment_text": "\n \t\tyes.. this is wheat detection. from normal experience the highest maps are in the range of 0.02. no big difference. but after running with it 50times it is the first time which reach 0.8\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n ---Original---\n From: \"Glenn Jocher\"<notifications@github.com&gt;\n Date: Thu, Jul 23, 2020 03:29 AM\n To: \"ultralytics/yolov5\"<yolov5@noreply.github.com&gt;;\n Cc: \"Mention\"<mention@noreply.github.com&gt;;\"AlexWang1900\"<41888506@qq.com&gt;;\n Subject: Re: [ultralytics/yolov5] custom anchors get flushed when loading pretrain weights (#459)\n \n \n \n \n \n @AlexWang1900 wow, thanks for running the tests! Surprisingly removing the tracked stats has almost no effect, though if you remove bn completely there is some noticeably higher instability in the early epochs. I think the highest mAPs are all essentially identical. This is wheat detection?\n \n I'll go ahead and push the PR with just 'anchor' in the exclude list.\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n \n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "AlexWang1900", "commentT": "2020-07-23T03:10:33Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  ah, so you are saying that the very best result was after removing 100% of the bn stats (all 5 values for each bn layer)?\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "AlexWang1900", "commentT": "2020-07-23T03:13:36Z", "comment_text": "\n \t\tOne item in your plots is that we want all 3 (2) val losses to bottom around the same time. If one bottoms before the other the peak mAP may not be as high as it could be. GIoU has a broad base (it generalizes well), obj has a much sharper base, and I've always struggled to prevent if from overtraining more. On COCO, wheat, and most others obj and cls overfit before GIoU.\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "AlexWang1900", "commentT": "2020-07-23T03:15:11Z", "comment_text": "\n \t\tyes, among other tricks and hyper parameters changed,\n change bn along gets highest validation score.&nbsp;\n now combined with mixup it gets higher.&nbsp;\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n ---Original---\n From: \"Glenn Jocher\"<notifications@github.com&gt;\n Date: Thu, Jul 23, 2020 11:10 AM\n To: \"ultralytics/yolov5\"<yolov5@noreply.github.com&gt;;\n Cc: \"Mention\"<mention@noreply.github.com&gt;;\"AlexWang1900\"<41888506@qq.com&gt;;\n Subject: Re: [ultralytics/yolov5] custom anchors get flushed when loading pretrain weights (#459)\n \n \n \n \n \n @AlexWang1900 ah, so you are saying that the very best result was after removing 100% of the bn stats (all 5 values for each bn layer)?\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n \n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "AlexWang1900", "commentT": "2020-07-23T03:22:16Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  I have an idea, you could try modifying the L24 activation function in the Conv() layer from LeakyReLU(0.1) to Swish() or Mish() to see if this helps wheat training. This will change almost all activations across the entire model. I've never tried this, but it may be possible to still start from pretraind weights when you do this:\n \n \n You'll have to reduce your batch size as these will consume much greater GPU RAM when training, and initial results may be poorer, but final mAP may be higher...\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "AlexWang1900", "commentT": "2020-07-23T03:27:07Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  also since pretrained weights are helping so much, it may make sense to freeze 100% of the transferred weights for the first few epochs before unfreezing. otherwise the pretrained layer gradients are being affected by the randomly initialized layers. An example training pipeline might be:\n \n Load pretrained weights, save keys which are successfully transferred into transferred list.\n Freeze parameters in transferred layers by setting x.requires_grad=False\n Train 1-10 epochs.\n if epoch == 10: Unfreeze all layers\n continue training\n \n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "AlexWang1900", "commentT": "2020-07-23T03:29:37Z", "comment_text": "\n \t\tThanks a lot!!!!\n I will test it!!!!\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n ---Original---\n From: \"Glenn Jocher\"<notifications@github.com&gt;\n Date: Thu, Jul 23, 2020 11:27 AM\n To: \"ultralytics/yolov5\"<yolov5@noreply.github.com&gt;;\n Cc: \"Mention\"<mention@noreply.github.com&gt;;\"AlexWang1900\"<41888506@qq.com&gt;;\n Subject: Re: [ultralytics/yolov5] custom anchors get flushed when loading pretrain weights (#459)\n \n \n \n \n \n @AlexWang1900 also since pretrained weights are helping so much, it may make sense to freeze 100% of the transferred weights for the first few epochs before unfreezing. otherwise the pretrained layer gradients are being affected by the randomly initialized layers. An example training pipeline might be:\n \n Load pretrained weights, save keys which are successfully transferred into transferred list.\n \n Freeze keys in transferred\n \n Train 1-10 epochs.\n \n if epoch == 10: Unfreeze all layers\n \n continue training\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n \n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "AlexWang1900", "commentT": "2020-07-23T04:57:53Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  I should probably add an optional train.py argument for this. Maybe something like --freeze-for or --freeze-epochs, i.e. to do my above tasks:\n python train.py --weights yolov5x.pt --freeze 10\n TODO: Add train.py argument to freeze transferred layers for a certain number of epochs.\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "AlexWang1900", "commentT": "2020-07-23T12:00:54Z", "comment_text": "\n \t\t\n @AlexWang1900 I should probably add an optional train.py argument for this. Maybe something like --freeze-for or --freeze-epochs, i.e. to do my above tasks:\n python train.py --weights yolov5x.pt --freeze 10\n TODO: Add train.py argument to freeze transferred layers for a certain number of epochs.\n \n <denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n \n I have implemented a simple test version and now it is running, waiting for result.\n it is like this:\n <denchmark-code>    if weights.endswith('.pt'):  # pytorch format\n         ckpt = torch.load(weights, map_location=device)  # load checkpoint\n \n         # load model\n         try:\n             exclude = ['anchor', 'tracked','running_mean','running_var','bn']\n             ckpt['model'] = {k: v for k, v in ckpt['model'].float().state_dict().items()\n                              if k in model.state_dict() and not any(x in k for x in exclude)\n                              and model.state_dict()[k].shape == v.shape}\n             model.load_state_dict(ckpt['model'], strict=False)\n             print('Transferred %g/%g items from %s' % (len(ckpt['model']), len(model.state_dict()), weights))\n # add \n             freeze_layers = []\n             for key in ckpt['model'].keys():\n                 freeze_layers.append(key)\n             frozen_layers = deepcopy(freeze_layers)\n             for name, param in model.named_parameters():\n                 #print(name)\n                 for element in freeze_layers:\n                     #print(element)\n                     if element in name:\n                         param.requires_grad = False\n                         freeze_layers.remove(element)\n                         break\n # add end\n         except KeyError as e:\n             s = \"%s is not compatible with %s. This may be due to model differences or %s may be out of date. \" \\\n                 \"Please delete or update %s and try again, or use --weights '' to train from scratch.\" \\\n                 % (weights, opt.cfg, weights, weights)\n             raise KeyError(s) from e\n </denchmark-code>\n \n <denchmark-code>    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n         model.train()\n #add \n         if epoch >=2 and len(frozen_layers)>0:\n             for name, param in model.named_parameters():\n                 #print(name)\n                 for element in frozen_layers:\n                     #print(element)\n                     if element in name:\n                         param.requires_grad = True\n                         frozen_layers.remove(element)\n                         break\n #add end\n </denchmark-code>\n \n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "AlexWang1900", "commentT": "2020-07-23T17:34:52Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  looks about right. The warmup is 3 epochs, so you might want to experiment with freezing < 3 epochs and then freezing > 3 epochs. I think you can refactor the first for loop also:\n \n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "AlexWang1900", "commentT": "2020-07-24T01:46:53Z", "comment_text": "\n \t\there are the results for freeze <4 , it seems overfit at 4.\n <denchmark-link:https://user-images.githubusercontent.com/60679873/88353945-f9049300-cd91-11ea-90f5-80a2c2aea546.png></denchmark-link>\n \n result_1 without freeze best map0.5-0.75  0.8025 at epoch 54/60.\n result_2 freeze              bset map0.5-0.75 0.7991 at epoch 60/60\n both lr cosine decay(end epochs = 80)\n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "AlexWang1900", "commentT": "2020-07-24T02:50:17Z", "comment_text": "\n \t\tWow that did not work well. My warmup strategy must be very important then.\n Maybe just try freezing 1 epoch and extend the warmup to 4 epochs up from 3\n now. Then you get 1 epoch full frozen while still enjoying the full 3 epoch\n warmup effects on all layers.\n \n BTW you can increase TTA augmentations, I\u2019ve only used a minimum of 3\n simple augmentations in the default TTA code. You can add vertical flip and\n extra sizes for better final mAP.\n On Thu, 23 Jul 2020 at 18:47, AlexWang1900 ***@***.***> wrote:\n  here are the results for freeze <4 , it seems overfit at 4.\n \n  [image: results]\n  <<denchmark-link:https://user-images.githubusercontent.com/60679873/88353945-f9049300-cd91-11ea-90f5-80a2c2aea546.png>https://user-images.githubusercontent.com/60679873/88353945-f9049300-cd91-11ea-90f5-80a2c2aea546.png</denchmark-link>\n >\n \n  result_1 without freeze best map0.5-0.75 0.8025 at epoch 54/60.\n  result_2 freeze bset map0.5-0.75 0.7991 at epoch 60/60\n  both lr cosine decay(end epochs = 80)\n \n  \u2014\n  You are receiving this because you were mentioned.\n  Reply to this email directly, view it on GitHub\n  <<denchmark-link:https://github.com/ultralytics/yolov5/issues/459#issuecomment-663312980>#459 (comment)</denchmark-link>\n >,\n  or unsubscribe\n  <<denchmark-link:https://github.com/notifications/unsubscribe-auth/AGMXEGMRCCPPAATU52MDC4LR5DRZXANCNFSM4PDBTPBQ>https://github.com/notifications/unsubscribe-auth/AGMXEGMRCCPPAATU52MDC4LR5DRZXANCNFSM4PDBTPBQ</denchmark-link>\n >\n  .\n \n -- \n <<denchmark-link:https://www.ultralytics.com/>https://www.ultralytics.com/</denchmark-link>\n >\n \n \n *Glenn Jocher*Founder & CEO, Ultralytics LLC\n +1 301 237 6695\n  <<denchmark-link:https://www.facebook.com/ultralytics>https://www.facebook.com/ultralytics</denchmark-link>\n >\n <<denchmark-link:https://www.twitter.com/ultralytics>https://www.twitter.com/ultralytics</denchmark-link>\n >\n <<denchmark-link:https://www.youtube.com/ultralytics>https://www.youtube.com/ultralytics</denchmark-link>\n >\n <<denchmark-link:https://www.github.com/ultralytics>https://www.github.com/ultralytics</denchmark-link>\n >\n <<denchmark-link:https://www.linkedin.com/company/ultralytics>https://www.linkedin.com/company/ultralytics</denchmark-link>\n >\n <<denchmark-link:https://www.instagram.com/ultralytics>https://www.instagram.com/ultralytics</denchmark-link>\n >\n <<denchmark-link:https://contact.ultralytics.com/>https://contact.ultralytics.com/</denchmark-link>\n >\n \t\t"}, "comments_23": {"comment_id": 24, "comment_author": "AlexWang1900", "commentT": "2020-07-24T02:52:48Z", "comment_text": "\n \t\tfor swish and mish, I am looking into some effiecient implemetations like here:\n <denchmark-link:url>https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/activations_me.py</denchmark-link>\n \n I have used mish and swish for image classification, it converges faster , but tend to overfit faster.\n \t\t"}, "comments_24": {"comment_id": 25, "comment_author": "AlexWang1900", "commentT": "2020-07-24T02:57:31Z", "comment_text": "\n \t\t\n Wow that did not work well. My warmup strategy must be very important then. Maybe just try freezing 1 epoch and extend the warmup to 4 epochs up from 3 now. Then you get 1 epoch full frozen while still enjoying the full 3 epoch warmup effects on all layers. BTW you can increase TTA augmentations, I\u2019ve only used a minimum of 3 simple augmentations in the default TTA code. You can add vertical flip and extra sizes for better final mAP.\n On Thu, 23 Jul 2020 at 18:47, AlexWang1900 @.***> wrote: here are the results for freeze <4 , it seems overfit at 4. [image: results] https://user-images.githubusercontent.com/60679873/88353945-f9049300-cd91-11ea-90f5-80a2c2aea546.png result_1 without freeze best map0.5-0.75 0.8025 at epoch 54/60. result_2 freeze bset map0.5-0.75 0.7991 at epoch 60/60 both lr cosine decay(end epochs = 80) \u2014 You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <#459 (comment)>, or unsubscribe https://github.com/notifications/unsubscribe-auth/AGMXEGMRCCPPAATU52MDC4LR5DRZXANCNFSM4PDBTPBQ .\n -- https://www.ultralytics.com/ Glenn JocherFounder & CEO, Ultralytics LLC +1 301 237 6695 https://www.facebook.com/ultralytics https://www.twitter.com/ultralytics https://www.youtube.com/ultralytics https://www.github.com/ultralytics https://www.linkedin.com/company/ultralytics https://www.instagram.com/ultralytics https://contact.ultralytics.com/\n \n I have added mixup , seems okay now.\n I also found this: RIFLE: Backpropagation in Depth for Deep Transfer Learning throughRe-Initializing the Fully-connected LayEr\n <denchmark-link:https://arxiv.org/pdf/2007.03349.pdf>https://arxiv.org/pdf/2007.03349.pdf</denchmark-link>\n \n I may try it.\n \t\t"}, "comments_25": {"comment_id": 26, "comment_author": "AlexWang1900", "commentT": "2020-07-24T09:45:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  , Hi!\n How do you get mAP.5:.75 0.8 with 60 epochs on wheat dataset? O.o\n I can't get such mAP even with 210 epochs.\n \t\t"}, "comments_26": {"comment_id": 27, "comment_author": "AlexWang1900", "commentT": "2020-07-24T10:20:54Z", "comment_text": "\n \t\tyou may used map0.5-0.95? another valid set?\n what is your&nbsp; score?\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n ---Original---\n From: \"Mark\"<notifications@github.com&gt;\n Date: Fri, Jul 24, 2020 17:46 PM\n To: \"ultralytics/yolov5\"<yolov5@noreply.github.com&gt;;\n Cc: \"Mention\"<mention@noreply.github.com&gt;;\"AlexWang1900\"<41888506@qq.com&gt;;\n Subject: Re: [ultralytics/yolov5] custom anchors get flushed when loading pretrain weights (#459)\n \n \n \n \n \n @AlexWang1900 , Hi!\n  How do you get mAP.5:.75 0.8 with 60 epochs on wheat dataset? O.o\n  I can't get such mAP even with 210 epochs.\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n \n \t\t"}, "comments_27": {"comment_id": 28, "comment_author": "AlexWang1900", "commentT": "2020-07-24T10:40:50Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  ,\n \n you may used map0.5-0.95?\n \n I modified this line \n \n \n yolov5/test.py\n \n \n          Line 59\n       in\n       4b5f480\n \n \n \n \n \n \n  iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95 \n \n \n \n \n \n to iouv = torch.linspace(0.5, 0.75, 6).to(device).\n is this okay?\n \n another valid set?\n \n I used standard 5-fold stratified split from some public notebook, so i think yes our valid sets are different.\n \n what is your\u00a0 score?\n \n My current mAP@.5:.75 for single model 0.73.\n My current LB: 5 yolov5 models with TTA: 0.7489;\n I don't want to use pseudo-labeling because it looks like a cheat.\n I understand that I will be excluded from the competition for using yolov5, but I'm just wondering how others get such a big score. It's greate to learn from others, i think.\n \t\t"}, "comments_28": {"comment_id": 29, "comment_author": "AlexWang1900", "commentT": "2020-07-24T11:00:46Z", "comment_text": "\n \t\tI think you are good for 0.7489. my best single model 0.7488.&nbsp;\n \n with some threahold tweeking and plabel you can easily go beyond 0.77\n \n \n for validation score I didn't change the iouv. I used first6 results from ap[ ]. I also printed them all. there is a thread in this repository. issue 339. I just copied it from Glenn Jocher\n \n \n I can't see what's the difference between changing Iouv and get from ap[]. from the LB result,we are close,so I think there is an bias between our validation scores\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n ---Original---\n From: \"Mark\"<notifications@github.com&gt;\n Date: Fri, Jul 24, 2020 18:41 PM\n To: \"ultralytics/yolov5\"<yolov5@noreply.github.com&gt;;\n Cc: \"Mention\"<mention@noreply.github.com&gt;;\"AlexWang1900\"<41888506@qq.com&gt;;\n Subject: Re: [ultralytics/yolov5] custom anchors get flushed when loading pretrain weights (#459)\n \n \n \n \n \n @AlexWang1900 ,\n \n you may used map0.5-0.95?\n \n I modified this line https://github.com/ultralytics/yolov5/blob/4b5f4806bcd513b18171034c06364432ef2c19c2/test.py#L59\n  to iouv = torch.linspace(0.5, 0.75, 6).to(device).\n  is this okay?\n \n another valid set?\n \n I used standard 5-fold stratified split from some public notebook, so i think yes our valid sets are different.\n \n what is your&nbsp; score?\n \n My current mAP@.5:.75 for single model 0.73.\n  My current LB: 5 yolov5 models with TTA: 0.7489;\n  I don't want to use pseudo-labeling because it looks like a cheat.\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n \n \t\t"}, "comments_29": {"comment_id": 30, "comment_author": "AlexWang1900", "commentT": "2020-07-24T11:10:43Z", "comment_text": "\n \t\tplabel has a paper. \"self training with noisy student impoves imagenet classification\"\n it should be legit and nice.&nbsp;\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n ---Original---\n From: \"Mark\"<notifications@github.com&gt;\n Date: Fri, Jul 24, 2020 18:41 PM\n To: \"ultralytics/yolov5\"<yolov5@noreply.github.com&gt;;\n Cc: \"Mention\"<mention@noreply.github.com&gt;;\"AlexWang1900\"<41888506@qq.com&gt;;\n Subject: Re: [ultralytics/yolov5] custom anchors get flushed when loading pretrain weights (#459)\n \n \n \n \n \n @AlexWang1900 ,\n \n you may used map0.5-0.95?\n \n I modified this line https://github.com/ultralytics/yolov5/blob/4b5f4806bcd513b18171034c06364432ef2c19c2/test.py#L59\n  to iouv = torch.linspace(0.5, 0.75, 6).to(device).\n  is this okay?\n \n another valid set?\n \n I used standard 5-fold stratified split from some public notebook, so i think yes our valid sets are different.\n \n what is your&nbsp; score?\n \n My current mAP@.5:.75 for single model 0.73.\n  My current LB: 5 yolov5 models with TTA: 0.7489;\n  I don't want to use pseudo-labeling because it looks like a cheat.\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n \n \t\t"}, "comments_30": {"comment_id": 31, "comment_author": "AlexWang1900", "commentT": "2020-07-24T13:08:32Z", "comment_text": "\n \t\tDear <denchmark-link:https://github.com/AlexWang1900>@AlexWang1900</denchmark-link>\n  , thank you!\n I'll try to read plabel paper and try use 339 issue to see for changes betwee mAP.\n \t\t"}, "comments_31": {"comment_id": 32, "comment_author": "AlexWang1900", "commentT": "2020-08-05T19:49:11Z", "comment_text": "\n \t\tI believe this issue is resolved, removing TODO layer.\n \t\t"}}}, "commit": {"commit_id": "5e970d45c44fff11d1eb29bfc21bed9553abf986", "commit_author": "Glenn Jocher", "commitT": "2020-07-22 12:32:03-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "train.py", "file_new_name": "train.py", "file_complexity": {"file_NLOC": "371", "file_CCN": "91", "file_NToken": "4135"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "126,128,129,131", "deleted_lines": "127", "method_info": {"method_name": "train", "method_params": "hyp,tb_writer,opt,device", "method_startline": "46", "method_endline": "403", "method_complexity": {"method_NLOC": "241", "method_CCN": "91", "method_NToken": "2721", "method_nesting_level": "0"}}}}}}}}