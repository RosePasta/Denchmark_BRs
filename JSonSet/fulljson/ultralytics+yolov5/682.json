{"BR": {"BR_id": "682", "BR_author": "NanoCode012", "BRopenT": "2020-08-09T13:33:19Z", "BRcloseT": "2020-08-09T18:01:37Z", "BR_text": {"BRsummary": "torch.nn.modules.module.ModuleAttributeError in DP and DDP mode", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n Due to latest update on <denchmark-link:https://github.com/ultralytics/yolov5/commit/3c6e2f7668ea178287040c14c4cf81f45357d50b>3c6e2f7</denchmark-link>\n  , DP and DDP mode would error because they wrap around the model, so the attribute  cannot be accessed.\n <denchmark-h:h2>To Reproduce (REQUIRED)</denchmark-h>\n \n Input:\n python train.py --weights yolov5s.pt --epochs 3 --img 320 --device 0,1 # DP\n python -m torch.distributed.launch --nproc_per_node 2 train.py --weights yolov5s.pt --epochs 3 --img 320 --device 0,1 # DDP\n Output in DDP mode (DP mode output is just a bit different):\n <denchmark-code>Transferred 370/370 items from yolov5s.pt\n Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n Transferred 370/370 items from yolov5s.pt\n Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n Traceback (most recent call last):\n   File \"train.py\", line 439, in <module>\n Traceback (most recent call last):\n   File \"train.py\", line 439, in <module>\n     train(hyp, opt, device, tb_writer)\n   File \"train.py\", line 144, in train\n     gs = int(max(model.stride))  # grid size (max stride)\n   File \".conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 772, in __getattr__\n     train(hyp, opt, device, tb_writer)\n   File \"train.py\", line 144, in train\n     gs = int(max(model.stride))  # grid size (max stride)\n   File \".conda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 772, in __getattr__\n     type(self).__name__, name))\n torch.nn.modules.module.ModuleAttributeError: 'DistributedDataParallel' object has no attribute 'stride'\n     type(self).__name__, name))\n torch.nn.modules.module.ModuleAttributeError: 'DistributedDataParallel' object has no attribute 'stride'\n Traceback (most recent call last):\n   File \".conda/envs/py37/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n     \"__main__\", mod_spec)\n   File \".conda/envs/py37/lib/python3.7/runpy.py\", line 85, in _run_code\n     exec(code, run_globals)\n   File \".conda/envs/py37/lib/python3.7/site-packages/torch/distributed/launch.py\", line 261, in <module>\n     main()\n   File \".conda/envs/py37/lib/python3.7/site-packages/torch/distributed/launch.py\", line 257, in main\n     cmd=cmd)\n subprocess.CalledProcessError: Command '['.conda/envs/py37/bin/python', '-u', 'train.py', '--local_rank=1', '--weights', 'yolov5s.pt', '--epochs', '3', '--img', '320', '--device', '0,1']' returned non-zero exit status 1.\n </denchmark-code>\n \n <denchmark-h:h2>Expected behavior</denchmark-h>\n \n Run like Single GPU mode\n <denchmark-h:h2>Environment</denchmark-h>\n \n \n OS: Ubuntu\n GPU: V100s\n \n <denchmark-h:h2>Additional context</denchmark-h>\n \n Solution is to move the line below, above DP/ DDP wrappers, particularly Line 144.\n \n \n \n yolov5/train.py\n \n \n         Lines 143 to 145\n       in\n       a0ac5ad\n \n \n \n \n \n \n  # Image sizes \n \n \n \n  gs = int(max(model.stride))  # grid size (max stride) \n \n \n \n  imgsz, imgsz_test = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples \n \n \n \n \n \n to line 126\n \n \n \n yolov5/train.py\n \n \n         Lines 126 to 129\n       in\n       a0ac5ad\n \n \n \n \n \n \n  \n \n \n \n  # DP mode \n \n \n \n  if cuda and rank == -1 and torch.cuda.device_count() > 1: \n \n \n \n  model = torch.nn.DataParallel(model) \n \n \n \n \n \n I added PR for your convenience. This is minimal needed to change. Tested working on my unit test. If you want to keep image sizes near the dataloaders, it \"may be\" possible to move them above the DP/DDP wrappers, but I'm not sure.\n I think having a CI or unit test in DDP/DP mode should be important as it's easy to miss bugs like these. Of course, I understand that resources are expensive.\n On a side note, this would be how to do pretrain right? Just pass the weights yolov5s.pt without the yolov5s.yaml file?\n \n My Unit test (includes DDP/DP mode)\n set -e \n rm -rf yolov5 && git clone https://github.com/ultralytics/yolov5.git && cd yolov5\n \n #pip install -r requirements.txt onnx\n #python3 -c \"from utils.google_utils import *; gdrive_download('1n_oKgR81BJtqk75b00eAjdv03qVCQn2f', 'coco128.zip')\" && mv -n ./coco128 ../\n export PYTHONPATH=\"$PWD\" # to run *.py. files in subdirectories\n for x in yolov5s #yolov5m yolov5l yolov5x # models\n do\n   python -m torch.distributed.launch --master_port 9990 --nproc_per_node 2 train.py --weights $x.pt --epochs 3 --img 320 --device 0,1 # DDP train\n   for di in 0,1 0 cpu # inference devices\n   do\n     python train.py --weights $x.pt --epochs 3 --img 320 --device $di  # train\n     python detect.py --weights $x.pt --device $di  # detect official\n     python detect.py --weights runs/exp0/weights/last.pt --device $di  # detect custom\n     python test.py --weights $x.pt --device $di # test official\n     python test.py --weights runs/exp0/weights/last.pt --device $di # test custom\n   done\n   python models/yolo.py --cfg $x.yaml # inspect\n   python models/export.py --weights $x.pt --img 640 --batch 1 # export\n done\n \n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "NanoCode012", "commentT": "2020-08-09T18:10:26Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/NanoCode012>@NanoCode012</denchmark-link>\n  thanks, just saw your PR and merged!\n Yes, single and multi-GPU CI would be awesome. It's a very rare use-case though, so I think there is only one company offering support for it, which charges hourly. Alternatively I think Github actions can use self hosted runners that you can point to a cloud instance. This article just appeared a few days ago:\n <denchmark-link:https://github.blog/2020-08-04-github-actions-self-hosted-runners-on-google-cloud/>https://github.blog/2020-08-04-github-actions-self-hosted-runners-on-google-cloud/</denchmark-link>\n \n If this could spin up a 2x K80 GPU VM (the cheapest and slowest GPUs on GCP), then we could run additional CI tests on linux at least on single and double GPU, and then immediately shut it down afterwards, the costs should be manageable.\n But the blog post also notes:\n \n \u26a0\ufe0f Note that these use cases are considered experimental and not officially supported by GitHub at this time. Additionally, it\u2019s recommended not to use self-hosted runners on public repositories for a number of security reasons.\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "NanoCode012", "commentT": "2020-08-09T18:16:22Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/NanoCode012>@NanoCode012</denchmark-link>\n  oh about your other question, yes, now we can 'finetune', or start training from pretrained weights just by supplying the --weights, the --cfg is no longer required.\n If you pass both a --cfg and --weights, the --cfg is used to create a model, and then any matching layers are transferred from the --weights. The anchors are on an exclude list of layers not to transfer, but I need to review this for the --resume use case.\n Also the hyps are now in their own file in data/hyp.yaml. If pretrained weights are supplied then the finetuning hyps are used. If no pretrained weights are supplied then the from-scratch hyps are used. If you supply your own --hyp those are used instead. They two hyp files are identical for now, but may change in the future.\n \t\t"}}}, "commit": {"commit_id": "3d8ed0a76b4a53e0e594c4dcc4b6215001d1d669", "commit_author": "NanoCode012", "commitT": "2020-08-09 11:01:36-07:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "train.py", "file_new_name": "train.py", "file_complexity": {"file_NLOC": "374", "file_CCN": "81", "file_NToken": "4303"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "126,127,128,129", "deleted_lines": "143,144,145,146", "method_info": {"method_name": "train", "method_params": "hyp,opt,device,tb_writer", "method_startline": "31", "method_endline": "367", "method_complexity": {"method_NLOC": "230", "method_CCN": "81", "method_NToken": "2620", "method_nesting_level": "0"}}}}}}}}