{"BR": {"BR_id": "818", "BR_author": "myungjoo", "BRopenT": "2018-11-13T01:10:26Z", "BRcloseT": "2018-11-28T07:35:13Z", "BR_text": {"BRsummary": "Caps negotiation power of tensor_converter is limited.", "BRdescription": "\n In the following pipeline:\n <denchmark-code>v4l2src (cam_src) --> videoscale --> videoconvert --> tensor_converter --> tensor_filter --> ...\n </denchmark-code>\n \n where tensor_filter is using tensorflow-lite model using static input dimension, 3:224:224:1 (image recognition), videoscale / videoconvert MUST automatically convert any video/x-raw stream into RGB 224x224 stream.\n However, without capsfilter specifying 224x224 before tensor_converter, it does not work. (tested in pipeviz)\n tensor_converter and tensor_filter MUST be able to enforce such.\n <denchmark-code>v4l2src --> videoconvert --> videoscale --> tee --> queue --> t_c --> t_f\n </denchmark-code>\n \n as well.\n Therefore, I presume that the cap-nego-power is limited to downstream (media->tensor) and upstream cap-nego is not working as expected (srcpad (tensor) --> sink pad (media) cap negotiation is not working as expected)\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "myungjoo", "commentT": "2018-11-13T01:10:28Z", "comment_text": "\n \t\t : Thank you for posting issue <denchmark-link:https://github.com/nnstreamer/nnstreamer/issues/818>#818</denchmark-link>\n . The person in charge will reply soon.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "myungjoo", "commentT": "2018-11-13T02:04:29Z", "comment_text": "\n \t\tI'll add a test case where such negotiation power is required.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "myungjoo", "commentT": "2018-11-21T04:50:34Z", "comment_text": "\n \t\tlaunch pipeline\n <denchmark-code>GST_DEBUG=tensor_converter:6 gst-launch-1.0 v4l2src ! videoscale ! tensor_converter silent=false ! tensor_filter framework=tensorflow-lite model=./tflite_model/mobilenet_v1_1.0_224_quant.tflite ! tensor_sink\n </denchmark-code>\n \n In tensor-converter gst_tensor_converter_query_caps(), if pad is sinkpad,\n <denchmark-code>/* get possible caps from downstream element */\n peer_caps = gst_pad_peer_query_caps (self->srcpad, NULL);\n \n if (peer_caps) {\n   /* convert peer caps to possible media caps */\n   structure = gst_caps_get_structure (peer_caps, 0);\n   gst_tensor_config_from_structure (&config, structure);\n \n   media_caps = gst_caps_new_empty ();\n \n   /* video caps */\n   tmp = gst_caps_from_string (GST_TENSOR_VIDEO_CAPS_STR);\n   gst_caps_set_simple (tmp, \"format\", G_TYPE_STRING, format, NULL);\n   gst_caps_set_simple (tmp, \"width\", G_TYPE_INT, width, NULL);\n   gst_caps_set_simple (tmp, \"height\", G_TYPE_INT, height, NULL);\n   gst_caps_append (media_caps, tmp);\n \n   /* audio caps */\n   tmp = gst_caps_from_string (GST_TENSOR_AUDIO_CAPS_STR);\n   gst_caps_set_simple (tmp, \"format\", G_TYPE_STRING, format, NULL);\n   gst_caps_append (media_caps, tmp);\n \n   tmp = gst_caps_intersect_full (caps, media_caps, GST_CAPS_INTERSECT_FIRST);\n   gst_caps_unref (caps);\n   caps = tmp;\n \n   gst_caps_unref (peer_caps);\n }\n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "myungjoo", "commentT": "2018-11-28T07:35:13Z", "comment_text": "\n \t\tPR merged, close this issue.\n \t\t"}}}, "commit": {"commit_id": "7d5ee0c01f9957a29a96646e35fa652dbd6c7816", "commit_author": "Jaeyun", "commitT": "2018-11-27 11:54:10+09:00", "commit_complexity": {"commit_NLOC": "0.11278195488721804", "commit_CCN": "0.0", "commit_Nprams": "0.11278195488721804"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "gst\\tensor_converter\\tensor_converter.c", "file_new_name": "gst\\tensor_converter\\tensor_converter.c", "file_complexity": {"file_NLOC": "767", "file_CCN": "113", "file_NToken": "4148"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "913,914,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1068,1078", "deleted_lines": null, "method_info": {"method_name": "gst_tensor_converter_query_caps", "method_params": "self,pad,filter", "method_startline": "908", "method_endline": "1080", "method_complexity": {"method_NLOC": "138", "method_CCN": "30", "method_NToken": "711", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902", "deleted_lines": "890,892,893,899", "method_info": {"method_name": "gst_tensor_converter_get_format_list", "method_params": "list", "method_startline": "885", "method_endline": "902", "method_complexity": {"method_NLOC": "15", "method_CCN": "2", "method_NToken": "87", "method_nesting_level": "0"}}}}}}}}