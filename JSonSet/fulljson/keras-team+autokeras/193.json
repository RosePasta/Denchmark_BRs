{"BR": {"BR_id": "193", "BR_author": "aojue1109", "BRopenT": "2018-09-13T09:47:35Z", "BRcloseT": "2018-11-14T05:58:21Z", "BR_text": {"BRsummary": "Compress image before feed to NN if image is too large", "BRdescription": "\n <denchmark-h:h3>Bug Description</denchmark-h>\n \n I did a cat and dog image classification task, only used 100 pictures to train, and a RuntimeError appeared on a single 8GB system: $ Torch: not enough memory: you tried to allocate 0GB. The image input is 100 * 224 * 224 *3. This problem occurs. The input standard for reducing the image is 100 * 32 * 32 * 3. This problem is not the case, but the accuracy is very low for the training result. The final evaluation value of the second classification. Less than 0.6.\n The specific issues are as follows:\n <denchmark-code>\u2552==============================================\u2555\n |               Training model 1               |\n \u2558==============================================\u255b\n Using TensorFlow backend.\n Current Epoch:   0%|                             | 0/1 [00:00<?, ? batch/s]Exception ignored in: <bound method tqdm.__del__ of Current Epoch:   0%|                             | 0/1 [07:59<?, ? batch/s]>                                                   \n Traceback (most recent call last):\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 885, in __del__\n     self.close()\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 1090, in close\n     self._decr_instances(self)\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 454, in _decr_instances\n     cls.monitor.exit()\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/tqdm/_monitor.py\", line 52, in exit\n     self.join()\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/threading.py\", line 1053, in join\n     raise RuntimeError(\"cannot join current thread\")\n RuntimeError: cannot join current thread\n multiprocessing.pool.RemoteTraceback: \n \"\"\"\n Traceback (most recent call last):\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n     result = (True, func(*args, **kwds))\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n     return list(map(*args))\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/autokeras/search.py\", line 296, in train\n     verbose=verbose).train_model(**trainer_args)\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/autokeras/model_trainer.py\", line 103, in train_model\n     self._train()\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/autokeras/model_trainer.py\", line 147, in _train\n     outputs = self.model(inputs)\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/autokeras/graph.py\", line 610, in forward\n     temp_tensor = torch_layer(edge_input_tensor)\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 477, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\", line 66, in forward\n     exponential_average_factor, self.eps)\n   File \"/root/anaconda3/envs/automl-formal/lib/python3.6/site-packages/torch/nn/functional.py\", line 1254, in batch_norm\n     training, momentum, eps, torch.backends.cudnn.enabled\n RuntimeError: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at [/pytorch/aten/src/TH/THGeneral.cpp:204]\n </denchmark-code>\n \n <denchmark-h:h3>Reproducing Steps</denchmark-h>\n \n Steps to reproduce the behavior:\n \n Step 1: Choose 1 CPU to use (among 8 CPUs):\n Step 2: Run the Cat and Dog Wars classification task, select 50 cats and 50 dogs for the classification task, enter the image parameters: 100 * 224 * 224 *3\n \n <denchmark-h:h3>Expected Behavior</denchmark-h>\n \n Succeed in running the classification task without this error\n Image classification accuracy increased to an acceptable greater than 80%\n <denchmark-h:h3>Setup Details</denchmark-h>\n \n Include the details about the versions of:\n \n OS type and version:\n Python: 3.6\n autokeras: 0.2.14\n scikit-learn:0.19.1\n numpy:1.14.5\n keras:2.2.2\n scipy:1.1.0\n tensorflow:1.10.1\n pytorch:\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "aojue1109", "commentT": "2018-10-02T14:13:18Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/satyakesav>@satyakesav</denchmark-link>\n \n First, you may examine whether the data is loaded to GPU memory batch by batch, or all together.\n If is loaded all together, try to change it to load batch by batch.\n <denchmark-link:https://github.com/jhfjhfj1/autokeras/blob/master/autokeras/model_trainer.py#L219>https://github.com/jhfjhfj1/autokeras/blob/master/autokeras/model_trainer.py#L219</denchmark-link>\n \n Second, if the image is oversize (the total size is larger than 64643), resize the image before feed into the NN, according to their original length/width ratio. Keep the size just right.\n Thanks.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "aojue1109", "commentT": "2018-10-29T23:25:58Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/aojue1109>@aojue1109</denchmark-link>\n \n I was trying to reproduce the error that you reported using the following scenario but unable to do that.\n My training set has 2000 images (1000 each of cat and dog images from Cat vs Dog image classification task). The images have arbitrary sizes in the training set and hence I resized all of them to 324 x 324 x 3 since you have mentioned that the images in your scenario are the same. I have verified that I am training my network on a CPU not GPU.\n The following is the code that I used\n <denchmark-code>x_train, y_train = load_image_dataset(csv_file_path=\"labels.csv\", images_path=\"data\")\n \n x_temp = []\n for x in x_train:\n     x_temp.append(scipy.misc.imresize(x, [324, 324, 3]))\n x_train = numpy.array(x_temp)\n \n if __name__ == '__main__':\n     clf = ImageClassifier(verbose=True, augment=False)\n     clf.fit(x_train, y_train, time_limit=12 * 60 * 60)\n \n </denchmark-code>\n \n Despite the scenario, my model is training without any failure but it is insanely slow because of the obvious reasons.\n Can you please let me know the exact steps to reproduce the issue. Before doing that, it will be good If you can verify whether the issue is reproducible in your environment with the latest pull request. Please let me know.\n Thanks,\n Satya\n \t\t"}}}, "commit": {"commit_id": "5cc81801589dafa7aaeaae052a20f4be0863b8cc", "commit_author": "Satya Kesav", "commitT": "2018-11-13 23:58:20-06:00", "commit_complexity": {"commit_NLOC": "0.3076923076923077", "commit_CCN": "0.6703296703296703", "commit_Nprams": "0.7032967032967034"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "autokeras\\constant.py", "file_new_name": "autokeras\\constant.py", "file_complexity": {"file_NLOC": "40", "file_CCN": "0", "file_NToken": "145"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "55,56,57,58", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 8, "file_old_name": "autokeras\\image\\image_supervised.py", "file_new_name": "autokeras\\image\\image_supervised.py", "file_complexity": {"file_NLOC": "226", "file_CCN": "62", "file_NToken": "1714"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "323,333,334", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,graph,data_transformer,y_encoder,metric,inverse_transform_y_method,resize_params", "method_startline": "323", "method_endline": "334", "method_complexity": {"method_NLOC": "8", "method_CCN": "1", "method_NToken": "62", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "250,251", "deleted_lines": null, "method_info": {"method_name": "export_autokeras_model", "method_params": "self,model_file_name", "method_startline": "244", "method_endline": "252", "method_complexity": {"method_NLOC": "8", "method_CCN": "1", "method_NToken": "62", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "119,120", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,verbose,path,resume,searcher_args,augment", "method_startline": "82", "method_endline": "120", "method_complexity": {"method_NLOC": "20", "method_CCN": "6", "method_NToken": "163", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "224,225,226,227,228", "deleted_lines": "233", "method_info": {"method_name": "final_fit", "method_params": "self,x_train,y_train,x_test,y_test,trainer_args,retrain", "method_startline": "210", "method_endline": "235", "method_complexity": {"method_NLOC": "12", "method_CCN": "5", "method_NToken": "144", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "134,135,136,137,138,139,140", "deleted_lines": null, "method_info": {"method_name": "fit", "method_params": "self,x,y,x_test,y_test,time_limit", "method_startline": "132", "method_endline": "169", "method_complexity": {"method_NLOC": "28", "method_CCN": "8", "method_NToken": "287", "method_nesting_level": "1"}}}, "hunk_5": {"Ismethod": 1, "added_lines": null, "deleted_lines": "305", "method_info": {"method_name": "__init__", "method_params": "self,graph,data_transformer,y_encoder,metric,inverse_transform_y_method", "method_startline": "305", "method_endline": "314", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "44", "method_nesting_level": "1"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "205,206", "deleted_lines": null, "method_info": {"method_name": "evaluate", "method_params": "self,x_test,y_test", "method_startline": "203", "method_endline": "208", "method_complexity": {"method_NLOC": "5", "method_CCN": "3", "method_NToken": "67", "method_nesting_level": "1"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "347", "deleted_lines": null, "method_info": {"method_name": "predict", "method_params": "self,x_test", "method_startline": "336", "method_endline": "357", "method_complexity": {"method_NLOC": "12", "method_CCN": "3", "method_NToken": "101", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "autokeras\\utils.py", "file_new_name": "autokeras\\utils.py", "file_complexity": {"file_NLOC": "143", "file_CCN": "47", "file_NToken": "1104"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197", "deleted_lines": null, "method_info": {"method_name": "compute_image_resize_params", "method_params": "data", "method_startline": "177", "method_endline": "197", "method_complexity": {"method_NLOC": "7", "method_CCN": "2", "method_NToken": "85", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223", "deleted_lines": null, "method_info": {"method_name": "resize_image_data", "method_params": "data,h,w", "method_startline": "200", "method_endline": "223", "method_complexity": {"method_NLOC": "10", "method_CCN": "3", "method_NToken": "73", "method_nesting_level": "0"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "requirements.txt", "file_new_name": "requirements.txt", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "6", "deleted_lines": null}}}, "file_4": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tests\\image\\temp_test.py", "file_complexity": {"file_NLOC": "42", "file_CCN": "1", "file_NToken": "438"}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\test_utils.py", "file_new_name": "tests\\test_utils.py", "file_complexity": {"file_NLOC": "74", "file_CCN": "15", "file_NToken": "558"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76", "deleted_lines": null, "method_info": {"method_name": "test_compute_image_resize_params", "method_params": "", "method_startline": "52", "method_endline": "76", "method_complexity": {"method_NLOC": "20", "method_CCN": "3", "method_NToken": "245", "method_nesting_level": "0"}}}}}}}}