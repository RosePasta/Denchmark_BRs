{"BR": {"BR_id": "292", "BR_author": "kmkolasinski", "BRopenT": "2020-03-10T21:15:23Z", "BRcloseT": "2020-04-14T21:40:21Z", "BR_text": {"BRsummary": "Quantization: Several issues with quantize_model function", "BRdescription": "\n Describe the bug\n Hi, I'm aware of WIP on this project. I had several issues with quantize_model function.\n See my code examples below.\n System information\n TensorFlow installed from (source or binary): binary\n TensorFlow version: 2.2.0-dev20200310\n I use CPU version:\n tf-estimator-nightly          2.1.0.dev2020031001 \n tf-nightly-cpu                2.2.0.dev20200310   \n TensorFlow Model Optimization version: 0.3.0.dev3\n Python version: 3.7.0\n Describe the expected behavior\n I can quantize_model on any model. I should be able to reuse existing feature extractors.\n Describe the current behavior\n Examples are in section below.\n Code to reproduce the issue\n Provide a reproducible code that is the bare minimum necessary to generate the\n problem.\n I will show what work and what not.\n \n This case work for me (I see QuantizeLayers in the summary):\n \n import tensorflow_model_optimization as tfmot\n import tensorflow as tf\n keras = tf.keras\n \n quantize_model = tfmot.quantization.keras.quantize_model\n image_dim = 224\n \n backbone = tf.keras.applications.MobileNetV2(\n     input_shape=[image_dim, image_dim, 3],\n     include_top=False,\n     weights=None,\n     input_tensor=None,\n     pooling=None,\n     classes=None,\n )\n q_model = quantize_model(backbone)\n \n This one raises error:\n \n input_image = keras.Input(shape=[image_dim, image_dim, 3], name='image')\n outputs = backbone(input_image)\n not_working_model = keras.Model(input_image, outputs)\n q_model = quantize_model(not_working_model)\n ---------------------------------------------------------------------------\n TypeError                                 Traceback (most recent call last)\n <ipython-input-10-ff8232533be0> in <module>\n       3 outputs = backbone(input_image)\n       4 not_working_model = keras.Model(input_image, outputs)\n ----> 5 q_aware_model = quantize_model(not_working_model)\n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py in quantize_model(to_quantize)\n      99         'the `quantize_annotate_layer` API to handle individual layers.')\n     100 \n --> 101   annotated_model = quantize_annotate_model(to_quantize)\n     102   return quantize_apply(annotated_model)\n     103 \n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py in quantize_annotate_model(to_annotate)\n     148 \n     149   return keras.models.clone_model(\n --> 150       to_annotate, input_tensors=None, clone_function=_add_quant_wrapper)\n     151 \n     152 \n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/models.py in clone_model(model, input_tensors, clone_function)\n     425   else:\n     426     return _clone_functional_model(\n --> 427         model, input_tensors=input_tensors, layer_fn=clone_function)\n     428 \n     429 \n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/models.py in _clone_functional_model(model, input_tensors, layer_fn)\n     198   input_tensors, output_tensors, created_layers = (\n     199       network.reconstruct_from_config(model_config,\n --> 200                                       created_layers=created_layers))\n     201   metrics_names = model.metrics_names\n     202   model = Model(input_tensors, output_tensors, name=model.name)\n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py in reconstruct_from_config(config, custom_objects, created_layers)\n    2044     layer = created_layers[layer_name]\n    2045     node_index = get_node_index(layer, node_index)\n -> 2046     layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n    2047     output_tensors.append(nest.flatten(layer_output_tensors)[tensor_index])\n    2048 \n \n TypeError: list indices must be integers or slices, not NoneType\n \n This one seems to stuck in some infinite loop (I had to interrupt it):\n \n input_image = keras.Input(shape=[image_dim, image_dim, 3], name='image')\n outputs = backbone(input_image)\n # add extra convolution\n outputs = keras.layers.Conv2D(64, 3, activation='softmax')(outputs)\n not_working_model = keras.Model(input_image, outputs)\n \n # this seems to stuck in some while loop or something else\n q_aware_model = quantize_model(not_working_model)\n \n Creating custom keras model does not work:\n \n input_image = keras.Input(shape=[image_dim, image_dim, 3], name='image')\n \n class MyWrapper(tf.keras.Model):\n     def call(self, x, **kwargs):\n         return backbone(x) #  or return just x\n \n outputs = MyWrapper()(input_image)\n not_working_model = keras.Model(input_image, outputs)\n q_aware_model = quantize_model(not_working_model)\n Tail of traceback:\n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py in get_network_config(network, serialize_layer_fn)\n    2112           filtered_inbound_nodes.append(node_data)\n    2113 \n -> 2114     layer_config = serialize_layer_fn(layer)\n    2115     layer_config['name'] = layer.name\n    2116     layer_config['inbound_nodes'] = filtered_inbound_nodes\n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/models.py in _copy_layer(layer)\n     241       created_layers[layer.name] = InputLayer(**layer.get_config())\n     242     else:\n --> 243       created_layers[layer.name] = layer_fn(layer)\n     244     return {}\n     245 \n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/models.py in _clone_layer(layer)\n      59 \n      60 def _clone_layer(layer):\n ---> 61   return layer.__class__.from_config(layer.get_config())\n      62 \n      63 \n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate.py in get_config(self)\n      81 \n      82   def get_config(self):\n ---> 83     base_config = super(QuantizeAnnotate, self).get_config()\n      84     config = {'quantize_config': serialize_keras_object(self.quantize_config)}\n      85     return dict(list(base_config.items()) + list(config.items()))\n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/layers/wrappers.py in get_config(self)\n      71         'layer': {\n      72             'class_name': self.layer.__class__.__name__,\n ---> 73             'config': self.layer.get_config()\n      74         }\n      75     }\n \n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py in get_config(self)\n     960   def get_config(self):\n     961     if not self._is_graph_network:\n --> 962       raise NotImplementedError\n     963     return copy.deepcopy(get_network_config(self))\n     964 \n \n NotImplementedError: \n \n Custom layer does not work for me:\n \n input_image = keras.Input(shape=[image_dim, image_dim, 3], name='image')\n \n class MyLayer(tf.keras.layers.Layer):\n     def call(self, x, **kwargs):\n         return x\n \n outputs = MyLayer()(input_image)\n not_working_model = keras.Model(input_image, outputs)\n q_aware_model = quantize_model(not_working_model)\n results in ValueError\n ~/anaconda3/envs/tensorflow2/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)\n     319   cls = get_registered_object(class_name, custom_objects, module_objects)\n     320   if cls is None:\n --> 321     raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)\n     322 \n     323   cls_config = config['config']\n \n ValueError: Unknown layer: MyLayer\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "kmkolasinski", "commentT": "2020-04-14T18:00:44Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/kmkolasinski>@kmkolasinski</denchmark-link>\n  for filling this issue!\n In response, <denchmark-link:https://github.com/tensorflow/model-optimization/pull/322>#322</denchmark-link>\n  and <denchmark-link:https://github.com/tensorflow/model-optimization/pull/344>#344</denchmark-link>\n  (this second one isn't in the current 0.3.0 release) should make the experience friendlier. Some of the pathways you mentioned don't have support.\n Now that the API has had its first launch, I'd also encourage you to take a look at <denchmark-link:https://www.tensorflow.org/model_optimization/guide/quantization/training>our documentation</denchmark-link>\n  to check out what's initially supported, as well as other tutorials.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "kmkolasinski", "commentT": "2020-04-14T21:39:38Z", "comment_text": "\n \t\tIn particular, only 1 and 5 work (and for 5, you need to follow what's done in the comprehensive guide tutorial). 2., 3., and 4. are not supported yet (optimizing a subclassed model). You can file a feature request for subclassed models support, but as mentioned in our documentation, there are fundamental reasons we cannot support them well.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "kmkolasinski", "commentT": "2020-04-14T21:40:20Z", "comment_text": "\n \t\tClosing in light of the above - please do feel free to reopen for followups.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "kmkolasinski", "commentT": "2020-04-15T17:43:37Z", "comment_text": "\n \t\tHi, thanks for feedback, sure this issue can be closed now \ud83d\udc4d\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "kmkolasinski", "commentT": "2020-04-30T03:45:45Z", "comment_text": "\n \t\tI have saved the Qunatized model after training, Now I am trying to load it again but giving me this error\n q_aware_model = tf.keras.models.load_model(input_model_name)\n ValueError: Unknown layer: QuantizeLayer\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "kmkolasinski", "commentT": "2020-04-30T15:12:23Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Craftsman381>@Craftsman381</denchmark-link>\n , See <denchmark-link:https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide#checkpoint_and_deserialize>https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide#checkpoint_and_deserialize</denchmark-link>\n \n for how to resolve your issue.\n I had also submitted <denchmark-link:https://github.com/tensorflow/model-optimization/pull/344>#344</denchmark-link>\n , so it'll be clearer on what to do starting with the next TFMOT release.\n \t\t"}}}, "commit": {"commit_id": "b6a97f26e240c39a1d4290f4639f7136168774aa", "commit_author": "Alan Chiao", "commitT": "2020-03-30 17:56:22-07:00", "commit_complexity": {"commit_NLOC": "0.16666666666666666", "commit_CCN": "0.4666666666666667", "commit_Nprams": "0.7"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize.py", "file_new_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize.py", "file_complexity": {"file_NLOC": "150", "file_CCN": "40", "file_NToken": "925"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "165,170,171,172,173,174", "deleted_lines": null, "method_info": {"method_name": "quantize_annotate_model._add_quant_wrapper", "method_params": "layer", "method_startline": "164", "method_endline": "175", "method_complexity": {"method_NLOC": "8", "method_CCN": "3", "method_NToken": "42", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "107,108,109,110,111,112", "deleted_lines": null, "method_info": {"method_name": "quantize_model", "method_params": "to_quantize", "method_startline": "69", "method_endline": "114", "method_complexity": {"method_NLOC": "16", "method_CCN": "5", "method_NToken": "79", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "158,159,160,161,162,163,165,170,171,172,173,174", "deleted_lines": null, "method_info": {"method_name": "quantize_annotate_model", "method_params": "to_annotate", "method_startline": "117", "method_endline": "178", "method_complexity": {"method_NLOC": "17", "method_CCN": "5", "method_NToken": "87", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_annotate.py", "file_new_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_annotate.py", "file_complexity": {"file_NLOC": "76", "file_CCN": "18", "file_NToken": "468"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "55,56,57,58,59,60,61,62,63,64,65", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,layer,quantize_config,kwargs", "method_startline": "45", "method_endline": "88", "method_complexity": {"method_NLOC": "15", "method_CCN": "6", "method_NToken": "124", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_annotate_test.py", "file_new_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_annotate_test.py", "file_complexity": {"file_NLOC": "60", "file_CCN": "9", "file_NToken": "436"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "92,93,94,95,96,97", "deleted_lines": null, "method_info": {"method_name": "testQuantizeAnnotate_FailsWithModel", "method_params": "self", "method_startline": "92", "method_endline": "97", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "50", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_test.py", "file_new_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_test.py", "file_complexity": {"file_NLOC": "284", "file_CCN": "46", "file_NToken": "2383"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "168,169,170,171,172,173,174", "deleted_lines": null, "method_info": {"method_name": "testQuantizeAnnotateModel_FailsWithSubclassedModel", "method_params": "self", "method_startline": "168", "method_endline": "174", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "176,177,178,179,180", "deleted_lines": null, "method_info": {"method_name": "testQuantizeAnnotateModel_FailsWithNestedModels", "method_params": "self", "method_startline": "176", "method_endline": "180", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "45", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "170,171", "deleted_lines": null, "method_info": {"method_name": "testQuantizeAnnotateModel_FailsWithSubclassedModel.call", "method_params": "self,inputs,training,mask", "method_startline": "170", "method_endline": "171", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "17", "method_nesting_level": "3"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "428,429,430,431,432,433,434", "deleted_lines": null, "method_info": {"method_name": "testQuantizeApply_RunsWhenNestedModelNotAnnotated", "method_params": "self", "method_startline": "428", "method_endline": "434", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "53", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_wrapper.py", "file_new_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_wrapper.py", "file_complexity": {"file_NLOC": "133", "file_CCN": "30", "file_NToken": "937"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "50,51,52,53,54,55,56,57,58,59", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,layer,quantize_config,kwargs", "method_startline": "42", "method_endline": "71", "method_complexity": {"method_NLOC": "17", "method_CCN": "6", "method_NToken": "123", "method_nesting_level": "1"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_wrapper_test.py", "file_new_name": "tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize_wrapper_test.py", "file_complexity": {"file_NLOC": "129", "file_CCN": "8", "file_NToken": "991"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "183,184,185,186,187,188,189,190", "deleted_lines": null, "method_info": {"method_name": "testQuantizeWrapper_FailsWithModel", "method_params": "self", "method_startline": "183", "method_endline": "190", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "59", "method_nesting_level": "1"}}}}}}}}