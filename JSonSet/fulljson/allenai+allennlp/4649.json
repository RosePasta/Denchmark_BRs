{"BR": {"BR_id": "4649", "BR_author": "ianupright", "BRopenT": "2020-09-18T01:26:02Z", "BRcloseT": "2020-11-11T00:44:06Z", "BR_text": {"BRsummary": "Problem with PretrainedTransformerEmbedder and models such as T5", "BRdescription": "\n In  PretrainedTransformerEmbedder and PretrainedTransformerTokenizer, there is the line:\n <denchmark-code>    self._num_added_end_tokens = len(tokenizer.single_sequence_end_tokens)\n </denchmark-code>\n \n In the case of models such as T5, the _num_added_tokens results in zero.\n but then there is code like:\n <denchmark-code>    embeddings = embeddings[\n         :, :, self._num_added_start_tokens : -(self._num_added_end_tokens), :\n     ]  # truncate segment-level start/end tokens\n </denchmark-code>\n \n which results in an empty tensor, because I think it should be a -1 to get the last element in the array, instead of -(self._num_added_end_tokens), which results in 0?\n Nevertheless, a T5 model doesn't seem to work with the PretrainedTransformerEmbedder/PretrainedTransformerTokenizer\n \t"}, "comments": {}}, "commit": {"commit_id": "f27ef38b3074ec89a964d9b2d8de110ed75e7cd1", "commit_author": "Dirk Groeneveld", "commitT": "2020-11-10 16:44:05-08:00", "commit_complexity": {"commit_NLOC": "0.8333333333333334", "commit_CCN": "0.8333333333333334", "commit_Nprams": "0.3333333333333333"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "39", "deleted_lines": "39"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "allennlp\\data\\token_indexers\\pretrained_transformer_indexer.py", "file_new_name": "allennlp\\data\\token_indexers\\pretrained_transformer_indexer.py", "file_complexity": {"file_NLOC": "197", "file_CCN": "28", "file_NToken": "1030"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "167,168,169", "deleted_lines": "167", "method_info": {"method_name": "_postprocess_output", "method_params": "self,IndexedTokenList", "method_startline": "150", "method_endline": "187", "method_complexity": {"method_NLOC": "26", "method_CCN": "6", "method_NToken": "136", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "allennlp\\data\\tokenizers\\pretrained_transformer_tokenizer.py", "file_new_name": "allennlp\\data\\tokenizers\\pretrained_transformer_tokenizer.py", "file_complexity": {"file_NLOC": "387", "file_CCN": "22", "file_NToken": "1957"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "121,122,123,124,125,126,185,186,187,188,189", "deleted_lines": null}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "allennlp\\modules\\token_embedders\\pretrained_transformer_embedder.py", "file_new_name": "allennlp\\modules\\token_embedders\\pretrained_transformer_embedder.py", "file_complexity": {"file_NLOC": "279", "file_CCN": "10", "file_NToken": "1211"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "325", "deleted_lines": "325"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "setup.py", "file_new_name": "setup.py", "file_complexity": {"file_NLOC": "59", "file_CCN": "0", "file_NToken": "187"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "67", "deleted_lines": "67"}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\data\\dataset_readers\\dataset_reader_test.py", "file_new_name": "tests\\data\\dataset_readers\\dataset_reader_test.py", "file_complexity": {"file_NLOC": "291", "file_CCN": "36", "file_NToken": "2246"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "24,25", "deleted_lines": null, "method_info": {"method_name": "mock_collate_fn", "method_params": "item", "method_startline": "24", "method_endline": "25", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "10", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "195,211", "deleted_lines": "191,207", "method_info": {"method_name": "test_caching_with_lazy_reader_in_multi_process_loader", "method_params": "self", "method_startline": "186", "method_endline": "213", "method_complexity": {"method_NLOC": "21", "method_CCN": "1", "method_NToken": "132", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "239", "deleted_lines": "235", "method_info": {"method_name": "test_max_instances_with_multi_process_loader", "method_params": "self,num_workers", "method_startline": "229", "method_endline": "242", "method_complexity": {"method_NLOC": "14", "method_CCN": "1", "method_NToken": "61", "method_nesting_level": "1"}}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\modules\\token_embedders\\pretrained_transformer_embedder_test.py", "file_new_name": "tests\\modules\\token_embedders\\pretrained_transformer_embedder_test.py", "file_complexity": {"file_NLOC": "258", "file_CCN": "9", "file_NToken": "2134"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "40,41,42,43", "deleted_lines": "39,43", "method_info": {"method_name": "test_end_to_end", "method_params": "self,bool,bool,bool", "method_startline": "39", "method_endline": "43", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "16", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "42,43", "deleted_lines": "43", "method_info": {"method_name": "test_end_to_end", "method_params": "self,bool,bool,bool", "method_startline": "42", "method_endline": "43", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "15", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "112,113,114,115,116", "deleted_lines": null, "method_info": {"method_name": "test_end_to_end_t5", "method_params": "self,bool,bool,bool", "method_startline": "112", "method_endline": "116", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "16", "method_nesting_level": "1"}}}}}}}}