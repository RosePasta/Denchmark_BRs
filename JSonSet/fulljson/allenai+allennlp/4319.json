{"BR": {"BR_id": "4319", "BR_author": "ud2195", "BRopenT": "2020-06-04T12:59:48Z", "BRcloseT": "2020-06-08T16:24:10Z", "BR_text": {"BRsummary": "Predictor.from_path not loading my trained model", "BRdescription": "\n Hi , After training my Textual entailment model successfully using roBERTa, I am unable to load the same:-\n Traceback:-\n <denchmark-code>---------------------------------------------------------------------------\n ---------------------------------------------------------------------------\n ConfigurationError                        Traceback (most recent call last)\n <ipython-input-56-91de5da48e5e> in <module>()\n      10 from allennlp.predictors.predictor import Predictor\n      11 get_ipython().system('pip install swifter')\n ---> 12 predictor = Predictor.from_path(\"/content/allenepi/model.tar.gz\")\n      13 labels_dict = predictor._model.vocab.get_index_to_token_vocabulary('labels')\n      14 \n 3 frames\n /usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py\n  in from_path(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen)\n     257             predictor_name,\n     258             dataset_reader_to_load=dataset_reader_to_load,\n --> 259             frozen=frozen,\n     260         )\n     261 \n /usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py in from_archive(cls, archive, predictor_name, dataset_reader_to_load, frozen)\n     292         else:\n     293             dataset_reader_params = config[\"dataset_reader\"]\n --> 294         dataset_reader = DatasetReader.from_params(dataset_reader_params)\n     295 \n     296         model = archive.model\n /usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)\n     558                 \"type\",\n     559                 choices=as_registrable.list_available(),\n --> 560                 default_to_first_choice=default_to_first_choice,\n     561             )\n     562             subclass, constructor_name = as_registrable.resolve_class_name(choice)\n /usr/local/lib/python3.6/dist-packages/allennlp/common/params.py in pop_choice(self, key, choices, default_to_first_choice, allow_class_names)\n     349                 \"\"\"{\"model\": \"my_module.models.MyModel\"} to have it imported automatically.\"\"\"\n     350             )\n --> 351             raise ConfigurationError(message)\n     352         return value\n     353 \n ConfigurationError: snli not in acceptable choices for dataset_reader.type: ['conll2003', 'interleaving', 'sequence_tagging', 'sharded', 'babi', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.```\n \n \n \n </denchmark-code>\n \n <denchmark-code>my config.jsonnet:-\n local transformer_model = \"roberta-large\";\n local transformer_dim = 1024;\n local cls_is_last_token = false;\n \n {\n   \"dataset_reader\":{\n     \"type\": \"snli\",\n     \"tokenizer\": {\n       \"type\": \"pretrained_transformer\",\n       \"model_name\": transformer_model,\n       \"add_special_tokens\": false\n     },\n     \"token_indexers\": {\n       \"tokens\": {\n         \"type\": \"pretrained_transformer\",\n         \"model_name\": transformer_model,\n         \"max_length\": 40\n       }\n     }\n   },\n   \"train_data_path\": \"/content/cnli_train_5L.jsonl\",\n   \"validation_data_path\": \"/content/cnli_val_5L.jsonl\",\n   \n   \"model\": {\n     \"type\": \"basic_classifier\",\n     \"text_field_embedder\": {\n       \"token_embedders\": {\n         \"tokens\": {\n           \"type\": \"pretrained_transformer\",\n           \"model_name\": transformer_model,\n           \"max_length\": 40\n         }\n       }\n     },\n     \"seq2vec_encoder\": {\n        \"type\": \"cls_pooler\",\n        \"embedding_dim\": transformer_dim,\n        \"cls_is_last_token\": cls_is_last_token\n     },\n     \"feedforward\": {\n       \"input_dim\": transformer_dim,\n       \"num_layers\": 1,\n       \"hidden_dims\": transformer_dim,\n       \"activations\": \"tanh\"\n     },\n     \"dropout\": 0.1,\n     \"namespace\": \"tags\"\n   },\n   \"data_loader\": {\n     \"batch_sampler\": {\n       \"type\": \"bucket\",\n       \"batch_size\" : 4\n     }\n   },\n   \"trainer\": {\n     \"num_epochs\": 10,\n     \"cuda_device\" : 0,\n     \"validation_metric\": \"+accuracy\",\n     \"learning_rate_scheduler\": {\n       \"type\": \"slanted_triangular\",\n       \"cut_frac\": 0.06\n     },\n     \"optimizer\": {\n       \"type\": \"huggingface_adamw\",\n       \"lr\": 2e-5,\n       \"weight_decay\": 0.1,\n     }\n   }\n }\n \n </denchmark-code>\n \n code :-\n <denchmark-code>from allennlp.predictors.predictor import Predictor \n predictor = Predictor.from_path(\"/content/allenepi/model.tar.gz\")\n </denchmark-code>\n \n allennlp and allennlp-model version is 1.0.0rc5\n will really appreciate some help on the same, Thank you\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ud2195", "commentT": "2020-06-04T16:44:35Z", "comment_text": "\n \t\tThis looks like a duplicate of <denchmark-link:https://github.com/allenai/allennlp/issues/4104>#4104</denchmark-link>\n , which I thought we already fixed.  You're not supposed to need to do any imports or anything to get the  models and dataset readers registered.  <denchmark-link:https://github.com/epwalsh>@epwalsh</denchmark-link>\n , any idea why this isn't working in rc5?  Is it because we're not importing everything in ?\n <denchmark-link:https://github.com/ud2195>@ud2195</denchmark-link>\n , a simple workaround is to run  before your other lines.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ud2195", "commentT": "2020-06-04T17:48:17Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/matt-gardner>@matt-gardner</denchmark-link>\n  Thanks for replying matt. Model loaded successfully but when running the below function on my dataset i get \n function-\n <denchmark-code>def get_labels(hypothesis, premise):\n     pred = predictor.predict(\n       hypothesis=hypothesis,\n       premise=premise\n     )\n     \n     label = labels_dict[np.argmax(pred['label_probs'])]\n     return label\n \n </denchmark-code>\n \n traceback:-\n Traceback (most recent call last):\n <denchmark-code>\n   File \"<ipython-input-23-558217224d8c>\", line 10, in <module>\n     testdata['predicted']=testdata.swifter.apply(lambda x:get_labels(x['hypothesis'],x['sent']))\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/swifter/swifter.py\", line 343, in apply\n     timed = timeit.timeit(wrapped, number=N_REPEATS)\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/timeit.py\", line 233, in timeit\n     return Timer(stmt, setup, timer, globals).timeit(number)\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/timeit.py\", line 178, in timeit\n     timing = self.inner(it, self.timer)\n \n   File \"<timeit-src>\", line 6, in inner\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/swifter/swifter.py\", line 271, in wrapped\n     func, axis=axis, raw=raw, result_type=result_type, args=args, **kwds\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 6878, in apply\n     return op.get_result()\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/apply.py\", line 186, in get_result\n     return self.apply_standard()\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/apply.py\", line 296, in apply_standard\n     values, self.f, axis=self.axis, dummy=dummy, labels=labels\n \n   File \"pandas/_libs/reduction.pyx\", line 618, in pandas._libs.reduction.compute_reduction\n \n   File \"pandas/_libs/reduction.pyx\", line 128, in pandas._libs.reduction.Reducer.get_result\n \n   File \"<ipython-input-23-558217224d8c>\", line 10, in <lambda>\n     testdata['predicted']=testdata.swifter.apply(lambda x:get_labels(x['hypothesis'],x['sent']))\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/series.py\", line 871, in __getitem__\n     result = self.index.get_value(self, key)\n \n   File \"/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 4405, in get_value\n     return self._engine.get_value(s, k, tz=getattr(series.dtype, \"tz\", None))\n \n   File \"pandas/_libs/index.pyx\", line 80, in pandas._libs.index.IndexEngine.get_value\n \n   File \"pandas/_libs/index.pyx\", line 90, in pandas._libs.index.IndexEngine.get_value\n \n   File \"pandas/_libs/index.pyx\", line 135, in pandas._libs.index.IndexEngine.get_loc\n \n   File \"pandas/_libs/index_class_helper.pxi\", line 109, in pandas._libs.index.Int64Engine._check_type\n \n KeyError: 'hypothesis'\n </denchmark-code>\n \n code:-\n <denchmark-code>import swifter\n testdata['predicted']=testdata.swifter.apply(lambda x:get_labels(x['hypothesis'],x['sent']))\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ud2195", "commentT": "2020-06-04T18:04:08Z", "comment_text": "\n \t\tFor that model you have to specify a separate predictor:\n predictor = Predictor.from_path(\n     \"/content/allenepi/model.tar.gz\",\n     predictor_name=\"textual-entailment\"\n )\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "ud2195", "commentT": "2020-06-04T18:45:01Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/matt-gardner>@matt-gardner</denchmark-link>\n  thank you so much, really appreciate your prompt replies and the work that you guys do to build such packages :)\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "ud2195", "commentT": "2020-06-05T22:39:06Z", "comment_text": "\n \t\tFrom issue review: A simple solution is to just import default plugins in allennlp.__init__.  That has potential speed and memory implications that we want to measure before doing it.  Another solution is to do it when importing Predictor, because that's where this issue keeps coming up.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "ud2195", "commentT": "2020-06-05T23:24:45Z", "comment_text": "\n \t\tI think importing plugins in  could potentially result in some circular import issues. Anyway, here's a one potential solution: <denchmark-link:https://github.com/allenai/allennlp/pull/4333>#4333</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "8f68d69b55d5410c39552937e33fb93d0b346d84", "commit_author": "Evan Pete Walsh", "commitT": "2020-06-08 09:24:09-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "22,23,24", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "allennlp\\predictors\\predictor.py", "file_new_name": "allennlp\\predictors\\predictor.py", "file_complexity": {"file_NLOC": "262", "file_CCN": "28", "file_NToken": "1094"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "238", "deleted_lines": null, "method_info": {"method_name": "from_path", "method_params": "cls,str,str,int,str,bool,bool", "method_startline": "231", "method_endline": "238", "method_complexity": {"method_NLOC": "8", "method_CCN": "1", "method_NToken": "39", "method_nesting_level": "1"}}}}}}}}