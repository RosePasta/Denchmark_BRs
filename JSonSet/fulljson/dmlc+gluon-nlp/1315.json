{"BR": {"BR_id": "1315", "BR_author": "ZiyueHuang", "BRopenT": "2020-08-25T14:35:13Z", "BRcloseT": "2020-08-28T11:53:25Z", "BR_text": {"BRsummary": "Bugs for run_electra.py at master branch", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n <denchmark-h:h3>Bug for Horovod support</denchmark-h>\n \n At <denchmark-link:https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/run_electra.py#L418>https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/run_electra.py#L418</denchmark-link>\n ,  depends on the data batch, and thus could be different across the horovod processes (note that Horovod will launch a process for each GPU card), meaning that the parameters maintained in each horovod process (since we use ) might diverge.\n We can normalize the loss by batch_size on each worker before trainer.allreduce_grads(), to avoid syncing num_samples_per_update across all workers.\n <denchmark-h:h3>Bug for MLM loss</denchmark-h>\n \n In the current implementation, the MLM loss actually doesn't take into account masked_weights.\n At <denchmark-link:https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/run_electra.py#L383-L384>https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/run_electra.py#L383-L384</denchmark-link>\n ,  should be replaced by , please see the doc of  at <denchmark-link:https://github.com/apache/incubator-mxnet/pull/19010/files>https://github.com/apache/incubator-mxnet/pull/19010/files</denchmark-link>\n  or the example usage in bert at <denchmark-link:https://github.com/dmlc/gluon-nlp/blob/v0.10.x/scripts/bert/pretraining_utils.py#L416-L418>https://github.com/dmlc/gluon-nlp/blob/v0.10.x/scripts/bert/pretraining_utils.py#L416-L418</denchmark-link>\n \n Note that\n mlm_scores's shape: (batch_size, num_masked_positions, vocab_size)\n unmasked_tokens's shape: (batch_size, num_masked_positions)\n masked_weights's shape: (batch_size, num_masked_positions)\n If we comment out  and add two lines before/after <denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/loss.py#L408>https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/loss.py#L408</denchmark-link>\n :  and , running the current script run_electra.py we will get\n <denchmark-code>loss.shape before weighting  (64, 19, 1)  sample_weight.shape  (1216,)\n loss.shape after weighting  (64, 19, 1216)\n </denchmark-code>\n \n note that 1216 = 64 x 19\n cc <denchmark-link:https://github.com/sxjscience>@sxjscience</denchmark-link>\n  <denchmark-link:https://github.com/ZheyuYe>@ZheyuYe</denchmark-link>\n \n <denchmark-h:h3>Error Message</denchmark-h>\n \n (Paste the complete error message, including stack trace.)\n <denchmark-h:h2>To Reproduce</denchmark-h>\n \n (If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\n <denchmark-h:h3>Steps to reproduce</denchmark-h>\n \n (Paste the commands you ran that produced the error.)\n \n \n \n \n <denchmark-h:h2>What have you tried to solve it?</denchmark-h>\n \n \n \n \n \n <denchmark-h:h2>Environment</denchmark-h>\n \n We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\n <denchmark-code>curl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\n \n # paste outputs here\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ZiyueHuang", "commentT": "2020-08-25T14:58:43Z", "comment_text": "\n \t\tThere is indeed a Bug for mlm loss here, thank you very patiently and carefully to revise the training script and find this bug out. As Far as I can see, this MLM bug will lead to a steep increase in calculations which need to be fixed.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ZiyueHuang", "commentT": "2020-08-25T15:00:06Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ZheyuYe>@ZheyuYe</denchmark-link>\n  Thanks for the response, I will work on the fix later.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ZiyueHuang", "commentT": "2020-08-25T17:04:53Z", "comment_text": "\n \t\tThat might also explain why it's slower. Thanks for the observation! We need to refactor the pretraining script to make it more structured.\n \t\t"}}}, "commit": {"commit_id": "66e5e057347c3710eb8fa27c134a9303309e94c0", "commit_author": "Ziyue Huang", "commitT": "2020-08-28 02:32:22-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.4666666666666667", "commit_Nprams": "0.5333333333333333"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "scripts\\pretraining\\run_electra.py", "file_new_name": "scripts\\pretraining\\run_electra.py", "file_complexity": {"file_NLOC": "461", "file_CCN": "57", "file_NToken": "3485"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "495", "deleted_lines": "492,493", "method_info": {"method_name": "accuracy", "method_params": "labels,predictions,weights", "method_startline": "490", "method_endline": "495", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "71", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "229,230,231,232,233,234,277,278,280,338,358,383,385,386,387,388,390,398,409,413,415,416,417,418,419,420,421,422,423,424,425,427,441,458,459,460,461,462,463,478,479,482", "deleted_lines": "271,273,339,340,347,348,349,355,376,381,382,384,386,394,405,409,410,411,412,413,414,416,417,418,420,434,451,452,453,454,455,461,471,472,475,481,482", "method_info": {"method_name": "train", "method_params": "args", "method_startline": "226", "method_endline": "486", "method_complexity": {"method_NLOC": "215", "method_CCN": "38", "method_NToken": "1554", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "533,534,535,536,537,538,539,540,541,542,543,544,545,546,547", "deleted_lines": "529,530,531,532,533,534,535,536,541,543,544,545,546", "method_info": {"method_name": "evaluation", "method_params": "writer,step_num,masked_input,eval_input", "method_startline": "513", "method_endline": "547", "method_complexity": {"method_NLOC": "33", "method_CCN": "2", "method_NToken": "247", "method_nesting_level": "0"}}}}}}}}