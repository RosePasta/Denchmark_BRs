{"BR": {"BR_id": "129", "BR_author": "jihunchoi", "BRopenT": "2017-09-25T13:16:50Z", "BRcloseT": "2017-10-10T05:38:18Z", "BR_text": {"BRsummary": "Unintuitive behavior of Iterator when sort is False", "BRdescription": "\n Currently, the following line is executed regardless of sort value.\n \n \n \n text/torchtext/data/iterator.py\n \n \n          Line 162\n       in\n       2980f1b\n \n \n \n \n \n \n  minibatch.reverse() \n \n \n \n \n \n It could result in a counter-intuitive behavior when sort is False, since one would probably expect that the order of data is kept intact when sort is False.\n I think this should be executed only when sort is True.\n Is it by design, or a bug?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jihunchoi", "commentT": "2017-09-30T13:26:16Z", "comment_text": "\n \t\tHmm it seems that it can't be solved simply --- I think currently sorting is kind of tangled in the implementation.\n For example when BucketIterator is used, sorting is done within a batch, whether sort is True or not.\n (But with the plain Iterator, sort-within-batch does not occur thus we can't use packed_padded_sequence unless we perform some explicit sorting.)\n I think just calling \"reverse\" function in the iterator cannot completely solve the issue wrt \"packed sequence\". Currently it works only with BucketIterator.\n I suggest the following modification:\n \n \"sort\" flag is used only for indicating \"sort the entire data\".\n Add the additional \"sort_batch\" (or more appropriate name) flag to let the iterator sort the batch.\n Sort order (increasing or decreasing) should be designated only by sort_key function of a dataset. Implanting \"reverse\" operation directly into the core Dataset implementation does not seem to be a good way to do this.\n \n For example, if one wants to sort the batch, not the entire data, in the decreasing order of length, they should set sort=False, sort_batch=True, and sort_key=lambda ex: -len(ex.text).\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jihunchoi", "commentT": "2017-10-02T07:09:12Z", "comment_text": "\n \t\tI agree with most of that, but I still think it's helpful for the order within a batch to default to the opposite of the provided sort_key order (which is used directly as the order between batches). That packed sequences are sorted in decreasing order is essentially a cuDNN implementation detail, while reversing the batch later is difficult to do performantly in the absence of negative stride support in TH/THC core and I think it's strange to ask users to manually provide a reversed sort_key if they want to use packed sequences (since I see sort_key as largely a dataset property that says by which field's length/combination of field lengths a dataset is most naturally sorted).\n Ideally I want to satisfy everyone, but this sorting question has been causing issues in OpenNMT for a few weeks, so I think we should come to a decision and release 0.2 to pypi? Personally I'd lean towards a) making the change outlined in the OP and b) also adding a separate flag to allow sorting the batch even when the data isn't otherwise sorted, but retaining the . Any thoughts <denchmark-link:https://github.com/nelson-liu>@nelson-liu</denchmark-link>\n ?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jihunchoi", "commentT": "2017-10-08T06:33:36Z", "comment_text": "\n \t\tWhoops, this seems to have skipped my inbox. I agree with the conclusion that seems to have been reached (make change described in OP, add flag to allow sorting batch when data isn't otherwise sorted but retaining the reverse)...\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jihunchoi", "commentT": "2017-10-10T05:57:26Z", "comment_text": "\n \t\tI think the solution is cool. In default settings it works nicely with packed sequences, and it's highly customizable! (+ solves the OpenNMT issue)\n \t\t"}}}, "commit": {"commit_id": "c7389b1e4a2897c8c173f33c3132bfefe6c3125c", "commit_author": "jekbradbury", "commitT": "2017-10-09 22:38:17-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.8"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "torchtext\\data\\iterator.py", "file_new_name": "torchtext\\data\\iterator.py", "file_complexity": {"file_NLOC": "233", "file_CCN": "44", "file_NToken": "1355"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "76,77", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,dataset,batch_size,sort_key,device,batch_size_fn,count,count,train,repeat,shuffle,sort,sort_within_batch", "method_startline": "74", "method_endline": "77", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "48", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "72", "method_info": {"method_name": "__init__", "method_params": "self,dataset,batch_size,sort_key,device,batch_size_fn,count,count,train,repeat,shuffle,sort", "method_startline": "70", "method_endline": "72", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "44", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "169,170,171,172,173,174,175,176", "deleted_lines": "160,161,162", "method_info": {"method_name": "__iter__", "method_params": "self", "method_startline": "160", "method_endline": "180", "method_complexity": {"method_NLOC": "17", "method_CCN": "7", "method_NToken": "99", "method_nesting_level": "1"}}}}}}}}