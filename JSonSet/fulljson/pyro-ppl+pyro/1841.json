{"BR": {"BR_id": "1841", "BR_author": "curtis999", "BRopenT": "2019-04-30T03:16:49Z", "BRcloseT": "2019-05-08T05:55:21Z", "BR_text": {"BRsummary": "LDA tutorial: incorrect tensor shape when document size is larger than the vocabulary size", "BRdescription": "\n \n \n \n pyro/examples/lda.py\n \n \n          Line 101\n       in\n       56c0617\n \n \n \n \n \n \n  counts.scatter_add_(0, data[:, ind], torch.tensor(1.).expand(counts.shape)) \n \n \n \n \n \n The filler array of ones should have expanded into the size of the sliced data. This is problematic when the number of words per document is larger than the vocabulary size\n Try\n counts.scatter_add_(0, data[:, ind], torch.tensor(1.).expand(data[:,ind].shape))\n instead\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "curtis999", "commentT": "2019-04-30T17:02:23Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/curtis999>@curtis999</denchmark-link>\n  for the report and fix! Do you have a simple example we can add as a regression test? It can be totally random data.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "curtis999", "commentT": "2019-04-30T21:36:15Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/fritzo>@fritzo</denchmark-link>\n  the error can be replicated simply by passing  or whatever that sets the vocabulary size to be smaller than the total number of words in a document.\n In the example, the data is from the generative model, or we can explicatly generate it with\n <denchmark-code>theta = dist.Dirichlet(torch.zeros([args.num_docs, args.num_topics]) + 0.2).sample()\n phi = dist.Dirichlet(torch.zeros([args.num_topics, args.num_words]) + 0.1).sample()\n z = dist.Categorical(theta).expand([args.num_words_per_doc, args.num_docs]).sample()\n data = dist.Categorical(phi[z]).sample()\n </denchmark-code>\n \n \t\t"}}}, "commit": {"commit_id": "3671ec74b8cbdf08af8b1031b91c0596fe53dc14", "commit_author": "Fritz Obermeyer", "commitT": "2019-05-07 22:55:21-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "0.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "examples\\lda.py", "file_new_name": "examples\\lda.py", "file_complexity": {"file_NLOC": "107", "file_CCN": "10", "file_NToken": "999"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "95,98,99", "deleted_lines": "97,98,99,100,101", "method_info": {"method_name": "parametrized_guide", "method_params": "predictor,data,args,batch_size", "method_startline": "78", "method_endline": "101", "method_complexity": {"method_NLOC": "19", "method_CCN": "1", "method_NToken": "210", "method_nesting_level": "0"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\test_examples.py", "file_new_name": "tests\\test_examples.py", "file_complexity": {"file_NLOC": "157", "file_CCN": "20", "file_NToken": "797"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "118", "deleted_lines": "118"}}}}}}