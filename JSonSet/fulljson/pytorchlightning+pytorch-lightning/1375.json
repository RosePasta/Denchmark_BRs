{"BR": {"BR_id": "1375", "BR_author": "areshytko", "BRopenT": "2020-04-04T16:20:54Z", "BRcloseT": "2020-04-07T10:39:55Z", "BR_text": {"BRsummary": "Tensorboard logger error: lightning_logs directory not exists in multi-node DDP on nodes with rank != 0", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n In multi-node DDP train mode on all nodes except rank 0 errors appears at the start of the training caused by accessing lightning_logs directory in tensorboard logger which is not exist at the moment.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n \n setup multi-node cluster (without SLURM)\n set environment variables on each node:\n \n <denchmark-code>export MASTER_ADDR=<rank 0 node IP>\n export MASTER_PORT=23456\n export RANK=<node id>\n export SLURM_NODEID=<node id>\n export WORLD_SIZE=<world-size>\n </denchmark-code>\n \n \n install dependencies:\n \n <denchmark-code>pip install torch torchvision hydra-core pytorch-lightning\n </denchmark-code>\n \n \n copy app.y and conf.yaml to each node\n run script on each node\n \n <denchmark-code>python app.py\n </denchmark-code>\n \n \n see the error:\n \n <denchmark-code>Exception:\n \n -- Process 0 terminated with the following error:\n Traceback (most recent call last):\n   File \"/home/ubuntu/anaconda3/envs/nightly_pt/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 19, in _wrap\n     fn(i, *args)\n   File \"/home/ubuntu/anaconda3/envs/nightly_pt/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 342, in ddp_train\n     self.run_pretrain_routine(model)\n   File \"/home/ubuntu/anaconda3/envs/nightly_pt/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 777, in run_pretrain_routine\n     self.configure_checkpoint_callback()\n   File \"/home/ubuntu/anaconda3/envs/nightly_pt/lib/python3.6/site-packages/pytorch_lightning/trainer/callback_config.py\", line 45, in configure_checkpoint_callback\n     f'version_{self.logger.version}',\n   File \"/home/ubuntu/anaconda3/envs/nightly_pt/lib/python3.6/site-packages/pytorch_lightning/loggers/tensorboard.py\", line 161, in version\n     self._version = self._get_next_version()\n   File \"/home/ubuntu/anaconda3/envs/nightly_pt/lib/python3.6/site-packages/pytorch_lightning/loggers/tensorboard.py\", line 167, in _get_next_version\n     for d in os.listdir(root_dir):\n FileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/pytorch-lightning-intro-guide/outputs/2020-04-04/15-53-26/lightning_logs'\n </denchmark-code>\n \n <denchmark-h:h4>Code sample</denchmark-h>\n \n app.py:\n <denchmark-code>import pathlib\n \n import hydra\n import pytorch_lightning as pl\n import torch\n from omegaconf import OmegaConf\n from torch.nn import functional as F\n from torch.optim import Adam\n from torch.utils.data import DataLoader, random_split\n from torchvision import datasets, transforms\n \n \n class LitMNIST(pl.LightningModule):\n     def __init__(self):\n         super().__init__()\n         self.layer_1 = torch.nn.Linear(28 * 28, 128)\n         self.layer_2 = torch.nn.Linear(128, 256)\n         self.layer_3 = torch.nn.Linear(256, 10)\n \n         self.train_dataset = None\n         self.val_dataset = None\n         self.test_dataset = None\n \n     def forward(self, x):\n         batch_size, channels, width, height = x.size()\n         x = x.view(batch_size, -1)\n         x = self.layer_1(x)\n         x = F.relu(x)\n         x = self.layer_2(x)\n         x = F.relu(x)\n         x = self.layer_3(x)\n         x = F.log_softmax(x, dim=1)\n         return x\n \n     def prepare_data(self):\n         # transform\n         transform = transforms.Compose(\n             [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n \n         # download\n         data_dir = pathlib.Path.home() / 'data'\n         mnist_train = datasets.MNIST(data_dir, train=True,\n                                      download=True, transform=transform)\n         mnist_test = datasets.MNIST(data_dir, train=False,\n                                     download=True, transform=transform)\n \n         # train/val split\n         mnist_train, mnist_val = random_split(mnist_train, [55000, 5000])\n \n         # assign to use in dataloaders\n         self.train_dataset = mnist_train\n         self.val_dataset = mnist_val\n         self.test_dataset = mnist_test\n \n     def train_dataloader(self):\n         return DataLoader(self.train_dataset, batch_size=64)\n \n     def val_dataloader(self):\n         return DataLoader(self.val_dataset, batch_size=64)\n \n     def test_dataloader(self):\n         return DataLoader(self.test_dataset, batch_size=64)\n \n     def configure_optimizers(self):\n         return Adam(self.parameters(), lr=1e-3)\n \n     def training_step(self, batch, batch_idx):\n         x, y = batch\n         logits = self(x)\n         loss = F.nll_loss(logits, y)\n \n         # add logging\n         logs = {'loss': loss}\n         return {'loss': loss, 'log': logs}\n \n     def validation_step(self, batch, batch_idx):\n         x, y = batch\n         logits = self(x)\n         loss = F.nll_loss(logits, y)\n         return {'val_loss': loss}\n \n     def validation_epoch_end(self, outputs):\n         avg_loss = torch.stack(  # pylint: disable=no-member\n             [x['val_loss'] for x in outputs]).mean()\n         tensorboard_logs = {'val_loss': avg_loss}\n         return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n \n     def test_step(self, batch, batch_idx):\n         x, y = batch\n         logits = self(x)\n         loss = F.nll_loss(logits, y)\n         return {'val_loss': loss}\n \n     def test_epoch_end(self, outputs):\n         avg_loss = torch.stack(  # pylint: disable=no-member\n             [x['val_loss'] for x in outputs]).mean()\n         tensorboard_logs = {'val_loss': avg_loss}\n         return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n \n     def init_ddp_connection(self, proc_rank: int, world_size: int) -> None:\n         torch.distributed.init_process_group(\n             'nccl', rank=proc_rank, world_size=world_size)\n \n \n @hydra.main(config_path='conf.yaml')\n def main(conf: OmegaConf):\n     model = LitMNIST()\n \n     trainer = pl.Trainer(gpus=conf.gpus,\n                          num_nodes=conf.num_nodes,\n                          distributed_backend=conf.distributed_backend,\n                          max_epochs=3)\n     trainer.fit(model)\n \n \n if __name__ == '__main__':\n     main()  # pylint: disable=no-value-for-parameter\n </denchmark-code>\n \n conf.yaml:\n <denchmark-code>gpus: 1\n num_nodes: 2\n distributed_backend: ddp\n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n Train should go without error\n <denchmark-h:h3>Environment</denchmark-h>\n \n <denchmark-code>cuda:\n \tGPU:\n \t\tTesla K80\n \t\tTesla K80\n \t\tTesla K80\n \t\tTesla K80\n \t\tTesla K80\n \t\tTesla K80\n \t\tTesla K80\n \t\tTesla K80\n \tavailable:           True\n \tversion:             10.1\n packages:\n \tnumpy:               1.18.1\n \tpyTorch_debug:       False\n \tpyTorch_version:     1.4.0\n \tpytorch-lightning:   0.7.1\n \ttensorboard:         2.2.0\n \ttqdm:                4.45.0\n system:\n \tOS:                  Linux\n \tarchitecture:\n \t\t64bit\n \n \tprocessor:           x86_64\n \tpython:              3.6.10\n \tversion:             #113-Ubuntu SMP Wed Jan 29 14:54:54 UTC 2020\n </denchmark-code>\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {}}, "commit": {"commit_id": "495ffbd028ae860528c719544cf0409b41d5ef5a", "commit_author": "areshytko", "commitT": "2020-04-07 06:39:54-04:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "0.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "86", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\loggers\\tensorboard.py", "file_new_name": "pytorch_lightning\\loggers\\tensorboard.py", "file_complexity": {"file_NLOC": "149", "file_CCN": "27", "file_NToken": "804"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "167,168,169,170,171", "deleted_lines": null, "method_info": {"method_name": "_get_next_version", "method_params": "self", "method_startline": "165", "method_endline": "180", "method_complexity": {"method_NLOC": "12", "method_CCN": "6", "method_NToken": "116", "method_nesting_level": "1"}}}}}}}}