{"BR": {"BR_id": "3032", "BR_author": "AAnoosheh", "BRopenT": "2020-08-18T07:32:29Z", "BRcloseT": "2020-08-20T10:27:49Z", "BR_text": {"BRsummary": "Epoch counting is one-off in multiple instances", "BRdescription": "\n \ud83d\udc1b Bug\n Two issues occur:\n \n The final epoch does not save a checkpoint during training.\n Resuming from a checkpoint N will start the epochs at N+2.\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n \n Final checkpoint should save a .ckpt file, as usual.\n Should resume from epoch N+1.\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n <denchmark-code>* CUDA:\n \t- GPU:\n \t\t- Tesla V100-DGXS-16GB\n \t\t- Tesla V100-DGXS-16GB\n \t\t- Tesla V100-DGXS-16GB\n \t\t- Tesla V100-DGXS-16GB\n \t- available:         True\n \t- version:           10.1\n * Packages:\n \t- numpy:             1.18.1\n \t- pyTorch_debug:     False\n \t- pyTorch_version:   1.6.0\n \t- pytorch-lightning: 0.9.0rc12\n \t- tensorboard:       2.2.1\n \t- tqdm:              4.46.1\n * System:\n \t- OS:                Linux\n \t- architecture:\n \t\t- 64bit\n \t\t-\n \t- processor:         x86_64\n \t- python:            3.7.7\n \t- version:           #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "AAnoosheh", "commentT": "2020-08-18T18:04:58Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AAnoosheh>@AAnoosheh</denchmark-link>\n  Honestly I do not understand how the PR you linked relates to the bug your report. Did you mean to link another issue?\n \n The final epoch does not save a checkpoint during training.\n \n I don't experience this. The epoch number is 0-indexed, and by default it only saves best checkpoints. Could one of these reasons be why you may think this is a bug?\n How can I reproduce the second issue?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "AAnoosheh", "commentT": "2020-08-18T18:22:15Z", "comment_text": "\n \t\tSorry I should have clarified I use the following to save every epoch:\n pl.callbacks.ModelCheckpoint(save_top_k=-1, verbose=True)\n The second is done via Trainer(resume_from_checkpoint=some_ckpt_file)\n I assume some change was made to move epochs to 0-index, when previously they were 1-indexed, and there's a mismatch now.\n EDIT:\n I also have no idea how a PR was linked in my comment. Those numbers came out of nowhere from the auto-generated issue template.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "AAnoosheh", "commentT": "2020-08-19T14:35:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/AAnoosheh>@AAnoosheh</denchmark-link>\n  so when you run  all the checkpoints are saved, however we do not save the last one as 'last.ckpt'. Also, the checkpoints are numbered from 0, so if you run for 4 epochs, the last checkpoint saved will be 'epoch=3.ckpt' and when you resume, it resumes from the expected 5th epoch.\n Updating tests and code for this\n \t\t"}}}, "commit": {"commit_id": "10150fccb001867472e3cbde298591999e321278", "commit_author": "Ananya Harsh Jha", "commitT": "2020-08-20 06:27:48-04:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "pytorch_lightning\\callbacks\\progress.py", "file_new_name": "pytorch_lightning\\callbacks\\progress.py", "file_complexity": {"file_NLOC": "300", "file_CCN": "56", "file_NToken": "1361"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "333", "deleted_lines": "333", "method_info": {"method_name": "on_epoch_start", "method_params": "self,trainer,pl_module", "method_startline": "322", "method_endline": "333", "method_complexity": {"method_NLOC": "11", "method_CCN": "4", "method_NToken": "84", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "116", "deleted_lines": "116", "method_info": {"method_name": "total_val_batches", "method_params": "self", "method_startline": "108", "method_endline": "118", "method_complexity": {"method_NLOC": "11", "method_CCN": "3", "method_NToken": "52", "method_nesting_level": "1"}}}}}}}}