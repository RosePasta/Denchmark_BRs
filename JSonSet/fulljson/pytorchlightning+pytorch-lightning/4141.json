{"BR": {"BR_id": "4141", "BR_author": "ChanKaHou", "BRopenT": "2020-10-14T09:57:48Z", "BRcloseT": "2020-10-15T13:12:05Z", "BR_text": {"BRsummary": "the self.log problem in validation_step()", "BRdescription": "\n as doc say we should use self.log in last version,\n but the loged data are strange if we change EvalResult() to self.log(on_epoch=True)\n Then we check the data in tensorboard, the self.log() will only log the result of last batch each epoch, instead of the mean of them.\n That is quite unreliable about this issue, it must be turned back to EvalResult() for correct experiments.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ChanKaHou", "commentT": "2020-10-14T09:59:45Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ChanKaHou", "commentT": "2020-10-14T10:38:11Z", "comment_text": "\n \t\tI am having the same issue... Using PL 1.0.0. The progress bar does get the correct values for validation loss, on the other hand.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ChanKaHou", "commentT": "2020-10-14T11:18:05Z", "comment_text": "\n \t\tI found something wrong when saving the model. This is a serious bug.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "ChanKaHou", "commentT": "2020-10-14T12:20:00Z", "comment_text": "\n \t\tTo speed things up: here is a <denchmark-link:https://colab.research.google.com/drive/149CNaNZPHWzIBI2Ea0k6PSzVePsygYue?usp=sharing>boring model</denchmark-link>\n  demonstrating the error. In the TB output, observe that:\n \n the value for val_loss and val_loss_epoch are simply equal to the value of val_loss_step for the last step (same as val_loss_step in progress bar).\n the values for val_loss and val_loss_epoch in TB are different from their equivalents in the progress bar.\n \n So what's happening is that when logging to loggers, reduction is not applied.\n This occurs in version 0.10.0 as well as 1.0.0\n I don't understand how a bug this serious could've made it through all the tests from 0.10.0, through all the 1.0 rcs and all they way to the final version...\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "ChanKaHou", "commentT": "2020-10-14T13:05:28Z", "comment_text": "\n \t\tThe Issue is still present in version 1.0.1.\n I also found out that mean function used to calculate value at the and of the epoch (the value that is present in the progress bar) does not return the correct average value.\n <denchmark-code>def validation_step(self, batch, batch_idx):\n     loss = self.step(batch)\n     self.log('batch_idx', batch_idx, prog_bar=True)\n     self.batch_idxs.append(batch_idx)\n     return loss\n \n def validation_epoch_end(self, outputs: List[Any]) -> None:\n     super().validation_epoch_end(outputs)\n     print(\"batch_idxs mean\", sum(self.batch_idxs) / len(self.batch_idxs))\n     print(\"batch_idxs torch mean\", torch.mean(torch.tensor(self.batch_idxs, dtype=torch.float)))\n     self.batch_idxs = []\n </denchmark-code>\n \n logged value = 31\n progress bar value = 15.1\n mean value = 15.5\n torch mean value = 15.5\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "ChanKaHou", "commentT": "2020-10-14T15:44:42Z", "comment_text": "\n \t\tHere \n \n \n pytorch-lightning/pytorch_lightning/trainer/evaluation_loop.py\n \n \n          Line 199\n       in\n       09c2020\n \n \n \n \n \n \n  epoch_logs = self.trainer.get_model()._results \n \n \n \n \n  this private variable (_results) keeps last step_log. Maybe this is the problem, but I don\u2019t know how to fix it yet.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "ChanKaHou", "commentT": "2020-10-15T08:59:47Z", "comment_text": "\n \t\tI also find this problem, then I log it in validation_epoch_end and it seems ok\n <denchmark-code>     def validation_step(self,...):\n         return {'val_loss': loss}\n \n     def validation_epoch_end(self, outputs):\n         val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n \n \n         dist.all_reduce(val_loss, op=dist.ReduceOp.SUM)\n         val_loss = val_loss / self.trainer.world_size\n         self.log('val_loss', val_loss, on_epoch=True, sync_dist=True)\n \n         return {'val_loss': val_loss,}\n </denchmark-code>\n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "ChanKaHou", "commentT": "2020-10-15T10:41:36Z", "comment_text": "\n \t\tok. good catch. fixing this now!\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "ChanKaHou", "commentT": "2020-10-15T10:53:47Z", "comment_text": "\n \t\tRunning into the same problem with the logger only reporting the last value for the epoch rather than the average across the epoch. I was wondering why I was getting funky test scores \ud83d\ude05 .\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "ChanKaHou", "commentT": "2020-10-15T11:16:03Z", "comment_text": "\n \t\tIs this what you mean?\n <denchmark-link:https://user-images.githubusercontent.com/3640001/96116314-46d2f800-0eb6-11eb-8819-4f3a9ba63e80.png></denchmark-link>\n \n val_loss_epoch and val_loss are the same? but instead, val_loss should be the same as val_loss_step?\n Just wrote a test and it looks like everything is correct, except that the val_loss gets overwritten by the val_loss_epoch by mistake. So:\n \n val_loss_step is correct\n val_loss_epoch is correct\n val_loss is incorrect\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "ChanKaHou", "commentT": "2020-10-15T11:19:37Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  Yes, that's correct. Maybe even val_loss_epoch is incorrect, per <denchmark-link:https://github.com/Alek96>@Alek96</denchmark-link>\n 's comment. Although the bigger issue is wrong values being sent to the (tensorboard of anything non pbar) logger.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "ChanKaHou", "commentT": "2020-10-15T11:22:19Z", "comment_text": "\n \t\t\n def validation_step(self, batch, batch_idx):\n loss = self.step(batch)\n self.log('batch_idx', batch_idx, prog_bar=True)\n self.batch_idxs.append(batch_idx)\n return loss\n def validation_epoch_end(self, outputs: List[Any]) -> None:\n super().validation_epoch_end(outputs)\n print(\"batch_idxs mean\", sum(self.batch_idxs) / len(self.batch_idxs))\n print(\"batch_idxs torch mean\", torch.mean(torch.tensor(self.batch_idxs, dtype=torch.float)))\n self.batch_idxs = []\n \n Well... there is a bug in this code:\n def validation_step(self, batch, batch_idx):\n     loss = self.step(batch)\n     self.log('batch_idx', batch_idx, prog_bar=True)\n     self.batch_idxs.append(batch_idx)\n     return loss\n \n def validation_epoch_end(self, outputs: List[Any]) -> None:\n     super().validation_epoch_end(outputs)\n     print(\"batch_idxs mean\", sum(self.batch_idxs) / len(self.batch_idxs))\n     print(\"batch_idxs torch mean\", torch.mean(torch.tensor(self.batch_idxs, dtype=torch.float)))\n     self.batch_idxs = []\n You return the loss but then compare the batch_idxs...\n outputs has losses, not batch_idxs.\n ie:\n def validation_step(self, batch, batch_idx):\n     loss = self.step(batch)\n     self.log('batch_idx', batch_idx, prog_bar=True)\n     self.batch_idxs.append(batch_idx)\n     return loss # <---------- causes outputs to be losses not indexes\n \n def validation_epoch_end(self, outputs: List[Any]) -> None:\n     outputs = outputs # <------------- losses not indexes!\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "ChanKaHou", "commentT": "2020-10-15T11:31:56Z", "comment_text": "\n \t\tok, i think i found it. posting a fix now. Looks like the calculations are correct, but the wrong value got logged\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "ChanKaHou", "commentT": "2020-10-15T13:12:19Z", "comment_text": "\n \t\tThanks for the fast fix.\n To explain my intention:\n \n You return the loss but then compare the batch_idxs...\n outputs has losses, not batch_idxs.\n \n In my understanding it should not matter if I returned loss value and then compared the batch_idxs. self.log method should work the same regardless of the value you pass in. That is way I called a method with a value that easily shows if the calculated mean is correct.\n self.log('batch_idx', batch_idx, prog_bar=True)\n The \"bug\" was not in the code, but in my understating of mean function. PyTorch lightning is using weighted_mean that is also taking in the account the size of each batch.\n \n \n \n pytorch-lightning/pytorch_lightning/core/step_result.py\n \n \n         Lines 446 to 456\n       in\n       f064682\n \n \n \n \n \n \n  if option['on_epoch']: \n \n \n \n  fx = option['reduce_fx'] \n \n \n \n  if fx == torch.mean: \n \n \n \n  try: \n \n \n \n  reduced_val = weighted_mean(result[k], batch_sizes) \n \n \n \n  except Exception as e: \n \n \n \n  reduced_val = torch.mean(result[k]) \n \n \n \n  else: \n \n \n \n  reduced_val = fx(result[k]) \n \n \n \n  \n \n \n \n  result[k] = reduced_val \n \n \n \n \n \n <denchmark-link:https://colab.research.google.com/drive/1oa6TKF59k744HTX19597QHGY9gJV0A8I?usp=sharing>Boring_model</denchmark-link>\n  that shows the behavior.\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "ChanKaHou", "commentT": "2020-10-15T13:14:16Z", "comment_text": "\n \t\tall good!\n Please try on master now. Let me know if the errors are fixed.\n For reference, here is the new test for this:\n \n \n \n pytorch-lightning/tests/trainer/logging/test_eval_loop_logging_1_0.py\n \n \n         Lines 247 to 313\n       in\n       45d05ff\n \n \n \n \n \n \n  def test_eval_logging_auto_reduce(tmpdir): \n \n \n \n  \"\"\" \n \n \n \n      Tests that only training_step can be used \n \n \n \n      \"\"\" \n \n \n \n  seed_everything(1234) \n \n \n \n  \n \n \n \n  os.environ['PL_DEV_DEBUG'] = '1' \n \n \n \n  \n \n \n \n  class TestModel(BoringModel): \n \n \n \n  def on_pretrain_routine_end(self) -> None: \n \n \n \n  self.seen_vals = [] \n \n \n \n  self.manual_epoch_end_mean = None \n \n \n \n  \n \n \n \n  def on_validation_epoch_start(self) -> None: \n \n \n \n  self.seen_vals = [] \n \n \n \n  \n \n \n \n  def validation_step(self, batch, batch_idx): \n \n \n \n  output = self.layer(batch) \n \n \n \n  loss = self.loss(batch, output) \n \n \n \n  self.seen_vals.append(loss) \n \n \n \n  self.log('val_loss', loss, on_epoch=True, on_step=True, prog_bar=True) \n \n \n \n  return {\"x\": loss} \n \n \n \n  \n \n \n \n  def validation_epoch_end(self, outputs) -> None: \n \n \n \n  for passed_in, manually_tracked in zip(outputs, self.seen_vals): \n \n \n \n  assert passed_in['x'] == manually_tracked \n \n \n \n  self.manual_epoch_end_mean = torch.stack([x['x'] for x in outputs]).mean() \n \n \n \n  \n \n \n \n  model = TestModel() \n \n \n \n  \n \n \n \n  trainer = Trainer( \n \n \n \n  default_root_dir=tmpdir, \n \n \n \n  limit_train_batches=3, \n \n \n \n  limit_val_batches=3, \n \n \n \n  max_epochs=1, \n \n \n \n  log_every_n_steps=1, \n \n \n \n  weights_summary=None, \n \n \n \n  checkpoint_callback=callbacks.ModelCheckpoint('val_loss') \n \n \n \n      ) \n \n \n \n  trainer.fit(model) \n \n \n \n  \n \n \n \n  # make sure all the metrics are available for callbacks \n \n \n \n  manual_mean = model.manual_epoch_end_mean \n \n \n \n  callback_metrics = set(trainer.callback_metrics.keys()) \n \n \n \n  assert callback_metrics == {'debug_epoch', 'val_loss', 'val_loss_epoch'} \n \n \n \n  \n \n \n \n  # make sure values are correct \n \n \n \n  assert trainer.logged_metrics['val_loss_epoch'] == manual_mean \n \n \n \n  assert trainer.callback_metrics['val_loss'] == trainer.logged_metrics['val_loss_step/epoch_0'] \n \n \n \n  \n \n \n \n  # make sure correct values were logged \n \n \n \n  logged_val = trainer.dev_debugger.logged_metrics \n \n \n \n  \n \n \n \n  # sanity check \n \n \n \n  assert logged_val[0]['global_step'] == 0 \n \n \n \n  assert logged_val[1]['global_step'] == 0 \n \n \n \n  \n \n \n \n  # 3 val batches \n \n \n \n  assert logged_val[2]['val_loss_step/epoch_0'] == model.seen_vals[0] \n \n \n \n  assert logged_val[3]['val_loss_step/epoch_0'] == model.seen_vals[1] \n \n \n \n  assert logged_val[4]['val_loss_step/epoch_0'] == model.seen_vals[2] \n \n \n \n  \n \n \n \n  # epoch mean \n \n \n \n  assert logged_val[5]['val_loss_epoch'] == model.manual_epoch_end_mean \n \n \n \n  \n \n \n \n  # only those logged \n \n \n \n  assert len(logged_val) == 6 \n \n \n \n \n \n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "ChanKaHou", "commentT": "2020-10-15T13:30:38Z", "comment_text": "\n \t\tas a bonus, got rid of the duplicate metric, metric_step chart without losing support for callbacks\n <denchmark-link:https://user-images.githubusercontent.com/3640001/96133953-1183d580-0ec9-11eb-8850-dc50f5b78fea.png></denchmark-link>\n \n <denchmark-link:https://github.com/tchaton>@tchaton</denchmark-link>\n   FYI\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "ChanKaHou", "commentT": "2020-10-15T14:49:35Z", "comment_text": "\n \t\tok, mind verifying that this worked for you guys?\n this is a critical bug, so, we'll do a minor release now to fix it for everyone.\n Here's the new colab with master showing it's fixed:\n <denchmark-link:https://colab.research.google.com/drive/1lEZms9QjRZ7kPosu_m7Gbr_sdBZ7exzg?usp=sharing>https://colab.research.google.com/drive/1lEZms9QjRZ7kPosu_m7Gbr_sdBZ7exzg?usp=sharing</denchmark-link>\n \n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "ChanKaHou", "commentT": "2020-10-15T14:57:05Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  it works now, thanks a lot.\n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "ChanKaHou", "commentT": "2020-10-15T14:58:38Z", "comment_text": "\n \t\tWorks here too :)\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "ChanKaHou", "commentT": "2020-10-15T16:46:44Z", "comment_text": "\n \t\tJust testing and it works for me too \ud83d\udcaa\n \t\t"}}}, "commit": {"commit_id": "45d05ff68dbf3db300a782af97ea54cab70a3ff9", "commit_author": "William Falcon", "commitT": "2020-10-15 09:12:05-04:00", "commit_complexity": {"commit_NLOC": "0.23529411764705882", "commit_CCN": "0.8529411764705882", "commit_Nprams": "0.8970588235294118"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "pytorch_lightning\\core\\step_result.py", "file_new_name": "pytorch_lightning\\core\\step_result.py", "file_complexity": {"file_NLOC": "641", "file_CCN": "186", "file_NToken": "4230"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "305,306,307", "deleted_lines": null, "method_info": {"method_name": "get_epoch_pbar_metrics", "method_params": "self", "method_startline": "294", "method_endline": "318", "method_complexity": {"method_NLOC": "16", "method_CCN": "10", "method_NToken": "117", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "279,280,281", "deleted_lines": null, "method_info": {"method_name": "get_epoch_log_metrics", "method_params": "self", "method_startline": "268", "method_endline": "292", "method_complexity": {"method_NLOC": "19", "method_CCN": "10", "method_NToken": "119", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "468,469,470,471,472", "deleted_lines": null, "method_info": {"method_name": "reduce_on_epoch_end", "method_params": "cls,outputs", "method_startline": "450", "method_endline": "488", "method_complexity": {"method_NLOC": "30", "method_CCN": "9", "method_NToken": "196", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "561,562,563,564,565,566", "deleted_lines": null, "method_info": {"method_name": "choose_last", "method_params": "x", "method_startline": "561", "method_endline": "566", "method_complexity": {"method_NLOC": "6", "method_CCN": "4", "method_NToken": "57", "method_nesting_level": "0"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "320,321,322,323,324,325,326,327,328,329,330,331,332,333,334", "deleted_lines": null, "method_info": {"method_name": "get_forked_metrics", "method_params": "self", "method_startline": "320", "method_endline": "334", "method_complexity": {"method_NLOC": "9", "method_CCN": "4", "method_NToken": "50", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\connectors\\logger_connector.py", "file_new_name": "pytorch_lightning\\trainer\\connectors\\logger_connector.py", "file_complexity": {"file_NLOC": "311", "file_CCN": "86", "file_NToken": "2185"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "192,193,194,195,200,201", "deleted_lines": "196,197", "method_info": {"method_name": "_log_on_evaluation_epoch_end_metrics", "method_params": "self,epoch_logs", "method_startline": "137", "method_endline": "206", "method_complexity": {"method_NLOC": "34", "method_CCN": "7", "method_NToken": "267", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\evaluation_loop.py", "file_new_name": "pytorch_lightning\\trainer\\evaluation_loop.py", "file_complexity": {"file_NLOC": "242", "file_CCN": "88", "file_NToken": "1820"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "221,222,223", "deleted_lines": null, "method_info": {"method_name": "__run_eval_epoch_end", "method_params": "self,num_dataloaders,using_eval_result", "method_startline": "218", "method_endline": "263", "method_complexity": {"method_NLOC": "32", "method_CCN": "13", "method_NToken": "190", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tests\\core\\test_metric_result_integration.py", "file_new_name": "tests\\core\\test_metric_result_integration.py", "file_complexity": {"file_NLOC": "87", "file_CCN": "15", "file_NToken": "717"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "138", "deleted_lines": "139", "method_info": {"method_name": "test_result_metric_integration", "method_params": "", "method_startline": "104", "method_endline": "142", "method_complexity": {"method_NLOC": "28", "method_CCN": "5", "method_NToken": "253", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "86", "method_info": {"method_name": "_ddp_test_fn", "method_params": "rank,worldsize", "method_startline": "46", "method_endline": "92", "method_complexity": {"method_NLOC": "34", "method_CCN": "5", "method_NToken": "284", "method_nesting_level": "0"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 7, "file_old_name": "tests\\trainer\\logging\\test_eval_loop_logging_1_0.py", "file_new_name": "tests\\trainer\\logging\\test_eval_loop_logging_1_0.py", "file_complexity": {"file_NLOC": "226", "file_CCN": "22", "file_NToken": "1462"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "270,271,272,273", "deleted_lines": null, "method_info": {"method_name": "test_eval_logging_auto_reduce.validation_epoch_end", "method_params": "self,outputs", "method_startline": "270", "method_endline": "273", "method_complexity": {"method_NLOC": "4", "method_CCN": "3", "method_NToken": "53", "method_nesting_level": "2"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "263,264,265,266,267,268", "deleted_lines": null, "method_info": {"method_name": "test_eval_logging_auto_reduce.validation_step", "method_params": "self,batch,batch_idx", "method_startline": "263", "method_endline": "268", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "61", "method_nesting_level": "2"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "260,261", "deleted_lines": null, "method_info": {"method_name": "test_eval_logging_auto_reduce.on_validation_epoch_start", "method_params": "self", "method_startline": "260", "method_endline": "261", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "13", "method_nesting_level": "2"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "256,257,258", "deleted_lines": null, "method_info": {"method_name": "test_eval_logging_auto_reduce.on_pretrain_routine_end", "method_params": "self", "method_startline": "256", "method_endline": "258", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "18", "method_nesting_level": "2"}}}, "hunk_4": {"Ismethod": 1, "added_lines": null, "deleted_lines": "71", "method_info": {"method_name": "test__validation_step__log", "method_params": "tmpdir", "method_startline": "26", "method_endline": "85", "method_complexity": {"method_NLOC": "35", "method_CCN": "1", "method_NToken": "151", "method_nesting_level": "0"}}}, "hunk_5": {"Ismethod": 1, "added_lines": null, "deleted_lines": "145,150", "method_info": {"method_name": "test__validation_step__step_end__epoch_end__log", "method_params": "tmpdir", "method_startline": "88", "method_endline": "166", "method_complexity": {"method_NLOC": "45", "method_CCN": "1", "method_NToken": "190", "method_nesting_level": "0"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313", "deleted_lines": null, "method_info": {"method_name": "test_eval_logging_auto_reduce", "method_params": "tmpdir", "method_startline": "247", "method_endline": "313", "method_complexity": {"method_NLOC": "32", "method_CCN": "1", "method_NToken": "221", "method_nesting_level": "0"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\trainer\\logging\\test_train_loop_logging_1_0.py", "file_new_name": "tests\\trainer\\logging\\test_train_loop_logging_1_0.py", "file_complexity": {"file_NLOC": "343", "file_CCN": "38", "file_NToken": "2530"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "398,399", "deleted_lines": "398,399", "method_info": {"method_name": "test_different_batch_types_for_sizing", "method_params": "tmpdir", "method_startline": "362", "method_endline": "403", "method_complexity": {"method_NLOC": "22", "method_CCN": "1", "method_NToken": "80", "method_nesting_level": "0"}}}}}}}}