{"BR": {"BR_id": "760", "BR_author": "fdelrio89", "BRopenT": "2020-01-28T15:36:34Z", "BRcloseT": "2020-02-26T23:34:53Z", "BR_text": {"BRsummary": "Test metrics not logging to Comet after training", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n When testing a model with Trainer.test metrics are not logged to Comet if the model was previously trained using Trainer.fit. While training metrics are logged correctly.\n <denchmark-h:h4>Code sample</denchmark-h>\n \n <denchmark-code>    comet_logger = CometLogger()\n     trainer = Trainer(logger=comet_logger)\n     model = get_model()\n \n     trainer.fit(model) # Metrics are logged to Comet\n     trainer.test(model) # No metrics are logged to Comet\n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n Test metrics should also be logged in to Comet.\n <denchmark-h:h3>Environment</denchmark-h>\n \n <denchmark-code>- PyTorch version: 1.3.0\n Is debug build: No\n CUDA used to build PyTorch: 10.1.243\n \n OS: Ubuntu 18.04.3 LTS\n GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\n CMake version: version 3.10.2\n \n Python version: 3.7\n Is CUDA available: Yes\n CUDA runtime version: 10.1.168\n GPU models and configuration:\n GPU 0: GeForce GTX 1080 Ti\n GPU 1: GeForce GTX 1080 Ti\n GPU 2: GeForce GTX 1080 Ti\n GPU 3: GeForce GTX 1080 Ti\n GPU 4: GeForce GTX 1080 Ti\n GPU 5: GeForce GTX 1080 Ti\n GPU 6: GeForce GTX 1080 Ti\n GPU 7: GeForce GTX 1080 Ti\n \n Nvidia driver version: 418.67\n cuDNN version: /usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudnn.so.7.6.1\n \n Versions of relevant libraries:\n [pip3] numpy==1.16.4\n [pip3] pytorch-lightning==0.6.0\n [pip3] torch==1.3.0\n [pip3] torchvision==0.4.1\n [conda] Could not collect\n </denchmark-code>\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n I believe the issue is caused because at the <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/deffbaba7ffb16ff57b56fe65f62df761f25fbd6/pytorch_lightning/trainer/training_loop.py#L366>end of the training routine</denchmark-link>\n ,  is called. This in turn calls  inside the logger and the  object doesn't expect to send more information after this.\n An alternative is to create another Trainer object, with another logger but this means that the metrics will be logged into a different Comet experiment from the original. This issue can be solved using the ExistingExperiment object form the Comet SDK, but the solution seems a little hacky and the CometLogger currently doesn't support this kind of experiment.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "fdelrio89", "commentT": "2020-02-11T17:36:13Z", "comment_text": "\n \t\tDid you find a solution?\n Mind submitting a PR?\n <denchmark-link:https://github.com/fdelrio89>@fdelrio89</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "fdelrio89", "commentT": "2020-02-13T21:36:24Z", "comment_text": "\n \t\tI did solve the issue but in a kind of hacky way. It's not that elegant but it works for me, and I haven't had the time to think of a better solution.\n I solved it by getting the experiment key and creating another logger and trainer with it.\n <denchmark-code>    comet_logger = CometLogger()\n     trainer = Trainer(logger=comet_logger)\n     model = get_model()\n \n     trainer.fit(model)\n \n     experiment_key = comet_logger.experiment.get_key()\n     comet_logger = CometLogger(experiment_key=experiment_key)\n     trainer = Trainer(logger=comet_logger)\n \n     trainer.test(model)\n </denchmark-code>\n \n For this to work, I had to modify the CometLogger class to accept the experiment_key and create a CometExistingExperiment from the Comet SDK when this param is present.\n <denchmark-code>class CometLogger(LightningLoggerBase):\n      ...\n \n     @property\n     def experiment(self):\n         ...\n \n         if self.mode == \"online\":\n             if self.experiment_key is None:\n                 self._experiment = CometExperiment(\n                     api_key=self.api_key,\n                     workspace=self.workspace,\n                     project_name=self.project_name,\n                     **self._kwargs\n                 )\n             else:\n                 self._experiment = CometExistingExperiment(\n                     api_key=self.api_key,\n                     workspace=self.workspace,\n                     project_name=self.project_name,\n                     previous_experiment=self.experiment_key,\n                     **self._kwargs\n                 )\n         else:\n             ...\n \n         return self._experiment\n </denchmark-code>\n \n I can happily do the PR if this solution is acceptable for you guys, but I think a better solution can be achieved I haven't had the time to think about it <denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n .\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "fdelrio89", "commentT": "2020-02-17T11:18:50Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  Any progress on this Issue? I am facing the same problem.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "fdelrio89", "commentT": "2020-02-17T11:21:16Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/fdelrio89>@fdelrio89</denchmark-link>\n  Since the logger object is available for the lifetime of the trainer, maybe you can refactor to store the  directly in the logger object itself, instead of having to re-instantiate the logger.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "fdelrio89", "commentT": "2020-02-18T21:27:32Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/xssChauhan>@xssChauhan</denchmark-link>\n  good idea, I just submitted a PR (<denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/892>#892</denchmark-link>\n ) considering this. Thanks!\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "fdelrio89", "commentT": "2020-02-26T23:34:53Z", "comment_text": "\n \t\tI assume that it was fixed by <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/892>#892</denchmark-link>\n \n if you have some other problems feel free to reopen or create a new... \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "fdelrio89", "commentT": "2020-04-19T06:51:52Z", "comment_text": "\n \t\tActually I'm still facing the problem.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "fdelrio89", "commentT": "2020-04-19T09:11:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/dvirginz>@dvirginz</denchmark-link>\n  are you using the latest master? may you provide a minimal example?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "fdelrio89", "commentT": "2020-04-19T09:21:55Z", "comment_text": "\n \t\t\n @dvirginz are you using the latest master? may you provide a minimal example?\n \n You are right, sorry.\n After building from source it works.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "fdelrio89", "commentT": "2020-07-14T13:43:08Z", "comment_text": "\n \t\tI should probably open a new issue, but it happens with Weights & Biases logger too. I haven't had the time to delve deep into it yet.\n \t\t"}}}, "commit": {"commit_id": "4ac9925dad71edda26db486795341f0b0ba4ed38", "commit_author": "fdelrio89", "commitT": "2020-02-21 20:47:48-05:00", "commit_complexity": {"commit_NLOC": "0.5454545454545454", "commit_CCN": "1.0", "commit_Nprams": "0.9545454545454546"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "pytorch_lightning\\loggers\\comet.py", "file_new_name": "pytorch_lightning\\loggers\\comet.py", "file_complexity": {"file_NLOC": "172", "file_CCN": "14", "file_NToken": "585"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "176,177", "deleted_lines": null, "method_info": {"method_name": "reset_experiment", "method_params": "self", "method_startline": "176", "method_endline": "177", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "10", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "37,38", "deleted_lines": "36", "method_info": {"method_name": "__init__", "method_params": "self,api_key,save_dir,workspace,rest_api_key,project_name,experiment_name,experiment_key,kwargs", "method_startline": "36", "method_endline": "38", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "36", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152", "deleted_lines": "134,135,136,137,138,139", "method_info": {"method_name": "experiment", "method_params": "self", "method_startline": "123", "method_endline": "161", "method_complexity": {"method_NLOC": "37", "method_CCN": "4", "method_NToken": "145", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": null, "deleted_lines": "36", "method_info": {"method_name": "__init__", "method_params": "self,api_key,save_dir,workspace,rest_api_key,project_name,experiment_name,kwargs", "method_startline": "35", "method_endline": "36", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "32", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "181,182,183,184,185,186,187,188,190", "deleted_lines": null, "method_info": {"method_name": "finalize", "method_params": "self,status", "method_startline": "180", "method_endline": "190", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "21", "method_nesting_level": "1"}}}}}}}}