{"BR": {"BR_id": "2299", "BR_author": "Laksh1997", "BRopenT": "2020-06-20T14:15:24Z", "BRcloseT": "2020-06-27T19:08:23Z", "BR_text": {"BRsummary": "DDP Bug with Model Checkpoint parsing", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n My script works with CPU, single-GPU and dp.\n I need ddp to do 16 bit training. Also even on a single machine ddp is faster.\n Here is my ModelCheckpoint code:\n <denchmark-code>def setup_model_checkpoint(config):\n     kwargs = config[\"model_checkpoint_kwargs\"]\n     metrics = kwargs.pop(\"metrics\", [\"val_loss\"])\n     if isinstance(metrics, str):\n         metrics = [metrics]\n \n     fp = \"checkpoints/{epoch}\"\n     for metric in metrics:\n         fp += \"-{\"\n         fp += str(metric)\n         fp += \":.2f}\"\n \n     return ModelCheckpoint(filepath=fp, **kwargs)\n </denchmark-code>\n \n In my case it would generate the checkpoint: checkpoints/epoch=4_val_loss=0.6_auc=0.85 for example.\n Although I even tried it with just checkpoints and it's the same issue.\n The issue is the following:\n <denchmark-code>2020-06-20T14:50:19.704+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 891, in fit\n 2020-06-20T14:50:19.704+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 891, in fit\n 2020-06-20T14:50:19.704+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 891, in fit\n 2020-06-20T14:50:19.705+01:00\n self.ddp_train(task, model)\n 2020-06-20T14:50:19.705+01:00\n self.ddp_train(task, model)\n 2020-06-20T14:50:19.705+01:00\n self.ddp_train(task, model)\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 530, in ddp_train\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 530, in ddp_train\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 530, in ddp_train\n 2020-06-20T14:50:19.705+01:00\n self.run_pretrain_routine(model)\n 2020-06-20T14:50:19.705+01:00\n self.run_pretrain_routine(model)\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1046, in run_pretrain_routine\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1046, in run_pretrain_routine\n 2020-06-20T14:50:19.705+01:00\n self.run_pretrain_routine(model)\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1046, in run_pretrain_routine\n 2020-06-20T14:50:19.705+01:00\n self.configure_checkpoint_callback()\n 2020-06-20T14:50:19.705+01:00\n self.configure_checkpoint_callback()\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/callback_config.py\", line 60, in configure_checkpoint_callback\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/callback_config.py\", line 60, in configure_checkpoint_callback\n 2020-06-20T14:50:19.705+01:00\n self.configure_checkpoint_callback()\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/callback_config.py\", line 60, in configure_checkpoint_callback\n 2020-06-20T14:50:19.705+01:00\n \"checkpoints\"\n 2020-06-20T14:50:19.705+01:00\n \"checkpoints\"\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/posixpath.py\", line 94, in join\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/posixpath.py\", line 94, in join\n 2020-06-20T14:50:19.705+01:00\n \"checkpoints\"\n 2020-06-20T14:50:19.705+01:00\n genericpath._check_arg_types('join', a, *p)\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/genericpath.py\", line 149, in _check_arg_types\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/posixpath.py\", line 94, in join\n 2020-06-20T14:50:19.705+01:00\n genericpath._check_arg_types('join', a, *p)\n 2020-06-20T14:50:19.705+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/genericpath.py\", line 149, in _check_arg_types\n 2020-06-20T14:50:19.705+01:00\n (funcname, s.__class__.__name__)) from None\n 2020-06-20T14:50:19.705+01:00\n genericpath._check_arg_types('join', a, *p)\n 2020-06-20T14:50:19.705+01:00\n TypeError: join() argument must be str or bytes, not 'NoneType'\n 2020-06-20T14:50:19.706+01:00\n File \"/home/user/miniconda/envs/py36/lib/python3.6/genericpath.py\", line 149, in _check_arg_types\n 2020-06-20T14:50:19.706+01:00\n (funcname, s.__class__.__name__)) from None\n 2020-06-20T14:50:19.706+01:00\n TypeError: join() argument must be str or bytes, not 'NoneType'\n 2020-06-20T14:50:19.706+01:00\n (funcname, s.__class__.__name__)) from None\n 2020-06-20T14:50:19.706+01:00\n TypeError: join() argument must be str or bytes, not 'NoneType'\n </denchmark-code>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n \n PyTorch Version (e.g., 1.0): 1.4\n OS (e.g., Linux): Linux\n How you installed PyTorch (conda, pip, source): Conda\n Build command you used (if compiling from source):\n Python version: 3.6.5\n CUDA/cuDNN version: 10.1\n GPU models and configuration: 4 x V100\n Any other relevant information: Pytorch lightning 0.8.0\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Laksh1997", "commentT": "2020-06-20T14:32:05Z", "comment_text": "\n \t\tAhh, it may be because I do kwargs.pop(\"metrics\") which then means for the other processes its a NoneType.\n I've copy.deepcopy'd kwargs. Let's see if that fixes it!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Laksh1997", "commentT": "2020-06-20T14:46:40Z", "comment_text": "\n \t\tTurns out the above didn't help.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Laksh1997", "commentT": "2020-06-20T14:50:09Z", "comment_text": "\n \t\tThe error seems to be here (trainer/callback_config.py line 60)\n <denchmark-code>    def configure_checkpoint_callback(self):\n         \"\"\"\n         Weight path set in this priority:\n         Checkpoint_callback's path (if passed in).\n         User provided weights_saved_path\n         Otherwise use os.getcwd()\n         \"\"\"\n         ckpt_path = self.default_root_dir\n         if self.checkpoint_callback:\n             # init a default one\n             if self.logger is not None:\n                 save_dir = (getattr(self.logger, 'save_dir', None) or\n                             getattr(self.logger, '_save_dir', None) or\n                             self.default_root_dir)\n \n                 # weights_save_path overrides anything\n                 if self.weights_save_path is not None:\n                     save_dir = self.weights_save_path\n \n                 version = self.logger.version if isinstance(\n                     self.logger.version, str) else f'version_{self.logger.version}'\n                 ckpt_path = os.path.join(\n                     save_dir,\n                     self.logger.name,\n                     version,\n                     \"checkpoints\"\n                 )\n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Laksh1997", "commentT": "2020-06-20T14:52:13Z", "comment_text": "\n \t\tOne of the arguments in the last os.path.join is a NoneType. But it only happens on ddp2. Confusing...\n More confusing- exactly 3 (not 4) processes log this error. So one process seems to be fine but not the other 3!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Laksh1997", "commentT": "2020-06-20T14:57:52Z", "comment_text": "\n \t\tI have a suspicion self.default_root_dir is None.\n I am now explicitly passing in a default root dir.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Laksh1997", "commentT": "2020-06-20T15:14:09Z", "comment_text": "\n \t\tThe above didn't work. I now think that it's something to do with the logger, specifically logger.name\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Laksh1997", "commentT": "2020-06-20T19:03:40Z", "comment_text": "\n \t\tHere is my logger code:\n <denchmark-code>def setup_wandb_logging(total_cfg: Dict):\n     \"\"\"\n     Helper function to set-up WandB logging.\n     Parameters\n     ----------\n     total_cfg: A dictionary containing all possible config for a training run! (Model + Data + Training config)\n \n     Returns\n     -------\n     a WandbLogger ready to log in the training run.\n     \"\"\"\n     wandb_logger = WandbLogger(\n         name=total_cfg[\"name\"],\n         version=total_cfg[\"name\"],\n         save_dir=\"checkpoints\",\n         offline=False,\n         anonymous=False,\n         project=total_cfg[\"project\"],\n         tags=None,\n         experiment=None,\n     )\n     wandb_logger.log_hyperparams(total_cfg)\n     return wandb_logger\n </denchmark-code>\n \n which I then pass into trainer as Trainer(logger=wandb_logger, **kwargs)\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "Laksh1997", "commentT": "2020-06-22T17:26:12Z", "comment_text": "\n \t\tResponse from wandb:\n <denchmark-code>Hi Laksh - Try using wandb.init (reinit=True) wandb.join at the end of each run \n </denchmark-code>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "Laksh1997", "commentT": "2020-06-24T02:16:44Z", "comment_text": "\n \t\tlooking at this... so it looks to be specifically wb related?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "Laksh1997", "commentT": "2020-06-24T02:17:02Z", "comment_text": "\n \t\tcan you put up a colab that creates this issue?\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "Laksh1997", "commentT": "2020-06-24T08:48:34Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  Yeah it looks like it. I have tried to contact the wandb team but they've given me limited response so far. Sure, let me put together a basic colab.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "Laksh1997", "commentT": "2020-06-24T16:49:12Z", "comment_text": "\n \t\tHey guys, we can look into this.  <denchmark-link:https://github.com/Laksh1997>@Laksh1997</denchmark-link>\n  can you share a basic colab to reproduce?\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "Laksh1997", "commentT": "2020-06-24T18:22:22Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/vanpelt>@vanpelt</denchmark-link>\n , thanks! I'm working on a colab right now. Will need to go on a multi GPU machine to confirm error.\n I have tried 4 x V100 (p3.8xlarge) and 16 x K80 (p2.16xlarge) and I get the same error on only ddp (but works fine on dp).\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "Laksh1997", "commentT": "2020-06-24T18:48:55Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/vanpelt>@vanpelt</denchmark-link>\n  <denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n   Here's a working notebook.\n <denchmark-link:https://colab.research.google.com/drive/1dTgKDU4S8Oy8g9AvXZLEoE5_aDyzBLb_?usp=sharing>https://colab.research.google.com/drive/1dTgKDU4S8Oy8g9AvXZLEoE5_aDyzBLb_?usp=sharing</denchmark-link>\n \n To run on multi GPU you will need to copy the code (probs only 150 lines) input a script.\n The key things to note is in the Hparams, change your wandb name and project to whatever you want.\n Also, remember to turn on multi GPU (set gpus: 4 and distributed_backend=\"ddp\" in trainer_kwargs in hparams).\n Let me know if any issues\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "Laksh1997", "commentT": "2020-06-25T00:59:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/vanpelt>@vanpelt</denchmark-link>\n  <denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  Update - I just tried this on pytorch 1.6 nightly, and the error persists.\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "Laksh1997", "commentT": "2020-06-27T13:12:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/vanpelt>@vanpelt</denchmark-link>\n  <denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  Have you by any chance had any luck with the issue?\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "Laksh1997", "commentT": "2020-06-27T13:41:19Z", "comment_text": "\n \t\tlooking in a few hours. want to get this fix into 0.8.2\n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "Laksh1997", "commentT": "2020-06-27T14:27:33Z", "comment_text": "\n \t\tThanks so much!\n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "Laksh1997", "commentT": "2020-06-27T17:13:52Z", "comment_text": "\n \t\tok... running your exact code on a single GPU:\n <denchmark-code>\n   | Name  | Type                | Params\n ----------------------------------------------\n 0 | model | EncoderDecoderModel | 245 M \n Epoch 1:   0%|                                                                                                                                                       | 0/828 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n         addcmul_(Number value, Tensor tensor1, Tensor tensor2)\n Consider using one of the following signatures instead:\n         addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:761.)\n   exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n Epoch 1:  16%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                                              | 133/828 [00:50<04:23,  2.64it/s, loss=6.848, v_num=2nn4c31m]^Cwandb: Ctrl-c pressed.\n wandb: Program failed with code 255. Press ctrl-c to abort syncing.\n /opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n   warnings.warn(*args, **kwargs)\n Epoch 1:  16%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                                              | 133/828 [00:50<04:23,  2.63it/s, loss=6.848, v_num=2nn4c31m]\n \n wandb: Waiting for W&B process to finish, PID 29584\n wandb: Run summary:\n wandb:         _step 135\n wandb:    _timestamp 1593277979.7518523\n wandb:      _runtime 72.95207810401917\n wandb:          loss 6.491087913513184\n wandb:   global_step 100\n wandb:         epoch 0\n wandb: Syncing 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n wandb:                                                                                \n wandb: Synced MY-WANDB-NAME: https://app.wandb.ai/stk/MY-WANDB-PROJECT/runs/2nn4c31m\n </denchmark-code>\n \n Trying ddp now\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "Laksh1997", "commentT": "2020-06-27T17:49:00Z", "comment_text": "\n \t\tok fixed!\n <denchmark-code>/opt/conda/lib/python3.7/site-packages/graphql/type/directives.py:55: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n   assert isinstance(locations, collections.Iterable), 'Must provide locations for directive.'\n initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\n name: MY-WANDB-NAME\n project: MY-WANDB-PROJECT\n train_bs: 4\n val_bs: 4\n num_workers: 4\n max_length: 160\n num_datapoints: 100000\n optimizer: Ranger\n optimizer_kwargs:\n   lr: 0.0003\n   alpha: 0.5\n   betas:\n   - 0.95\n   - 0.999\n   eps: 1.0e-05\n   weight_decay: 0.001\n schedulers_kwargs:\n   num_warmup_steps: 1000\n trainer_kwargs:\n   gpus: 2\n   gradient_clip_val: 0.5\n   accumulate_grad_batches: 4\n   min_epochs: 5\n   max_epochs: 100\n   precision: 32\n   distributed_backend: ddp\n \n initializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\n ----------------------------------------------------------------------------------------------------\n distributed_backend=ddp\n All DDP processes registered. Starting ddp with 2 processes\n ----------------------------------------------------------------------------------------------------\n wandb: Tracking run with wandb version 0.9.1\n wandb: Run data is saved locally in wandb/run-20200627_174833-2sdoruup\n wandb: Syncing run MY-WANDB-NAME\n wandb: \u2b50\ufe0f View project at https://app.wandb.ai/stk/MY-WANDB-PROJECT\n wandb: \ud83d\ude80 View run at https://app.wandb.ai/stk/MY-WANDB-PROJECT/runs/2sdoruup\n wandb: Run `wandb off` to turn off syncing.\n \n \n   | Name  | Type                | Params\n ----------------------------------------------\n 0 | model | EncoderDecoderModel | 245 M \n wandb: Tracking run with wandb version 0.9.1\n wandb: Run data is saved locally in wandb/run-20200627_174834-3gkane0x\n wandb: Syncing run MY-WANDB-NAME\n wandb: \u2b50\ufe0f View project at https://app.wandb.ai/stk/MY-WANDB-PROJECT\n wandb: \ud83d\ude80 View run at https://app.wandb.ai/stk/MY-WANDB-PROJECT/runs/3gkane0x\n wandb: Run `wandb off` to turn off syncing.\n \n Epoch 1:   0%|                                                                                                                                                       | 0/414 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n         addcmul_(Number value, Tensor tensor1, Tensor tensor2)\n Consider using one of the following signatures instead:\n         addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:761.)\n   exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n /opt/conda/lib/python3.7/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n         addcmul_(Number value, Tensor tensor1, Tensor tensor2)\n Consider using one of the following signatures instead:\n         addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:761.)\n   exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n Epoch 1:   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                                                          | 29/414 [00:11<02:36,  2.46it/s, loss=9.714, v_num=2sdoruup]\n </denchmark-code>\n \n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "Laksh1997", "commentT": "2020-06-27T17:53:24Z", "comment_text": "\n \t\t2 things:\n \n we had a bug where something was trying to access a property not on rank zero which is now fixed.\n your prepare_data is not correct now.\n \n Prepare data is only ever called on the root GPU... this means assigning something self.something = a will only work on GPU 0. So, when you try to access that it will break on other GPUs.\n We fixed this by introducing\n <denchmark-code>def setup(self, step):\n </denchmark-code>\n \n in setup, you can assign whatever you want.\n Here are all the details on how to prepare data\n <denchmark-link:https://pytorch-lightning.readthedocs.io/en/stable/lightning-module.html#data-preparation>https://pytorch-lightning.readthedocs.io/en/stable/lightning-module.html#data-preparation</denchmark-link>\n \n <denchmark-link:https://user-images.githubusercontent.com/3640001/85928748-4cf88680-b87d-11ea-9820-d78aacedb255.png></denchmark-link>\n \n The fix is very simple in the HF example:\n <denchmark-code># old\n def prepare_data(self):\n     self.x = train_split\n \n # new\n def setup(self, step):\n     self.x = train_split\n </denchmark-code>\n \n And use prepare_data only for downloads\n <denchmark-code>def prepare_data(self):\n     self.download()\n     tokenize()\n     etc()\n \n    self.dont_assing = it_wont_work_on_other_gpus\n </denchmark-code>\n \n FYI <denchmark-link:https://github.com/sshleifer>@sshleifer</denchmark-link>\n \n <denchmark-link:https://github.com/Laksh1997>@Laksh1997</denchmark-link>\n  here's the fixed code\n <denchmark-link:https://gist.github.com/williamFalcon/645019619bdd897d135d232556bcf27d>https://gist.github.com/williamFalcon/645019619bdd897d135d232556bcf27d</denchmark-link>\n \n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "Laksh1997", "commentT": "2020-06-27T20:48:48Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  Thank you so much! Amazing!\n So if the data is particularly light to download, we might as well just put all the code in setup?\n Also what is the step argument for?\n \t\t"}}}, "commit": {"commit_id": "90f641af0d509645ecd679d00f1213f68d4a44ad", "commit_author": "William Falcon", "commitT": "2020-06-27 15:08:22-04:00", "commit_complexity": {"commit_NLOC": "0.625", "commit_CCN": "0.625", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "pl_examples\\models\\lightning_template.py", "file_new_name": "pl_examples\\models\\lightning_template.py", "file_complexity": {"file_NLOC": "127", "file_CCN": "20", "file_NToken": "1090"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "161", "method_info": {"method_name": "test_dataloader", "method_params": "self", "method_startline": "160", "method_endline": "162", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "157", "method_info": {"method_name": "val_dataloader", "method_params": "self", "method_startline": "156", "method_endline": "158", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "153", "method_info": {"method_name": "train_dataloader", "method_params": "self", "method_startline": "152", "method_endline": "154", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\callback_config.py", "file_new_name": "pytorch_lightning\\trainer\\callback_config.py", "file_complexity": {"file_NLOC": "90", "file_CCN": "28", "file_NToken": "560"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "45,56", "deleted_lines": "45,56,57,58,59,60,61", "method_info": {"method_name": "configure_checkpoint_callback", "method_params": "self", "method_startline": "35", "method_endline": "90", "method_complexity": {"method_NLOC": "35", "method_CCN": "15", "method_NToken": "280", "method_nesting_level": "1"}}}}}}}}