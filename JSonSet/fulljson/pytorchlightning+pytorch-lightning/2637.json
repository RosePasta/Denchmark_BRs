{"BR": {"BR_id": "2637", "BR_author": "JiangYize", "BRopenT": "2020-07-18T09:57:26Z", "BRcloseT": "2020-08-11T23:28:39Z", "BR_text": {"BRsummary": "to() got an unexpected keyword argument 'non_blocking' for DGLGraph", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n I use dgl library to make a gnn and batch the DGLGraph.\n No problem during training, but in test, I got a TypeError: to() got an unexpected keyword argument 'non_blocking'\n <class 'dgl.graph.DGLGraph'> .to() function has no keyword argument 'non_blocking'\n <denchmark-h:h4>Code sample</denchmark-h>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n \n OS: Linux\n CUDA: 10.1\n Python Version: 3.7\n PyTorch Version: 1.5.1\n DGL Version: 0.4.3post2\n PyTorch-Lightning Version: 0.8.5\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n <denchmark-code>   File \"../src/main.py\", line 131, in <module>\n     run(params)\n   File \"../src/main.py\", line 92, in run\n     trainer.test(model)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in test\n     results = self.__test_given_model(model, test_dataloaders)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1346, in __test_given_model\n     results = self.fit(model)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1003, in fit\n     results = self.single_gpu_train(model)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py\", line 186, in single_gpu_train\n     results = self.run_pretrain_routine(model)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in run_pretrain_routine\n     results = self.run_evaluation(test_mode=True)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 391, in run_evaluation\n     eval_results = self._evaluate(self.model, dataloaders, max_batches, test_mode)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 293, in _evaluate\n     output = self.evaluation_forward(model, batch, batch_idx, dataloader_idx, test_mode)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 458, in evaluation_forward\n     batch = self.transfer_batch_to_gpu(batch, root_gpu)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py\", line 159, in transfer_batch_to_gpu\n     return self.__transfer_batch_to_device(batch, device)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py\", line 164, in __transfer_batch_to_device\n     return model.transfer_batch_to_device(batch, device)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/core/hooks.py\", line 242, in transfer_batch_to_device\n     return move_data_to_device(batch, device)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py\", line 109, in move_data_to_device\n     return apply_to_collection(batch, dtype=(TransferableDataType, Batch), function=batch_to)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py\", line 40, in apply_to_collection\n     for k, v in data.items()})\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py\", line 40, in <dictcomp>\n     for k, v in data.items()})\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py\", line 35, in apply_to_collection\n     return function(data, *args, **kwargs)\n   File \"/home/jiangyize/miniconda3/envs/galixir/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py\", line 107, in batch_to\n     return data.to(device, non_blocking=True)\n TypeError: to() got an unexpected keyword argument 'non_blocking'\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "JiangYize", "commentT": "2020-07-18T09:58:17Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "JiangYize", "commentT": "2020-07-22T14:16:42Z", "comment_text": "\n \t\tHaving the same problem; it's because  (<denchmark-link:https://docs.dgl.ai/en/0.4.x/generated/dgl.DGLGraph.to.html#dgl.DGLGraph.to>docs</denchmark-link>\n , <denchmark-link:https://docs.dgl.ai/en/0.4.x/_modules/dgl/graph.html#DGLGraph.to>source</denchmark-link>\n ) doesn't take the non_blocking argument. Example:\n dgl.DGLGraph().to('cuda', non_blocking=True)\n Here's my temporary solution:\n class LightningDGLGraph(DGLGraph):\n     def to(self, ctx, *args, **kwargs):\n         return super().to(torch.device(ctx))\n \n g = LightningDGLGraph()\n g.to('cuda', non_blocking=True)\n Works, but probably not ideal.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "JiangYize", "commentT": "2020-07-22T20:23:12Z", "comment_text": "\n \t\t\n Having the same problem; it's because DGLGraph.to (docs, source) doesn't take the non_blocking argument. Example:\n dgl.DGLGraph().to('cuda', non_blocking=True)\n Here's my temporary solution:\n class LightningDGLGraph(DGLGraph):\n     def to(self, ctx, *args, **kwargs):\n         return super().to(torch.device(ctx))\n \n g = LightningDGLGraph()\n g.to('cuda', non_blocking=True)\n Works, but probably not ideal.\n \n Hi, I wonder how this will work if using dgl.batch? the class type they return to you is a DGLGraph.\n Ok, they also have this quick fix here: <denchmark-link:https://github.com/dmlc/dgl/pull/1600>dmlc/dgl#1600</denchmark-link>\n .\n so uninstall the stable version and install the latest version from main solves my problem:\n <denchmark-code>pip install --pre dgl           # For CPU Build\n pip install --pre dgl-cu90      # For CUDA 9.0 Build\n pip install --pre dgl-cu92      # For CUDA 9.2 Build\n pip install --pre dgl-cu100     # For CUDA 10.0 Build\n pip install --pre dgl-cu101     # For CUDA 10.1 Build\n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "JiangYize", "commentT": "2020-07-22T20:54:33Z", "comment_text": "\n \t\tIt seems to work for me for now.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "JiangYize", "commentT": "2020-07-26T16:16:30Z", "comment_text": "\n \t\t\n Ok, they also have this quick fix here: dmlc/dgl#1600.\n so uninstall the stable version and install the latest version from main solves my problem:\n \n Just saw your edit. This seems to work if I don't specify the number of gpus; when I do, same error. E: It's the distributed backend; it never calls graph.to. You can throw a 0/0 in there and it'll never break with distributed_backend ddp.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "JiangYize", "commentT": "2020-08-01T17:12:01Z", "comment_text": "\n \t\tFor a clean solution in Lightning, override <denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.hooks.html?highlight=transfer#pytorch_lightning.core.hooks.ModelHooks.transfer_batch_to_device>this</denchmark-link>\n  model hook and call .to() yourself on the graph object.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "JiangYize", "commentT": "2020-08-01T17:14:14Z", "comment_text": "\n \t\tRegarding ddp, is DGLGraph supposed to work with that (I mean in plain pytorch)? I don't think it can work with scatter and gather.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "JiangYize", "commentT": "2020-08-11T00:05:50Z", "comment_text": "\n \t\t\n For a clean solution in Lightning, override this model hook and call .to() yourself on the graph object.\n \n <denchmark-link:https://github.com/awaelchli>@awaelchli</denchmark-link>\n  Is this supposed to be overridden in the model? It doesn't seem to get called for me in a distributed setting.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "JiangYize", "commentT": "2020-08-11T02:57:55Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jacobdanovitch>@jacobdanovitch</denchmark-link>\n  Yes, this hook only works for single gpu, because in distributed we need to scatter and gather a batch, and if it is a custom object we don't know how to do that. For this, you would have to define your own DistributedDataParallel module and configure it in the <denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.html#pytorch_lightning.core.LightningModule.configure_ddp>configure_ddp </denchmark-link>\n model hook. We should probably update the docs regarding that.\n \t\t"}}}, "commit": {"commit_id": "69d241c82e10cf40e5787fb39bb808687d693b57", "commit_author": "Adrian W\u00e4lchli", "commitT": "2020-08-11 19:28:37-04:00", "commit_complexity": {"commit_NLOC": "0.75", "commit_CCN": "1.0", "commit_Nprams": "0.65"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "126,127", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\core\\hooks.py", "file_new_name": "pytorch_lightning\\core\\hooks.py", "file_complexity": {"file_NLOC": "232", "file_CCN": "28", "file_NToken": "401"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "312,313,314,315,316,317,318", "deleted_lines": "312,313", "method_info": {"method_name": "transfer_batch_to_device", "method_params": "self,Any,device", "method_startline": "276", "method_endline": "324", "method_complexity": {"method_NLOC": "49", "method_CCN": "1", "method_NToken": "25", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "pytorch_lightning\\utilities\\apply_func.py", "file_new_name": "pytorch_lightning\\utilities\\apply_func.py", "file_complexity": {"file_NLOC": "73", "file_CCN": "18", "file_NToken": "388"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "107,108", "deleted_lines": "107", "method_info": {"method_name": "move_data_to_device.batch_to", "method_params": "data", "method_startline": "96", "method_endline": "108", "method_complexity": {"method_NLOC": "9", "method_CCN": "5", "method_NToken": "81", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "107,108", "deleted_lines": "107", "method_info": {"method_name": "move_data_to_device", "method_params": "Any,device", "method_startline": "78", "method_endline": "110", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "33", "method_nesting_level": "0"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tests\\models\\test_gpu.py", "file_new_name": "tests\\models\\test_gpu.py", "file_complexity": {"file_NLOC": "304", "file_CCN": "39", "file_NToken": "2834"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "402,403", "deleted_lines": null, "method_info": {"method_name": "test_non_blocking.to", "method_params": "self,args,kwargs", "method_startline": "402", "method_endline": "403", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "12", "method_nesting_level": "2"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408", "deleted_lines": null, "method_info": {"method_name": "test_non_blocking", "method_params": "", "method_startline": "391", "method_endline": "408", "method_complexity": {"method_NLOC": "12", "method_CCN": "1", "method_NToken": "115", "method_nesting_level": "0"}}}}}}}}