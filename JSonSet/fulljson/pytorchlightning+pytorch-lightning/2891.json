{"BR": {"BR_id": "2891", "BR_author": "manipopopo", "BRopenT": "2020-08-09T04:52:31Z", "BRcloseT": "2020-10-04T12:32:19Z", "BR_text": {"BRsummary": "The total number of batches shows by the progress bar of the sanity check is wrong", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n The total of the sanity check progress bar is set by\n \n \n \n pytorch-lightning/pytorch_lightning/callbacks/progress.py\n \n \n          Line 296\n       in\n       4d0406e\n \n \n \n \n \n \n  self.val_progress_bar.total = convert_inf(trainer.num_sanity_val_steps * len(trainer.val_dataloaders)) \n \n \n \n \n \n The progress bar will always show trainer.num_sanity_val_steps even if  the length of the validation DataLoader is less than trainer.num_sanity_val_steps.\n Maybe the total could be computed by\n from pytorch_lightning.trainer import data_loading\n \n num_full_val_dataloader_batches = [\n     len(dataloader) if data_loading._has_len(dataloader) else float('inf')\n     for dataloader in trainer.val_dataloaders\n ]\n self.val_progress_bar.total = convert_inf(\n     sum(min(num_batches, trainer.num_sanity_val_steps)\n             for num_batches in num_full_val_dataloader_batches))\n We use the private function data_loading._has_len to check if dataloader has __len__, maybe we could make data_loading._has_len public.\n Or we could make num_full_val_dataloader_batches (and num_full_train_dataloader_batches) a member variable of Trainer and update the value in pytorch_lightning.trainer.data_loading.TrainerDataLoadingMixin.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n The progress bar of the sanity check in the following code (num_sanity_val_steps == 999 and len(val_data_loader) == 10) shows\n <denchmark-code>Validation sanity check:   1%|          | 9/999 [00:09<16:31,  1.00s/it]`\n </denchmark-code>\n \n <denchmark-h:h4>Code sample</denchmark-h>\n \n import time\n \n import pytorch_lightning as pl\n from torch.utils import data\n \n \n class Dataset(data.Dataset):\n \n   def __init__(self, length):\n     self._elements = list(range(length))\n \n   def __getitem__(self, item):\n     return self._elements[item]\n \n   def __len__(self):\n     return len(self._elements)\n \n \n class Model(pl.LightningModule):\n \n   def forward(self, *args, **kwargs):\n     pass\n \n   def training_step(self, *args, **kwargs):\n     pass\n \n   def train_dataloader(self):\n     pass\n \n   def configure_optimizers(self):\n     pass\n \n   def validation_step(self, *args, **kwargs):\n     time.sleep(1)\n     return pl.EvalResult()\n \n \n if __name__ == '__main__':\n   model = Model()\n \n   val_dataset_length = 10\n   val_dataset = Dataset(val_dataset_length)\n   val_data_loader = data.DataLoader(val_dataset)\n \n   trainer = pl.Trainer(num_sanity_val_steps=999, limit_val_batches=999,\n                        max_epochs=0)\n   trainer.fit(model, val_dataloaders=val_data_loader)\n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n The program above should be\n <denchmark-code>Validation sanity check: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:10<00:00,  1.00s/it]\n </denchmark-code>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n \n CUDA:\n \n GPU:\n available:\n version:\n \n \n Packages:\n \n numpy:             1.18.5\n pyTorch_debug:     False\n pyTorch_version:   1.6.0+cpu\n pytorch-lightning: 0.9.0rc11\n tensorboard:       1.15.0\n tqdm:              4.48.2\n \n \n System:\n \n OS:                Windows\n architecture:\n \n 64bit\n WindowsPE\n \n \n processor:\n python:            3.7.3\n version:           10.0.18362\n \n \n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "manipopopo", "commentT": "2020-08-09T07:33:03Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/manipopopo>@manipopopo</denchmark-link>\n  I guess the first solution gets things done without changing anything else. Mind submitting a PR?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "manipopopo", "commentT": "2020-08-09T09:30:11Z", "comment_text": "\n \t\tI think once <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2882>#2882</denchmark-link>\n  gets resolved this issue will be resolved automatically.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "manipopopo", "commentT": "2020-08-09T10:58:00Z", "comment_text": "\n \t\tIt seems that resolve <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2882>#2882</denchmark-link>\n  will make the sanity check of  run exactly  steps (or  ) if the validation  has at least 5 batches.\n Resolve this issue will make the total of the progress bar for the sanity check be the size of the validation DataLoader if it is less than num_sanity_val_steps (except num_sanity_val_steps == -1).\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "manipopopo", "commentT": "2020-08-09T12:02:11Z", "comment_text": "\n \t\tthen I would suggest fixing <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2882>#2882</denchmark-link>\n  first in which we can make self.num_sanity_val_steps to be a list of correct num_steps for each val_dataloader and then we can just do  here to assign it to progress_bar.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "manipopopo", "commentT": "2020-08-09T13:53:40Z", "comment_text": "\n \t\tIt seems that we have several ways to tackle the problem.\n \n \n Make self.num_sanity_val_steps a list of correct numbers of steps as @rohitgr7 suggests. ProgressBar can update self.val_progress_bar.total using self.num_sanity_val_steps. Accessing the member num_sanity_val_steps may get values different from the one passed into Trainer.__init__.\n \n \n Add a new member to save a list of correct numbers of steps or save a list of the sizes of validation DataLoaders. ProgressBar can update self.val_progress_bar.total using the new member.  Users of Trainer can still get num_sanity_val_steps passed into Trainer.__init__ by accessing the member num_sanity_val_steps. (Supposing #2882 is resolved and the member num_sanity_val_steps is independent of limit_val_batches )\n \n \n Compute the correct number of steps in the ProgressBar with the help of pytorch_lightning.trainer.data_loading._has_len\n \n \n It seems that the values of the public member Trainer.num_sanity_val_steps in stable 0.8.5 and master are different.\n \n \n In 0.8.5, Trainer.num_sanity_val_steps is num_sanity_val_steps passed in __init__.\n \n \n \n \n \n pytorch-lightning/pytorch_lightning/trainer/trainer.py\n \n \n          Line 491\n       in\n       1e68968\n \n \n \n \n \n \n  self.num_sanity_val_steps = float(\"inf\") if num_sanity_val_steps == -1 else num_sanity_val_steps \n \n \n \n \n \n sets Trainer.num_sanity_val_steps to float('inf') when the one passed in __init__ is -1.\n \n \n \n \n \n pytorch-lightning/pytorch_lightning/trainer/trainer.py\n \n \n          Line 461\n       in\n       a59e140\n \n \n \n \n \n \n  self.num_sanity_val_steps = min(num_sanity_val_steps, limit_val_batches) \n \n \n \n \n \n decides Trainer.num_sanity_val_steps according to limit_val_batches  and num_sanity_val_steps passed in __init__.\n \n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "manipopopo", "commentT": "2020-08-22T04:07:27Z", "comment_text": "\n \t\tFixed by <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2917>#2917</denchmark-link>\n .\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "manipopopo", "commentT": "2020-08-27T21:53:34Z", "comment_text": "\n \t\tIt's broken again due to refactors, opening this so that we don't forget to fix this. If required, let's fix this after a week once refactors are done.\n \n \n \n pytorch-lightning/pytorch_lightning/trainer/trainer.py\n \n \n          Line 1256\n       in\n       85cd558\n \n \n \n \n \n \n  _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches) \n \n \n \n \n \n \n \n \n pytorch-lightning/pytorch_lightning/trainer/evaluation_loop.py\n \n \n          Line 246\n       in\n       85cd558\n \n \n \n \n \n \n  self.evaluation_loop.on_evaluation_start() \n \n \n \n \n \n \n \n \n pytorch-lightning/pytorch_lightning/trainer/evaluate_loop.py\n \n \n         Lines 53 to 57\n       in\n       85cd558\n \n \n \n \n \n \n  def on_evaluation_start(self, *args, **kwargs): \n \n \n \n  if self.testing: \n \n \n \n  self.trainer.call_hook('on_test_start', *args, **kwargs) \n \n \n \n  else: \n \n \n \n  self.trainer.call_hook('on_validation_start', *args, **kwargs) \n \n \n \n \n \n \n \n \n pytorch-lightning/pytorch_lightning/callbacks/progress.py\n \n \n         Lines 341 to 344\n       in\n       85cd558\n \n \n \n \n \n \n  def on_validation_start(self, trainer, pl_module): \n \n \n \n  super().on_validation_start(trainer, pl_module) \n \n \n \n  self.val_progress_bar = self.init_validation_tqdm() \n \n \n \n  self.val_progress_bar.total = convert_inf(self.total_val_batches) \n \n \n \n \n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "manipopopo", "commentT": "2020-09-30T18:26:14Z", "comment_text": "\n \t\tthis issue is annoying. will fix this.\n \t\t"}}}, "commit": {"commit_id": "a628d181ee662a77b708a12c51477f912ce02f63", "commit_author": "Rohit Gupta", "commitT": "2020-10-04 08:32:18-04:00", "commit_complexity": {"commit_NLOC": "0.17391304347826086", "commit_CCN": "1.0", "commit_Nprams": "0.043478260869565216"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "96,98,99,100", "deleted_lines": "96,98"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\callbacks\\progress.py", "file_new_name": "pytorch_lightning\\callbacks\\progress.py", "file_complexity": {"file_NLOC": "301", "file_CCN": "57", "file_NToken": "1363"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "343,344,345", "deleted_lines": "343,344", "method_info": {"method_name": "on_validation_start", "method_params": "self,trainer,pl_module", "method_startline": "341", "method_endline": "345", "method_complexity": {"method_NLOC": "5", "method_CCN": "2", "method_NToken": "46", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\callbacks\\test_progress_bar.py", "file_new_name": "tests\\callbacks\\test_progress_bar.py", "file_complexity": {"file_NLOC": "159", "file_CCN": "25", "file_NToken": "1159"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "207,208,209", "deleted_lines": null, "method_info": {"method_name": "test_num_sanity_val_steps_progress_bar.__init__", "method_params": "self", "method_startline": "207", "method_endline": "209", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "17", "method_nesting_level": "2"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "211,212", "deleted_lines": null, "method_info": {"method_name": "test_num_sanity_val_steps_progress_bar.on_validation_epoch_end", "method_params": "self,trainer,pl_module", "method_startline": "211", "method_endline": "212", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "20", "method_nesting_level": "2"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229", "deleted_lines": null, "method_info": {"method_name": "test_num_sanity_val_steps_progress_bar", "method_params": "tmpdir,limit_val_batches,expected", "method_startline": "202", "method_endline": "229", "method_complexity": {"method_NLOC": "19", "method_CCN": "1", "method_NToken": "87", "method_nesting_level": "0"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tests\\trainer\\test_trainer.py", "file_new_name": "tests\\trainer\\test_trainer.py", "file_complexity": {"file_NLOC": "817", "file_CCN": "98", "file_NToken": "6538"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "960", "method_info": {"method_name": "test_num_sanity_val_steps", "method_params": "tmpdir,limit_val_batches", "method_startline": "946", "method_endline": "960", "method_complexity": {"method_NLOC": "13", "method_CCN": "1", "method_NToken": "64", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "984", "method_info": {"method_name": "test_num_sanity_val_steps_neg_one", "method_params": "tmpdir,limit_val_batches", "method_startline": "969", "method_endline": "984", "method_complexity": {"method_NLOC": "12", "method_CCN": "1", "method_NToken": "65", "method_nesting_level": "0"}}}}}}}}