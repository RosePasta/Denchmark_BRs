{"BR": {"BR_id": "189", "BR_author": "ExpectationMax", "BRopenT": "2019-09-03T15:48:23Z", "BRcloseT": "2019-09-05T02:31:13Z", "BR_text": {"BRsummary": "Logging of GPU memory utilization can significantly slow down training", "BRdescription": "\n When training using GPUs pytorch_lightning automatically logs the GPU memory utilization during training. This is a useful feature, but can severely impact performance dependent on the speed of the nvidia-smi call.\n On our particular cluster (University-scale hpc cluster based on IBM LSF), this leads to a performance decrease of almost 10 fold when training on GPU vs. CPU.\n Describe the bug\n Logging of GPU memory can have a severe impact on training performance.\n \n Remove gpu memory logging by commenting out the lines 937 to 939 in pytorch_lightning/models/trainer.py\n <denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/models/trainer.py#L937-L939>see here</denchmark-link>\n \n Expected behavior\n Logging of GPU memory utilization should not impede performance (by running the nvidia-smi call in the background) or it should at least be possible to deactivate it in case performance issues arise.\n Desktop (please complete the following information):\n \n OS: Ubuntu Linux 16.04, NVIDIA Geforce GTX 1080\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ExpectationMax", "commentT": "2019-09-05T02:31:12Z", "comment_text": "\n \t\tmerged\n \t\t"}}}, "commit": {"commit_id": "dac41030d48acbfecdf7c083b8e7b00f3fd9be06", "commit_author": "Max Horn", "commitT": "2019-09-04 10:43:46-04:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "1.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "docs\\Trainer\\Logging.md", "file_new_name": "docs\\Trainer\\Logging.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "17,18,19,20,21,22,23,24", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "pytorch_lightning\\models\\trainer.py", "file_new_name": "pytorch_lightning\\models\\trainer.py", "file_complexity": {"file_NLOC": "730", "file_CCN": "196", "file_NToken": "4660"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "66", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,experiment,early_stop_callback,checkpoint_callback,gradient_clip,cluster,process_position,current_gpu_name,nb_gpu_nodes,gpus,log_gpu_memory,show_progress_bar,overfit_pct,track_grad_norm,check_val_every_n_epoch,fast_dev_run,accumulate_grad_batches,max_nb_epochs,min_nb_epochs,train_percent_check,val_percent_check,test_percent_check,val_check_interval,log_save_interval,add_log_row_interval,distributed_backend,use_amp,print_nan_grads,print_weights_summary,amp_level,nb_sanity_val_steps", "method_startline": "56", "method_endline": "86", "method_complexity": {"method_NLOC": "31", "method_CCN": "1", "method_NToken": "136", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "942", "deleted_lines": "937", "method_info": {"method_name": "run_tng_epoch", "method_params": "self", "method_startline": "892", "method_endline": "969", "method_complexity": {"method_NLOC": "45", "method_CCN": "22", "method_NToken": "341", "method_nesting_level": "1"}}}}}}}}