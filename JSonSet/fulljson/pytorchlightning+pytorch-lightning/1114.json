{"BR": {"BR_id": "1114", "BR_author": "alexeykarnachev", "BRopenT": "2020-03-10T22:15:58Z", "BRcloseT": "2020-03-16T18:35:11Z", "BR_text": {"BRsummary": "ReduceLROnPlateau scheduler type check", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n Incorrect type check for scheduler of class ReduceLROnPlateau.\n \n \n \n pytorch-lightning/pytorch_lightning/trainer/trainer.py\n \n \n          Line 713\n       in\n       bc01b9a\n \n \n \n \n \n \n  isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau) \n \n \n \n \n \n I believe, this check:\n isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau)\n must look like this:\n isinstance(scheduler['scheduler'], optim.lr_scheduler.ReduceLROnPlateau)\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n \n Create a scheduler of type optim.lr_scheduler.ReduceLROnPlateau in the configure_optimizers method of a LightningModule class.\n Return an optimizer and scheduler from this method. Place them in lists: return [optimizer], [scheduler].\n Execute the trainer.fit(module).\n Put a break-point here: \n \n \n pytorch-lightning/pytorch_lightning/trainer/trainer.py\n \n \n          Line 712\n       in\n       bc01b9a\n \n \n \n \n \n \n  scheduler['reduce_on_plateau'] = \\ \n \n \n \n \n \n Make sure that the condition is never True.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "alexeykarnachev", "commentT": "2020-03-10T22:16:40Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "alexeykarnachev", "commentT": "2020-03-11T23:17:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/SkafteNicki>@SkafteNicki</denchmark-link>\n  could you pls check it? as it comes from your PR :]\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "alexeykarnachev", "commentT": "2020-03-12T11:23:00Z", "comment_text": "\n \t\tI agree with <denchmark-link:https://github.com/alexeykarnachev>@alexeykarnachev</denchmark-link>\n  that this is indeed a bug, that I introduced with the recent rework of the learning rate schedulers. I can send a new PR with the bug fix and include a test for  schedulers\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "alexeykarnachev", "commentT": "2020-03-12T11:38:41Z", "comment_text": "\n \t\tThx guys!\n <denchmark-link:https://github.com/alexeykarnachev>@alexeykarnachev</denchmark-link>\n  minds send fix PR?\n \t\t"}}}, "commit": {"commit_id": "384e124490f7a629dc677fc5b658b69afade0a04", "commit_author": "Nicki Skafte", "commitT": "2020-03-16 14:35:10-04:00", "commit_complexity": {"commit_NLOC": "0.23333333333333334", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "31", "deleted_lines": "31"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\trainer.py", "file_new_name": "pytorch_lightning\\trainer\\trainer.py", "file_complexity": {"file_NLOC": "660", "file_CCN": "58", "file_NToken": "2944"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "710,711", "deleted_lines": "710,711", "method_info": {"method_name": "configure_schedulers", "method_params": "self,list", "method_startline": "698", "method_endline": "724", "method_complexity": {"method_NLOC": "23", "method_CCN": "6", "method_NToken": "154", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\models\\__init__.py", "file_new_name": "tests\\models\\__init__.py", "file_complexity": {"file_NLOC": "44", "file_CCN": "3", "file_NToken": "149"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "27,28", "deleted_lines": "27"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\models\\mixins.py", "file_new_name": "tests\\models\\mixins.py", "file_complexity": {"file_NLOC": "450", "file_CCN": "97", "file_NToken": "3083"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "682,683,684,685,686,687,688", "deleted_lines": null, "method_info": {"method_name": "configure_optimizers", "method_params": "self", "method_startline": "682", "method_endline": "688", "method_complexity": {"method_NLOC": "7", "method_CCN": "2", "method_NToken": "74", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\trainer\\test_optimizers.py", "file_new_name": "tests\\trainer\\test_optimizers.py", "file_complexity": {"file_NLOC": "127", "file_CCN": "15", "file_NToken": "737"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181", "deleted_lines": null, "method_info": {"method_name": "test_reduce_lr_on_plateau_scheduling", "method_params": "tmpdir", "method_startline": "152", "method_endline": "181", "method_complexity": {"method_NLOC": "23", "method_CCN": "1", "method_NToken": "119", "method_nesting_level": "0"}}}}}}}}