{"BR": {"BR_id": "1683", "BR_author": "hirune924", "BRopenT": "2020-05-01T03:39:30Z", "BRcloseT": "2020-05-10T17:19:19Z", "BR_text": {"BRsummary": "NeptuneLogger doesn't work with distributed_backend='ddp'", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n When using NeptuneLogger with distributed_backend='ddp' and running it on a single node with two GPUs, I find an error like this.\n <denchmark-code>Traceback (most recent call last):\n   File \"pl.py\", line 146, in <module>\n     main()\n   File \"pl.py\", line 103, in main\n     trainer.fit(model)\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 751, in fit\n     mp.spawn(self.ddp_train, nprocs=self.num_processes, args=(model,))\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 200, in spawn\n     return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 158, in start_processes\n     while not context.join():\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 119, in join\n     raise Exception(msg)\n Exception:\n \n -- Process 1 terminated with the following error:\n Traceback (most recent call last):\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\n     fn(i, *args)\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 370, in ddp_train\n     self.run_pretrain_routine(model)\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 871, in run_pretrain_routine\n     self.configure_checkpoint_callback()\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/pytorch_lightning/trainer/callback_config.py\", line 54, in configure_checkpoint_callback\n     self.logger.name,\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/pytorch_lightning/loggers/neptune.py\", line 267, in name\n     return self.experiment.name\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/pytorch_lightning/loggers/neptune.py\", line 230, in experiment\n     **self._kwargs)\n   File \"/home/hirune/anaconda3/envs/PANDA/lib/python3.7/site-packages/neptune/__init__.py\", line 222, in create_experiment\n     raise Uninitialized()\n neptune.exceptions.Uninitialized: You must initialize neptune-client first. For more information, please visit: https://github.com/neptune-ai/neptune-client#initialize-neptune\n </denchmark-code>\n \n And I found a similar error with CommetLogger\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n Run the following code on a machine with two GPUs.\n This code is a slightly modified version of what was on this page.\n <denchmark-link:https://docs.neptune.ai/integrations/pytorch_lightning.html>https://docs.neptune.ai/integrations/pytorch_lightning.html</denchmark-link>\n \n <denchmark-h:h4>Code sample</denchmark-h>\n \n <denchmark-code>import os\n \n import torch\n from torch.nn import functional as F\n from torch.utils.data import DataLoader\n from torchvision.datasets import MNIST\n from torchvision import transforms\n \n import pytorch_lightning as pl\n \n MAX_EPOCHS=20\n LR=0.01\n BATCHSIZE=32\n CHECKPOINTS_DIR = 'my_models/checkpoints/7'\n \n class CoolSystem(pl.LightningModule):\n \n     def __init__(self):\n         super(CoolSystem, self).__init__()\n         # not the best model...\n         self.l1 = torch.nn.Linear(28 * 28, 10)\n \n     def forward(self, x):\n         return torch.relu(self.l1(x.view(x.size(0), -1)))\n \n     def training_step(self, batch, batch_idx):\n         # REQUIRED\n         x, y = batch\n         y_hat = self.forward(x)\n         loss = F.cross_entropy(y_hat, y)\n         tensorboard_logs = {'train_loss': loss}\n         return {'loss': loss, 'log': tensorboard_logs}\n \n     def validation_step(self, batch, batch_idx):\n         # OPTIONAL\n         x, y = batch\n         y_hat = self.forward(x)\n         return {'val_loss': F.cross_entropy(y_hat, y)}\n \n     def validation_end(self, outputs):\n         # OPTIONAL\n         avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n         tensorboard_logs = {'val_loss': avg_loss}\n         return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n \n     def test_step(self, batch, batch_idx):\n         # OPTIONAL\n         x, y = batch\n         y_hat = self.forward(x)\n         return {'test_loss': F.cross_entropy(y_hat, y)}\n \n     def test_end(self, outputs):\n         # OPTIONAL\n         avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n         tensorboard_logs = {'test_loss': avg_loss}\n         return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n \n     def configure_optimizers(self):\n         # REQUIRED\n         # can return multiple optimizers and learning_rate schedulers\n         # (LBFGS it is automatically supported, no need for closure function)\n         return torch.optim.Adam(self.parameters(), lr=LR)\n \n     @pl.data_loader\n     def train_dataloader(self):\n         # REQUIRED\n         return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=BATCHSIZE)\n \n     @pl.data_loader\n     def val_dataloader(self):\n         # OPTIONAL\n         return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=BATCHSIZE)\n \n     @pl.data_loader\n     def test_dataloader(self):\n         # OPTIONAL\n         return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=BATCHSIZE)\n \n \n from pytorch_lightning.loggers.neptune import NeptuneLogger\n def main():\n     neptune_logger = NeptuneLogger(\n         api_key=\"ANONYMOUS\",\n         project_name=\"shared/pytorch-lightning-integration\",\n         close_after_fit=False,\n         experiment_name=\"default\",  # Optional,\n         params={\"max_epochs\": MAX_EPOCHS,\n                 \"batch_size\": BATCHSIZE,\n                 \"lr\": LR}, # Optional,\n         tags=[\"pytorch-lightning\", \"mlp\"]  # Optional,\n     )\n     model_checkpoint = pl.callbacks.ModelCheckpoint(filepath=CHECKPOINTS_DIR)\n     \n     from pytorch_lightning import Trainer\n     \n     model = CoolSystem()\n     trainer = Trainer(max_epochs=MAX_EPOCHS,\n                       logger=neptune_logger,\n                       checkpoint_callback=model_checkpoint,\n                       gpus=-1,\n                       distributed_backend='ddp',\n                       )\n     trainer.fit(model)\n     trainer.test(model)\n     \n     # Get predictions on external test\n     import numpy as np\n     \n     model.freeze()\n     test_loader = DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=256)\n     \n     y_true, y_pred = [],[]\n     for i, (x, y) in enumerate(test_loader):\n         y_hat = model.forward(x).argmax(axis=1).cpu().detach().numpy()\n         y = y.cpu().detach().numpy()\n     \n         y_true.append(y)\n         y_pred.append(y_hat)\n     \n         if i == len(test_loader):\n             break\n     y_true = np.hstack(y_true)\n     y_pred = np.hstack(y_pred)\n     \n     # Log additional metrics\n     from sklearn.metrics import accuracy_score\n     \n     accuracy = accuracy_score(y_true, y_pred)\n     neptune_logger.experiment.log_metric('test_accuracy', accuracy)\n     \n     # Log charts\n     from scikitplot.metrics import plot_confusion_matrix\n     import matplotlib.pyplot as plt\n     \n     fig, ax = plt.subplots(figsize=(16, 12))\n     plot_confusion_matrix(y_true, y_pred, ax=ax)\n     neptune_logger.experiment.log_image('confusion_matrix', fig)\n     \n     # Save checkpoints folder\n     neptune_logger.experiment.log_artifact(CHECKPOINTS_DIR)\n     \n     # You can stop the experiment\n     neptune_logger.experiment.stop()\n \n if __name__ == \"__main__\":\n         main()\n \n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n \n CUDA:\n - GPU:\n - GeForce GTX TITAN X\n - GeForce GTX TITAN X\n - available:         True\n - version:           10.1\n Packages:\n - numpy:             1.18.1\n - pyTorch_debug:     False\n - pyTorch_version:   1.5.0\n - pytorch-lightning: 0.7.5\n - tensorboard:       2.2.1\n - tqdm:              4.42.1\n System:\n - OS:                Linux\n - architecture:\n - 64bit\n -\n - processor:         x86_64\n - python:            3.7.6\n - version:           #86-Ubuntu SMP Fri Jan 17 17:24:28 UTC 2020\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "hirune924", "commentT": "2020-05-01T03:40:09Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "hirune924", "commentT": "2020-05-01T07:38:15Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jakubczakon>@jakubczakon</denchmark-link>\n  pls ^^\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "hirune924", "commentT": "2020-05-01T07:54:03Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/hirune924>@hirune924</denchmark-link>\n  and thanks for raising it!\n I've already notified the dev team and <denchmark-link:https://github.com/pitercl>@pitercl</denchmark-link>\n  will get back to you once we have a solution.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "hirune924", "commentT": "2020-05-03T22:14:44Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jakubczakon>@jakubczakon</denchmark-link>\n  I assume that this is also Neptune issue only, not related to PL, right?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "hirune924", "commentT": "2020-05-04T06:02:40Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/hirune924>@hirune924</denchmark-link>\n  mentioned:\n \n And I found a similar error with CommetLogger\n \n So I think it may be a more general problem <denchmark-link:https://github.com/Borda>@Borda</denchmark-link>\n ,\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "hirune924", "commentT": "2020-05-04T16:15:43Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/hirune924>@hirune924</denchmark-link>\n , <denchmark-link:https://github.com/Borda>@Borda</denchmark-link>\n , just a quick update on this: from my initial tests, our Neptune logger and multiprocessing don't mix well. Tomorrow I'll dig a bit deeper into that and see if/how it can be remedied.\n <denchmark-link:https://github.com/Borda>@Borda</denchmark-link>\n , I don't know yet if this is more on Neptune side or PL side.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "hirune924", "commentT": "2020-05-06T13:15:46Z", "comment_text": "\n \t\tAnother quick update: I have a solution to this and will create a PR with a fix today or tomorrow.\n \t\t"}}}, "commit": {"commit_id": "0cb676746568b6ca3c1ef9d9d2879b913f183179", "commit_author": "Piotr \u0141usakowski", "commitT": "2020-05-10 13:19:18-04:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "pytorch_lightning\\loggers\\neptune.py", "file_new_name": "pytorch_lightning\\loggers\\neptune.py", "file_complexity": {"file_NLOC": "348", "file_CCN": "24", "file_NToken": "963"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "200,201,203,204,205", "deleted_lines": "198,199,200,201,202,203", "method_info": {"method_name": "__getstate__", "method_params": "self", "method_startline": "198", "method_endline": "206", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "33", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "258", "deleted_lines": null, "method_info": {"method_name": "name", "method_params": "self", "method_startline": "257", "method_endline": "261", "method_complexity": {"method_NLOC": "5", "method_CCN": "2", "method_NToken": "22", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380", "deleted_lines": null, "method_info": {"method_name": "_create_or_get_experiment", "method_params": "self", "method_startline": "361", "method_endline": "380", "method_complexity": {"method_NLOC": "18", "method_CCN": "3", "method_NToken": "129", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "265", "deleted_lines": "264", "method_info": {"method_name": "version", "method_params": "self", "method_startline": "264", "method_endline": "268", "method_complexity": {"method_NLOC": "5", "method_CCN": "2", "method_NToken": "22", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "220,221,223,224", "deleted_lines": "224,225", "method_info": {"method_name": "experiment", "method_params": "self", "method_startline": "209", "method_endline": "225", "method_complexity": {"method_NLOC": "13", "method_CCN": "2", "method_NToken": "29", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\loggers\\test_neptune.py", "file_new_name": "tests\\loggers\\test_neptune.py", "file_complexity": {"file_NLOC": "65", "file_CCN": "5", "file_NToken": "551"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "34,35,36,37,38,40,41,44,45,48,49,52,53,56,57,60,61,64,67,70,71,74", "deleted_lines": "34,37,38,41,42,45,46,49,52,55,56,59", "method_info": {"method_name": "test_neptune_additional_methods", "method_params": "neptune", "method_startline": "34", "method_endline": "74", "method_complexity": {"method_NLOC": "30", "method_CCN": "1", "method_NToken": "297", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "26,29,30", "deleted_lines": "26,29,30", "method_info": {"method_name": "test_neptune_offline", "method_params": "neptune", "method_startline": "26", "method_endline": "30", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "45", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "13,15,16,17,18,19,20,21,22", "deleted_lines": "13,14,16,17,21", "method_info": {"method_name": "test_neptune_online", "method_params": "neptune", "method_startline": "12", "method_endline": "22", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "56", "method_nesting_level": "0"}}}}}}}}