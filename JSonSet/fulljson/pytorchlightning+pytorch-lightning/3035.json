{"BR": {"BR_id": "3035", "BR_author": "junwen-austin", "BRopenT": "2020-08-18T15:31:56Z", "BRcloseT": "2020-09-15T12:36:15Z", "BR_text": {"BRsummary": "Incorrect Precision/Recall/F1 score compared to sklearn", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n \n Copy the code\n Run the code from top to bottom\n Compare print results\n See Difference between sklearn and Lightning\n \n <denchmark-h:h4>Code</denchmark-h>\n \n <denchmark-code>import torch\n import numpy as np\n import pytorch_lightning as pl\n from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n \n print(pl.__version__)\n \n \n #### Generate binary data\n pl.seed_everything(2020)\n n = 10000  # number of samples\n y = np.random.choice([0, 1], n)\n y_pred = np.random.choice([0, 1], n, p=[0.1, 0.9])\n y_tensor = torch.tensor(y)\n y_pred_tensor = torch.tensor(y_pred)\n \n \n # Accuracy appears alright\n print('accuracy from sklearn', accuracy_score(y, y_pred))\n print('accuracy from lightning functional', pl.metrics.functional.accuracy(y_pred_tensor, y_tensor, num_classes=2))\n print('accuracy from lightning tensor', pl.metrics.Accuracy(num_classes=2)(y_pred_tensor, y_tensor))\n \n ## results\n ## accuracy from sklearn 0.4986\n ## accuracy from lightning functional tensor(0.4986)\n ## accuracy from lightning tensor tensor(0.4986)\n \n # Precision appears to be off, compared to sklearn\n print('precision from sklearn', precision_score(y, y_pred))\n print('precision from lightning functional', pl.metrics.functional.precision(y_pred_tensor, y_tensor, num_classes=2))\n print('precision from lightning tensor', pl.metrics.Precision(num_classes=2)(y_pred_tensor, y_tensor))\n \n ## precision from sklearn 0.5005544466622311\n ## precision from lightning functional tensor(0.4906)\n ## precision from lightning tensor tensor(0.4906)\n \n #Recall appears to be off, compared to sklearn\n print('recall from sklearn', recall_score(y, y_pred))\n print('recall from lightning functional', pl.metrics.functional.recall(y_pred_tensor, y_tensor, num_classes=2))\n print('recall from lightning tensor', pl.metrics.Recall(num_classes=2)(y_pred_tensor, y_tensor))\n \n ## recall from sklearn 0.8984872611464968\n ## recall from lightning functional tensor(0.4967)\n ## recall from lightning tensor tensor(0.4967)\n \n #F1 appears to be off, compared to sklearn\n print('F1 from sklearn', f1_score(y, y_pred))\n print('F1 from lightning functional', pl.metrics.functional.f1_score(y_pred_tensor, y_tensor, num_classes=2))\n print('F1 from lightning tensor', pl.metrics.F1(num_classes=2)(y_pred_tensor, y_tensor))\n \n ## F1 from sklearn 0.6429283577837915\n ## F1 from lightning functional tensor(0.4007)\n ## F1 from lightning tensor tensor(0.4007)\n \n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n Precision/Recall/F1 results are expected to be consistent with those from sklearn.\n <denchmark-h:h3>Environment</denchmark-h>\n \n Please copy and paste the output from our\n <denchmark-link:https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py>environment collection script</denchmark-link>\n \n (or fill out the checklist below manually).\n You can get the script and run it with:\n <denchmark-code>wget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py\n # For security purposes, please check the contents of collect_env_details.py before running it.\n python collect_env_details.py\n </denchmark-code>\n \n \n PyTorch Version : 1.5.1\n OS (e.g., Linux):  MacOS\n How you installed PyTorch (conda, pip, source):  Pip\n Build command you used (if compiling from source):\n Python version:  3.7\n CUDA/cuDNN version:   None\n GPU models and configuration:    @@None\n Any other relevant information:\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "junwen-austin", "commentT": "2020-08-18T15:41:46Z", "comment_text": "\n \t\tBy the way, Precision/Recall/F1 scores are also off in Pytorch-lightning 0.8.5\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "junwen-austin", "commentT": "2020-08-18T16:21:39Z", "comment_text": "\n \t\ti thought we tested against sklearn?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "junwen-austin", "commentT": "2020-08-18T16:26:33Z", "comment_text": "\n \t\twe do test it here:\n \n \n \n pytorch-lightning/tests/metrics/functional/test_classification.py\n \n \n         Lines 38 to 59\n       in\n       321fb8b\n \n \n \n \n \n \n  @pytest.mark.parametrize(['sklearn_metric', 'torch_metric'], [ \n \n \n \n   pytest.param(sk_accuracy, accuracy, id='accuracy'), \n \n \n \n   pytest.param(partial(sk_precision, average='macro'), precision, id='precision'), \n \n \n \n   pytest.param(partial(sk_recall, average='macro'), recall, id='recall'), \n \n \n \n   pytest.param(partial(sk_f1_score, average='macro'), f1_score, id='f1_score'), \n \n \n \n   pytest.param(partial(sk_fbeta_score, average='macro', beta=2), partial(fbeta_score, beta=2), id='fbeta_score'), \n \n \n \n   pytest.param(sk_confusion_matrix, confusion_matrix, id='confusion_matrix') \n \n \n \n  ]) \n \n \n \n  def test_against_sklearn(sklearn_metric, torch_metric): \n \n \n \n  \"\"\"Compare PL metrics to sklearn version.\"\"\" \n \n \n \n  device = 'cuda' if torch.cuda.is_available() else 'cpu' \n \n \n \n  \n \n \n \n  # iterate over different label counts in predictions and target \n \n \n \n  for n_cls_pred, n_cls_target in [(10, 10), (5, 10), (10, 5)]: \n \n \n \n  pred = torch.randint(n_cls_pred, (300,), device=device) \n \n \n \n  target = torch.randint(n_cls_target, (300,), device=device) \n \n \n \n  \n \n \n \n  sk_score = sklearn_metric(target.cpu().detach().numpy(), \n \n \n \n  pred.cpu().detach().numpy()) \n \n \n \n  sk_score = torch.tensor(sk_score, dtype=torch.float, device=device) \n \n \n \n  pl_score = torch_metric(pred, target) \n \n \n \n  assert torch.allclose(sk_score, pl_score) \n \n \n \n \n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "junwen-austin", "commentT": "2020-08-18T16:27:05Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/justusschock>@justusschock</denchmark-link>\n  <denchmark-link:https://github.com/SkafteNicki>@SkafteNicki</denchmark-link>\n  mind have look, pls \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "junwen-austin", "commentT": "2020-08-18T16:31:49Z", "comment_text": "\n \t\tIts because we calculate the macro average instead of the micro average which is the default in sklearn\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "junwen-austin", "commentT": "2020-08-18T16:34:08Z", "comment_text": "\n \t\tAt some point we should probably support the different averaging methods that sklearn also have as one averaging method may be more meaningful in some cases (like very unbalanced datasets)\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "junwen-austin", "commentT": "2020-08-18T16:59:05Z", "comment_text": "\n \t\tI figured out the reason why this is a discrepancy:\n for binary classification, to recover sklearn, precision/recall/F1 should be done something like below:\n <denchmark-code>pl.metrics.functional.precision(y_pred_tensor, y_tensor, num_classes=2, reduction='none')[1])\n \n </denchmark-code>\n \n where reduction by default is elementwise_mean instead of none, the [1] returns the score for class 1\n We can close the issue for now, but it would be really good to update the document to reflect these subtle differences.\n For multi-classes, I assume there will be more nuances between Lightning and Sklearn, given different ways of doing average (macro,\n micro and so on\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "junwen-austin", "commentT": "2020-08-19T15:23:23Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/junwen-austin>@junwen-austin</denchmark-link>\n  mind update it docs so we avoid similar questions in future...\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "junwen-austin", "commentT": "2020-08-19T18:49:00Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Borda>@Borda</denchmark-link>\n  Yes I plan to do more testing on metrics if you do not mind and then update the docs so that we have more examples. Does this sound good to you?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "junwen-austin", "commentT": "2020-08-21T17:07:50Z", "comment_text": "\n \t\t\n @Borda Yes I plan to do more testing on metrics if you do not mind and then update the docs so that we have more examples. Does this sound good to you?\n \n that would be perfect!\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "junwen-austin", "commentT": "2020-09-01T06:03:08Z", "comment_text": "\n \t\t<denchmark-h:h1>\ud83d\udc1b Bug</denchmark-h>\n \n \n We can not produce sklearn's micro f1 with PL, right?\n \n \n For some scenario, like classifying 200 classes, with most of the predicted class index is right, micro f1 makes a lot more sense than macro f1\n Macro f1 for multi-classes problem suffers great fluctuation from batch size, as many classes neither appeared in prediction or label, as illustrated below the tiny batch f1 score.\n \n Steps to reproduce the behavior:\n \n Copy the code\n Run the code from top to bottom\n Compare print results\n See Difference between sklearn and Lightning\n \n from sklearn.metrics import f1_score as sklearn_f1\n from pytorch_lightning.metrics import F1\n import torch\n \n # create sample label\n y = torch.randint(high = 199,size = (210,))\n \n print(\"dummy label/prediction\")\n print(y)\n \n sk_macro_f1 = sklearn_f1(y.numpy(),y.numpy(),labels=list(range(200)),average = 'macro')\n sk_macro_f1_tiny_batch = sklearn_f1(y[:10].numpy(),y[:10].numpy(),\n                                     labels=list(range(200)),average = 'macro')\n sk_micro_f1 = sklearn_f1(y.numpy(),y.numpy(),labels=list(range(200)),average = 'micro')\n \n pl_f1 = F1(200,reduction = \"elementwise_mean\")\n pl_ele_f1 = pl_f1(y,y)\n \n print(f\"\"\"sklearn macro f1:\\t{sk_macro_f1}\n sklearn macro f1 (tiny batch):\\t{sk_macro_f1_tiny_batch}\n skelarn micro f1:\\t{sk_micro_f1}\n pl_elementwise f1:\\t{pl_ele_f1}\n \"\"\")\n will output the following, while PL produce the macro f1 0.625, the tiny batch macro f1 is much worse, but the model predicted perfectly\n <denchmark-code>dummy label/prediction\n tensor([  4,  61, 120,  64,  60,  18, 182, 123,  65, 149, 145,   2, 182, 154,\n          46, 125,  39, 142, 144,  93, 164,  45,  70,  60, 102, 121,  39, 150,\n          54, 109,  61, 120, 180,  52, 184, 189,   4,  89,  56,   5,  24, 100,\n         194, 148, 152, 133,  75, 141,   6,  76,  93, 160, 173, 164,  13, 134,\n         186, 176, 103,  30, 179, 172, 110, 164,  45, 157, 188, 187,  80,  54,\n          77,   3,  80, 146,  42,  65,  84, 195, 132,  15,  35, 167, 110,  61,\n          38, 197, 151, 102, 193,  78,  77, 169,  93, 129, 162, 168,  97, 190,\n         129, 117,  38, 118, 145,  95, 173, 148,  70,  69, 147, 121, 138,  95,\n          47,  41, 160, 131, 167, 116, 188, 171,  68, 196,  29,  22, 183,  29,\n          90, 157, 179,  13,  26,  89, 148, 166, 193, 125, 100,  74, 130, 187,\n          79, 166, 166, 131, 147, 191,  11, 147, 101, 139,  94,  20,  22, 187,\n         149,  61,  55, 141, 176, 120, 152, 187, 146, 197, 192, 180, 180,  68,\n           1, 115, 142,   5, 161,  77,  54, 115, 175,  39, 110,  68, 151,  98,\n         102, 147,  37,  42, 154,  53, 105, 170, 114, 109,  53,  16,  62,  57,\n          75,  79,  33,  42,  74,  92, 130, 151,  50, 112, 174, 113,  69,  34])\n sklearn macro f1:\t0.65\n sklearn macro f1 (tiny batch):\t0.05\n skelarn micro f1:\t1.0\n pl_elementwise f1:\t0.6499999761581421\n </denchmark-code>\n \n <denchmark-link:https://github.com/Borda>@Borda</denchmark-link>\n  <denchmark-link:https://github.com/SkafteNicki>@SkafteNicki</denchmark-link>\n \n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "junwen-austin", "commentT": "2020-09-01T06:44:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/raynardj>@raynardj</denchmark-link>\n  We are already tracking it in this issue and it will be part of our new aggregation system. However this may take a while to lay out.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "junwen-austin", "commentT": "2020-09-02T02:14:17Z", "comment_text": "\n \t\t\n @raynardj We are already tracking it in this issue and it will be part of our new aggregation system. However this may take a while to lay out.\n \n I'm also in the slack by the same user name, anything I can contribute to the matter?\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "junwen-austin", "commentT": "2020-09-02T07:40:58Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/raynardj>@raynardj</denchmark-link>\n  if you want to help, please write to me on slack (username Nicki Skafte), as I already have some code ready that you could help finish :]\n \t\t"}}}, "commit": {"commit_id": "28af34bc5134fddf544425fed9ffe04445b237e3", "commit_author": "Nicki Skafte", "commitT": "2020-09-15 14:36:14+02:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "0.3157894736842105"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "20,29,30,31,32", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "pytorch_lightning\\metrics\\classification.py", "file_new_name": "pytorch_lightning\\metrics\\classification.py", "file_complexity": {"file_NLOC": "616", "file_CCN": "35", "file_NToken": "1843"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "55", "deleted_lines": "55", "method_info": {"method_name": "__init__", "method_params": "self,None,str,Any", "method_startline": "52", "method_endline": "56", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "25", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "421", "method_info": {"method_name": "__init__", "method_params": "self,float,None,str,Any", "method_startline": "417", "method_endline": "422", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "55", "deleted_lines": "55", "method_info": {"method_name": "__init__", "method_params": "self,None,str,Any", "method_startline": "52", "method_endline": "56", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "25", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "436", "deleted_lines": "432", "method_info": {"method_name": "__init__", "method_params": "self,float,None,str,Any", "method_startline": "432", "method_endline": "437", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "86,87", "deleted_lines": "83", "method_info": {"method_name": "forward", "method_params": "self,Tensor,Tensor", "method_startline": "75", "method_endline": "87", "method_complexity": {"method_NLOC": "13", "method_CCN": "1", "method_NToken": "45", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 12, "file_old_name": "pytorch_lightning\\metrics\\functional\\classification.py", "file_new_name": "pytorch_lightning\\metrics\\functional\\classification.py", "file_complexity": {"file_NLOC": "880", "file_CCN": "30", "file_NToken": "3454"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "328,329", "deleted_lines": "328", "method_info": {"method_name": "precision_recall", "method_params": "Tensor,Tensor,None,str,bool", "method_startline": "324", "method_endline": "329", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "34", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "242", "deleted_lines": "242", "method_info": {"method_name": "accuracy", "method_params": "Tensor,Tensor,None,str", "method_startline": "238", "method_endline": "242", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "491", "deleted_lines": "487,488,489,490", "method_info": {"method_name": "f1_score", "method_params": "Tensor,Tensor,None,str", "method_startline": "487", "method_endline": "491", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": null, "deleted_lines": "412", "method_info": {"method_name": "recall", "method_params": "Tensor,Tensor,None,str", "method_startline": "408", "method_endline": "412", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "0"}}}, "hunk_4": {"Ismethod": 1, "added_lines": null, "deleted_lines": "447", "method_info": {"method_name": "fbeta_score", "method_params": "Tensor,Tensor,float,None,str", "method_startline": "442", "method_endline": "447", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "33", "method_nesting_level": "0"}}}, "hunk_5": {"Ismethod": 1, "added_lines": null, "deleted_lines": "377", "method_info": {"method_name": "precision", "method_params": "Tensor,Tensor,None,str", "method_startline": "373", "method_endline": "377", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "0"}}}, "hunk_6": {"Ismethod": 1, "added_lines": null, "deleted_lines": "497", "method_info": {"method_name": "f1_score", "method_params": "Tensor,Tensor,None,reduction", "method_startline": "493", "method_endline": "497", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "27", "method_nesting_level": "0"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "371", "deleted_lines": "367,368,369", "method_info": {"method_name": "precision", "method_params": "Tensor,Tensor,None,str", "method_startline": "367", "method_endline": "371", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "0"}}}, "hunk_8": {"Ismethod": 1, "added_lines": "441", "deleted_lines": "436,439", "method_info": {"method_name": "fbeta_score", "method_params": "Tensor,Tensor,float,None,str", "method_startline": "436", "method_endline": "441", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "33", "method_nesting_level": "0"}}}, "hunk_9": {"Ismethod": 1, "added_lines": "328", "deleted_lines": "328", "method_info": {"method_name": "precision_recall", "method_params": "Tensor,Tensor,None,str", "method_startline": "324", "method_endline": "328", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "0"}}}, "hunk_10": {"Ismethod": 1, "added_lines": "242", "deleted_lines": "242", "method_info": {"method_name": "accuracy", "method_params": "Tensor,Tensor,None,reduction", "method_startline": "238", "method_endline": "242", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "27", "method_nesting_level": "0"}}}, "hunk_11": {"Ismethod": 1, "added_lines": "406", "deleted_lines": "405", "method_info": {"method_name": "recall", "method_params": "Tensor,Tensor,None,str", "method_startline": "402", "method_endline": "406", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "0"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\metrics\\functional\\reduction.py", "file_new_name": "pytorch_lightning\\metrics\\functional\\reduction.py", "file_complexity": {"file_NLOC": "57", "file_CCN": "5", "file_NToken": "183"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "27,28,29,30", "deleted_lines": null, "method_info": {"method_name": "class_reduce", "method_params": "Tensor,Tensor,Tensor,str", "method_startline": "27", "method_endline": "30", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "31", "method_nesting_level": "0"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "pytorch_lightning\\metrics\\functional\\regression.py", "file_new_name": "pytorch_lightning\\metrics\\functional\\regression.py", "file_complexity": {"file_NLOC": "264", "file_CCN": "8", "file_NToken": "1007"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "194,195", "deleted_lines": "190,192", "method_info": {"method_name": "_gaussian_kernel.gaussian", "method_params": "kernel_size,sigma,device", "method_startline": "190", "method_endline": "195", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "91", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "184,186,187,188,189", "deleted_lines": "190,192", "method_info": {"method_name": "_gaussian_kernel._gaussian", "method_params": "kernel_size,sigma,device", "method_startline": "184", "method_endline": "192", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "91", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "184,186,187,188,189,194,195,196", "deleted_lines": "190,192,197,198", "method_info": {"method_name": "_gaussian_kernel", "method_params": "channel,kernel_size,sigma,device", "method_startline": "183", "method_endline": "198", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "78", "method_nesting_level": "0"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\metrics\\regression.py", "file_new_name": "pytorch_lightning\\metrics\\regression.py", "file_complexity": {"file_NLOC": "225", "file_CCN": "12", "file_NToken": "584"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "50,51,52,53,54,93,94,95,96,97,136,137,138,139,140,179,180,181,182,183,226,227,228,229,230,278,279,280,281,282", "deleted_lines": "50,51,52,53,54,93,94,95,96,97,136,137,138,139,140,179,180,181,182,183,226,227,228,229,230,278,279,280,281,282"}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "tests\\metrics\\functional\\test_classification.py", "file_new_name": "tests\\metrics\\functional\\test_classification.py", "file_complexity": {"file_NLOC": "287", "file_CCN": "26", "file_NToken": "4952"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "171,172,173,174,175,178", "deleted_lines": null, "method_info": {"method_name": "test_multilabel_accuracy", "method_params": "", "method_startline": "166", "method_endline": "178", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "231", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "227,228", "deleted_lines": null, "method_info": {"method_name": "test_precision_recall", "method_params": "pred,target,expected_prec,expected_rec", "method_startline": "226", "method_endline": "231", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "73", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "69,70,71,72,73,74,75,76,77,78,79,80", "deleted_lines": null, "method_info": {"method_name": "test_different_reduction_against_sklearn", "method_params": "class_reduction,sklearn_metric,torch_metric", "method_startline": "69", "method_endline": "80", "method_complexity": {"method_NLOC": "10", "method_CCN": "2", "method_NToken": "132", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "240,243", "deleted_lines": null, "method_info": {"method_name": "test_fbeta_score", "method_params": "pred,target,beta,exp_score", "method_startline": "239", "method_endline": "244", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "90", "method_nesting_level": "0"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "253,256", "deleted_lines": null, "method_info": {"method_name": "test_f1_score", "method_params": "pred,target,exp_score", "method_startline": "252", "method_endline": "257", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "84", "method_nesting_level": "0"}}}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\metrics\\functional\\test_reduction.py", "file_new_name": "tests\\metrics\\functional\\test_reduction.py", "file_complexity": {"file_NLOC": "22", "file_CCN": "2", "file_NToken": "272"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "18,19,20,21,22,23,24,25,26,27,28,29,30", "deleted_lines": null, "method_info": {"method_name": "test_class_reduce", "method_params": "", "method_startline": "18", "method_endline": "30", "method_complexity": {"method_NLOC": "12", "method_CCN": "1", "method_NToken": "172", "method_nesting_level": "0"}}}}}}}}