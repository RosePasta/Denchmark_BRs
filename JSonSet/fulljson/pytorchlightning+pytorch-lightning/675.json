{"BR": {"BR_id": "675", "BR_author": "onkyo14taro", "BRopenT": "2020-01-09T13:16:11Z", "BRcloseT": "2020-02-05T10:15:51Z", "BR_text": {"BRsummary": "Mismatch of displayed 'epoch'", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n The display of epoch's number mismatches between the progress bar and the checkpoint indicator. I wonder this mismatch could confuse users.\n \n progress bar: The number of epochs starts from 1.\n checkpoint indicator: The number of epochs starts from 0.\n metrics.csv also starts from 0.\n \n I think that to change checkpoint and metrics.csv causes a serious problem.\n So progress bar should be changed in my opinion.\n What do you think about it?\n <denchmark-code>Epoch 32: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 331/331 [00:05<00:00, 88.73batch/s, batch_idx=17, loss=1.148, train_batch_loss=1.02, v_num=0, val_loss=1.05]\n AINFO:root:\n Epoch 00031: val_loss reached 1.04545 (best 1.04545), saving model to /dummy/version_0/checkpoints/_ckpt_epoch_31.ckpt as top 1\n {'loss': 1.022357702255249, 'train_batch_loss': 1.022357702255249, 'val_loss': 1.0454469919204712}\n Epoch 33:   5%|\u258c         | 18/331 [00:00<00:05, 61.06batch/s, batch_idx=17, loss=1.073, train_batch_loss=1.31, v_num=0, val_loss=1.05]\n </denchmark-code>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n \n PyTorch Version : 1.3.1\n OS : macOS 10.14.6\n How you installed PyTorch : pip install git+https://github.com/williamFalcon/pytorch-lightning.git@master --upgrade\n Python version : 3.7.3\n use CPU\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "onkyo14taro", "commentT": "2020-01-19T13:24:02Z", "comment_text": "\n \t\tIndeed, the inconsistency of zero-based/one-based epoch is very confusing.\n I think we should use zero-based only.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "onkyo14taro", "commentT": "2020-01-21T12:28:20Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/matthew-z>@matthew-z</denchmark-link>\n  i  agree it should be zero based.  want to submit a PR?\n <denchmark-link:https://github.com/onkyo14taro>@onkyo14taro</denchmark-link>\n  <denchmark-link:https://github.com/matthew-z>@matthew-z</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "onkyo14taro", "commentT": "2020-01-21T12:31:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  I'll try this weekend.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "onkyo14taro", "commentT": "2020-01-26T08:40:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/matthew-z>@matthew-z</denchmark-link>\n  <denchmark-link:https://github.com/neggert>@neggert</denchmark-link>\n  <denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  <denchmark-link:https://github.com/Borda>@Borda</denchmark-link>\n \n I found a 'one epoch'-based API in GradientAccumulationScheduler while I was fixing the code.\n If we force the API and display to be zero-based, it will break backward compatibility.\n However, I think that mixing 0 and 1 will confuse users than changing the API, it should be zero based.\n I think it would be better we warn with FutureWarning in version 0.6.x, and then change the API and display to be zero-based in version 0.7.x.\n What do you think about it?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "onkyo14taro", "commentT": "2020-01-27T09:34:46Z", "comment_text": "\n \t\tI can't quite wrap my head around this. If you make it zero based, then when the progress bar shows\n Epoch 1: 50/100%\n it will no longer mean that the first epoch is in progress, but actually it is the second epoch 50% completed? Is this really what you want? Why should it be this way?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "onkyo14taro", "commentT": "2020-01-27T17:39:49Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/awaelchli>@awaelchli</denchmark-link>\n \n I agree with you, but I think zero-based would be better than one-based.\n Zero-based implementations are:\n \n Progress bar (console display)\n GradientAccumulationScheduler (console display, API)\n EarlyStopping (console display)\n \n One-based implementations are:\n \n metrics.csv (in the file)\n _ckpt_epoch_{0-based epoch number}.ckpt (filename)\n ModelCheckpoint (console display)\n \n I think what of most influensive in these items are \"metrics.csv\" and \"_ckpt_epoch_{0-based epoch number}.ckpt.\"\n That's because we usually use the result file rather than console display.\n So I think that zero-based implementations have less confusion than one-based when breaking backward compatibility in order to unify representation of epoch numbers.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "onkyo14taro", "commentT": "2020-01-27T17:52:14Z", "comment_text": "\n \t\tagreed. let\u2019s do zero-based\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "onkyo14taro", "commentT": "2020-01-28T11:48:54Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  Is it ok that  is thrown when Progress bar,  or  are used in version 0.6.x , and then the API and display renew in version 0.7.0?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "onkyo14taro", "commentT": "2020-01-28T13:18:31Z", "comment_text": "\n \t\twe are using DeprecatedWarning :]\n \t\t"}}}, "commit": {"commit_id": "734b28ed2dcd0feb23b44744a3d3d40de0b20a08", "commit_author": "Shunsuke Hidaka", "commitT": "2020-02-05 05:15:51-05:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.3333333333333333", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "pytorch_lightning\\callbacks\\pt_callbacks.py", "file_new_name": "pytorch_lightning\\callbacks\\pt_callbacks.py", "file_complexity": {"file_NLOC": "329", "file_CCN": "55", "file_NToken": "1513"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "400,401", "deleted_lines": "407", "method_info": {"method_name": "__init__", "method_params": "self,dict", "method_startline": "391", "method_endline": "409", "method_complexity": {"method_NLOC": "16", "method_CCN": "7", "method_NToken": "119", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "412,413,414", "deleted_lines": null, "method_info": {"method_name": "on_epoch_begin", "method_params": "self,epoch,trainer", "method_startline": "411", "method_endline": "418", "method_complexity": {"method_NLOC": "6", "method_CCN": "3", "method_NToken": "56", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "177,178", "deleted_lines": null, "method_info": {"method_name": "on_train_end", "method_params": "self,logs", "method_startline": "175", "method_endline": "179", "method_complexity": {"method_NLOC": "5", "method_CCN": "3", "method_NToken": "38", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\training_loop.py", "file_new_name": "pytorch_lightning\\trainer\\training_loop.py", "file_complexity": {"file_NLOC": "430", "file_CCN": "88", "file_NToken": "1803"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "284,285", "deleted_lines": null, "method_info": {"method_name": "train", "method_params": "self", "method_startline": "283", "method_endline": "368", "method_complexity": {"method_NLOC": "56", "method_CCN": "22", "method_NToken": "405", "method_nesting_level": "1"}}}}}}}}