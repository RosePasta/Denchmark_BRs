{"BR": {"BR_id": "3104", "BR_author": "dalmia", "BRopenT": "2020-08-22T19:24:01Z", "BRcloseT": "2020-10-06T17:54:38Z", "BR_text": {"BRsummary": "TPU available: true when there are no TPUs", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n I am using a DGX machine (and so, no TPUs), but on initiating Trainer, it logs TPU available: True. This ends up returning Missing XLA configuration when I run my script.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n <denchmark-h:h4>Code sample</denchmark-h>\n \n Simply running the following lines on my machine:\n >> trainer = pl.Trainer(gpus=[0])                                                                                                                 \n GPU available: True, used: True\n TPU available: True, using: 0 TPU cores\n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n >> trainer = pl.Trainer(gpus=[0])                                                                                                                 \n GPU available: True, used: True\n TPU available: False, using: 0 TPU cores\n <denchmark-h:h3>Environment</denchmark-h>\n \n <denchmark-code>* CUDA:\n         - GPU:\n                 - Tesla V100-SXM2-32GB\n         - available:         True\n         - version:           10.2\n * Packages:\n         - numpy:             1.18.2\n         - pyTorch_debug:     False\n         - pyTorch_version:   1.6.0\n         - pytorch-lightning: 0.9.0\n         - tensorboard:       2.2.0\n         - tqdm:              4.45.0\n * System:\n         - OS:                Linux\n         - architecture:\n                 - 64bit\n                 - \n         - processor:         x86_64\n         - python:            3.6.9\n         - version:           #168-Ubuntu SMP Wed Jan 16 21:00:45 UTC 2019\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "dalmia", "commentT": "2020-08-24T23:10:11Z", "comment_text": "\n \t\tsounds like some misconfiguration issue, are interested in sending a PR? \ud83d\udc30\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "dalmia", "commentT": "2020-08-28T01:39:04Z", "comment_text": "\n \t\tSure. I realized that the bug is in <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/8ebf4fe1739aae04c14ddb3ad572a57775018673/pytorch_lightning/trainer/distrib_parts.py>this</denchmark-link>\n  script.\n Specifically:\n <denchmark-code>try:\n     import torch_xla.core.xla_model as xm\n except ImportError:\n     XLA_AVAILABLE = False\n else:\n     XLA_AVAILABLE = True\n </denchmark-code>\n \n So, if the environment has  installed but no TPU, then this error is thrown. If I use an environment without , it works fine. So, is this something that should be fixed in the codebase or something that the user should take care of? <denchmark-link:https://github.com/Borda>@Borda</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "dalmia", "commentT": "2020-08-28T07:35:19Z", "comment_text": "\n \t\tyes, we had the XLA detection as a temporal solution as we did not expect someone would install XLA without having TPU...\n so, pls send a PR, I think that we have this patter in several files...\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "dalmia", "commentT": "2020-10-01T18:35:37Z", "comment_text": "\n \t\tThis issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.\n \t\t"}}}, "commit": {"commit_id": "69833dad5b2a0e7e68ed60a91a5a8c32ae22f707", "commit_author": "Lezwon Castelino", "commitT": "2020-10-06 19:54:37+02:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "0.8703703703703703"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "34,35", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "pytorch_lightning\\accelerators\\tpu_backend.py", "file_new_name": "pytorch_lightning\\accelerators\\tpu_backend.py", "file_complexity": {"file_NLOC": "187", "file_CCN": "45", "file_NToken": "1439"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "49,50", "deleted_lines": "50", "method_info": {"method_name": "setup", "method_params": "self,model", "method_startline": "46", "method_endline": "60", "method_complexity": {"method_NLOC": "8", "method_CCN": "2", "method_NToken": "52", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "174", "deleted_lines": "174", "method_info": {"method_name": "to_device", "method_params": "self,batch", "method_startline": "160", "method_endline": "181", "method_complexity": {"method_NLOC": "8", "method_CCN": "2", "method_NToken": "39", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\callbacks\\early_stopping.py", "file_new_name": "pytorch_lightning\\callbacks\\early_stopping.py", "file_complexity": {"file_NLOC": "145", "file_CCN": "27", "file_NToken": "741"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "188", "deleted_lines": "189", "method_info": {"method_name": "_run_early_stopping_check", "method_params": "self,trainer,pl_module", "method_startline": "170", "method_endline": "204", "method_complexity": {"method_NLOC": "21", "method_CCN": "7", "method_NToken": "161", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\core\\lightning.py", "file_new_name": "pytorch_lightning\\core\\lightning.py", "file_complexity": {"file_NLOC": "1119", "file_CCN": "100", "file_NToken": "2640"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "33,34,48,49,50", "deleted_lines": "46,48,49,50,51"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\trainer\\data_loading.py", "file_new_name": "pytorch_lightning\\trainer\\data_loading.py", "file_complexity": {"file_NLOC": "256", "file_CCN": "49", "file_NToken": "1587"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "30,33,39", "deleted_lines": "32,38,41,42,43,44,45"}}}, "file_5": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "pytorch_lightning\\utilities\\xla_device_utils.py", "file_complexity": {"file_NLOC": "60", "file_CCN": "11", "file_NToken": "254"}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\models\\test_tpu.py", "file_new_name": "tests\\models\\test_tpu.py", "file_complexity": {"file_NLOC": "214", "file_CCN": "17", "file_NToken": "1415"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2,9,13,18,19,20", "deleted_lines": "15,20,21,22,23,219"}}}, "file_7": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tests\\utilities\\test_xla_device_utils.py", "file_complexity": {"file_NLOC": "20", "file_CCN": "3", "file_NToken": "137"}}}}}