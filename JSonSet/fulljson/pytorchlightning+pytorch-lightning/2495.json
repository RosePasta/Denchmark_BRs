{"BR": {"BR_id": "2495", "BR_author": "tadejsv", "BRopenT": "2020-07-04T12:30:29Z", "BRcloseT": "2020-07-05T02:52:50Z", "BR_text": {"BRsummary": "`precision=16` displaying wrong loss in progress bar", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n When training on a GPU (using native AMP) and setting precision=16, the loss displayed by the progress bar is some crazy large number.\n Stopping the example bellow in the middle of Epoch 1 gives a loss of ~15 000. If I train with precision=32, this loss is the true value of ~0.23.\n The loss tensor is OK, if I add a print statement in the training loop it displays normal values.\n <denchmark-h:h4>Code sample</denchmark-h>\n \n import torch\n from torch.nn import functional as F\n from torch import nn\n \n from pytorch_lightning.core.lightning import LightningModule\n from pytorch_lightning import Trainer\n \n from torch.utils.data import DataLoader, random_split\n from torchvision.datasets import MNIST\n \n import os\n from torchvision import datasets, transforms\n \n class LitMNIST(LightningModule):\n     def __init__(self):\n         super().__init__()\n         self.layer_1 = torch.nn.Linear(28 * 28, 128)\n         self.layer_2 = torch.nn.Linear(128, 256)\n         self.layer_3 = torch.nn.Linear(256, 10)\n \n     def forward(self, x):\n         batch_size, channels, width, height = x.size()\n         x = x.view(batch_size, -1)\n         x = self.layer_1(x)\n         x = torch.relu(x)\n         x = self.layer_2(x)\n         x = torch.relu(x)\n         x = self.layer_3(x)\n         x = torch.log_softmax(x, dim=1)\n         return x\n \n     def train_dataloader(self):\n         transform=transforms.Compose([transforms.ToTensor(),\n                                       transforms.Normalize((0.1307,), (0.3081,))])\n         mnist_train = MNIST(os.getcwd(), train=True, download=False, transform=transform)\n         return DataLoader(mnist_train, batch_size=64)\n \n     def configure_optimizers(self):\n         return torch.optim.Adam(self.parameters(), lr=1e-3)\n \n     def training_step(self, batch, batch_idx):\n         x, y = batch\n         logits = self(x)\n         loss = F.nll_loss(logits, y)\n \n         # add logging\n         logs = {'loss': loss}\n         return {'loss': loss, 'log': logs}\n     \n \n model = LitMNIST()\n trainer = Trainer(gpus=1, precision=16)\n trainer.fit(model)\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n PyTorch Version:  v1.7.0.dev20200704 (nightly)\n OS (e.g., Linux): Ubuntu 18.04\n How you installed PyTorch (conda, pip, source): conda\n Python version: 3.8\n CUDA/cuDNN version: 10.2 (installed with conda from pytorch chanel)\n GPU models and configuration: RTX 2070 SUPER\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "tadejsv", "commentT": "2020-07-04T12:31:18Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "tadejsv", "commentT": "2020-10-30T10:18:01Z", "comment_text": "\n \t\tI have the same issue, but not on the sample code provided. The only difference in my sample code is that using a custom dataset and L1 loss the numbers are (initially) over 200.0 (as opposed to MNIST where it starts very low).\n All is fine until after ~10 epochs where the loss in the pbar becomes 'inf'; whereas the logs shows the correct value being around 20.\n \t\t"}}}, "commit": {"commit_id": "9924c76faa7789294811a27c392ba6b33e07f3f1", "commit_author": "William Falcon", "commitT": "2020-07-04 22:52:49-04:00", "commit_complexity": {"commit_NLOC": "0.5555555555555556", "commit_CCN": "0.8888888888888888", "commit_Nprams": "0.4444444444444444"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "pl_examples\\models\\lightning_template.py", "file_new_name": "pl_examples\\models\\lightning_template.py", "file_complexity": {"file_NLOC": "131", "file_CCN": "20", "file_NToken": "1121"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "163", "deleted_lines": null, "method_info": {"method_name": "test_dataloader", "method_params": "self", "method_startline": "162", "method_endline": "163", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "160", "deleted_lines": "159", "method_info": {"method_name": "val_dataloader", "method_params": "self", "method_startline": "159", "method_endline": "160", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "182", "deleted_lines": null, "method_info": {"method_name": "add_model_specific_args", "method_params": "parent_parser,root_dir", "method_startline": "166", "method_endline": "191", "method_complexity": {"method_NLOC": "13", "method_CCN": "1", "method_NToken": "175", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "48", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,float,int,int,float,str,str,int,int,int,kwargs", "method_startline": "40", "method_endline": "51", "method_complexity": {"method_NLOC": "12", "method_CCN": "1", "method_NToken": "70", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "157", "deleted_lines": "156", "method_info": {"method_name": "train_dataloader", "method_params": "self", "method_startline": "156", "method_endline": "157", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\core\\hooks.py", "file_new_name": "pytorch_lightning\\core\\hooks.py", "file_complexity": {"file_NLOC": "162", "file_CCN": "19", "file_NToken": "291"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "194", "method_info": {"method_name": "amp_scale_loss", "method_params": "self,unscaled_loss,optimizer,optimizer_idx", "method_startline": "191", "method_endline": "198", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "40", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\distrib_data_parallel.py", "file_new_name": "pytorch_lightning\\trainer\\distrib_data_parallel.py", "file_complexity": {"file_NLOC": "440", "file_CCN": "100", "file_NToken": "2071"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "439", "method_info": {"method_name": "spawn_ddp_children", "method_params": "self,model", "method_startline": "394", "method_endline": "450", "method_complexity": {"method_NLOC": "35", "method_CCN": "8", "method_NToken": "290", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "pytorch_lightning\\trainer\\training_loop.py", "file_new_name": "pytorch_lightning\\trainer\\training_loop.py", "file_complexity": {"file_NLOC": "647", "file_CCN": "158", "file_NToken": "3325"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "639", "deleted_lines": null, "method_info": {"method_name": "run_training_batch", "method_params": "self,batch,batch_idx", "method_startline": "580", "method_endline": "687", "method_complexity": {"method_NLOC": "58", "method_CCN": "18", "method_NToken": "442", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "801,802,803,842", "deleted_lines": "837", "method_info": {"method_name": "optimizer_closure", "method_params": "self,split_batch,batch_idx,opt_idx,optimizer,hiddens", "method_startline": "762", "method_endline": "847", "method_complexity": {"method_NLOC": "50", "method_CCN": "11", "method_NToken": "354", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "745", "deleted_lines": null, "method_info": {"method_name": "call_optimizer_step", "method_params": "self,optimizer,opt_idx,batch_idx,split_batch", "method_startline": "715", "method_endline": "760", "method_complexity": {"method_NLOC": "28", "method_CCN": "9", "method_NToken": "187", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\base\\deterministic_model.py", "file_new_name": "tests\\base\\deterministic_model.py", "file_complexity": {"file_NLOC": "103", "file_CCN": "27", "file_NToken": "1024"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "137,138,139,140", "deleted_lines": "137", "method_info": {"method_name": "backward", "method_params": "self,trainer,loss,optimizer,optimizer_idx", "method_startline": "136", "method_endline": "141", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "41", "method_nesting_level": "1"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\trainer\\test_trainer_steps.py", "file_new_name": "tests\\trainer\\test_trainer_steps.py", "file_complexity": {"file_NLOC": "107", "file_CCN": "8", "file_NToken": "741"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "20,21,48,49,50", "deleted_lines": "36", "method_info": {"method_name": "test_training_step_dict", "method_params": "tmpdir", "method_startline": "9", "method_endline": "50", "method_complexity": {"method_NLOC": "30", "method_CCN": "2", "method_NToken": "209", "method_nesting_level": "0"}}}}}}}}