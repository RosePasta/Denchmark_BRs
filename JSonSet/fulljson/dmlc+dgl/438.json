{"BR": {"BR_id": "438", "BR_author": "jackroos", "BRopenT": "2019-03-08T13:36:22Z", "BRcloseT": "2019-03-19T04:02:15Z", "BR_text": {"BRsummary": "Picking/unpickling DGLGraph breaks feature set/get", "BRdescription": "\n Hi, I am trying to emit BatchedDGLGraph in torch.utils.data.DataLoader, but it failed when num_workers > 0. Could you help me solve this problem?\n The error message is as following:\n \n Traceback (most recent call last):\n File \"/xxx/anaconda3/envs/xxx/lib/python3.6/multiprocessing/queues.py\", line 234, in _feed\n obj = _ForkingPickler.dumps(obj)\n File \"/xxx/anaconda3/envs/xxx/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n cls(buf, protocol).dump(obj)\n TypeError: can't pickle module objects\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jackroos", "commentT": "2019-03-08T23:23:12Z", "comment_text": "\n \t\tHi, could you paste the code here? My guess is you use \"register_reduce_func\" somewhere and the function/module object is not pickleable. A walkaround is directly pass the reduce func to the message passing APIs you call (e.g. update_all, send_and_recv, etc.).\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jackroos", "commentT": "2019-03-09T03:27:05Z", "comment_text": "\n \t\t\n Hi, could you paste the code here? My guess is you use \"register_reduce_func\" somewhere and the function/module object is not pickleable. A walkaround is directly pass the reduce func to the message passing APIs you call (e.g. update_all, send_and_recv, etc.).\n \n I do not use register_reduce_func . I just construct a DGLGraph with nodes, edges, ndata, edata in __getitem__() of my dataset, and use dgl.batch() in collate_fn of dataloader. My original code is a little complicated. I am trying to reproduce this error using toy example. But I find I can't reproduce the error now. By the way, if I remove the BatchedDGLGraph in the output of collate_fn. This error will disappear. So it must be related to the graph.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jackroos", "commentT": "2019-03-09T03:48:47Z", "comment_text": "\n \t\tActually, I can't even pickle graph.ndata.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jackroos", "commentT": "2019-03-09T16:58:12Z", "comment_text": "\n \t\tI'll look into this.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jackroos", "commentT": "2019-03-11T11:26:56Z", "comment_text": "\n \t\tIt is very weird. When I debug line by line in my code, I find the graph can't be pickled just after it be created and call add_nodes. But when I try to reproduce this in following simple code:\n import dgl\n import torch\n import _pickle\n \n graph = dgl.DGLGraph()\n graph.add_nodes(5, {'type': torch.zeros(5, dtype=torch.int64)})\n _pickle.dumps(graph)\n the graph is pickled successfully. Do you have any ideas?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "jackroos", "commentT": "2019-03-11T11:32:06Z", "comment_text": "\n \t\tIn addition, in my original code, after graph created by:\n <denchmark-code>graph = dgl.DGLGraph()\n </denchmark-code>\n \n then _pickle.dumps(graph) will be None. But in the simple code of my previous comment, it's not None.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "jackroos", "commentT": "2019-03-11T11:44:31Z", "comment_text": "\n \t\t\n In addition, in my original code, after graph created by:\n graph = dgl.DGLGraph()\n \n then _pickle.dumps(graph) will be None. But in the simple code of my previous comment, it's not None.\n \n Sorry, I debug again using IPython, it's not None. Previously I used 'evaluate' in PyCharm Debugger. But in IPython, it still can't be pickled just after add_nodes.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "jackroos", "commentT": "2019-03-12T20:49:21Z", "comment_text": "\n \t\tHi, I found the following script can reproduce the error on my side consistently. Could you help confirm?\n import networkx as nx\n import dgl\n import torch\n import pickle\n import io\n def _reconstruct_pickle(obj):\n     f = io.BytesIO()\n     pickle.dump(obj, f)\n     f.seek(0)\n     obj = pickle.load(f)\n     f.close()\n     return obj\n \n def test_pickling_batched_graph():\n     glist = [nx.path_graph(i + 5) for i in range(5)]\n     glist = [dgl.DGLGraph(g) for g in glist]\n     bg = dgl.batch(glist)\n     bg.ndata['x'] = torch.randn((35, 5))\n     bg.edata['y'] = torch.randn((60, 3))\n     new_bg = _reconstruct_pickle(bg)\n \n test_pickling_batched_graph()\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "jackroos", "commentT": "2019-03-12T20:57:27Z", "comment_text": "\n \t\tIn fact, the problem is torch dtype. Here is a more precise reproduction. Note that if import networkx is deleted, the code works ...\n import networkx as nx  # if this line is removed, it works !!\n import torch\n import pickle\n import io\n \n def _reconstruct_pickle(obj):\n     f = io.BytesIO()\n     pickle.dump(obj, f)\n     f.seek(0)\n     obj = pickle.load(f)\n     f.close()\n     return obj\n \n def test():\n     x = torch.float32\n     new_bg = _reconstruct_pickle(x)\n \n test()\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "jackroos", "commentT": "2019-03-13T00:55:29Z", "comment_text": "\n \t\tSimilar dtype pickling issues are tracked in <denchmark-link:https://github.com/pytorch/pytorch/issues/14057>pytorch/pytorch#14057</denchmark-link>\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "jackroos", "commentT": "2019-03-13T10:53:22Z", "comment_text": "\n \t\tHi, <denchmark-link:https://github.com/jermainewang>@jermainewang</denchmark-link>\n . I can reproduce your result. But after I remove all 'import networkx' in my code. It still has 'pickle' problem. I guess some other library I import have the same problem with 'networkx'. Do you know any other library of this kind?\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "jackroos", "commentT": "2019-03-13T14:49:40Z", "comment_text": "\n \t\tTry this workaround. First, figure out the path of your DGL installation by:\n >>> import dgl\n >>> dgl.__path__\n Then, in the DGL folder, remove the if in L31 in dgl/frame.py and unindent L32-L40. The change will use our own serializer for torch.dtype. Let me know whether this fixes your issue and we will include it in the next patch release.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "jackroos", "commentT": "2019-03-14T02:41:32Z", "comment_text": "\n \t\tIt does fix pickling error. But when I want to transfer data of graph to cuda by following code:\n def graph_to_cuda(graph):\n     for key in graph.ndata:\n         graph.ndata[key] = graph.ndata[key].cuda(non_blocking=True)\n \n     for key in graph.edata:\n         graph.edata[key] = graph.edata[key].cuda(non_blocking=True)\n \n     return graph\n Another error happened:\n Traceback (most recent call last):\n   File \"xxx.py\", line 63, in xxx\n     graph = graph_to_cuda(graph)\n   File \"xxx/graph.py\", line 158, in graph_to_cuda\n     graph.ndata[key] = graph.ndata[key].cuda(non_blocking=True)\n   File \"xxx/python3.6/site-packages/dgl/view.py\", line 60, in __setitem__\n     self._graph.set_n_repr({key : val}, self._nodes)\n   File \"xxx/lib/python3.6/site-packages/dgl/graph.py\", line 1591, in set_n_repr\n     self._node_frame[key] = val\n   File \"xxx/lib/python3.6/site-packages/dgl/frame.py\", line 616, in __setitem__\n     self.update_data(key, val, inplace=False)\n   File \"xxx/lib/python3.6/site-packages/dgl/frame.py\", line 643, in update_data\n     self.update_column(key, val, inplace=inplace)\n   File \"xxx/lib/python3.6/site-packages/dgl/frame.py\", line 681, in update_column\n     fcol.update(self._index, data, inplace)\n   File \"xxx/lib/python3.6/site-packages/dgl/frame.py\", line 149, in update\n     self.data = F.scatter_row(self.data, idx, feats)\n   File \"xxx/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\", line 115, in scatter_row\n     return data.index_copy(0, row_index, value)\n   File \"xxx/lib/python3.6/site-packages/torch/tensor.py\", line 312, in index_copy\n     return self.clone().index_copy_(dim, index, tensor)\n RuntimeError: Expected object of backend CPU but got backend CUDA for argument #4 'source'\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "jackroos", "commentT": "2019-03-14T02:56:41Z", "comment_text": "\n \t\tCould you show how the graph is created?\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "jackroos", "commentT": "2019-03-14T06:25:24Z", "comment_text": "\n \t\tIt's something like this.\n def construct_graph():\n     graph = dgl.DGLGraph()\n     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})\n     for i in range(4):\n         for j in range(4):\n             if i == j:\n                 continue\n             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),\n                          'type': torch.tensor([0])}\n             graph.add_edge(i, j, edge_data)\n \n     super_id = graph.number_of_nodes()\n     graph.add_nodes(1, {'type': torch.tensor([2], dtype=torch.int64)})\n \n     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})\n     for i1 in range(4):\n         i = i1 + 4 + 1\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i, super_id, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(super_id, i, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i, i1, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i1, i, edge_data)\n         for j1 in range(4):\n             j = j1 + 4 + 1\n             if i == j:\n                 continue\n             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),\n                          'type': torch.tensor([1])}\n             graph.add_edge(i, j, edge_data)\n \n     # assign in-degree for each node\n     assign_norm(graph)\n \n     return graph\n \n def assign_norm(graph):\n \n     def msg_func(edges):\n         return {'msg': torch.ones_like(edges.data['type'])}\n \n     def reduce_func(nodes):\n         in_deg = torch.sum(nodes.mailbox['msg'], 1)\n         norm = 1.0 / torch.sqrt(in_deg.float())\n         return {'norm': norm}\n \n     graph.update_all(msg_func, reduce_func, None)\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "jackroos", "commentT": "2019-03-15T14:11:28Z", "comment_text": "\n \t\tAny ideas to solve this? <denchmark-link:https://github.com/jermainewang>@jermainewang</denchmark-link>\n \n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "jackroos", "commentT": "2019-03-18T03:24:50Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/jackroos>@jackroos</denchmark-link>\n  , sorry for the late reply! I tried your codes but cannot reproduce the error. Would you provide some environment information? Thank you.\n <denchmark-h:h2>Environment</denchmark-h>\n \n \n DGL Version (e.g., 1.0):\n Backend Library & Version (e.g., PyTorch 0.4.1, MXNet/Gluon 1.3):\n OS (e.g., Linux):\n How you installed DGL (conda, pip, source):\n Build command you used (if compiling from source):\n Python version:\n CUDA/cuDNN version (if applicable):\n GPU models and configuration (e.g. V100):\n Any other relevant information:\n \n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "jackroos", "commentT": "2019-03-18T03:54:05Z", "comment_text": "\n \t\t\n DGL: build from my forked version: https://github.com/jackroos/dgl, just modify the pickle part in frame.py.\n Backend: PyTorch 1.0.0\n OS: Linux, Ubuntu 16.04\n Build command:\n \n python setup.py install\n \n Python version: 3.6.6\n CUDA version: release 9.0, V9.0.176\n cuDNN version: 7.0\n GPU models: Tesla M40 24GB\n \n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "jackroos", "commentT": "2019-03-18T03:59:49Z", "comment_text": "\n \t\tTried your repo and still cannot reproduce the error. Could you verify this is the error example?\n import torch\n import dgl\n \n def construct_graph():\n     graph = dgl.DGLGraph()\n     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})\n     for i in range(4):\n         for j in range(4):\n             if i == j:\n                 continue\n             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),\n                          'type': torch.tensor([0])}\n             graph.add_edge(i, j, edge_data)\n \n     super_id = graph.number_of_nodes()\n     graph.add_nodes(1, {'type': torch.tensor([2], dtype=torch.int64)})\n \n     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})\n     for i1 in range(4):\n         i = i1 + 4 + 1\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i, super_id, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(super_id, i, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i, i1, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i1, i, edge_data)\n         for j1 in range(4):\n             j = j1 + 4 + 1\n             if i == j:\n                 continue\n             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),\n                          'type': torch.tensor([1])}\n             graph.add_edge(i, j, edge_data)\n \n     # assign in-degree for each node\n     assign_norm(graph)\n \n     return graph\n \n def assign_norm(graph):\n \n     def msg_func(edges):\n         return {'msg': torch.ones_like(edges.data['type'])}\n \n     def reduce_func(nodes):\n         in_deg = torch.sum(nodes.mailbox['msg'], 1)\n         norm = 1.0 / torch.sqrt(in_deg.float())\n         return {'norm': norm}\n \n     graph.update_all(msg_func, reduce_func, None)\n \n def graph_to_cuda(graph):\n     for key in graph.ndata:\n         graph.ndata[key] = graph.ndata[key].cuda(non_blocking=True)\n \n     for key in graph.edata:\n         graph.edata[key] = graph.edata[key].cuda(non_blocking=True)\n \n     return graph\n \n g = construct_graph()\n g = graph_to_cuda(g)\n print(g.ndata)\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "jackroos", "commentT": "2019-03-18T04:01:28Z", "comment_text": "\n \t\tOh, could you also verify the DGL version by python -c 'import dgl; print(dgl.__version__)'?\n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "jackroos", "commentT": "2019-03-18T04:38:38Z", "comment_text": "\n \t\t\n python -c 'import dgl; print(dgl.version)'\n \n 0.2\n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "jackroos", "commentT": "2019-03-18T04:39:54Z", "comment_text": "\n \t\tI can't reproduce the error based on this simple code also. I don't know if it's something related to dependency again. BTW, in the situation of num_workers=0, graph_to_cuda() can successfully transfer the graph to cuda. But now dataloader is the bottleneck of my code, so I must increase num_workers to improve my training speed.\n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "jackroos", "commentT": "2019-03-18T22:36:16Z", "comment_text": "\n \t\tFinally bug confirmed! The cuda call failed after pickle and unpickle:\n import torch\n import dgl\n \n def construct_graph():\n     graph = dgl.DGLGraph()\n     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})\n     for i in range(4):\n         for j in range(4):\n             if i == j:\n                 continue\n             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),\n                          'type': torch.tensor([0])}\n             graph.add_edge(i, j, edge_data)\n \n     super_id = graph.number_of_nodes()\n     graph.add_nodes(1, {'type': torch.tensor([2], dtype=torch.int64)})\n \n     graph.add_nodes(4, {'type': torch.zeros(4, dtype=torch.int64)})\n     for i1 in range(4):\n         i = i1 + 4 + 1\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i, super_id, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(super_id, i, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i, i1, edge_data)\n         edge_data = {'h': torch.tensor([[0, 0., 0., 0.]]),\n                      'type': torch.tensor([1])}\n         graph.add_edge(i1, i, edge_data)\n         for j1 in range(4):\n             j = j1 + 4 + 1\n             if i == j:\n                 continue\n             edge_data = {'h': torch.tensor([[0.0, 0.0, 0.0, 0.0]]),\n                          'type': torch.tensor([1])}\n             graph.add_edge(i, j, edge_data)\n \n     # assign in-degree for each node\n     assign_norm(graph)\n \n     return graph\n \n def assign_norm(graph):\n \n     def msg_func(edges):\n         return {'msg': torch.ones_like(edges.data['type'])}\n \n     def reduce_func(nodes):\n         in_deg = torch.sum(nodes.mailbox['msg'], 1)\n         norm = 1.0 / torch.sqrt(in_deg.float())\n         return {'norm': norm}\n \n     graph.update_all(msg_func, reduce_func, None)\n \n def graph_to_cuda(graph):\n     for key in graph.ndata:\n         graph.ndata[key] = graph.ndata[key].cuda(non_blocking=True)\n \n     for key in graph.edata:\n         graph.edata[key] = graph.edata[key].cuda(non_blocking=True)\n \n     return graph\n \n import pickle\n import io\n \n def _reconstruct_pickle(obj):\n     f = io.BytesIO()\n     pickle.dump(obj, f)\n     f.seek(0)\n     obj = pickle.load(f)\n     f.close()\n     return obj\n \n g = construct_graph()\n gg = _reconstruct_pickle(g)\n gg = graph_to_cuda(gg)\n print(gg.ndata)\n \t\t"}, "comments_23": {"comment_id": 24, "comment_author": "jackroos", "commentT": "2019-03-19T03:28:32Z", "comment_text": "\n \t\tCool! Thank you so much for your effort! Look forward to the bug fix.\n \t\t"}, "comments_24": {"comment_id": 25, "comment_author": "jackroos", "commentT": "2019-03-19T03:49:07Z", "comment_text": "\n \t\tJust merged the fix. The above example works on my machine. Could you pull the latest master and test it again?\n \t\t"}, "comments_25": {"comment_id": 26, "comment_author": "jackroos", "commentT": "2019-03-19T03:59:16Z", "comment_text": "\n \t\tIt works for me now! Many thanks to you again! \ud83d\udc2e\ud83c\udf7a!!!\n \t\t"}}}, "commit": {"commit_id": "33b9c38389a37086b69397872e75d9fdbc58ee09", "commit_author": "Minjie Wang", "commitT": "2019-03-18 23:48:20-04:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\dgl\\frame.py", "file_new_name": "python\\dgl\\frame.py", "file_complexity": {"file_NLOC": "357", "file_CCN": "111", "file_NToken": "2685"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "34,35,36", "deleted_lines": "34,35,36", "method_info": {"method_name": "_reconstruct_scheme", "method_params": "cls,shape,dtype_str", "method_startline": "34", "method_endline": "36", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "29,30,31", "deleted_lines": "31", "method_info": {"method_name": "__reduce__", "method_params": "self", "method_startline": "29", "method_endline": "31", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "27", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\dgl\\utils.py", "file_new_name": "python\\dgl\\utils.py", "file_complexity": {"file_NLOC": "276", "file_CCN": "97", "file_NToken": "2072"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "131,132,133,134,135", "deleted_lines": "131", "method_info": {"method_name": "__getstate__", "method_params": "self", "method_startline": "130", "method_endline": "135", "method_complexity": {"method_NLOC": "5", "method_CCN": "2", "method_NToken": "25", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "tests\\compute\\test_pickle.py", "file_new_name": "tests\\compute\\test_pickle.py", "file_complexity": {"file_NLOC": "172", "file_CCN": "20", "file_NToken": "1639"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "52,53,54,55,56", "deleted_lines": null, "method_info": {"method_name": "_assert_is_identical_batchedgraph", "method_params": "bg1,bg2", "method_startline": "52", "method_endline": "56", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "37", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "58,59,60", "deleted_lines": null, "method_info": {"method_name": "_assert_is_identical_index", "method_params": "i1,i2", "method_startline": "58", "method_endline": "60", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "36", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "14,15,16,17,18,19,20,21,22,23,24,25,26,27,28", "deleted_lines": "24,27,28", "method_info": {"method_name": "_assert_is_identical", "method_params": "g,g2", "method_startline": "14", "method_endline": "28", "method_complexity": {"method_NLOC": "14", "method_CCN": "3", "method_NToken": "151", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "208,209,210,211,212,213,214,215", "deleted_lines": null, "method_info": {"method_name": "test_pickling_batched_graph", "method_params": "", "method_startline": "208", "method_endline": "215", "method_complexity": {"method_NLOC": "8", "method_CCN": "3", "method_NToken": "91", "method_nesting_level": "0"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50", "deleted_lines": null, "method_info": {"method_name": "_assert_is_identical_nodeflow", "method_params": "nf1,nf2", "method_startline": "30", "method_endline": "50", "method_complexity": {"method_NLOC": "20", "method_CCN": "5", "method_NToken": "269", "method_nesting_level": "0"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "72,77,79,80,81,82", "deleted_lines": "71,72,73,74,75,76,77,78,79,80,81,82", "method_info": {"method_name": "test_pickling_index", "method_params": "", "method_startline": "71", "method_endline": "82", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "61", "method_nesting_level": "0"}}}}}, "file_3": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tests\\pytorch\\test_pickle.py", "file_complexity": {"file_NLOC": "21", "file_CCN": "4", "file_NToken": "148"}}}}}