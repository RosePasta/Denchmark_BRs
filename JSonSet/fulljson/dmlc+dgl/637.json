{"BR": {"BR_id": "637", "BR_author": "yangysc", "BRopenT": "2019-06-10T12:59:30Z", "BRcloseT": "2019-06-11T02:07:23Z", "BR_text": {"BRsummary": "The GPU usage keep growing as the training is going, if graph is passed into the model every time", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n Hello, I'm using the GAT model from the dgl library. But I made a small modification, since my input graph is changing all the time, so I do not store a graph in the model (I commented the code self.g=g), instead that I treat the graph and feature tensor as the input to the model every time.  Then the problem occured: the GPU usage is keeping growing as the training is going.\n <denchmark-code>Processes:                                                           GPU Memory   \n  GPU  PID         Type   Process name                                Usage   \n \n    0     19583      C   ...noone/anaconda3/envs/tf_test/bin/python   697MiB\n    0     19731      C   ...noone/anaconda3/envs/tf_test/bin/python  1159MiB \n    0     19583      C   ...noone/anaconda3/envs/tf_test/bin/python  1459MiB \n    0     19731      C   ...noone/anaconda3/envs/tf_test/bin/python  1929MiB \n    0     19731      C   ...noone/anaconda3/envs/tf_test/bin/python  2297MiB\n    0     19731      C   ...noone/anaconda3/envs/tf_test/bin/python  6023MiB\n </denchmark-code>\n \n Is this because some data still exist in the GPU memory, and begin to accumulate whenever I call the model like probs = net(graph, feature)?  If this is true, what information should I delete when the model is called?\n Thanks in advance!\n <denchmark-h:h2>To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n \n \n Install the latest dgl.\n \n \n Download the files I uploaded  in here.\n \n \n Run the following command to train\n python3 train.py --dataset=cora --gpu=0 --epochs=20000\n \n \n Watch the GPU usage every 3 seconds.\n watch -n 3 nvidia-smi\n \n \n # gat model\n \"\"\"\n Graph Attention Networks in DGL using SPMV optimization.\n References\n ----------\n Paper: https://arxiv.org/abs/1710.10903\n Author's code: https://github.com/PetarV-/GAT\n Pytorch implementation: https://github.com/Diego999/pyGAT\n \"\"\"\n \n import torch\n import torch.nn as nn\n import dgl.function as fn\n from dgl.nn.pytorch import edge_softmax\n \n class GraphAttention(nn.Module):\n     def __init__(self,\n                  in_dim,\n                  out_dim,\n                  num_heads,\n                  feat_drop,\n                  attn_drop,\n                  alpha,\n                  residual=False):\n         super(GraphAttention, self).__init__()\n         # self.g = g\n         self.num_heads = num_heads\n         self.fc = nn.Linear(in_dim, num_heads * out_dim, bias=False)\n         if feat_drop:\n             self.feat_drop = nn.Dropout(feat_drop)\n         else:\n             self.feat_drop = lambda x : x\n         if attn_drop:\n             self.attn_drop = nn.Dropout(attn_drop)\n         else:\n             self.attn_drop = lambda x : x\n         self.attn_l = nn.Parameter(torch.Tensor(size=(1, num_heads, out_dim)))\n         self.attn_r = nn.Parameter(torch.Tensor(size=(1, num_heads, out_dim)))\n         nn.init.xavier_normal_(self.fc.weight.data, gain=1.414)\n         nn.init.xavier_normal_(self.attn_l.data, gain=1.414)\n         nn.init.xavier_normal_(self.attn_r.data, gain=1.414)\n         self.leaky_relu = nn.LeakyReLU(alpha)\n         self.softmax = edge_softmax\n         self.residual = residual\n         if residual:\n             if in_dim != out_dim:\n                 self.res_fc = nn.Linear(in_dim, num_heads * out_dim, bias=False)\n                 nn.init.xavier_normal_(self.res_fc.weight.data, gain=1.414)\n             else:\n                 self.res_fc = None\n \n     def forward(self, g, inputs):\n         # prepare\n         h = self.feat_drop(inputs)  # NxD\n         ft = self.fc(h).reshape((h.shape[0], self.num_heads, -1))  # NxHxD'\n         a1 = (ft * self.attn_l).sum(dim=-1).unsqueeze(-1) # N x H x 1\n         a2 = (ft * self.attn_r).sum(dim=-1).unsqueeze(-1) # N x H x 1\n         g.ndata.update({'ft' : ft, 'a1' : a1, 'a2' : a2})\n         # 1. compute edge attention\n         g.apply_edges(self.edge_attention)\n         # 2. compute softmax\n         self.edge_softmax(g)\n         # 3. compute the aggregated node features scaled by the dropped,\n         # unnormalized attention values.\n         g.update_all(fn.src_mul_edge('ft', 'a_drop', 'ft'), fn.sum('ft', 'ft'))\n         ret = g.ndata['ft']\n         # 4. residual\n         if self.residual:\n             if self.res_fc is not None:\n                 resval = self.res_fc(h).reshape((h.shape[0], self.num_heads, -1))  # NxHxD'\n             else:\n                 resval = torch.unsqueeze(h, 1)  # Nx1xD'\n             ret = resval + ret\n         return ret\n \n     def edge_attention(self, edges):\n         # an edge UDF to compute unnormalized attention values from src and dst\n         a = self.leaky_relu(edges.src['a1'] + edges.dst['a2'])\n         return {'a' : a}\n \n     def edge_softmax(self, g):\n         attention = self.softmax(g, g.edata.pop('a'))\n         # Dropout attention scores and save them\n         g.edata['a_drop'] = self.attn_drop(attention)\n \n class GAT(nn.Module):\n     def __init__(self,\n                  num_layers,\n                  in_dim,\n                  num_hidden,\n                  num_classes,\n                  heads,\n                  activation,\n                  feat_drop,\n                  attn_drop,\n                  alpha,\n                  residual):\n         super(GAT, self).__init__()\n         # self.g = g\n         self.num_layers = num_layers\n         self.gat_layers = nn.ModuleList()\n         self.activation = activation\n         # input projection (no residual)\n         self.gat_layers.append(GraphAttention(\n             in_dim, num_hidden, heads[0], feat_drop, attn_drop, alpha, False))\n         # hidden layers\n         for l in range(1, num_layers):\n             # due to multi-head, the in_dim = num_hidden * num_heads\n             self.gat_layers.append(GraphAttention(\n                 num_hidden * heads[l-1], num_hidden, heads[l],\n                 feat_drop, attn_drop, alpha, residual))\n         # output projection\n         self.gat_layers.append(GraphAttention(\n             num_hidden * heads[-2], num_classes, heads[-1],\n             feat_drop, attn_drop, alpha, residual))\n \n     def forward(self, g, inputs):\n         h = inputs\n         for l in range(self.num_layers):\n             h = self.gat_layers[l](g, h).flatten(1)\n             h = self.activation(h)\n         # output projection\n         logits = self.gat_layers[-1](g, h).mean(1)\n         return logits\n # train.py\n \"\"\"\n Graph Attention Networks in DGL using SPMV optimization.\n Multiple heads are also batched together for faster training.\n Compared with the original paper, this code does not implement\n early stopping.\n References\n ----------\n Paper: https://arxiv.org/abs/1710.10903\n Author's code: https://github.com/PetarV-/GAT\n Pytorch implementation: https://github.com/Diego999/pyGAT\n \"\"\"\n \n import argparse\n import numpy as np\n import time\n import torch\n import torch.nn.functional as F\n from dgl import DGLGraph\n from dgl.data import register_data_args, load_data\n from gat import GAT\n \n def accuracy(logits, labels):\n     _, indices = torch.max(logits, dim=1)\n     correct = torch.sum(indices == labels)\n     return correct.item() * 1.0 / len(labels)\n \n def evaluate(model, g, features, labels, mask):\n     model.eval()\n     with torch.no_grad():\n         logits = model(g, features)\n         logits = logits[mask]\n         labels = labels[mask]\n         return accuracy(logits, labels)\n \n def main(args):\n     # load and preprocess dataset\n     data = load_data(args)\n     features = torch.FloatTensor(data.features)\n     labels = torch.LongTensor(data.labels)\n     train_mask = torch.ByteTensor(data.train_mask)\n     val_mask = torch.ByteTensor(data.val_mask)\n     test_mask = torch.ByteTensor(data.test_mask)\n     num_feats = features.shape[1]\n     n_classes = data.num_labels\n     n_edges = data.graph.number_of_edges()\n     print(\"\"\"----Data statistics------'\n       #Edges %d\n       #Classes %d\n       #Train samples %d\n       #Val samples %d\n       #Test samples %d\"\"\" %\n           (n_edges, n_classes,\n            train_mask.sum().item(),\n            val_mask.sum().item(),\n            test_mask.sum().item()))\n \n     if args.gpu < 0:\n         cuda = False\n     else:\n         cuda = True\n         torch.cuda.set_device(args.gpu)\n         features = features.cuda()\n         labels = labels.cuda()\n         train_mask = train_mask.cuda()\n         val_mask = val_mask.cuda()\n         test_mask = test_mask.cuda()\n \n     g = data.graph\n     # add self loop\n     g.remove_edges_from(g.selfloop_edges())\n     g = DGLGraph(g)\n     g.add_edges(g.nodes(), g.nodes())\n     n_edges = g.number_of_edges()\n     # create model\n     heads = ([args.num_heads] * args.num_layers) + [args.num_out_heads]\n     model = GAT(\n                 args.num_layers,\n                 num_feats,\n                 args.num_hidden,\n                 n_classes,\n                 heads,\n                 F.elu,\n                 args.in_drop,\n                 args.attn_drop,\n                 args.alpha,\n                 args.residual)\n     print(model)\n     if cuda:\n         model.cuda()\n     loss_fcn = torch.nn.CrossEntropyLoss()\n \n     # use optimizer\n     optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n \n     # initialize graph\n     dur = []\n     for epoch in range(args.epochs):\n         model.train()\n         if epoch >= 3:\n             t0 = time.time()\n         # forward\n         logits = model(g, features)\n         loss = loss_fcn(logits[train_mask], labels[train_mask])\n \n         optimizer.zero_grad()\n         loss.backward()\n         optimizer.step()\n \n         if epoch >= 3:\n             dur.append(time.time() - t0)\n \n         train_acc = accuracy(logits[train_mask], labels[train_mask])\n \n         if args.fastmode:\n             val_acc = accuracy(logits[val_mask], labels[val_mask])\n         else:\n             val_acc = evaluate(model, g, features, labels, val_mask)\n \n         print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | TrainAcc {:.4f} |\"\n               \" ValAcc {:.4f} | ETputs(KTEPS) {:.2f}\".\n               format(epoch, np.mean(dur), loss.item(), train_acc,\n                      val_acc, n_edges / np.mean(dur) / 1000))\n \n     print()\n     acc = evaluate(model, g, features, labels, test_mask)\n     print(\"Test Accuracy {:.4f}\".format(acc))\n \n if __name__ == '__main__':\n \n     parser = argparse.ArgumentParser(description='GAT')\n     register_data_args(parser)\n     # parser.add_argument(\"--dataset\", type=str, default='cora',\n     #                     help=\"The input dataset. Can be cora, citeseer, pubmed, syn(synthetic dataset) or reddit\")\n     parser.add_argument(\"--gpu\", type=int, default=0,\n                         help=\"which GPU to use. Set -1 to use CPU.\")\n     parser.add_argument(\"--epochs\", type=int, default=20000,\n                         help=\"number of training epochs\")\n     parser.add_argument(\"--num-heads\", type=int, default=8,\n                         help=\"number of hidden attention heads\")\n     parser.add_argument(\"--num-out-heads\", type=int, default=1,\n                         help=\"number of output attention heads\")\n     parser.add_argument(\"--num-layers\", type=int, default=1,\n                         help=\"number of hidden layers\")\n     parser.add_argument(\"--num-hidden\", type=int, default=8,\n                         help=\"number of hidden units\")\n     parser.add_argument(\"--residual\", action=\"store_true\", default=False,\n                         help=\"use residual connection\")\n     parser.add_argument(\"--in-drop\", type=float, default=.6,\n                         help=\"input feature dropout\")\n     parser.add_argument(\"--attn-drop\", type=float, default=.6,\n                         help=\"attention dropout\")\n     parser.add_argument(\"--lr\", type=float, default=0.005,\n                         help=\"learning rate\")\n     parser.add_argument('--weight-decay', type=float, default=5e-4,\n                         help=\"weight decay\")\n     parser.add_argument('--alpha', type=float, default=0.2,\n                         help=\"the negative slop of leaky relu\")\n     parser.add_argument('--fastmode', action=\"store_true\", default=False,\n                         help=\"skip re-evaluate the validation set\")\n     args = parser.parse_args()\n     print(args)\n \n     main(args)\n <denchmark-h:h2>Expected behavior</denchmark-h>\n \n I assumed that the GPU usage should keep unchanged all the time, since the size of the input graph is not changed.\n <denchmark-h:h2>Environment</denchmark-h>\n \n \n DGL Version (0.2, the lasted one until 20:48, 6/10/2019):\n Backend Library & Version (PyTorch 1.1.0):\n OS (Linux 18.04):\n How you installed DGL (source):\n Build command you used (if compiling from source):\n just build it normally with GPU-enabled\n Python version: 3.6\n CUDA/cuDNN version (if applicable): CUDA 10.2\n GPU models and configuration (e.g. V100): GTX 1080Ti\n Any other relevant information:\n \n <denchmark-h:h2>Additional context</denchmark-h>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "yangysc", "commentT": "2019-06-10T14:30:42Z", "comment_text": "\n \t\t@ylfdq1118 I remember that DGL 0.3 would cache an csr representation of the graph for operations like edge_softmax. Would you clear the cache when the graph structure changes(like the case in this issue)?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "yangysc", "commentT": "2019-06-10T16:33:46Z", "comment_text": "\n \t\t@ylfdq1118 could you have a look? It looks a like a bug of our new NN module.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "yangysc", "commentT": "2019-06-10T21:29:18Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/yangysc>@yangysc</denchmark-link>\n  <denchmark-link:https://github.com/yzh119>@yzh119</denchmark-link>\n  <denchmark-link:https://github.com/jermainewang>@jermainewang</denchmark-link>\n  The bug is, in edge_softmax operator, the backward function used a separate cache to save forward pass tensors and did not explicitly clear the cache. It's not because caching DGL graph structure.\n Similar issue was discussed <denchmark-link:https://discuss.pytorch.org/t/when-should-you-save-for-backward-vs-storing-in-ctx/6522>here</denchmark-link>\n . I will push a fix.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "yangysc", "commentT": "2019-06-11T02:07:23Z", "comment_text": "\n \t\tThanks a lot! @ylfdq1118 <denchmark-link:https://github.com/yzh119>@yzh119</denchmark-link>\n  <denchmark-link:https://github.com/jermainewang>@jermainewang</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "5549c70d337168414879bcd95f32daf817d72576", "commit_author": "Lingfan Yu", "commitT": "2019-06-10 18:44:23-04:00", "commit_complexity": {"commit_NLOC": "0.75", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\dgl\\backend\\mxnet\\tensor.py", "file_new_name": "python\\dgl\\backend\\mxnet\\tensor.py", "file_complexity": {"file_NLOC": "278", "file_CCN": "70", "file_NToken": "2492"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "313,314", "deleted_lines": null, "method_info": {"method_name": "backward", "method_params": "self,grad_out", "method_startline": "294", "method_endline": "315", "method_complexity": {"method_NLOC": "21", "method_CCN": "1", "method_NToken": "229", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\dgl\\nn\\mxnet\\softmax.py", "file_new_name": "python\\dgl\\nn\\mxnet\\softmax.py", "file_complexity": {"file_NLOC": "82", "file_CCN": "4", "file_NToken": "392"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "68,69,70", "deleted_lines": "68", "method_info": {"method_name": "backward", "method_params": "self,grad_out", "method_startline": "57", "method_endline": "80", "method_complexity": {"method_NLOC": "14", "method_CCN": "1", "method_NToken": "138", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\dgl\\nn\\pytorch\\softmax.py", "file_new_name": "python\\dgl\\nn\\pytorch\\softmax.py", "file_complexity": {"file_NLOC": "78", "file_CCN": "3", "file_NToken": "370"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "65,66", "deleted_lines": null, "method_info": {"method_name": "backward", "method_params": "ctx,grad_out", "method_startline": "54", "method_endline": "76", "method_complexity": {"method_NLOC": "13", "method_CCN": "1", "method_NToken": "136", "method_nesting_level": "1"}}}}}}}}