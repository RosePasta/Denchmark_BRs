{"BR": {"BR_id": "1046", "BR_author": "maximillian91", "BRopenT": "2019-11-26T15:42:08Z", "BRcloseT": "2020-03-23T09:59:49Z", "BR_text": {"BRsummary": "[Bug] Error when backward with retain_graph=True", "BRdescription": "\n <denchmark-h:h2>\u2753 Questions and Help</denchmark-h>\n \n Any reason for clearing the ctx.backward_cache explicitly in every backward() method?\n This is causing errors when calling loss.backward(retain_graph=True) twice:\n TypeError: 'NoneType' object is not iterable\n Here's an example:\n <denchmark-link:https://stackoverflow.com/questions/58655746/typeerror-nonetype-object-is-not-iterable-in-loss-backward-in-pytorch>typeerror-nonetype-object-is-not-iterable-in-loss-backward-in-pytorch</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "maximillian91", "commentT": "2019-11-27T16:35:04Z", "comment_text": "\n \t\tHi,\n Why you set retain_graph to true? Do you need second-order derivative?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "maximillian91", "commentT": "2019-11-27T16:54:38Z", "comment_text": "\n \t\tHypothetically yes, but did not encounter the problem for that. For me it was just a quick fix of mistakenly constructing  with required gradients, so the call of  in  2nd epoch  caused the same error as in <denchmark-link:https://stackoverflow.com/questions/58655746/typeerror-nonetype-object-is-not-iterable-in-loss-backward-in-pytorch>typeerror-nonetype-object-is-not-iterable-in-loss-backward-in-pytorch</denchmark-link>\n . In that question I think the DQN basically refer twice to the same instance of tensors and thereby meeting  in the  on the second call of it. I'm not an expert on the DQN, so might be wrong.\n Anyway I don't understand why we need to explicitly clear the backward cache, ctx.backward_cache = None. Maybe you can clarify?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "maximillian91", "commentT": "2019-11-28T06:33:59Z", "comment_text": "\n \t\tWe found if we didn't do this, the cache would not be properly cleared by pytorch, which results in memory leak.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "maximillian91", "commentT": "2019-11-28T15:03:16Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/BarclayII>@BarclayII</denchmark-link>\n  is re-confirming the memory leak issue. The latest pytorch may have already resolved this issue. Either way, this is likely a bug on our side and we never test .\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "maximillian91", "commentT": "2019-11-29T03:19:43Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/maximillian91>@maximillian91</denchmark-link>\n  Could you give a minimal example of  failing?  The following seems to work for me on the  branch.\n import dgl\n import numpy as np\n import scipy.sparse as ssp\n from dgl.nn.pytorch import SAGEConv\n import torch\n import torch.nn as nn\n \n g = dgl.DGLGraph(ssp.random(20, 20, 0.2))\n x = torch.randn(20, 10)\n m = nn.Linear(10, 20)\n g.ndata['x'] = x\n g.ndata['w'] = m(x)\n \n g.update_all(dgl.function.copy_u('w', 'm'), dgl.function.sum('m', 'y'))\n g.update_all(dgl.function.copy_u('w', 'm'), dgl.function.max('m', 'z'))\n loss = g.ndata['y'].sum()\n loss2 = g.ndata['z'].sum()\n loss.backward(retain_graph=True)\n loss2.backward()\n As per second-order derivative, I'm not sure if/when we would support it, since it needs another kernel that computes such a derivative and so far I'm not aware of any model that needs this functionality.\n As per memory leak, please see <denchmark-link:https://github.com/dmlc/dgl/pull/1060>#1060</denchmark-link>\n  , although I need to confirm a failing example of  first.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "maximillian91", "commentT": "2019-12-02T10:44:11Z", "comment_text": "\n \t\tMy \"minimal\" failing example became this based on my implementation of the Deep Tensor Neural Network <denchmark-link:https://www.nature.com/articles/ncomms13890>K. Sch\u00fctt 2017</denchmark-link>\n , where the error can be produced (and thereby also resolved) under 2 circumstances:\n \n \n The target requires gradients through the PolarGaussianExpansionLayer, so it fails on the second backward, when the cache have been cleared (even when retain_graph=True)\n \n \n The forward-pass pred = net(g) has not been called prior to the backward-pass.\n \n \n Here's the last 20 lines of the code failing and the rest is in the .zip.\n <denchmark-code>net = DTNN(\n     num_node_feats=1,\n     num_edge_feats=num_edge_feats,\n     num_latent_feats=3,\n     num_out=1,\n     stat_radi=(mu_radi_rand, sigma2_radi_rand),\n     stat_azim=(mu_azim_rand, sigma2_azim_rand)\n )\n \n pred = net(g)\n loss = F.mse_loss(pred, target)\n \n loss.backward(retain_graph=True)\n \n # BUG! 2nd call of backward causes error if forward of net is not called \n # again, even though retain_graph=True. Same problem for when loss is not\n # computed again.\n # pred = net(g)\n loss = F.mse_loss(pred, target)\n \n # BUG!\n loss.backward()\n </denchmark-code>\n \n with the following error message:\n <denchmark-code>python debug_retain_graph.py\n DGL Version: 0.4.1\n PyTorch Version: 1.3.1\n Traceback (most recent call last):\n   File \"debug_retain_graph.py\", line 240, in <module>\n     loss.backward()\n   File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/tensor.py\", line 166, in backward\n     torch.autograd.backward(self, gradient, retain_graph, create_graph)\n   File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\n     allow_unreachable=True)  # allow_unreachable flag\n   File \"/usr/local/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\", line 77, in apply\n     return self._forward_cls.backward(self, *args)\n   File \"/usr/local/anaconda3/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\", line 396, in backward\n     = ctx.backward_cache\n TypeError: 'NoneType' object is not iterable\n </denchmark-code>\n \n <denchmark-link:https://github.com/dmlc/dgl/files/3910711/debug_retain_graph.py.zip>debug_retain_graph.py.zip</denchmark-link>\n \n I know that my example is basically wrong and sloppy in the sense, that I do not need to backprob gradients through the , but I would still expect  to solve it and it seems as if <denchmark-link:https://stackoverflow.com/questions/58655746/typeerror-nonetype-object-is-not-iterable-in-loss-backward-in-pytorch>this issue</denchmark-link>\n  is more difficult to solve by correct direction of gradients. I hope this helps.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "maximillian91", "commentT": "2019-12-03T07:46:40Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/maximillian91>@maximillian91</denchmark-link>\n  Your code ran fine with the latest  branch.  Currently we only have nightly build for Linux.  Could you install from source and try again?  Thanks.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "maximillian91", "commentT": "2019-12-04T16:29:09Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/BarclayII>@BarclayII</denchmark-link>\n  I did now and the issue was solved when building from source in the latest  branch on MacOS. Seems like  has been rewritten to not clear backward cache explicitly by  since v. 0.4.1, which I was using. Thanks\n \t\t"}}}, "commit": {"commit_id": "49b406c981bc023c6db6674662f2c3ea7f920d7f", "commit_author": "Quan (Andy) Gan", "commitT": "2019-11-29 14:37:33+08:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.5", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\dgl\\backend\\pytorch\\tensor.py", "file_new_name": "python\\dgl\\backend\\pytorch\\tensor.py", "file_complexity": {"file_NLOC": "329", "file_CCN": "95", "file_NToken": "2927"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "336,338,339", "deleted_lines": "335,337", "method_info": {"method_name": "backward", "method_params": "ctx,grad_out", "method_startline": "334", "method_endline": "363", "method_complexity": {"method_NLOC": "29", "method_CCN": "6", "method_NToken": "261", "method_nesting_level": "1"}}}}}}}}