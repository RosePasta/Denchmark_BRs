{"BR": {"BR_id": "1065", "BR_author": "nickjong", "BRopenT": "2018-09-05T20:41:54Z", "BRcloseT": "2018-09-10T21:01:33Z", "BR_text": {"BRsummary": "Image deep feature extractor vulnerable to invalid model cache", "BRdescription": "\n I finally reproduced the error we've been seeing in some CI tests:\n <denchmark-code>RuntimeError: CoreML Error: Unable to extract model type from stream in compiled model: Error opening file stream: /var/folders/y5/9ghgwpqs77s9k8s7s881ng_m0000gn/T/model_cache/squeezenet_v1.1_modified.mlmodelc/coremldata.bin: unspecified iostream_category error\n </denchmark-code>\n \n Inspection of this file reveals that it doesn't exist: there's an empty squeezenet_v1.1_modified.mlmodelc directory in the model cache. (Well, the directory contains some empty subdirectories.)\n I don't know whether this invalid compiled model is the result of ordinary cleanup within a temp directory (returned by NSTemporaryDirectory) or something like a crash while writing the model in a previous run.\n Regardless, we should make this code path robust to model cache corruption. For example, if the cached model cannot be loaded, follow the no-cache path (and regenerate the model).\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "nickjong", "commentT": "2018-09-06T17:29:36Z", "comment_text": "\n \t\tThe baseline logic should be write_model && read_model.\n The current logic is (model_exists || write_model) && read_model.\n The cached version should be read_model || (write_model && read_model), cleaned up slightly to (model_exists && read_model) || (write_model && read_model).\n (In theory, it's probably actually more efficient not to check for model_exists, but currently we might spew some confusing logging when the read fails the first time.)\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "nickjong", "commentT": "2018-09-06T17:35:23Z", "comment_text": "\n \t\tThis should be P1, since any customer who gets their system into this state will be unable to use any image-feature-extractor-based toolkit until they remove the corrupted model cache from their temp directory. The failure state is somewhat persistent.\n \t\t"}}}, "commit": {"commit_id": "47dcf1c9a4e61bdbd23f4f76e44b2af7f439c2a2", "commit_author": "Nick Jong", "commitT": "2018-09-10 14:01:32-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\toolkits\\image_deep_feature_extractor\\mlmodel_image_feature_extractor.mm", "file_new_name": "src\\toolkits\\image_deep_feature_extractor\\mlmodel_image_feature_extractor.mm", "file_complexity": {"file_NLOC": "367", "file_CCN": "42", "file_NToken": "3052"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "165,166,167,168,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,191,238,240,244,245,246", "deleted_lines": "168,214,216,217,218,220,221,222,224,227", "method_info": {"method_name": "turi::image_deep_feature_extractor::create_model", "method_params": "download_path,model_name", "method_startline": "162", "method_endline": "247", "method_complexity": {"method_NLOC": "56", "method_CCN": "8", "method_NToken": "426", "method_nesting_level": "3"}}}}}}}}