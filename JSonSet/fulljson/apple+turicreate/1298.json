{"BR": {"BR_id": "1298", "BR_author": "TobyRoseman", "BRopenT": "2019-01-09T19:16:46Z", "BRcloseT": "2019-03-19T06:20:09Z", "BR_text": {"BRsummary": "Linear Regression Gives Incorrect Error Message with Image Column", "BRdescription": "\n Using the <denchmark-link:https://www.microsoft.com/en-us/download/details.aspx?id=54765>Kaggle Cats and Dogs dataset</denchmark-link>\n , the following code:\n import turicreate as tc\n import os\n data = tc.image_analysis.load_images('PetImages', with_path=True)\n data['label'] = data['path'].apply(lambda path: 'dog' if '/Dog' in path else 'cat')\n model = tc.linear_regression.create(data, target='label')\n Give the following error message: ToolkitError: Column type of target 'label' must be int or float.\n However linear regression does support string target types. The following works fine:\n data = tc.SFrame({'x': ['0', '1', '2', '99', '100', '101'], 'y':['low', 'low', 'low', 'high', 'high', 'high']})\n model = tc.linear_regression.create(data, target='y')\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "TobyRoseman", "commentT": "2019-01-23T21:02:39Z", "comment_text": "\n \t\tWell, following your example, I get:\n <denchmark-code>>>> model.predict(data)\n dtype: float\n Rows: 6\n [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n >>> model.evaluate(data)\n {'max_error': 0.0, 'rmse': 0.0}\n </denchmark-code>\n \n It doesn't seem like we're doing anything sensible with the string targets. Maybe the model training here should throw an error too?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "TobyRoseman", "commentT": "2019-03-14T19:28:52Z", "comment_text": "\n \t\tI think it's because a validation set is automatically created when the dataset_size >= 100 and the type of the target column is only checked for then. I think the fix is to do a sanity check on the target column (along with maybe other checks that are independent of creating a validation set) in the code path when no validation set is created.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "TobyRoseman", "commentT": "2019-03-14T22:06:54Z", "comment_text": "\n \t\t\n I think it's because a validation set is automatically created when the dataset_size >= 100 and the type of the target column is only checked for then. I think the fix is to do a sanity check on the target column (along with maybe other checks that are independent of creating a validation set) in the code path when no validation set is created.\n \n <denchmark-link:https://github.com/shantanuchhabra>@shantanuchhabra</denchmark-link>\n  I already fixed this issue. We went over this fix yesterday - thanks for re-iterating it here..\n \t\t"}}}, "commit": {"commit_id": "f350b19114514f9cd338bf85fdb564c176f0fe75", "commit_author": "fareeha", "commitT": "2019-03-18 23:20:08-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\unity\\toolkits\\supervised_learning\\supervised_learning.cpp", "file_new_name": "src\\unity\\toolkits\\supervised_learning\\supervised_learning.cpp", "file_complexity": {"file_NLOC": "905", "file_CCN": "139", "file_NToken": "6668"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1040,1041,1054", "deleted_lines": "1052,1053", "method_info": {"method_name": "turi::supervised::supervised_learning_model_base::api_train", "method_params": "data,target,_validation_data,_options", "method_startline": "1008", "method_endline": "1092", "method_complexity": {"method_NLOC": "56", "method_CCN": "8", "method_NToken": "447", "method_nesting_level": "2"}}}}}}}}