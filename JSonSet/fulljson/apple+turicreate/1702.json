{"BR": {"BR_id": "1702", "BR_author": "mr-sudo", "BRopenT": "2019-04-05T22:32:40Z", "BRcloseT": "2019-04-16T01:13:24Z", "BR_text": {"BRsummary": "Creating a Sound Classifier for Short Audio Clips", "BRdescription": "\n I'm trying to create a custom sound classifier and use a directory of folders for the labeling of each audio file. For example, all .wav files in the folder \"Meow\" should be labeled \"Meow\" in classifier and all .wav files in the folder \"Woof\" should be labeled \"Woof\". After modifying the <denchmark-link:https://apple.github.io/turicreate/docs/userguide/sound_classifier/>Sound Classifier Example</denchmark-link>\n , I ended up with this code:\n \n # Load the input data from the directories.\n data = tc.load_audio('./Audio/', with_path=True)\n data['label'] = data['path'].apply(lambda p: os.path.basename(os.path.dirname(p)))\n data.save('classifier.sframe')\n data = tc.SFrame('classifier.sframe')\n # Make a train-test split\n test_set, train_set = data.random_split(0.8)\n # Create the model.\n model = tc.sound_classifier.create(train_set, target='label', feature='audio')\n # Generate an SArray of predictions from the test set.\n data = model.predict(test_set)\n # Evaluate the model and print the results\n metrics = model.evaluate(test_set)\n \n However, when I try to execute 'model.predict', I receive an error message:\n \n \"Input SArrays 'targets' and 'predictions' must be of the same length.\"\n \n \n What causes this error message and how can I train a custom classifier using the approach above? I looked for the cause of the message online and it seems like it might have to do with a mismatch in the column lengths from the source data.\n Do audio files have to be in a particular format for the classifier to work correctly? The audio files I'm working with have variable durations, bitrates, etc. I thought this might be causing the error above, but after converting the files to a standard format the issue persisted.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "mr-sudo", "commentT": "2019-04-06T00:23:47Z", "comment_text": "\n \t\tAfter looking at the code I believe I've identified the issue. I'm able to reproduce this problem myself. It doesn't have anything to do with using the directory to get labels. Your code for that looks good to me.\n In order for the sound classifier to use an audio clip it basically needs to be at least a second long (well 975 milliseconds to be precise). Unfortunately there is a bug in what the sound classifier does when it's asked to make a prediction for a clip which is too short. It's silently dropping it. So if you pass in an SFrame for ten wav files but one of them isn't long enough, you only get nine predictions out. This is a bug.\n To answer your second question: we can currently only read wav files. So the only limitations should be that it needs to be a wav file which is at least 975 milliseconds long.\n As a temporary work around, please try filtering out audio clicks that are less than 975 milliseconds. This can be done using the following code right before your train/test split:\n def is_at_least_min_length(audio_dict):\n      num_samples = len(audio_dict['data'])\n      audio_length = num_samples / float(audio_dict['sample_rate'])\n      return audio_length > .975\n \n data['is_long_enought'] = data['audio'].apply(is_at_least_min_length)\n data = data.filter_by([1], 'is_long_enought')\n Please let me know if that works.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "mr-sudo", "commentT": "2019-04-06T08:51:10Z", "comment_text": "\n \t\tThank you very much for your responsive help with this bug <denchmark-link:https://github.com/TobyRoseman>@TobyRoseman</denchmark-link>\n . The simple check did resolve the issue and I'll be sure to use audio files that are at least one second long for training! With that being said, it would be also be great to see support for shorter audio clips in the future.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "mr-sudo", "commentT": "2019-04-08T23:38:06Z", "comment_text": "\n \t\t@madebysasha thanks for confirming the work around. I've created <denchmark-link:https://github.com/apple/turicreate/issues/1712>#1712</denchmark-link>\n  to track the Sound Classifier using clips which are less than a second. If you have ideas about how to use shorter clips, please add them to that issue.\n Let's make this issue solely about the fixing this bug. I want to make sure that this bug is fixed in our next release. An enhancement to use clips which are less than a second will take more time.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "mr-sudo", "commentT": "2019-04-09T08:21:39Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/TobyRoseman>@TobyRoseman</denchmark-link>\n  Fantastic, I'll keep my eye on the new thread.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "mr-sudo", "commentT": "2019-04-09T18:01:33Z", "comment_text": "\n \t\tLet's leave this open till I fix the bug, i.e. until we can call predict with short clips and it doesn't break things.\n \t\t"}}}, "commit": {"commit_id": "f5b32c05a90f91792535c7477a3d2c9580378cfc", "commit_author": "Toby Roseman", "commitT": "2019-04-15 18:13:24-07:00", "commit_complexity": {"commit_NLOC": "0.2537313432835821", "commit_CCN": "0.6268656716417911", "commit_Nprams": "0.5373134328358209"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "src\\unity\\python\\turicreate\\test\\test_audio_functionality.py", "file_new_name": "src\\unity\\python\\turicreate\\test\\test_audio_functionality.py", "file_complexity": {"file_NLOC": "338", "file_CCN": "53", "file_NToken": "3582"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376", "deleted_lines": null, "method_info": {"method_name": "test_model", "method_params": "self", "method_startline": "346", "method_endline": "376", "method_complexity": {"method_NLOC": "25", "method_CCN": "5", "method_NToken": "279", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "341,342,343,344", "deleted_lines": null, "method_info": {"method_name": "test_get_deep_features", "method_params": "self", "method_startline": "341", "method_endline": "344", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "49", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "331,332,333,334,335,336,337,338,339", "deleted_lines": null, "method_info": {"method_name": "setUpClass", "method_params": "self", "method_startline": "331", "method_endline": "339", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "91", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\unity\\python\\turicreate\\toolkits\\sound_classifier\\_audio_feature_extractor.py", "file_new_name": "src\\unity\\python\\turicreate\\toolkits\\sound_classifier\\_audio_feature_extractor.py", "file_complexity": {"file_NLOC": "138", "file_CCN": "35", "file_NToken": "1281"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "179,180,181,182,183,184,185,186", "deleted_lines": null, "method_info": {"method_name": "get_deep_features", "method_params": "self,audio_data,verbose", "method_startline": "170", "method_endline": "188", "method_complexity": {"method_NLOC": "13", "method_CCN": "3", "method_NToken": "141", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "src\\unity\\python\\turicreate\\toolkits\\sound_classifier\\sound_classifier.py", "file_new_name": "src\\unity\\python\\turicreate\\toolkits\\sound_classifier\\sound_classifier.py", "file_complexity": {"file_NLOC": "480", "file_CCN": "74", "file_NToken": "4182"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,575,578,583,585,587,589,591,593,595,597", "deleted_lines": "551,554,559,561,563,565,567,569,571,573", "method_info": {"method_name": "evaluate", "method_params": "self,dataset,metric,verbose,batch_size", "method_startline": "488", "method_endline": "599", "method_complexity": {"method_NLOC": "51", "method_CCN": "17", "method_NToken": "508", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "800,801,802,803,804,805,833,838,839,840,841,842,843,844,845,846,847,848", "deleted_lines": "776,802,805,810,811", "method_info": {"method_name": "predict", "method_params": "self,dataset,output_type,verbose,batch_size", "method_startline": "721", "method_endline": "848", "method_complexity": {"method_NLOC": "65", "method_CCN": "21", "method_NToken": "659", "method_nesting_level": "1"}}}}}}}}