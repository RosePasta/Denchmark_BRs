{"BR": {"BR_id": "2690", "BR_author": "hkvision", "BRopenT": "2020-08-07T10:20:08Z", "BRcloseT": "2020-09-16T01:15:37Z", "BR_text": {"BRsummary": "Should not let users export PYTHONHOME for PyTorch example local mode", "BRdescription": "\n I run pytorch/train/mnist/main.py on Spark local and get the following error after the training:\n <denchmark-code>java.lang.IllegalArgumentException: requirement failed\n \tat scala.Predef$.require(Predef.scala:212)\n \tat com.intel.analytics.zoo.feature.PythonFeatureSet$.toArrayTensor(FeatureSet.scala:390)\n \tat com.intel.analytics.zoo.pipeline.api.net.TorchModel.getExtraParameter(TorchModel.scala:188)\n \tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalOptimizerUtil$$anonfun$8.apply(Topology.scala:1041)\n \tat com.intel.analytics.zoo.pipeline.api.keras.models.InternalOptimizerUtil$$anonfun$8.apply(Topology.scala:1041)\n \tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n \tat scala.collection.Iterator$$anon$10.next(Iterator.scala:394)\n \tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n \tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n \tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n \tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n \tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n \tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\n \tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n \tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\n \tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n \tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\n \tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n \tat org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)\n \tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n \tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)\n \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n \tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n \tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n \tat java.lang.Thread.run(Thread.java:748)\n </denchmark-code>\n \n Also:\n \n Is the following warning expected? Look quite like an error stack actually:\n \n <denchmark-code>Warn: jep.JepException: <class 'NameError'>: name 'loader3b553ae7_0_iter_true' is not defined\n \tat <string>.<module>(<string>:2)\n \tat jep.Jep.exec(Native Method)\n \tat jep.Jep.exec(Jep.java:478)\n \tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:94)\n \tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n \tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n \tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n \tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n \tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n \tat java.lang.Thread.run(Thread.java:748)\n \n Warn: jep.JepException: <class 'StopIteration'>\n \tat jep.Jep.exec(Native Method)\n \tat jep.Jep.exec(Jep.java:478)\n \tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:94)\n \tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n \tat com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n \tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n \tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n \tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n \tat java.lang.Thread.run(Thread.java:748)\n </denchmark-code>\n \n \n Seems if JEP is not installed, the program would crash? Can we instead raise some error on Python side directly?\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "hkvision", "commentT": "2020-08-07T11:11:22Z", "comment_text": "\n \t\tYes, we need to improve the error checking and error message\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "hkvision", "commentT": "2020-08-10T02:30:31Z", "comment_text": "\n \t\tThe error is thrown after training&validation finished, when optimizer try to get extraparameters.\n This bug is fixing in <denchmark-link:https://github.com/intel-analytics/analytics-zoo/pull/2630>#2630</denchmark-link>\n .\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "hkvision", "commentT": "2020-08-10T02:32:21Z", "comment_text": "\n \t\tSix issues in total:\n \n java.lang.IllegalArgumentException: requirement failed showed above.\n In the README: https://github.com/intel-analytics/analytics-zoo/tree/master/pyzoo/zoo/examples/pytorch/train/mnist\n \n <denchmark-code>conda install pytorch-cpu torchvision-cpu -c pytorch #command for linux\n </denchmark-code>\n \n This will install pytorch 1.1.0 but not 1.5.0 as guided in the readme.\n \n In README, hdfs dfs -put /tmp/zoo/dogs_cats dogs_cats  This sentence is wrong.\n Not installing JEP would cause the program to crash. Better detect first on Python side.\n [Low priority] For local mode, users need to manually set PYTHONHOME. Actually this can be detected in code instead of setting by users.\n [Low priority] The warning stack of JEP may not be friendly to users, seems like to be an error stack.\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "hkvision", "commentT": "2020-08-31T07:38:37Z", "comment_text": "\n \t\tBetter fix the issue of letting users export PYTHONHOME for running PyTorch example in local mode. This environment variable would affect other programs, for example conda-pack and conda install.\n If I first run on local mode and export PYTHONHOME, then I want to run for yarn-client mode without starting a new session or cleaning the environment variables, it would throw the following error:\n <denchmark-code>Start to pack current python env\n Collecting packages...\n CondaPackError: Failed to determine path to environment: 'orca-kai'. This may be due to conda not being on your PATH. The full error is below:\n \n b''\n </denchmark-code>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "hkvision", "commentT": "2020-09-16T01:15:37Z", "comment_text": "\n \t\tFixed in <denchmark-link:https://github.com/intel-analytics/analytics-zoo/pull/2869>#2869</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "60a4bf24b39c9f139dac814cef26b7e1a5d84044", "commit_author": "Xin Qiu", "commitT": "2020-08-20 11:31:53+08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pyzoo\\zoo\\examples\\pytorch\\train\\mnist\\README.md", "file_new_name": "pyzoo\\zoo\\examples\\pytorch\\train\\mnist\\README.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "7,8,19", "deleted_lines": "7,8,19,53"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pyzoo\\zoo\\pipeline\\api\\torch\\torch_loss.py", "file_new_name": "pyzoo\\zoo\\pipeline\\api\\torch\\torch_loss.py", "file_complexity": {"file_NLOC": "21", "file_CCN": "2", "file_NToken": "109"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "19,25,26,27", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pyzoo\\zoo\\pipeline\\api\\torch\\torch_model.py", "file_new_name": "pyzoo\\zoo\\pipeline\\api\\torch\\torch_model.py", "file_complexity": {"file_NLOC": "50", "file_CCN": "6", "file_NToken": "343"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "25,31,32,33", "deleted_lines": null}}}}}}