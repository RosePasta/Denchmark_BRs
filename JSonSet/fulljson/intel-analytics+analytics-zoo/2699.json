{"BR": {"BR_id": "2699", "BR_author": "hkvision", "BRopenT": "2020-08-10T10:44:28Z", "BRcloseT": "2020-09-09T02:01:07Z", "BR_text": {"BRsummary": "Error when running PyTorch example", "BRdescription": "\n I run pytorch/train/mnist/main.py on YARN Almaren cluster and get the following error:\n <denchmark-code>[Stage 1:>                                                          (0 + 2) / 2]2020-08-10 18:43:28 ERROR TaskSetManager:70 - Task 1 in stage 1.0 failed 1 times; aborting job\n Traceback (most recent call last):\n   File \"main.py\", line 124, in <module>\n     main()\n   File \"main.py\", line 113, in main\n     train_featureset = FeatureSet.pytorch_dataloader(train_loader)\n   File \"/opt/work/client/anaconda3/envs/standalone/lib/python3.6/site-packages/zoo/feature/common.py\", line 383, in pytorch_dataloader\n     jvalue = callZooFunc(bigdl_type, \"createFeatureSetFromPyTorch\", bys)\n   File \"/opt/work/client/anaconda3/envs/standalone/lib/python3.6/site-packages/zoo/common/utils.py\", line 133, in callZooFunc\n     raise e\n   File \"/opt/work/client/anaconda3/envs/standalone/lib/python3.6/site-packages/zoo/common/utils.py\", line 127, in callZooFunc\n     java_result = api(*args)\n   File \"/opt/work/client/anaconda3/envs/standalone/lib/python3.6/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n     answer, self.gateway_client, self.target_id, self.name)\n   File \"/opt/work/client/anaconda3/envs/standalone/lib/python3.6/site-packages/py4j/protocol.py\", line 328, in get_return_value\n     format(target_id, \".\", name), value)\n py4j.protocol.Py4JJavaError: An error occurred while calling o67.createFeatureSetFromPyTorch.\n : org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 1 times, most recent failure: Lost task 1.0 in stage 1.0 (TID 3, Almaren-Node-058, executor 2): jep.JepException: jep.JepException: <class 'zipimport.ZipImportError'>: can't decompress data; zlib not available\n         at com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:87)\n         at com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:96)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$$anonfun$loadPythonSet$1.apply(FeatureSet.scala:358)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$$anonfun$loadPythonSet$1.apply(FeatureSet.scala:354)\n         at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n         at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n         at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n         at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n         at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n         at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n         at org.apache.spark.scheduler.Task.run(Task.scala:121)\n         at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n         at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n         at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n         at java.lang.Thread.run(Thread.java:745)\n Caused by: jep.JepException: <class 'zipimport.ZipImportError'>: can't decompress data; zlib not available\n         at <string>.<module>(<string>:2)\n         at jep.Jep.exec(Native Method)\n         at jep.Jep.exec(Jep.java:478)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:94)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n         at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n         at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n         at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n         ... 3 more\n \n Driver stacktrace:\n         at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n         at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n         at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n         at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n         at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n         at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n         at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n         at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n         at scala.Option.foreach(Option.scala:257)\n         at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n         at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n         at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n         at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n         at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n         at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n         at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n         at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n         at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n         at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n         at org.apache.spark.rdd.RDD.count(RDD.scala:1168)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$.loadPythonSet(FeatureSet.scala:366)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet.<init>(FeatureSet.scala:428)\n         at com.intel.analytics.zoo.feature.FeatureSet$.python(FeatureSet.scala:648)\n         at com.intel.analytics.zoo.feature.python.PythonFeatureSet.createFeatureSetFromPyTorch(PythonFeatureSet.scala:189)\n         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n         at java.lang.reflect.Method.invoke(Method.java:497)\n         at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n         at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n         at py4j.Gateway.invoke(Gateway.java:282)\n         at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n         at py4j.commands.CallCommand.execute(CallCommand.java:79)\n         at py4j.GatewayConnection.run(GatewayConnection.java:238)\n         at java.lang.Thread.run(Thread.java:745)\n Caused by: jep.JepException: jep.JepException: <class 'zipimport.ZipImportError'>: can't decompress data; zlib not available\n         at com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:87)\n         at com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:96)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$$anonfun$loadPythonSet$1.apply(FeatureSet.scala:358)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$$anonfun$loadPythonSet$1.apply(FeatureSet.scala:354)\n         at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n         at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n         at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n         at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n         at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n         at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n         at org.apache.spark.scheduler.Task.run(Task.scala:121)\n         at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n         at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n         at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n         ... 1 more\n Caused by: jep.JepException: <class 'zipimport.ZipImportError'>: can't decompress data; zlib not available\n         at <string>.<module>(<string>:2)\n         at jep.Jep.exec(Native Method)\n         at jep.Jep.exec(Jep.java:478)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:94)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n         at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n         at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n         at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n         ... 3 more\n </denchmark-code>\n \n Am I doing anything wrong or it is related to executor no zlib?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "hkvision", "commentT": "2020-08-11T08:10:59Z", "comment_text": "\n \t\tYou should use python3.7\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "hkvision", "commentT": "2020-08-14T08:15:38Z", "comment_text": "\n \t\tadd version check in <denchmark-link:https://github.com/intel-analytics/analytics-zoo/pull/2630>#2630</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "hkvision", "commentT": "2020-08-31T06:42:06Z", "comment_text": "\n \t\tI used Python 3.7 running <denchmark-link:https://github.com/intel-analytics/analytics-zoo/blob/master/pyzoo/zoo/examples/orca/learn/bigdl/pytorch/mnist/lenet_mnist.py>https://github.com/intel-analytics/analytics-zoo/blob/master/pyzoo/zoo/examples/orca/learn/bigdl/pytorch/mnist/lenet_mnist.py</denchmark-link>\n  but still got this error:\n <denchmark-code>Traceback (most recent call last):\n   File \"pytorch_lenet_mnist.py\", line 113, in <module>\n     main()\n   File \"pytorch_lenet_mnist.py\", line 107, in main\n     validation_methods=[Accuracy()], checkpoint_trigger=EveryEpoch())\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/zoo/orca/learn/pytorch/estimator.py\", line 209, in fit\n     train_feature_set = FeatureSet.pytorch_dataloader(data, \"\", \"\")\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/zoo/feature/common.py\", line 389, in pytorch_dataloader\n     False, features, labels)\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/zoo/common/utils.py\", line 133, in callZooFunc\n     raise e\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/zoo/common/utils.py\", line 127, in callZooFunc\n     java_result = api(*args)\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n     answer, self.gateway_client, self.target_id, self.name)\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/py4j/protocol.py\", line 328, in get_return_value\n     format(target_id, \".\", name), value)\n py4j.protocol.Py4JJavaError: An error occurred while calling o67.createFeatureSetFromPyTorch.\n : org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3.0 (TID 19, Almaren-Node-056, executor 1): jep.JepException: jep.JepException: <class 'zipimport.ZipImportError'>: can't decompress data; zlib not available\n         at com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:87)\n         at com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:96)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$$anonfun$loadPythonSet$1.apply(FeatureSet.scala:358)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$$anonfun$loadPythonSet$1.apply(FeatureSet.scala:354)\n         at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n         at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n </denchmark-code>\n \n Please take a look.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "hkvision", "commentT": "2020-08-31T07:11:48Z", "comment_text": "\n \t\tWhen I run in local, got the following error:\n <denchmark-code>Caused by: jep.JepException: <class 'ImportError'>: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/torch/lib/libshm.so)\n         at /opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/torch/__init__.<module>(__init__.py:136)\n         at <string>.<module>(<string>:6)\n         at jep.Jep.exec(Native Method)\n         at jep.Jep.exec(Jep.java:478)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:94)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n         at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n         at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n         at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n         ... 3 more\n </denchmark-code>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "hkvision", "commentT": "2020-08-31T08:35:32Z", "comment_text": "\n \t\tlocal error can't be reproduced. probably is my environment issue. Will confirm it later.\n YARN error can be reproduced by <denchmark-link:https://github.com/qiuxin2012>@qiuxin2012</denchmark-link>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "hkvision", "commentT": "2020-08-31T09:10:05Z", "comment_text": "\n \t\t\n When I run in local, got the following error:\n Caused by: jep.JepException: <class 'ImportError'>: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/torch/lib/libshm.so)\n         at /opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/torch/__init__.<module>(__init__.py:136)\n         at <string>.<module>(<string>:6)\n         at jep.Jep.exec(Native Method)\n         at jep.Jep.exec(Jep.java:478)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply$mcV$sp(PythonInterpreter.scala:94)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n         at com.intel.analytics.zoo.common.PythonInterpreter$$anonfun$1.apply(PythonInterpreter.scala:93)\n         at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n         at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n         at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n         at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n         ... 3 more\n \n \n Seems something wrong in your torch.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "hkvision", "commentT": "2020-08-31T09:13:53Z", "comment_text": "\n \t\t\n I used Python 3.7 running https://github.com/intel-analytics/analytics-zoo/blob/master/pyzoo/zoo/examples/orca/learn/bigdl/pytorch/mnist/lenet_mnist.py but still got this error:\n Traceback (most recent call last):\n   File \"pytorch_lenet_mnist.py\", line 113, in <module>\n     main()\n   File \"pytorch_lenet_mnist.py\", line 107, in main\n     validation_methods=[Accuracy()], checkpoint_trigger=EveryEpoch())\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/zoo/orca/learn/pytorch/estimator.py\", line 209, in fit\n     train_feature_set = FeatureSet.pytorch_dataloader(data, \"\", \"\")\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/zoo/feature/common.py\", line 389, in pytorch_dataloader\n     False, features, labels)\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/zoo/common/utils.py\", line 133, in callZooFunc\n     raise e\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/zoo/common/utils.py\", line 127, in callZooFunc\n     java_result = api(*args)\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1257, in __call__\n     answer, self.gateway_client, self.target_id, self.name)\n   File \"/opt/work/client/anaconda3/envs/orca-kai/lib/python3.7/site-packages/py4j/protocol.py\", line 328, in get_return_value\n     format(target_id, \".\", name), value)\n py4j.protocol.Py4JJavaError: An error occurred while calling o67.createFeatureSetFromPyTorch.\n : org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3.0 (TID 19, Almaren-Node-056, executor 1): jep.JepException: jep.JepException: <class 'zipimport.ZipImportError'>: can't decompress data; zlib not available\n         at com.intel.analytics.zoo.common.PythonInterpreter$.threadExecute(PythonInterpreter.scala:87)\n         at com.intel.analytics.zoo.common.PythonInterpreter$.exec(PythonInterpreter.scala:96)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$$anonfun$loadPythonSet$1.apply(FeatureSet.scala:358)\n         at com.intel.analytics.zoo.feature.PythonFeatureSet$$anonfun$loadPythonSet$1.apply(FeatureSet.scala:354)\n         at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n         at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801)\n \n Please take a look.\n \n Based on my previous experience on Centos7.5,  you should install zlib on your yarn nodemanager and update python to 3.7.\n <denchmark-link:https://unix.stackexchange.com/questions/291737/zipimport-zipimporterror-cant-decompress-data-zlib-not-available/334103>https://unix.stackexchange.com/questions/291737/zipimport-zipimporterror-cant-decompress-data-zlib-not-available/334103</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "e4c9453de3745d9ae334de94a1caa6c74a00bf76", "commit_author": "Xin Qiu", "commitT": "2020-09-09 10:01:06+08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pyzoo\\zoo\\util\\spark.py", "file_new_name": "pyzoo\\zoo\\util\\spark.py", "file_complexity": {"file_NLOC": "227", "file_CCN": "12", "file_NToken": "1425"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "18,103,104,106,107", "deleted_lines": "103"}}}}}}