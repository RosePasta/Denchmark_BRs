{"BR": {"BR_id": "1566", "BR_author": "shakhyar", "BRopenT": "2020-12-16T11:17:09Z", "BRcloseT": "2020-12-18T04:57:17Z", "BR_text": {"BRsummary": "ModuleNotFoundError: No module named 'transformers.tokenization_bert'", "BRdescription": "\n Hello. I am getting an error.\n I was using the<denchmark-link:https://colab.research.google.com/github/NVIDIA/NeMo/blob/v1.0.0b2/tutorials/nlp/Text_Classification_Sentiment_Analysis.ipynb#scrollTo=dzqD2WDFOIN-> Sentiment analysis notebook</denchmark-link>\n  on colab by NVIDIA NeMo\n I followed the instructions as it said(run the first cell if you are on colab and vice versa).\n In the second cell, it is said that restart runtime after running it. After restarting kernal, (or even if I don't) I am getting this error:\n . It is from the first import of the 3rd cell,\n \n The full traceback is:\n <denchmark-code>ModuleNotFoundError                       Traceback (most recent call last)\n <ipython-input-6-9dea72b2f46b> in <module>()\n ----> 1 from nemo.collections import nlp as nemo_nlp\n       2 from nemo.utils.exp_manager import exp_manager\n       3 \n       4 import os\n       5 import wget\n \n 3 frames\n /usr/local/lib/python3.6/dist-packages/nemo/collections/nlp/__init__.py in <module>()\n      13 # limitations under the License.\n      14 \n ---> 15 from nemo.collections.nlp import data, models, modules\n      16 from nemo.package_info import __version__\n      17 \n \n /usr/local/lib/python3.6/dist-packages/nemo/collections/nlp/data/__init__.py in <module>()\n      25     NeuralMachineTranslationDataset,\n      26 )\n ---> 27 from nemo.collections.nlp.data.question_answering_squad.qa_dataset import SquadDataset\n      28 from nemo.collections.nlp.data.token_classification.token_classification_dataset import (\n      29     BertTokenClassificationDataset,\n \n /usr/local/lib/python3.6/dist-packages/nemo/collections/nlp/data/question_answering_squad/qa_dataset.py in <module>()\n      26 \n      27 from nemo.collections.common.parts.utils import _compute_softmax\n ---> 28 from nemo.collections.nlp.data.question_answering_squad.qa_squad_processing import (\n      29     EVALUATION_MODE,\n      30     INFERENCE_MODE,\n \n /usr/local/lib/python3.6/dist-packages/nemo/collections/nlp/data/question_answering_squad/qa_squad_processing.py in <module>()\n      20 \n      21 from tqdm import tqdm\n ---> 22 from transformers.tokenization_bert import BasicTokenizer\n      23 \n      24 from nemo.collections.nlp.data.data_utils import DataProcessor, is_whitespace, normalize_answer\n \n ModuleNotFoundError: No module named 'transformers.tokenization_bert'\n \n ---------------------------------------------------------------------------\n NOTE: If your import is failing due to a missing package, you can\n manually install dependencies using either !pip or !apt.\n \n To view examples of installing some common dependencies, click the\n \"Open Examples\" button below.\n ---------------------------------------------------------------------------\n </denchmark-code>\n \n I tried searching stack overflow, but it didn't helped. And I don't want to tinker the main NeMo module myself cause I don't know what might go wrong if I change something.\n What shall I do?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "shakhyar", "commentT": "2020-12-16T13:18:13Z", "comment_text": "\n \t\tI am also getting this error\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "shakhyar", "commentT": "2020-12-16T13:30:13Z", "comment_text": "\n \t\tIt looks like the latest version of transformers (4.0.1) is being installed. I reverted to 3.5, and the code works.\n Before importing nemo.collections, run the following and it should work:\n <denchmark-code>!pip uninstall transformers\n !pip install transformers==3.5\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "shakhyar", "commentT": "2020-12-17T08:25:46Z", "comment_text": "\n \t\tThanks it worked for that cell, however <denchmark-link:https://colab.research.google.com/github/NVIDIA/NeMo/blob/v1.0.0b2/tutorials/nlp/Text_Classification_Sentiment_Analysis.ipynb#scrollTo=NgsGLydWo-6->here</denchmark-link>\n   I am getting another error, traceback is:\n <denchmark-code>Using bos_token, but it is not set yet.\n Using eos_token, but it is not set yet.\n ---------------------------------------------------------------------------\n FileNotFoundError                         Traceback (most recent call last)\n <ipython-input-31-543503bf2763> in <module>()\n ----> 1 model = nemo_nlp.models.TextClassificationModel(cfg=config.model, trainer=trainer)\n \n 4 frames\n /usr/local/lib/python3.6/dist-packages/nemo/collections/nlp/models/text_classification/text_classification_model.py in __init__(self, cfg, trainer)\n      58 \n      59         # init superclass\n ---> 60         super().__init__(cfg=cfg, trainer=trainer)\n      61 \n      62         self.bert_model = get_lm_model(\n \n /usr/local/lib/python3.6/dist-packages/nemo/collections/nlp/models/nlp_model.py in __init__(self, cfg, trainer)\n      35 \n      36     def __init__(self, cfg: DictConfig, trainer: Trainer = None):\n ---> 37         super().__init__(cfg, trainer)\n      38         self.bert_model = None  # Pretrained BERT encoder\n      39         self.set_world_size(trainer)\n \n /usr/local/lib/python3.6/dist-packages/nemo/core/classes/modelPT.py in __init__(self, cfg, trainer)\n      97         if self._cfg is not None and not self.__is_model_being_restored():\n      98             if 'train_ds' in self._cfg and self._cfg.train_ds is not None:\n ---> 99                 self.setup_training_data(self._cfg.train_ds)\n     100 \n     101             if 'validation_ds' in self._cfg and self._cfg.validation_ds is not None:\n \n /usr/local/lib/python3.6/dist-packages/nemo/collections/nlp/models/text_classification/text_classification_model.py in setup_training_data(self, train_data_config)\n     206             self._test_dl = None\n     207             return\n --> 208         self._train_dl = self._setup_dataloader_from_config(cfg=train_data_config)\n     209 \n     210     def setup_validation_data(self, val_data_config: Optional[DictConfig]):\n \n /usr/local/lib/python3.6/dist-packages/nemo/collections/nlp/models/text_classification/text_classification_model.py in _setup_dataloader_from_config(self, cfg)\n     235                 The label of the example is separated with TAB at the end of each line. \\n\\\n     236                 Each line of the files should follow the format: \\n\\\n --> 237                 [WORD][SPACE][WORD][SPACE][WORD][...][TAB][LABEL]'\n     238             )\n     239 \n \n FileNotFoundError: DATA_DIR/SST-2/train_nemo_format.tsv not found! The data should be be stored in TAB-separated files \n                 \"validation_ds.file_path\" and \"train_ds.file_path\" for train and evaluation respectively. \n                 Each line of the files contains text sequences, where words are separated with spaces. \n                 The label of the example is separated with TAB at the end of each line. \n                 Each line of the files should follow the format: \n                 [WORD][SPACE][WORD][SPACE][WORD][...][TAB][LABEL]\n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "shakhyar", "commentT": "2020-12-17T15:58:47Z", "comment_text": "\n \t\tDid you create DATA_DIR/SST-2/train_nemo_format.tsv?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "shakhyar", "commentT": "2020-12-18T11:32:31Z", "comment_text": "\n \t\tI think we'd better use the new version to solve the problem , not to always use the older version 3.5 tranformers to solve it.\n \t\t"}}}, "commit": {"commit_id": "dd35d6849f4dc9facf138bd4e380237d6e5fcbea", "commit_author": "Evelina", "commitT": "2020-12-17 20:57:16-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "README.rst", "file_new_name": "README.rst", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "74,191,194,197,200,203,206,209,212,215,218,221,224,227,230,233,236,239,242,246", "deleted_lines": "74,191,194,197,200,203,206,209,212,215,218,221,224,227,230,233,236,239,242,246"}}}}}}