{"BR": {"BR_id": "215", "BR_author": "zkx741481546", "BRopenT": "2020-09-12T02:51:26Z", "BRcloseT": "2020-09-16T09:43:20Z", "BR_text": {"BRsummary": "PER weight does not support customized replay buffer", "BRdescription": "\n \n  I have marked all applicable categories:\n \n  exception-raising bug\n  RL algorithm bug\n  documentation request (i.e. \"X is missing from the documentation.\")\n  new feature request\n \n \n  I have visited the source website\n  I have searched through the issue tracker for duplicates\n  I have mentioned version numbers, operating system and environment, where applicable:\n \n I'm running TD3 with the newest version of tianshou, and when calling td3.learn, there is an exception raised due to td1 is a tensor but weight is a numpy.ndarray, the pytorch automatically turn td1 tensor into numpy.ndarray. But I'm running on gpu, so here comes the exception.\n Here is the code that raised exception:\n def learn(self, batch: Batch, **kwargs) -> Dict[str, float]:\n     weight = batch.pop('weight', 1.)\n     # critic 1\n     current_q1 = self.critic1(batch.obs, batch.act).flatten()\n     target_q = batch.returns.flatten()\n     td1 = current_q1 - target_q\n     critic1_loss = (td1.pow(2) * weight).mean() ------exception\n <denchmark-code>Epoch #1:   0%|          | 0/1 [00:21<?, ?it/s]\n Traceback (most recent call last):\n   File \"D:/PycharmProjects/Stable-BaselineTrading/Tianshou/TD3.py\", line 85, in <module>\n     save_fn=lambda p: torch.save(p.state_dict(), save_dir))\n   File \"D:\\PycharmProjects\\Stable-BaselineTrading\\Tianshou\\Trainer\\offpolicy.py\", line 110, in offpolicy_trainer\n     losses = policy.update(batch_size, train_collector.buffer)\n   File \"C:\\Users\\zkx74\\Anaconda3\\envs\\RL\\lib\\site-packages\\tianshou\\policy\\base.py\", line 147, in update\n     result = self.learn(batch, *args, **kwargs)\n   File \"C:\\Users\\zkx74\\Anaconda3\\envs\\RL\\lib\\site-packages\\tianshou\\policy\\modelfree\\td3.py\", line 123, in learn\n     critic1_loss = (td1.pow(2) * weight).mean()\n   File \"C:\\Users\\zkx74\\Anaconda3\\envs\\RL\\lib\\site-packages\\torch\\tensor.py\", line 480, in __array__\n     return self.numpy()\n TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n </denchmark-code>\n \n By the way, it's very odd that I can run this code normally on centos gpu server without this error.\n Here is my env version:\n <denchmark-code>numpy 1.19.0\n torch 1.6.0\n cuda 10.1\n tianshou 0.2.7\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "zkx741481546", "commentT": "2020-09-12T02:55:36Z", "comment_text": "\n \t\tI think the best way to fix this is detect is the td_error is a tensor on gpu, and convert weight to a tensor saved on the same device\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "zkx741481546", "commentT": "2020-09-12T03:03:32Z", "comment_text": "\n \t\tCould you please provide some other details? In my own Linux computer, it doesn't have such an exception.\n --> Your os platform is win10? Did you use PER in TD3?\n And add one line before    critic1_loss = (td1.pow(2) * weight).mean():\n print(td1.dtype, type(weight), weight.dtype, batch.weight)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "zkx741481546", "commentT": "2020-09-12T03:30:12Z", "comment_text": "\n \t\t\n Could you please provide some other details? In my own Linux computer, it doesn't have such an exception.\n --> Your os platform is win10? Did you use PER in TD3?\n And add one line before  critic1_loss = (td1.pow(2) * weight).mean():\n print(td1.dtype, type(weight), weight.dtype, batch.weight)\n \n I'm running on win10 with PER in TD3. Oh, I customized my own PER based on last version, maybe it's because I didn't update it to this version, I will check my code and reply later.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "zkx741481546", "commentT": "2020-09-12T03:32:34Z", "comment_text": "\n \t\tPossibly it is because you create a new class which doesn't inherit the PrioritizedReplayBuffer class, which fails the checking in BasePolicy\n \n \n \n tianshou/tianshou/policy/base.py\n \n \n         Lines 246 to 248\n       in\n       16d8e9b\n \n \n \n \n \n \n  # prio buffer update \n \n \n \n  if isinstance(buffer, PrioritizedReplayBuffer): \n \n \n \n  batch.weight = to_torch_as(batch.weight, target_q_torch) \n \n \n \n \n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "zkx741481546", "commentT": "2020-09-12T07:42:02Z", "comment_text": "\n \t\t\n Possibly it is because you create a new class which doesn't inherit the PrioritizedReplayBuffer class, which fails the checking in BasePolicy\n \n \n \n tianshou/tianshou/policy/base.py\n \n \n         Lines 246 to 248\n       in\n       16d8e9b\n \n \n \n \n \n \n  # prio buffer update \n \n \n \n  if isinstance(buffer, PrioritizedReplayBuffer): \n \n \n \n  batch.weight = to_torch_as(batch.weight, target_q_torch) \n \n \n \n \n \n \n I customized a StockReplayBuffer class inherit the ReplayBuffer class, and implement a StockPrioritizedReplayBuffer class inherit the StockReplayBuffer class, both of them overwrite the add method.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "zkx741481546", "commentT": "2020-09-12T07:43:39Z", "comment_text": "\n \t\tBut, if you want to use the prioritized experience replay's feature, plz inherit PrioritizedReplayBuffer instead of ReplayBuffer. Or change the line in BasePolicy as listed above to:\n     if isinstance(buffer, (PrioritizedReplayBuffer, StockReplayBuffer)):\n        batch.weight = to_torch_as(batch.weight, target_q_torch) \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "zkx741481546", "commentT": "2020-09-12T07:59:02Z", "comment_text": "\n \t\t\n print(td1.dtype, type(weight), weight.dtype, batch.weight)\n \n the output is\n torch.float32\n <class 'numpy.ndarray'>\n float64\n {AttributeError}'Batch' object has no attribute 'weight'\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "zkx741481546", "commentT": "2020-09-12T08:00:16Z", "comment_text": "\n \t\t\n But, if you want to use the prioritized experience replay's feature, plz inherit PrioritizedReplayBuffer instead of ReplayBuffer. Or change the line in BasePolicy as listed above to:\n     if isinstance(buffer, (PrioritizedReplayBuffer, StockReplayBuffer)):\n        batch.weight = to_torch_as(batch.weight, target_q_torch) \n \n try to do this first and see if the issue is fixed\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "zkx741481546", "commentT": "2020-09-12T08:01:16Z", "comment_text": "\n \t\t\n But, if you want to use the prioritized experience replay's feature, plz inherit PrioritizedReplayBuffer instead of ReplayBuffer. Or change the line in BasePolicy as listed above to:\n     if isinstance(buffer, (PrioritizedReplayBuffer, StockReplayBuffer)):\n        batch.weight = to_torch_as(batch.weight, target_q_torch) \n \n I used a stupid way by copying PrioritizedReplayBuffer code and edit it, I will try to inherit it or use the method you said, thanks for your helping!\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "zkx741481546", "commentT": "2020-09-12T08:50:00Z", "comment_text": "\n \t\t\n \n But, if you want to use the prioritized experience replay's feature, plz inherit PrioritizedReplayBuffer instead of ReplayBuffer. Or change the line in BasePolicy as listed above to:\n     if isinstance(buffer, (PrioritizedReplayBuffer, StockReplayBuffer)):\n        batch.weight = to_torch_as(batch.weight, target_q_torch) \n \n try to do this first and see if the issue is fixed\n \n I used multi-inherit, my own PER inherit my replay buffer class and PER from tianshou the same time, now it working normally, thank you very much!\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "zkx741481546", "commentT": "2020-09-12T08:50:38Z", "comment_text": "\n \t\tBut my code before working on linux is really weird, it shouldn't.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "zkx741481546", "commentT": "2020-09-12T08:52:26Z", "comment_text": "\n \t\tHmm... I think it has a better way to solve this issue: change\n \n \n \n tianshou/tianshou/policy/base.py\n \n \n         Lines 246 to 248\n       in\n       16d8e9b\n \n \n \n \n \n \n  # prio buffer update \n \n \n \n  if isinstance(buffer, PrioritizedReplayBuffer): \n \n \n \n  batch.weight = to_torch_as(batch.weight, target_q_torch) \n \n \n \n \n \n to\n if hasattr(batch, \"weight\"):\n     batch.weight = to_torch_as(batch.weight, target_q_torch)\n and change \n \n \n tianshou/tianshou/policy/base.py\n \n \n         Lines 141 to 143\n       in\n       c91def6\n \n \n \n \n \n \n  if isinstance(buffer, PrioritizedReplayBuffer) and hasattr( \n \n \n \n  batch, \"weight\" \n \n \n \n  ): \n \n \n \n \n \n to\n if hasattr(batch, \"weight\"):\n     buffer.update_weight(indice, batch.weight)\n I'll fix it later.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "zkx741481546", "commentT": "2020-09-12T08:58:38Z", "comment_text": "\n \t\t\n Hmm... I think it has a better way to solve this issue: change\n \n \n \n tianshou/tianshou/policy/base.py\n \n \n         Lines 246 to 248\n       in\n       16d8e9b\n \n \n \n \n \n \n  # prio buffer update \n \n \n \n  if isinstance(buffer, PrioritizedReplayBuffer): \n \n \n \n  batch.weight = to_torch_as(batch.weight, target_q_torch) \n \n \n \n \n \n to\n if hasattr(batch, \"weight\"):\n     batch.weight = to_torch_as(batch.weight, target_q_torch)\n and change\n \n \n \n tianshou/tianshou/policy/base.py\n \n \n         Lines 141 to 143\n       in\n       c91def6\n \n \n \n \n \n \n  if isinstance(buffer, PrioritizedReplayBuffer) and hasattr( \n \n \n \n  batch, \"weight\" \n \n \n \n  ): \n \n \n \n \n \n to\n if hasattr(batch, \"weight\"):\n     buffer.update_weight(indice, batch.weight)\n I'll fix it later.\n \n Indeed\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "zkx741481546", "commentT": "2020-09-13T09:46:31Z", "comment_text": "\n \t\tPlease have a look at <denchmark-link:https://github.com/thu-ml/tianshou/pull/217>#217</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "eec0826fd3a7c3066f68a5cc8b0b7ac145a6f1ac", "commit_author": "n+e", "commitT": "2020-09-16 17:43:19+08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tianshou\\policy\\base.py", "file_new_name": "tianshou\\policy\\base.py", "file_complexity": {"file_NLOC": "290", "file_CCN": "12", "file_NToken": "1162"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9,140,253", "deleted_lines": "9,10,141,142,143,256,257"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tianshou\\policy\\modelfree\\discrete_sac.py", "file_new_name": "tianshou\\policy\\modelfree\\discrete_sac.py", "file_complexity": {"file_NLOC": "129", "file_CCN": "6", "file_NToken": "860"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "130,131", "deleted_lines": "130,131", "method_info": {"method_name": "learn", "method_params": "self,Batch,Any", "method_startline": "91", "method_endline": "148", "method_complexity": {"method_NLOC": "46", "method_CCN": "3", "method_NToken": "432", "method_nesting_level": "1"}}}}}}}}