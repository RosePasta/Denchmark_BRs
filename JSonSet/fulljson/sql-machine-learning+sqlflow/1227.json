{"BR": {"BR_id": "1227", "BR_author": "BlackPoint-CX", "BRopenT": "2019-11-21T13:31:44Z", "BRcloseT": "2019-11-22T19:24:45Z", "BR_text": {"BRsummary": "File '/tmp/sqlflow227199809/input.sql' cannot be read", "BRdescription": "\n Description\n It seems that SQLFlow cannot read temporary file saved on server.\n Reproduction Steps\n After restart the kernel of notebook, the following exception will be thrown out.\n <denchmark-code>_Rendezvous: <_Rendezvous of RPC that terminated with:\n \tstatus = StatusCode.UNKNOWN\n \tdetails = \"thirdPartyParse failed: java.io.IOException: File '/tmp/sqlflow227199809/input.sql' cannot be read\n \tat org.apache.commons.io.FileUtils.openInputStream(FileUtils.java:294)\n \tat org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1851)\n \tat org.sqlflow.parser.ParserAdaptorCmd.main(ParserAdaptorCmd.java:42)\n  exit status 255\"\n \tdebug_error_string = \"{\"created\":\"@1574340457.693353044\",\"description\":\"Error received from peer ipv4:10.82.128.7:8005\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1055,\"grpc_message\":\"thirdPartyParse failed: java.io.IOException: File '/tmp/sqlflow227199809/input.sql' cannot be read\\n\\tat org.apache.commons.io.FileUtils.openInputStream(FileUtils.java:294)\\n\\tat org.apache.commons.io.FileUtils.readFileToByteArray(FileUtils.java:1851)\\n\\tat org.sqlflow.parser.ParserAdaptorCmd.main(ParserAdaptorCmd.java:42)\\n exit status 255\",\"grpc_status\":2}\"\n >\n </denchmark-code>\n \n Expected Behavior\n What you expected to happen.\n Screenshots\n Environment (Please complete the following information):\n \n OS:\n Browser:\n Version:\n \n Additional Notes\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "BlackPoint-CX", "commentT": "2019-11-21T14:47:07Z", "comment_text": "\n \t\tIn my case, I've encountered an error:\n %%sqlflow\n SELECT *\n FROM iris.train\n TO TRAIN DNNClassifier\n WITH model.n_classes = 3,\n   model.hidden_units = [10, 10],\n   train.epoch = 100\n COLUMN sepal_length, sepal_width, petal_length, petal_width\n LABEL class\n INTO sqlflow_models.my_dnn_model;\n <denchmark-code>_Rendezvous: <_Rendezvous of RPC that terminated with:\n \tstatus = StatusCode.UNKNOWN\n \tdetails = \"thirdPartyParse failed: ERROR StatusLogger Unrecognized format specifier [d]\n ERROR StatusLogger Unrecognized conversion specifier [d] starting at position 16 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [thread]\n ERROR StatusLogger Unrecognized conversion specifier [thread] starting at position 25 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [level]\n ERROR StatusLogger Unrecognized conversion specifier [level] starting at position 35 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [logger]\n ERROR StatusLogger Unrecognized conversion specifier [logger] starting at position 47 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [msg]\n ERROR StatusLogger Unrecognized conversion specifier [msg] starting at position 54 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [n]\n ERROR StatusLogger Unrecognized conversion specifier [n] starting at position 56 in conversion pattern.\n ERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console. Set system property 'log4j2.debug' to show Log4j2 internal initialization logging.\n ERROR StatusLogger Unrecognized format specifier [d]\n ERROR StatusLogger Unrecognized conversion specifier [d] starting at position 16 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [thread]\n ERROR StatusLogger Unrecognized conversion specifier [thread] starting at position 25 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [level]\n ERROR StatusLogger Unrecognized conversion specifier [level] starting at position 35 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [logger]\n ERROR StatusLogger Unrecognized conversion specifier [logger] starting at position 47 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [msg]\n ERROR StatusLogger Unrecognized conversion specifier [msg] starting at position 54 in conversion pattern.\n ERROR StatusLogger Unrecognized format specifier [n]\n ERROR StatusLogger Unrecognized conversion specifier [n] starting at position 56 in conversion pattern.\n NoViableAltException(312@[205:64: ( ( KW_AS )? alias= identifier )?])\n \tat org.antlr.runtime.DFA.noViableAlt(DFA.java:158)\n \tat org.antlr.runtime.DFA.predict(DFA.java:116)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.tableSource(HiveParser_FromClauseParser.java:4171)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.atomjoinSource(HiveParser_FromClauseParser.java:1600)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.joinSource(HiveParser_FromClauseParser.java:1854)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.fromSource(HiveParser_FromClauseParser.java:1527)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.fromClause(HiveParser_FromClauseParser.java:1370)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser.fromClause(HiveParser.java:45198)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser.atomSelectStatement(HiveParser.java:39792)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:40044)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:39690)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:38900)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:38788)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:2396)\n \tat org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1420)\n \tat org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:220)\n \tat org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:178)\n \tat org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:173)\n \tat org.sqlflow.parser.HiveQLParserAdaptor.ParseAndSplit(HiveQLParserAdaptor.java:44)\n \tat org.sqlflow.parser.ParserAdaptorCmd.main(ParserAdaptorCmd.java:54)\n Exception in thread \"main\" java.lang.StringIndexOutOfBoundsException: String index out of range: 235\n \tat java.lang.String.substring(String.java:1963)\n \tat org.sqlflow.parser.HiveQLParserAdaptor.ParseAndSplit(HiveQLParserAdaptor.java:71)\n \tat org.sqlflow.parser.ParserAdaptorCmd.main(ParserAdaptorCmd.java:54)\n </denchmark-code>\n \n Seems like a internal parser bug: Exception in thread \"main\" java.lang.StringIndexOutOfBoundsException: String index out of range: 235\n cc: <denchmark-link:https://github.com/tonyyang-svail>@tonyyang-svail</denchmark-link>\n \n <denchmark-h:hr></denchmark-h>\n \n PS: recompile the latest jar and I can run the TRAIN SQL without error.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "BlackPoint-CX", "commentT": "2019-11-21T18:42:42Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/BlackPoint-CX>@BlackPoint-CX</denchmark-link>\n  I am not able to reproduce it in , where I started the Jupyter notebook by .\n <denchmark-link:https://user-images.githubusercontent.com/29932814/69366384-20c3ba00-0c4b-11ea-9d9a-7ca7c5a27cab.png></denchmark-link>\n \n Could you please check if the file /tmp/sqlflow227199809/input.sql exists? If it exists, what is the permission of the file?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "BlackPoint-CX", "commentT": "2019-11-21T18:56:33Z", "comment_text": "\n \t\t\n Seems like a internal parser bug: Exception in thread \"main\" java.lang.StringIndexOutOfBoundsException: String index out of range: 235\n \n <denchmark-link:https://github.com/typhoonzero>@typhoonzero</denchmark-link>\n  Are you using the latest Docker image? I believe this error is fixed by <denchmark-link:https://github.com/sql-machine-learning/sqlflow/pull/1202>#1202</denchmark-link>\n .\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "BlackPoint-CX", "commentT": "2019-11-22T08:00:58Z", "comment_text": "\n \t\t\n if err := ioutil.WriteFile(inputFile, []byte(sql), 755); err != nil {\n \n change 755 to 0755 can fix this bug.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "BlackPoint-CX", "commentT": "2019-11-22T10:19:19Z", "comment_text": "\n \t\t\n @BlackPoint-CX I am not able to reproduce it in iris-dnn.ipynb, where I started the Jupyter notebook by docker run -it -p 8888:8888 sqlflow/sqlflow.\n \n Could you please check if the file /tmp/sqlflow227199809/input.sql exists? If it exists, what is the permission of the file?\n \n I had checked the existence of the temp file and  but the permission of those were not 755 specified in code. <denchmark-link:https://github.com/Yancey1989>@Yancey1989</denchmark-link>\n  and me has found this problem was caused by the format of permission. When change 755 into 0755 can solve this problem.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "BlackPoint-CX", "commentT": "2019-11-22T10:23:03Z", "comment_text": "\n \t\t\n \n Seems like a internal parser bug: Exception in thread \"main\" java.lang.StringIndexOutOfBoundsException: String index out of range: 235\n \n @typhoonzero Are you using the latest Docker image? I believe this error is fixed by #1202.\n \n We can not use public docker image in internal environment. Sad.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "BlackPoint-CX", "commentT": "2019-11-22T19:31:01Z", "comment_text": "\n \t\t\n change 755 to 0755 can fix this bug.\n \n <denchmark-link:https://github.com/Yancey1989>@Yancey1989</denchmark-link>\n  <denchmark-link:https://github.com/BlackPoint-CX>@BlackPoint-CX</denchmark-link>\n  Thank you so much for spotting this bug. I realized that we need to write  in octal format, which can be done by prepending a  in front of the digit.\n \t\t"}}}, "commit": {"commit_id": "15a8a721d57c2564b192e14e7fc019b9130994cb", "commit_author": "Yan Xu", "commitT": "2019-11-22 11:24:44-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pkg\\sql\\tpp\\parser.go", "file_new_name": "pkg\\sql\\tpp\\parser.go", "file_complexity": {"file_NLOC": "115", "file_CCN": "1", "file_NToken": "184"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "107", "deleted_lines": "106", "method_info": {"method_name": "tiDBInit", "method_params": "", "method_startline": "40", "method_endline": "136", "method_complexity": {"method_NLOC": "95", "method_CCN": "1", "method_NToken": "149", "method_nesting_level": "0"}}}}}}}}