{"BR": {"BR_id": "460", "BR_author": "amolchanov86", "BRopenT": "2019-01-09T02:09:21Z", "BRcloseT": "2019-03-28T19:52:56Z", "BR_text": {"BRsummary": "CEM and CMA don't support parallel sampling from TF policy", "BRdescription": "\n Currently, both ES are under the original branch. I managed to run them with some minor modifications (added the session initialization) with a single sampler but running with multiple samplers causes problems (that completely undermines the advantages of ES).\n Are there any immediate plans to move both algorithms into the main TF branch?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "amolchanov86", "commentT": "2019-01-09T06:37:20Z", "comment_text": "\n \t\tThey are not in garage.tf because (to my knowledge) they do not depend on TensorFlow.\n Can you post the error messages you got? These are both tested by the CI but perhaps some of the support code (e.g. sampler and/or plotter) have TF dependencies?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "amolchanov86", "commentT": "2019-01-09T22:42:35Z", "comment_text": "\n \t\tWHen one has to extract parameters from a policy one has to run a session. The absence of a default session is what it complained about initially (that is what I fixed by simply creating a session in the training routine). But it only works with a single sampler. When I am trying to increase n_parallel it keeps complaining about the lack of default session. I haven't dug into that yet hoping that maybe there was a plan to fix it. Here is the full post of the error I got now:\n (garage) artem@artempc:~/prj/quad_metalearn/quad_dynalearn/quad_dynalearn$ ./train_garage_quad.py config/cem_quad.conf _results_temp/cem_quad_test --n_parallel 2\n Reading parameter file config/cem_quad.conf ...\n ###############################################################\n ### PARAMETERS LOADED FROM CONFIG FILES (Later updated by arguments provided)\n {'seed': 1, 'variant': {'env': 'QuadrotorEnv', 'alg_class': 'CEM', 'alg_param': {'max_path_length': 100, 'n_itr': 10, 'n_samples': 100, 'best_frac': 0.05, 'init_std': 0.1, 'plot': False, 'play_every_itr': 1, 'play_rollouts_num': 1}, 'policy_class': 'GaussianMLPPolicy', 'policy_param': {'hidden_sizes': [32, 32]}}}\n +++++++++++++++++++++++++++++++++++++++++++++++++++\n PARAMETERS TUPLE:  None ()  SEED:  1\n python /home/artem/prj/drl/garage/scripts/run_experiment.py  --seed '1'  --n_parallel '2'  --snapshot_mode 'last'  --plot 'False'  --exp_name 'experiment_2019_01_09_14_39_27_0001'  --log_dir '_results_temp/cem_quad_test/seed_001/'  --use_cloudpickle 'True'  --args_data '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'  --variant_data 'gAN9cQAoWAMAAABlbnZxAVgMAAAAUXVhZHJvdG9yRW52cQJYCQAAAGFsZ19jbGFzc3EDWAMAAABDRU1xBFgJAAAAYWxnX3BhcmFtcQV9cQYoWA8AAABtYXhfcGF0aF9sZW5ndGhxB0tkWAUAAABuX2l0cnEISwpYCQAAAG5fc2FtcGxlc3EJS2RYCQAAAGJlc3RfZnJhY3EKRz+pmZmZmZmaWAgAAABpbml0X3N0ZHELRz+5mZmZmZmaWAQAAABwbG90cQyJWA4AAABwbGF5X2V2ZXJ5X2l0cnENSwFYEQAAAHBsYXlfcm9sbG91dHNfbnVtcQ5LAXVYDAAAAHBvbGljeV9jbGFzc3EPWBEAAABHYXVzc2lhbk1MUFBvbGljeXEQWAwAAABwb2xpY3lfcGFyYW1xEX1xElgMAAAAaGlkZGVuX3NpemVzcRNdcRQoSyBLIGVzWAgAAABleHBfbmFtZXEVWCMAAABleHBlcmltZW50XzIwMTlfMDFfMDlfMTRfMzlfMjdfMDAwMXEWdS4='\n 2019-01-09 14:39:31 | Setting seed to 1\n 2019-01-09 14:39:31 | Setting seed to 2\n 2019-01-09 14:39:31 | tensorboard data will be logged into:_results_temp/cem_quad_test/seed_001/\n WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n 2019-01-09 14:39:36.348996: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n 2019-01-09 14:39:36 | [experiment_2019_01_09_14_39_27_0001] Populating workers...\n WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n WARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\n *** Error in `python': double free or corruption (fasttop)multiprocessing.pool.RemoteTraceback: \n \"\"\"\n Traceback (most recent call last):\n   File \"/home/artem/prj/drl/garage/garage/sampler/stateful_pool.py\", line 186, in _worker_run_each\n     return runner(singleton_pool.G, *args)\n   File \"/home/artem/prj/drl/garage/garage/sampler/parallel_sampler.py\", line 40, in _worker_populate_task\n     g.policy = pickle.loads(policy)\n   File \"/home/artem/prj/drl/garage/garage/tf/core/parameterized.py\", line 107, in __setstate__\n     tf.get_default_session().run(\n AttributeError: 'NoneType' object has no attribute 'run'\n \n During handling of the above exception, another exception occurred:\n \n Traceback (most recent call last):\n   File \"/opt/anaconda2/envs/garage/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n     result = (True, func(*args, **kwds))\n   File \"/opt/anaconda2/envs/garage/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n     return list(map(*args))\n   File \"/home/artem/prj/drl/garage/garage/sampler/stateful_pool.py\", line 188, in _worker_run_each\n     raise Exception(\"\".join(traceback.format_exception(*sys.exc_info())))\n Exception: Traceback (most recent call last):\n   File \"/home/artem/prj/drl/garage/garage/sampler/stateful_pool.py\", line 186, in _worker_run_each\n     return runner(singleton_pool.G, *args)\n   File \"/home/artem/prj/drl/garage/garage/sampler/parallel_sampler.py\", line 40, in _worker_populate_task\n     g.policy = pickle.loads(policy)\n   File \"/home/artem/prj/drl/garage/garage/tf/core/parameterized.py\", line 107, in __setstate__\n     tf.get_default_session().run(\n AttributeError: 'NoneType' object has no attribute 'run'\n \n \"\"\"\n \n The above exception was the direct cause of the following exception:\n \n Traceback (most recent call last):\n   File \"/home/artem/prj/drl/garage/scripts/run_experiment.py\", line 242, in <module>\n     run_experiment(sys.argv)\n   File \"/home/artem/prj/drl/garage/scripts/run_experiment.py\", line 185, in run_experiment\n     method_call(variant_data)\n   File \"./train_garage_quad.py\", line 125, in run_task\n     algo.train()\n   File \"/home/artem/prj/quad_metalearn/quad_dynalearn/quad_dynalearn/algos/cem.py\", line 137, in train\n     parallel_sampler.populate_task(self.env, self.policy)\n   File \"/home/artem/prj/drl/garage/garage/sampler/parallel_sampler.py\", line 58, in populate_task\n     ] * singleton_pool.n_parallel)\n   File \"/home/artem/prj/drl/garage/garage/sampler/stateful_pool.py\", line 72, in run_each\n     return results.get()\n   File \"/opt/anaconda2/envs/garage/lib/python3.6/multiprocessing/pool.py\", line 644, in get\n     raise self._value\n Exception: Traceback (most recent call last):\n   File \"/home/artem/prj/drl/garage/garage/sampler/stateful_pool.py\", line 186, in _worker_run_each\n     return runner(singleton_pool.G, *args)\n   File \"/home/artem/prj/drl/garage/garage/sampler/parallel_sampler.py\", line 40, in _worker_populate_task\n     g.policy = pickle.loads(policy)\n   File \"/home/artem/prj/drl/garage/garage/tf/core/parameterized.py\", line 107, in __setstate__\n     tf.get_default_session().run(\n AttributeError: 'NoneType' object has no attribute 'run'\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "amolchanov86", "commentT": "2019-01-13T04:16:59Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/naeioi>@naeioi</denchmark-link>\n  thoughts?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "amolchanov86", "commentT": "2019-01-13T23:06:40Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/amolchanov86>@amolchanov86</denchmark-link>\n  Thanks for reporting. CEM itself depends on neither tf or theano. I notice that you were using  which is a tensorflow policy, that's why you need to initialize a tensorflow session manually for the policy to use. <denchmark-link:https://github.com/ryanjulian>@ryanjulian</denchmark-link>\n  CI does not break because it only tests CEM under theano policy.\n <denchmark-link:https://github.com/amolchanov86>@amolchanov86</denchmark-link>\n  Can you also post your ? The magic  setups several processes and instruct them to run the callable  passed to it. I suspect that your tf session was not initialized within .\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "amolchanov86", "commentT": "2019-01-14T21:02:41Z", "comment_text": "\n \t\tI see, so what you are trying to say is that making a session in the training routine itself is too late and it should be called earlier?\n Here my full train_garage_quad.py\n <denchmark-code>#!/usr/bin/env python\n \"\"\"\n This is a parametrized script to run TRPO/PPO \n with a custom env\n \"\"\"\n import argparse\n import sys\n import os\n import datetime, time\n import itertools\n import os.path as osp\n import uuid\n import copy\n \n import numpy as np\n \n import dateutil.tz\n import yaml\n \n import gym\n \n from garage.envs import normalize\n from garage.experiment import run_experiment\n \n # Custom stuff\n import quad_dynalearn.config.config_loader as conf\n import quad_dynalearn.misc.variants_utils as vu\n \n \n ########################################################################\n ## ARGUMENTS\n parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n parser.add_argument(\"config_file\", help='yaml file with default settings of parameters')\n parser.add_argument(\"log_dir\", default='_results_temp/trpo_ppo_last', help='Directory to log into')\n parser.add_argument(\"--seed\", '-s', default=None, help='list of seeds to use separated by comma (or a single seed w/o comma). If None seeds from config_file will be used')\n parser.add_argument(\"--n_parallel\", '-n', type=int, default=1, help='Number of parallel workers to run a single task')\n parser.add_argument(\"--snapshot_mode\", '-snm', default='last', help='Snapshot mode. Opt: last')\n parser.add_argument(\"--plot\", '-plt', action=\"store_true\", help='Plotting')\n parser.add_argument(\"--param_name\", '-p', help='task hyperparameter names separated by comma')\n parser.add_argument(\"--param_val\", '-pv', help='task hyperparam values.'+ \n                     ' For a single par separated by comma.' +\n                     ' For adjacent params separated by double comma.' +\n                     '   Ex: \\\"-p par1,par2 -pv pv11,pv12,,pv21,pv22\\\"' + \n                     '   where pv11,pv12 - par values for par1 , pv21,pv22 - par values for par2')\n args = parser.parse_args()\n \n ########################################################################\n ## PARAMETERS (non grid)\n # Loading parameters not specified in the arguments\n print('Reading parameter file %s ...' % args.config_file)\n params = conf.trpo_ppo_default_params()\n yaml_stream = open(args.config_file, 'r')\n params_new = yaml.load(yaml_stream)\n params.update(params_new)\n print('###############################################################')\n print('### PARAMETERS LOADED FROM CONFIG FILES (Later updated by arguments provided)')\n print(params)\n \n ## Get a grid of task variations and put it into list as parameter dictionaries\n ## WARN: when you add more parameters to add_arguments you will have to modify grid_of_variants()\n variants_list = vu.grid_of_variants(args, params)\n \n ## Saving command line executing the script\n cmd = \" \".join(sys.argv)\n if not os.path.isdir(args.log_dir):\n     os.makedirs(args.log_dir)\n with open(args.log_dir + os.sep + \"cmd.sh\", \"w\") as cmdfile:\n     cmdfile.write(\"#!/usr/bin/bash\\n\")\n     cmdfile.write(cmd)\n \n \n def run_task(task_param):\n     \"\"\"\n     Wrap PPO training task in the run_task function.\n \n     :param _:\n     :return:\n     \"\"\"\n     from garage.tf.baselines import GaussianMLPBaseline\n     from garage.tf.envs import TfEnv\n     from garage.tf.policies import GaussianMLPPolicy, DeterministicMLPPolicy\n     from garage.tf.algos.trpo import TRPO\n     \n     from quad_dynalearn.algos.cem import CEM\n     from quad_dynalearn.algos.cma_es import CMAES\n     from quad_dynalearn.algos.ppo import PPO\n \n     if task_param[\"env\"] == \"QuadrotorEnv\":\n         # from gym_art.quadrotor.quadrotor_control import *\n         from gym_art.quadrotor.quadrotor_modular import QuadrotorEnv\n         env = TfEnv(QuadrotorEnv(**task_param[\"env_param\"]))\n         del task_param[\"env_param\"]\n     else:\n         env = TfEnv(normalize(gym.make(task_param[\"env\"])))\n     del task_param[\"env\"]\n     \n     policy = locals()[task_param[\"policy_class\"]](env_spec=env.spec, **task_param[\"policy_param\"])\n     del task_param[\"policy_class\"]\n     del task_param[\"policy_param\"]\n \n     if task_param[\"alg_class\"] != \"CEM\" and task_param[\"alg_class\"] != \"CMAES\":\n         baseline = locals()[task_param[\"baseline_class\"]](env_spec=env.spec, **task_param[\"baseline_param\"])\n         del task_param[\"baseline_class\"]\n         del task_param[\"baseline_param\"]\n \n         algo = locals()[task_param[\"alg_class\"]](\n             env=env,\n             policy=policy,\n             baseline=baseline,\n             **task_param[\"alg_param\"])\n     else:\n         algo = locals()[task_param[\"alg_class\"]](\n             env=env,\n             policy=policy,\n             **task_param[\"alg_param\"])\n \n     del task_param[\"alg_class\"]\n     del task_param[\"alg_param\"]\n \n     # Check that we used all parameters:\n     # It helps revealing situations where you thought you set certain parameter\n     # But in fact made spelling mistake and it failed\n     del task_param[\"exp_name\"] #This is probably generated by garage\n     assert task_param == {}, \"ERROR: Some of parameter values were not used: %s\" % str(task_param)\n \n     algo.train()\n \n start_time = time.time()\n for var in variants_list:\n     ## Dumping config\n     with open(var[\"log_dir\"] + os.sep + \"config.yml\", 'w') as yaml_file:\n         yaml_file.write(yaml.dump(var, default_flow_style=False))\n \n     ## Running\n     run_experiment(\n         run_task,\n         **var\n     )\n \n end_time = time.time()\n print(\"##################################################\")\n print(\"Total Runtime: \", end_time - start_time)\n </denchmark-code>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "amolchanov86", "commentT": "2019-01-14T22:03:51Z", "comment_text": "\n \t\tYes. I assume the training routine you are referring to is the implementation of CEM, where there's nothing related to tf session. So you have to do it outside, earlier before algo.train() is called.\n I made some change to your script. There are some deps I don't have so I cannot test but it should work. Could you give it a try? <denchmark-link:https://gist.github.com/naeioi/28bb467abf6a598e814bdb136f7c2230>https://gist.github.com/naeioi/28bb467abf6a598e814bdb136f7c2230</denchmark-link>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "amolchanov86", "commentT": "2019-01-22T21:30:37Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/amolchanov86>@amolchanov86</denchmark-link>\n  Would like to know if you have solved your problem?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "amolchanov86", "commentT": "2019-01-23T18:26:04Z", "comment_text": "\n \t\tHi,\n sorry, I have switched to other things and just missed your previous post. I will try today and report. Thanks a lot for the help!\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "amolchanov86", "commentT": "2019-01-23T23:02:43Z", "comment_text": "\n \t\tI tried your example and I had the same result (i.e. works with one worker, fails if n_parallel > 1).\n I even substituted the cem version I had with the original one. Hence I think if the bug is eliminated on the original version then my code should also work. Or maybe I am doing something wrong then, please, share a script that successfully runs CEM/CMAES with n_parallel > 1 and TF policies.\n Thanks a lot for the support!\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "amolchanov86", "commentT": "2019-01-24T23:55:43Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/amolchanov86>@amolchanov86</denchmark-link>\n  After some debugging, I found that both CEM and CMAES work only under theano policy when doing parallel sampling.\n The root cause is that tf session is <denchmark-link:https://github.com/tensorflow/tensorflow/issues/2448>not fork-safe</denchmark-link>\n , meaning that one tf session cannot be shared by multiple processes. Algos under  uses tf-specific samplers to manager isolated session in each worker, and since CEM and CMAES don't use those samplers, they cannot work under tf policy.\n <denchmark-link:https://github.com/ryanjulian>@ryanjulian</denchmark-link>\n  <denchmark-link:https://github.com/CatherineSue>@CatherineSue</denchmark-link>\n  Do we need to add tf support for CEM and CMAES in this case?\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "amolchanov86", "commentT": "2019-01-25T01:15:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/amolchanov86>@amolchanov86</denchmark-link>\n  <denchmark-link:https://github.com/naeioi>@naeioi</denchmark-link>\n  Thanks for pointing out the problem. I think there are two solutions:\n \n Add tf support for CEM and CMAES; We always like more algorithms support. It'd be great that we have tf support for CEM and CMAES.\n Add policies into garage.policies. Since CEM and CMAES don't depend on tf or theano, they should use primitives not depend on tf or theano, too. For instance, numpy. If we can add some policies to garage.policies, it could also solve this problem.\n \n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "amolchanov86", "commentT": "2019-01-25T02:16:03Z", "comment_text": "\n \t\tuhh, these two solutions both require some effort. I think the first step we should take is to move those two algorithms under garage.theano.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "amolchanov86", "commentT": "2019-01-25T02:22:26Z", "comment_text": "\n \t\tWe are going to remove theano module soon. We also need to make sure the tf algo parity with theano. So move them to theano is equivalent to option one. And the algorithms don't actually depend on theano. The root reason is that we don't have a policy ready for the algirithm.\n I prefer to leave them here then add tf support or no dep policy later.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "amolchanov86", "commentT": "2019-01-25T02:31:46Z", "comment_text": "\n \t\tI agree, let's just keep the issue open.\n \t\t"}}}, "commit": {"commit_id": "96c3517cd69aee937e161448a1b59cbef5d03c47", "commit_author": "Keren Zhu", "commitT": "2019-03-28 12:52:56-07:00", "commit_complexity": {"commit_NLOC": "0.8372093023255814", "commit_CCN": "1.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "examples\\cem_cartpole.py", "file_complexity": {"file_NLOC": "37", "file_CCN": "1", "file_NToken": "185"}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 9, "file_old_name": "garage\\np\\algos\\cem.py", "file_new_name": "garage\\np\\algos\\cem.py", "file_complexity": {"file_NLOC": "100", "file_CCN": "5", "file_NToken": "530"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "120,121", "deleted_lines": "120,121", "method_info": {"method_name": "get_itr_snapshot", "method_params": "self,itr", "method_startline": "120", "method_endline": "121", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "26", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "14,15,16,17", "deleted_lines": "14,15,16,17", "method_info": {"method_name": "_get_stderr_lb", "method_params": "x", "method_startline": "14", "method_endline": "17", "method_complexity": {"method_NLOC": "4", "method_CCN": "2", "method_NToken": "54", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "20,21,22,23,24,25,26,27", "deleted_lines": "20,21,22,23,24,25,26,27", "method_info": {"method_name": "_get_stderr_lb_varyinglens", "method_params": "x", "method_startline": "20", "method_endline": "27", "method_complexity": {"method_NLOC": "8", "method_CCN": "3", "method_NToken": "111", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "41,43,44,45,48", "deleted_lines": "40,41,42,43,44,45,46,47,48,49,50,51,52", "method_info": {"method_name": "__init__", "method_params": "self,env_spec,policy,baseline,n_samples,gae_lambda,max_path_length,discount,init_std,best_frac,extra_std,extra_decay_time,kwargs", "method_startline": "40", "method_endline": "52", "method_complexity": {"method_NLOC": "13", "method_CCN": "1", "method_NToken": "49", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "30,31,32,33,34,35,36,37,38,39,41,43,44,45,48,53,55,56", "deleted_lines": "30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58", "method_info": {"method_name": "_worker_rollout_policy", "method_params": "g,args", "method_startline": "30", "method_endline": "58", "method_complexity": {"method_NLOC": "25", "method_CCN": "4", "method_NToken": "218", "method_nesting_level": "0"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "110,111,112,113,114,115,116,117,118,119,120,121", "deleted_lines": "110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185", "method_info": {"method_name": "train", "method_params": "self", "method_startline": "110", "method_endline": "185", "method_complexity": {"method_NLOC": "70", "method_CCN": "11", "method_NToken": "562", "method_nesting_level": "1"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118", "deleted_lines": "87,88,89,90,91,92,93,94,95,97,98,102,106,107,110,111,112,113,114,115,116,117,118", "method_info": {"method_name": "train_once", "method_params": "self,itr,paths", "method_startline": "87", "method_endline": "118", "method_complexity": {"method_NLOC": "22", "method_CCN": "2", "method_NToken": "204", "method_nesting_level": "1"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "62,66,67,68,69,70,71,72,73,74,75,76", "deleted_lines": "63,65,68,69,70,74,75", "method_info": {"method_name": "__init__", "method_params": "self,env,policy,n_itr,max_path_length,discount,init_std,n_samples,batch_size,best_frac,extra_std,extra_decay_time,plot,n_evals,kwargs", "method_startline": "62", "method_endline": "76", "method_complexity": {"method_NLOC": "15", "method_CCN": "1", "method_NToken": "62", "method_nesting_level": "1"}}}, "hunk_8": {"Ismethod": 1, "added_lines": "79,80,81,82,83,84,85", "deleted_lines": "79,80,81,82,83,84,85", "method_info": {"method_name": "sample_params", "method_params": "self,epoch", "method_startline": "79", "method_endline": "85", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "66", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "garage\\tf\\algos\\batch_polopt.py", "file_new_name": "garage\\tf\\algos\\batch_polopt.py", "file_complexity": {"file_NLOC": "46", "file_CCN": "6", "file_NToken": "219"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "57,58", "method_info": {"method_name": "initialize", "method_params": "self,sess", "method_startline": "57", "method_endline": "58", "method_complexity": {"method_NLOC": "2", "method_CCN": "2", "method_NToken": "20", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\garage\\np\\algos\\test_algos.py", "file_new_name": "tests\\garage\\np\\algos\\test_algos.py", "file_complexity": {"file_NLOC": "52", "file_CCN": "1", "file_NToken": "339"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "33", "deleted_lines": "10,25,26,27,28,29,39"}}}, "file_4": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "tests\\garage\\tf\\algos\\test_cem.py", "file_complexity": {"file_NLOC": "28", "file_CCN": "1", "file_NToken": "191"}}}}}