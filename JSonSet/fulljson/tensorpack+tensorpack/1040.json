{"BR": {"BR_id": "1040", "BR_author": "elmirador", "BRopenT": "2019-01-09T10:57:57Z", "BRcloseT": "2019-01-10T07:05:48Z", "BR_text": {"BRsummary": "Bug Report: BilinearUpSample() only works when channels=1", "BRdescription": "\n <denchmark-h:h3>1. What you did:</denchmark-h>\n \n I wrote a piece of code to test the behavior of BilinearUpSample() layer:\n <denchmark-link:https://gist.github.com/elmirador/4816836ca5b35481a43b07109f6dae63>https://gist.github.com/elmirador/4816836ca5b35481a43b07109f6dae63</denchmark-link>\n \n The layer's code is directly copied from models/pool.py from \n \n \n tensorpack/tensorpack/models/pool.py\n \n \n         Lines 145 to 196\n       in\n       7bf5581\n \n \n \n \n \n \n  def BilinearUpSample(x, shape): \n \n \n \n  \"\"\" \n \n \n \n      Deterministic bilinearly-upsample the input images. \n \n \n \n      It is implemented by deconvolution with \"BilinearFiller\" in Caffe. \n \n \n \n      It is aimed to mimic caffe behavior. \n \n \n \n   \n \n \n \n      Args: \n \n \n \n          x (tf.Tensor): a NHWC tensor \n \n \n \n          shape (int): the upsample factor \n \n \n \n   \n \n \n \n      Returns: \n \n \n \n          tf.Tensor: a NHWC tensor. \n \n \n \n      \"\"\" \n \n \n \n  log_deprecated(\"BilinearUpsample\", \"Please implement it in your own code instead!\", \"2019-03-01\") \n \n \n \n  inp_shape = x.shape.as_list() \n \n \n \n  ch = inp_shape[3] \n \n \n \n  assert ch is not None \n \n \n \n  \n \n \n \n  shape = int(shape) \n \n \n \n  filter_shape = 2 * shape \n \n \n \n  \n \n \n \n  def bilinear_conv_filler(s): \n \n \n \n  \"\"\" \n \n \n \n          s: width, height of the conv filter \n \n \n \n          https://github.com/BVLC/caffe/blob/99bd99795dcdf0b1d3086a8d67ab1782a8a08383/include/caffe/filler.hpp#L219-L268 \n \n \n \n          \"\"\" \n \n \n \n  f = np.ceil(float(s) / 2) \n \n \n \n  c = float(2 * f - 1 - f % 2) / (2 * f) \n \n \n \n  ret = np.zeros((s, s), dtype='float32') \n \n \n \n  for x in range(s): \n \n \n \n  for y in range(s): \n \n \n \n  ret[x, y] = (1 - abs(x / f - c)) * (1 - abs(y / f - c)) \n \n \n \n  return ret \n \n \n \n  w = bilinear_conv_filler(filter_shape) \n \n \n \n  w = np.repeat(w, ch * ch).reshape((filter_shape, filter_shape, ch, ch)) \n \n \n \n  \n \n \n \n  weight_var = tf.constant(w, tf.float32, \n \n \n \n  shape=(filter_shape, filter_shape, ch, ch), \n \n \n \n  name='bilinear_upsample_filter') \n \n \n \n  x = tf.pad(x, [[0, 0], [shape - 1, shape - 1], [shape - 1, shape - 1], [0, 0]], mode='SYMMETRIC') \n \n \n \n  out_shape = tf.shape(x) * tf.constant([1, shape, shape, 1], tf.int32) \n \n \n \n  deconv = tf.nn.conv2d_transpose(x, weight_var, out_shape, \n \n \n \n                                      [1, shape, shape, 1], 'SAME') \n \n \n \n  edge = shape * (shape - 1) \n \n \n \n  deconv = deconv[:, edge:-edge, edge:-edge, :] \n \n \n \n  \n \n \n \n  if inp_shape[1]: \n \n \n \n  inp_shape[1] *= shape \n \n \n \n  if inp_shape[2]: \n \n \n \n  inp_shape[2] *= shape \n \n \n \n  deconv.set_shape(inp_shape) \n \n \n \n  return deconv \n \n \n \n \n \n <denchmark-h:h3>2. What you observed:</denchmark-h>\n \n Original Image:\n <denchmark-link:https://user-images.githubusercontent.com/3897907/50889932-2437c380-1434-11e9-92ff-25babf24f31d.png></denchmark-link>\n \n Upsampled Image (in color):\n <denchmark-link:https://user-images.githubusercontent.com/3897907/50890247-c6f04200-1434-11e9-983c-5db985f61fdd.png></denchmark-link>\n \n Read the original image as grayscale, then upsample:\n <denchmark-link:https://user-images.githubusercontent.com/3897907/50890657-9230ba80-1435-11e9-870d-ce8c59c4b9f0.png></denchmark-link>\n \n The reason for this behavior is that conv2d_tranpose() is a convolution. It convolutes on all channels instead of one single channel while bilinear upsampling is a channel-wise operation. To fix it just apply the convolution channel-wise.\n I do think it's a good idea to use Caffe's version of bilinear upsampling instead of the one in TF. Sad to see it's going to be deprecated.\n The CaffeBilinearUpSample() in the HED example should also be corrected.\n <denchmark-h:h3>3. Your environment:</denchmark-h>\n \n \n Python version: 3.5\n TF version: 1.4.0\n Tensorpack version: 0.9.0.1-master (ac9ac2a)\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "elmirador", "commentT": "2019-01-09T17:49:41Z", "comment_text": "\n \t\tThanks a lot for finding this!\n A great example of what I wrote here: <denchmark-link:https://tensorpack.readthedocs.io/tutorial/symbolic.html#use-other-symbolic-libraries>https://tensorpack.readthedocs.io/tutorial/symbolic.html#use-other-symbolic-libraries</denchmark-link>\n \n \n It\u2019s best to not trust others\u2019 layers!\n For non-standard layers that\u2019s not included in TensorFlow or Tensorpack, it\u2019s best to implement them yourself. Non-standard layers often do not have a mathematical definition that people all agree on, and different people can implement it differently. Also, deep learning models on github often have bugs, especially when there is no reproduced experiments with the code.\n For your own good, it\u2019s best to implement the layers yourself. This is also why Tensorpack does not contain non-standard layers.\n \n  was made un-public and removed from documentation (<denchmark-link:https://tensorpack.readthedocs.io/modules/models.html>https://tensorpack.readthedocs.io/modules/models.html</denchmark-link>\n ) a while ago because it's a non-standard layer and we should not provide an implementation for it. But it's good to know the bug!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "elmirador", "commentT": "2019-01-09T18:13:33Z", "comment_text": "\n \t\tNew implementation:\n def BilinearUpSample(x, shape):\n     \"\"\"\n     Deterministic bilinearly-upsample the input images.\n     It is implemented by deconvolution with \"BilinearFiller\" in Caffe.\n     It is aimed to mimic caffe behavior.\n     Args:\n         x (tf.Tensor): a NHWC tensor\n         shape (int): the upsample factor\n     Returns:\n         tf.Tensor: a NHWC tensor.\n     \"\"\"\n     #log_deprecated(\"BilinearUpsample\", \"Please implement it in your own code instead!\", \"2019-03-01\")\n     inp_shape = x.shape.as_list()\n     ch = inp_shape[3]\n     assert ch is not None\n \n     shape = int(shape)\n     filter_shape = 2 * shape\n \n     def bilinear_conv_filler(s):\n         \"\"\"\n         s: width, height of the conv filter\n         https://github.com/BVLC/caffe/blob/99bd99795dcdf0b1d3086a8d67ab1782a8a08383/include/caffe/filler.hpp#L219-L268\n         \"\"\"\n         f = np.ceil(float(s) / 2)\n         c = float(2 * f - 1 - f % 2) / (2 * f)\n         ret = np.zeros((s, s), dtype='float32')\n         for x in range(s):\n             for y in range(s):\n                 ret[x, y] = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n         return ret\n     w = bilinear_conv_filler(filter_shape)\n     w = np.repeat(w, ch * 1).reshape((filter_shape, filter_shape, ch, 1))\n \n     weight_var = tf.constant(w, tf.float32,\n                              shape=(filter_shape, filter_shape, ch, 1),\n                              name='bilinear_upsample_filter')\n     x = tf.pad(x, [[0, 0], [shape - 1, shape - 1], [shape - 1, shape - 1], [0, 0]], mode='SYMMETRIC')\n     out_shape = tf.shape(x) * tf.constant([1, shape, shape, 1], tf.int32)\n \n     @tf.custom_gradient\n     def depthwise_deconv(x):\n         ret = tf.nn.depthwise_conv2d_native_backprop_input(\n             out_shape, weight_var, x, [1, shape, shape, 1], padding='SAME')\n         def grad(dy):\n             return tf.nn.depthwise_conv2d(dy, weight_var, [1, shape, shape, 1], padding='SAME')\n         return ret, grad\n \n     deconv = depthwise_deconv(x)\n \n     edge = shape * (shape - 1)\n     deconv = deconv[:, edge:-edge, edge:-edge, :]\n \n     if inp_shape[1]:\n         inp_shape[1] *= shape\n     if inp_shape[2]:\n         inp_shape[2] *= shape\n     deconv.set_shape(inp_shape)\n     return deconv\n I haven't verified the backward is correct, but forward seems right now.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "elmirador", "commentT": "2019-01-10T06:16:33Z", "comment_text": "\n \t\t\n Thanks a lot for finding this!\n A great example of what I wrote here: https://tensorpack.readthedocs.io/tutorial/symbolic.html#use-other-symbolic-libraries\n \n It\u2019s best to not trust others\u2019 layers!\n For non-standard layers that\u2019s not included in TensorFlow or Tensorpack, it\u2019s best to implement them yourself. Non-standard layers often do not have a mathematical definition that people all agree on, and different people can implement it differently. Also, deep learning models on github often have bugs, especially when there is no reproduced experiments with the code.\n For your own good, it\u2019s best to implement the layers yourself. This is also why Tensorpack does not contain non-standard layers.\n \n BilinearUpSample was made un-public and removed from documentation (https://tensorpack.readthedocs.io/modules/models.html) a while ago because it's a non-standard layer and we should not provide an implementation for it. But it's good to know the bug!\n \n I see, but some of the non-standard layers like upsampling are pretty common. A separate non-standard layer codebase might be helpful though.\n The reason I hesitate to use TF's implementation is that the image.resize_* functions are messy (at least in resize_area) and might cause some weird things to happen. tf.image.resize_bilinear works fine though.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "elmirador", "commentT": "2019-01-10T06:27:01Z", "comment_text": "\n \t\t\n A separate non-standard layer codebase might be helpful though.\n \n Might be helpful as a reference. But it will have the same issue: personally I would not trust any non-standard layers written by others.\n tf.image.resize_bilinear has its own issues as well and it certainly is not equivalent to this layer in tensorpack during upsampling. That's why they're called non-standard.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "elmirador", "commentT": "2019-01-10T07:03:28Z", "comment_text": "\n \t\t\n Might be helpful as a reference. But it will have the same issue: personally I would not trust any non-standard layers written by others.\n \n I agree. Someone should at least read the code before using it.\n \n tf.image.resize_bilinear has its own issues as well and it certainly is not equivalent to this layer in tensorpack during upsampling. That's why they're called non-standard.\n \n Got it. I'll dig harder on TF's code.\n All in all, pretty happy to contribute. I love tensorpack much more than keras personally lol\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "elmirador", "commentT": "2019-01-10T07:05:47Z", "comment_text": "\n \t\tAlso, just found that the HED example uses the layer with channel=1 only, so there is nothing to fix. But I'll add some notes to the code.\n Closing as resolved. Thanks again!\n \t\t"}}}, "commit": {"commit_id": "0b2ab4ae4536a074d9159c73f86f6fed52e512fc", "commit_author": "Yuxin Wu", "commitT": "2019-01-09 23:23:02-08:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "README.md", "file_new_name": "README.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "66,67", "deleted_lines": "66,67"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "docs\\tutorial\\extend\\dataflow.md", "file_new_name": "docs\\tutorial\\extend\\dataflow.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "4,5,6", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "examples\\HED\\hed.py", "file_new_name": "examples\\HED\\hed.py", "file_complexity": {"file_NLOC": "241", "file_CCN": "32", "file_NToken": "2297"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "290", "deleted_lines": null, "method_info": {"method_name": "run", "method_params": "model_path,image_path,output", "method_startline": "272", "method_endline": "293", "method_complexity": {"method_NLOC": "22", "method_CCN": "5", "method_NToken": "183", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "55,59,62,63,86,87,89,91,95,96", "deleted_lines": "54,58,61,62,85,86,88,90,92,93", "method_info": {"method_name": "CaffeBilinearUpSample", "method_params": "x,shape", "method_startline": "48", "method_endline": "98", "method_complexity": {"method_NLOC": "24", "method_CCN": "3", "method_NToken": "265", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "108,118,121,122,150,151,152,153,156,168,169,170,171,173,174,175,176", "deleted_lines": "116,119,147,148,149,150,164,165,166,167,168,170,171,172,173", "method_info": {"method_name": "build_graph", "method_params": "self,image,edgemap", "method_startline": "106", "method_endline": "176", "method_complexity": {"method_NLOC": "52", "method_CCN": "2", "method_NToken": "599", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "118", "deleted_lines": "116,119", "method_info": {"method_name": "build_graph.branch", "method_params": "name,l,up", "method_startline": "111", "method_endline": "119", "method_complexity": {"method_NLOC": "9", "method_CCN": "2", "method_NToken": "75", "method_nesting_level": "2"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorpack\\dataflow\\base.py", "file_new_name": "tensorpack\\dataflow\\base.py", "file_complexity": {"file_NLOC": "74", "file_CCN": "18", "file_NToken": "342"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "100,101,102", "deleted_lines": "100,101,102", "method_info": {"method_name": "__len__", "method_params": "self", "method_startline": "89", "method_endline": "120", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "10", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorpack\\models\\conv2d.py", "file_new_name": "tensorpack\\models\\conv2d.py", "file_complexity": {"file_NLOC": "165", "file_CCN": "2", "file_NToken": "935"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "45", "deleted_lines": "45"}}}}}}