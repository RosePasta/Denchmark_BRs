{"BR": {"BR_id": "914", "BR_author": "thuzhf", "BRopenT": "2018-09-29T08:49:26Z", "BRcloseT": "2018-09-30T07:09:29Z", "BR_text": {"BRsummary": "param `last_k` in `StatMonitorParamSetter` is misleading", "BRdescription": "\n \n \n \n tensorpack/tensorpack/callbacks/param.py\n \n \n         Lines 301 to 367\n       in\n       da143e0\n \n \n \n \n \n \n  class StatMonitorParamSetter(HyperParamSetter): \n \n \n \n  \"\"\" \n \n \n \n      Change the param by monitoring the change of a statistic. \n \n \n \n      Change when it wasn't decreasing/increasing enough. \n \n \n \n      \"\"\" \n \n \n \n  def __init__(self, param, stat_name, value_func, threshold, \n \n \n \n  last_k, reverse=False): \n \n \n \n  \"\"\" \n \n \n \n          Args: \n \n \n \n              param: same as in :class:`HyperParamSetter`. \n \n \n \n              stat_name (str): name of the statistics. \n \n \n \n              value_func (float -> float): a function which returns a new value \n \n \n \n                  taking the old value. \n \n \n \n              threshold (float): change threshold. \n \n \n \n              last_k (int): last k epochs. \n \n \n \n              reverse (bool): monitor increasing instead of decreasing. \n \n \n \n   \n \n \n \n          This callback will change ``param`` by ``new_value = value_func(old_value)``, when: \n \n \n \n          ``min(stats) >= stats[0] - threshold``, where \n \n \n \n          ``stats = [the values of stat_name in last k epochs]`` \n \n \n \n   \n \n \n \n          If ``reverse`` is True, it will change the ``param`` when: \n \n \n \n          ``max(stats) <= stats[0] + threshold``. \n \n \n \n   \n \n \n \n          Example: \n \n \n \n              If validation error wasn't decreasing for 5 epochs, anneal the learning rate by 0.2: \n \n \n \n   \n \n \n \n              .. code-block:: python \n \n \n \n   \n \n \n \n                  StatMonitorParamSetter('learning_rate', 'val-error', lambda x: x * 0.2, 0, 5) \n \n \n \n          \"\"\" \n \n \n \n  super(StatMonitorParamSetter, self).__init__(param) \n \n \n \n  self.stat_name = stat_name \n \n \n \n  self.value_func = value_func \n \n \n \n  self.last_k = last_k \n \n \n \n  self.threshold = threshold \n \n \n \n  self.reverse = reverse \n \n \n \n  \n \n \n \n  self.last_changed_epoch = 0 \n \n \n \n  \n \n \n \n  def _get_value_to_set(self): \n \n \n \n  try: \n \n \n \n  hist = self.trainer.monitors.get_history(self.stat_name) \n \n \n \n  except KeyError: \n \n \n \n  logger.warn( \n \n \n \n  \"[StatMonitorParamSetter] Key {} not found in monitor history! Ignore it.\".format(self.stat_name)) \n \n \n \n  return None \n \n \n \n  \n \n \n \n  if len(hist) < self.last_k + 1 or \\ \n \n \n \n  self.epoch_num - self.last_changed_epoch < self.last_k: \n \n \n \n  return None \n \n \n \n  hist = hist[-self.last_k - 1:]    # len==last_k+1 \n \n \n \n  \n \n \n \n  hist_first = hist[0] \n \n \n \n  if not self.reverse: \n \n \n \n  hist_min = min(hist) \n \n \n \n  if hist_min < hist_first - self.threshold:  # small enough \n \n \n \n  return None \n \n \n \n  else: \n \n \n \n  hist_max = max(hist) \n \n \n \n  if hist_max > hist_first + self.threshold:  # large enough \n \n \n \n  return None \n \n \n \n  self.last_changed_epoch = self.epoch_num \n \n \n \n  logger.info( \n \n \n \n  \"[StatMonitorParamSetter] Triggered, history of {}: \".format( \n \n \n \n  self.stat_name) + ','.join([str(round(x, 3)) for x in hist])) \n \n \n \n  return self.value_func(self.get_current_value()) \n \n \n \n \n \n last_k in the above class means the last k epochs. But L352 only uses the last k values in the hist (hist = self.trainer.monitors.get_history(self.stat_name)) variable. And if you set period in the following class to be greater than 0, the hist variable can also be appended values within each epoch together with at the end of each epoch which will lead to that the last k values in hist doesn't correspond to the last k epochs.\n \n \n \n tensorpack/tensorpack/callbacks/summary.py\n \n \n          Line 101\n       in\n       da143e0\n \n \n \n \n \n \n  def MergeAllSummaries(period=0, run_alone=False, key=tf.GraphKeys.SUMMARIES): \n \n \n \n \n \n Since the class StatMonitorParamSetter  seems coupling with class MergeAllSummaries, I think you can change the last_k's meaning to be the last k period which is defined in MergeAllSummaries, and also change some epoch-related code in the class StatMonitorParamSetter. Otherwise users cannot use this class together with setting period to be greater than 0 in MergeAllSummaries.\n \t"}, "comments": {}}, "commit": {"commit_id": "cbcaef73505c6175d75c0257a925ecdc43851122", "commit_author": "Yuxin Wu", "commitT": "2018-09-30 00:08:48-07:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tensorpack\\callbacks\\monitor.py", "file_new_name": "tensorpack\\callbacks\\monitor.py", "file_complexity": {"file_NLOC": "327", "file_CCN": "97", "file_NToken": "2123"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "475", "deleted_lines": null, "method_info": {"method_name": "get_latest", "method_params": "self,name", "method_startline": "472", "method_endline": "477", "method_complexity": {"method_NLOC": "6", "method_CCN": "2", "method_NToken": "41", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "126,127,128,129", "deleted_lines": null, "method_info": {"method_name": "_setup_graph", "method_params": "self", "method_startline": "126", "method_endline": "129", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "15", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "212,213,214", "deleted_lines": null, "method_info": {"method_name": "get_history", "method_params": "self,name", "method_startline": "206", "method_endline": "216", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "17", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "470", "deleted_lines": null, "method_info": {"method_name": "process_scalar", "method_params": "self,name,val", "method_startline": "469", "method_endline": "470", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "29", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorpack\\callbacks\\param.py", "file_new_name": "tensorpack\\callbacks\\param.py", "file_complexity": {"file_NLOC": "236", "file_CCN": "63", "file_NToken": "1336"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "366,367,369,370,371,372,375,376,377,378,379,382,383,385,389,395", "deleted_lines": "366", "method_info": {"method_name": "_get_value_to_set", "method_params": "self", "method_startline": "364", "method_endline": "396", "method_complexity": {"method_NLOC": "29", "method_CCN": "11", "method_NToken": "232", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "177,178", "deleted_lines": null, "method_info": {"method_name": "_before_train", "method_params": "self", "method_startline": "176", "method_endline": "178", "method_complexity": {"method_NLOC": "3", "method_CCN": "2", "method_NToken": "15", "method_nesting_level": "1"}}}}}}}}