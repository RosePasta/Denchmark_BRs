{"BR": {"BR_id": "3240", "BR_author": "kevinthesun", "BRopenT": "2019-05-24T20:55:56Z", "BRcloseT": "2019-07-24T18:48:47Z", "BR_text": {"BRsummary": "[TOPI] Operator overloading issue when dealing with zero-rank tensor", "BRdescription": "\n This PR <denchmark-link:https://github.com/apache/tvm/pull/1029>#1029</denchmark-link>\n  overloads binary op for tensor to use topi broadcast op when importing topi. This will cause topi.compute to fail when zero-rank tensor appears in the fcompute body, since a topi broadcast op returns a tensor while comm_reducer requires an expr:\n import tvm\n from tvm import relay\n \n n = 10\n A = tvm.placeholder((n, ), name='A')\n scale = tvm.placeholder((), name='scale')\n k = tvm.reduce_axis((0, n), name=\"k\")\n fcompute = lambda : tvm.sum(A[k] * scale, axis=k)\n C = tvm.compute((), fcompute, name=\"C\")\n Error msg:\n <denchmark-code>Traceback (most recent call last):\n   File \"test.py\", line 9, in <module>\n     C = tvm.compute((), fcompute, name=\"C\")\n   File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tvm-0.6.dev0-py3.6-macosx-10.11-x86_64.egg/tvm/api.py\", line 309, in compute\n     body = fcompute(*[v.var for v in dim_var])\n   File \"test.py\", line 8, in <lambda>\n     fcompute = lambda : tvm.sum(A[k] * scale, axis=k)\n   File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tvm-0.6.dev0-py3.6-macosx-10.11-x86_64.egg/tvm/api.py\", line 819, in reducer\n     return _make_reduce(expr, axis, where)\n   File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tvm-0.6.dev0-py3.6-macosx-10.11-x86_64.egg/tvm/api.py\", line 795, in _make_reduce\n     assert isinstance(expr, _expr.Expr)\n AssertionError\n </denchmark-code>\n \n <denchmark-link:https://github.com/tqchen>@tqchen</denchmark-link>\n  <denchmark-link:https://github.com/jroesch>@jroesch</denchmark-link>\n  <denchmark-link:https://github.com/yzhliu>@yzhliu</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "kevinthesun", "commentT": "2019-05-30T17:43:30Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/kevinthesun>@kevinthesun</denchmark-link>\n  please followup to propose a fix for this.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "kevinthesun", "commentT": "2019-07-06T21:33:22Z", "comment_text": "\n \t\tping <denchmark-link:https://github.com/kevinthesun>@kevinthesun</denchmark-link>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "kevinthesun", "commentT": "2019-07-09T02:10:56Z", "comment_text": "\n \t\tIs it possible we force binary op to be the correct implementation inside tvm.compute?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "kevinthesun", "commentT": "2019-07-09T17:02:08Z", "comment_text": "\n \t\tBecause it is not context-dependent, it is harder to do force that. We could, however, avoid force  TensorSlice mul scalar to always get an Expr(which should fix your case)\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "kevinthesun", "commentT": "2019-07-13T20:32:37Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/kevinthesun>@kevinthesun</denchmark-link>\n  what is the status on this?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "kevinthesun", "commentT": "2019-07-15T22:39:39Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tqchen>@tqchen</denchmark-link>\n  Did you mean force mul-scalar to always get Expr?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "kevinthesun", "commentT": "2019-07-17T23:55:29Z", "comment_text": "\n \t\tit depends on the type. If it is TensorSlice that has 0-rank, we could always return Expr.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "kevinthesun", "commentT": "2019-07-24T18:06:32Z", "comment_text": "\n \t\tAfter i think a bit more about it. I think the problem was that we do need to represent the 0-rank tensor as TensorSlice, so in the above case, we should instead write(note the call in the scale)\n import tvm\n from tvm import relay\n \n n = 10\n A = tvm.placeholder((n, ), name='A')\n scale = tvm.placeholder((), name='scale')\n k = tvm.reduce_axis((0, n), name=\"k\")\n fcompute = lambda : tvm.sum(A[k] * scale(), axis=k)\n C = tvm.compute((), fcompute, name=\"C\")\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "kevinthesun", "commentT": "2019-07-24T18:12:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/apache/tvm/pull/3612>#3612</denchmark-link>\n  makes the test cases more conservative. So that the topi behavior can remains the same.\n \t\t"}}}, "commit": {"commit_id": "90eee08746d7b96d834331aa910a760451330f7b", "commit_author": "Tianqi Chen", "commitT": "2019-07-24 11:48:39-07:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "1.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tests\\python\\unittest\\test_codegen_llvm.py", "file_new_name": "tests\\python\\unittest\\test_codegen_llvm.py", "file_complexity": {"file_NLOC": "462", "file_CCN": "69", "file_NToken": "5294"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "353,354", "deleted_lines": "352,353", "method_info": {"method_name": "test_rank_zero", "method_params": "", "method_startline": "346", "method_endline": "367", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "10", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "377,378", "deleted_lines": "376,377", "method_info": {"method_name": "test_rank_zero_bound_checkers.check_llvm", "method_params": "n", "method_startline": "370", "method_endline": "390", "method_complexity": {"method_NLOC": "19", "method_CCN": "2", "method_NToken": "284", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "377,378", "deleted_lines": "376,377", "method_info": {"method_name": "test_rank_zero_bound_checkers", "method_params": "", "method_startline": "369", "method_endline": "391", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "10", "method_nesting_level": "0"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "353,354", "deleted_lines": "352,353", "method_info": {"method_name": "test_rank_zero.check_llvm", "method_params": "n", "method_startline": "347", "method_endline": "366", "method_complexity": {"method_NLOC": "18", "method_CCN": "2", "method_NToken": "274", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "topi\\python\\topi\\generic_op_impl.py", "file_new_name": "topi\\python\\topi\\generic_op_impl.py", "file_complexity": {"file_NLOC": "25", "file_CCN": "6", "file_NToken": "226"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "82,83", "deleted_lines": null, "method_info": {"method_name": "_make_bop._tensor_bop_impl", "method_params": "lhs,rhs", "method_startline": "56", "method_endline": "86", "method_complexity": {"method_NLOC": "6", "method_CCN": "3", "method_NToken": "65", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "82,83", "deleted_lines": null, "method_info": {"method_name": "_make_bop", "method_params": "broadcast_bop,orig_bop", "method_startline": "25", "method_endline": "88", "method_complexity": {"method_NLOC": "5", "method_CCN": "1", "method_NToken": "31", "method_nesting_level": "0"}}}}}}}}