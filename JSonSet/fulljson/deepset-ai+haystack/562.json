{"BR": {"BR_id": "562", "BR_author": "x0rzkov", "BRopenT": "2020-11-06T15:37:31Z", "BRcloseT": "2020-11-16T15:08:13Z", "BR_text": {"BRsummary": "Duplicate document bulk index error with Faiss document store", "BRdescription": "\n Hi,\n Hope you are all well !\n I think that a parameter is missing for the faiss document store while writing documents like you made for elasticesarch.\n :param update_existing_documents: Whether to update any existing documents with the same ID when adding\n documents. When set as True, any document with an existing ID gets updated.\n If set to False, an error is raised if the document ID of the document being\n added already exists.\n Because, I tried to load some documents and I have the following error preventing me to load the full dataset into the faiss store.\n Error:This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (MySQLdb._exceptions.IntegrityError) (1062, \"Duplicate entry '52713153-stackoverflow.com' for key 'PRIMARY'\")\n [SQL: INSERT INTO document (id, text, `index`, vector_id) VALUES (%s, %s, %s, %s)]\n [parameters: (('52713148-stackoverflow.com', b'Question: \\nBehaviorSubject next method not updating changes for another component \\n <p>Hello I have developed user service, working of that user s ... (63 characters truncated) ... lationship with them. if i am changing data from peoplecompoent it is not detected by inboxcomponent. Here i am posnting code for \\n\\n Answer: \\nBody', 'document', None), ('52713149-stackoverflow.com', b\"Question: \\nposition of floating button changes with number of elements in flatlist in react native \\n <p>I have a flatlist below which I need to pl ... (80 characters truncated) ... bottom edge of the screen; instead, I want the flatlist window to be a fixed size and scrollable to accommodate more rows. Below t\\n\\n Answer: \\nBody\", 'document', None), ('52713150-stackoverflow.com', b\"Question: \\nRails 6, Devise and Active Storage \\n <p>I'm using Devise and Active Storage in my rails 6 application. Currently using <code>before_act ... (27 characters truncated) ... de> disables all images for non users, which is great, except I want to allow images with the <code>record_type</code> 'News' in m\\n\\n Answer: \\nBody\", 'document', None), ('52713152-stackoverflow.com', b'Question: \\nfish shell shows error in piping - new error \\n \"<p><a href=\"\"https://i.stack.imgur.com/wyBue.jpg\"\" rel=\"\"nofollow noreferrer\"\"><img src ... (37 characters truncated) ... g\"\" alt=\"\"enter image description here\"\" /></a>I am getting multiple errors from shell init scripts which more or less seem the sa\\n\\n Answer: \\nBody', 'document', None), ('52713153-stackoverflow.com', b'Question: \\nApplying CSS to Datatables that has NEXT Page \\n \"<p>I have this Script that works and does what I need, but it will only apply to the f ... (289 characters truncated) ... our $.each loop each time the page changes or (I think better) use <a href=\"\"https://datatables.net/reference/option/createdRow\"\" rel=\"\"nofollow nore', 'document', None), ('52713154-stackoverflow.com', b'Question: \\nNumber of rows in a datetime index sampled by day \\n \"<p>I am trying to count the number of rows of the index in Data frame X and then g ... (42 characters truncated) ... as Data frame Y showing 11 rows on 7/10/2020 and 12 rows in 7/11/2020</p> <p><img src=\"\"https://i.stack.imgur.com/rLX5o.jpg\"\" alt=\\n\\n Answer: \\nBody', 'document', None), ('52713157-stackoverflow.com', b'Question: \\nIs it possible to turn a gameObject (using DontDestroyOnLoad()) into a child of a gameObject from another scene? \\n <p>I am making a 2d  ... (127 characters truncated) ... ite Renderer (in the game scene) is enabled and all other sprites are disabled... so I made an empty object containing the skins (\\n\\n Answer: \\nBody', 'document', None), ('52713159-stackoverflow.com', b'Question: \\nRobotframework for loop continue with next test \\n <p>I have below code:</p> <pre><code>*** Settings *** Library     OperatingSystem Lib ... (291 characters truncated) ... ramework.org/robotframework/latest/RobotFrameworkUserGuide.html#templates-with-for-loops\"\" rel=\"\"nofollow noreferrer\"\">Templates with for loops</a>, ', 'document', None)  ... displaying 10 of 500 total bound parameter sets ...  ('52714181-stackoverflow.com', b'Question: \\nLogin & registration redirects - don\\'t redirect login when on checkout page in WooCommerce \\n \"<p>My code works as expected but it shou ... (84 characters truncated) ... code>is_checkout()</code> to try and detect this but it is not working as expected.</p> <pre class=\"\"lang-php prettyprint-override\\n\\n Answer: \\nBody', 'document', None), ('52714183-stackoverflow.com', b'Question: \\nHow to activate autocomplete option of tomtom in my html code? \\n \"<p>I have the following simple code for using tomtom which works:</p> ... (61 characters truncated) ... \\'use-all-space\\'&gt;     &lt;head&gt;     &lt;meta http-equiv=\\'X-UA-Compatible\\' content=\\'IE=Edge\\' /&gt;     &lt;meta charset=\\n\\n Answer: \\nBody', 'document', None))]\n (Background on this error at: http://sqlalche.me/e/13/gkpj) (Background on this error at: http://sqlalche.me/e/13/7s2a)\n document_store.write_documents=1557\n Bulk not indexed\n Cheers,\n X\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "x0rzkov", "commentT": "2020-11-10T11:46:41Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n  Any ideas how to fix it ?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "x0rzkov", "commentT": "2020-11-12T09:51:10Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/x0rzkov>@x0rzkov</denchmark-link>\n ,\n Sorry, it's been crazily busy days on our side. It's correct that FAISSDocumentStore does not support update_existing_documents yet. What is your intended workflow here? Do you really want to update a subset of your existing documents?\n If you are just trying to load documents and face this error, it probably means that you still have documents in SQL from a previous run while the FAISS index does not know about them. You can call  document_store.delete_all_documents() or manually drop the tables in SQL.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "x0rzkov", "commentT": "2020-11-12T10:43:16Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n  ,\n Hope you are all well !\n I am converting the xml stackoverflow dump, extracting pairs of question with their validated answers. Each time, I insert those pairs in the db and update the delta of pairs that have changed.\n Would be also convenient to have an ignore flag if duplicate meanwhile you implement the update_existing_documents feature ^^\n Is there a quick workaround ?\n Cheers,\n X\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "x0rzkov", "commentT": "2020-11-12T19:23:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/x0rzkov>@x0rzkov</denchmark-link>\n  Two dirty hack you can do -\n \n If you want to update docs on duplicate then, change session.add( to session.merge( at this place https://github.com/deepset-ai/haystack/blob/master/haystack/document_store/sql.py#L135\n If you want to skip on duplicate then, wrap this line under try/catch. https://github.com/deepset-ai/haystack/blob/master/haystack/document_store/sql.py#L135\n \n For more information please refer <denchmark-link:https://stackoverflow.com/questions/6611563/sqlalchemy-on-duplicate-key-update#:~:text=ON%20DUPLICATE%20KEY%20UPDATE%20functionality,question%20is%20a%20primary%20key>https://stackoverflow.com/questions/6611563/sqlalchemy-on-duplicate-key-update#:~:text=ON%20DUPLICATE%20KEY%20UPDATE%20functionality,question%20is%20a%20primary%20key</denchmark-link>\n .\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "x0rzkov", "commentT": "2020-11-12T19:30:58Z", "comment_text": "\n \t\tI forgot to mention that in either hack you have to clear faiss_index before calling update_embeddings function. You can do as follows -\n <denchmark-code>faiss_document_store.faiss_index.reset()\n </denchmark-code>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "x0rzkov", "commentT": "2020-11-13T05:18:35Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n \n Hope you are all well !\n Thanks, I ll have a try this morning ^^\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "x0rzkov", "commentT": "2020-11-13T14:05:05Z", "comment_text": "\n \t\tI have raised PR <denchmark-link:https://github.com/deepset-ai/haystack/pull/584>#584</denchmark-link>\n  to add this support\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "x0rzkov", "commentT": "2020-11-13T14:30:04Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n \n Thanks for this !\n You have an error in your PyTest:\n <denchmark-link:https://github.com/deepset-ai/haystack/pull/584/checks?check_run_id=1396123070>https://github.com/deepset-ai/haystack/pull/584/checks?check_run_id=1396123070</denchmark-link>\n \n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "x0rzkov", "commentT": "2020-11-13T14:39:35Z", "comment_text": "\n \t\tYes, I am trying to fix this. I can't locally test it as my docker engine is not working after macOS upgrade :(\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "x0rzkov", "commentT": "2020-11-13T20:29:59Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/x0rzkov>@x0rzkov</denchmark-link>\n  It is fixed now. Can you please give it try - <denchmark-link:https://github.com/lalitpagaria/haystack/tree/add_update_existing_documents>https://github.com/lalitpagaria/haystack/tree/add_update_existing_documents</denchmark-link>\n \n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "x0rzkov", "commentT": "2020-11-14T05:33:10Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n  and <denchmark-link:https://github.com/lalitpagaria>@lalitpagaria</denchmark-link>\n \n I rebuilt my docker container with your fork and it works fine.\n Also, I noticed that if the database encoding is , instead of , the varchar length should be 768 and not 1000.\n <denchmark-link:https://github.com/lalitpagaria/haystack/blob/add_update_existing_documents/haystack/document_store/sql.py#L44>https://github.com/lalitpagaria/haystack/blob/add_update_existing_documents/haystack/document_store/sql.py#L44</denchmark-link>\n \n And btw, it is incredibly slow to insert 10M entries, anything we can do about that ?\n I do not know, like using LOAD DATA INTO FILE command, for MySQL instances\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "x0rzkov", "commentT": "2020-11-14T08:27:27Z", "comment_text": "\n \t\tHi guys,\n Just a quick question, is it normal that the vector_id column is NULL ?\n <denchmark-link:https://user-images.githubusercontent.com/56916043/99143127-6b5bf480-265b-11eb-9309-be8a34c2ef11.png></denchmark-link>\n \n Thanks for any inputs or insights about that.\n Cheers,\n X\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "x0rzkov", "commentT": "2020-11-14T09:57:11Z", "comment_text": "\n \t\tYes this is normal. If you just call write_documents() and pass the plain documents (without embeddings) there, only their text and meta data will be added to SQL. The vectors can then later be initialized by calling doc_store.update_embeddings(retriever). We decoupled those two operations as update embeddings really depends on the retriever model you choose and is a very heavy operation (usually run on a GPU).\n However, if your workflow requires it, you could als compute the embeddings yourself, add them to the dicts and pass everything to write_documents.\n Hope this helps!\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "x0rzkov", "commentT": "2020-11-14T10:01:59Z", "comment_text": "\n \t\t<denchmark-link:https://user-images.githubusercontent.com/56916043/99144727-90a32f80-2668-11eb-8535-7a7b7034efb1.png></denchmark-link>\n \n <denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n \n Thanks for your reply :-)\n I ll tell you later how it goes for embeddings update in 28:00 hours.\n Btw, here is the dataset if you wanna play with it for demo project:\n <denchmark-link:https://www.kaggle.com/lucmichalski/stackoverflow-stackexchange-dataset-10m-qa>https://www.kaggle.com/lucmichalski/stackoverflow-stackexchange-dataset-10m-qa</denchmark-link>\n \n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "x0rzkov", "commentT": "2020-11-16T15:10:02Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/x0rzkov>@x0rzkov</denchmark-link>\n , this should now be resolved with <denchmark-link:https://github.com/deepset-ai/haystack/pull/584>#584</denchmark-link>\n . Please update here if you face any issues.\n \t\t"}}}, "commit": {"commit_id": "3f81c93f36519ab78213f145c699ce7df2c4ddf8", "commit_author": "Lalit Pagaria", "commitT": "2020-11-16 16:08:13+01:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.6", "commit_Nprams": "0.9428571428571428"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "haystack\\document_store\\faiss.py", "file_new_name": "haystack\\document_store\\faiss.py", "file_complexity": {"file_NLOC": "173", "file_CCN": "37", "file_NToken": "1247"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "113,120,121,122,123,124", "deleted_lines": null, "method_info": {"method_name": "write_documents", "method_params": "self,None", "method_startline": "102", "method_endline": "140", "method_complexity": {"method_NLOC": "24", "method_CCN": "13", "method_NToken": "223", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "40,41", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,str,int,int,str,None,True,bool,str,kwargs", "method_startline": "32", "method_endline": "42", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "65", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "154,155,156", "deleted_lines": null, "method_info": {"method_name": "update_embeddings", "method_params": "self,BaseRetriever,None", "method_startline": "142", "method_endline": "184", "method_complexity": {"method_NLOC": "26", "method_CCN": "8", "method_NToken": "231", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "haystack\\document_store\\sql.py", "file_new_name": "haystack\\document_store\\sql.py", "file_complexity": {"file_NLOC": "207", "file_CCN": "49", "file_NToken": "1960"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "157,158,159,160,161,162,163,164,165,166,167,168,169", "deleted_lines": "135,136", "method_info": {"method_name": "write_documents", "method_params": "self,None", "method_startline": "134", "method_endline": "169", "method_complexity": {"method_NLOC": "19", "method_CCN": "9", "method_NToken": "207", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "66,67", "deleted_lines": "61,67", "method_info": {"method_name": "__init__", "method_params": "self,str,index", "method_startline": "61", "method_endline": "67", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "54", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "66,67,68,69,70,71", "deleted_lines": "67", "method_info": {"method_name": "__init__", "method_params": "self,str,str,str,bool", "method_startline": "66", "method_endline": "71", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "28", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "test\\test_db.py", "file_new_name": "test\\test_db.py", "file_complexity": {"file_NLOC": "314", "file_CCN": "25", "file_NToken": "2244"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114", "deleted_lines": null, "method_info": {"method_name": "test_update_existing_documents", "method_params": "document_store,update_existing_documents", "method_startline": "90", "method_endline": "114", "method_complexity": {"method_NLOC": "21", "method_CCN": "3", "method_NToken": "136", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "144,145", "deleted_lines": null, "method_info": {"method_name": "test_write_document_index", "method_params": "document_store", "method_startline": "136", "method_endline": "148", "method_complexity": {"method_NLOC": "11", "method_CCN": "1", "method_NToken": "112", "method_nesting_level": "0"}}}}}}}}