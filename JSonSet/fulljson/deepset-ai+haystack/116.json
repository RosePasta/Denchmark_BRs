{"BR": {"BR_id": "116", "BR_author": "Ierezell", "BRopenT": "2020-05-19T14:27:06Z", "BRcloseT": "2020-06-03T14:22:56Z", "BR_text": {"BRsummary": "Cannot use EmbeddingRetriever (Indexing of embeddings)", "BRdescription": "\n I want to use an EmbeddingRetriever instead of a BM25.\n I have a huge handcrafted corpus of text files, each corresponding to a paragraph.\n The goal is to ask a question, get the k best paragraph regarding the embeddings similarity (text files and question). I've done my own method but I would like to compare with Haystack.\n I'm creating the DocumentStore as in the doc :\n <denchmark-code>document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\",  password=\"\", index=\"document\", text_field=\"answer\", embedding_field=\"question_emb\", embedding_dim=768, excluded_meta_data=[\"question_emb\"])\n     write_documents_to_db(document_store=document_store, only_empty_db=True, document_dir=\"./datas/txt\")\n </denchmark-code>\n \n Then the retriever (multilang sentence transformer):\n <denchmark-code>retriever = EmbeddingRetriever(document_store=document_store, embedding_model=\"distiluse-base-multilingual-cased\", model_format=\"sentence_transformers\")\n </denchmark-code>\n \n And finnaly when I try to retrieve the top k documents :\n <denchmark-code>top_docs = retriever.retrieve(query=q, top_k=10)\n </denchmark-code>\n \n I got this info :\n <denchmark-code>05/19/2020 10:22:49 - INFO - elasticsearch -   PUT http://localhost:9200/document [status:400 request:0.008s]\n 05/19/2020 10:22:49 - INFO - elasticsearch -   POST http://localhost:9200/_count [status:200 request:0.003s]\n 05/19/2020 10:22:49 - INFO - haystack.indexing.io -   Skip writing documents since DB already contains 2141 docs ...  (Disable `only_empty_db`, if you want to add docs anyway.)\n 05/19/2020 10:22:49 - INFO - haystack.retriever.elasticsearch -   Init retriever using embeddings of model distiluse-base-multilingual-cased\n 05/19/2020 10:22:49 - INFO - root -   Load pretrained SentenceTransformer: distiluse-base-multilingual-cased\n 05/19/2020 10:22:49 - INFO - root -   Did not find a '/' or '\\' in the name. Assume to download model from server.\n 05/19/2020 10:22:49 - INFO - root -   Load SentenceTransformer from folder: /home/pedro/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distiluse-base-multilingual-cased.zip\n 05/19/2020 10:22:51 - INFO - root -   Use pytorch device: cuda\n Batches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 148.86it/s]\n </denchmark-code>\n \n Then a traceback\n <denchmark-code>Traceback (most recent call last):\n   File \"/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/serializer.py\", line 50, in dumps\n     return json.dumps(\n   File \"/home/pedro/.local/lib/python3.8/site-packages/simplejson/__init__.py\", line 398, in dumps\n     return cls(\n   File \"/home/pedro/.local/lib/python3.8/site-packages/simplejson/encoder.py\", line 296, in encode\n     chunks = self.iterencode(o, _one_shot=True)\n   File \"/home/pedro/.local/lib/python3.8/site-packages/simplejson/encoder.py\", line 378, in iterencode\n     return _iterencode(o, 0)\n   File \"/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/serializer.py\", line 36, in default\n     raise TypeError(\"Unable to serialize %r (type: %s)\" % (data, type(data)))\n TypeError: Unable to serialize -0.065520875 (type: <class 'numpy.float32'>)\n \n During handling of the above exception, another exception occurred:\n \n Traceback (most recent call last):\n   File \"sdk/accuracy_retriever.py\", line 75, in <module>\n     top_docs = haystack_retriever(q, doc_store)\n   File \"/mnt/Documents/Projets/BotPress/R_D/R_D_q_a/sdk/retrievers.py\", line 113, in haystack_retriever\n     top_docs = retriever.retrieve(query=q, top_k=10)\n   File \"/mnt/Documents/Projets/git_clones/haystack/haystack/retriever/elasticsearch.py\", line 92, in retrieve\n     documents = self.document_store.query_by_embedding(query_emb[0], top_k, candidate_doc_ids)\n   File \"/mnt/Documents/Projets/git_clones/haystack/haystack/database/elasticsearch.py\", line 184, in query_by_embedding\n     result = self.client.search(index=self.index, body=body)[\"hits\"][\"hits\"]\n   File \"/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/client/utils.py\", line 92, in _wrapped\n     return func(*args, params=params, headers=headers, **kwargs)\n   File \"/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/client/__init__.py\", line 1622, in search\n     return self.transport.perform_request(\n   File \"/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/transport.py\", line 321, in perform_request\n     body = self.serializer.dumps(body)\n   File \"/home/pedro/.local/lib/python3.8/site-packages/elasticsearch/serializer.py\", line 54, in dumps\n     raise SerializationError(data, e)\n elasticsearch.exceptions.SerializationError: ({'size': 10, 'query': {'script_score': {'query': {'match_all': {}}, 'script': {'source': \"cosineSimilarity(params.query_vector,doc['question_emb']) + 1.0\", 'params': {'query_vector': [-0.065520875, 0.023728848, ... lot of numbers ..., 0.047961414]}}}}, '_source': {'excludes': ['question_emb']}}, TypeError(\"Unable to serialize -0.065520875 (type: <class 'numpy.float32'>)\"))\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Ierezell", "commentT": "2020-05-21T10:53:49Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/Ierezell>@Ierezell</denchmark-link>\n  ,\n For using the EmbeddingRetriever you'll need to add the embeddings for your documents to the Elasticsearch index first. At query time we can then embed the question on-the-fly and calculate similarity to the indexed embeddings.\n Please have a look at <denchmark-link:https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial4_FAQ_style_QA.py#L70>Tutorial 4</denchmark-link>\n , where we do this for \"FAQ style QA\". If you wanted to apply this to regular extractive QA, you would need to adjust the \"write_documents_to_db()\" utility function to also create the embeddings.\n We'll probably simplify this and add an example once we have implemented the DPR encoders (<denchmark-link:https://github.com/deepset-ai/haystack/issues/63>#63</denchmark-link>\n ).\n Be aware that using sentence-transformers / USE embeddings for both (question and long passages) might not yield great performance. Dual encoder approaches usually work better here.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Ierezell", "commentT": "2020-05-25T20:40:10Z", "comment_text": "\n \t\tOh sorry I thought the write_to_db would get each sentence and embed it when initialising the db. I will embed them myself first, thanks.\n Yes indeed, to overcome that I splitted my dataset in chunks.\n Because I'm looking for similarity on the content, chunking is okay and just lead to more documents.\n Furthermore, I'm doing unsupervised lookup so I don't have pairs to train an Dual encoder, but thanks a lot for the suggestion, it's a really good one \ud83d\ude03\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Ierezell", "commentT": "2020-05-26T09:33:23Z", "comment_text": "\n \t\tBesides your issue of indexing the embeddings first, there was still a small issue with the serialization of float64 returned by sentence-transformers. Fixed this in <denchmark-link:https://github.com/deepset-ai/haystack/pull/121>#121</denchmark-link>\n .\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Ierezell", "commentT": "2020-06-03T14:22:56Z", "comment_text": "\n \t\tClosing this as the original issue seems to be fixed. <denchmark-link:https://github.com/Ierezell>@Ierezell</denchmark-link>\n  feel free to re-open in case there's still a problem on your side.\n \t\t"}}}, "commit": {"commit_id": "df554fcb458515c0fd5b08dab46cc11b73acd3bb", "commit_author": "Malte Pietsch", "commitT": "2020-05-26 16:43:05+02:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "haystack\\retriever\\elasticsearch.py", "file_new_name": "haystack\\retriever\\elasticsearch.py", "file_complexity": {"file_NLOC": "59", "file_CCN": "11", "file_NToken": "470"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "118", "deleted_lines": "114", "method_info": {"method_name": "create_embedding", "method_params": "self", "method_startline": "100", "method_endline": "119", "method_complexity": {"method_NLOC": "11", "method_CCN": "7", "method_NToken": "114", "method_nesting_level": "1"}}}}}}}}