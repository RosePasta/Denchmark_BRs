{"BR": {"BR_id": "278", "BR_author": "nsankar", "BRopenT": "2020-07-31T16:18:23Z", "BRcloseT": "2020-08-03T14:22:51Z", "BR_text": {"BRsummary": "ValueError: badly formed hexadecimal UUID string    exception", "BRdescription": "\n Question\n ValueError: badly formed hexadecimal UUID string      exception\n Additional context\n I created a document store in elasticsearch by tokenizing text from a pdf document\n when I used the DensePassageRetriever,\n from haystack.retriever.dense import DensePassageRetriever\n retriever = DensePassageRetriever(document_store=document_store, embedding_model=\"dpr-bert-base-nq\",do_lower_case=True, use_gpu=True)\n document_store.update_embeddings(retriever)\n I get the following ValueError  . What could be the reason ? and would like to know how to fix this issue?\n 07/31/2020 16:12:59 - INFO - haystack.retriever.dpr_utils -   Loading saved model from models/dpr/checkpoint/retriever/single/nq/bert-base-encoder.cp\n 07/31/2020 16:12:59 - INFO - haystack.retriever.dense -   Loaded encoder params:  {'do_lower_case': True, 'pretrained_model_cfg': 'bert-base-uncased', 'encoder_model_type': 'hf_bert', 'pretrained_file': None, 'projection_dim': 0, 'sequence_length': 256}\n 07/31/2020 16:13:09 - INFO - haystack.retriever.dense -   Loading saved model state ...\n 07/31/2020 16:13:09 - INFO - haystack.retriever.dense -   Loading saved model state ...\n 07/31/2020 16:13:09 - INFO - elasticsearch -   POST https://df4bc7e5f2a54314ac10223dd343fe94.us-central1.gcp.cloud.es.io:9243/document/_search?scroll=5m&size=1000 [status:200 request:0.139s]\n ---------------------------------------------------------------------------\n ValueError                                Traceback (most recent call last)\n <ipython-input-22-9372aaabee19> in <module>()\n      11 # At query time, we only need to embed the query and compare it the existing doc embeddings which is very fast.\n      12 \n ---> 13 document_store.update_embeddings(retriever)\n      14 \n      15 # ES retreivar\n \n 5 frames\n /usr/lib/python3.6/uuid.py in __init__(self, hex, bytes, bytes_le, fields, int, version)\n     138             hex = hex.strip('{}').replace('-', '')\n     139             if len(hex) != 32:\n --> 140                 raise ValueError('badly formed hexadecimal UUID string')\n     141             int = int_(hex, 16)\n     142         if bytes_le is not None:\n \n **ValueError: badly formed hexadecimal UUID string**\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "nsankar", "commentT": "2020-08-02T02:59:54Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/nsankar>@nsankar</denchmark-link>\n  I obtained the same error by posting to the API endpoint /models/{model_id}/doc-qa with an Elasticsearch Document Store.  Hopefully my findings can help you out. Digging further into the issue I noticed that this line \n  was causing the issue.  It looks like the returned results by Elasticsearch are passed to \n  which by definition as seen here the field id \n  can be a string or a UUID, however because my elasticsearch ids are not hex based strings then it fails like previously mentioned on line \n \n I got around the issue on my local codebase by doing the following changes:\n \n \n modified line 35 from base.py to self.id = id\n \n \n adding to \n \n \n haystack/rest_api/controller/search.py\n \n \n          Line 4\n       in\n       d90435e\n \n \n \n \n \n \n  from typing import List, Dict, Optional \n \n \n \n \n  the type Union\n \n \n Correcting \n \n \n haystack/rest_api/controller/search.py\n \n \n          Line 119\n       in\n       d90435e\n \n \n \n \n \n \n  document_id: Optional[UUID] = None \n \n \n \n \n  to match the type flexibility defined in \n \n \n haystack/haystack/database/base.py\n \n \n          Line 8\n       in\n       d90435e\n \n \n \n \n \n \n  id: Optional[Union[str, UUID]] = None, \n \n \n \n \n  by modifying line 119 of search.py to document_id: Optional[Union[str, UUID]] = None\n \n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "nsankar", "commentT": "2020-08-02T09:46:53Z", "comment_text": "\n \t\t\n however because my elasticsearch ids are not hex based strings [...]\n \n <denchmark-link:https://github.com/karimjp>@karimjp</denchmark-link>\n  <denchmark-link:https://github.com/nsankar>@nsankar</denchmark-link>\n  Do I get this right that you both use your own \"custom\" elasticsearch indices that have been created without using DocumentStore.write_documents()?\n <denchmark-link:https://github.com/tanaysoni>@tanaysoni</denchmark-link>\n  Can you please investigate this further and work on a fix? I think we didn't cover this use case in the last PR that introduced UUIDs (<denchmark-link:https://github.com/deepset-ai/haystack/pull/243>#243</denchmark-link>\n  )\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "nsankar", "commentT": "2020-08-02T15:32:05Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n  I used DocumentStore.write_documents() to ingest my documents in elasticsearch 7.8.1. The latest commit on master at that time was <denchmark-link:https://github.com/deepset-ai/haystack/commit/52a805be86414ea987cf6bf5be6bb5f6e2bf8f53>52a805b</denchmark-link>\n . Later, I pulled the latest changes and tried to run the API when I started seeing the errors related the uuid.  However, the case of custom indices is possible and if so an Elasticsearch document would need to be compatible with an _id field of at most <denchmark-link:https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-id-field.html>512 bytes</denchmark-link>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "nsankar", "commentT": "2020-08-02T16:36:43Z", "comment_text": "\n \t\tOk got it. In that older commit we were still indexing with arbitrary IDs. The switch to UUID is now causing the issue.\n <denchmark-link:https://github.com/tanaysoni>@tanaysoni</denchmark-link>\n  what do you think? Shall we allow also arbitrary string IDs in the Document class, even though we loose assurance of uniqueness? Otherwise support of already existing, custom ES Indices might be difficult.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "nsankar", "commentT": "2020-08-03T03:10:21Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n  I didn't use any custom ES indexing when I reported the error. I was using the standard Haystack APIs. My Elastic search instance  is an externally hosted one .that's it.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "nsankar", "commentT": "2020-08-03T03:23:34Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n   How about Numeric hashes instead of UUIDs ?\n <denchmark-link:https://www.elastic.co/blog/efficient-duplicate-prevention-for-event-based-data-in-elasticsearch>https://www.elastic.co/blog/efficient-duplicate-prevention-for-event-based-data-in-elasticsearch</denchmark-link>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "nsankar", "commentT": "2020-08-03T09:28:22Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/nsankar>@nsankar</denchmark-link>\n  and <denchmark-link:https://github.com/karimjp>@karimjp</denchmark-link>\n , thank you for raising the issue.\n \n \n Shall we allow also arbitrary string IDs in the Document class\n \n <denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n  from how I see, there are some constraints for the document IDs:\n \n the Document object is generic across different document store implementations, so the IDs should be compatible across document stores.\n for the creation of new documents via write_documents(), the IDs must be unique.\n \n For supporting existing document stores not created with Haystack, we cannot rely on the availability of UUIDs.\n As a workaround, we can change the Document.id to be always of str type. When we create a new document, we assign a UUID string under the hood, otherwise, we read string(or numeric) values from an existing index as str.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "nsankar", "commentT": "2020-08-03T11:07:49Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tanaysoni>@tanaysoni</denchmark-link>\n  Yeah, I think changing the id to str type would be good. It will come at some costs of risking duplicates if user provide their own id and don't check uniqueness by themselves, but I think the flexibility we gain (e.g support for custom indices and existing IDs from QA datasets) outweighs this.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "nsankar", "commentT": "2020-08-03T12:39:01Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tanaysoni>@tanaysoni</denchmark-link>\n  <denchmark-link:https://github.com/tholor>@tholor</denchmark-link>\n   Sounds good!\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "nsankar", "commentT": "2020-08-03T14:22:50Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/nsankar>@nsankar</denchmark-link>\n  and <denchmark-link:https://github.com/karimjp>@karimjp</denchmark-link>\n , this should now be resolved with <denchmark-link:https://github.com/deepset-ai/haystack/pull/284>#284</denchmark-link>\n . I am closing this issue but please feel free to re-open if you still face any errors.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "nsankar", "commentT": "2020-08-03T14:29:41Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tanaysoni>@tanaysoni</denchmark-link>\n  thank you for taking a look at this issue. Not sure if this should go into another issue, but here is another use case for generating a unique ID with  beyond the use of UUIDs.\n \n Document Hash as ID case: A user has a directory with multiple documents to write documents from and keeps adding documents to it.  In order to prevent duplicate documents from being inserted with a different id the document id needs to have a hash of the document itself.\n \n I haven't tested what happens if I have an index with a custom mapping and my document to be inserted using write_documents() already has an _id field with any string I define but if that works, it could be the right answer for the use case above.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "nsankar", "commentT": "2020-08-04T06:57:50Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/karimjp>@karimjp</denchmark-link>\n , for the document hash case, you can use the newly added(<denchmark-link:https://github.com/deepset-ai/haystack/pull/285>#285</denchmark-link>\n )  parameter for the . When the parameter is set to , the documents with the same id gets updated. Otherwise, when set to , the document store throws an error if a document with the given id already exists.\n \t\t"}}}, "commit": {"commit_id": "723921475f905077065183111c5d445aaa8ce5fa", "commit_author": "Tanay Soni", "commitT": "2020-08-03 16:20:17+02:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "1.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "haystack\\database\\base.py", "file_new_name": "haystack\\database\\base.py", "file_complexity": {"file_NLOC": "96", "file_CCN": "21", "file_NToken": "656"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "8", "deleted_lines": "8", "method_info": {"method_name": "__init__", "method_params": "self,str,str,None,None,None,str,None,str,None,None", "method_startline": "7", "method_endline": "13", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "78", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "149", "method_info": {"method_name": "get_document_by_id", "method_params": "self,UUID,None", "method_startline": "149", "method_endline": "150", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "69", "deleted_lines": "72", "method_info": {"method_name": "__init__", "method_params": "self,str,str,bool,bool,str,None,None,None,None", "method_startline": "64", "method_endline": "72", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "61", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "140", "deleted_lines": null, "method_info": {"method_name": "get_document_by_id", "method_params": "self,str,None", "method_startline": "140", "method_endline": "141", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "1"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "69", "deleted_lines": "72", "method_info": {"method_name": "__init__", "method_params": "self,str,str,bool,bool,str,None,None,None,None", "method_startline": "67", "method_endline": "75", "method_complexity": {"method_NLOC": "9", "method_CCN": "1", "method_NToken": "61", "method_nesting_level": "1"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "8", "deleted_lines": "8", "method_info": {"method_name": "__init__", "method_params": "self,str,str,None,None,str,None,str,None,None", "method_startline": "7", "method_endline": "13", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "70", "method_nesting_level": "1"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "haystack\\database\\elasticsearch.py", "file_new_name": "haystack\\database\\elasticsearch.py", "file_complexity": {"file_NLOC": "331", "file_CCN": "58", "file_NToken": "2560"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "124", "deleted_lines": "125", "method_info": {"method_name": "get_document_by_id", "method_params": "self,str,index", "method_startline": "124", "method_endline": "131", "method_complexity": {"method_NLOC": "7", "method_CCN": "3", "method_NToken": "84", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "125", "method_info": {"method_name": "get_document_by_id", "method_params": "self,UUID,index", "method_startline": "125", "method_endline": "132", "method_complexity": {"method_NLOC": "7", "method_CCN": "3", "method_NToken": "89", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "haystack\\database\\memory.py", "file_new_name": "haystack\\database\\memory.py", "file_complexity": {"file_NLOC": "130", "file_CCN": "49", "file_NToken": "1164"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "67", "deleted_lines": "67", "method_info": {"method_name": "get_document_by_id", "method_params": "self,str,None", "method_startline": "67", "method_endline": "69", "method_complexity": {"method_NLOC": "3", "method_CCN": "2", "method_NToken": "37", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "49", "deleted_lines": "49", "method_info": {"method_name": "write_labels", "method_params": "self,None", "method_startline": "44", "method_endline": "50", "method_complexity": {"method_NLOC": "6", "method_CCN": "5", "method_NToken": "83", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "67", "deleted_lines": "67", "method_info": {"method_name": "get_document_by_id", "method_params": "self,str,None", "method_startline": "67", "method_endline": "69", "method_complexity": {"method_NLOC": "3", "method_CCN": "2", "method_NToken": "42", "method_nesting_level": "1"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "haystack\\database\\sql.py", "file_new_name": "haystack\\database\\sql.py", "file_complexity": {"file_NLOC": "158", "file_CCN": "35", "file_NToken": "1292"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "72", "deleted_lines": "73", "method_info": {"method_name": "get_document_by_id", "method_params": "self,str,index", "method_startline": "72", "method_endline": "76", "method_complexity": {"method_NLOC": "5", "method_CCN": "3", "method_NToken": "62", "method_nesting_level": "1"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "151", "deleted_lines": null, "method_info": {"method_name": "write_labels", "method_params": "self,labels,index", "method_startline": "145", "method_endline": "164", "method_complexity": {"method_NLOC": "19", "method_CCN": "5", "method_NToken": "133", "method_nesting_level": "1"}}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "73", "method_info": {"method_name": "get_document_by_id", "method_params": "self,UUID,index", "method_startline": "73", "method_endline": "77", "method_complexity": {"method_NLOC": "5", "method_CCN": "3", "method_NToken": "62", "method_nesting_level": "1"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rest_api\\controller\\search.py", "file_new_name": "rest_api\\controller\\search.py", "file_complexity": {"file_NLOC": "156", "file_CCN": "12", "file_NToken": "952"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "118", "deleted_lines": "5,119"}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "test\\test_tfidf_retriever.py", "file_new_name": "test\\test_tfidf_retriever.py", "file_complexity": {"file_NLOC": "16", "file_CCN": "1", "file_NToken": "117"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "17", "deleted_lines": "1,2,3", "method_info": {"method_name": "test_tfidf_retriever", "method_params": "", "method_startline": "1", "method_endline": "19", "method_complexity": {"method_NLOC": "16", "method_CCN": "1", "method_NToken": "116", "method_nesting_level": "0"}}}}}}}}