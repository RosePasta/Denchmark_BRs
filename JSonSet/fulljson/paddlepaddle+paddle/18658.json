{"BR": {"BR_id": "18658", "BR_author": "jczaja", "BRopenT": "2019-07-16T13:49:09Z", "BRcloseT": "2019-08-30T09:13:20Z", "BR_text": {"BRsummary": "[MKL-DNN] Failure to run face model (demark)", "BRdescription": "\n Hi,\n We have just tested that internal face model of yours (demark) stopped to work with mkl-dnn (it is fine when paddle naive ops are used).\n commit tested:\n <denchmark-link:https://github.com/PaddlePaddle/Paddle/commit/fd6631ef2fb8c896f89ddaa94a5112c08665f35b>fd6631e</denchmark-link>\n \n commandline used:\n ./paddle/fluid/inference/tests/api/test_analyzer_image_classification  --infer_model=/home/jczaja/models/demark/demark/ --gtest_filter=*profile_mkldnn --batch_size=1\n Output:\n Exception: /home/jczaja/paddle/paddle/fluid/memory/detail/meta_cache.cc:33 Assertiondesc->check_guards()failed. terminate called after throwing an instance of 'std::runtime_error' what():  Exception encounter. Aborted\n We do not know yet when exactly problem appeared\n <denchmark-link:https://github.com/luotao1>@luotao1</denchmark-link>\n  Could you please confirm that demark model does fail  for you when mkl-dnn is used? If all works for you then tell us revision used and commandline\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jczaja", "commentT": "2019-07-17T02:12:51Z", "comment_text": "\n \t\tI will confirm it ASAP.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jczaja", "commentT": "2019-07-19T04:58:46Z", "comment_text": "\n \t\tI could run successfully with the latest develop branch on demark model.\n please check the md5sum for it.\n <denchmark-code>e5fa00447f90969a95e2b77fd5b77c26  demark/model\n 9c8ab6ea9db3b5d59b70d68bf0086524  demark/params\n </denchmark-code>\n \n command:\n <denchmark-code>./test_analyzer_image_classification --gtest_filter=Analyzer_resnet50.profile_mkldnn --batch_size=1 --warmup --repeat=100 --paddle_num_threads=4 --infer_model=face_model/demark\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jczaja", "commentT": "2019-07-19T08:28:38Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/luotao1>@luotao1</denchmark-link>\n  it keeps failing for me, md5sums are fine. Could you provide me build command you used?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jczaja", "commentT": "2019-07-19T08:54:00Z", "comment_text": "\n \t\tWhich mkldnn version do you use?\n The build command is in <denchmark-link:https://github.com/PaddlePaddle/Paddle/issues/18658#issuecomment-513090602>#18658 (comment)</denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jczaja", "commentT": "2019-07-19T09:14:23Z", "comment_text": "\n \t\tI meant cmake command you used to build PaddlePaddle. I just cloned current develop branch so mkldnn version is 0.18\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "jczaja", "commentT": "2019-07-19T09:36:39Z", "comment_text": "\n \t\tHow about give your CMake command at first?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "jczaja", "commentT": "2019-07-19T10:00:12Z", "comment_text": "\n \t\tMy cmake command is\n <denchmark-code>cmake .. -DON_INFER=ON -DWITH_GPU=OFF -DWITH_MKLDNN=ON -DCMAKE_BUILD_TYPE=Release -DWITH_TESTING=ON -DWITH_PYTHON=ON -DWITH_INFERENCE_API_TEST=ON\n </denchmark-code>\n \n <denchmark-link:https://github.com/grygielski>@grygielski</denchmark-link>\n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "jczaja", "commentT": "2019-07-19T11:16:47Z", "comment_text": "\n \t\tI've been using same command for building. We'll have to take look at it.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "jczaja", "commentT": "2019-08-02T17:36:32Z", "comment_text": "\n \t\tStatus:\n Problem root caused. Mkl-dnn activation op for getting y tensor allocated is using:\n T *y_data = y->mutable_data<T>(ctx.GetPlace());\n This is wrong, for out of place computation as when blocked formats (NCHW16C) are used\n allocation may be a bit bigger that N*C*H*W*sizeof(data_type), as implicit padding may be present.\n Proper allocation should be:\n  T *y_data = y->mutable_data<T>(ctx.GetPlace(), activation_pd->dst_primitive_desc().get_size());\n as destination primitive descriptor holds total number of allocation size.\n <denchmark-h:h4>Notes:</denchmark-h>\n \n \n If allocation is not big enough then it is likely that meta-data of next chunk of memory\n in buddy allocator will be overwritten resulting in a crash as presented in first entry of this issue.\n Problem does not manifest on Face Model of BDW platform because activation (tanh) is using\n NCHW format then no implict padding is used by mkl-dnn so size of allocation is proper\n \n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "jczaja", "commentT": "2019-08-03T14:40:11Z", "comment_text": "\n \t\t\n Problem does not manifest on Face Model of BDW platform\n \n What's the meaning of BDW? I still don't know why I could run OK on this model but you got fails. What's the reason of it, different machine?\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "jczaja", "commentT": "2019-08-06T15:16:16Z", "comment_text": "\n \t\tI guess Jacek meant that You are running models on Broadwell (BDW) architecture: <denchmark-link:https://en.wikipedia.org/wiki/Broadwell_(microarchitecture)>https://en.wikipedia.org/wiki/Broadwell_(microarchitecture)</denchmark-link>\n . It doesn't support AVX-512 processor operations (<denchmark-link:https://en.wikipedia.org/wiki/Advanced_Vector_Extensions>https://en.wikipedia.org/wiki/Advanced_Vector_Extensions</denchmark-link>\n ) so it uses older ones which have different data formats (e.g. NCHW instead of NCHW16C). <denchmark-link:https://github.com/luotao1>@luotao1</denchmark-link>\n \n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "jczaja", "commentT": "2019-08-07T02:02:41Z", "comment_text": "\n \t\tGot it. We use E5-2650 v4 CPU, which only support AVX2.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "jczaja", "commentT": "2019-08-22T17:11:07Z", "comment_text": "\n \t\tStatus of investigation: Failure (accuracy problems) are a result that fetch operator does not perform conversion of mkl-dnn data into paddle data. OperatorsWithKernel are invoking PrepareData which may trigger conversion from MKL-DNN data format into Paddle data format. For face model just before fetch op there is \"tanh\" operator which is executed by mkl-dnn . For AVX512 tanh will work on mkl-dnn format nchw16c  and will send tensor of such data format into fetch op. Fetch assumes this tensor is NCHW and will copy it to output. NCHW16C is diffrent/not compatible with NCHW so this is a problem. To fix this  conversion(reorder) has to be added before fetch op.\n Fast workaround:\n \n Disable tanh op in face model eg. use paddlepaddle tanh activation. MKL-DNN tanh is not faster.\n So no performance penalty is by disabling tanh.\n \n <denchmark-link:https://github.com/luotao1>@luotao1</denchmark-link>\n  , <denchmark-link:https://github.com/Superjomn>@Superjomn</denchmark-link>\n   Please advice how to proceed . Eg. Where to call TransDataLayoutFromMKLDNN  (data_layout_transform.cc:~119) to have output from MKL-DNN ops converted for the purpose of consuming it by fetch op ?\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "jczaja", "commentT": "2019-08-23T03:26:18Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jczaja>@jczaja</denchmark-link>\n   Could the accuracy diff be solved If there is only first  in , not each time?\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "jczaja", "commentT": "2019-08-23T03:28:21Z", "comment_text": "\n \t\t\n Disable tanh op in face model eg. use paddlepaddle tanh activation. MKL-DNN tanh is not faster.\n So no performance penalty is by disabling tanh.\n \n I think it's Ok for just this model on avx512.\n \n Where to call TransDataLayoutFromMKLDNN (data_layout_transform.cc:~119) to have output from MKL-DNN ops converted for the purpose of consuming it by fetch op ?\n \n <denchmark-link:https://github.com/LeoZhao-Intel>@LeoZhao-Intel</denchmark-link>\n  <denchmark-link:https://github.com/jianhang-liu>@jianhang-liu</denchmark-link>\n  How do you think about it?\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "jczaja", "commentT": "2019-08-23T05:48:28Z", "comment_text": "\n \t\t\n \n Disable tanh op in face model eg. use paddlepaddle tanh activation. MKL-DNN tanh is not faster.\n So no performance penalty is by disabling tanh.\n \n I think it's Ok for just this model on avx512.\n \n Where to call TransDataLayoutFromMKLDNN (data_layout_transform.cc:~119) to have output from MKL-DNN ops converted for the purpose of consuming it by fetch op ?\n \n @LeoZhao-Intel @jianhang-liu How do you think about it?\n \n Just my 2 cents:\n Currently for ops based on OperatorsWithKernel, PrepareData is just doing data layout transform on input tensors instead of outputs, in one graph it follows this rule and works well.\n But this case is special since last op based on OperatorsWithKernel is connected with fetch op which is not based on OperatorsWithKernel, then there is issue.\n 2 options I think, one is do layout conversion for output in OperatorsWithKernel, but I don't think it is good solution, since it don't know which format is needed by next op. The other is doing conversion in fetch op, which I think is good.\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "jczaja", "commentT": "2019-08-23T07:41:50Z", "comment_text": "\n \t\tOk, I will work on adding conversion into fetch op eg.call TransDataLayoutFromMKLDNN inside fetch::RunImpl\n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "jczaja", "commentT": "2019-08-23T17:40:31Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/LeoZhao-Intel>@LeoZhao-Intel</denchmark-link>\n  , <denchmark-link:https://github.com/luotao1>@luotao1</denchmark-link>\n  PR <denchmark-link:https://github.com/PaddlePaddle/Paddle/pull/19282>#19282</denchmark-link>\n  with my proposal of modifications to fetch op so it solves most recent issue discussed here (lack of conversion from MKL-DNN to Paddle in fetch op). It works for Face model and some other testing I have done. Please take a look and let me know what you think.\n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "jczaja", "commentT": "2019-08-30T09:13:20Z", "comment_text": "\n \t\tFixed in <denchmark-link:https://github.com/PaddlePaddle/Paddle/pull/19282>#19282</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "ecd9f330c9ae86414ef31e6808f87a48ce99dac3", "commit_author": "Jacek Czaja", "commitT": "2019-08-30 16:00:35+08:00", "commit_complexity": {"commit_NLOC": "0.9130434782608695", "commit_CCN": "1.0", "commit_Nprams": "0.9130434782608695"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "paddle\\fluid\\framework\\data_layout_transform.cc", "file_new_name": "paddle\\fluid\\framework\\data_layout_transform.cc", "file_complexity": {"file_NLOC": "137", "file_CCN": "23", "file_NToken": "1131"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "134,135,136,147,174", "deleted_lines": "140,141,168", "method_info": {"method_name": "paddle::framework::innerTransDataLayoutFromMKLDNN", "method_params": "in_layout,out_layout,in,out,place", "method_startline": "134", "method_endline": "188", "method_complexity": {"method_NLOC": "40", "method_CCN": "5", "method_NToken": "397", "method_nesting_level": "2"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "124,131,132", "deleted_lines": null, "method_info": {"method_name": "paddle::framework::TransDataLayoutFromMKLDNN", "method_params": "kernel_type_for_var,expected_kernel_type,in,out", "method_startline": "119", "method_endline": "132", "method_complexity": {"method_NLOC": "12", "method_CCN": "2", "method_NToken": "75", "method_nesting_level": "2"}}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "paddle\\fluid\\framework\\data_layout_transform.h", "file_new_name": "paddle\\fluid\\framework\\data_layout_transform.h", "file_complexity": {"file_NLOC": "54", "file_CCN": "8", "file_NToken": "356"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "72,73,74,75", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "paddle\\fluid\\operators\\controlflow\\fetch_op.cc", "file_new_name": "paddle\\fluid\\operators\\controlflow\\fetch_op.cc", "file_complexity": {"file_NLOC": "70", "file_CCN": "7", "file_NToken": "453"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "59,60,61,62,63,64,65,66,67,68", "deleted_lines": "58", "method_info": {"method_name": "paddle::operators::FetchOp::RunImpl", "method_params": "scope,place", "method_startline": "32", "method_endline": "77", "method_complexity": {"method_NLOC": "36", "method_CCN": "5", "method_NToken": "305", "method_nesting_level": "3"}}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "paddle\\fluid\\operators\\mkldnn\\activation_mkldnn_op.cc", "file_new_name": "paddle\\fluid\\operators\\mkldnn\\activation_mkldnn_op.cc", "file_complexity": {"file_NLOC": "175", "file_CCN": "20", "file_NToken": "1569"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "121", "deleted_lines": "90,122", "method_info": {"method_name": "paddle::operators::eltwise_forward", "method_params": "ctx,algorithm", "method_startline": "79", "method_endline": "131", "method_complexity": {"method_NLOC": "37", "method_CCN": "7", "method_NToken": "453", "method_nesting_level": "2"}}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "paddle\\fluid\\operators\\mkldnn\\batch_norm_mkldnn_op.cc", "file_new_name": "paddle\\fluid\\operators\\mkldnn\\batch_norm_mkldnn_op.cc", "file_complexity": {"file_NLOC": "408", "file_CCN": "30", "file_NToken": "3539"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "62,63,64,65,66,67,68", "deleted_lines": null, "method_info": {"method_name": "paddle::operators::BatchNormMKLDNNHandler::AcquireDstMemoryFromPrimitive", "method_params": "output,place", "method_startline": "62", "method_endline": "68", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "55", "method_nesting_level": "4"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "345", "deleted_lines": null, "method_info": {"method_name": "paddle::operators::BatchNormMKLDNNGradOpKernel::Compute", "method_params": "ctx", "method_startline": "317", "method_endline": "529", "method_complexity": {"method_NLOC": "161", "method_CCN": "6", "method_NToken": "1461", "method_nesting_level": "3"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "261,262", "deleted_lines": "192,253,254", "method_info": {"method_name": "paddle::operators::BatchNormMKLDNNOpKernel::Compute", "method_params": "ctx", "method_startline": "170", "method_endline": "311", "method_complexity": {"method_NLOC": "104", "method_CCN": "9", "method_NToken": "1043", "method_nesting_level": "3"}}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "paddle\\fluid\\operators\\mkldnn\\mul_mkldnn_op.cc", "file_new_name": "paddle\\fluid\\operators\\mkldnn\\mul_mkldnn_op.cc", "file_complexity": {"file_NLOC": "342", "file_CCN": "44", "file_NToken": "3150"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "424,425", "deleted_lines": "424", "method_info": {"method_name": "paddle::operators::MulMKLDNNKernel::Compute", "method_params": "ctx", "method_startline": "404", "method_endline": "426", "method_complexity": {"method_NLOC": "18", "method_CCN": "2", "method_NToken": "200", "method_nesting_level": "3"}}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "paddle\\fluid\\platform\\mkldnn_helper.h", "file_new_name": "paddle\\fluid\\platform\\mkldnn_helper.h", "file_complexity": {"file_NLOC": "145", "file_CCN": "35", "file_NToken": "1172"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "134,135,136,137,139,140,141", "deleted_lines": null, "method_info": {"method_name": "paddle::platform::MKLDNNFormatForSize", "method_params": "dims_size,data_format", "method_startline": "122", "method_endline": "149", "method_complexity": {"method_NLOC": "28", "method_CCN": "12", "method_NToken": "219", "method_nesting_level": "2"}}}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 7, "file_old_name": "paddle\\fluid\\platform\\mkldnn_reuse.h", "file_new_name": "paddle\\fluid\\platform\\mkldnn_reuse.h", "file_complexity": {"file_NLOC": "1215", "file_CCN": "162", "file_NToken": "9845"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "396", "deleted_lines": "398", "method_info": {"method_name": "paddle::platform::ActivationMKLDNNHandler::AcquireActivation", "method_params": "dst_memory_p,src_memory_p", "method_startline": "386", "method_endline": "401", "method_complexity": {"method_NLOC": "13", "method_CCN": "2", "method_NToken": "96", "method_nesting_level": "3"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "428", "deleted_lines": "427", "method_info": {"method_name": "paddle::platform::ActivationMKLDNNHandler::AcquireActivationBackward", "method_params": "diff_src_memory_p,diff_dst_memory_p,src_memory_p", "method_startline": "417", "method_endline": "434", "method_complexity": {"method_NLOC": "15", "method_CCN": "2", "method_NToken": "111", "method_nesting_level": "3"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "404,405,406,407,408,409", "deleted_lines": "405,406,407,408", "method_info": {"method_name": "paddle::platform::ActivationMKLDNNHandler::AcquireDstMemoryFromPrimitive", "method_params": "output,place", "method_startline": "404", "method_endline": "410", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "55", "method_nesting_level": "3"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "368,371,372,376,379,380,381,383", "deleted_lines": "369,372,373,377,378,381,382,383", "method_info": {"method_name": "paddle::platform::ActivationMKLDNNHandler::AcquireActivationBackwardPrimitiveDescriptor", "method_params": "algorithm,diff_dst_md,src_md,alpha,beta", "method_startline": "363", "method_endline": "384", "method_complexity": {"method_NLOC": "21", "method_CCN": "2", "method_NToken": "162", "method_nesting_level": "3"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "413,414", "deleted_lines": "412,413", "method_info": {"method_name": "paddle::platform::ActivationMKLDNNHandler::AcquireDiffSrcMemoryFromPrimitive", "method_params": "ptr", "method_startline": "412", "method_endline": "415", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "3"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "406,407,408,409", "deleted_lines": "406,407,408", "method_info": {"method_name": "paddle::platform::ActivationMKLDNNHandler::AcquireDstMemoryFromPrimitive", "method_params": "ptr", "method_startline": "406", "method_endline": "409", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "3"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "340,341,342,347,350,354,356,359", "deleted_lines": "340,341,342,343,348,351,355,357,360", "method_info": {"method_name": "paddle::platform::ActivationMKLDNNHandler::AcquireActivationPrimitiveDescriptor", "method_params": "prop_kind,algorithm,md,alpha,beta", "method_startline": "332", "method_endline": "360", "method_complexity": {"method_NLOC": "24", "method_CCN": "3", "method_NToken": "165", "method_nesting_level": "3"}}}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\paddle\\fluid\\tests\\unittests\\mkldnn\\test_conv2d_int8_mkldnn_op.py", "file_new_name": "python\\paddle\\fluid\\tests\\unittests\\mkldnn\\test_conv2d_int8_mkldnn_op.py", "file_complexity": {"file_NLOC": "265", "file_CCN": "36", "file_NToken": "2142"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "28", "deleted_lines": null, "method_info": {"method_name": "conv2d_forward_refer", "method_params": "input,filter,group,conv_param", "method_startline": "25", "method_endline": "28", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "33", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "80,81,108,109,110", "deleted_lines": "82,83,84,85,112,113,114,115", "method_info": {"method_name": "setUp", "method_params": "self", "method_startline": "32", "method_endline": "146", "method_complexity": {"method_NLOC": "108", "method_CCN": "10", "method_NToken": "881", "method_nesting_level": "1"}}}}}, "file_9": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\paddle\\fluid\\tests\\unittests\\mkldnn\\test_elementwise_mul_mkldnn_op.py", "file_new_name": "python\\paddle\\fluid\\tests\\unittests\\mkldnn\\test_elementwise_mul_mkldnn_op.py", "file_complexity": {"file_NLOC": "251", "file_CCN": "51", "file_NToken": "1913"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "185", "deleted_lines": "185", "method_info": {"method_name": "init_input_output", "method_params": "self", "method_startline": "179", "method_endline": "185", "method_complexity": {"method_NLOC": "6", "method_CCN": "1", "method_NToken": "112", "method_nesting_level": "1"}}}}}}}}