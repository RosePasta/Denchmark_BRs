{"BR": {"BR_id": "1815", "BR_author": "zzzace2000", "BRopenT": "2020-05-13T20:31:47Z", "BRcloseT": "2020-05-31T19:02:20Z", "BR_text": {"BRsummary": "Set precision=16 (using apex) would cause early stopping break", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n The current early stopping monitor initilize by comparing if the function monitor_op is equal to torch.lt.\n self.best = torch_inf if self.monitor_op == torch.lt else -torch_inf\n \n \n \n pytorch-lightning/pytorch_lightning/callbacks/early_stopping.py\n \n \n          Line 110\n       in\n       12138ce\n \n \n \n \n \n \n  self.best = torch_inf if self.monitor_op == torch.lt else -torch_inf \n \n \n \n \n \n However when intializing with the apex, it seems that the torch.lt would change and this evaluation would be always false and thus the self.best is intialized to -inf instead of +inf.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n <denchmark-code>import torch\n from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n import apex.amp as amp\n \n es = EarlyStopping()\n es.monitor_op == torch.lt\n Out[6]: True\n \n model = torch.Linear(5, 5).to('cuda')\n optimizers = torch.optim.Adam(model.parameters(), lr=1e-3)\n amp.initialize(model, optimizers)\n \n es.monitor_op == torch.lt\n Out[22]: False\n </denchmark-code>\n \n And this bug leads to the initialization of self.best to be -inf instead of inf\n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n self.best should be initialized to inf instead of -inf.\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n CUDA:\n - GPU:\n - TITAN Xp\n - Quadro P400\n - available:         True\n - version:           10.1\n Packages:\n - numpy:             1.18.1\n - pyTorch_debug:     False\n - pyTorch_version:   1.4.0\n - pytorch-lightning: 0.7.5\n - tensorboard:       2.1.1\n - tqdm:              4.43.0\n System:\n - OS:                Linux\n - architecture:\n - 64bit\n -\n - processor:         x86_64\n - python:            3.6.10\n - version:           #67-Ubuntu SMP Thu Aug 22 16:55:30 UTC 2019\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n I bump into this bug after downloading from the master branch couple days ago. I would guess the old version is fine but did not test it.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "zzzace2000", "commentT": "2020-05-13T20:32:30Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}}}, "commit": {"commit_id": "bf39cb26c57f1fd5968420e99ba351a9e0df9541", "commit_author": "authman", "commitT": "2020-05-31 15:02:19-04:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\callbacks\\early_stopping.py", "file_new_name": "pytorch_lightning\\callbacks\\early_stopping.py", "file_complexity": {"file_NLOC": "114", "file_CCN": "17", "file_NToken": "546"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "110", "deleted_lines": "110", "method_info": {"method_name": "on_train_start", "method_params": "self,trainer,pl_module", "method_startline": "106", "method_endline": "110", "method_complexity": {"method_NLOC": "4", "method_CCN": "2", "method_NToken": "53", "method_nesting_level": "1"}}}}}}}}