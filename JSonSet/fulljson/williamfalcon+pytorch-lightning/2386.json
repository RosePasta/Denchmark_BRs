{"BR": {"BR_id": "2386", "BR_author": "nischal-sanil", "BRopenT": "2020-06-27T16:13:53Z", "BRcloseT": "2020-06-29T00:22:04Z", "BR_text": {"BRsummary": "An Extra argument passed to the class, loaded from load_from_checkpoint.", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n Hello,\n I was facing few issues while using the trainer.test() function, on debugging I found out that the problem was with the _load_model_state class method which is called by load_from_checkpoint.\n <denchmark-h:h4>Code For reference</denchmark-h>\n \n <denchmark-code>@classmethod\n def _load_model_state(cls, checkpoint: Dict[str, Any], *args, **kwargs):\n     # pass in the values we saved automatically\n     if cls.CHECKPOINT_HYPER_PARAMS_KEY in checkpoint:\n         model_args = {}\n \n         # add some back compatibility, the actual one shall be last\n         for hparam_key in CHECKPOINT_PAST_HPARAMS_KEYS + (cls.CHECKPOINT_HYPER_PARAMS_KEY,):\n             if hparam_key in checkpoint:\n                 model_args.update(checkpoint[hparam_key])\n \n         if cls.CHECKPOINT_HYPER_PARAMS_TYPE in checkpoint:\n             model_args = checkpoint[cls.CHECKPOINT_HYPER_PARAMS_TYPE](model_args)\n \n         args_name = checkpoint.get(cls.CHECKPOINT_HYPER_PARAMS_NAME)\n         init_args_name = inspect.signature(cls).parameters.keys()\n \n         if args_name == 'kwargs':\n             cls_kwargs = {k: v for k, v in model_args.items() if k in init_args_name}\n             kwargs.update(**cls_kwargs)\n         elif args_name:\n             if args_name in init_args_name:\n                 kwargs.update({args_name: model_args})\n         else:\n             args = (model_args, ) + args\n \n     # load the state_dict on the model automatically\n     model = cls(*args, **kwargs)\n     model.load_state_dict(checkpoint['state_dict'])\n \n     # give model a chance to load something\n     model.on_load_checkpoint(checkpoint)\n \n     return model\n </denchmark-code>\n \n Consider the case where the  model has no arguments, which corresponds to . Here, the else clause of the if-elif is being executed where the  variable is updated from an empty tuple to a tuple with an empty dictionary  (as ). Therefore, while unpacking the args and kwargs (), There is an extra argument being passed which raises a . <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2364>#2364</denchmark-link>\n \n In some cases if the model has an argument and the user has forgotten to add it in the load_from_checkpoint, then an empty dictionary will be passed instead and it raises other errors depending on the code. For example, in the issue <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2359>#2359</denchmark-link>\n  an empty dict is passed while loading the model and hence raises .\n I do not fully understand what is happening in the function. It would be great if someone can suggest changes to make in the comments so that I can start working after updating the changes in my forked repo.\n <denchmark-h:h4>Steps to reproduce</denchmark-h>\n \n <denchmark-code>!pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade\n \n import os\n \n import torch\n from torch.nn import functional as F\n from torch.utils.data import DataLoader\n from torchvision.datasets import MNIST\n from torchvision import transforms\n import pytorch_lightning as pl\n \n class MNISTModel(pl.LightningModule):\n \n     def __init__(self):\n         super(MNISTModel, self).__init__()\n         self.l1 = torch.nn.Linear(28 * 28, 10)\n \n     def forward(self, x):\n         return torch.relu(self.l1(x.view(x.size(0), -1)))\n \n     def training_step(self, batch, batch_nb):\n         x, y = batch\n         loss = F.cross_entropy(self(x), y)\n         tensorboard_logs = {'train_loss': loss}\n         return {'loss': loss, 'log': tensorboard_logs}\n \n     def test_step(self, batch, batch_nb):\n         x, y = batch\n         y_hat = self(x)\n         loss = F.cross_entropy(y_hat, y)\n         tensorboard_logs = {'train_loss': loss}\n         return {'loss': loss, 'log': tensorboard_logs}\n \n     def configure_optimizers(self):\n         return torch.optim.Adam(self.parameters(), lr=0.02)\n \n \n train_loader = DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n \n mnist_model = MNISTModel()\n trainer = pl.Trainer(gpus=1,max_epochs=3)    \n trainer.fit(mnist_model, train_loader)  \n \n test_loader = DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)\n trainer.test(test_dataloaders=test_loader)\n </denchmark-code>\n \n Which returns:\n <denchmark-code>TypeError                                 Traceback (most recent call last)\n \n <ipython-input-5-50449ee4f6cc> in <module>()\n       1 test_loader = DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)\n ----> 2 trainer.test(test_dataloaders=test_loader)\n \n /usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py in test(self, model, test_dataloaders, ckpt_path)\n    1168             if ckpt_path == 'best':\n    1169                 ckpt_path = self.checkpoint_callback.best_model_path\n -> 1170             model = self.get_model().load_from_checkpoint(ckpt_path)\n    1171 \n    1172         self.testing = True\n \n /usr/local/lib/python3.6/dist-packages/pytorch_lightning/core/saving.py in load_from_checkpoint(cls, checkpoint_path, map_location, hparams_file, tags_csv, *args, **kwargs)\n     167         checkpoint[cls.CHECKPOINT_HYPER_PARAMS_KEY].update(kwargs)\n     168 \n --> 169         model = cls._load_model_state(checkpoint, *args, **kwargs)\n     170         return model\n     171 \n \n /usr/local/lib/python3.6/dist-packages/pytorch_lightning/core/saving.py in _load_model_state(cls, checkpoint, *cls_args, **cls_kwargs)\n     201 \n     202         # load the state_dict on the model automatically\n --> 203         model = cls(*cls_args, **cls_kwargs)\n     204         model.load_state_dict(checkpoint['state_dict'])\n     205 \n \n TypeError: __init__() takes 1 positional argument but 2 were given\n </denchmark-code>\n \n <denchmark-h:h4>Expected behavior</denchmark-h>\n \n Start testing\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "nischal-sanil", "commentT": "2020-06-27T16:14:30Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}}}, "commit": {"commit_id": "1e16681693e113d25a4207ce2827a39c64b19211", "commit_author": "Jirka Borovec", "commitT": "2020-06-28 20:22:03-04:00", "commit_complexity": {"commit_NLOC": "0.975609756097561", "commit_CCN": "0.975609756097561", "commit_Nprams": "0.7804878048780488"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "47,48", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\core\\saving.py", "file_new_name": "pytorch_lightning\\core\\saving.py", "file_complexity": {"file_NLOC": "312", "file_CCN": "42", "file_NToken": "1245"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "174,175,198,199,200,201,202,203,204,206", "deleted_lines": "186,187,188,192,193,201", "method_info": {"method_name": "_load_model_state", "method_params": "cls,str,cls_args,cls_kwargs", "method_startline": "173", "method_endline": "212", "method_complexity": {"method_NLOC": "25", "method_CCN": "12", "method_NToken": "224", "method_nesting_level": "1"}}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 11, "file_old_name": "tests\\models\\test_hparams.py", "file_new_name": "tests\\models\\test_hparams.py", "file_complexity": {"file_NLOC": "289", "file_CCN": "50", "file_NToken": "2362"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "108,113,116,117", "deleted_lines": "106,111,114,115", "method_info": {"method_name": "test_explicit_args_hparams", "method_params": "tmpdir", "method_startline": "102", "method_endline": "120", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "56", "method_nesting_level": "0"}}}, "hunk_1": {"Ismethod": 1, "added_lines": "465,466,467,468,469,470,471,472,473,474,475,476,477,478", "deleted_lines": null, "method_info": {"method_name": "test_model_nohparams_train_test", "method_params": "tmpdir,cls", "method_startline": "465", "method_endline": "478", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "92", "method_nesting_level": "0"}}}, "hunk_2": {"Ismethod": 1, "added_lines": "452,453,454,455", "deleted_lines": null, "method_info": {"method_name": "test_step", "method_params": "self,batch,batch_nb", "method_startline": "452", "method_endline": "455", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "41", "method_nesting_level": "1"}}}, "hunk_3": {"Ismethod": 1, "added_lines": "129,134,137,138", "deleted_lines": "127,132,135,136", "method_info": {"method_name": "test_implicit_args_hparams", "method_params": "tmpdir", "method_startline": "123", "method_endline": "141", "method_complexity": {"method_NLOC": "7", "method_CCN": "1", "method_NToken": "56", "method_nesting_level": "0"}}}, "hunk_4": {"Ismethod": 1, "added_lines": "447,448,449,450", "deleted_lines": null, "method_info": {"method_name": "training_step", "method_params": "self,batch,batch_nb", "method_startline": "447", "method_endline": "450", "method_complexity": {"method_NLOC": "4", "method_CCN": "1", "method_NToken": "41", "method_nesting_level": "1"}}}, "hunk_5": {"Ismethod": 1, "added_lines": "481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499", "deleted_lines": null, "method_info": {"method_name": "test_model_ignores_non_exist_kwargument", "method_params": "tmpdir", "method_startline": "481", "method_endline": "499", "method_complexity": {"method_NLOC": "10", "method_CCN": "1", "method_NToken": "70", "method_nesting_level": "0"}}}, "hunk_6": {"Ismethod": 1, "added_lines": "435,436", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self", "method_startline": "435", "method_endline": "436", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "12", "method_nesting_level": "1"}}}, "hunk_7": {"Ismethod": 1, "added_lines": "457,458", "deleted_lines": null, "method_info": {"method_name": "configure_optimizers", "method_params": "self", "method_startline": "457", "method_endline": "458", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "1"}}}, "hunk_8": {"Ismethod": 1, "added_lines": "485,486,487", "deleted_lines": null, "method_info": {"method_name": "test_model_ignores_non_exist_kwargument.__init__", "method_params": "self,batch_size", "method_startline": "485", "method_endline": "487", "method_complexity": {"method_NLOC": "3", "method_CCN": "1", "method_NToken": "24", "method_nesting_level": "2"}}}, "hunk_9": {"Ismethod": 1, "added_lines": "150,155,171", "deleted_lines": "148,153,169", "method_info": {"method_name": "test_explicit_missing_args_hparams", "method_params": "tmpdir", "method_startline": "144", "method_endline": "175", "method_complexity": {"method_NLOC": "15", "method_CCN": "1", "method_NToken": "119", "method_nesting_level": "0"}}}, "hunk_10": {"Ismethod": 1, "added_lines": "444,445", "deleted_lines": null, "method_info": {"method_name": "forward", "method_params": "self,x", "method_startline": "444", "method_endline": "445", "method_complexity": {"method_NLOC": "2", "method_CCN": "1", "method_NToken": "32", "method_nesting_level": "1"}}}}}}}}