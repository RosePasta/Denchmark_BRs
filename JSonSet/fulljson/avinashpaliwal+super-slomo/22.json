{"BR": {"BR_id": "22", "BR_author": "ChenxiTU", "BRopenT": "2019-01-15T10:02:10Z", "BRcloseT": "2019-03-04T14:51:45Z", "BR_text": {"BRsummary": "About preparing training data", "BRdescription": "\n Thank you for sharing your nice work!\n I used create_dataset.py to build the training dataset as you mentioned.  But I find that 12 frames in each clip is not continuous.\n Maybe L.69 in create_dataset.py should be modified:\n images = os.listdir(os.path.join(root, file))  -> images = sorted(os.listdir(os.path.join(root, file)))\n Or I misunderstood, the frame in each clip should not be continuous?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ChenxiTU", "commentT": "2019-01-15T15:56:39Z", "comment_text": "\n \t\tThe frames inside a clip (folder) should be continuous. The clips can be in different order which doesn't affect the training because the network only looks at the frames from one particular clip. There is no need for sorted and it actually doesn't work because 11 is taken before 2. I have added zero padding using `%04d' <denchmark-link:https://github.com/avinashpaliwal/Super-SloMo/blob/e8508bd949e51985ba73b99d0063090cec7e3679/data/create_dataset.py#L40>here</denchmark-link>\n  so that frames are named 0001.jpg, 0002.jpg and so on. But if you have more than 9999 frames, you'll have to increase the zero padding.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ChenxiTU", "commentT": "2019-01-16T03:00:57Z", "comment_text": "\n \t\tThank you for your quickly reply. According to what you said, I think my understand is right.\n What I'd like to say is that the frames inside a clip is not continuous when I used  create_dataset.py.\n For example, in adobe240/train/0/, I got 12 frames like this: 0257.jpg, 0438.jpg, 1116.jpg ... which are not continuous.\n If I add sorted(), in adobe240/train/0/, I got 12 frames: 0001.jpg, 0002.jpg, 0003.jpg ... 0012.jpg\n I think sorted() can work because after extracted from video, frames' names are already padded.\n Maybe different operating system has different result. In may case, I use ubuntu 16.04.\n Sorry in advance, if I still misunderstand something.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ChenxiTU", "commentT": "2019-01-16T06:03:22Z", "comment_text": "\n \t\t\n Thank you for your quickly reply. According to what you said, I think my understand is right.\n What I'd like to say is that the frames inside a clip is not continuous when I used create_dataset.py.\n For example, in adobe240/train/0/, I got 12 frames like this: 0257.jpg, 0438.jpg, 1116.jpg ... which are not continuous.\n If I add sorted(), in adobe240/train/0/, I got 12 frames: 0001.jpg, 0002.jpg, 0003.jpg ... 0012.jpg\n I think sorted() can work because after extracted from video, frames' names are already padded.\n Maybe different operating system has different result. In may case, I use ubuntu 16.04.\n Sorry in advance, if I still misunderstand something.\n \n Ohh. I haven't tested it on Linux OSes yet. Thanks for pointing out the bug.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "ChenxiTU", "commentT": "2019-01-22T01:30:08Z", "comment_text": "\n \t\tHey, I want to know whether the images in one folder are really continues, or I just need to change the images' name by myself? The checkpoint trained by myself works really terrible, and is there anything to do with this bug?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "ChenxiTU", "commentT": "2019-03-04T14:51:40Z", "comment_text": "\n \t\t\n Hey, I want to know whether the images in one folder are really continues, or I just need to change the images' name by myself? The checkpoint trained by myself works really terrible, and is there anything to do with this bug?\n \n Yes. The images inside 'clips' folders which contains 12 images should be continuous. If they are not, that would mess up the training. I have updated the dataset generation script. Try running it again to generate the whole dataset.\n \t\t"}}}, "commit": {"commit_id": "3641f201316fd772eaa5ed332c212b4d02f11e6c", "commit_author": "Avinash Paliwal", "commitT": "2019-03-04 08:47:07-06:00", "commit_complexity": {"commit_NLOC": "None", "commit_CCN": "None", "commit_Nprams": "None"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "data\\create_dataset.py", "file_new_name": "data\\create_dataset.py", "file_complexity": {"file_NLOC": "73", "file_CCN": "17", "file_NToken": "836"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "69", "deleted_lines": "69", "method_info": {"method_name": "create_clips", "method_params": "root,destination", "method_startline": "45", "method_endline": "79", "method_complexity": {"method_NLOC": "13", "method_CCN": "5", "method_NToken": "130", "method_nesting_level": "0"}}}}}}}}