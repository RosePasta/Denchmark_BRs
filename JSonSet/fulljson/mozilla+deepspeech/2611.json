{"BR": {"BR_id": "2611", "BR_author": "JinZhuXing", "BRopenT": "2019-12-19T05:43:14Z", "BRcloseT": "2020-03-06T14:52:22Z", "BR_text": {"BRsummary": "CRLF in alphabet file breaks usage", "BRdescription": "\n <denchmark-code>python ./DeepSpeech.py --train_files ../zh-cn/clips/train.csv --dev_files ../zh-cn/clips/dev.csv --test_files ../zh-cn/clips/test.csv\n \n Traceback (most recent call last):\n   File \"/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py\", line 33, in _label_from_string\n     return self._str_to_label[string]\n KeyError: '\u6bcd'\n \n During handling of the above exception, another exception occurred:\n \n Traceback (most recent call last):\n   File \"/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py\", line 130, in text_to_char_array\n     transcript = np.asarray(alphabet.encode(series['transcript']))\n   File \"/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py\", line 47, in encode\n     res.append(self._label_from_string(char))\n   File \"/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py\", line 39, in _label_from_string\n     ).with_traceback(e.__traceback__)\n   File \"/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py\", line 33, in _label_from_string\n     return self._str_to_label[string]\n KeyError: \"ERROR: Your transcripts contain characters (e.g. '\u6bcd') which do not occur in data/alphabet.txt! Use util/check_characters.py to see what characters are in your [train,dev,test].csv transcripts, and then add all these to data/alphabet.txt.\"\n \n During handling of the above exception, another exception occurred:\n \n Traceback (most recent call last):\n   File \"./DeepSpeech.py\", line 965, in <module>\n     absl.app.run(main)\n   File \"/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/absl/app.py\", line 299, in run\n     _run_main(main, args)\n   File \"/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\n     sys.exit(main(argv))\n   File \"./DeepSpeech.py\", line 938, in main\n     train()\n   File \"./DeepSpeech.py\", line 438, in train\n     train_phase=True)\n   File \"/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/feeding.py\", line 101, in create_dataset\n     df['transcript'] = df.apply(text_to_char_array, alphabet=Config.alphabet, result_type='reduce', axis=1)\n   File \"/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/frame.py\", line 6928, in apply           return op.get_result()\n   File \"/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/apply.py\", line 186, in get_result       return self.apply_standard()\n   File \"/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/apply.py\", line 292, in apply_standard\n     self.apply_series_generator()\n   File \"/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/apply.py\", line 321, in apply_series_generator\n     results[i] = self.f(v)\n   File \"/home/kms/anaconda3/envs/speechenv/lib/python3.6/site-packages/pandas/core/apply.py\", line 112, in f\n     return func(x, *args, **kwds)\n   File \"/mnt/d/FPProject_git/My_Work/speech/mozilla/DeepSpeech/util/text.py\", line 136, in text_to_char_array\n     raise ValueError('While processing: {}\\n{}'.format(series['wav_filename'], e))\n ValueError: ('While processing: /mnt/d/FPProject_git/My_Work/speech/mozilla/zh-cn/clips/common_voice_zh-CN_18782225.wav\\n\"ERROR: Your transcripts contain characters (e.g. \\'\u6bcd\\') which do not occur in data/alphabet.txt! Use util/check_characters.py to see what characters are in your [train,dev,test].csv transcripts, and then add all these to data/alphabet.txt.\"', 'occurred at index 550')\n </denchmark-code>\n \n I am training deep speech model in chinese.\n I have already downloaded chiense dataset from voice.mozilla.org (Common Voice).\n Then, I tried training as the description in Project Document(<denchmark-link:https://github.com/mozilla/DeepSpeech/blob/master/TRAINING.rst#training-your-own-model>https://github.com/mozilla/DeepSpeech/blob/master/TRAINING.rst#training-your-own-model</denchmark-link>\n ).\n But when I train data using DeepSpeech.py, it failed with above errors.\n data/alphabet.txt already contains '\u6bcd'.\n I can't find reason.\n Please help me.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "JinZhuXing", "commentT": "2019-12-19T07:53:25Z", "comment_text": "\n \t\t\n data/alphabet.txt already contains '\u6bcd'.\n \n Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?\n How did you generate data/alphabet.txt ? Did you used util/check_characters.py as suggested ?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "JinZhuXing", "commentT": "2019-12-19T10:13:30Z", "comment_text": "\n \t\t\n \n data/alphabet.txt already contains '\u6bcd'.\n \n Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?\n How did you generate data/alphabet.txt ? Did you used util/check_characters.py as suggested ?\n \n Yes. I have generated data/alphabet.txt file using util/check_characters.py.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "JinZhuXing", "commentT": "2019-12-19T10:20:28Z", "comment_text": "\n \t\t\n \n \n data/alphabet.txt already contains '\u6bcd'.\n \n Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?\n How did you generate data/alphabet.txt ? Did you used util/check_characters.py as suggested ?\n \n Yes. I have generated data/alphabet.txt file using util/check_characters.py.\n \n Well, I can't help more without more data. But you have an unmatched character in your dataset, for sure.\n Maybe you could share more of you data ? The offending transcript as well as the alphabet file ?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "JinZhuXing", "commentT": "2019-12-19T10:25:43Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JinZhuXing>@JinZhuXing</denchmark-link>\n  Also, can you verify if the offending character is a unicode multi-byte character?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "JinZhuXing", "commentT": "2019-12-19T10:36:33Z", "comment_text": "\n \t\tEvery Chinese character is multibyte in UTF-8.\n <denchmark-link:#>\u2026</denchmark-link>\n \n \n  On 19 Dec 2019, at 10:25, lissyx ***@***.***> wrote:\n \n  \ufeff\n  @JinZhuXing Also, can you verify if the offending character is a unicode multi-byte character?\n \n  \u2014\n  You are receiving this because you are subscribed to this thread.\n  Reply to this email directly, view it on GitHub, or unsubscribe.\n \n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "JinZhuXing", "commentT": "2019-12-19T10:45:33Z", "comment_text": "\n \t\t\n Every Chinese character is multibyte in UTF-8.\n \u2026\n On 19 Dec 2019, at 10:25, lissyx @.***> wrote: \ufeff @JinZhuXing Also, can you verify if the offending character is a unicode multi-byte character? \u2014 You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or unsubscribe.\n \n Not multi-byte then, but was it multi-point ?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "JinZhuXing", "commentT": "2019-12-19T11:00:09Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JinZhuXing>@JinZhuXing</denchmark-link>\n  I also see you are using Anaconda. We're got weird behaviors sometimes, can you reproduce with vanilla Python and a new virtualenv properly setup from scratch ?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "JinZhuXing", "commentT": "2019-12-23T03:12:01Z", "comment_text": "\n \t\tOK, I will test with vanilla Python.\n Thanks, all of you.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "JinZhuXing", "commentT": "2020-01-02T11:44:23Z", "comment_text": "\n \t\t\n OK, I will test with vanilla Python.\n Thanks, all of you.\n \n <denchmark-link:https://github.com/JinZhuXing>@JinZhuXing</denchmark-link>\n  Any update ?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "JinZhuXing", "commentT": "2020-02-13T11:19:34Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JinZhuXing>@JinZhuXing</denchmark-link>\n  Please, can you give feedback ?\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "JinZhuXing", "commentT": "2020-02-14T05:22:38Z", "comment_text": "\n \t\t\n @JinZhuXing Please, can you give feedback ?\n \n It's the same. I can't do it.\n So I will try with english dataset.\n Thanks.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "JinZhuXing", "commentT": "2020-02-14T07:03:02Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JinZhuXing>@JinZhuXing</denchmark-link>\n  Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "JinZhuXing", "commentT": "2020-02-14T10:31:26Z", "comment_text": "\n \t\t\n @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?\n \n Uploaded.\n <denchmark-link:https://github.com/mozilla/DeepSpeech/files/4204035/alphabet_20200214.zip>alphabet_20200214.zip</denchmark-link>\n \n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "JinZhuXing", "commentT": "2020-02-29T10:19:12Z", "comment_text": "\n \t\tMake use you have run export LC_ALL=\"en_US.UTF-8\" in your runtime for Python to handle unicode.\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "JinZhuXing", "commentT": "2020-03-02T14:46:38Z", "comment_text": "\n \t\t\n Make use you have run export LC_ALL=\"en_US.UTF-8\" in your runtime for Python to handle unicode.\n \n Same error.\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "JinZhuXing", "commentT": "2020-03-02T15:08:30Z", "comment_text": "\n \t\t\n \n OK, I will test with vanilla Python.\n Thanks, all of you.\n \n @JinZhuXing Any update ?\n \n It's the same. I can't do it.\n So I will try with english dataset.\n Thanks.\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "JinZhuXing", "commentT": "2020-03-02T15:18:44Z", "comment_text": "\n \t\t\n \n @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?\n \n Uploaded.\n alphabet_20200214.zip\n \n This does not include the transcript. Please, share debuggable data.\n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "JinZhuXing", "commentT": "2020-03-03T02:56:51Z", "comment_text": "\n \t\t\n \n \n @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?\n \n Uploaded.\n alphabet_20200214.zip\n \n This does not include the transcript. Please, share debuggable data.\n \n Uploaded transcript.\n <denchmark-link:https://github.com/mozilla/DeepSpeech/files/4279001/zh-cn_trans.zip>zh-cn_trans.zip</denchmark-link>\n \n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "JinZhuXing", "commentT": "2020-03-05T17:24:20Z", "comment_text": "\n \t\t\n \n \n \n @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?\n \n Uploaded.\n alphabet_20200214.zip\n \n This does not include the transcript. Please, share debuggable data.\n \n Uploaded transcript.\n zh-cn_trans.zip\n \n Ok, looking at your alphabet file there are three occurrences of \u6bcd. Now I have no knowledge of zh-cn locale, but I suspect this is not expected.\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "JinZhuXing", "commentT": "2020-03-06T01:22:07Z", "comment_text": "\n \t\t\n \n \n \n \n @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?\n \n Uploaded.\n alphabet_20200214.zip\n \n This does not include the transcript. Please, share debuggable data.\n \n Uploaded transcript.\n zh-cn_trans.zip\n \n Ok, looking at your alphabet file there are three occurrences of \u6bcd. Now I have no knowledge of zh-cn locale, but I suspect this is not expected.\n \n I just removed two '\u6bcd\u2018 characters at alphabet file. But the same error occur.\n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "JinZhuXing", "commentT": "2020-03-06T08:10:15Z", "comment_text": "\n \t\t\n \n \n \n \n \n @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?\n \n Uploaded.\n alphabet_20200214.zip\n \n This does not include the transcript. Please, share debuggable data.\n \n Uploaded transcript.\n zh-cn_trans.zip\n \n Ok, looking at your alphabet file there are three occurrences of \u6bcd. Now I have no knowledge of zh-cn locale, but I suspect this is not expected.\n \n I just removed two '\u6bcd\u2018 characters at alphabet file. But the same error occur.\n \n Could you please work on a reduced test case that reproduces the issue ?\n 99.999% of the time, those bugs are dataset-side.\n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "JinZhuXing", "commentT": "2020-03-06T09:18:32Z", "comment_text": "\n \t\t<denchmark-code>$ file issue_2611/alphabet.txt \n issue_2611/alphabet.txt: UTF-8 Unicode text, with CRLF line terminators\n </denchmark-code>\n \n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "JinZhuXing", "commentT": "2020-03-06T09:20:06Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JinZhuXing>@JinZhuXing</denchmark-link>\n  Just removing  line ending was enough. Training is only tested / supported on Linux so far, as documented. Looks like this was prepared on a Windows system to be with  line endings.\n \t\t"}, "comments_23": {"comment_id": 24, "comment_author": "JinZhuXing", "commentT": "2020-03-06T09:36:07Z", "comment_text": "\n \t\tThank you <denchmark-link:https://github.com/lissyx>@lissyx</denchmark-link>\n  .\n Solved.\n Thanks all of you.\n \t\t"}, "comments_24": {"comment_id": 25, "comment_author": "JinZhuXing", "commentT": "2020-03-06T12:14:32Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/JinZhuXing>@JinZhuXing</denchmark-link>\n  <denchmark-link:https://github.com/mozilla/DeepSpeech/pull/2813>#2813</denchmark-link>\n  will make sure people producing alphabet on one system and using it on another won't get into troubles.\n \t\t"}, "comments_25": {"comment_id": 26, "comment_author": "JinZhuXing", "commentT": "2020-04-15T08:16:56Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "763ed38baeecb07801e90875c222966f622d44b6", "commit_author": "Alexandre Lissy", "commitT": "2020-03-06 15:19:56+01:00", "commit_complexity": {"commit_NLOC": "1.0", "commit_CCN": "1.0", "commit_Nprams": "0.2857142857142857"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": ".travis.yml", "file_new_name": ".travis.yml", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}, "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26", "deleted_lines": "10,11,12,13,14,15,16,17"}}}, "file_1": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "requirements_tests.txt", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_2": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "util\\test_data\\alphabet_macos.txt", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_3": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "util\\test_data\\alphabet_unix.txt", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_4": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "util\\test_data\\alphabet_windows.txt", "file_complexity": {"file_NLOC": "None", "file_CCN": "None", "file_NToken": "None"}}, "file_5": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "util\\test_text.py", "file_complexity": {"file_NLOC": "27", "file_CCN": "7", "file_NToken": "219"}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "util\\text.py", "file_new_name": "util\\text.py", "file_complexity": {"file_NLOC": "131", "file_CCN": "37", "file_NToken": "939"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "17", "deleted_lines": "18", "method_info": {"method_name": "__init__", "method_params": "self,config_file", "method_startline": "11", "method_endline": "25", "method_complexity": {"method_NLOC": "15", "method_CCN": "5", "method_NToken": "108", "method_nesting_level": "1"}}}}}}}}