{"BR": {"BR_id": "508", "BR_author": "epyeoh", "BRopenT": "2019-07-11T05:51:04Z", "BRcloseT": "2019-08-05T16:46:41Z", "BR_text": {"BRsummary": "benchdnn -rnn: some tests failed", "BRdescription": "\n After install build and install mkl-dnn to Ubuntu-16.04, I tried to execute some rnn tests inside benchdnn, some of the tests failed.\n Attached the log:\n $ ./benchdnn --rnn --batch=inputs/rnn/test_rnn_inference\n 0:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t30mb1sic512slc512dic512dlc512n\"\"GNMT_enc-inference\"\"\n 1:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l7t30mb1sic1024slc1024dic1024dlc1024n\"\"GNMT_enc-inference\"\"\n 2:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l8t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 3:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 4:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t50mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 5:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t100mb1sic760slc760dic760dlc760n\"\"deepspeech2-inference\"\"\n 6:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t200mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 7:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t50mb1sic500slc500dic500dlc500n\"\"pytorch_testcase-inference\"\"\n 8:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t629mb1sic128slc128dic128dlc128n\"\"paddlepaddle_testcase-inference\"\"\n 9:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t10mb1sic128slc512dic128dlc128n\"\"exp-0\"\"\n 10:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l10t1mb1sic512slc128dic128dlc128n\"\"exp-1\"\"\n 11:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t1mb640sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 12:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t30mb1sic512slc512dic512dlc512n\"\"GNMT_enc-inference\"\"\n 13:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l7t30mb1sic1024slc1024dic1024dlc1024n\"\"GNMT_enc-inference\"\"\n 14:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l8t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 15:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 16:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t50mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 17:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t100mb1sic760slc760dic760dlc760n\"\"deepspeech2-inference\"\"\n 18:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t200mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 19:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t50mb1sic500slc500dic500dlc500n\"\"pytorch_testcase-inference\"\"\n 20:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t629mb1sic128slc128dic128dlc128n\"\"paddlepaddle_testcase-inference\"\"\n 21:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t10mb1sic128slc512dic128dlc128n\"\"exp-0\"\"\n 22:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l10t1mb1sic512slc128dic128dlc128n\"\"exp-1\"\"\n 23:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=concat --cfg=f32 --scaling=none l1t1mb640sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 24:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t30mb1sic512slc512dic512dlc512n\"\"GNMT_enc-inference\"\"\n 25:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l7t30mb1sic1024slc1024dic1024dlc1024n\"\"GNMT_enc-inference\"\"\n 26:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l8t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 27:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 28:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t50mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 29:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t100mb1sic760slc760dic760dlc760n\"\"deepspeech2-inference\"\"\n 30:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t200mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 31:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t50mb1sic500slc500dic500dlc500n\"\"pytorch_testcase-inference\"\"\n 32:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t629mb1sic128slc128dic128dlc128n\"\"paddlepaddle_testcase-inference\"\"\n 33:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t10mb1sic128slc512dic128dlc128n\"\"exp-0\"\"\n 34:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l10t1mb1sic512slc128dic128dlc128n\"\"exp-1\"\"\n 35:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_RNN --activation=LOGISTIC --direction=sum --cfg=f32 --scaling=none l1t1mb640sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 36:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t30mb1sic512slc512dic512dlc512n\"\"GNMT_enc-inference\"\"\n 37:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l7t30mb1sic1024slc1024dic1024dlc1024n\"\"GNMT_enc-inference\"\"\n 1276, , [DST_LAST_ITERATION][0,0,0,0,1276 fp:1.68531e-05 dt:1.68529e-05 diff:1.8008e-10 rdiff:1.06853e-05\n 5862, , [DST_LAST_ITERATION][1,0,0,0,1766 fp:-1.04922e-05 dt:-1.04923e-05 diff:1.10049e-10 rdiff:1.04886e-05\n 14334, , [DST_LAST_ITERATION][3,0,0,0,2046 fp:-1.11321e-05 dt:-1.1132e-05 diff:1.38243e-10 rdiff:1.24184e-05\n 16270, , [DST_LAST_ITERATION][3,0,1,0,1934 fp:1.14213e-05 dt:1.14215e-05 diff:1.31877e-10 rdiff:1.15465e-05\n @@@ [DST_LAST_ITERATION] final: diff: l0(0.000402838) l1:(6.87066,6.87066,7.41249e-07,1.07886e-07) l2:(0.07063,0.07063,8.91044e-09,1.26157e-07) l8:(0.00271677,0.00271677,5.82077e-10,2.14253e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t*, res_t*):460]: 'compare_dst_last_iteration(p, dst_last_iteration, dst_last_iteration_fp, r, true)' -> 1\n 38:FAILED (errors:4 total:16384) __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l8t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 39:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 40:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t50mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 41:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t100mb1sic760slc760dic760dlc760n\"\"deepspeech2-inference\"\"\n 42:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t200mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 43:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t50mb1sic500slc500dic500dlc500n\"\"pytorch_testcase-inference\"\"\n 44:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t629mb1sic128slc128dic128dlc128n\"\"paddlepaddle_testcase-inference\"\"\n 45:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t10mb1sic128slc512dic128dlc128n\"\"exp-0\"\"\n 46:PASSED __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l10t1mb1sic512slc128dic128dlc128n\"\"exp-1\"\"\n 17424, , [DST_LAST_LAYER][0,0,8,1040] fp:1.32936e-05 dt:1.32938e-05 diff:1.71894e-10 rdiff:1.29306e-05\n 19935, , [DST_LAST_LAYER][0,0,9,1503] fp:-1.15878e-05 dt:-1.15879e-05 diff:1.19144e-10 rdiff:1.02819e-05\n 29084, , [DST_LAST_LAYER][0,0,14,412] fp:1.01474e-05 dt:1.01475e-05 diff:1.12777e-10 rdiff:1.1114e-05\n 45306, , [DST_LAST_LAYER][0,0,22,250] fp:-1.21389e-05 dt:-1.21391e-05 diff:1.71894e-10 rdiff:1.41606e-05\n 59254, , [DST_LAST_LAYER][0,0,28,1910] fp:1.07757e-05 dt:1.07758e-05 diff:1.14596e-10 rdiff:1.06347e-05\n 80899, , [DST_LAST_LAYER][0,0,39,1027] fp:-1.45544e-05 dt:-1.45546e-05 diff:1.49157e-10 rdiff:1.02482e-05\n 100627, , [DST_LAST_LAYER][0,0,49,275] fp:1.11075e-05 dt:1.11077e-05 diff:1.50067e-10 rdiff:1.35104e-05\n 120012, , [DST_LAST_LAYER][0,0,58,1228] fp:1.10909e-05 dt:1.1091e-05 diff:1.30058e-10 rdiff:1.17266e-05\n 127816, , [DST_LAST_LAYER][0,0,62,840] fp:1.58495e-05 dt:1.58497e-05 diff:1.67347e-10 rdiff:1.05585e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.0158448) l1:(184.494,184.494,2.64499e-05,1.43364e-07) l2:(0.285765,0.285765,4.98086e-08,1.74299e-07) l8:(0.00174728,0.00174728,6.98492e-10,3.9976e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 47:FAILED (errors:37 total:655360) __REPRO: --prop=FWD_D --alg=VANILLA_LSTM --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t1mb640sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 2402, , [DST_LAST_LAYER][0,0,4,354] fp:-1.02193e-05 dt:-1.02192e-05 diff:1.2642e-10 rdiff:1.23707e-05\n 2512, , [DST_LAST_LAYER][0,0,4,464] fp:1.07097e-05 dt:1.07098e-05 diff:1.14596e-10 rdiff:1.07003e-05\n 3664, , [DST_LAST_LAYER][0,0,7,80] fp:1.75632e-05 dt:1.75628e-05 diff:3.51065e-10 rdiff:1.99887e-05\n 5034, , [DST_LAST_LAYER][0,0,9,426] fp:1.48164e-05 dt:1.48165e-05 diff:1.83718e-10 rdiff:1.23997e-05\n 5420, , [DST_LAST_LAYER][0,0,10,300] fp:-1.61728e-05 dt:-1.61726e-05 diff:1.69166e-10 rdiff:1.04599e-05\n 6899, , [DST_LAST_LAYER][0,0,13,243] fp:1.1558e-05 dt:1.15578e-05 diff:1.9827e-10 rdiff:1.71544e-05\n 7015, , [DST_LAST_LAYER][0,0,13,359] fp:2.03642e-05 dt:2.03639e-05 diff:2.49202e-10 rdiff:1.22373e-05\n 8456, , [DST_LAST_LAYER][0,0,16,264] fp:-1.10571e-05 dt:-1.10572e-05 diff:1.15506e-10 rdiff:1.04463e-05\n 10120, , [DST_LAST_LAYER][0,0,19,392] fp:-1.4753e-05 dt:-1.47528e-05 diff:1.628e-10 rdiff:1.1035e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.0203776) l1:(78.9717,78.9717,7.47007e-06,9.45917e-08) l2:(0.273161,0.273161,3.16778e-08,1.15967e-07) l8:(0.00321064,0.00321064,6.98492e-10,2.17556e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 48:FAILED (errors:72 total:131072) __REPRO: --prop=FWD_D --alg=VANILLA_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l2t2mb128sic512slc512dic512dlc512n\"\"exp-gru-0\"\"\n 953, , [DST_LAST_LAYER][0,0,1,441] fp:-2.2691e-05 dt:-2.26913e-05 diff:2.83762e-10 rdiff:1.25055e-05\n 1250, , [DST_LAST_LAYER][0,0,2,226] fp:1.58591e-05 dt:1.58589e-05 diff:1.76442e-10 rdiff:1.11256e-05\n 3826, , [DST_LAST_LAYER][0,0,7,242] fp:-1.54971e-05 dt:-1.54969e-05 diff:1.63709e-10 rdiff:1.05638e-05\n 4422, , [DST_LAST_LAYER][0,0,8,326] fp:-1.0284e-05 dt:-1.02842e-05 diff:1.46429e-10 rdiff:1.42385e-05\n 4423, , [DST_LAST_LAYER][0,0,8,327] fp:-1.0075e-05 dt:-1.00748e-05 diff:1.56433e-10 rdiff:1.55269e-05\n 5282, , [DST_LAST_LAYER][0,0,10,162] fp:1.6475e-05 dt:1.64748e-05 diff:1.74623e-10 rdiff:1.05993e-05\n 5324, , [DST_LAST_LAYER][0,0,10,204] fp:1.33113e-05 dt:1.33115e-05 diff:2.11003e-10 rdiff:1.58514e-05\n 7803, , [DST_LAST_LAYER][0,0,15,123] fp:-1.26343e-05 dt:-1.26345e-05 diff:1.80989e-10 rdiff:1.43252e-05\n 12837, , [DST_LAST_LAYER][0,0,25,37] fp:1.77305e-05 dt:1.77308e-05 diff:2.91038e-10 rdiff:1.64146e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.00381473) l1:(334.857,334.857,2.53197e-05,7.56134e-08) l2:(0.613689,0.613689,5.8255e-08,9.49259e-08) l8:(0.00306389,0.00306389,6.98492e-10,2.27975e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 49:FAILED (errors:72 total:458752) __REPRO: --prop=FWD_D --alg=VANILLA_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t7mb128sic512slc1024dic512dlc512n\"\"exp-gru-1\"\"\n 1057, , [DST_LAST_LAYER][0,0,8,33] fp:-1.74192e-05 dt:-1.74194e-05 diff:1.85537e-10 rdiff:1.06513e-05\n 1467, , [DST_LAST_LAYER][0,0,11,59] fp:-1.16647e-05 dt:-1.16646e-05 diff:1.18234e-10 rdiff:1.01361e-05\n 2326, , [DST_LAST_LAYER][0,0,18,22] fp:-1.24116e-05 dt:-1.24118e-05 diff:2.20098e-10 rdiff:1.77332e-05\n 3015, , [DST_LAST_LAYER][0,0,23,71] fp:-2.45086e-05 dt:-2.45089e-05 diff:2.65572e-10 rdiff:1.08359e-05\n 3422, , [DST_LAST_LAYER][0,0,26,94] fp:-1.28438e-05 dt:-1.28439e-05 diff:1.83718e-10 rdiff:1.43041e-05\n 4372, , [DST_LAST_LAYER][0,1,2,20] fp:-1.98373e-05 dt:-1.98371e-05 diff:2.00089e-10 rdiff:1.00865e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.000136882) l1:(38.0102,38.0102,2.78881e-06,7.33699e-08) l2:(0.233406,0.233406,2.16316e-08,9.26782e-08) l8:(0.00364702,0.00364702,6.98492e-10,1.91524e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 50:FAILED (errors:6 total:40960) __REPRO: --prop=FWD_D --alg=VANILLA_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t10mb32sic128slc512dic128dlc128n\"\"exp-gru-2\"\"\n 509, , [DST_LAST_LAYER][0,0,0,509] fp:1.68099e-05 dt:1.68098e-05 diff:1.76442e-10 rdiff:1.04963e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.00465438) l1:(13.6392,13.6392,1.11404e-06,8.16797e-08) l2:(0.136334,0.136334,1.35477e-08,9.9371e-08) l8:(0.00346488,0.00346488,6.98492e-10,2.01592e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 51:FAILED (errors:1 total:15360) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t30mb1sic512slc512dic512dlc512n\"\"GNMT_enc-inference\"\"\n 867, , [DST_LAST_LAYER][0,0,0,867] fp:-1.66974e-05 dt:-1.66978e-05 diff:3.9654e-10 rdiff:2.37485e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.0102928) l1:(26.2815,26.2815,2.49175e-06,9.481e-08) l2:(0.188739,0.188739,2.16456e-08,1.14685e-07) l8:(0.00357101,0.00357101,9.31323e-10,2.60801e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 52:FAILED (errors:1 total:30720) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l7t30mb1sic1024slc1024dic1024dlc1024n\"\"GNMT_enc-inference\"\"\n 1621, , [DST_LAST_ITERATION][0,0,0,0,1621 fp:1.12915e-05 dt:1.12912e-05 diff:2.71939e-10 rdiff:2.40836e-05\n 3299, , [DST_LAST_ITERATION][1,0,0,0,1251 fp:1.6895e-05 dt:1.68948e-05 diff:1.74623e-10 rdiff:1.03358e-05\n 3462, , [DST_LAST_ITERATION][1,0,0,0,1414 fp:-1.31856e-05 dt:-1.31858e-05 diff:2.22826e-10 rdiff:1.68992e-05\n 4379, , [DST_LAST_ITERATION][2,0,0,0,283 fp:-1.33005e-05 dt:-1.33007e-05 diff:1.53705e-10 rdiff:1.15563e-05\n 5086, , [DST_LAST_ITERATION][2,0,0,0,990 fp:-1.43184e-05 dt:-1.43186e-05 diff:1.93722e-10 rdiff:1.35296e-05\n 7127, , [DST_LAST_ITERATION][3,0,0,0,983 fp:-1.25229e-05 dt:-1.25227e-05 diff:1.71894e-10 rdiff:1.37264e-05\n @@@ [DST_LAST_ITERATION] final: diff: l0(0.000275973) l1:(4.85977,4.85977,4.96115e-07,1.02086e-07) l2:(0.0670462,0.0670462,8.23656e-09,1.22849e-07) l8:(0.0028051,0.0028051,6.1118e-10,2.17882e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):460]: 'compare_dst_last_iteration(p, dst_last_iteration, dst_last_iteration_fp, r, true)' -> 1\n 53:FAILED (errors:6 total:8192) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l8t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 339, , [DST_LAST_LAYER][0,0,0,339] fp:1.09256e-05 dt:1.09255e-05 diff:1.10049e-10 rdiff:1.00726e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.000136831) l1:(0.591236,0.591236,5.9619e-08,1.00838e-07) l2:(0.0232978,0.0232978,2.79339e-09,1.19899e-07) l8:(0.00275012,0.00275012,4.80213e-10,1.74615e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 54:FAILED (errors:1 total:1024) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t1mb1sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n 840, , [DST_LAST_LAYER][0,0,0,840] fp:-1.70641e-05 dt:-1.70639e-05 diff:1.9827e-10 rdiff:1.16191e-05\n 7890, , [DST_LAST_LAYER][0,4,0,850] fp:1.03448e-05 dt:1.03447e-05 diff:1.28239e-10 rdiff:1.23964e-05\n 65896, , [DST_LAST_LAYER][0,37,0,776] fp:-1.21589e-05 dt:-1.21587e-05 diff:1.23691e-10 rdiff:1.01729e-05\n 75227, , [DST_LAST_LAYER][0,42,0,1307] fp:1.01425e-05 dt:1.01426e-05 diff:1.12777e-10 rdiff:1.11193e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.00487747) l1:(77.6934,77.6934,6.21001e-06,7.99297e-08) l2:(0.327464,0.327464,3.19724e-08,9.76364e-08) l8:(0.00424435,0.00424435,9.31323e-10,2.19426e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 55:FAILED (errors:4 total:88000) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t50mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 288, , [DST_LAST_LAYER][0,0,0,288] fp:-1.19614e-05 dt:-1.19616e-05 diff:1.40062e-10 rdiff:1.17095e-05\n 305, , [DST_LAST_LAYER][0,0,0,305] fp:1.78705e-05 dt:1.78703e-05 diff:1.85537e-10 rdiff:1.03823e-05\n 593, , [DST_LAST_LAYER][0,0,0,593] fp:-1.12253e-05 dt:-1.12254e-05 diff:1.18234e-10 rdiff:1.05329e-05\n 1076, , [DST_LAST_LAYER][0,1,0,316] fp:1.06862e-05 dt:1.0686e-05 diff:1.58252e-10 rdiff:1.4809e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.000940038) l1:(67.2097,67.2097,5.20788e-06,7.7487e-08) l2:(0.305667,0.305667,2.91688e-08,9.54268e-08) l8:(0.00445874,0.00445874,9.31323e-10,2.08876e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 56:FAILED (errors:4 total:76000) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t100mb1sic760slc760dic760dlc760n\"\"deepspeech2-inference\"\"\n 840, , [DST_LAST_LAYER][0,0,0,840] fp:-1.70641e-05 dt:-1.70639e-05 diff:1.9827e-10 rdiff:1.16191e-05\n 7890, , [DST_LAST_LAYER][0,4,0,850] fp:1.03448e-05 dt:1.03447e-05 diff:1.28239e-10 rdiff:1.23964e-05\n 132105, , [DST_LAST_LAYER][0,75,0,105] fp:1.15397e-05 dt:1.15398e-05 diff:1.16415e-10 rdiff:1.00882e-05\n 142665, , [DST_LAST_LAYER][0,81,0,105] fp:1.39483e-05 dt:1.39484e-05 diff:1.50976e-10 rdiff:1.0824e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.00628048) l1:(314.421,314.421,2.47317e-05,7.86577e-08) l2:(0.661761,0.661761,6.36699e-08,9.62128e-08) l8:(0.0042449,0.00424489,9.31323e-10,2.19398e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 57:FAILED (errors:4 total:352000) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t200mb1sic1760slc1760dic1760dlc1760n\"\"deepspeech2-inference\"\"\n 64, , [DST_LAST_LAYER][0,0,0,64] fp:1.39e-05 dt:1.39002e-05 diff:1.94632e-10 rdiff:1.40023e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.00135423) l1:(22.3646,22.3646,1.75291e-06,7.83791e-08) l2:(0.174925,0.174925,1.67573e-08,9.57969e-08) l8:(0.00365241,0.00365241,6.98492e-10,1.91242e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 58:FAILED (errors:1 total:25000) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t50mb1sic500slc500dic500dlc500n\"\"pytorch_testcase-inference\"\"\n 59:PASSED __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t629mb1sic128slc128dic128dlc128n\"\"paddlepaddle_testcase-inference\"\"\n 60:PASSED __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t10mb1sic128slc512dic128dlc128n\"\"exp-0\"\"\n 336, , [DST_LAST_ITERATION][0,0,0,0,336 fp:-1.61922e-05 dt:-1.61924e-05 diff:2.38288e-10 rdiff:1.47162e-05\n 875, , [DST_LAST_ITERATION][1,0,0,0,363 fp:1.53776e-05 dt:1.53773e-05 diff:2.3465e-10 rdiff:1.52592e-05\n @@@ [DST_LAST_ITERATION] final: diff: l0(0.000275001) l1:(0.788719,0.788719,7.86266e-08,9.96891e-08) l2:(0.0278671,0.0278671,3.27285e-09,1.17445e-07) l8:(0.00308593,0.00308593,4.22006e-10,1.36751e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):460]: 'compare_dst_last_iteration(p, dst_last_iteration, dst_last_iteration_fp, r, true)' -> 1\n 61:FAILED (errors:2 total:1280) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l10t1mb1sic512slc128dic128dlc128n\"\"exp-1\"\"\n 567, , [DST_LAST_LAYER][0,0,0,567] fp:1.21229e-05 dt:1.21227e-05 diff:1.87356e-10 rdiff:1.54547e-05\n 1842, , [DST_LAST_LAYER][0,0,0,1842] fp:-1.45148e-05 dt:-1.4515e-05 diff:1.81899e-10 rdiff:1.2532e-05\n 2404, , [DST_LAST_LAYER][0,0,1,356] fp:1.03334e-05 dt:1.03336e-05 diff:1.28239e-10 rdiff:1.24101e-05\n 2536, , [DST_LAST_LAYER][0,0,1,488] fp:1.24903e-05 dt:1.24905e-05 diff:1.45519e-10 rdiff:1.16506e-05\n 2971, , [DST_LAST_LAYER][0,0,1,923] fp:1.37668e-05 dt:1.37666e-05 diff:2.12822e-10 rdiff:1.54591e-05\n 6253, , [DST_LAST_LAYER][0,0,3,109] fp:1.34798e-05 dt:1.34795e-05 diff:3.91992e-10 rdiff:2.90799e-05\n 6968, , [DST_LAST_LAYER][0,0,3,824] fp:1.26679e-05 dt:1.26677e-05 diff:1.60981e-10 rdiff:1.27078e-05\n 9013, , [DST_LAST_LAYER][0,0,4,821] fp:1.65134e-05 dt:1.65137e-05 diff:3.03771e-10 rdiff:1.83955e-05\n 9792, , [DST_LAST_LAYER][0,0,4,1600] fp:-1.83082e-05 dt:-1.83079e-05 diff:2.6921e-10 rdiff:1.47044e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.03106) l1:(387.452,387.452,3.87625e-05,1.00044e-07) l2:(0.600824,0.600824,7.2446e-08,1.20578e-07) l8:(0.00358941,0.00358941,9.31323e-10,2.59464e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, *dst_last_layer_fp, r, true)' -> 1\n 62:FAILED (errors:608 total:655360) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t1mb640sic2048slc1024dic1024dlc1024n\"\"GNMT_dec-inference\"\"\n tests:63 passed:48 skipped:0 mistrusted:0 unimplemented:0 failed:15\n <denchmark-h:hr></denchmark-h>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n Intel MKL-DNN includes hardware-specific optimizations and may behave\n differently on depending on the compiler and build environment. Include\n the following information to help reproduce the issue:\n \n \n CPU make and model (try lscpu; if your lscpu does not list CPU flags,\n try running cat /proc/cpuinfo | grep flags | sort -u)\n $ lscpu\n Architecture:          x86_64\n CPU op-mode(s):        32-bit, 64-bit\n Byte Order:            Little Endian\n CPU(s):                4\n On-line CPU(s) list:   0-3\n Thread(s) per core:    2\n Core(s) per socket:    2\n Socket(s):             1\n NUMA node(s):          1\n Vendor ID:             GenuineIntel\n CPU family:            6\n Model:                 142\n Model name:            Intel(R) Core(TM) i7-7567U CPU @ 3.50GHz\n Stepping:              9\n CPU MHz:               701.376\n CPU max MHz:           4000.0000\n CPU min MHz:           400.0000\n BogoMIPS:              7008.00\n Virtualization:        VT-x\n L1d cache:             32K\n L1i cache:             32K\n L2 cache:              256K\n L3 cache:              4096K\n NUMA node0 CPU(s):     0-3\n Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d\n \n \n OS version (uname -a)\n $ uname -a\n Linux eyeoh7-NUC7i7BNH 4.15.0-51-generic #55~16.04.1-Ubuntu SMP Thu May 16 09:24:37 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\n \n \n Compiler version (gcc --version)\n $ gcc --version\n gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\n Copyright (C) 2015 Free Software Foundation, Inc.\n This is free software; see the source for copying conditions.  There is NO\n warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n \n \n MKLROOT value (echo MKLROOT=$MKLROOT)\n $ echo MKLROOT=$MKLROOT\n MKLROOT=\n \n \n CMake version (cmake --version)\n $ cmake --version\n cmake version 3.5.1\n \n \n CMake suite maintained and supported by Kitware (kitware.com/cmake).\n \n CMake output log\n git hash (git log -1 --format=%H)\n $  git log -1 --format=%H\n aef88b7\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "epyeoh", "commentT": "2019-07-11T08:27:40Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/epyeoh>@epyeoh</denchmark-link>\n ,\n Thanks for the report!\n I recall we recently made some improvements to RNN testing as well as removed few unstable tests.\n Could you please try the latest version of Intel MKL-DNN (<denchmark-link:https://github.com/oneapi-src/oneDNN/commit/038c9c7e58311b414452b89b3f3bbc9566e8b7df>038c9c7</denchmark-link>\n ) to check if the problem is gone?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "epyeoh", "commentT": "2019-07-11T09:05:01Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/emfomenk>@emfomenk</denchmark-link>\n \n I did git pull the latest from master branch.\n $ git log -1 --format=%H\n <denchmark-link:https://github.com/oneapi-src/oneDNN/commit/038c9c7e58311b414452b89b3f3bbc9566e8b7df>038c9c7</denchmark-link>\n \n $ ./benchdnn --rnn --batch=inputs/rnn/test_rnn_inference\n tests:63 passed:47 skipped:0 mistrusted:0 unimplemented:0 failed:16\n There are more tests failed, 16 failed as compared to 15 failed previously.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "epyeoh", "commentT": "2019-07-11T09:11:57Z", "comment_text": "\n \t\tI hoped we are improving the library, not vice versa :)\n Thanks for checking! We will investigate the failures.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "epyeoh", "commentT": "2019-07-11T23:55:24Z", "comment_text": "\n \t\tHi <denchmark-link:https://github.com/epyeoh>@epyeoh</denchmark-link>\n ,\n I reproduced the issue. I also talked to <denchmark-link:https://github.com/mgouicem>@mgouicem</denchmark-link>\n  and he said that the failures are in fact expected.\n The failures are caused by rounding errors in the finite floating point arithmetic.\n But in terms of the l1, l2, and l_infinity norms of relative error the accuracy is really good.\n For instance, in the case 58 the  l2 norm of the relative error is 9.57969e-08 which is absolutely fine:\n <denchmark-code>64, , [DST_LAST_LAYER][0,0,0,64] fp:1.39e-05 dt:1.39002e-05 diff:1.94632e-10 rdiff:1.40023e-05\n @@@ [DST_LAST_LAYER] final: diff: l0(0.00135423) l1:(22.3646,22.3646,1.75291e-06,7.83791e-08) l2:(0.174925,0.174925,1.67573e-08,9.57969e-08) l8:(0.00365241,0.00365241,6.98492e-10,1.91242e-07)\n @@@ error [int rnn::doit(const rnn::rnn_prb_t, res_t*):457]: 'compare_dst_last_layer( p, dst_last_layer, dst_last_layer_fp, r, true)' -> 1\n 58:FAILED (errors:1 total:25000) __REPRO: --prop=FWD_D --alg=LBR_GRU --activation=LOGISTIC --direction=left2right --cfg=f32 --scaling=none l1t50mb1sic500slc500dic500dlc500n\"\"pytorch_testcase-inference\"\"\n </denchmark-code>\n \n The problem is that it is really hard to develop robust testing solution for RNNs, since they invoke a huge number of operations and it is completely unclear how to choose the threshold so that it would not be too large to let the error escape, but at the same time not too small to report false positives error (the latter is exactly the case that you observe).\n We are working on the solution right now and hopefully will soon address this issue. For now we recommend to run tests only for small RNNs, (see tests/benchdnn/inputs/rnn/test_rnn_small input file). For bigger sizes ignore the failures reported by benchdnn and just check the l2_norm of the error.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "epyeoh", "commentT": "2019-07-12T01:44:05Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/emfomenk>@emfomenk</denchmark-link>\n  understood, thanks for the sharing and help to root cause this issue.\n \t\t"}}}, "commit": {"commit_id": "e84764960636802ee25e746d3ffea3ea1deeac88", "commit_author": "Mourad Gouicem", "commitT": "2019-07-30 14:52:11-07:00", "commit_complexity": {"commit_NLOC": "0.0", "commit_CCN": "0.0", "commit_Nprams": "0.0"}, "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\benchdnn\\rnn\\rnn_aux.cpp", "file_new_name": "tests\\benchdnn\\rnn\\rnn_aux.cpp", "file_complexity": {"file_NLOC": "574", "file_CCN": "149", "file_NToken": "4310"}, "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "401,402,403,404,405,406,407,408,409,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,575,576,577,578,579,580,581,582", "deleted_lines": "420,421,422,423,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,490", "method_info": {"method_name": "rnn::compare_dat", "method_params": "p,kind,mem_dt,mem_fp,r,final_compare", "method_startline": "364", "method_endline": "614", "method_complexity": {"method_NLOC": "215", "method_CCN": "57", "method_NToken": "1851", "method_nesting_level": "1"}}}}}}}}