{"BR": {"BR_id": "33376", "BR_author": "rggjan", "BRopenT": "2019-10-15T13:32:32Z", "BRcloseT": "2019-12-17T21:41:47Z", "BR_text": {"BRsummary": "importing tensorflow inside a function/object causes a memory leak", "BRdescription": "\n System information\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15\n Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\n TensorFlow installed from (source or binary): pip install tensorflow==1.14\n TensorFlow version (use command below): 1.14.0\n Python version: 3.6.8\n Bazel version (if compiling from source): -\n GCC/Compiler version (if compiling from source): -\n CUDA/cuDNN version: -\n GPU model and memory: -\n \n Describe the current behavior\n When importing tensorflow from a function or object, the import statement somehow keeps a reference to the function and increasing it's reference count. The full import stacktrace is never freed, making it impossible for the object (and anything referenced from that object or function) to be freed from memory.\n Describe the expected behavior\n It should be possible to free the function calling import tensorflow. This is not an issue with any other imports (like import logger).\n Code to reproduce the issue\n <denchmark-code>import gc\n \n \n class TFImporter:\n     def __init__(self, name):\n         self._name = name\n         print(f\"TFImporter init {self._name}\")\n \n     def get_tf(self):\n         print(f\"import tensorflow {self._name}\")\n         import tensorflow\n         print(tensorflow.version.VERSION)\n \n     def get_other_module(self):\n         print(f\"import logging {self._name}\")\n         import logging\n         logging.info(\"Message\")\n \n     def __del__(self):\n         print(f\"TFImporter delete {self._name}\")\n \n \n def main():\n     importer1 = TFImporter(1)\n     importer1.get_other_module()\n     del importer1\n     print(\"importer1 deleted\")\n \n     importer2 = TFImporter(2)\n     importer2.get_tf()\n     del importer2\n     print(\"importer2 deleted\")\n \n     importer3 = TFImporter(3)\n     importer3.get_tf()\n     del importer3\n     print(\"importer3 deleted\")\n \n     print(f\"Garbage collection: {gc.collect()}\")\n \n     print(f\"Waiting for input:\")\n     input()\n \n \n main()\n </denchmark-code>\n \n this outputs:\n <denchmark-code>/Users/jan/miniconda/envs/foo/bin/python /Users/jan/code/tensorflow_error.py\n TFImporter init 1\n import logging 1\n TFImporter delete 1\n importer1 deleted\n TFImporter init 2\n import tensorflow 2\n 1.14.0\n importer2 deleted\n TFImporter init 3\n import tensorflow 3\n 1.14.0\n TFImporter delete 3\n importer3 deleted\n Garbage collection: 22\n Waiting for input:\n foo\n TFImporter delete 2\n \n Process finished with exit code 0\n </denchmark-code>\n \n So importer2 is only freed after the python application finishes. Neither gc.collect nor deleting the object causes it to be released in python.\n This is not an issue in this toy example, but importer2 could have a reference to a large number of other objects that take considerable space in memory in reality.\n Also, this only happens for the first import. importer3 can be freed without issues.\n \n <denchmark-link:https://github.com/tensorflow/tensorflow/files/3729501/tf_env.txt>tf_env.txt</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "rggjan", "commentT": "2019-10-16T06:34:23Z", "comment_text": "\n \t\tIssue replicating for Tf 1.14, kindly for the <denchmark-link:https://colab.sandbox.google.com/gist/oanush/e224d0fa208b982d84e5cb18c1317ce9/33376.ipynb>gist</denchmark-link>\n .ThThanks!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "rggjan", "commentT": "2019-12-16T21:11:18Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/annarev>@annarev</denchmark-link>\n  is this related to lazy loaders or estimator/keras integration?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "rggjan", "commentT": "2019-12-17T00:30:38Z", "comment_text": "\n \t\tIt appears to be due to saving error when importing portpicker here:\n <denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L44>https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L44</denchmark-link>\n \n We can probably save the error text instead or import portpicker inside the function that creates a cluster.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "rggjan", "commentT": "2019-12-17T01:08:20Z", "comment_text": "\n \t\tYeah, it seems weird that we'd survive the import, only to error out later.\n Let's either import it inside the cluster creation, or print the error\n directly on import (but still continue), and later error with a note to\n look for the earlier error.\n \n Honestly, I think the local import is preferable in this case.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "rggjan", "commentT": "2019-12-17T21:41:49Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33376>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33376>No</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "413d0fa9d75e99e02b74bb079465bea728eb3a44", "commit_author": "Anna R", "commitT": "2019-12-17 13:40:41-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tensorflow\\python\\framework\\test_util.py", "file_new_name": "tensorflow\\python\\framework\\test_util.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "3088", "deleted_lines": "40,41,42,43,44,45,46,47,3096,3097"}}}}}}