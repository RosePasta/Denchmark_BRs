{"BR": {"BR_id": "10641", "BR_author": "JerrikEph", "BRopenT": "2017-06-12T02:16:00Z", "BRcloseT": "2018-02-08T17:44:56Z", "BR_text": {"BRsummary": "bug: BeamSearchDecoder should not assume that  when time &gt; 0 beam will be full", "BRdescription": "\n <denchmark-code>  scores_flat = control_flow_ops.cond(\n       time > 0,\n       lambda: array_ops.reshape(scores, [batch_size, -1]),\n       lambda: scores[:, 0])\n   num_available_beam = control_flow_ops.cond(\n       time > 0,\n       lambda: math_ops.reduce_prod(scores_shape[1:]),\n       lambda: math_ops.reduce_prod(scores_shape[2:]))\n \n   # Pick the next beams according to the specified successors function\n   next_beam_size = math_ops.minimum(\n       ops.convert_to_tensor(\n           beam_width, dtype=dtypes.int32, name=\"beam_width\"),\n       num_available_beam)\n   next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=next_beam_size)\n   next_beam_scores.set_shape([static_batch_size, beam_width])\n   word_indices.set_shape([static_batch_size, beam_width])\n </denchmark-code>\n \n code start from\n <denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py#L510>https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py#L510</denchmark-link>\n \n Correct me if I am wrong, but I think this code is assuming that, when time > 0 the beam will be full. It is true when the vocabulary is big such as is the case in machine translation. but if the vocabulary is small, the beam might won't be full when time > 0 and might pose a problem.  the value of next_beam_size  in the code seems must be beam_width or it will raise an error since next_beam_scores.set_shape([static_batch_size, beam_width]), which make  next_beam_size = math_ops.minimum useless.\n I am trying to write a Pointer Network BeamSearch Decoder by modifying this source file. And the vocabulary is usually small, so there is a possibility that when time == 1 the beam won't be fully filled.\n I appreciate finally some one wrote a general BeamSeach decoder, that will make my life easier.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "JerrikEph", "commentT": "2017-06-13T17:27:39Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ebrevdo>@ebrevdo</denchmark-link>\n , could you please take a look, it's beyond my expertise.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "JerrikEph", "commentT": "2017-06-13T18:07:49Z", "comment_text": "\n \t\tThis is indeed the assumption.  Unfortunately it's unlikely to be fixed\n until after the 1.2 release and I'm away this week.  If you would like to\n send a PR to fix this by using the tf.shape() on the input Tensor instead\n of assuming beam_width, and adding a unit test, I can review when I return.\n \n On Jun 13, 2017 10:28 AM, \"Andrew Selle\" <notifications@github.com> wrote:\n \n <denchmark-link:https://github.com/ebrevdo>@ebrevdo</denchmark-link>\n  <<denchmark-link:https://github.com/ebrevdo>https://github.com/ebrevdo</denchmark-link>\n >, could you please take a look, it's\n beyond my expertise.\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub\n <<denchmark-link:https://github.com/tensorflow/tensorflow/issues/10641#issuecomment-308189704>#10641 (comment)</denchmark-link>\n >,\n or mute the thread\n <<denchmark-link:https://github.com/notifications/unsubscribe-auth/ABtim6kdt62nhk_I7Ie5cDr45ccAy5MRks5sDsbEgaJpZM4N2l0D>https://github.com/notifications/unsubscribe-auth/ABtim6kdt62nhk_I7Ie5cDr45ccAy5MRks5sDsbEgaJpZM4N2l0D</denchmark-link>\n >\n .\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "JerrikEph", "commentT": "2017-06-14T15:01:17Z", "comment_text": "\n \t\t<denchmark-code>def initialize(self, name=None):\n     \"\"\"Initialize the decoder.\n \n     Args:\n       name: Name scope for any created operations.\n \n     Returns:\n       `(finished, start_inputs, initial_state)`.\n     \"\"\"\n     finished, start_inputs = self._finished, self._start_inputs\n \n     log_prob_mask = array_ops.one_hot(                          # shape(batch_sz, beam_sz)\n         array_ops.ones([self._batch_size], dtype=dtypes.int32),\n         depth=self._beam_width, dtype=dtypes.bool)\n \n     log_prob_zeros = array_ops.zeros([self._batch_size, self._beam_width],  # shape(batch_sz, beam_sz)\n                     dtype=nest.flatten(self._initial_cell_state)[0].dtype)\n     log_prob_neg_inf = array_ops.ones([self._batch_size, self._beam_width],  #shape(batch_sz, beam_sz)\n                     dtype=nest.flatten(self._initial_cell_state)[0].dtype) * -float('inf')\n \n     log_probs = array_ops.where(log_prob_mask, log_prob_zeros, log_prob_neg_inf)\n \n     initial_state = BeamSearchDecoderState(\n         cell_state=self._initial_cell_state,\n         log_probs=log_probs,\n         finished=finished,\n         lengths=array_ops.zeros(\n             [self._batch_size, self._beam_width], dtype=dtypes.int32))\n \n     return (finished, start_inputs, initial_state)\n </denchmark-code>\n \n <denchmark-link:https://github.com/ebrevdo>@ebrevdo</denchmark-link>\n \n It probably is not  a good idea to push tensors with variant shape to TensorArray.\n Actually I think it's a good idea to just set  to negative infinity in initialize function.\n and of course set\n <denchmark-code>  scores_flat = control_flow_ops.cond(\n       time > 0,\n       lambda: array_ops.reshape(scores, [batch_size, -1]),\n       lambda: scores[:, 0])\n   num_available_beam = control_flow_ops.cond(\n       time > 0,\n       lambda: math_ops.reduce_prod(scores_shape[1:]),\n       lambda: math_ops.reduce_prod(scores_shape[2:]))\n \n   # Pick the next beams according to the specified successors function\n   next_beam_size = math_ops.minimum(\n       ops.convert_to_tensor(\n           beam_width, dtype=dtypes.int32, name=\"beam_width\"),\n       num_available_beam)\n </denchmark-code>\n \n to a  simple reshape\n <denchmark-code>  scores_flat = array_ops.reshape(scores, [batch_size, -1])\n </denchmark-code>\n \n I will add a test unit and test it if you think it's ok.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "JerrikEph", "commentT": "2017-12-20T19:15:33Z", "comment_text": "\n \t\tIt has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "JerrikEph", "commentT": "2018-01-04T19:21:30Z", "comment_text": "\n \t\tIt has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "JerrikEph", "commentT": "2018-01-23T23:07:33Z", "comment_text": "\n \t\tA member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "JerrikEph", "commentT": "2018-02-07T13:47:33Z", "comment_text": "\n \t\tNagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.\n \t\t"}}}, "commit": {"commit_id": "be1b702ff357e851eb4a7237728d80fe08220816", "commit_author": "JerrikEph", "commitT": "2018-01-20 14:06:16-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tensorflow\\contrib\\seq2seq\\python\\kernel_tests\\beam_search_decoder_test.py", "file_new_name": "tensorflow\\contrib\\seq2seq\\python\\kernel_tests\\beam_search_decoder_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314", "deleted_lines": null, "method_info": {"method_name": "test_step", "method_params": "self", "method_startline": "243", "method_endline": "314"}}, "hunk_1": {"Ismethod": 1, "added_lines": "234,235,236,237,238,239,240", "deleted_lines": null, "method_info": {"method_name": "setUp", "method_params": "self", "method_startline": "234", "method_endline": "240"}}, "hunk_2": {"Ismethod": 1, "added_lines": "244,245,246,247,248,249,250,251,252,253,254,255,256,257,258", "deleted_lines": null, "method_info": {"method_name": "test_step.get_probs", "method_params": "", "method_startline": "244", "method_endline": "258"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\contrib\\seq2seq\\python\\ops\\beam_search_decoder.py", "file_new_name": "tensorflow\\contrib\\seq2seq\\python\\ops\\beam_search_decoder.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "303,304,305,306,307,308,311", "deleted_lines": "303,304,305", "method_info": {"method_name": "initialize", "method_params": "self,name", "method_startline": "292", "method_endline": "316"}}}}}}}