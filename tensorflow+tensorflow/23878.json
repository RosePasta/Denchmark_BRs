{"BR": {"BR_id": "23878", "BR_author": "javiermas", "BRopenT": "2018-11-20T11:31:19Z", "BRcloseT": "2018-12-18T16:50:57Z", "BR_text": {"BRsummary": "Bug: instantiating dynamic_rnn with tf.int32 in input and state raises TypeError", "BRdescription": "\n System information\n \n OS Platform: OS X 10.13.3\n Custom code\n tensorflow version: 1.12.0\n python version: 3.6.5\n \n Describe the current behavior\n Tensorflow raises a TypeError when creating a dynamic_rnn with tf.int32 type in its input and state. When changing the type to tf.float32 the error is not raised.\n Describe the expected behavior\n Ideally, a dynamic_rnn should support tf.in32 types. If there's any reason why instantiating a dynamic_rnn with tf.int32 type in its input and state should not be allowed, a custom error should be raised.\n Code to reproduce the issue\n The code below reproduces the error:\n <denchmark-code>import tensorflow as tf\n \n X = tf.placeholder(tf.int32, [None, 10, 1])\n cell = tf.nn.rnn_cell.LSTMCell(1, dtype=tf.int32)\n output, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.int32)\n \n </denchmark-code>\n \n The code below doesn't:\n <denchmark-code>\n import tensorflow as tf\n \n X = tf.placeholder(tf.float32, [None, 10, 1])\n cell = tf.nn.rnn_cell.LSTMCell(1, dtype=tf.float32)\n output, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.float32)\n \n </denchmark-code>\n \n Note the change in dtype.\n <denchmark-h:h2>Other info / logs\n TRACEBACK:</denchmark-h>\n \n TypeError                                 Traceback (most recent call last)\n  in ()\n 2 X = tf.placeholder(tf.int32, [None, 10, 1])\n 3 cell = tf.nn.rnn_cell.LSTMCell(1, dtype=tf.int32)\n ----> 4 output, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.int32)#, initial_state=state)\n 5\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py in dynamic_rnn(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\n 662         swap_memory=swap_memory,\n 663         sequence_length=sequence_length,\n --> 664         dtype=dtype)\n 665\n 666     # Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py in _dynamic_rnn_loop(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\n 870       parallel_iterations=parallel_iterations,\n 871       maximum_iterations=time_steps,\n --> 872       swap_memory=swap_memory)\n 873\n 874   # Unpack final output if not using output tuples.\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\n 3289       ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\n 3290     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n -> 3291                                     return_same_structure)\n 3292     if maximum_iterations is not None:\n 3293       return result[1]\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants, return_same_structure)\n 3002       with ops.get_default_graph()._mutation_lock():  # pylint: disable=protected-access\n 3003         original_body_result, exit_vars = self._BuildLoop(\n -> 3004             pred, body, original_loop_vars, loop_vars, shape_invariants)\n 3005     finally:\n 3006       self.Exit()\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\n 2937         flat_sequence=vars_for_body_with_tensor_arrays)\n 2938     pre_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\n -> 2939     body_result = body(*packed_vars_for_body)\n 2940     post_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\n 2941     if not nest.is_sequence(body_result):\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in (i, lv)\n 3258         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n 3259             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n -> 3260         body = lambda i, lv: (i + 1, orig_body(*lv))\n 3261\n 3262     if context.executing_eagerly():\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py in _time_step(time, output_ta_t, state)\n 838           skip_conditionals=True)\n 839     else:\n --> 840       (output, new_state) = call_cell()\n 841\n 842     # Keras cells always wrap state as list, even if it's a single tensor.\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py in ()\n 824     if is_keras_rnn_cell and not nest.is_sequence(state):\n 825       state = [state]\n --> 826     call_cell = lambda: cell(input_t, state)\n 827\n 828     if sequence_length is not None:\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py in call(self, inputs, state, scope, *args, **kwargs)\n 368     # method.  See the class docstring for more details.\n 369     return base_layer.Layer.call(self, inputs, state, scope=scope,\n --> 370                                      *args, **kwargs)\n 371\n 372\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in call(self, inputs, *args, **kwargs)\n 372\n 373       # Actually call layer\n --> 374       outputs = super(Layer, self).call(inputs, *args, **kwargs)\n 375\n 376     if not context.executing_eagerly():\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in call(self, inputs, *args, **kwargs)\n 755       if not in_deferred_mode:\n 756         self._in_call = True\n --> 757         outputs = self.call(inputs, *args, **kwargs)\n 758         self._in_call = False\n 759         if outputs is None:\n ~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py in call(self, inputs, state)\n 1003            sigmoid(i + self._w_i_diag * c_prev) * self._activation(j))\n 1004     else:\n -> 1005       c = (sigmoid(f + self._forget_bias) * c_prev + sigmoid(i) *\n 1006            self._activation(j))\n 1007\n TypeError: unsupported operand type(s) for +: 'Tensor' and 'float'\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "javiermas", "commentT": "2018-11-26T20:33:53Z", "comment_text": "\n \t\tThanks for the clear repro example. Probably this is a duplicate of <denchmark-link:https://github.com/tensorflow/tensorflow/issues/14729>#14729</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "javiermas", "commentT": "2018-11-27T15:30:06Z", "comment_text": "\n \t\tThanks for the report, I will take a look today or tomorrow.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "javiermas", "commentT": "2018-12-17T18:25:48Z", "comment_text": "\n \t\tSorry for the very late reply. After some digging, the root cause is because of the default forget gate bias being initialized as float. However, even casting it to be int32 will still causing the code to fail down the road since the activation function for LSTM (tanh and sigmoid) only support floating numbers. So the conclusion is that LSTM will only support floating numbers as the dtype for input and states.\n I will update the code to have a clear error message when the input dtype is not float number.\n \t\t"}}}, "commit": {"commit_id": "36304bc4ceb6140e470420b65ce470092fc47ab2", "commit_author": "Scott Zhu", "commitT": "2018-12-17 14:50:42-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\kernel_tests\\rnn_test.py", "file_new_name": "tensorflow\\python\\kernel_tests\\rnn_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193", "deleted_lines": null, "method_info": {"method_name": "testInvalidDtype", "method_params": "self", "method_startline": "176", "method_endline": "193"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tensorflow\\python\\ops\\rnn_cell_impl.py", "file_new_name": "tensorflow\\python\\ops\\rnn_cell_impl.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1553,1554,1555,1556,1557,1558,1559", "deleted_lines": null, "method_info": {"method_name": "_check_supported_dtypes", "method_params": "dtype", "method_startline": "1553", "method_endline": "1559"}}, "hunk_1": {"Ismethod": 1, "added_lines": "1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550", "deleted_lines": null, "method_info": {"method_name": "_check_rnn_cell_input_dtypes", "method_params": "inputs", "method_startline": "1534", "method_endline": "1550"}}, "hunk_2": {"Ismethod": 1, "added_lines": "436", "deleted_lines": null, "method_info": {"method_name": "build", "method_params": "self,inputs_shape", "method_startline": "432", "method_endline": "447"}}, "hunk_3": {"Ismethod": 1, "added_lines": "451", "deleted_lines": "449", "method_info": {"method_name": "call", "method_params": "self,inputs,state", "method_startline": "449", "method_endline": "456"}}}}}}}