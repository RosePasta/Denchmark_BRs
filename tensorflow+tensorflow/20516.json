{"BR": {"BR_id": "20516", "BR_author": "sleighsoft", "BRopenT": "2018-07-03T12:25:05Z", "BRcloseT": "2018-07-04T00:45:38Z", "BR_text": {"BRsummary": "Cannot restore variables with Checkpoint because keys do not align", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10\n TensorFlow installed from (source or binary): binary\n TensorFlow version (use command below): tf-nightly==1.10.0.dev20180609\n Python version: 3.6.5\n Bazel version (if compiling from source): -\n GCC/Compiler version (if compiling from source): -\n CUDA/cuDNN version: -\n GPU model and memory: -\n Exact command to reproduce:\n \n I get the error that is thrown here:\n <denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/training/checkpointable/util.py#L633>https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/training/checkpointable/util.py#L633</denchmark-link>\n \n I cannot provide code to reproduce it. But basically what happens is I have a class that inherits from Checkpointable. It assigns all variables to itself to make them checkpointable. It also assigns an optimizer to itself. I then save the model and restore it. When calling .assert_consumed() on the load_status object of restore(dir, session) it throws an error because some key does not match. The variable it tries to restore is actually in the saved checkpoint it just has a different key then the one it gets from enumerate(self._checkpoint.object_graph_proto.nodes).\n This describes it as good as I can. Sorry for not being able to share the code. I tried to reproduce it but so far I cannot. I believe it is a bug, because I call ckpt.save() and immediately after it ckpt.restore() and I get the exception.\n Output of self._checkpoint.object_by_proto_id.keys() at line 631.\n You can see that some keys are missing (idk why) but theses are the ones I need to restore.\n <denchmark-code>[0, 1, 2, 3, 4, 5, 6, 7, 14, 19, 10, 17, 22, 11, 18, 23, 12, 13]\n </denchmark-code>\n \n Output of util._serialize_object_graph(self.checkpoint, None) after restore before assert_consumed\n nodes {\n   children {\n     node_id: 1\n     local_name: \"model\"\n   }\n   children {\n     node_id: 2\n     local_name: \"save_counter\"\n   }\n }\n nodes {\n   children {\n     node_id: 3\n     local_name: \"_global_step_pretrain\"\n   }\n   children {\n     node_id: 4\n     local_name: \"embedding\"\n   }\n   children {\n     node_id: 5\n     local_name: \"cell\"\n   }\n   children {\n     node_id: 6\n     local_name: \"dense\"\n   }\n   children {\n     node_id: 7\n     local_name: \"_optimizer\"\n   }\n   children {\n     local_name: \"_checkpoint\"\n   }\n }\n nodes {\n   attributes {\n     name: \"VARIABLE_VALUE\"\n     full_name: \"initialize_or_restore/save_counter\"\n     checkpoint_key: \"save_counter/.ATTRIBUTES/VARIABLE_VALUE\"\n   }\n }\n nodes {\n   attributes {\n     name: \"VARIABLE_VALUE\"\n     full_name: \"ConditionedLSTMGenerator2/CONDITIONED_LSTM/pretrain/global_step\"\n     checkpoint_key: \"model/_global_step_pretrain/.ATTRIBUTES/VARIABLE_VALUE\"\n   }\n }\n nodes {\n   attributes {\n     name: \"VARIABLE_VALUE\"\n     full_name: \"ConditionedLSTMGenerator2/CONDITIONED_LSTM/embedding\"\n     checkpoint_key: \"model/embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n   }\n }\n nodes {\n   children {\n     node_id: 8\n     local_name: \"kernel\"\n   }\n   children {\n     node_id: 9\n     local_name: \"bias\"\n   }\n   attributes {\n     name: \"OBJECT_CONFIG_JSON\"\n     checkpoint_key: \"model/cell/.ATTRIBUTES/OBJECT_CONFIG_JSON\"\n   }\n }\n nodes {\n   children {\n     node_id: 10\n     local_name: \"kernel\"\n   }\n   children {\n     node_id: 11\n     local_name: \"bias\"\n   }\n   attributes {\n     name: \"OBJECT_CONFIG_JSON\"\n     checkpoint_key: \"model/dense/.ATTRIBUTES/OBJECT_CONFIG_JSON\"\n   }\n }\n nodes {\n   children {\n     node_id: 12\n     local_name: \"beta1_power\"\n   }\n   children {\n     node_id: 13\n     local_name: \"beta2_power\"\n   }\n   slot_variables {\n     original_variable_node_id: 4\n     slot_name: \"m\"\n     slot_variable_node_id: 14\n   }\n   slot_variables {\n     original_variable_node_id: 8\n     slot_name: \"m\"\n     slot_variable_node_id: 15\n   }\n   slot_variables {\n     original_variable_node_id: 9\n     slot_name: \"m\"\n     slot_variable_node_id: 16\n   }\n   slot_variables {\n     original_variable_node_id: 10\n     slot_name: \"m\"\n     slot_variable_node_id: 17\n   }\n   slot_variables {\n     original_variable_node_id: 11\n     slot_name: \"m\"\n     slot_variable_node_id: 18\n   }\n   slot_variables {\n     original_variable_node_id: 4\n     slot_name: \"v\"\n     slot_variable_node_id: 19\n   }\n   slot_variables {\n     original_variable_node_id: 8\n     slot_name: \"v\"\n     slot_variable_node_id: 20\n   }\n   slot_variables {\n     original_variable_node_id: 9\n     slot_name: \"v\"\n     slot_variable_node_id: 21\n   }\n   slot_variables {\n     original_variable_node_id: 10\n     slot_name: \"v\"\n     slot_variable_node_id: 22\n   }\n   slot_variables {\n     original_variable_node_id: 11\n     slot_name: \"v\"\n     slot_variable_node_id: 23\n   }\n }\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "sleighsoft", "commentT": "2018-07-03T12:43:33Z", "comment_text": "\n \t\tI assume this is something for <denchmark-link:https://github.com/allenlavoie>@allenlavoie</denchmark-link>\n  ?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "sleighsoft", "commentT": "2018-07-03T13:15:10Z", "comment_text": "\n \t\tI found the culprit. Double assigning a variable. Here BasicLSTMCell.\n import tensorflow as tf\n from tensorflow.python.training.checkpointable import base as checkpointable\n from tensorflow.python.training.checkpointable import util\n \n class Model(checkpointable.Checkpointable):\n \n   def __init__(self):\n     self.cell = tf.nn.rnn_cell.BasicLSTMCell(4)\n     self.cell = tf.nn.rnn_cell.BasicLSTMCell(4)\n     # self.cell = tf.nn.rnn_cell.BasicLSTMCell(4)\n     out = self.cell(tf.constant([[1.]]), self.cell.zero_state(1, tf.float32))\n     self.optimizer = tf.train.AdamOptimizer()\n     self.optimizer.minimize(tf.reduce_sum(out[0]))\n     self.session = tf.Session()\n     self.checkpoint = tf.train.Checkpoint(model=self)\n \n   def init(self):\n     print('Init')\n     self.session.run(tf.global_variables_initializer())\n \n   def save(self):\n     print('Save')\n     self.checkpoint.save('./tmp/', self.session)\n \n   def restore(self):\n     print('Restore')\n     latest = tf.train.latest_checkpoint('./tmp/')\n     load_status = self.checkpoint.restore(latest)\n     print(util._serialize_object_graph(self.checkpoint, None))\n     load_status.assert_consumed().run_restore_ops(self.session)\n \n   def print(self):\n     print(self.session.run(self.cell._kernel))\n \n \n m = Model()\n m.init()\n m.print()\n m.save()\n m.restore()\n m.print()\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "sleighsoft", "commentT": "2018-07-03T13:35:35Z", "comment_text": "\n \t\tIt works if I double assign a  though. Seems like this <denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/training/checkpointable/base.py#L593>https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/training/checkpointable/base.py#L593</denchmark-link>\n  does not override/clear all previous state.\n Edit: Also does not work for tf.layers.Dense and probably others.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "sleighsoft", "commentT": "2018-07-03T16:27:24Z", "comment_text": "\n \t\tHuh, good point, looks like the by-name lookup isn't being updated when the dependency is replaced. Thank you for the report!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "sleighsoft", "commentT": "2018-07-03T17:55:41Z", "comment_text": "\n \t\tHappy to help\n \t\t"}}}, "commit": {"commit_id": "f46627f9ed9cd41b5a1ad9cebbdd4c240846c4e0", "commit_author": "Allen Lavoie", "commitT": "2018-07-03 11:32:16-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\training\\checkpointable\\base.py", "file_new_name": "tensorflow\\python\\training\\checkpointable\\base.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "636", "deleted_lines": "634", "method_info": {"method_name": "_track_checkpointable", "method_params": "self,checkpointable,name,overwrite", "method_startline": "585", "method_endline": "637"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\training\\checkpointable\\tracking_test.py", "file_new_name": "tensorflow\\python\\training\\checkpointable\\tracking_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "47,48,49", "deleted_lines": null, "method_info": {"method_name": "testMultipleAssignment", "method_params": "self", "method_startline": "36", "method_endline": "49"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\training\\checkpointable\\util_test.py", "file_new_name": "tensorflow\\python\\training\\checkpointable\\util_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "105", "deleted_lines": "105", "method_info": {"method_name": "testAddVariable", "method_params": "self", "method_startline": "79", "method_endline": "136"}}}}}}}