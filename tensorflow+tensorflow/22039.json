{"BR": {"BR_id": "22039", "BR_author": "gulingfengze", "BRopenT": "2018-09-04T03:49:40Z", "BRcloseT": "2020-07-28T12:32:01Z", "BR_text": {"BRsummary": "Session.run () takes a long time", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\n Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\n TensorFlow installed from (source or binary): source\n TensorFlow version (use command below):1.9.0\n Python version:3.6\n Bazel version (if compiling from source):N/A\n GCC/Compiler version (if compiling from source):6.4.0\n CUDA/cuDNN version:9.0 / 7.0\n GPU model and memory:GeForce GTX960\n Exact command to reproduce:N/A\n \n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n Each time tensorflow performs session.run() for target detection, the detection time of the first image is very long (including some initialization operations, of course), while the detection time of other images is normal. Suppose I detect the image under a certain path (for example, there are ten images), the time of detecting the first image is relatively long, and the remaining nine images are relatively short (basically consistent). However, my operation in practical application is as follows: the session.run() is called every once in a while to detect a picture. I hope that the detection time after the first one is normal except for the long time. However, through my test (guess), after exiting the loop logic of detection, tensorflow redid a series of initialization operations the next time the detection was done, which puzzled me.\n With other frameworks, such as mxnet, initial detection takes longer. And then the detection time is normal, as if it's not doing some initialization anymore. I thought, could tensorflow do the same thing?\n <denchmark-h:h3>Source code / logs</denchmark-h>\n \n 2018-09-04 14:48:59.111510: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.57GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n time\uff1a5627.940655ms\n 0.9999423027038574\n time\uff1a657.650471ms\n 0.9996843338012695\n time\uff1a676.565170ms\n 0.9722122550010681\n 0.6320008635520935\n time\uff1a667.881966ms\n 0.996504545211792\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "gulingfengze", "commentT": "2018-09-05T00:44:11Z", "comment_text": "\n \t\tI met a similar problem. It seems to be caused by some lazy operations. That means some operations will not be executed until the graph actually runs.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "gulingfengze", "commentT": "2018-09-06T02:39:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/bignamehyp>@bignamehyp</denchmark-link>\n  Is there a way to solve this problem?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "gulingfengze", "commentT": "2019-02-13T21:54:31Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/gulingfengze>@gulingfengze</denchmark-link>\n  is this still an issue? Could you load TF 1.12 (stable) or latest version and check whether the issue persists? It is will be good if you can share a simplified code to reproduce the issue. If it was solved by newer version, please close the issue. Thanks!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "gulingfengze", "commentT": "2019-02-16T08:18:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jvishnuvardhan>@jvishnuvardhan</denchmark-link>\n  The latest version still has this problem, and my guess is that the program did some initialization like gpu at the beginning of execution.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "gulingfengze", "commentT": "2019-02-19T17:49:28Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jvishnuvardhan>@jvishnuvardhan</denchmark-link>\n  I work on XLA, so this is outside of my area of ownership.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "gulingfengze", "commentT": "2019-02-19T17:50:00Z", "comment_text": "\n \t\t\n my guess is that the program did some initialization like gpu at the beginning of execution.\n \n Quite possibly.  To address this, when you run configure.py, you need to ensure that you tell TF to build for sm_XY corresponding to your machine's GPU.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "gulingfengze", "commentT": "2020-07-14T11:05:35Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/gulingfengze>@gulingfengze</denchmark-link>\n \n Please confirm if this is still an issue, or if possible use later stable versions of tf and let us know.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "gulingfengze", "commentT": "2020-07-21T11:52:04Z", "comment_text": "\n \t\tThis issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "gulingfengze", "commentT": "2020-07-28T12:31:58Z", "comment_text": "\n \t\tClosing as stale. Please reopen if you'd like to work on this further.\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "gulingfengze", "commentT": "2020-07-28T12:32:03Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22039>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/22039>No</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "59166604c26b8ffde742389fcd99c8090bf8ec04", "commit_author": "Feng Liu", "commitT": "2019-12-19 14:36:01-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\compiler\\mlir\\lite\\python\\graphdef_to_tfl_flatbuffer.cc", "file_new_name": "tensorflow\\compiler\\mlir\\lite\\python\\graphdef_to_tfl_flatbuffer.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "280", "method_info": {"method_name": "tensorflow::ConvertGraphDefToTFLiteFlatBuffer", "method_params": "model_flags,toco_flags,debug_info,input,result", "method_startline": "169", "method_endline": "289"}}}}}}}