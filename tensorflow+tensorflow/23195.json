{"BR": {"BR_id": "23195", "BR_author": "brianmartin", "BRopenT": "2018-10-23T20:21:54Z", "BRcloseT": "2018-10-31T01:38:43Z", "BR_text": {"BRsummary": "Segfault reading dataset more than once (`make_batched_features_dataset`)", "BRdescription": "\n System information\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14 Mojave\n Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\n TensorFlow installed from (source or binary): Binary / pip\n TensorFlow version (use command below): ('v1.11.0-rc2-4-gc19e29306c', '1.11.0')\n Python version: 2.7.10\n Bazel version (if compiling from source): NA\n GCC/Compiler version (if compiling from source): NA\n CUDA/cuDNN version: NA\n GPU model and memory: NA\n \n <denchmark-link:https://gist.github.com/brianmartin/2b43dca69453478ed33b49f1029e03fe>Gist of full output of `./tools/tf_env_collect.sh</denchmark-link>\n \n Exact command to reproduce:\n <denchmark-code>$ wget https://gist.githubusercontent.com/brianmartin/4f221eb838dce8099342f829fb13253d/raw/00c2a1736b9a292f8a6fb88164d240a766468744/gistfile1.txt\n $ python gistfile1.txt\n </denchmark-code>\n \n Describe the current behavior\n Current behavior in 1.11.0, 1.12.0rcX is that the included script segfaults (11: SIGSEGV).\n Describe the expected behavior\n Expected behavior is no segfault. Version 1.10.1, 1.10.0, and 1.9.0 do not segfault. I have not checked lower versions.\n Code to reproduce the issue\n See a full script which reproduces this issue along two different code paths here: <denchmark-link:https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d>https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d</denchmark-link>\n \n The segfault occurs when reading the dataset a second time. The first read works as expected.\n For reference the two code samples which produce datasets which cause a segfault on second read are:\n     dataset = make_batched_features_dataset(file_pattern=data_file,\n                                             batch_size=1,\n                                             features=feature_spec)\n I've also dug into make_batched_features_dataset and minified down to this repro:\n     from tensorflow.contrib.data.python.ops import parsing_ops\n     from tensorflow.python.data.ops import readers\n \n     dataset = Dataset.from_tensor_slices([data_file]) \\\n                      .interleave(readers.TFRecordDataset, cycle_length=1) \\\n                      .batch(batch_size=1) \\\n                      .apply(parsing_ops.parse_example_dataset(feature_spec))\n <denchmark-h:hr></denchmark-h>\n \n Please let me know if there's anything else I can provide or help with! This is blocking us from upgrading to the latest Tensorflow version in <denchmark-link:https://github.com/spotify/spotify-tensorflow>spotify/spotify-tensorflow</denchmark-link>\n .\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "brianmartin", "commentT": "2018-10-24T06:44:07Z", "comment_text": "\n \t\tThank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\n Have I written custom code\n OS Platform and Distribution\n TensorFlow installed from\n Bazel version\n CUDA/cuDNN version\n GPU model and memory\n Exact command to reproduce\n Mobile device\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "brianmartin", "commentT": "2018-10-24T14:28:33Z", "comment_text": "\n \t\tUpdated!\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "brianmartin", "commentT": "2018-10-26T01:24:06Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/shivaniag>@shivaniag</denchmark-link>\n  As we discussed offline, can you please take a look at this issue, in case there\u2019s a bug in ? Thanks!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "brianmartin", "commentT": "2018-10-30T14:56:30Z", "comment_text": "\n \t\tI've dug in a bit more. For a FixedLenFeature, this test case still succeeds on the first read and fails on the second read -- no change there. But it fails with an exception rather than the segfault we see with VarLenFeature.\n I've updated the gist to reproduce in tensorflow>=1.11.0 here: <denchmark-link:https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d>https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d</denchmark-link>\n \n The exception on the second, failing read (after seeing the first read succeed):\n <denchmark-code>Attempting first read..\n 2018-10-30 10:53:26.766551: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n {'f0': <tf.Tensor: id=26, shape=(1, 1), dtype=int64, numpy=array([[1]])>}\n Attempting second identical read..\n Traceback (most recent call last):\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py\", line 109, in <module>\n     main()\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py\", line 104, in main\n     run(make_it_fail, read_fn, var_len=var_len)\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py\", line 79, in run\n     _print_first(read_fn(data_file, feature_spec))\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py\", line 35, in _print_first\n     print next(xs.__iter__())\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 139, in __iter__\n     return iterator_ops.EagerIterator(self)\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 521, in __init__\n     ds_variant = dataset._as_variant_tensor()  # pylint: disable=protected-access\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/contrib/data/python/ops/parsing_ops.py\", line 90, in _as_variant_tensor\n     **dataset_ops.flat_structure(self))\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 3963, in parse_example_dataset\n     ctx=_ctx)\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 4015, in parse_example_dataset_eager_fallback\n     attrs=_attrs, ctx=_ctx, name=name)\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\n     six.raise_from(core._status_to_exception(e.code, message), None)\n   File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/six.py\", line 737, in raise_from\n     raise value\n tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected len(dense_defaults) == len(dense_keys) but got: 1 vs. 0 [Op:ParseExampleDataset]\n </denchmark-code>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "brianmartin", "commentT": "2018-10-31T00:18:08Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/brianmartin>@brianmartin</denchmark-link>\n  Thank you very much for narrowing down the bug, we have fixed it and are going to submit it soon, will update you when that is done.\n \t\t"}}}, "commit": {"commit_id": "95de98b58a35aaac2804716a70979e68596f3dae", "commit_author": "Shivani Agrawal", "commitT": "2018-10-30 18:36:11-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\core\\kernels\\data\\parse_example_dataset_op.cc", "file_new_name": "tensorflow\\core\\kernels\\data\\parse_example_dataset_op.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "145,146,147,148,149", "deleted_lines": "145,146,147,148,149", "method_info": {"method_name": "tensorflow::data::ParseExampleDatasetOp::MakeDataset", "method_params": "ctx,input,output", "method_startline": "72", "method_endline": "150"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 25, "file_old_name": "tensorflow\\python\\data\\experimental\\kernel_tests\\parse_example_dataset_test.py", "file_new_name": "tensorflow\\python\\data\\experimental\\kernel_tests\\parse_example_dataset_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "537,538", "deleted_lines": null, "method_info": {"method_name": "testSkipEagerSerializedSparseAndSparseFeatureAndDenseWithNoDefault", "method_params": "self", "method_startline": "537", "method_endline": "538"}}, "hunk_1": {"Ismethod": 1, "added_lines": "266,301,302", "deleted_lines": "295,297", "method_info": {"method_name": "testSkipEagerSerializedContainingSparseFeature", "method_params": "self", "method_startline": "266", "method_endline": "302"}}, "hunk_2": {"Ismethod": 1, "added_lines": "694,695,697,702,762,763", "deleted_lines": "685,745", "method_info": {"method_name": "testSerializedContainingVarLenDense", "method_params": "self", "method_startline": "685", "method_endline": "846"}}, "hunk_3": {"Ismethod": 1, "added_lines": "534,535,537,538", "deleted_lines": "524,580", "method_info": {"method_name": "testSerializedContainingSparseAndSparseFeatureAndDenseWithNoDefault", "method_params": "self", "method_startline": "524", "method_endline": "580"}}, "hunk_4": {"Ismethod": 1, "added_lines": "121,159,160", "deleted_lines": "155", "method_info": {"method_name": "testSkipEagerEmptySerializedWithAllDefaults", "method_params": "self", "method_startline": "121", "method_endline": "160"}}, "hunk_5": {"Ismethod": 1, "added_lines": "263,264,266", "deleted_lines": "260,295", "method_info": {"method_name": "testSerializedContainingSparseFeature", "method_params": "self", "method_startline": "260", "method_endline": "295"}}, "hunk_6": {"Ismethod": 1, "added_lines": "472,473", "deleted_lines": "462", "method_info": {"method_name": "testSerializedContainingDenseWithConcat", "method_params": "self", "method_startline": "430", "method_endline": "473"}}, "hunk_7": {"Ismethod": 1, "added_lines": null, "deleted_lines": "82", "method_info": {"method_name": "_test", "method_params": "self,input_tensor,feature_val,expected_values,expected_err", "method_startline": "78", "method_endline": "82"}}, "hunk_8": {"Ismethod": 1, "added_lines": "694,695", "deleted_lines": "678,680,685", "method_info": {"method_name": "_testSerializedContainingVarLenDenseLargerBatch", "method_params": "self,batch_size", "method_startline": "637", "method_endline": "695"}}, "hunk_9": {"Ismethod": 1, "added_lines": "425,426", "deleted_lines": "416", "method_info": {"method_name": "testSerializedContainingDense", "method_params": "self", "method_startline": "393", "method_endline": "426"}}, "hunk_10": {"Ismethod": 1, "added_lines": "117,118,119,120,121", "deleted_lines": "117,155", "method_info": {"method_name": "testEmptySerializedWithAllDefaults", "method_params": "self", "method_startline": "117", "method_endline": "155"}}, "hunk_11": {"Ismethod": 1, "added_lines": "344,345,347", "deleted_lines": "339,382", "method_info": {"method_name": "testSerializedContaining3DSparseFeature", "method_params": "self", "method_startline": "339", "method_endline": "382"}}, "hunk_12": {"Ismethod": 1, "added_lines": "347,390,391", "deleted_lines": "382", "method_info": {"method_name": "testSkipEagerSerializedContaining3DSparseFeature", "method_params": "self", "method_startline": "347", "method_endline": "391"}}, "hunk_13": {"Ismethod": 1, "added_lines": "84,85", "deleted_lines": "82,83,84,85", "method_info": {"method_name": "_test", "method_params": "self,input_tensor,feature_val,expected_values,expected_err,create_iterator_twice", "method_startline": "80", "method_endline": "85"}}, "hunk_14": {"Ismethod": 1, "added_lines": "534,535", "deleted_lines": "522,524", "method_info": {"method_name": "testSerializedContainingDenseWithDefaults", "method_params": "self", "method_startline": "499", "method_endline": "535"}}, "hunk_15": {"Ismethod": 1, "added_lines": null, "deleted_lines": "680", "method_info": {"method_name": "testSerializedContainingVarLenDenseLargerBatch", "method_params": "self", "method_startline": "680", "method_endline": "683"}}, "hunk_16": {"Ismethod": 1, "added_lines": "222", "deleted_lines": "217,258", "method_info": {"method_name": "testSerializedContainingSparse", "method_params": "self", "method_startline": "217", "method_endline": "258"}}, "hunk_17": {"Ismethod": 1, "added_lines": "222,263,264", "deleted_lines": "258,260", "method_info": {"method_name": "testSkipEagerSerializedContainingSparse", "method_params": "self", "method_startline": "222", "method_endline": "264"}}, "hunk_18": {"Ismethod": 1, "added_lines": "597,634,635", "deleted_lines": "619", "method_info": {"method_name": "testSkipEagererializedContainingSparseAndSparseFeatureWithReuse", "method_params": "self", "method_startline": "597", "method_endline": "635"}}, "hunk_19": {"Ismethod": 1, "added_lines": "304,344,345", "deleted_lines": "337,339", "method_info": {"method_name": "testSkipEagerSerializedContainingSparseFeatureReuse", "method_params": "self", "method_startline": "304", "method_endline": "345"}}, "hunk_20": {"Ismethod": 1, "added_lines": "697", "deleted_lines": null, "method_info": {"method_name": "testSkipEagerSerializedContainingVarLenDenseLargerBatch", "method_params": "self", "method_startline": "697", "method_endline": "700"}}, "hunk_21": {"Ismethod": 1, "added_lines": "594,595,597", "deleted_lines": "582,619", "method_info": {"method_name": "testSerializedContainingSparseAndSparseFeatureWithReuse", "method_params": "self", "method_startline": "582", "method_endline": "619"}}, "hunk_22": {"Ismethod": 1, "added_lines": "496,497", "deleted_lines": "485", "method_info": {"method_name": "testSerializedContainingDenseScalar", "method_params": "self", "method_startline": "475", "method_endline": "497"}}, "hunk_23": {"Ismethod": 1, "added_lines": "702,762,763", "deleted_lines": "745", "method_info": {"method_name": "testSkipEagerSerializedContainingVarLenDense", "method_params": "self", "method_startline": "702", "method_endline": "864"}}, "hunk_24": {"Ismethod": 1, "added_lines": "301,302,304", "deleted_lines": "297,337", "method_info": {"method_name": "testSerializedContainingSparseFeatureReuse", "method_params": "self", "method_startline": "297", "method_endline": "337"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\python\\framework\\test_util.py", "file_new_name": "tensorflow\\python\\framework\\test_util.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "767,768", "deleted_lines": "767", "method_info": {"method_name": "run_all_in_graph_and_eager_modes", "method_params": "cls", "method_startline": "763", "method_endline": "770"}}, "hunk_1": {"Ismethod": 1, "added_lines": "836", "deleted_lines": "835", "method_info": {"method_name": "decorator", "method_params": "f", "method_startline": "832", "method_endline": "872"}}}}}}}