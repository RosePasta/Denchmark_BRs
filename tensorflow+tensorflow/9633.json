{"BR": {"BR_id": "9633", "BR_author": "tpet", "BRopenT": "2017-05-03T15:49:22Z", "BRcloseT": "2017-05-05T18:20:38Z", "BR_text": {"BRsummary": "SIGSEGV with sparse_add and broadcasting", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\n yes, enclosed below\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n Ubuntu 16.04\n TensorFlow installed from (source or binary):\n binary via pip\n TensorFlow version (use command below):\n ('v1.0.0-65-g4763edf-dirty', '1.0.1')\n Bazel version (if compiling from source):\n N/A, using pip installation\n CUDA/cuDNN version:\n N/A, CPU-only\n GPU model and memory:\n none\n Exact command to reproduce:\n \n <denchmark-code>from __future__ import print_function\n import numpy as np\n import tensorflow as tf\n \n dense_sz = [1, 1000, 1000]\n dense = tf.constant(1.0, shape=dense_sz, dtype=tf.float32)\n \n sparse_sz = [10, 1000, 1000]\n nnz = 100\n nz_ind = np.random.choice(np.prod(sparse_sz), size=nnz, replace=False)\n nz_ind = np.unravel_index(nz_ind, dims=sparse_sz)\n nz_ind = np.array(nz_ind).T\n assert np.all(nz_ind < np.array(sparse_sz)[None, :])\n # Ensure canonical ordering.\n ind = np.lexsort([nz_ind[:, i].flatten() for i in reversed(range(nz_ind.shape[1]))])\n nz_ind = nz_ind[ind, :]\n print('nz_ind\\n', nz_ind)\n \n sparse_plc = tf.sparse_placeholder(tf.float32)\n sparse_sum = tf.sparse_add(dense, sparse_plc)\n init = tf.global_variables_initializer()\n \n with tf.Session() as sess:\n     sess.run(init)\n     print('after init')\n     res = sess.run(sparse_sum, feed_dict={sparse_plc: tf.SparseTensorValue(nz_ind, np.ones((nnz,)), sparse_sz)})\n     print('sum\\n', res)\n </denchmark-code>\n \n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n Running the code above results in\n <denchmark-code>[...]\n after init\n \n Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)\n </denchmark-code>\n \n For lower values of nnz, (nnz = 1) it finishes fine quite often.\n <denchmark-code>[...]\n after init\n sum\n  [[[ 1.  1.  1. ...,  1.  1.  1.]\n   [ 1.  1.  1. ...,  1.  1.  1.]\n   [ 1.  1.  1. ...,  1.  1.  1.]\n   ..., \n   [ 1.  1.  1. ...,  1.  1.  1.]\n   [ 1.  1.  1. ...,  1.  1.  1.]\n   [ 1.  1.  1. ...,  1.  1.  1.]]]\n \n Process finished with exit code 0\n </denchmark-code>\n \n <denchmark-h:h3>Source code / logs</denchmark-h>\n \n See above.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "tpet", "commentT": "2017-05-03T17:29:05Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/concretevitamin>@concretevitamin</denchmark-link>\n  can you take a look at this?\n Here's the stacktrace:\n <denchmark-code>PC: @     0x7f37662d027d  (unknown)  raise\n     @         0x243417e6       1120  FailureSignalHandler()\n     @     0x7f37662d03d0       1472  (unknown)\n     @     0x7f3764db3191        128  faulthandler_fatal_error\n     @     0x7f37662d03d0  (unknown)  (unknown)\n     @         0x2217d353       1664  tensorflow::SparseTensorDenseAddOp<>::Compute()\n     @         0x22f76586         96  tensorflow::ThreadPoolDevice::Compute()\n     @         0x22f0764b       2464  tensorflow::(anonymous namespace)::ExecutorState::Process()\n     @         0x22f13cb1        160  std::_Mem_fn<>::operator()<>()\n     @         0x22f13bc3         96  std::_Bind<>::__call<>()\n     @         0x22f13b06         64  std::_Bind<>::operator()<>()\n     @         0x22f136fd         32  std::_Function_handler<>::_M_invoke()\n     @         0x13172ede         32  std::function<>::operator()()\n     @         0x2325fcc8        128  tensorflow::thread::EigenEnvironment::ExecuteTask()\n     @         0x2325f019        208  Eigen::ThreadPoolTempl<>::WorkerLoop()\n     @         0x2325ec5e         32  Eigen::ThreadPoolTempl<>::ThreadPoolTempl()::{lambda()#1}::operator()()\n     @         0x2325eacd         32  std::_Function_handler<>::_M_invoke()\n     @         0x13172ede         32  std::function<>::operator()()\n     @         0x2325e934         48  tensorflow::thread::EigenEnvironment::CreateThread()::{lambda()#1}::operator()()\n     @         0x2325e76d         32  std::_Function_handler<>::_M_invoke()\n     @         0x13172ede         32  std::function<>::operator()()\n     @         0x23296f0c         32  tensorflow::(anonymous namespace)::GoogleThread::FuncThread::Run()\n     @         0x23d41427        448  Thread::ThreadBody()\n     @     0x7f37662c6890        176  start_thread\n     @     0x7f3765d2237d  (unknown)  clone\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "tpet", "commentT": "2017-05-03T23:10:18Z", "comment_text": "\n \t\tDid you modify anything else in the code? The version shows dirty.\n <denchmark-link:https://github.com/yifeif>@yifeif</denchmark-link>\n  <denchmark-link:https://github.com/av8ramit>@av8ramit</denchmark-link>\n  are the pip installs built from a dirty git repo?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "tpet", "commentT": "2017-05-04T01:14:38Z", "comment_text": "\n \t\tI'm taking a look.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "tpet", "commentT": "2017-05-04T10:56:25Z", "comment_text": "\n \t\tThe results look the same with tf pip-upgraded to ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0').\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "tpet", "commentT": "2017-05-04T18:59:16Z", "comment_text": "\n \t\tThanks for the report <denchmark-link:https://github.com/tpet>@tpet</denchmark-link>\n .\n I am submitting a \"fix\" that instead of segfaulting, return a proper error status that requires both operands have matching shapes.  This has always been the assumption in the , but was <denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc#L56>not enforced</denchmark-link>\n .  The patch should show up in master within a day or two.\n Do you exactly require the functionality of \"sparse + dense -> dense, with dense-to-sparse broadcast\"?  If so, I'd like to mark this as contributions welcome (the current kernels do not support this broadcast pattern).\n However, if you can get away with \"sparse + dense -> sparse, with dense-to-sparse broadcast\", we already have <denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/sparse_ops.py#L316>sparse_dense_cwise_add()</denchmark-link>\n  that does this.  Let us know, and we can expose this function as a public method.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "tpet", "commentT": "2017-05-05T10:40:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/concretevitamin>@concretevitamin</denchmark-link>\n  I agree raising an exception is much better. The \"sparse + dense -> dense, with dense-to-sparse broadcast\" really seems not that much useful, compared to \"sparse + dense -> sparse, with dense-to-sparse broadcast\". Now I actually don't need this particular thing.\n My initial use case was a bit different. In the process of trying to get some reasonable behavior I happened to find the segfault and created this example.\n My use case is this:\n D + reduce_sum(a * S)\n where D and the result is dense [1 n2 n3 n4]\n S is sparse [n1 n2 n3 n4]\n a is dense [n1 1 1 1] and broadcasts to S.\n So far I hasn't been able to get to some reasonable performance with this.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "tpet", "commentT": "2017-05-05T10:50:52Z", "comment_text": "\n \t\tI'm using a pip installation so it will take some time until it propagates down to me so feel free to close the issue if you think it is resolved. Thanks.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "tpet", "commentT": "2017-05-05T18:20:38Z", "comment_text": "\n \t\tOkay, closing for now.  For the reduce, take a look at tf.sparse_reduce_sum() and/or tf.sparse_reduce_sum_reduce().\n \t\t"}}}, "commit": {"commit_id": "50b836addfed6b49fc823987e9301f1b6eeef90c", "commit_author": "Zongheng Yang", "commitT": "2017-05-04 12:30:04-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\core\\kernels\\sparse_tensor_dense_add_op.cc", "file_new_name": "tensorflow\\core\\kernels\\sparse_tensor_dense_add_op.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "50,51,52,57,58,59,60,61,62,63,64,65,66,67,68,69,95,96,97", "deleted_lines": "50,51,56,57,58,59,85,86", "method_info": {"method_name": "tensorflow::SparseTensorDenseAddOp::Compute", "method_params": "ctx", "method_startline": "37", "method_endline": "102"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\ops\\sparse_ops.py", "file_new_name": "tensorflow\\python\\ops\\sparse_ops.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "244,245", "deleted_lines": null, "method_info": {"method_name": "sparse_add", "method_params": "a,b,thresh", "method_startline": "236", "method_endline": "315"}}}}}}}