{"BR": {"BR_id": "224", "BR_author": "vdaita", "BRopenT": "2020-06-28T23:30:32Z", "BRcloseT": "2020-06-29T00:07:10Z", "BR_text": {"BRsummary": "Unable to Convert to ONNX MOdel", "BRdescription": "\n Before submitting a bug report, please be aware that your issue must be reproducible with all of the following, otherwise it is non-actionable, and we can not help you:\n \n Current repo: run git fetch && git status -uno to check and git pull to update repo - Is using current repository.\n Common dataset: coco.yaml or coco128.yaml Dataset: https://github.com/archie9211/Mask-Detection-Dataset, with .yaml files described in notebook.\n Common environment: Colab, Google Cloud, or Docker image. See https://github.com/ultralytics/yolov5#reproduce-our-environment --\n \n Based on the following repository: <denchmark-link:https://github.com/offsouza/yolov5_face_mask_detection>https://github.com/offsouza/yolov5_face_mask_detection</denchmark-link>\n \n If this is a custom dataset/training question you must include your train*.jpg, test*.jpg and results.png figures, or we can not help you. You can generate these with utils.plot_results().\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n A clear and concise description of what the bug is.\n Following error when using the following command to convert .pt to ONNX.\n !python3 onnx_export.py --weights=results.pt --img-size=416 --batch-size=1 \n <denchmark-code>/content/yolov5\n Namespace(batch_size=1, img_size=[416], weights='results.pt')\n Fusing layers...\n Model Summary: 140 layers, 7.24922e+06 parameters, 6.61683e+06 gradients\n Traceback (most recent call last):\n   File \"onnx_export.py\", line 34, in <module>\n     _ = model(img)  # dry run\n   File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"/content/yolov5/models/yolo.py\", line 90, in forward\n     return self.forward_once(x, profile)  # single-scale inference, train\n   File \"/content/yolov5/models/yolo.py\", line 110, in forward_once\n     x = m(x)  # run\n   File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"/content/yolov5/models/common.py\", line 87, in forward\n     return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))\n   File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"/content/yolov5/models/common.py\", line 25, in fuseforward\n     return self.act(self.conv(x))\n   File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 353, in forward\n     return self._conv_forward(input, self.weight)\n   File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 350, in _conv_forward\n     self.padding, self.dilation, self.groups)\n RuntimeError: Expected 4-dimensional input for 4-dimensional weight [32, 12, 3, 3], but got 3-dimensional input of size [1, 6, 208] instead\n </denchmark-code>\n \n <denchmark-h:h2>To Reproduce (REQUIRED)</denchmark-h>\n \n Input:\n <denchmark-code>import torch\n \n a = torch.tensor([5])\n c = a / 0\n </denchmark-code>\n \n Output:\n <denchmark-code>Traceback (most recent call last):\n   File \"/Users/glennjocher/opt/anaconda3/envs/env1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n     exec(code_obj, self.user_global_ns, self.user_ns)\n   File \"<ipython-input-5-be04c762b799>\", line 5, in <module>\n     c = a / 0\n RuntimeError: ZeroDivisionError\n </denchmark-code>\n \n <denchmark-h:h2>Expected behavior</denchmark-h>\n \n A clear and concise description of what you expected to happen.\n I expected an onnx model that I could then convert to Tensorflow, before integrating that into an Android app. (Hopefully MLKit has built-in NMS)\n <denchmark-h:h2>Environment</denchmark-h>\n \n If applicable, add screenshots to help explain your problem.\n \n OS: [e.g. Ubuntu]\n GPU [e.g. 2080 Ti]\n \n Google Colab GPU instance\n <denchmark-h:h2>Additional context</denchmark-h>\n \n Add any other context about the problem here.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "vdaita", "commentT": "2020-06-28T23:31:10Z", "comment_text": "\n \t\tHello <denchmark-link:https://github.com/vdaita>@vdaita</denchmark-link>\n , thank you for your interest in our work! Please visit our <denchmark-link:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data>Custom Training Tutorial</denchmark-link>\n  to get started, and see our <denchmark-link:https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb>Jupyter Notebook</denchmark-link>\n  <denchmark-link:https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb></denchmark-link>\n , <denchmark-link:https://hub.docker.com/r/ultralytics/yolov5>Docker Image</denchmark-link>\n , and <denchmark-link:https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart>Google Cloud Quickstart Guide</denchmark-link>\n  for example environments.\n If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.\n If this is a custom model or data training question, please note that Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:\n \n Cloud-based AI systems operating on hundreds of HD video streams in realtime.\n Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.\n Custom data training, hyperparameter evolution, and model exportation to any destination.\n \n For more information please visit <denchmark-link:https://www.ultralytics.com>https://www.ultralytics.com</denchmark-link>\n .\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "vdaita", "commentT": "2020-07-09T23:36:35Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/vdaita>@vdaita</denchmark-link>\n  have you transferred the model to tensorflow format successfully?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "vdaita", "commentT": "2020-07-09T23:44:10Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/zhanghang1989>@zhanghang1989</denchmark-link>\n  Not to TF formal, there is another Issue for that I believe.\n \t\t"}}}, "commit": {"commit_id": "0bc80e1e57d1a993e4980e73f7c89820fc2801c5", "commit_author": "Glenn Jocher", "commitT": "2020-06-28 17:07:03-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "models\\onnx_export.py", "file_new_name": "models\\onnx_export.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "20", "deleted_lines": null}}}}}}